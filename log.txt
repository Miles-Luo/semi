[20:05:58.247] Namespace(base_lr=0.01, batch_size=6, consistency=0.1, consistency_rampup=200.0, consistency_type='mse', deterministic=1, ema_decay=0.99, exp='ACDC/my_net3210', labeled_bs=3, labeled_num=14, max_iterations=30000, model='unet_cct', num_classes=4, patch_size=[256, 256], root_path='../data/ACDC', seed=1337)
[20:06:00.269] 85 iterations per epoch
[20:06:02.608] iteration 1 : model1 loss : 1.155341 model2 loss : 1.055976
[20:06:03.319] iteration 2 : model1 loss : 1.131544 model2 loss : 1.049468
[20:06:04.020] iteration 3 : model1 loss : 1.096046 model2 loss : 1.021249
[20:06:04.707] iteration 4 : model1 loss : 1.049186 model2 loss : 0.970979
[20:06:05.377] iteration 5 : model1 loss : 1.021066 model2 loss : 0.957227
[20:06:06.060] iteration 6 : model1 loss : 0.939087 model2 loss : 0.880937
[20:06:06.744] iteration 7 : model1 loss : 0.901306 model2 loss : 0.851915
[20:06:07.425] iteration 8 : model1 loss : 0.829080 model2 loss : 0.807662
[20:06:08.103] iteration 9 : model1 loss : 0.779141 model2 loss : 0.756972
[20:06:08.799] iteration 10 : model1 loss : 0.737794 model2 loss : 0.723504
[20:06:09.486] iteration 11 : model1 loss : 0.710577 model2 loss : 0.707587
[20:06:10.163] iteration 12 : model1 loss : 0.665916 model2 loss : 0.661373
[20:06:10.846] iteration 13 : model1 loss : 0.633270 model2 loss : 0.636128
[20:06:11.522] iteration 14 : model1 loss : 0.603116 model2 loss : 0.611493
[20:06:12.198] iteration 15 : model1 loss : 0.602325 model2 loss : 0.606837
[20:06:12.884] iteration 16 : model1 loss : 0.582956 model2 loss : 0.585912
[20:06:13.571] iteration 17 : model1 loss : 0.574812 model2 loss : 0.577040
[20:06:14.273] iteration 18 : model1 loss : 0.534468 model2 loss : 0.544817
[20:06:14.954] iteration 19 : model1 loss : 0.544749 model2 loss : 0.552927
[20:06:15.643] iteration 20 : model1 loss : 0.558073 model2 loss : 0.557412
[20:06:16.341] iteration 21 : model1 loss : 0.503981 model2 loss : 0.498618
[20:06:17.026] iteration 22 : model1 loss : 0.541808 model2 loss : 0.544838
[20:06:17.709] iteration 23 : model1 loss : 0.509555 model2 loss : 0.499257
[20:06:18.393] iteration 24 : model1 loss : 0.485904 model2 loss : 0.485731
[20:06:19.092] iteration 25 : model1 loss : 0.533958 model2 loss : 0.522847
[20:06:19.788] iteration 26 : model1 loss : 0.502883 model2 loss : 0.509909
[20:06:20.491] iteration 27 : model1 loss : 0.476604 model2 loss : 0.480119
[20:06:21.188] iteration 28 : model1 loss : 0.519780 model2 loss : 0.519289
[20:06:21.858] iteration 29 : model1 loss : 0.464830 model2 loss : 0.470771
[20:06:22.568] iteration 30 : model1 loss : 0.480881 model2 loss : 0.485898
[20:06:23.271] iteration 31 : model1 loss : 0.467091 model2 loss : 0.467647
[20:06:24.111] iteration 32 : model1 loss : 0.457770 model2 loss : 0.454314
[20:06:24.828] iteration 33 : model1 loss : 0.486313 model2 loss : 0.491442
[20:06:25.531] iteration 34 : model1 loss : 0.456733 model2 loss : 0.454601
[20:06:26.212] iteration 35 : model1 loss : 0.471159 model2 loss : 0.455958
[20:06:26.908] iteration 36 : model1 loss : 0.463988 model2 loss : 0.452408
[20:06:27.574] iteration 37 : model1 loss : 0.457131 model2 loss : 0.448164
[20:06:28.270] iteration 38 : model1 loss : 0.419581 model2 loss : 0.423924
[20:06:28.964] iteration 39 : model1 loss : 0.486971 model2 loss : 0.482592
[20:06:29.631] iteration 40 : model1 loss : 0.503990 model2 loss : 0.490036
[20:06:30.327] iteration 41 : model1 loss : 0.455064 model2 loss : 0.448746
[20:06:31.011] iteration 42 : model1 loss : 0.453603 model2 loss : 0.449172
[20:06:31.691] iteration 43 : model1 loss : 0.518457 model2 loss : 0.508887
[20:06:32.365] iteration 44 : model1 loss : 0.440147 model2 loss : 0.445689
[20:06:33.043] iteration 45 : model1 loss : 0.425367 model2 loss : 0.425951
[20:06:33.723] iteration 46 : model1 loss : 0.429818 model2 loss : 0.426019
[20:06:34.417] iteration 47 : model1 loss : 0.451583 model2 loss : 0.444951
[20:06:35.098] iteration 48 : model1 loss : 0.416173 model2 loss : 0.409829
[20:06:35.783] iteration 49 : model1 loss : 0.453692 model2 loss : 0.457492
[20:06:36.471] iteration 50 : model1 loss : 0.411681 model2 loss : 0.406538
[20:06:37.224] iteration 51 : model1 loss : 0.416512 model2 loss : 0.412958
[20:06:37.928] iteration 52 : model1 loss : 0.399197 model2 loss : 0.405859
[20:06:38.648] iteration 53 : model1 loss : 0.437447 model2 loss : 0.432720
[20:06:39.354] iteration 54 : model1 loss : 0.436191 model2 loss : 0.430007
[20:06:40.029] iteration 55 : model1 loss : 0.433309 model2 loss : 0.440208
[20:06:40.717] iteration 56 : model1 loss : 0.430330 model2 loss : 0.458089
[20:06:41.413] iteration 57 : model1 loss : 0.442421 model2 loss : 0.442143
[20:06:42.082] iteration 58 : model1 loss : 0.449742 model2 loss : 0.450473
[20:06:42.740] iteration 59 : model1 loss : 0.438597 model2 loss : 0.418681
[20:06:43.402] iteration 60 : model1 loss : 0.451271 model2 loss : 0.449118
[20:06:44.070] iteration 61 : model1 loss : 0.425278 model2 loss : 0.417792
[20:06:44.727] iteration 62 : model1 loss : 0.428918 model2 loss : 0.424825
[20:06:45.385] iteration 63 : model1 loss : 0.405810 model2 loss : 0.407078
[20:06:46.066] iteration 64 : model1 loss : 0.438578 model2 loss : 0.441457
[20:06:46.736] iteration 65 : model1 loss : 0.424572 model2 loss : 0.423307
[20:06:47.403] iteration 66 : model1 loss : 0.428711 model2 loss : 0.430439
[20:06:48.079] iteration 67 : model1 loss : 0.465346 model2 loss : 0.452445
[20:06:48.742] iteration 68 : model1 loss : 0.424175 model2 loss : 0.423040
[20:06:49.428] iteration 69 : model1 loss : 0.433408 model2 loss : 0.422706
[20:06:50.086] iteration 70 : model1 loss : 0.423245 model2 loss : 0.424392
[20:06:50.748] iteration 71 : model1 loss : 0.415515 model2 loss : 0.413181
[20:06:51.432] iteration 72 : model1 loss : 0.448190 model2 loss : 0.443331
[20:06:52.092] iteration 73 : model1 loss : 0.403707 model2 loss : 0.394607
[20:06:52.759] iteration 74 : model1 loss : 0.416930 model2 loss : 0.404875
[20:06:53.436] iteration 75 : model1 loss : 0.439834 model2 loss : 0.449848
[20:06:54.108] iteration 76 : model1 loss : 0.418692 model2 loss : 0.415572
[20:06:54.779] iteration 77 : model1 loss : 0.434729 model2 loss : 0.429252
[20:06:55.435] iteration 78 : model1 loss : 0.378907 model2 loss : 0.376313
[20:06:56.101] iteration 79 : model1 loss : 0.394023 model2 loss : 0.411267
[20:06:56.775] iteration 80 : model1 loss : 0.453534 model2 loss : 0.453441
[20:06:57.440] iteration 81 : model1 loss : 0.446128 model2 loss : 0.438691
[20:06:58.152] iteration 82 : model1 loss : 0.395698 model2 loss : 0.397760
[20:06:58.825] iteration 83 : model1 loss : 0.439296 model2 loss : 0.419701
[20:06:59.490] iteration 84 : model1 loss : 0.399850 model2 loss : 0.404099
[20:07:00.154] iteration 85 : model1 loss : 0.441000 model2 loss : 0.451079
[20:07:00.818] iteration 86 : model1 loss : 0.411407 model2 loss : 0.415394
[20:07:01.494] iteration 87 : model1 loss : 0.419896 model2 loss : 0.407703
[20:07:02.148] iteration 88 : model1 loss : 0.391103 model2 loss : 0.401787
[20:07:02.809] iteration 89 : model1 loss : 0.355923 model2 loss : 0.370003
[20:07:03.480] iteration 90 : model1 loss : 0.422979 model2 loss : 0.447967
[20:07:04.154] iteration 91 : model1 loss : 0.399285 model2 loss : 0.398823
[20:07:04.824] iteration 92 : model1 loss : 0.425779 model2 loss : 0.414574
[20:07:05.491] iteration 93 : model1 loss : 0.424247 model2 loss : 0.410859
[20:07:06.163] iteration 94 : model1 loss : 0.437101 model2 loss : 0.431762
[20:07:06.827] iteration 95 : model1 loss : 0.427057 model2 loss : 0.429670
[20:07:07.492] iteration 96 : model1 loss : 0.394363 model2 loss : 0.393078
[20:07:08.162] iteration 97 : model1 loss : 0.462009 model2 loss : 0.457808
[20:07:08.819] iteration 98 : model1 loss : 0.430788 model2 loss : 0.419904
[20:07:09.472] iteration 99 : model1 loss : 0.443898 model2 loss : 0.457886
[20:07:10.145] iteration 100 : model1 loss : 0.464567 model2 loss : 0.464554
[20:07:10.845] iteration 101 : model1 loss : 0.420219 model2 loss : 0.429854
[20:07:11.522] iteration 102 : model1 loss : 0.416211 model2 loss : 0.404325
[20:07:12.194] iteration 103 : model1 loss : 0.423243 model2 loss : 0.429296
[20:07:12.866] iteration 104 : model1 loss : 0.429497 model2 loss : 0.417940
[20:07:13.536] iteration 105 : model1 loss : 0.444403 model2 loss : 0.452746
[20:07:14.195] iteration 106 : model1 loss : 0.421491 model2 loss : 0.425713
[20:07:14.869] iteration 107 : model1 loss : 0.410586 model2 loss : 0.409604
[20:07:15.533] iteration 108 : model1 loss : 0.406448 model2 loss : 0.423677
[20:07:16.217] iteration 109 : model1 loss : 0.388717 model2 loss : 0.389256
[20:07:16.889] iteration 110 : model1 loss : 0.369712 model2 loss : 0.393085
[20:07:17.549] iteration 111 : model1 loss : 0.398105 model2 loss : 0.433336
[20:07:18.206] iteration 112 : model1 loss : 0.377377 model2 loss : 0.379180
[20:07:18.866] iteration 113 : model1 loss : 0.404905 model2 loss : 0.396309
[20:07:19.539] iteration 114 : model1 loss : 0.372859 model2 loss : 0.369578
[20:07:20.206] iteration 115 : model1 loss : 0.397117 model2 loss : 0.409687
[20:07:20.867] iteration 116 : model1 loss : 0.414314 model2 loss : 0.402951
[20:07:21.544] iteration 117 : model1 loss : 0.415061 model2 loss : 0.393411
[20:07:22.210] iteration 118 : model1 loss : 0.444194 model2 loss : 0.427871
[20:07:22.868] iteration 119 : model1 loss : 0.434165 model2 loss : 0.419186
[20:07:23.538] iteration 120 : model1 loss : 0.372531 model2 loss : 0.370889
[20:07:24.207] iteration 121 : model1 loss : 0.389632 model2 loss : 0.382940
[20:07:24.871] iteration 122 : model1 loss : 0.416467 model2 loss : 0.393639
[20:07:25.538] iteration 123 : model1 loss : 0.384648 model2 loss : 0.410130
[20:07:26.198] iteration 124 : model1 loss : 0.365627 model2 loss : 0.367610
[20:07:26.866] iteration 125 : model1 loss : 0.386620 model2 loss : 0.403976
[20:07:27.527] iteration 126 : model1 loss : 0.360626 model2 loss : 0.366328
[20:07:28.197] iteration 127 : model1 loss : 0.413336 model2 loss : 0.420433
[20:07:28.867] iteration 128 : model1 loss : 0.405723 model2 loss : 0.424145
[20:07:29.526] iteration 129 : model1 loss : 0.405618 model2 loss : 0.405035
[20:07:30.190] iteration 130 : model1 loss : 0.382307 model2 loss : 0.412578
[20:07:30.841] iteration 131 : model1 loss : 0.378951 model2 loss : 0.380005
[20:07:31.519] iteration 132 : model1 loss : 0.430372 model2 loss : 0.446936
[20:07:32.170] iteration 133 : model1 loss : 0.445489 model2 loss : 0.439465
[20:07:32.836] iteration 134 : model1 loss : 0.415340 model2 loss : 0.435560
[20:07:33.500] iteration 135 : model1 loss : 0.383680 model2 loss : 0.405430
[20:07:34.157] iteration 136 : model1 loss : 0.361054 model2 loss : 0.373970
[20:07:34.818] iteration 137 : model1 loss : 0.420286 model2 loss : 0.421297
[20:07:35.487] iteration 138 : model1 loss : 0.386395 model2 loss : 0.393478
[20:07:36.149] iteration 139 : model1 loss : 0.404261 model2 loss : 0.411038
[20:07:36.814] iteration 140 : model1 loss : 0.383087 model2 loss : 0.392654
[20:07:37.487] iteration 141 : model1 loss : 0.340284 model2 loss : 0.333620
[20:07:38.146] iteration 142 : model1 loss : 0.402836 model2 loss : 0.412946
[20:07:38.806] iteration 143 : model1 loss : 0.394617 model2 loss : 0.391247
[20:07:39.475] iteration 144 : model1 loss : 0.382146 model2 loss : 0.404768
[20:07:40.139] iteration 145 : model1 loss : 0.404061 model2 loss : 0.411763
[20:07:40.828] iteration 146 : model1 loss : 0.346078 model2 loss : 0.365169
[20:07:41.483] iteration 147 : model1 loss : 0.358038 model2 loss : 0.355446
[20:07:42.153] iteration 148 : model1 loss : 0.337717 model2 loss : 0.338283
[20:07:42.837] iteration 149 : model1 loss : 0.397041 model2 loss : 0.382822
[20:07:43.502] iteration 150 : model1 loss : 0.359730 model2 loss : 0.365776
[20:07:44.209] iteration 151 : model1 loss : 0.375664 model2 loss : 0.367078
[20:07:44.878] iteration 152 : model1 loss : 0.325694 model2 loss : 0.334339
[20:07:45.556] iteration 153 : model1 loss : 0.399982 model2 loss : 0.396075
[20:07:46.222] iteration 154 : model1 loss : 0.406740 model2 loss : 0.409283
[20:07:46.877] iteration 155 : model1 loss : 0.339018 model2 loss : 0.353954
[20:07:47.543] iteration 156 : model1 loss : 0.418277 model2 loss : 0.424391
[20:07:48.205] iteration 157 : model1 loss : 0.396083 model2 loss : 0.404406
[20:07:48.870] iteration 158 : model1 loss : 0.349124 model2 loss : 0.359460
[20:07:49.524] iteration 159 : model1 loss : 0.372517 model2 loss : 0.383869
[20:07:50.189] iteration 160 : model1 loss : 0.384116 model2 loss : 0.357201
[20:07:50.859] iteration 161 : model1 loss : 0.385888 model2 loss : 0.358353
[20:07:51.540] iteration 162 : model1 loss : 0.408610 model2 loss : 0.396427
[20:07:52.196] iteration 163 : model1 loss : 0.383892 model2 loss : 0.367876
[20:07:52.862] iteration 164 : model1 loss : 0.420562 model2 loss : 0.389580
[20:07:53.533] iteration 165 : model1 loss : 0.364610 model2 loss : 0.357253
[20:07:54.192] iteration 166 : model1 loss : 0.388297 model2 loss : 0.410903
[20:07:54.882] iteration 167 : model1 loss : 0.377176 model2 loss : 0.361162
[20:07:55.564] iteration 168 : model1 loss : 0.414801 model2 loss : 0.422344
[20:07:56.243] iteration 169 : model1 loss : 0.434641 model2 loss : 0.417644
[20:07:56.913] iteration 170 : model1 loss : 0.352681 model2 loss : 0.351943
[20:07:57.580] iteration 171 : model1 loss : 0.364280 model2 loss : 0.360460
[20:07:58.242] iteration 172 : model1 loss : 0.372809 model2 loss : 0.378425
[20:07:58.921] iteration 173 : model1 loss : 0.423220 model2 loss : 0.393521
[20:07:59.596] iteration 174 : model1 loss : 0.356084 model2 loss : 0.337772
[20:08:00.261] iteration 175 : model1 loss : 0.365134 model2 loss : 0.362964
[20:08:00.939] iteration 176 : model1 loss : 0.406524 model2 loss : 0.351268
[20:08:01.618] iteration 177 : model1 loss : 0.364216 model2 loss : 0.373172
[20:08:02.310] iteration 178 : model1 loss : 0.321132 model2 loss : 0.309525
[20:08:02.980] iteration 179 : model1 loss : 0.383243 model2 loss : 0.383133
[20:08:03.645] iteration 180 : model1 loss : 0.400949 model2 loss : 0.398628
[20:08:04.313] iteration 181 : model1 loss : 0.353056 model2 loss : 0.332830
[20:08:04.982] iteration 182 : model1 loss : 0.355318 model2 loss : 0.353154
[20:08:05.645] iteration 183 : model1 loss : 0.383263 model2 loss : 0.413702
[20:08:06.312] iteration 184 : model1 loss : 0.333237 model2 loss : 0.326627
[20:08:06.992] iteration 185 : model1 loss : 0.401506 model2 loss : 0.381898
[20:08:07.712] iteration 186 : model1 loss : 0.392466 model2 loss : 0.404549
[20:08:08.433] iteration 187 : model1 loss : 0.450311 model2 loss : 0.441051
[20:08:09.201] iteration 188 : model1 loss : 0.355372 model2 loss : 0.341032
[20:08:09.943] iteration 189 : model1 loss : 0.387079 model2 loss : 0.401139
[20:08:10.662] iteration 190 : model1 loss : 0.343165 model2 loss : 0.370642
[20:08:11.341] iteration 191 : model1 loss : 0.369409 model2 loss : 0.372306
[20:08:12.017] iteration 192 : model1 loss : 0.337665 model2 loss : 0.340107
[20:08:12.690] iteration 193 : model1 loss : 0.325381 model2 loss : 0.320996
[20:08:13.354] iteration 194 : model1 loss : 0.341779 model2 loss : 0.332254
[20:08:14.016] iteration 195 : model1 loss : 0.340745 model2 loss : 0.331091
[20:08:14.690] iteration 196 : model1 loss : 0.352837 model2 loss : 0.350855
[20:08:15.351] iteration 197 : model1 loss : 0.396444 model2 loss : 0.391363
[20:08:16.021] iteration 198 : model1 loss : 0.333998 model2 loss : 0.347382
[20:08:16.694] iteration 199 : model1 loss : 0.395377 model2 loss : 0.368932
[20:08:17.350] iteration 200 : model1 loss : 0.348330 model2 loss : 0.357930
[20:08:33.587] iteration 200 : model1_mean_dice : 0.138997 model1_mean_hd95 : 17.038706
[20:08:49.655] iteration 200 : model2_mean_dice : 0.107232 model2_mean_hd95 : 19.765398
[20:08:50.344] iteration 201 : model1 loss : 0.356774 model2 loss : 0.353561
[20:08:51.004] iteration 202 : model1 loss : 0.289654 model2 loss : 0.384649
[20:08:51.667] iteration 203 : model1 loss : 0.299666 model2 loss : 0.335716
[20:08:52.333] iteration 204 : model1 loss : 0.368213 model2 loss : 0.384458
[20:08:52.989] iteration 205 : model1 loss : 0.329341 model2 loss : 0.371887
[20:08:53.646] iteration 206 : model1 loss : 0.392807 model2 loss : 0.403402
[20:08:54.306] iteration 207 : model1 loss : 0.364350 model2 loss : 0.416519
[20:08:54.972] iteration 208 : model1 loss : 0.349550 model2 loss : 0.369164
[20:08:55.639] iteration 209 : model1 loss : 0.364124 model2 loss : 0.337276
[20:08:56.299] iteration 210 : model1 loss : 0.343096 model2 loss : 0.344527
[20:08:56.963] iteration 211 : model1 loss : 0.329768 model2 loss : 0.407004
[20:08:57.632] iteration 212 : model1 loss : 0.328275 model2 loss : 0.402501
[20:08:58.307] iteration 213 : model1 loss : 0.323241 model2 loss : 0.386989
[20:08:59.006] iteration 214 : model1 loss : 0.280511 model2 loss : 0.348536
[20:08:59.702] iteration 215 : model1 loss : 0.340316 model2 loss : 0.339759
[20:09:00.369] iteration 216 : model1 loss : 0.338059 model2 loss : 0.352525
[20:09:01.041] iteration 217 : model1 loss : 0.302422 model2 loss : 0.299432
[20:09:01.710] iteration 218 : model1 loss : 0.329851 model2 loss : 0.328418
[20:09:02.418] iteration 219 : model1 loss : 0.342614 model2 loss : 0.371671
[20:09:03.100] iteration 220 : model1 loss : 0.348680 model2 loss : 0.388965
[20:09:03.756] iteration 221 : model1 loss : 0.403951 model2 loss : 0.413700
[20:09:04.423] iteration 222 : model1 loss : 0.308670 model2 loss : 0.351658
[20:09:05.084] iteration 223 : model1 loss : 0.337342 model2 loss : 0.358349
[20:09:05.744] iteration 224 : model1 loss : 0.415758 model2 loss : 0.407548
[20:09:06.412] iteration 225 : model1 loss : 0.312374 model2 loss : 0.339203
[20:09:07.068] iteration 226 : model1 loss : 0.340171 model2 loss : 0.356367
[20:09:07.728] iteration 227 : model1 loss : 0.417680 model2 loss : 0.400544
[20:09:08.400] iteration 228 : model1 loss : 0.343929 model2 loss : 0.324155
[20:09:09.065] iteration 229 : model1 loss : 0.295581 model2 loss : 0.311087
[20:09:09.745] iteration 230 : model1 loss : 0.282299 model2 loss : 0.341303
[20:09:10.407] iteration 231 : model1 loss : 0.400627 model2 loss : 0.347888
[20:09:11.068] iteration 232 : model1 loss : 0.332034 model2 loss : 0.296868
[20:09:11.741] iteration 233 : model1 loss : 0.314171 model2 loss : 0.327300
[20:09:12.393] iteration 234 : model1 loss : 0.292103 model2 loss : 0.308272
[20:09:13.057] iteration 235 : model1 loss : 0.384994 model2 loss : 0.390285
[20:09:13.724] iteration 236 : model1 loss : 0.300502 model2 loss : 0.319182
[20:09:14.401] iteration 237 : model1 loss : 0.307136 model2 loss : 0.328834
[20:09:15.058] iteration 238 : model1 loss : 0.395873 model2 loss : 0.403226
[20:09:15.721] iteration 239 : model1 loss : 0.249182 model2 loss : 0.269354
[20:09:16.389] iteration 240 : model1 loss : 0.275096 model2 loss : 0.287975
[20:09:17.065] iteration 241 : model1 loss : 0.363689 model2 loss : 0.354436
[20:09:17.725] iteration 242 : model1 loss : 0.288361 model2 loss : 0.292706
[20:09:18.400] iteration 243 : model1 loss : 0.297763 model2 loss : 0.309304
[20:09:19.064] iteration 244 : model1 loss : 0.267591 model2 loss : 0.284411
[20:09:19.734] iteration 245 : model1 loss : 0.293955 model2 loss : 0.313337
[20:09:20.402] iteration 246 : model1 loss : 0.345396 model2 loss : 0.357795
[20:09:21.058] iteration 247 : model1 loss : 0.254884 model2 loss : 0.282136
[20:09:21.725] iteration 248 : model1 loss : 0.329348 model2 loss : 0.407717
[20:09:22.386] iteration 249 : model1 loss : 0.444202 model2 loss : 0.401243
[20:09:23.058] iteration 250 : model1 loss : 0.280684 model2 loss : 0.312067
[20:09:23.776] iteration 251 : model1 loss : 0.287431 model2 loss : 0.335502
[20:09:24.441] iteration 252 : model1 loss : 0.298729 model2 loss : 0.336131
[20:09:25.113] iteration 253 : model1 loss : 0.386860 model2 loss : 0.374841
[20:09:25.783] iteration 254 : model1 loss : 0.383866 model2 loss : 0.392007
[20:09:26.446] iteration 255 : model1 loss : 0.279821 model2 loss : 0.293236
[20:09:27.114] iteration 256 : model1 loss : 0.278981 model2 loss : 0.274178
[20:09:27.783] iteration 257 : model1 loss : 0.321329 model2 loss : 0.350548
[20:09:28.458] iteration 258 : model1 loss : 0.289318 model2 loss : 0.265205
[20:09:29.122] iteration 259 : model1 loss : 0.357036 model2 loss : 0.365804
[20:09:29.789] iteration 260 : model1 loss : 0.345915 model2 loss : 0.336074
[20:09:30.463] iteration 261 : model1 loss : 0.316792 model2 loss : 0.282967
[20:09:31.142] iteration 262 : model1 loss : 0.288341 model2 loss : 0.301040
[20:09:31.804] iteration 263 : model1 loss : 0.274351 model2 loss : 0.300464
[20:09:32.476] iteration 264 : model1 loss : 0.284965 model2 loss : 0.299366
[20:09:33.135] iteration 265 : model1 loss : 0.337711 model2 loss : 0.302058
[20:09:33.812] iteration 266 : model1 loss : 0.399716 model2 loss : 0.337588
[20:09:34.474] iteration 267 : model1 loss : 0.273548 model2 loss : 0.289846
[20:09:35.133] iteration 268 : model1 loss : 0.294388 model2 loss : 0.288156
[20:09:35.806] iteration 269 : model1 loss : 0.260485 model2 loss : 0.277631
[20:09:36.476] iteration 270 : model1 loss : 0.296129 model2 loss : 0.309252
[20:09:37.149] iteration 271 : model1 loss : 0.334563 model2 loss : 0.399308
[20:09:37.822] iteration 272 : model1 loss : 0.304475 model2 loss : 0.354336
[20:09:38.473] iteration 273 : model1 loss : 0.409758 model2 loss : 0.374712
[20:09:39.133] iteration 274 : model1 loss : 0.380880 model2 loss : 0.401870
[20:09:39.815] iteration 275 : model1 loss : 0.263656 model2 loss : 0.252031
[20:09:40.492] iteration 276 : model1 loss : 0.347274 model2 loss : 0.378630
[20:09:41.154] iteration 277 : model1 loss : 0.349911 model2 loss : 0.356717
[20:09:41.814] iteration 278 : model1 loss : 0.256067 model2 loss : 0.263790
[20:09:42.494] iteration 279 : model1 loss : 0.238582 model2 loss : 0.240421
[20:09:43.159] iteration 280 : model1 loss : 0.281788 model2 loss : 0.301428
[20:09:43.826] iteration 281 : model1 loss : 0.222858 model2 loss : 0.231975
[20:09:44.493] iteration 282 : model1 loss : 0.292193 model2 loss : 0.280720
[20:09:45.170] iteration 283 : model1 loss : 0.291716 model2 loss : 0.301983
[20:09:45.848] iteration 284 : model1 loss : 0.280459 model2 loss : 0.251645
[20:09:46.514] iteration 285 : model1 loss : 0.327566 model2 loss : 0.381866
[20:09:47.176] iteration 286 : model1 loss : 0.270513 model2 loss : 0.317104
[20:09:47.842] iteration 287 : model1 loss : 0.332165 model2 loss : 0.336415
[20:09:48.504] iteration 288 : model1 loss : 0.338197 model2 loss : 0.349464
[20:09:49.175] iteration 289 : model1 loss : 0.310907 model2 loss : 0.320963
[20:09:49.840] iteration 290 : model1 loss : 0.220885 model2 loss : 0.229929
[20:09:50.502] iteration 291 : model1 loss : 0.249105 model2 loss : 0.223581
[20:09:51.172] iteration 292 : model1 loss : 0.256784 model2 loss : 0.282763
[20:09:51.834] iteration 293 : model1 loss : 0.379670 model2 loss : 0.423435
[20:09:52.520] iteration 294 : model1 loss : 0.238504 model2 loss : 0.291081
[20:09:53.179] iteration 295 : model1 loss : 0.229225 model2 loss : 0.278150
[20:09:53.845] iteration 296 : model1 loss : 0.230392 model2 loss : 0.249754
[20:09:54.507] iteration 297 : model1 loss : 0.335479 model2 loss : 0.329350
[20:09:55.171] iteration 298 : model1 loss : 0.243058 model2 loss : 0.265956
[20:09:55.848] iteration 299 : model1 loss : 0.298248 model2 loss : 0.347920
[20:09:56.526] iteration 300 : model1 loss : 0.364814 model2 loss : 0.404402
[20:09:57.242] iteration 301 : model1 loss : 0.317470 model2 loss : 0.275337
[20:09:57.918] iteration 302 : model1 loss : 0.211864 model2 loss : 0.237124
[20:09:58.588] iteration 303 : model1 loss : 0.288279 model2 loss : 0.284433
[20:09:59.267] iteration 304 : model1 loss : 0.323846 model2 loss : 0.317468
[20:09:59.941] iteration 305 : model1 loss : 0.283492 model2 loss : 0.266020
[20:10:00.592] iteration 306 : model1 loss : 0.301014 model2 loss : 0.323269
[20:10:01.287] iteration 307 : model1 loss : 0.187631 model2 loss : 0.194666
[20:10:01.978] iteration 308 : model1 loss : 0.234285 model2 loss : 0.252378
[20:10:02.653] iteration 309 : model1 loss : 0.246870 model2 loss : 0.361462
[20:10:03.327] iteration 310 : model1 loss : 0.299641 model2 loss : 0.299493
[20:10:03.996] iteration 311 : model1 loss : 0.266408 model2 loss : 0.319987
[20:10:04.650] iteration 312 : model1 loss : 0.330085 model2 loss : 0.329112
[20:10:05.319] iteration 313 : model1 loss : 0.287419 model2 loss : 0.304555
[20:10:05.986] iteration 314 : model1 loss : 0.250817 model2 loss : 0.284544
[20:10:06.651] iteration 315 : model1 loss : 0.214481 model2 loss : 0.247477
[20:10:07.305] iteration 316 : model1 loss : 0.256115 model2 loss : 0.278597
[20:10:07.978] iteration 317 : model1 loss : 0.296663 model2 loss : 0.282095
[20:10:08.636] iteration 318 : model1 loss : 0.273789 model2 loss : 0.293742
[20:10:09.303] iteration 319 : model1 loss : 0.229715 model2 loss : 0.262516
[20:10:09.971] iteration 320 : model1 loss : 0.243703 model2 loss : 0.276340
[20:10:10.634] iteration 321 : model1 loss : 0.255257 model2 loss : 0.235177
[20:10:11.304] iteration 322 : model1 loss : 0.231583 model2 loss : 0.236207
[20:10:11.975] iteration 323 : model1 loss : 0.279164 model2 loss : 0.284921
[20:10:12.639] iteration 324 : model1 loss : 0.181934 model2 loss : 0.205356
[20:10:13.308] iteration 325 : model1 loss : 0.327934 model2 loss : 0.299793
[20:10:13.975] iteration 326 : model1 loss : 0.227048 model2 loss : 0.216176
[20:10:14.633] iteration 327 : model1 loss : 0.260185 model2 loss : 0.331283
[20:10:15.289] iteration 328 : model1 loss : 0.197092 model2 loss : 0.197170
[20:10:15.958] iteration 329 : model1 loss : 0.312863 model2 loss : 0.276398
[20:10:16.623] iteration 330 : model1 loss : 0.317874 model2 loss : 0.335562
[20:10:17.295] iteration 331 : model1 loss : 0.257919 model2 loss : 0.269479
[20:10:17.959] iteration 332 : model1 loss : 0.326495 model2 loss : 0.306137
[20:10:18.624] iteration 333 : model1 loss : 0.224890 model2 loss : 0.292561
[20:10:19.317] iteration 334 : model1 loss : 0.326906 model2 loss : 0.210690
[20:10:19.989] iteration 335 : model1 loss : 0.287349 model2 loss : 0.272603
[20:10:20.644] iteration 336 : model1 loss : 0.188149 model2 loss : 0.191082
[20:10:21.315] iteration 337 : model1 loss : 0.259791 model2 loss : 0.235337
[20:10:21.984] iteration 338 : model1 loss : 0.237324 model2 loss : 0.242513
[20:10:22.640] iteration 339 : model1 loss : 0.281317 model2 loss : 0.226553
[20:10:23.314] iteration 340 : model1 loss : 0.264590 model2 loss : 0.247637
[20:10:23.976] iteration 341 : model1 loss : 0.231170 model2 loss : 0.232077
[20:10:24.643] iteration 342 : model1 loss : 0.236741 model2 loss : 0.215319
[20:10:25.317] iteration 343 : model1 loss : 0.220424 model2 loss : 0.171639
[20:10:25.983] iteration 344 : model1 loss : 0.256761 model2 loss : 0.268293
[20:10:26.647] iteration 345 : model1 loss : 0.217278 model2 loss : 0.216721
[20:10:27.328] iteration 346 : model1 loss : 0.367891 model2 loss : 0.341829
[20:10:27.988] iteration 347 : model1 loss : 0.299012 model2 loss : 0.355219
[20:10:28.651] iteration 348 : model1 loss : 0.308465 model2 loss : 0.291727
[20:10:29.323] iteration 349 : model1 loss : 0.247160 model2 loss : 0.233915
[20:10:29.999] iteration 350 : model1 loss : 0.334416 model2 loss : 0.380987
[20:10:30.705] iteration 351 : model1 loss : 0.227680 model2 loss : 0.205027
[20:10:31.376] iteration 352 : model1 loss : 0.296521 model2 loss : 0.346263
[20:10:32.035] iteration 353 : model1 loss : 0.225545 model2 loss : 0.236313
[20:10:32.695] iteration 354 : model1 loss : 0.270734 model2 loss : 0.269495
[20:10:33.362] iteration 355 : model1 loss : 0.332614 model2 loss : 0.298743
[20:10:34.034] iteration 356 : model1 loss : 0.245511 model2 loss : 0.253076
[20:10:34.697] iteration 357 : model1 loss : 0.395483 model2 loss : 0.358555
[20:10:35.368] iteration 358 : model1 loss : 0.274504 model2 loss : 0.219898
[20:10:36.031] iteration 359 : model1 loss : 0.293935 model2 loss : 0.317582
[20:10:36.710] iteration 360 : model1 loss : 0.273288 model2 loss : 0.303913
[20:10:37.387] iteration 361 : model1 loss : 0.194573 model2 loss : 0.215498
[20:10:38.052] iteration 362 : model1 loss : 0.235457 model2 loss : 0.238916
[20:10:38.725] iteration 363 : model1 loss : 0.278905 model2 loss : 0.287938
[20:10:39.386] iteration 364 : model1 loss : 0.197874 model2 loss : 0.224775
[20:10:40.051] iteration 365 : model1 loss : 0.280477 model2 loss : 0.257986
[20:10:40.714] iteration 366 : model1 loss : 0.339909 model2 loss : 0.383629
[20:10:41.380] iteration 367 : model1 loss : 0.243384 model2 loss : 0.241460
[20:10:42.045] iteration 368 : model1 loss : 0.250190 model2 loss : 0.234458
[20:10:42.711] iteration 369 : model1 loss : 0.221542 model2 loss : 0.204158
[20:10:43.385] iteration 370 : model1 loss : 0.273716 model2 loss : 0.286205
[20:10:44.044] iteration 371 : model1 loss : 0.251625 model2 loss : 0.208421
[20:10:44.693] iteration 372 : model1 loss : 0.199004 model2 loss : 0.171174
[20:10:45.364] iteration 373 : model1 loss : 0.187742 model2 loss : 0.186819
[20:10:46.032] iteration 374 : model1 loss : 0.308056 model2 loss : 0.305088
[20:10:46.686] iteration 375 : model1 loss : 0.235351 model2 loss : 0.254540
[20:10:47.357] iteration 376 : model1 loss : 0.217440 model2 loss : 0.253875
[20:10:48.026] iteration 377 : model1 loss : 0.245647 model2 loss : 0.224391
[20:10:48.693] iteration 378 : model1 loss : 0.249848 model2 loss : 0.208529
[20:10:49.361] iteration 379 : model1 loss : 0.266628 model2 loss : 0.268248
[20:10:50.029] iteration 380 : model1 loss : 0.205357 model2 loss : 0.254406
[20:10:50.693] iteration 381 : model1 loss : 0.264664 model2 loss : 0.317639
[20:10:51.365] iteration 382 : model1 loss : 0.222841 model2 loss : 0.285190
[20:10:52.043] iteration 383 : model1 loss : 0.195726 model2 loss : 0.198547
[20:10:52.704] iteration 384 : model1 loss : 0.211892 model2 loss : 0.238236
[20:10:53.380] iteration 385 : model1 loss : 0.239200 model2 loss : 0.267386
[20:10:54.042] iteration 386 : model1 loss : 0.196963 model2 loss : 0.226510
[20:10:54.706] iteration 387 : model1 loss : 0.359356 model2 loss : 0.368475
[20:10:55.373] iteration 388 : model1 loss : 0.172537 model2 loss : 0.213228
[20:10:56.041] iteration 389 : model1 loss : 0.156092 model2 loss : 0.181337
[20:10:56.711] iteration 390 : model1 loss : 0.245020 model2 loss : 0.311011
[20:10:57.381] iteration 391 : model1 loss : 0.225118 model2 loss : 0.242116
[20:10:58.052] iteration 392 : model1 loss : 0.216831 model2 loss : 0.210713
[20:10:58.731] iteration 393 : model1 loss : 0.213589 model2 loss : 0.241292
[20:10:59.389] iteration 394 : model1 loss : 0.171000 model2 loss : 0.243406
[20:11:00.077] iteration 395 : model1 loss : 0.259450 model2 loss : 0.232387
[20:11:00.749] iteration 396 : model1 loss : 0.184895 model2 loss : 0.216196
[20:11:01.422] iteration 397 : model1 loss : 0.236961 model2 loss : 0.323588
[20:11:02.073] iteration 398 : model1 loss : 0.326950 model2 loss : 0.313729
[20:11:02.746] iteration 399 : model1 loss : 0.183712 model2 loss : 0.221445
[20:11:03.423] iteration 400 : model1 loss : 0.290800 model2 loss : 0.289078
[20:11:22.252] iteration 400 : model1_mean_dice : 0.469741 model1_mean_hd95 : 49.038092
[20:11:39.974] iteration 400 : model2_mean_dice : 0.203576 model2_mean_hd95 : 18.482090
[20:11:40.679] iteration 401 : model1 loss : 0.323571 model2 loss : 0.257183
[20:11:41.348] iteration 402 : model1 loss : 0.208219 model2 loss : 0.348592
[20:11:42.011] iteration 403 : model1 loss : 0.184304 model2 loss : 0.232712
[20:11:42.677] iteration 404 : model1 loss : 0.247508 model2 loss : 0.231252
[20:11:43.343] iteration 405 : model1 loss : 0.178740 model2 loss : 0.186237
[20:11:43.997] iteration 406 : model1 loss : 0.233614 model2 loss : 0.254061
[20:11:44.656] iteration 407 : model1 loss : 0.207560 model2 loss : 0.258906
[20:11:45.322] iteration 408 : model1 loss : 0.176439 model2 loss : 0.183293
[20:11:45.976] iteration 409 : model1 loss : 0.259949 model2 loss : 0.317528
[20:11:46.643] iteration 410 : model1 loss : 0.309466 model2 loss : 0.350511
[20:11:47.308] iteration 411 : model1 loss : 0.204717 model2 loss : 0.211939
[20:11:47.971] iteration 412 : model1 loss : 0.159529 model2 loss : 0.147982
[20:11:48.643] iteration 413 : model1 loss : 0.213012 model2 loss : 0.229342
[20:11:49.300] iteration 414 : model1 loss : 0.192077 model2 loss : 0.213537
[20:11:49.966] iteration 415 : model1 loss : 0.181490 model2 loss : 0.173738
[20:11:50.632] iteration 416 : model1 loss : 0.162706 model2 loss : 0.184521
[20:11:51.289] iteration 417 : model1 loss : 0.214727 model2 loss : 0.246330
[20:11:51.955] iteration 418 : model1 loss : 0.225121 model2 loss : 0.243420
[20:11:52.619] iteration 419 : model1 loss : 0.198918 model2 loss : 0.189749
[20:11:53.302] iteration 420 : model1 loss : 0.237912 model2 loss : 0.248972
[20:11:53.975] iteration 421 : model1 loss : 0.229220 model2 loss : 0.236562
[20:11:54.635] iteration 422 : model1 loss : 0.201271 model2 loss : 0.211416
[20:11:55.307] iteration 423 : model1 loss : 0.197675 model2 loss : 0.196246
[20:11:55.973] iteration 424 : model1 loss : 0.270202 model2 loss : 0.260310
[20:11:56.641] iteration 425 : model1 loss : 0.147714 model2 loss : 0.176054
[20:11:57.296] iteration 426 : model1 loss : 0.288968 model2 loss : 0.292440
[20:11:57.962] iteration 427 : model1 loss : 0.251089 model2 loss : 0.279060
[20:11:58.625] iteration 428 : model1 loss : 0.188848 model2 loss : 0.203450
[20:11:59.292] iteration 429 : model1 loss : 0.241625 model2 loss : 0.296837
[20:11:59.942] iteration 430 : model1 loss : 0.180804 model2 loss : 0.143902
[20:12:00.638] iteration 431 : model1 loss : 0.196661 model2 loss : 0.273829
[20:12:01.297] iteration 432 : model1 loss : 0.257051 model2 loss : 0.231266
[20:12:01.961] iteration 433 : model1 loss : 0.296919 model2 loss : 0.266814
[20:12:02.636] iteration 434 : model1 loss : 0.245935 model2 loss : 0.253329
[20:12:03.305] iteration 435 : model1 loss : 0.240260 model2 loss : 0.260443
[20:12:03.976] iteration 436 : model1 loss : 0.176450 model2 loss : 0.166460
[20:12:04.627] iteration 437 : model1 loss : 0.195028 model2 loss : 0.233521
[20:12:05.305] iteration 438 : model1 loss : 0.175862 model2 loss : 0.228166
[20:12:05.962] iteration 439 : model1 loss : 0.227305 model2 loss : 0.236414
[20:12:06.625] iteration 440 : model1 loss : 0.209427 model2 loss : 0.189913
[20:12:07.287] iteration 441 : model1 loss : 0.176463 model2 loss : 0.197394
[20:12:07.949] iteration 442 : model1 loss : 0.244878 model2 loss : 0.181796
[20:12:08.630] iteration 443 : model1 loss : 0.168210 model2 loss : 0.202894
[20:12:09.291] iteration 444 : model1 loss : 0.162057 model2 loss : 0.167813
[20:12:09.958] iteration 445 : model1 loss : 0.186186 model2 loss : 0.157203
[20:12:10.632] iteration 446 : model1 loss : 0.163615 model2 loss : 0.189588
[20:12:11.304] iteration 447 : model1 loss : 0.170771 model2 loss : 0.177680
[20:12:11.963] iteration 448 : model1 loss : 0.149291 model2 loss : 0.170556
[20:12:12.644] iteration 449 : model1 loss : 0.181805 model2 loss : 0.243395
[20:12:13.311] iteration 450 : model1 loss : 0.340982 model2 loss : 0.377427
[20:12:14.039] iteration 451 : model1 loss : 0.253046 model2 loss : 0.208787
[20:12:14.696] iteration 452 : model1 loss : 0.435353 model2 loss : 0.436103
[20:12:15.369] iteration 453 : model1 loss : 0.246379 model2 loss : 0.211120
[20:12:16.041] iteration 454 : model1 loss : 0.149920 model2 loss : 0.162357
[20:12:16.709] iteration 455 : model1 loss : 0.261748 model2 loss : 0.234401
[20:12:17.382] iteration 456 : model1 loss : 0.326577 model2 loss : 0.336199
[20:12:18.045] iteration 457 : model1 loss : 0.185511 model2 loss : 0.173271
[20:12:18.708] iteration 458 : model1 loss : 0.211218 model2 loss : 0.196576
[20:12:19.377] iteration 459 : model1 loss : 0.174536 model2 loss : 0.192625
[20:12:20.048] iteration 460 : model1 loss : 0.320007 model2 loss : 0.315672
[20:12:20.707] iteration 461 : model1 loss : 0.346128 model2 loss : 0.306236
[20:12:21.381] iteration 462 : model1 loss : 0.259013 model2 loss : 0.205582
[20:12:22.034] iteration 463 : model1 loss : 0.284591 model2 loss : 0.214703
[20:12:22.725] iteration 464 : model1 loss : 0.158892 model2 loss : 0.134389
[20:12:23.392] iteration 465 : model1 loss : 0.148286 model2 loss : 0.158847
[20:12:24.053] iteration 466 : model1 loss : 0.200764 model2 loss : 0.241864
[20:12:24.714] iteration 467 : model1 loss : 0.185980 model2 loss : 0.146998
[20:12:25.382] iteration 468 : model1 loss : 0.178735 model2 loss : 0.172135
[20:12:26.038] iteration 469 : model1 loss : 0.182691 model2 loss : 0.215937
[20:12:26.709] iteration 470 : model1 loss : 0.180057 model2 loss : 0.162630
[20:12:27.399] iteration 471 : model1 loss : 0.157086 model2 loss : 0.184900
[20:12:28.061] iteration 472 : model1 loss : 0.154946 model2 loss : 0.171287
[20:12:28.716] iteration 473 : model1 loss : 0.218299 model2 loss : 0.213272
[20:12:29.394] iteration 474 : model1 loss : 0.196269 model2 loss : 0.254487
[20:12:30.051] iteration 475 : model1 loss : 0.235266 model2 loss : 0.235572
[20:12:30.718] iteration 476 : model1 loss : 0.274285 model2 loss : 0.259154
[20:12:31.386] iteration 477 : model1 loss : 0.220040 model2 loss : 0.210210
[20:12:32.042] iteration 478 : model1 loss : 0.188432 model2 loss : 0.206608
[20:12:32.716] iteration 479 : model1 loss : 0.255610 model2 loss : 0.258916
[20:12:33.382] iteration 480 : model1 loss : 0.153154 model2 loss : 0.155441
[20:12:34.048] iteration 481 : model1 loss : 0.305181 model2 loss : 0.264416
[20:12:34.720] iteration 482 : model1 loss : 0.137589 model2 loss : 0.133099
[20:12:35.396] iteration 483 : model1 loss : 0.238248 model2 loss : 0.223696
[20:12:36.064] iteration 484 : model1 loss : 0.229558 model2 loss : 0.266334
[20:12:36.727] iteration 485 : model1 loss : 0.253232 model2 loss : 0.245180
[20:12:37.396] iteration 486 : model1 loss : 0.192358 model2 loss : 0.225077
[20:12:38.067] iteration 487 : model1 loss : 0.163487 model2 loss : 0.185382
[20:12:38.749] iteration 488 : model1 loss : 0.138735 model2 loss : 0.142238
[20:12:39.427] iteration 489 : model1 loss : 0.172368 model2 loss : 0.230567
[20:12:40.083] iteration 490 : model1 loss : 0.216158 model2 loss : 0.172768
[20:12:40.748] iteration 491 : model1 loss : 0.152105 model2 loss : 0.145975
[20:12:41.429] iteration 492 : model1 loss : 0.232827 model2 loss : 0.237143
[20:12:42.085] iteration 493 : model1 loss : 0.241586 model2 loss : 0.263379
[20:12:42.746] iteration 494 : model1 loss : 0.169218 model2 loss : 0.231351
[20:12:43.415] iteration 495 : model1 loss : 0.221157 model2 loss : 0.207418
[20:12:44.085] iteration 496 : model1 loss : 0.149497 model2 loss : 0.154313
[20:12:44.752] iteration 497 : model1 loss : 0.136519 model2 loss : 0.156413
[20:12:45.421] iteration 498 : model1 loss : 0.150758 model2 loss : 0.172954
[20:12:46.083] iteration 499 : model1 loss : 0.219665 model2 loss : 0.198013
[20:12:46.753] iteration 500 : model1 loss : 0.148075 model2 loss : 0.167986
[20:12:47.475] iteration 501 : model1 loss : 0.150785 model2 loss : 0.157359
[20:12:48.140] iteration 502 : model1 loss : 0.146840 model2 loss : 0.196404
[20:12:48.813] iteration 503 : model1 loss : 0.177803 model2 loss : 0.161908
[20:12:49.480] iteration 504 : model1 loss : 0.151618 model2 loss : 0.176173
[20:12:50.144] iteration 505 : model1 loss : 0.226143 model2 loss : 0.231663
[20:12:50.804] iteration 506 : model1 loss : 0.143261 model2 loss : 0.139231
[20:12:51.464] iteration 507 : model1 loss : 0.305301 model2 loss : 0.283456
[20:12:52.133] iteration 508 : model1 loss : 0.327255 model2 loss : 0.320694
[20:12:52.793] iteration 509 : model1 loss : 0.232896 model2 loss : 0.219063
[20:12:53.469] iteration 510 : model1 loss : 0.146650 model2 loss : 0.145544
[20:12:54.143] iteration 511 : model1 loss : 0.299712 model2 loss : 0.289212
[20:12:54.806] iteration 512 : model1 loss : 0.209665 model2 loss : 0.254282
[20:12:55.488] iteration 513 : model1 loss : 0.233922 model2 loss : 0.246272
[20:12:56.157] iteration 514 : model1 loss : 0.350586 model2 loss : 0.381603
[20:12:56.825] iteration 515 : model1 loss : 0.371539 model2 loss : 0.358471
[20:12:57.497] iteration 516 : model1 loss : 0.371396 model2 loss : 0.406061
[20:12:58.221] iteration 517 : model1 loss : 0.165392 model2 loss : 0.169649
[20:12:58.933] iteration 518 : model1 loss : 0.200944 model2 loss : 0.200378
[20:12:59.633] iteration 519 : model1 loss : 0.165560 model2 loss : 0.172941
[20:13:00.324] iteration 520 : model1 loss : 0.227629 model2 loss : 0.191555
[20:13:01.044] iteration 521 : model1 loss : 0.205370 model2 loss : 0.208915
[20:13:01.708] iteration 522 : model1 loss : 0.199219 model2 loss : 0.208554
[20:13:02.383] iteration 523 : model1 loss : 0.156224 model2 loss : 0.156454
[20:13:03.051] iteration 524 : model1 loss : 0.232676 model2 loss : 0.291173
[20:13:03.718] iteration 525 : model1 loss : 0.321545 model2 loss : 0.305216
[20:13:04.397] iteration 526 : model1 loss : 0.353603 model2 loss : 0.290964
[20:13:05.056] iteration 527 : model1 loss : 0.217492 model2 loss : 0.208701
[20:13:05.735] iteration 528 : model1 loss : 0.193582 model2 loss : 0.168073
[20:13:06.398] iteration 529 : model1 loss : 0.193444 model2 loss : 0.207743
[20:13:07.067] iteration 530 : model1 loss : 0.175724 model2 loss : 0.158749
[20:13:07.749] iteration 531 : model1 loss : 0.163499 model2 loss : 0.169778
[20:13:08.415] iteration 532 : model1 loss : 0.269264 model2 loss : 0.267198
[20:13:09.080] iteration 533 : model1 loss : 0.179032 model2 loss : 0.173574
[20:13:09.748] iteration 534 : model1 loss : 0.133308 model2 loss : 0.138418
[20:13:10.427] iteration 535 : model1 loss : 0.219878 model2 loss : 0.193036
[20:13:11.106] iteration 536 : model1 loss : 0.194692 model2 loss : 0.224723
[20:13:11.771] iteration 537 : model1 loss : 0.152835 model2 loss : 0.163026
[20:13:12.443] iteration 538 : model1 loss : 0.163874 model2 loss : 0.184667
[20:13:13.113] iteration 539 : model1 loss : 0.187593 model2 loss : 0.276946
[20:13:13.781] iteration 540 : model1 loss : 0.233336 model2 loss : 0.248062
[20:13:14.464] iteration 541 : model1 loss : 0.146013 model2 loss : 0.130529
[20:13:15.119] iteration 542 : model1 loss : 0.245730 model2 loss : 0.308139
[20:13:15.776] iteration 543 : model1 loss : 0.219822 model2 loss : 0.154802
[20:13:16.449] iteration 544 : model1 loss : 0.154935 model2 loss : 0.165521
[20:13:17.127] iteration 545 : model1 loss : 0.193672 model2 loss : 0.195427
[20:13:17.798] iteration 546 : model1 loss : 0.159338 model2 loss : 0.130537
[20:13:18.468] iteration 547 : model1 loss : 0.181374 model2 loss : 0.251573
[20:13:19.124] iteration 548 : model1 loss : 0.145478 model2 loss : 0.157130
[20:13:19.798] iteration 549 : model1 loss : 0.192413 model2 loss : 0.179129
[20:13:20.461] iteration 550 : model1 loss : 0.152353 model2 loss : 0.157691
[20:13:21.154] iteration 551 : model1 loss : 0.186292 model2 loss : 0.243722
[20:13:21.835] iteration 552 : model1 loss : 0.191457 model2 loss : 0.164863
[20:13:22.492] iteration 553 : model1 loss : 0.203322 model2 loss : 0.172984
[20:13:23.158] iteration 554 : model1 loss : 0.160988 model2 loss : 0.172388
[20:13:23.832] iteration 555 : model1 loss : 0.120078 model2 loss : 0.163236
[20:13:24.504] iteration 556 : model1 loss : 0.102999 model2 loss : 0.137752
[20:13:25.172] iteration 557 : model1 loss : 0.366563 model2 loss : 0.356177
[20:13:25.843] iteration 558 : model1 loss : 0.113639 model2 loss : 0.132336
[20:13:26.499] iteration 559 : model1 loss : 0.121017 model2 loss : 0.170803
[20:13:27.195] iteration 560 : model1 loss : 0.102554 model2 loss : 0.128105
[20:13:27.862] iteration 561 : model1 loss : 0.210432 model2 loss : 0.187563
[20:13:28.550] iteration 562 : model1 loss : 0.145338 model2 loss : 0.187431
[20:13:29.210] iteration 563 : model1 loss : 0.207602 model2 loss : 0.160691
[20:13:29.878] iteration 564 : model1 loss : 0.157251 model2 loss : 0.158828
[20:13:30.553] iteration 565 : model1 loss : 0.114982 model2 loss : 0.102485
[20:13:31.224] iteration 566 : model1 loss : 0.154182 model2 loss : 0.155497
[20:13:31.894] iteration 567 : model1 loss : 0.178561 model2 loss : 0.210348
[20:13:32.554] iteration 568 : model1 loss : 0.134876 model2 loss : 0.198678
[20:13:33.219] iteration 569 : model1 loss : 0.197455 model2 loss : 0.183453
[20:13:33.891] iteration 570 : model1 loss : 0.145036 model2 loss : 0.151758
[20:13:34.552] iteration 571 : model1 loss : 0.129209 model2 loss : 0.116831
[20:13:35.222] iteration 572 : model1 loss : 0.147963 model2 loss : 0.142686
[20:13:35.887] iteration 573 : model1 loss : 0.186114 model2 loss : 0.191977
[20:13:36.552] iteration 574 : model1 loss : 0.145467 model2 loss : 0.177402
[20:13:37.212] iteration 575 : model1 loss : 0.104362 model2 loss : 0.118974
[20:13:37.876] iteration 576 : model1 loss : 0.262081 model2 loss : 0.243818
[20:13:38.561] iteration 577 : model1 loss : 0.147680 model2 loss : 0.144924
[20:13:39.220] iteration 578 : model1 loss : 0.214794 model2 loss : 0.227824
[20:13:39.885] iteration 579 : model1 loss : 0.165812 model2 loss : 0.139198
[20:13:40.553] iteration 580 : model1 loss : 0.188560 model2 loss : 0.247235
[20:13:41.215] iteration 581 : model1 loss : 0.133337 model2 loss : 0.129361
[20:13:41.877] iteration 582 : model1 loss : 0.198052 model2 loss : 0.178331
[20:13:42.553] iteration 583 : model1 loss : 0.146542 model2 loss : 0.170443
[20:13:43.225] iteration 584 : model1 loss : 0.236664 model2 loss : 0.223025
[20:13:43.896] iteration 585 : model1 loss : 0.207779 model2 loss : 0.227510
[20:13:44.573] iteration 586 : model1 loss : 0.135188 model2 loss : 0.146725
[20:13:45.240] iteration 587 : model1 loss : 0.116759 model2 loss : 0.125343
[20:13:45.906] iteration 588 : model1 loss : 0.118308 model2 loss : 0.127109
[20:13:46.583] iteration 589 : model1 loss : 0.339206 model2 loss : 0.291127
[20:13:47.255] iteration 590 : model1 loss : 0.098066 model2 loss : 0.103572
[20:13:47.924] iteration 591 : model1 loss : 0.146201 model2 loss : 0.147592
[20:13:48.593] iteration 592 : model1 loss : 0.214416 model2 loss : 0.206645
[20:13:49.274] iteration 593 : model1 loss : 0.229025 model2 loss : 0.152225
[20:13:49.947] iteration 594 : model1 loss : 0.161866 model2 loss : 0.138640
[20:13:50.607] iteration 595 : model1 loss : 0.163182 model2 loss : 0.142081
[20:13:51.283] iteration 596 : model1 loss : 0.210479 model2 loss : 0.161301
[20:13:51.951] iteration 597 : model1 loss : 0.209304 model2 loss : 0.190264
[20:13:52.633] iteration 598 : model1 loss : 0.157946 model2 loss : 0.178541
[20:13:53.312] iteration 599 : model1 loss : 0.167939 model2 loss : 0.175569
[20:13:53.963] iteration 600 : model1 loss : 0.248919 model2 loss : 0.237129
[20:14:12.782] iteration 600 : model1_mean_dice : 0.574699 model1_mean_hd95 : 27.534265
[20:14:31.407] iteration 600 : model2_mean_dice : 0.607528 model2_mean_hd95 : 23.394502
[20:14:32.086] iteration 601 : model1 loss : 0.136538 model2 loss : 0.186725
[20:14:32.751] iteration 602 : model1 loss : 0.188302 model2 loss : 0.124729
[20:14:33.423] iteration 603 : model1 loss : 0.112163 model2 loss : 0.103749
[20:14:34.084] iteration 604 : model1 loss : 0.165531 model2 loss : 0.136174
[20:14:34.736] iteration 605 : model1 loss : 0.173761 model2 loss : 0.152175
[20:14:35.398] iteration 606 : model1 loss : 0.137210 model2 loss : 0.282482
[20:14:36.064] iteration 607 : model1 loss : 0.205031 model2 loss : 0.215956
[20:14:36.736] iteration 608 : model1 loss : 0.118882 model2 loss : 0.162996
[20:14:37.396] iteration 609 : model1 loss : 0.129280 model2 loss : 0.130053
[20:14:38.075] iteration 610 : model1 loss : 0.173725 model2 loss : 0.181036
[20:14:38.753] iteration 611 : model1 loss : 0.159485 model2 loss : 0.142970
[20:14:39.410] iteration 612 : model1 loss : 0.209249 model2 loss : 0.184754
[20:14:40.078] iteration 613 : model1 loss : 0.136555 model2 loss : 0.139080
[20:14:40.740] iteration 614 : model1 loss : 0.227502 model2 loss : 0.229544
[20:14:41.398] iteration 615 : model1 loss : 0.200622 model2 loss : 0.144932
[20:14:42.068] iteration 616 : model1 loss : 0.166225 model2 loss : 0.195368
[20:14:42.738] iteration 617 : model1 loss : 0.217903 model2 loss : 0.234629
[20:14:43.411] iteration 618 : model1 loss : 0.127940 model2 loss : 0.114678
[20:14:44.070] iteration 619 : model1 loss : 0.120476 model2 loss : 0.115546
[20:14:44.729] iteration 620 : model1 loss : 0.125711 model2 loss : 0.144036
[20:14:45.407] iteration 621 : model1 loss : 0.156647 model2 loss : 0.163585
[20:14:46.069] iteration 622 : model1 loss : 0.159574 model2 loss : 0.151683
[20:14:46.725] iteration 623 : model1 loss : 0.095803 model2 loss : 0.099650
[20:14:47.386] iteration 624 : model1 loss : 0.166839 model2 loss : 0.147590
[20:14:48.067] iteration 625 : model1 loss : 0.176320 model2 loss : 0.162841
[20:14:48.737] iteration 626 : model1 loss : 0.227885 model2 loss : 0.247418
[20:14:49.405] iteration 627 : model1 loss : 0.121117 model2 loss : 0.117778
[20:14:50.072] iteration 628 : model1 loss : 0.127952 model2 loss : 0.135301
[20:14:50.742] iteration 629 : model1 loss : 0.120167 model2 loss : 0.117511
[20:14:51.404] iteration 630 : model1 loss : 0.095944 model2 loss : 0.111146
[20:14:52.080] iteration 631 : model1 loss : 0.238297 model2 loss : 0.234521
[20:14:52.759] iteration 632 : model1 loss : 0.274147 model2 loss : 0.276598
[20:14:53.426] iteration 633 : model1 loss : 0.109153 model2 loss : 0.118895
[20:14:54.100] iteration 634 : model1 loss : 0.186614 model2 loss : 0.153944
[20:14:54.765] iteration 635 : model1 loss : 0.244001 model2 loss : 0.197972
[20:14:55.443] iteration 636 : model1 loss : 0.179478 model2 loss : 0.180719
[20:14:56.104] iteration 637 : model1 loss : 0.164411 model2 loss : 0.164126
[20:14:56.764] iteration 638 : model1 loss : 0.208184 model2 loss : 0.179380
[20:14:57.442] iteration 639 : model1 loss : 0.160141 model2 loss : 0.137403
[20:14:58.113] iteration 640 : model1 loss : 0.174510 model2 loss : 0.138359
[20:14:58.798] iteration 641 : model1 loss : 0.124295 model2 loss : 0.115981
[20:14:59.463] iteration 642 : model1 loss : 0.130035 model2 loss : 0.165042
[20:15:00.132] iteration 643 : model1 loss : 0.163997 model2 loss : 0.222332
[20:15:00.807] iteration 644 : model1 loss : 0.163741 model2 loss : 0.132555
[20:15:01.480] iteration 645 : model1 loss : 0.203542 model2 loss : 0.130136
[20:15:02.198] iteration 646 : model1 loss : 0.151109 model2 loss : 0.191617
[20:15:02.864] iteration 647 : model1 loss : 0.116093 model2 loss : 0.098833
[20:15:03.542] iteration 648 : model1 loss : 0.103823 model2 loss : 0.115040
[20:15:04.210] iteration 649 : model1 loss : 0.216518 model2 loss : 0.251834
[20:15:04.886] iteration 650 : model1 loss : 0.233186 model2 loss : 0.303497
[20:15:05.598] iteration 651 : model1 loss : 0.092958 model2 loss : 0.089721
[20:15:06.272] iteration 652 : model1 loss : 0.096213 model2 loss : 0.118424
[20:15:06.948] iteration 653 : model1 loss : 0.070024 model2 loss : 0.089720
[20:15:07.614] iteration 654 : model1 loss : 0.140522 model2 loss : 0.101225
[20:15:08.287] iteration 655 : model1 loss : 0.148937 model2 loss : 0.174887
[20:15:08.952] iteration 656 : model1 loss : 0.204462 model2 loss : 0.168524
[20:15:09.616] iteration 657 : model1 loss : 0.111964 model2 loss : 0.157906
[20:15:10.277] iteration 658 : model1 loss : 0.143474 model2 loss : 0.168360
[20:15:10.940] iteration 659 : model1 loss : 0.118391 model2 loss : 0.142627
[20:15:11.607] iteration 660 : model1 loss : 0.251646 model2 loss : 0.212554
[20:15:12.275] iteration 661 : model1 loss : 0.167561 model2 loss : 0.141477
[20:15:12.960] iteration 662 : model1 loss : 0.175301 model2 loss : 0.239986
[20:15:13.633] iteration 663 : model1 loss : 0.191564 model2 loss : 0.175820
[20:15:14.291] iteration 664 : model1 loss : 0.238034 model2 loss : 0.288431
[20:15:14.966] iteration 665 : model1 loss : 0.249999 model2 loss : 0.251425
[20:15:15.631] iteration 666 : model1 loss : 0.199833 model2 loss : 0.153755
[20:15:16.326] iteration 667 : model1 loss : 0.153791 model2 loss : 0.186169
[20:15:16.989] iteration 668 : model1 loss : 0.157160 model2 loss : 0.147405
[20:15:17.663] iteration 669 : model1 loss : 0.206963 model2 loss : 0.169223
[20:15:18.339] iteration 670 : model1 loss : 0.190154 model2 loss : 0.240730
[20:15:19.019] iteration 671 : model1 loss : 0.181055 model2 loss : 0.129676
[20:15:19.686] iteration 672 : model1 loss : 0.111289 model2 loss : 0.092468
[20:15:20.358] iteration 673 : model1 loss : 0.234942 model2 loss : 0.261050
[20:15:21.026] iteration 674 : model1 loss : 0.091468 model2 loss : 0.133880
[20:15:21.694] iteration 675 : model1 loss : 0.225523 model2 loss : 0.228058
[20:15:22.356] iteration 676 : model1 loss : 0.074802 model2 loss : 0.120310
[20:15:23.029] iteration 677 : model1 loss : 0.086169 model2 loss : 0.170792
[20:15:23.692] iteration 678 : model1 loss : 0.103829 model2 loss : 0.103735
[20:15:24.355] iteration 679 : model1 loss : 0.172867 model2 loss : 0.165102
[20:15:25.015] iteration 680 : model1 loss : 0.116122 model2 loss : 0.208681
[20:15:25.692] iteration 681 : model1 loss : 0.136039 model2 loss : 0.107820
[20:15:26.357] iteration 682 : model1 loss : 0.211268 model2 loss : 0.215811
[20:15:27.019] iteration 683 : model1 loss : 0.135988 model2 loss : 0.193767
[20:15:27.679] iteration 684 : model1 loss : 0.104233 model2 loss : 0.124628
[20:15:28.350] iteration 685 : model1 loss : 0.112538 model2 loss : 0.140783
[20:15:29.030] iteration 686 : model1 loss : 0.078964 model2 loss : 0.095760
[20:15:29.705] iteration 687 : model1 loss : 0.175418 model2 loss : 0.153193
[20:15:30.380] iteration 688 : model1 loss : 0.119602 model2 loss : 0.156650
[20:15:31.043] iteration 689 : model1 loss : 0.139217 model2 loss : 0.149069
[20:15:31.708] iteration 690 : model1 loss : 0.195054 model2 loss : 0.205660
[20:15:32.376] iteration 691 : model1 loss : 0.140231 model2 loss : 0.124794
[20:15:33.036] iteration 692 : model1 loss : 0.144544 model2 loss : 0.143636
[20:15:33.709] iteration 693 : model1 loss : 0.120650 model2 loss : 0.122701
[20:15:34.375] iteration 694 : model1 loss : 0.144516 model2 loss : 0.156270
[20:15:35.040] iteration 695 : model1 loss : 0.076105 model2 loss : 0.099610
[20:15:35.708] iteration 696 : model1 loss : 0.094204 model2 loss : 0.104831
[20:15:36.377] iteration 697 : model1 loss : 0.152462 model2 loss : 0.134404
[20:15:37.050] iteration 698 : model1 loss : 0.118972 model2 loss : 0.125108
[20:15:37.718] iteration 699 : model1 loss : 0.116449 model2 loss : 0.121627
[20:15:38.381] iteration 700 : model1 loss : 0.119410 model2 loss : 0.107785
[20:15:39.094] iteration 701 : model1 loss : 0.156728 model2 loss : 0.153647
[20:15:39.763] iteration 702 : model1 loss : 0.172330 model2 loss : 0.118628
[20:15:40.427] iteration 703 : model1 loss : 0.268048 model2 loss : 0.281026
[20:15:41.102] iteration 704 : model1 loss : 0.178239 model2 loss : 0.185281
[20:15:41.772] iteration 705 : model1 loss : 0.215083 model2 loss : 0.153989
[20:15:42.445] iteration 706 : model1 loss : 0.153799 model2 loss : 0.176164
[20:15:43.116] iteration 707 : model1 loss : 0.086260 model2 loss : 0.100821
[20:15:43.777] iteration 708 : model1 loss : 0.145977 model2 loss : 0.112450
[20:15:44.446] iteration 709 : model1 loss : 0.167932 model2 loss : 0.112153
[20:15:45.116] iteration 710 : model1 loss : 0.081319 model2 loss : 0.090139
[20:15:45.799] iteration 711 : model1 loss : 0.116693 model2 loss : 0.259872
[20:15:46.470] iteration 712 : model1 loss : 0.135206 model2 loss : 0.158201
[20:15:47.135] iteration 713 : model1 loss : 0.095129 model2 loss : 0.091365
[20:15:47.800] iteration 714 : model1 loss : 0.147260 model2 loss : 0.218287
[20:15:48.469] iteration 715 : model1 loss : 0.183354 model2 loss : 0.135498
[20:15:49.129] iteration 716 : model1 loss : 0.272385 model2 loss : 0.284230
[20:15:49.788] iteration 717 : model1 loss : 0.131652 model2 loss : 0.109517
[20:15:50.459] iteration 718 : model1 loss : 0.124890 model2 loss : 0.127154
[20:15:51.130] iteration 719 : model1 loss : 0.119131 model2 loss : 0.169968
[20:15:51.802] iteration 720 : model1 loss : 0.069931 model2 loss : 0.077481
[20:15:52.468] iteration 721 : model1 loss : 0.142154 model2 loss : 0.170388
[20:15:53.127] iteration 722 : model1 loss : 0.170233 model2 loss : 0.191604
[20:15:53.793] iteration 723 : model1 loss : 0.230282 model2 loss : 0.195799
[20:15:54.458] iteration 724 : model1 loss : 0.086057 model2 loss : 0.098364
[20:15:55.127] iteration 725 : model1 loss : 0.157639 model2 loss : 0.186229
[20:15:55.797] iteration 726 : model1 loss : 0.140107 model2 loss : 0.119638
[20:15:56.484] iteration 727 : model1 loss : 0.101490 model2 loss : 0.099682
[20:15:57.138] iteration 728 : model1 loss : 0.086632 model2 loss : 0.112150
[20:15:57.810] iteration 729 : model1 loss : 0.155654 model2 loss : 0.206408
[20:15:58.478] iteration 730 : model1 loss : 0.087938 model2 loss : 0.130957
[20:15:59.153] iteration 731 : model1 loss : 0.139484 model2 loss : 0.174292
[20:15:59.815] iteration 732 : model1 loss : 0.223435 model2 loss : 0.206525
[20:16:00.483] iteration 733 : model1 loss : 0.148451 model2 loss : 0.181344
[20:16:01.154] iteration 734 : model1 loss : 0.164194 model2 loss : 0.163036
[20:16:01.818] iteration 735 : model1 loss : 0.104390 model2 loss : 0.117857
[20:16:02.510] iteration 736 : model1 loss : 0.079875 model2 loss : 0.122364
[20:16:03.186] iteration 737 : model1 loss : 0.245713 model2 loss : 0.203374
[20:16:03.842] iteration 738 : model1 loss : 0.115179 model2 loss : 0.122876
[20:16:04.512] iteration 739 : model1 loss : 0.173104 model2 loss : 0.142843
[20:16:05.181] iteration 740 : model1 loss : 0.147492 model2 loss : 0.117949
[20:16:05.851] iteration 741 : model1 loss : 0.277883 model2 loss : 0.206168
[20:16:06.516] iteration 742 : model1 loss : 0.082722 model2 loss : 0.071417
[20:16:07.178] iteration 743 : model1 loss : 0.138446 model2 loss : 0.146391
[20:16:07.836] iteration 744 : model1 loss : 0.068642 model2 loss : 0.105888
[20:16:08.506] iteration 745 : model1 loss : 0.057441 model2 loss : 0.067083
[20:16:09.172] iteration 746 : model1 loss : 0.080167 model2 loss : 0.116738
[20:16:09.837] iteration 747 : model1 loss : 0.107136 model2 loss : 0.126627
[20:16:10.505] iteration 748 : model1 loss : 0.156833 model2 loss : 0.184717
[20:16:11.171] iteration 749 : model1 loss : 0.062531 model2 loss : 0.078087
[20:16:11.833] iteration 750 : model1 loss : 0.178109 model2 loss : 0.238433
[20:16:12.559] iteration 751 : model1 loss : 0.112001 model2 loss : 0.209349
[20:16:13.225] iteration 752 : model1 loss : 0.122110 model2 loss : 0.148048
[20:16:13.893] iteration 753 : model1 loss : 0.100794 model2 loss : 0.105006
[20:16:14.558] iteration 754 : model1 loss : 0.137868 model2 loss : 0.162738
[20:16:15.227] iteration 755 : model1 loss : 0.120772 model2 loss : 0.285474
[20:16:15.884] iteration 756 : model1 loss : 0.151264 model2 loss : 0.175369
[20:16:16.558] iteration 757 : model1 loss : 0.110391 model2 loss : 0.134619
[20:16:17.225] iteration 758 : model1 loss : 0.093000 model2 loss : 0.130759
[20:16:17.898] iteration 759 : model1 loss : 0.131366 model2 loss : 0.132563
[20:16:18.570] iteration 760 : model1 loss : 0.122770 model2 loss : 0.161662
[20:16:19.249] iteration 761 : model1 loss : 0.103896 model2 loss : 0.202026
[20:16:19.917] iteration 762 : model1 loss : 0.068494 model2 loss : 0.106299
[20:16:20.583] iteration 763 : model1 loss : 0.089454 model2 loss : 0.109051
[20:16:21.255] iteration 764 : model1 loss : 0.115481 model2 loss : 0.133531
[20:16:21.923] iteration 765 : model1 loss : 0.176730 model2 loss : 0.222938
[20:16:22.586] iteration 766 : model1 loss : 0.093301 model2 loss : 0.132106
[20:16:23.255] iteration 767 : model1 loss : 0.102663 model2 loss : 0.120544
[20:16:23.926] iteration 768 : model1 loss : 0.109801 model2 loss : 0.139917
[20:16:24.587] iteration 769 : model1 loss : 0.100518 model2 loss : 0.157054
[20:16:25.261] iteration 770 : model1 loss : 0.148142 model2 loss : 0.248033
[20:16:25.925] iteration 771 : model1 loss : 0.113244 model2 loss : 0.136515
[20:16:26.583] iteration 772 : model1 loss : 0.145468 model2 loss : 0.122898
[20:16:27.248] iteration 773 : model1 loss : 0.100621 model2 loss : 0.103823
[20:16:27.908] iteration 774 : model1 loss : 0.083519 model2 loss : 0.148367
[20:16:28.604] iteration 775 : model1 loss : 0.173323 model2 loss : 0.196006
[20:16:29.273] iteration 776 : model1 loss : 0.094097 model2 loss : 0.097371
[20:16:29.937] iteration 777 : model1 loss : 0.115541 model2 loss : 0.136053
[20:16:30.613] iteration 778 : model1 loss : 0.086832 model2 loss : 0.090946
[20:16:31.278] iteration 779 : model1 loss : 0.182622 model2 loss : 0.169127
[20:16:31.942] iteration 780 : model1 loss : 0.178689 model2 loss : 0.160817
[20:16:32.612] iteration 781 : model1 loss : 0.074972 model2 loss : 0.105462
[20:16:33.269] iteration 782 : model1 loss : 0.158365 model2 loss : 0.161850
[20:16:33.946] iteration 783 : model1 loss : 0.152288 model2 loss : 0.142439
[20:16:34.612] iteration 784 : model1 loss : 0.153354 model2 loss : 0.146776
[20:16:35.291] iteration 785 : model1 loss : 0.277500 model2 loss : 0.278124
[20:16:35.960] iteration 786 : model1 loss : 0.114303 model2 loss : 0.158694
[20:16:36.629] iteration 787 : model1 loss : 0.089280 model2 loss : 0.094994
[20:16:37.308] iteration 788 : model1 loss : 0.100764 model2 loss : 0.116208
[20:16:37.968] iteration 789 : model1 loss : 0.105264 model2 loss : 0.142984
[20:16:38.645] iteration 790 : model1 loss : 0.167824 model2 loss : 0.140555
[20:16:39.314] iteration 791 : model1 loss : 0.121025 model2 loss : 0.113553
[20:16:39.981] iteration 792 : model1 loss : 0.216468 model2 loss : 0.210295
[20:16:40.663] iteration 793 : model1 loss : 0.155108 model2 loss : 0.177023
[20:16:41.339] iteration 794 : model1 loss : 0.074805 model2 loss : 0.115822
[20:16:42.033] iteration 795 : model1 loss : 0.080837 model2 loss : 0.116353
[20:16:42.739] iteration 796 : model1 loss : 0.117364 model2 loss : 0.147710
[20:16:43.419] iteration 797 : model1 loss : 0.176041 model2 loss : 0.128512
[20:16:44.091] iteration 798 : model1 loss : 0.149528 model2 loss : 0.214402
[20:16:44.758] iteration 799 : model1 loss : 0.132511 model2 loss : 0.125330
[20:16:45.435] iteration 800 : model1 loss : 0.174984 model2 loss : 0.180420
[20:17:04.514] iteration 800 : model1_mean_dice : 0.661986 model1_mean_hd95 : 46.173532
[20:17:23.199] iteration 800 : model2_mean_dice : 0.584527 model2_mean_hd95 : 47.052340
[20:17:23.901] iteration 801 : model1 loss : 0.086760 model2 loss : 0.108796
[20:17:24.552] iteration 802 : model1 loss : 0.203024 model2 loss : 0.169940
[20:17:25.222] iteration 803 : model1 loss : 0.103121 model2 loss : 0.119944
[20:17:25.885] iteration 804 : model1 loss : 0.161820 model2 loss : 0.178307
[20:17:26.551] iteration 805 : model1 loss : 0.220832 model2 loss : 0.211032
[20:17:27.211] iteration 806 : model1 loss : 0.176395 model2 loss : 0.203021
[20:17:27.866] iteration 807 : model1 loss : 0.088281 model2 loss : 0.091312
[20:17:28.538] iteration 808 : model1 loss : 0.092355 model2 loss : 0.096634
[20:17:29.199] iteration 809 : model1 loss : 0.094987 model2 loss : 0.115113
[20:17:29.865] iteration 810 : model1 loss : 0.287383 model2 loss : 0.264318
[20:17:30.513] iteration 811 : model1 loss : 0.083925 model2 loss : 0.117656
[20:17:31.173] iteration 812 : model1 loss : 0.190060 model2 loss : 0.164924
[20:17:31.830] iteration 813 : model1 loss : 0.097966 model2 loss : 0.108330
[20:17:32.506] iteration 814 : model1 loss : 0.143480 model2 loss : 0.159981
[20:17:33.168] iteration 815 : model1 loss : 0.145081 model2 loss : 0.194905
[20:17:33.834] iteration 816 : model1 loss : 0.193481 model2 loss : 0.170650
[20:17:34.508] iteration 817 : model1 loss : 0.123472 model2 loss : 0.171582
[20:17:35.168] iteration 818 : model1 loss : 0.163071 model2 loss : 0.200529
[20:17:35.818] iteration 819 : model1 loss : 0.084535 model2 loss : 0.103519
[20:17:36.482] iteration 820 : model1 loss : 0.066182 model2 loss : 0.073394
[20:17:37.146] iteration 821 : model1 loss : 0.097910 model2 loss : 0.136518
[20:17:37.806] iteration 822 : model1 loss : 0.100360 model2 loss : 0.127811
[20:17:38.482] iteration 823 : model1 loss : 0.135726 model2 loss : 0.140003
[20:17:39.149] iteration 824 : model1 loss : 0.114097 model2 loss : 0.111117
[20:17:39.827] iteration 825 : model1 loss : 0.165052 model2 loss : 0.131767
[20:17:40.491] iteration 826 : model1 loss : 0.083982 model2 loss : 0.091847
[20:17:41.148] iteration 827 : model1 loss : 0.279222 model2 loss : 0.252635
[20:17:41.808] iteration 828 : model1 loss : 0.081942 model2 loss : 0.106237
[20:17:42.464] iteration 829 : model1 loss : 0.182461 model2 loss : 0.217741
[20:17:43.128] iteration 830 : model1 loss : 0.106344 model2 loss : 0.159016
[20:17:43.796] iteration 831 : model1 loss : 0.135436 model2 loss : 0.107876
[20:17:44.474] iteration 832 : model1 loss : 0.126796 model2 loss : 0.153048
[20:17:45.139] iteration 833 : model1 loss : 0.100935 model2 loss : 0.140214
[20:17:45.803] iteration 834 : model1 loss : 0.083795 model2 loss : 0.102706
[20:17:46.463] iteration 835 : model1 loss : 0.085777 model2 loss : 0.095866
[20:17:47.122] iteration 836 : model1 loss : 0.068745 model2 loss : 0.080172
[20:17:47.788] iteration 837 : model1 loss : 0.104513 model2 loss : 0.111471
[20:17:48.477] iteration 838 : model1 loss : 0.238960 model2 loss : 0.250795
[20:17:49.140] iteration 839 : model1 loss : 0.079748 model2 loss : 0.088374
[20:17:49.819] iteration 840 : model1 loss : 0.085445 model2 loss : 0.110366
[20:17:50.489] iteration 841 : model1 loss : 0.089287 model2 loss : 0.113103
[20:17:51.174] iteration 842 : model1 loss : 0.056663 model2 loss : 0.065911
[20:17:51.834] iteration 843 : model1 loss : 0.060509 model2 loss : 0.063432
[20:17:52.526] iteration 844 : model1 loss : 0.085452 model2 loss : 0.125774
[20:17:53.241] iteration 845 : model1 loss : 0.195607 model2 loss : 0.179378
[20:17:53.967] iteration 846 : model1 loss : 0.054039 model2 loss : 0.077296
[20:17:54.659] iteration 847 : model1 loss : 0.055330 model2 loss : 0.082138
[20:17:55.353] iteration 848 : model1 loss : 0.122090 model2 loss : 0.109575
[20:17:56.041] iteration 849 : model1 loss : 0.058203 model2 loss : 0.134199
[20:17:56.698] iteration 850 : model1 loss : 0.048003 model2 loss : 0.084214
[20:17:57.468] iteration 851 : model1 loss : 0.067207 model2 loss : 0.089855
[20:17:58.136] iteration 852 : model1 loss : 0.076515 model2 loss : 0.110648
[20:17:58.815] iteration 853 : model1 loss : 0.048732 model2 loss : 0.070678
[20:17:59.475] iteration 854 : model1 loss : 0.080148 model2 loss : 0.106122
[20:18:00.131] iteration 855 : model1 loss : 0.080240 model2 loss : 0.085713
[20:18:00.800] iteration 856 : model1 loss : 0.185741 model2 loss : 0.171763
[20:18:01.475] iteration 857 : model1 loss : 0.072060 model2 loss : 0.089899
[20:18:02.138] iteration 858 : model1 loss : 0.081110 model2 loss : 0.066806
[20:18:02.796] iteration 859 : model1 loss : 0.066853 model2 loss : 0.074036
[20:18:03.491] iteration 860 : model1 loss : 0.068125 model2 loss : 0.085429
[20:18:04.151] iteration 861 : model1 loss : 0.092255 model2 loss : 0.074896
[20:18:04.809] iteration 862 : model1 loss : 0.064128 model2 loss : 0.067629
[20:18:05.490] iteration 863 : model1 loss : 0.125201 model2 loss : 0.152781
[20:18:06.162] iteration 864 : model1 loss : 0.094774 model2 loss : 0.147720
[20:18:06.820] iteration 865 : model1 loss : 0.070759 model2 loss : 0.085427
[20:18:07.488] iteration 866 : model1 loss : 0.137985 model2 loss : 0.141613
[20:18:08.159] iteration 867 : model1 loss : 0.073915 model2 loss : 0.080606
[20:18:08.824] iteration 868 : model1 loss : 0.204375 model2 loss : 0.186384
[20:18:09.498] iteration 869 : model1 loss : 0.159810 model2 loss : 0.133892
[20:18:10.159] iteration 870 : model1 loss : 0.063399 model2 loss : 0.093737
[20:18:10.819] iteration 871 : model1 loss : 0.209344 model2 loss : 0.184325
[20:18:11.481] iteration 872 : model1 loss : 0.098481 model2 loss : 0.121664
[20:18:12.141] iteration 873 : model1 loss : 0.310752 model2 loss : 0.268373
[20:18:12.814] iteration 874 : model1 loss : 0.180258 model2 loss : 0.174386
[20:18:13.475] iteration 875 : model1 loss : 0.089766 model2 loss : 0.084978
[20:18:14.147] iteration 876 : model1 loss : 0.112798 model2 loss : 0.141007
[20:18:14.818] iteration 877 : model1 loss : 0.067848 model2 loss : 0.119742
[20:18:15.485] iteration 878 : model1 loss : 0.102299 model2 loss : 0.137009
[20:18:16.157] iteration 879 : model1 loss : 0.142007 model2 loss : 0.155199
[20:18:16.813] iteration 880 : model1 loss : 0.066613 model2 loss : 0.080072
[20:18:17.487] iteration 881 : model1 loss : 0.065326 model2 loss : 0.082202
[20:18:18.155] iteration 882 : model1 loss : 0.113482 model2 loss : 0.110329
[20:18:18.819] iteration 883 : model1 loss : 0.116008 model2 loss : 0.105648
[20:18:19.479] iteration 884 : model1 loss : 0.148166 model2 loss : 0.109158
[20:18:20.143] iteration 885 : model1 loss : 0.116953 model2 loss : 0.117091
[20:18:20.808] iteration 886 : model1 loss : 0.067368 model2 loss : 0.064572
[20:18:21.488] iteration 887 : model1 loss : 0.156878 model2 loss : 0.214044
[20:18:22.146] iteration 888 : model1 loss : 0.071892 model2 loss : 0.078492
[20:18:22.813] iteration 889 : model1 loss : 0.124387 model2 loss : 0.137028
[20:18:23.475] iteration 890 : model1 loss : 0.067232 model2 loss : 0.096176
[20:18:24.140] iteration 891 : model1 loss : 0.115929 model2 loss : 0.106179
[20:18:24.811] iteration 892 : model1 loss : 0.082516 model2 loss : 0.102985
[20:18:25.480] iteration 893 : model1 loss : 0.168395 model2 loss : 0.209167
[20:18:26.141] iteration 894 : model1 loss : 0.120253 model2 loss : 0.133440
[20:18:26.813] iteration 895 : model1 loss : 0.106784 model2 loss : 0.175422
[20:18:27.488] iteration 896 : model1 loss : 0.150010 model2 loss : 0.118300
[20:18:28.168] iteration 897 : model1 loss : 0.081353 model2 loss : 0.074294
[20:18:28.834] iteration 898 : model1 loss : 0.077628 model2 loss : 0.114176
[20:18:29.504] iteration 899 : model1 loss : 0.125210 model2 loss : 0.141837
[20:18:30.168] iteration 900 : model1 loss : 0.154467 model2 loss : 0.142044
[20:18:30.877] iteration 901 : model1 loss : 0.175768 model2 loss : 0.143595
[20:18:31.556] iteration 902 : model1 loss : 0.112935 model2 loss : 0.132930
[20:18:32.215] iteration 903 : model1 loss : 0.099758 model2 loss : 0.118334
[20:18:32.883] iteration 904 : model1 loss : 0.082983 model2 loss : 0.142856
[20:18:33.541] iteration 905 : model1 loss : 0.126125 model2 loss : 0.100160
[20:18:34.204] iteration 906 : model1 loss : 0.166715 model2 loss : 0.108435
[20:18:34.878] iteration 907 : model1 loss : 0.120936 model2 loss : 0.118967
[20:18:35.536] iteration 908 : model1 loss : 0.099976 model2 loss : 0.119180
[20:18:36.216] iteration 909 : model1 loss : 0.048082 model2 loss : 0.069094
[20:18:36.869] iteration 910 : model1 loss : 0.068754 model2 loss : 0.084247
[20:18:37.523] iteration 911 : model1 loss : 0.079890 model2 loss : 0.115027
[20:18:38.191] iteration 912 : model1 loss : 0.109988 model2 loss : 0.118163
[20:18:38.859] iteration 913 : model1 loss : 0.141772 model2 loss : 0.176242
[20:18:39.522] iteration 914 : model1 loss : 0.076282 model2 loss : 0.083916
[20:18:40.206] iteration 915 : model1 loss : 0.247930 model2 loss : 0.169162
[20:18:40.866] iteration 916 : model1 loss : 0.048561 model2 loss : 0.080182
[20:18:41.536] iteration 917 : model1 loss : 0.104963 model2 loss : 0.097054
[20:18:42.196] iteration 918 : model1 loss : 0.068003 model2 loss : 0.075302
[20:18:42.864] iteration 919 : model1 loss : 0.123422 model2 loss : 0.121373
[20:18:43.540] iteration 920 : model1 loss : 0.065487 model2 loss : 0.072179
[20:18:44.228] iteration 921 : model1 loss : 0.051613 model2 loss : 0.062850
[20:18:44.906] iteration 922 : model1 loss : 0.187635 model2 loss : 0.190844
[20:18:45.567] iteration 923 : model1 loss : 0.119924 model2 loss : 0.119857
[20:18:46.240] iteration 924 : model1 loss : 0.110320 model2 loss : 0.074973
[20:18:46.907] iteration 925 : model1 loss : 0.169077 model2 loss : 0.115051
[20:18:47.572] iteration 926 : model1 loss : 0.236854 model2 loss : 0.257313
[20:18:48.238] iteration 927 : model1 loss : 0.074590 model2 loss : 0.078053
[20:18:48.899] iteration 928 : model1 loss : 0.127908 model2 loss : 0.139119
[20:18:49.552] iteration 929 : model1 loss : 0.079579 model2 loss : 0.105209
[20:18:50.224] iteration 930 : model1 loss : 0.099809 model2 loss : 0.103582
[20:18:50.881] iteration 931 : model1 loss : 0.097491 model2 loss : 0.126161
[20:18:51.537] iteration 932 : model1 loss : 0.086693 model2 loss : 0.110360
[20:18:52.197] iteration 933 : model1 loss : 0.092340 model2 loss : 0.121688
[20:18:52.849] iteration 934 : model1 loss : 0.111718 model2 loss : 0.143985
[20:18:53.524] iteration 935 : model1 loss : 0.178224 model2 loss : 0.173869
[20:18:54.195] iteration 936 : model1 loss : 0.093962 model2 loss : 0.088115
[20:18:54.862] iteration 937 : model1 loss : 0.165574 model2 loss : 0.122557
[20:18:55.600] iteration 938 : model1 loss : 0.091243 model2 loss : 0.126294
[20:18:56.272] iteration 939 : model1 loss : 0.089003 model2 loss : 0.144368
[20:18:56.946] iteration 940 : model1 loss : 0.100559 model2 loss : 0.105522
[20:18:57.604] iteration 941 : model1 loss : 0.128503 model2 loss : 0.185009
[20:18:58.267] iteration 942 : model1 loss : 0.121147 model2 loss : 0.149469
[20:18:58.929] iteration 943 : model1 loss : 0.186294 model2 loss : 0.226479
[20:18:59.600] iteration 944 : model1 loss : 0.078169 model2 loss : 0.087701
[20:19:00.271] iteration 945 : model1 loss : 0.068239 model2 loss : 0.074448
[20:19:00.928] iteration 946 : model1 loss : 0.172968 model2 loss : 0.106810
[20:19:01.594] iteration 947 : model1 loss : 0.091113 model2 loss : 0.090139
[20:19:02.262] iteration 948 : model1 loss : 0.161727 model2 loss : 0.122723
[20:19:02.927] iteration 949 : model1 loss : 0.065319 model2 loss : 0.078662
[20:19:03.613] iteration 950 : model1 loss : 0.167993 model2 loss : 0.126062
[20:19:04.334] iteration 951 : model1 loss : 0.151155 model2 loss : 0.085273
[20:19:05.014] iteration 952 : model1 loss : 0.078205 model2 loss : 0.066642
[20:19:05.678] iteration 953 : model1 loss : 0.170577 model2 loss : 0.165818
[20:19:06.348] iteration 954 : model1 loss : 0.100112 model2 loss : 0.090301
[20:19:07.008] iteration 955 : model1 loss : 0.209515 model2 loss : 0.190195
[20:19:07.673] iteration 956 : model1 loss : 0.152696 model2 loss : 0.117765
[20:19:08.342] iteration 957 : model1 loss : 0.060314 model2 loss : 0.067482
[20:19:09.019] iteration 958 : model1 loss : 0.086323 model2 loss : 0.108933
[20:19:09.683] iteration 959 : model1 loss : 0.099943 model2 loss : 0.111958
[20:19:10.353] iteration 960 : model1 loss : 0.074404 model2 loss : 0.075552
[20:19:11.018] iteration 961 : model1 loss : 0.068215 model2 loss : 0.074104
[20:19:11.679] iteration 962 : model1 loss : 0.158943 model2 loss : 0.094120
[20:19:12.349] iteration 963 : model1 loss : 0.074295 model2 loss : 0.049080
[20:19:13.013] iteration 964 : model1 loss : 0.183001 model2 loss : 0.148540
[20:19:13.680] iteration 965 : model1 loss : 0.059547 model2 loss : 0.064297
[20:19:14.351] iteration 966 : model1 loss : 0.090229 model2 loss : 0.087203
[20:19:15.012] iteration 967 : model1 loss : 0.083678 model2 loss : 0.069106
[20:19:15.677] iteration 968 : model1 loss : 0.082785 model2 loss : 0.119628
[20:19:16.343] iteration 969 : model1 loss : 0.108101 model2 loss : 0.116363
[20:19:17.012] iteration 970 : model1 loss : 0.065530 model2 loss : 0.059835
[20:19:17.676] iteration 971 : model1 loss : 0.064157 model2 loss : 0.059895
[20:19:18.353] iteration 972 : model1 loss : 0.149588 model2 loss : 0.164439
[20:19:19.033] iteration 973 : model1 loss : 0.075213 model2 loss : 0.061343
[20:19:19.715] iteration 974 : model1 loss : 0.111043 model2 loss : 0.174879
[20:19:20.375] iteration 975 : model1 loss : 0.126061 model2 loss : 0.141957
[20:19:21.057] iteration 976 : model1 loss : 0.082253 model2 loss : 0.104662
[20:19:21.725] iteration 977 : model1 loss : 0.157805 model2 loss : 0.131241
[20:19:22.399] iteration 978 : model1 loss : 0.144826 model2 loss : 0.187758
[20:19:23.060] iteration 979 : model1 loss : 0.260170 model2 loss : 0.227171
[20:19:23.724] iteration 980 : model1 loss : 0.049127 model2 loss : 0.061321
[20:19:24.394] iteration 981 : model1 loss : 0.070723 model2 loss : 0.085438
[20:19:25.068] iteration 982 : model1 loss : 0.099369 model2 loss : 0.086650
[20:19:25.732] iteration 983 : model1 loss : 0.083963 model2 loss : 0.087629
[20:19:26.407] iteration 984 : model1 loss : 0.092659 model2 loss : 0.142179
[20:19:27.067] iteration 985 : model1 loss : 0.066503 model2 loss : 0.078191
[20:19:27.739] iteration 986 : model1 loss : 0.073958 model2 loss : 0.073282
[20:19:28.398] iteration 987 : model1 loss : 0.169199 model2 loss : 0.148376
[20:19:29.060] iteration 988 : model1 loss : 0.088820 model2 loss : 0.086545
[20:19:29.733] iteration 989 : model1 loss : 0.181408 model2 loss : 0.150944
[20:19:30.399] iteration 990 : model1 loss : 0.102567 model2 loss : 0.113402
[20:19:31.059] iteration 991 : model1 loss : 0.043904 model2 loss : 0.060604
[20:19:31.718] iteration 992 : model1 loss : 0.059016 model2 loss : 0.076756
[20:19:32.382] iteration 993 : model1 loss : 0.069873 model2 loss : 0.087480
[20:19:33.044] iteration 994 : model1 loss : 0.173849 model2 loss : 0.094615
[20:19:33.693] iteration 995 : model1 loss : 0.090791 model2 loss : 0.085865
[20:19:34.353] iteration 996 : model1 loss : 0.157870 model2 loss : 0.134761
[20:19:35.023] iteration 997 : model1 loss : 0.110427 model2 loss : 0.092227
[20:19:35.681] iteration 998 : model1 loss : 0.078300 model2 loss : 0.108899
[20:19:36.339] iteration 999 : model1 loss : 0.065518 model2 loss : 0.070655
[20:19:37.001] iteration 1000 : model1 loss : 0.115322 model2 loss : 0.092238
[20:19:55.600] iteration 1000 : model1_mean_dice : 0.707913 model1_mean_hd95 : 24.054031
[20:20:14.801] iteration 1000 : model2_mean_dice : 0.689636 model2_mean_hd95 : 26.322082
[20:20:15.490] iteration 1001 : model1 loss : 0.099644 model2 loss : 0.068525
[20:20:16.159] iteration 1002 : model1 loss : 0.213234 model2 loss : 0.190456
[20:20:16.819] iteration 1003 : model1 loss : 0.077817 model2 loss : 0.060053
[20:20:17.477] iteration 1004 : model1 loss : 0.085315 model2 loss : 0.095465
[20:20:18.146] iteration 1005 : model1 loss : 0.143826 model2 loss : 0.115766
[20:20:18.808] iteration 1006 : model1 loss : 0.126412 model2 loss : 0.114440
[20:20:19.484] iteration 1007 : model1 loss : 0.135595 model2 loss : 0.130640
[20:20:20.137] iteration 1008 : model1 loss : 0.064648 model2 loss : 0.057251
[20:20:20.798] iteration 1009 : model1 loss : 0.082446 model2 loss : 0.068923
[20:20:21.457] iteration 1010 : model1 loss : 0.108083 model2 loss : 0.090073
[20:20:22.139] iteration 1011 : model1 loss : 0.109671 model2 loss : 0.144194
[20:20:22.813] iteration 1012 : model1 loss : 0.073155 model2 loss : 0.076918
[20:20:23.461] iteration 1013 : model1 loss : 0.107527 model2 loss : 0.066791
[20:20:24.127] iteration 1014 : model1 loss : 0.114183 model2 loss : 0.112235
[20:20:24.779] iteration 1015 : model1 loss : 0.043690 model2 loss : 0.044640
[20:20:25.438] iteration 1016 : model1 loss : 0.068152 model2 loss : 0.095709
[20:20:26.105] iteration 1017 : model1 loss : 0.189689 model2 loss : 0.180074
[20:20:26.768] iteration 1018 : model1 loss : 0.178273 model2 loss : 0.124587
[20:20:27.440] iteration 1019 : model1 loss : 0.154729 model2 loss : 0.174298
[20:20:28.111] iteration 1020 : model1 loss : 0.100466 model2 loss : 0.095623
[20:20:28.785] iteration 1021 : model1 loss : 0.066370 model2 loss : 0.078601
[20:20:29.446] iteration 1022 : model1 loss : 0.098382 model2 loss : 0.077482
[20:20:30.111] iteration 1023 : model1 loss : 0.088407 model2 loss : 0.133549
[20:20:30.772] iteration 1024 : model1 loss : 0.092360 model2 loss : 0.105680
[20:20:31.428] iteration 1025 : model1 loss : 0.154488 model2 loss : 0.142757
[20:20:32.088] iteration 1026 : model1 loss : 0.116471 model2 loss : 0.092057
[20:20:32.769] iteration 1027 : model1 loss : 0.252000 model2 loss : 0.250380
[20:20:33.428] iteration 1028 : model1 loss : 0.207503 model2 loss : 0.172311
[20:20:34.087] iteration 1029 : model1 loss : 0.329531 model2 loss : 0.212662
[20:20:34.756] iteration 1030 : model1 loss : 0.087761 model2 loss : 0.070894
[20:20:35.411] iteration 1031 : model1 loss : 0.128347 model2 loss : 0.123728
[20:20:36.079] iteration 1032 : model1 loss : 0.167186 model2 loss : 0.113885
[20:20:36.739] iteration 1033 : model1 loss : 0.049705 model2 loss : 0.082829
[20:20:37.442] iteration 1034 : model1 loss : 0.131944 model2 loss : 0.127228
[20:20:38.117] iteration 1035 : model1 loss : 0.043411 model2 loss : 0.066709
[20:20:38.776] iteration 1036 : model1 loss : 0.080836 model2 loss : 0.084087
[20:20:39.448] iteration 1037 : model1 loss : 0.060459 model2 loss : 0.054457
[20:20:40.114] iteration 1038 : model1 loss : 0.090566 model2 loss : 0.101169
[20:20:40.779] iteration 1039 : model1 loss : 0.064494 model2 loss : 0.062138
[20:20:41.448] iteration 1040 : model1 loss : 0.064254 model2 loss : 0.057761
[20:20:42.112] iteration 1041 : model1 loss : 0.100312 model2 loss : 0.096339
[20:20:42.772] iteration 1042 : model1 loss : 0.071231 model2 loss : 0.073726
[20:20:43.461] iteration 1043 : model1 loss : 0.078720 model2 loss : 0.079777
[20:20:44.134] iteration 1044 : model1 loss : 0.095164 model2 loss : 0.084407
[20:20:44.814] iteration 1045 : model1 loss : 0.168412 model2 loss : 0.162073
[20:20:45.510] iteration 1046 : model1 loss : 0.108763 model2 loss : 0.129265
[20:20:46.202] iteration 1047 : model1 loss : 0.114586 model2 loss : 0.116776
[20:20:46.875] iteration 1048 : model1 loss : 0.068670 model2 loss : 0.060490
[20:20:47.540] iteration 1049 : model1 loss : 0.093985 model2 loss : 0.087952
[20:20:48.205] iteration 1050 : model1 loss : 0.071458 model2 loss : 0.058797
[20:20:48.918] iteration 1051 : model1 loss : 0.075933 model2 loss : 0.070998
[20:20:49.584] iteration 1052 : model1 loss : 0.124692 model2 loss : 0.108549
[20:20:50.258] iteration 1053 : model1 loss : 0.227244 model2 loss : 0.103201
[20:20:50.945] iteration 1054 : model1 loss : 0.107514 model2 loss : 0.082671
[20:20:51.606] iteration 1055 : model1 loss : 0.064910 model2 loss : 0.070311
[20:20:52.260] iteration 1056 : model1 loss : 0.045349 model2 loss : 0.044672
[20:20:52.921] iteration 1057 : model1 loss : 0.074355 model2 loss : 0.073133
[20:20:53.587] iteration 1058 : model1 loss : 0.049273 model2 loss : 0.045278
[20:20:54.262] iteration 1059 : model1 loss : 0.078683 model2 loss : 0.091605
[20:20:54.929] iteration 1060 : model1 loss : 0.065672 model2 loss : 0.064422
[20:20:55.604] iteration 1061 : model1 loss : 0.164451 model2 loss : 0.166569
[20:20:56.260] iteration 1062 : model1 loss : 0.060611 model2 loss : 0.108876
[20:20:56.927] iteration 1063 : model1 loss : 0.056624 model2 loss : 0.066249
[20:20:57.594] iteration 1064 : model1 loss : 0.156322 model2 loss : 0.146352
[20:20:58.268] iteration 1065 : model1 loss : 0.062305 model2 loss : 0.089281
[20:20:58.930] iteration 1066 : model1 loss : 0.194793 model2 loss : 0.196516
[20:20:59.594] iteration 1067 : model1 loss : 0.074162 model2 loss : 0.054105
[20:21:00.268] iteration 1068 : model1 loss : 0.085138 model2 loss : 0.090923
[20:21:00.939] iteration 1069 : model1 loss : 0.157311 model2 loss : 0.132372
[20:21:01.608] iteration 1070 : model1 loss : 0.163852 model2 loss : 0.135206
[20:21:02.288] iteration 1071 : model1 loss : 0.165484 model2 loss : 0.162583
[20:21:02.946] iteration 1072 : model1 loss : 0.057423 model2 loss : 0.061281
[20:21:03.622] iteration 1073 : model1 loss : 0.095349 model2 loss : 0.113455
[20:21:04.276] iteration 1074 : model1 loss : 0.217005 model2 loss : 0.168220
[20:21:04.973] iteration 1075 : model1 loss : 0.087974 model2 loss : 0.091028
[20:21:05.643] iteration 1076 : model1 loss : 0.058194 model2 loss : 0.054643
[20:21:06.306] iteration 1077 : model1 loss : 0.070654 model2 loss : 0.062218
[20:21:06.969] iteration 1078 : model1 loss : 0.063621 model2 loss : 0.089780
[20:21:07.633] iteration 1079 : model1 loss : 0.065793 model2 loss : 0.078516
[20:21:08.301] iteration 1080 : model1 loss : 0.096600 model2 loss : 0.109797
[20:21:08.974] iteration 1081 : model1 loss : 0.146003 model2 loss : 0.098796
[20:21:09.644] iteration 1082 : model1 loss : 0.078726 model2 loss : 0.101438
[20:21:10.316] iteration 1083 : model1 loss : 0.079452 model2 loss : 0.076561
[20:21:10.990] iteration 1084 : model1 loss : 0.115217 model2 loss : 0.140723
[20:21:11.662] iteration 1085 : model1 loss : 0.153113 model2 loss : 0.179000
[20:21:12.348] iteration 1086 : model1 loss : 0.104553 model2 loss : 0.087743
[20:21:13.015] iteration 1087 : model1 loss : 0.045359 model2 loss : 0.041628
[20:21:13.679] iteration 1088 : model1 loss : 0.078511 model2 loss : 0.062688
[20:21:14.365] iteration 1089 : model1 loss : 0.053964 model2 loss : 0.061949
[20:21:15.027] iteration 1090 : model1 loss : 0.074934 model2 loss : 0.087535
[20:21:15.685] iteration 1091 : model1 loss : 0.046817 model2 loss : 0.060794
[20:21:16.352] iteration 1092 : model1 loss : 0.104705 model2 loss : 0.149796
[20:21:17.016] iteration 1093 : model1 loss : 0.064281 model2 loss : 0.101732
[20:21:17.689] iteration 1094 : model1 loss : 0.055048 model2 loss : 0.104462
[20:21:18.371] iteration 1095 : model1 loss : 0.084500 model2 loss : 0.114151
[20:21:19.053] iteration 1096 : model1 loss : 0.237904 model2 loss : 0.247452
[20:21:19.715] iteration 1097 : model1 loss : 0.141668 model2 loss : 0.163672
[20:21:20.383] iteration 1098 : model1 loss : 0.060174 model2 loss : 0.110144
[20:21:21.057] iteration 1099 : model1 loss : 0.111223 model2 loss : 0.115362
[20:21:21.723] iteration 1100 : model1 loss : 0.058176 model2 loss : 0.053593
[20:21:22.445] iteration 1101 : model1 loss : 0.126795 model2 loss : 0.228057
[20:21:23.344] iteration 1102 : model1 loss : 0.097148 model2 loss : 0.091231
[20:21:24.030] iteration 1103 : model1 loss : 0.061382 model2 loss : 0.060039
[20:21:24.749] iteration 1104 : model1 loss : 0.076925 model2 loss : 0.081219
[20:21:25.444] iteration 1105 : model1 loss : 0.088019 model2 loss : 0.090529
[20:21:26.101] iteration 1106 : model1 loss : 0.114981 model2 loss : 0.065599
[20:21:26.759] iteration 1107 : model1 loss : 0.091583 model2 loss : 0.132919
[20:21:27.432] iteration 1108 : model1 loss : 0.058334 model2 loss : 0.067202
[20:21:28.104] iteration 1109 : model1 loss : 0.055018 model2 loss : 0.073855
[20:21:28.772] iteration 1110 : model1 loss : 0.219408 model2 loss : 0.216669
[20:21:29.459] iteration 1111 : model1 loss : 0.103919 model2 loss : 0.155658
[20:21:30.130] iteration 1112 : model1 loss : 0.134173 model2 loss : 0.135610
[20:21:30.799] iteration 1113 : model1 loss : 0.061766 model2 loss : 0.054873
[20:21:31.477] iteration 1114 : model1 loss : 0.103895 model2 loss : 0.145244
[20:21:32.142] iteration 1115 : model1 loss : 0.102139 model2 loss : 0.096487
[20:21:32.804] iteration 1116 : model1 loss : 0.077284 model2 loss : 0.071446
[20:21:33.479] iteration 1117 : model1 loss : 0.154357 model2 loss : 0.136464
[20:21:34.143] iteration 1118 : model1 loss : 0.091082 model2 loss : 0.074528
[20:21:34.805] iteration 1119 : model1 loss : 0.072106 model2 loss : 0.095770
[20:21:35.466] iteration 1120 : model1 loss : 0.065813 model2 loss : 0.063478
[20:21:36.125] iteration 1121 : model1 loss : 0.184965 model2 loss : 0.162347
[20:21:36.795] iteration 1122 : model1 loss : 0.077794 model2 loss : 0.099361
[20:21:37.457] iteration 1123 : model1 loss : 0.047045 model2 loss : 0.057752
[20:21:38.161] iteration 1124 : model1 loss : 0.118462 model2 loss : 0.117754
[20:21:38.836] iteration 1125 : model1 loss : 0.047985 model2 loss : 0.059227
[20:21:39.503] iteration 1126 : model1 loss : 0.083929 model2 loss : 0.103664
[20:21:40.158] iteration 1127 : model1 loss : 0.057983 model2 loss : 0.072772
[20:21:40.830] iteration 1128 : model1 loss : 0.062279 model2 loss : 0.066261
[20:21:41.507] iteration 1129 : model1 loss : 0.048416 model2 loss : 0.069186
[20:21:42.183] iteration 1130 : model1 loss : 0.133515 model2 loss : 0.166070
[20:21:42.859] iteration 1131 : model1 loss : 0.054122 model2 loss : 0.073415
[20:21:43.532] iteration 1132 : model1 loss : 0.045921 model2 loss : 0.056074
[20:21:44.206] iteration 1133 : model1 loss : 0.063971 model2 loss : 0.087498
[20:21:44.855] iteration 1134 : model1 loss : 0.073020 model2 loss : 0.081681
[20:21:45.518] iteration 1135 : model1 loss : 0.059548 model2 loss : 0.076209
[20:21:46.187] iteration 1136 : model1 loss : 0.214039 model2 loss : 0.222043
[20:21:46.858] iteration 1137 : model1 loss : 0.085868 model2 loss : 0.116024
[20:21:47.538] iteration 1138 : model1 loss : 0.065149 model2 loss : 0.085745
[20:21:48.198] iteration 1139 : model1 loss : 0.082531 model2 loss : 0.150015
[20:21:48.862] iteration 1140 : model1 loss : 0.077508 model2 loss : 0.072515
[20:21:49.536] iteration 1141 : model1 loss : 0.111298 model2 loss : 0.143298
[20:21:50.209] iteration 1142 : model1 loss : 0.045191 model2 loss : 0.059383
[20:21:50.872] iteration 1143 : model1 loss : 0.052183 model2 loss : 0.077175
[20:21:51.548] iteration 1144 : model1 loss : 0.133881 model2 loss : 0.123771
[20:21:52.197] iteration 1145 : model1 loss : 0.059123 model2 loss : 0.081027
[20:21:52.864] iteration 1146 : model1 loss : 0.055440 model2 loss : 0.054147
[20:21:53.524] iteration 1147 : model1 loss : 0.100790 model2 loss : 0.119694
[20:21:54.197] iteration 1148 : model1 loss : 0.067445 model2 loss : 0.076491
[20:21:54.859] iteration 1149 : model1 loss : 0.059658 model2 loss : 0.065003
[20:21:55.528] iteration 1150 : model1 loss : 0.058864 model2 loss : 0.076287
[20:21:56.263] iteration 1151 : model1 loss : 0.111903 model2 loss : 0.125255
[20:21:56.922] iteration 1152 : model1 loss : 0.097767 model2 loss : 0.119090
[20:21:57.603] iteration 1153 : model1 loss : 0.050018 model2 loss : 0.054369
[20:21:58.272] iteration 1154 : model1 loss : 0.067705 model2 loss : 0.065098
[20:21:58.940] iteration 1155 : model1 loss : 0.097482 model2 loss : 0.109747
[20:21:59.611] iteration 1156 : model1 loss : 0.115884 model2 loss : 0.107724
[20:22:00.274] iteration 1157 : model1 loss : 0.090755 model2 loss : 0.158620
[20:22:00.942] iteration 1158 : model1 loss : 0.048145 model2 loss : 0.046600
[20:22:01.612] iteration 1159 : model1 loss : 0.121576 model2 loss : 0.093132
[20:22:02.276] iteration 1160 : model1 loss : 0.045758 model2 loss : 0.060515
[20:22:02.942] iteration 1161 : model1 loss : 0.061178 model2 loss : 0.065163
[20:22:03.612] iteration 1162 : model1 loss : 0.042546 model2 loss : 0.044146
[20:22:04.279] iteration 1163 : model1 loss : 0.073353 model2 loss : 0.102897
[20:22:04.943] iteration 1164 : model1 loss : 0.039273 model2 loss : 0.036198
[20:22:05.626] iteration 1165 : model1 loss : 0.061221 model2 loss : 0.067055
[20:22:06.295] iteration 1166 : model1 loss : 0.061600 model2 loss : 0.057326
[20:22:06.959] iteration 1167 : model1 loss : 0.066934 model2 loss : 0.069678
[20:22:07.644] iteration 1168 : model1 loss : 0.050505 model2 loss : 0.055964
[20:22:08.314] iteration 1169 : model1 loss : 0.044021 model2 loss : 0.043723
[20:22:09.025] iteration 1170 : model1 loss : 0.216268 model2 loss : 0.190102
[20:22:09.739] iteration 1171 : model1 loss : 0.086894 model2 loss : 0.091871
[20:22:10.421] iteration 1172 : model1 loss : 0.250506 model2 loss : 0.213090
[20:22:11.161] iteration 1173 : model1 loss : 0.049193 model2 loss : 0.046421
[20:22:11.878] iteration 1174 : model1 loss : 0.063556 model2 loss : 0.064680
[20:22:12.584] iteration 1175 : model1 loss : 0.116108 model2 loss : 0.113581
[20:22:13.291] iteration 1176 : model1 loss : 0.113509 model2 loss : 0.109108
[20:22:13.980] iteration 1177 : model1 loss : 0.146365 model2 loss : 0.136122
[20:22:14.664] iteration 1178 : model1 loss : 0.123695 model2 loss : 0.123177
[20:22:15.352] iteration 1179 : model1 loss : 0.102834 model2 loss : 0.124176
[20:22:16.033] iteration 1180 : model1 loss : 0.106401 model2 loss : 0.150581
[20:22:16.714] iteration 1181 : model1 loss : 0.087191 model2 loss : 0.129692
[20:22:17.432] iteration 1182 : model1 loss : 0.060367 model2 loss : 0.049920
[20:22:18.143] iteration 1183 : model1 loss : 0.081492 model2 loss : 0.061524
[20:22:18.836] iteration 1184 : model1 loss : 0.074935 model2 loss : 0.128627
[20:22:19.531] iteration 1185 : model1 loss : 0.050339 model2 loss : 0.051417
[20:22:20.313] iteration 1186 : model1 loss : 0.102049 model2 loss : 0.093074
[20:22:21.065] iteration 1187 : model1 loss : 0.099602 model2 loss : 0.101446
[20:22:21.811] iteration 1188 : model1 loss : 0.053723 model2 loss : 0.056504
[20:22:22.510] iteration 1189 : model1 loss : 0.054357 model2 loss : 0.060770
[20:22:23.199] iteration 1190 : model1 loss : 0.043177 model2 loss : 0.041374
[20:22:23.866] iteration 1191 : model1 loss : 0.167064 model2 loss : 0.179669
[20:22:24.538] iteration 1192 : model1 loss : 0.064304 model2 loss : 0.063016
[20:22:25.208] iteration 1193 : model1 loss : 0.105737 model2 loss : 0.148937
[20:22:25.881] iteration 1194 : model1 loss : 0.059260 model2 loss : 0.058808
[20:22:26.558] iteration 1195 : model1 loss : 0.087804 model2 loss : 0.099910
[20:22:27.228] iteration 1196 : model1 loss : 0.088556 model2 loss : 0.104254
[20:22:27.899] iteration 1197 : model1 loss : 0.048959 model2 loss : 0.050641
[20:22:28.580] iteration 1198 : model1 loss : 0.046861 model2 loss : 0.046561
[20:22:29.259] iteration 1199 : model1 loss : 0.057974 model2 loss : 0.070930
[20:22:29.928] iteration 1200 : model1 loss : 0.053512 model2 loss : 0.047362
[20:22:56.624] iteration 1200 : model1_mean_dice : 0.755809 model1_mean_hd95 : 11.073744
[20:23:16.915] iteration 1200 : model2_mean_dice : 0.713111 model2_mean_hd95 : 14.402878
[20:23:17.598] iteration 1201 : model1 loss : 0.079647 model2 loss : 0.126401
[20:23:18.286] iteration 1202 : model1 loss : 0.076719 model2 loss : 0.075020
[20:23:19.005] iteration 1203 : model1 loss : 0.108098 model2 loss : 0.101709
[20:23:19.709] iteration 1204 : model1 loss : 0.067512 model2 loss : 0.062977
[20:23:20.410] iteration 1205 : model1 loss : 0.046977 model2 loss : 0.043483
[20:23:21.105] iteration 1206 : model1 loss : 0.053658 model2 loss : 0.054376
[20:23:21.832] iteration 1207 : model1 loss : 0.102705 model2 loss : 0.080774
[20:23:22.525] iteration 1208 : model1 loss : 0.038825 model2 loss : 0.042080
[20:23:23.242] iteration 1209 : model1 loss : 0.046618 model2 loss : 0.060186
[20:23:23.941] iteration 1210 : model1 loss : 0.067927 model2 loss : 0.104346
[20:23:24.636] iteration 1211 : model1 loss : 0.101936 model2 loss : 0.079490
[20:23:25.359] iteration 1212 : model1 loss : 0.087911 model2 loss : 0.076116
[20:23:26.060] iteration 1213 : model1 loss : 0.069456 model2 loss : 0.081310
[20:23:26.754] iteration 1214 : model1 loss : 0.145363 model2 loss : 0.135122
[20:23:27.465] iteration 1215 : model1 loss : 0.054458 model2 loss : 0.052275
[20:23:28.140] iteration 1216 : model1 loss : 0.039558 model2 loss : 0.042185
[20:23:28.812] iteration 1217 : model1 loss : 0.102337 model2 loss : 0.078118
[20:23:29.486] iteration 1218 : model1 loss : 0.068064 model2 loss : 0.060394
[20:23:30.149] iteration 1219 : model1 loss : 0.056083 model2 loss : 0.062673
[20:23:30.838] iteration 1220 : model1 loss : 0.124819 model2 loss : 0.131484
[20:23:31.498] iteration 1221 : model1 loss : 0.105543 model2 loss : 0.101450
[20:23:32.147] iteration 1222 : model1 loss : 0.036979 model2 loss : 0.047420
[20:23:32.819] iteration 1223 : model1 loss : 0.116770 model2 loss : 0.152005
[20:23:33.502] iteration 1224 : model1 loss : 0.146922 model2 loss : 0.108145
[20:23:34.186] iteration 1225 : model1 loss : 0.113868 model2 loss : 0.142854
[20:23:34.846] iteration 1226 : model1 loss : 0.092994 model2 loss : 0.100533
[20:23:35.514] iteration 1227 : model1 loss : 0.043169 model2 loss : 0.044467
[20:23:36.176] iteration 1228 : model1 loss : 0.061946 model2 loss : 0.049614
[20:23:36.832] iteration 1229 : model1 loss : 0.064840 model2 loss : 0.070528
[20:23:37.503] iteration 1230 : model1 loss : 0.111448 model2 loss : 0.113357
[20:23:38.168] iteration 1231 : model1 loss : 0.133125 model2 loss : 0.108626
[20:23:38.826] iteration 1232 : model1 loss : 0.056233 model2 loss : 0.047268
[20:23:39.496] iteration 1233 : model1 loss : 0.094710 model2 loss : 0.090309
[20:23:40.153] iteration 1234 : model1 loss : 0.057354 model2 loss : 0.072425
[20:23:40.826] iteration 1235 : model1 loss : 0.081939 model2 loss : 0.090480
[20:23:41.484] iteration 1236 : model1 loss : 0.070822 model2 loss : 0.130951
[20:23:42.147] iteration 1237 : model1 loss : 0.057821 model2 loss : 0.056722
[20:23:42.864] iteration 1238 : model1 loss : 0.079341 model2 loss : 0.064351
[20:23:43.551] iteration 1239 : model1 loss : 0.092225 model2 loss : 0.084911
[20:23:44.223] iteration 1240 : model1 loss : 0.039205 model2 loss : 0.049711
[20:23:44.904] iteration 1241 : model1 loss : 0.067003 model2 loss : 0.127535
[20:23:45.593] iteration 1242 : model1 loss : 0.113510 model2 loss : 0.100388
[20:23:46.273] iteration 1243 : model1 loss : 0.080683 model2 loss : 0.063248
[20:23:46.943] iteration 1244 : model1 loss : 0.127262 model2 loss : 0.089724
[20:23:47.621] iteration 1245 : model1 loss : 0.068066 model2 loss : 0.084900
[20:23:48.286] iteration 1246 : model1 loss : 0.091771 model2 loss : 0.104747
[20:23:48.964] iteration 1247 : model1 loss : 0.111144 model2 loss : 0.136827
[20:23:49.649] iteration 1248 : model1 loss : 0.070659 model2 loss : 0.050670
[20:23:50.339] iteration 1249 : model1 loss : 0.058696 model2 loss : 0.076539
[20:23:51.031] iteration 1250 : model1 loss : 0.105141 model2 loss : 0.128025
[20:23:51.780] iteration 1251 : model1 loss : 0.095426 model2 loss : 0.075741
[20:23:52.474] iteration 1252 : model1 loss : 0.062860 model2 loss : 0.086780
[20:23:53.168] iteration 1253 : model1 loss : 0.051701 model2 loss : 0.086981
[20:23:53.843] iteration 1254 : model1 loss : 0.066436 model2 loss : 0.058475
[20:23:54.529] iteration 1255 : model1 loss : 0.066837 model2 loss : 0.073462
[20:23:55.219] iteration 1256 : model1 loss : 0.056202 model2 loss : 0.055014
[20:23:55.901] iteration 1257 : model1 loss : 0.054068 model2 loss : 0.051051
[20:23:56.582] iteration 1258 : model1 loss : 0.043941 model2 loss : 0.053615
[20:23:57.299] iteration 1259 : model1 loss : 0.066436 model2 loss : 0.057980
[20:23:57.992] iteration 1260 : model1 loss : 0.052075 model2 loss : 0.057074
[20:23:58.679] iteration 1261 : model1 loss : 0.096171 model2 loss : 0.113727
[20:23:59.355] iteration 1262 : model1 loss : 0.074085 model2 loss : 0.103227
[20:24:00.021] iteration 1263 : model1 loss : 0.065457 model2 loss : 0.083466
[20:24:00.696] iteration 1264 : model1 loss : 0.064861 model2 loss : 0.097427
[20:24:01.396] iteration 1265 : model1 loss : 0.130647 model2 loss : 0.137734
[20:24:02.073] iteration 1266 : model1 loss : 0.066927 model2 loss : 0.063556
[20:24:02.781] iteration 1267 : model1 loss : 0.074400 model2 loss : 0.063688
[20:24:03.468] iteration 1268 : model1 loss : 0.062691 model2 loss : 0.086775
[20:24:04.165] iteration 1269 : model1 loss : 0.056198 model2 loss : 0.094658
[20:24:04.876] iteration 1270 : model1 loss : 0.091841 model2 loss : 0.091093
[20:24:05.573] iteration 1271 : model1 loss : 0.209942 model2 loss : 0.259813
[20:24:06.347] iteration 1272 : model1 loss : 0.057046 model2 loss : 0.048742
[20:24:07.029] iteration 1273 : model1 loss : 0.047976 model2 loss : 0.045213
[20:24:07.707] iteration 1274 : model1 loss : 0.088405 model2 loss : 0.074280
[20:24:08.462] iteration 1275 : model1 loss : 0.088600 model2 loss : 0.104404
[20:24:09.307] iteration 1276 : model1 loss : 0.185779 model2 loss : 0.109316
[20:24:10.142] iteration 1277 : model1 loss : 0.073492 model2 loss : 0.065556
[20:24:10.963] iteration 1278 : model1 loss : 0.052992 model2 loss : 0.046361
[20:24:11.769] iteration 1279 : model1 loss : 0.186650 model2 loss : 0.143925
[20:24:12.605] iteration 1280 : model1 loss : 0.178478 model2 loss : 0.176672
[20:24:13.405] iteration 1281 : model1 loss : 0.084856 model2 loss : 0.049863
[20:24:14.233] iteration 1282 : model1 loss : 0.089360 model2 loss : 0.063274
[20:24:14.955] iteration 1283 : model1 loss : 0.094758 model2 loss : 0.062640
[20:24:15.660] iteration 1284 : model1 loss : 0.053675 model2 loss : 0.051337
[20:24:16.473] iteration 1285 : model1 loss : 0.103668 model2 loss : 0.100386
[20:24:17.192] iteration 1286 : model1 loss : 0.060787 model2 loss : 0.052727
[20:24:17.864] iteration 1287 : model1 loss : 0.066389 model2 loss : 0.060976
[20:24:18.560] iteration 1288 : model1 loss : 0.057961 model2 loss : 0.044352
[20:24:19.242] iteration 1289 : model1 loss : 0.062548 model2 loss : 0.052020
[20:24:19.921] iteration 1290 : model1 loss : 0.162186 model2 loss : 0.174151
[20:24:20.600] iteration 1291 : model1 loss : 0.132199 model2 loss : 0.117907
[20:24:21.287] iteration 1292 : model1 loss : 0.086031 model2 loss : 0.107386
[20:24:22.004] iteration 1293 : model1 loss : 0.055860 model2 loss : 0.059077
[20:24:22.682] iteration 1294 : model1 loss : 0.130325 model2 loss : 0.147459
[20:24:23.379] iteration 1295 : model1 loss : 0.076680 model2 loss : 0.042436
[20:24:24.053] iteration 1296 : model1 loss : 0.110572 model2 loss : 0.140806
[20:24:24.717] iteration 1297 : model1 loss : 0.076364 model2 loss : 0.070423
[20:24:25.397] iteration 1298 : model1 loss : 0.062615 model2 loss : 0.061574
[20:24:26.068] iteration 1299 : model1 loss : 0.127229 model2 loss : 0.153748
[20:24:26.743] iteration 1300 : model1 loss : 0.049978 model2 loss : 0.054739
[20:24:27.443] iteration 1301 : model1 loss : 0.061099 model2 loss : 0.047985
[20:24:28.117] iteration 1302 : model1 loss : 0.106528 model2 loss : 0.077700
[20:24:28.810] iteration 1303 : model1 loss : 0.273812 model2 loss : 0.225685
[20:24:29.476] iteration 1304 : model1 loss : 0.071995 model2 loss : 0.061746
[20:24:30.159] iteration 1305 : model1 loss : 0.056589 model2 loss : 0.059132
[20:24:30.850] iteration 1306 : model1 loss : 0.057185 model2 loss : 0.049327
[20:24:31.527] iteration 1307 : model1 loss : 0.095441 model2 loss : 0.077732
[20:24:32.194] iteration 1308 : model1 loss : 0.045099 model2 loss : 0.043534
[20:24:32.894] iteration 1309 : model1 loss : 0.070196 model2 loss : 0.050157
[20:24:33.573] iteration 1310 : model1 loss : 0.069817 model2 loss : 0.086537
[20:24:34.243] iteration 1311 : model1 loss : 0.054868 model2 loss : 0.047346
[20:24:34.921] iteration 1312 : model1 loss : 0.071572 model2 loss : 0.063763
[20:24:35.609] iteration 1313 : model1 loss : 0.093750 model2 loss : 0.092363
[20:24:36.290] iteration 1314 : model1 loss : 0.060654 model2 loss : 0.055845
[20:24:36.957] iteration 1315 : model1 loss : 0.075223 model2 loss : 0.059760
[20:24:37.640] iteration 1316 : model1 loss : 0.060286 model2 loss : 0.056764
[20:24:38.317] iteration 1317 : model1 loss : 0.060414 model2 loss : 0.042372
[20:24:38.990] iteration 1318 : model1 loss : 0.201398 model2 loss : 0.133428
[20:24:39.676] iteration 1319 : model1 loss : 0.038488 model2 loss : 0.042594
[20:24:40.346] iteration 1320 : model1 loss : 0.100133 model2 loss : 0.104266
[20:24:41.021] iteration 1321 : model1 loss : 0.097392 model2 loss : 0.064163
[20:24:41.684] iteration 1322 : model1 loss : 0.031142 model2 loss : 0.045224
[20:24:42.355] iteration 1323 : model1 loss : 0.071578 model2 loss : 0.055613
[20:24:43.037] iteration 1324 : model1 loss : 0.047930 model2 loss : 0.046485
[20:24:43.724] iteration 1325 : model1 loss : 0.054097 model2 loss : 0.069608
[20:24:44.382] iteration 1326 : model1 loss : 0.134651 model2 loss : 0.118623
[20:24:45.053] iteration 1327 : model1 loss : 0.157511 model2 loss : 0.181690
[20:24:45.728] iteration 1328 : model1 loss : 0.051718 model2 loss : 0.039062
[20:24:46.401] iteration 1329 : model1 loss : 0.053122 model2 loss : 0.055942
[20:24:47.074] iteration 1330 : model1 loss : 0.048927 model2 loss : 0.070727
[20:24:47.745] iteration 1331 : model1 loss : 0.052913 model2 loss : 0.055446
[20:24:48.420] iteration 1332 : model1 loss : 0.044075 model2 loss : 0.046548
[20:24:49.089] iteration 1333 : model1 loss : 0.096209 model2 loss : 0.047140
[20:24:49.769] iteration 1334 : model1 loss : 0.096123 model2 loss : 0.083617
[20:24:50.445] iteration 1335 : model1 loss : 0.098235 model2 loss : 0.099077
[20:24:51.102] iteration 1336 : model1 loss : 0.050431 model2 loss : 0.064841
[20:24:51.771] iteration 1337 : model1 loss : 0.049274 model2 loss : 0.050726
[20:24:52.447] iteration 1338 : model1 loss : 0.074255 model2 loss : 0.067658
[20:24:53.120] iteration 1339 : model1 loss : 0.040634 model2 loss : 0.047991
[20:24:53.777] iteration 1340 : model1 loss : 0.103736 model2 loss : 0.059242
[20:24:54.451] iteration 1341 : model1 loss : 0.044392 model2 loss : 0.047266
[20:24:55.117] iteration 1342 : model1 loss : 0.160799 model2 loss : 0.118110
[20:24:55.798] iteration 1343 : model1 loss : 0.241656 model2 loss : 0.246604
[20:24:56.492] iteration 1344 : model1 loss : 0.103747 model2 loss : 0.094902
[20:24:57.164] iteration 1345 : model1 loss : 0.066319 model2 loss : 0.066896
[20:24:57.844] iteration 1346 : model1 loss : 0.106829 model2 loss : 0.088597
[20:24:58.533] iteration 1347 : model1 loss : 0.046602 model2 loss : 0.042371
[20:24:59.208] iteration 1348 : model1 loss : 0.046568 model2 loss : 0.048867
[20:24:59.885] iteration 1349 : model1 loss : 0.060728 model2 loss : 0.070181
[20:25:00.586] iteration 1350 : model1 loss : 0.050465 model2 loss : 0.056014
[20:25:01.348] iteration 1351 : model1 loss : 0.169169 model2 loss : 0.172869
[20:25:02.054] iteration 1352 : model1 loss : 0.104938 model2 loss : 0.082142
[20:25:02.749] iteration 1353 : model1 loss : 0.063754 model2 loss : 0.053711
[20:25:03.462] iteration 1354 : model1 loss : 0.113774 model2 loss : 0.120255
[20:25:04.179] iteration 1355 : model1 loss : 0.051427 model2 loss : 0.046522
[20:25:04.910] iteration 1356 : model1 loss : 0.056292 model2 loss : 0.083713
[20:25:05.599] iteration 1357 : model1 loss : 0.179349 model2 loss : 0.159906
[20:25:06.307] iteration 1358 : model1 loss : 0.033647 model2 loss : 0.038087
[20:25:07.021] iteration 1359 : model1 loss : 0.040728 model2 loss : 0.049225
[20:25:07.708] iteration 1360 : model1 loss : 0.068325 model2 loss : 0.075624
[20:25:08.415] iteration 1361 : model1 loss : 0.047463 model2 loss : 0.051597
[20:25:09.094] iteration 1362 : model1 loss : 0.074869 model2 loss : 0.072551
[20:25:09.776] iteration 1363 : model1 loss : 0.064746 model2 loss : 0.048499
[20:25:10.461] iteration 1364 : model1 loss : 0.049502 model2 loss : 0.053301
[20:25:11.163] iteration 1365 : model1 loss : 0.056928 model2 loss : 0.054858
[20:25:11.852] iteration 1366 : model1 loss : 0.076808 model2 loss : 0.055390
[20:25:12.553] iteration 1367 : model1 loss : 0.040115 model2 loss : 0.039630
[20:25:13.246] iteration 1368 : model1 loss : 0.068997 model2 loss : 0.064006
[20:25:13.938] iteration 1369 : model1 loss : 0.043349 model2 loss : 0.063421
[20:25:14.632] iteration 1370 : model1 loss : 0.048717 model2 loss : 0.051013
[20:25:15.318] iteration 1371 : model1 loss : 0.066511 model2 loss : 0.097137
[20:25:16.013] iteration 1372 : model1 loss : 0.056216 model2 loss : 0.054770
[20:25:16.713] iteration 1373 : model1 loss : 0.034256 model2 loss : 0.045032
[20:25:17.387] iteration 1374 : model1 loss : 0.050125 model2 loss : 0.044950
[20:25:18.062] iteration 1375 : model1 loss : 0.044440 model2 loss : 0.084390
[20:25:18.745] iteration 1376 : model1 loss : 0.133292 model2 loss : 0.105363
[20:25:19.452] iteration 1377 : model1 loss : 0.048796 model2 loss : 0.050590
[20:25:20.128] iteration 1378 : model1 loss : 0.088853 model2 loss : 0.070415
[20:25:20.830] iteration 1379 : model1 loss : 0.052968 model2 loss : 0.058733
[20:25:21.516] iteration 1380 : model1 loss : 0.298323 model2 loss : 0.286669
[20:25:22.215] iteration 1381 : model1 loss : 0.062287 model2 loss : 0.059708
[20:25:22.918] iteration 1382 : model1 loss : 0.067441 model2 loss : 0.094041
[20:25:23.622] iteration 1383 : model1 loss : 0.073301 model2 loss : 0.091342
[20:25:24.323] iteration 1384 : model1 loss : 0.052890 model2 loss : 0.063956
[20:25:25.028] iteration 1385 : model1 loss : 0.043440 model2 loss : 0.046615
[20:25:25.695] iteration 1386 : model1 loss : 0.046776 model2 loss : 0.044834
[20:25:26.368] iteration 1387 : model1 loss : 0.037471 model2 loss : 0.033493
[20:25:27.048] iteration 1388 : model1 loss : 0.066089 model2 loss : 0.094842
[20:25:27.715] iteration 1389 : model1 loss : 0.090372 model2 loss : 0.085240
[20:25:28.393] iteration 1390 : model1 loss : 0.076280 model2 loss : 0.080873
[20:25:29.067] iteration 1391 : model1 loss : 0.061776 model2 loss : 0.076306
[20:25:29.753] iteration 1392 : model1 loss : 0.055026 model2 loss : 0.056913
[20:25:30.430] iteration 1393 : model1 loss : 0.064900 model2 loss : 0.058809
[20:25:31.098] iteration 1394 : model1 loss : 0.169619 model2 loss : 0.169578
[20:25:31.760] iteration 1395 : model1 loss : 0.077942 model2 loss : 0.055364
[20:25:32.428] iteration 1396 : model1 loss : 0.123328 model2 loss : 0.078990
[20:25:33.116] iteration 1397 : model1 loss : 0.057391 model2 loss : 0.056592
[20:25:33.791] iteration 1398 : model1 loss : 0.056350 model2 loss : 0.060135
[20:25:34.459] iteration 1399 : model1 loss : 0.072512 model2 loss : 0.060566
[20:25:35.147] iteration 1400 : model1 loss : 0.047173 model2 loss : 0.051242
[20:25:54.094] iteration 1400 : model1_mean_dice : 0.763890 model1_mean_hd95 : 3.575360
[20:26:13.033] iteration 1400 : model2_mean_dice : 0.742190 model2_mean_hd95 : 17.011200
[20:26:13.730] iteration 1401 : model1 loss : 0.048587 model2 loss : 0.042810
[20:26:14.408] iteration 1402 : model1 loss : 0.053696 model2 loss : 0.049600
[20:26:15.073] iteration 1403 : model1 loss : 0.056419 model2 loss : 0.056758
[20:26:15.743] iteration 1404 : model1 loss : 0.051623 model2 loss : 0.050163
[20:26:16.409] iteration 1405 : model1 loss : 0.070223 model2 loss : 0.088301
[20:26:17.067] iteration 1406 : model1 loss : 0.059287 model2 loss : 0.053012
[20:26:17.739] iteration 1407 : model1 loss : 0.130443 model2 loss : 0.088613
[20:26:18.408] iteration 1408 : model1 loss : 0.051659 model2 loss : 0.045607
[20:26:19.072] iteration 1409 : model1 loss : 0.063770 model2 loss : 0.076202
[20:26:19.749] iteration 1410 : model1 loss : 0.049410 model2 loss : 0.050455
[20:26:20.425] iteration 1411 : model1 loss : 0.089767 model2 loss : 0.076480
[20:26:21.139] iteration 1412 : model1 loss : 0.042995 model2 loss : 0.036382
[20:26:21.826] iteration 1413 : model1 loss : 0.065580 model2 loss : 0.068965
[20:26:22.493] iteration 1414 : model1 loss : 0.067590 model2 loss : 0.069040
[20:26:23.168] iteration 1415 : model1 loss : 0.088714 model2 loss : 0.065590
[20:26:23.840] iteration 1416 : model1 loss : 0.078494 model2 loss : 0.059655
[20:26:24.518] iteration 1417 : model1 loss : 0.059006 model2 loss : 0.061708
[20:26:25.197] iteration 1418 : model1 loss : 0.057295 model2 loss : 0.065946
[20:26:25.864] iteration 1419 : model1 loss : 0.058773 model2 loss : 0.062673
[20:26:26.533] iteration 1420 : model1 loss : 0.055218 model2 loss : 0.050257
[20:26:27.198] iteration 1421 : model1 loss : 0.077836 model2 loss : 0.058584
[20:26:27.872] iteration 1422 : model1 loss : 0.033290 model2 loss : 0.038672
[20:26:28.551] iteration 1423 : model1 loss : 0.114620 model2 loss : 0.100965
[20:26:29.223] iteration 1424 : model1 loss : 0.107125 model2 loss : 0.161082
[20:26:29.883] iteration 1425 : model1 loss : 0.065043 model2 loss : 0.060516
[20:26:30.565] iteration 1426 : model1 loss : 0.080164 model2 loss : 0.082437
[20:26:31.225] iteration 1427 : model1 loss : 0.104376 model2 loss : 0.074647
[20:26:31.886] iteration 1428 : model1 loss : 0.037630 model2 loss : 0.038493
[20:26:32.612] iteration 1429 : model1 loss : 0.059821 model2 loss : 0.062461
[20:26:33.279] iteration 1430 : model1 loss : 0.058780 model2 loss : 0.069465
[20:26:33.945] iteration 1431 : model1 loss : 0.059010 model2 loss : 0.051828
[20:26:34.605] iteration 1432 : model1 loss : 0.066558 model2 loss : 0.076775
[20:26:35.269] iteration 1433 : model1 loss : 0.072056 model2 loss : 0.104018
[20:26:35.938] iteration 1434 : model1 loss : 0.055301 model2 loss : 0.058739
[20:26:36.598] iteration 1435 : model1 loss : 0.042221 model2 loss : 0.044275
[20:26:37.269] iteration 1436 : model1 loss : 0.075375 model2 loss : 0.085867
[20:26:37.959] iteration 1437 : model1 loss : 0.200438 model2 loss : 0.205596
[20:26:38.633] iteration 1438 : model1 loss : 0.063448 model2 loss : 0.072205
[20:26:39.299] iteration 1439 : model1 loss : 0.054456 model2 loss : 0.053733
[20:26:39.986] iteration 1440 : model1 loss : 0.034361 model2 loss : 0.031174
[20:26:40.676] iteration 1441 : model1 loss : 0.052270 model2 loss : 0.068753
[20:26:41.363] iteration 1442 : model1 loss : 0.178821 model2 loss : 0.086145
[20:26:42.043] iteration 1443 : model1 loss : 0.181727 model2 loss : 0.174159
[20:26:42.755] iteration 1444 : model1 loss : 0.117244 model2 loss : 0.118772
[20:26:43.449] iteration 1445 : model1 loss : 0.080635 model2 loss : 0.093535
[20:26:44.116] iteration 1446 : model1 loss : 0.077885 model2 loss : 0.057551
[20:26:44.820] iteration 1447 : model1 loss : 0.041763 model2 loss : 0.046440
[20:26:45.510] iteration 1448 : model1 loss : 0.069587 model2 loss : 0.066301
[20:26:46.208] iteration 1449 : model1 loss : 0.050168 model2 loss : 0.053626
[20:26:46.892] iteration 1450 : model1 loss : 0.057760 model2 loss : 0.063088
[20:26:47.617] iteration 1451 : model1 loss : 0.060708 model2 loss : 0.046125
[20:26:48.299] iteration 1452 : model1 loss : 0.063942 model2 loss : 0.071103
[20:26:48.957] iteration 1453 : model1 loss : 0.083011 model2 loss : 0.097905
[20:26:49.636] iteration 1454 : model1 loss : 0.048619 model2 loss : 0.053076
[20:26:50.307] iteration 1455 : model1 loss : 0.045164 model2 loss : 0.034683
[20:26:50.976] iteration 1456 : model1 loss : 0.092516 model2 loss : 0.192744
[20:26:51.652] iteration 1457 : model1 loss : 0.048118 model2 loss : 0.047673
[20:26:52.334] iteration 1458 : model1 loss : 0.060318 model2 loss : 0.047966
[20:26:53.013] iteration 1459 : model1 loss : 0.061883 model2 loss : 0.055076
[20:26:53.677] iteration 1460 : model1 loss : 0.045619 model2 loss : 0.058576
[20:26:54.358] iteration 1461 : model1 loss : 0.087837 model2 loss : 0.068137
[20:26:55.040] iteration 1462 : model1 loss : 0.077033 model2 loss : 0.082455
[20:26:55.719] iteration 1463 : model1 loss : 0.068097 model2 loss : 0.086192
[20:26:56.395] iteration 1464 : model1 loss : 0.062361 model2 loss : 0.062297
[20:26:57.073] iteration 1465 : model1 loss : 0.045349 model2 loss : 0.045497
[20:26:57.749] iteration 1466 : model1 loss : 0.065708 model2 loss : 0.090055
[20:26:58.421] iteration 1467 : model1 loss : 0.095120 model2 loss : 0.112260
[20:26:59.086] iteration 1468 : model1 loss : 0.064971 model2 loss : 0.140440
[20:26:59.757] iteration 1469 : model1 loss : 0.123485 model2 loss : 0.144282
[20:27:00.441] iteration 1470 : model1 loss : 0.037308 model2 loss : 0.055544
[20:27:01.109] iteration 1471 : model1 loss : 0.064668 model2 loss : 0.055503
[20:27:01.789] iteration 1472 : model1 loss : 0.082596 model2 loss : 0.109822
[20:27:02.461] iteration 1473 : model1 loss : 0.069126 model2 loss : 0.107339
[20:27:03.117] iteration 1474 : model1 loss : 0.043928 model2 loss : 0.050210
[20:27:03.788] iteration 1475 : model1 loss : 0.045097 model2 loss : 0.058694
[20:27:04.478] iteration 1476 : model1 loss : 0.067613 model2 loss : 0.064564
[20:27:05.159] iteration 1477 : model1 loss : 0.074787 model2 loss : 0.063266
[20:27:05.832] iteration 1478 : model1 loss : 0.048696 model2 loss : 0.055931
[20:27:06.513] iteration 1479 : model1 loss : 0.093503 model2 loss : 0.069252
[20:27:07.194] iteration 1480 : model1 loss : 0.082191 model2 loss : 0.091324
[20:27:07.891] iteration 1481 : model1 loss : 0.060540 model2 loss : 0.073043
[20:27:08.567] iteration 1482 : model1 loss : 0.076092 model2 loss : 0.090806
[20:27:09.252] iteration 1483 : model1 loss : 0.055992 model2 loss : 0.053440
[20:27:09.946] iteration 1484 : model1 loss : 0.079105 model2 loss : 0.095459
[20:27:10.644] iteration 1485 : model1 loss : 0.084849 model2 loss : 0.135203
[20:27:11.363] iteration 1486 : model1 loss : 0.106977 model2 loss : 0.109166
[20:27:12.057] iteration 1487 : model1 loss : 0.059839 model2 loss : 0.049937
[20:27:12.775] iteration 1488 : model1 loss : 0.047367 model2 loss : 0.062840
[20:27:13.478] iteration 1489 : model1 loss : 0.049251 model2 loss : 0.054537
[20:27:14.198] iteration 1490 : model1 loss : 0.068040 model2 loss : 0.057555
[20:27:14.919] iteration 1491 : model1 loss : 0.050124 model2 loss : 0.063499
[20:27:15.615] iteration 1492 : model1 loss : 0.040448 model2 loss : 0.089702
[20:27:16.313] iteration 1493 : model1 loss : 0.057673 model2 loss : 0.066948
[20:27:17.029] iteration 1494 : model1 loss : 0.038959 model2 loss : 0.053246
[20:27:17.725] iteration 1495 : model1 loss : 0.061155 model2 loss : 0.071470
[20:27:18.435] iteration 1496 : model1 loss : 0.094833 model2 loss : 0.052649
[20:27:19.156] iteration 1497 : model1 loss : 0.051233 model2 loss : 0.041037
[20:27:19.840] iteration 1498 : model1 loss : 0.052598 model2 loss : 0.064500
[20:27:20.539] iteration 1499 : model1 loss : 0.054700 model2 loss : 0.072280
[20:27:21.243] iteration 1500 : model1 loss : 0.074070 model2 loss : 0.080470
[20:27:21.982] iteration 1501 : model1 loss : 0.095009 model2 loss : 0.089672
[20:27:22.709] iteration 1502 : model1 loss : 0.084521 model2 loss : 0.082636
[20:27:23.438] iteration 1503 : model1 loss : 0.068010 model2 loss : 0.063342
[20:27:24.161] iteration 1504 : model1 loss : 0.045771 model2 loss : 0.053253
[20:27:24.862] iteration 1505 : model1 loss : 0.066743 model2 loss : 0.115275
[20:27:25.623] iteration 1506 : model1 loss : 0.035916 model2 loss : 0.032263
[20:27:26.376] iteration 1507 : model1 loss : 0.050006 model2 loss : 0.048945
[20:27:27.089] iteration 1508 : model1 loss : 0.087541 model2 loss : 0.123663
[20:27:27.770] iteration 1509 : model1 loss : 0.047459 model2 loss : 0.051059
[20:27:28.463] iteration 1510 : model1 loss : 0.034704 model2 loss : 0.037988
[20:27:29.190] iteration 1511 : model1 loss : 0.106829 model2 loss : 0.124586
[20:27:29.885] iteration 1512 : model1 loss : 0.159043 model2 loss : 0.170602
[20:27:30.602] iteration 1513 : model1 loss : 0.126900 model2 loss : 0.121851
[20:27:31.326] iteration 1514 : model1 loss : 0.079904 model2 loss : 0.091733
[20:27:32.005] iteration 1515 : model1 loss : 0.260970 model2 loss : 0.335598
[20:27:32.746] iteration 1516 : model1 loss : 0.068620 model2 loss : 0.066703
[20:27:33.457] iteration 1517 : model1 loss : 0.077534 model2 loss : 0.091280
[20:27:34.166] iteration 1518 : model1 loss : 0.129094 model2 loss : 0.121943
[20:27:34.868] iteration 1519 : model1 loss : 0.076590 model2 loss : 0.052700
[20:27:35.559] iteration 1520 : model1 loss : 0.048054 model2 loss : 0.052681
[20:27:36.301] iteration 1521 : model1 loss : 0.056262 model2 loss : 0.050913
[20:27:36.998] iteration 1522 : model1 loss : 0.055850 model2 loss : 0.043277
[20:27:37.704] iteration 1523 : model1 loss : 0.052045 model2 loss : 0.052712
[20:27:38.423] iteration 1524 : model1 loss : 0.061374 model2 loss : 0.063140
[20:27:39.113] iteration 1525 : model1 loss : 0.051623 model2 loss : 0.068019
[20:27:39.796] iteration 1526 : model1 loss : 0.100360 model2 loss : 0.069210
[20:27:40.520] iteration 1527 : model1 loss : 0.122238 model2 loss : 0.160528
[20:27:41.219] iteration 1528 : model1 loss : 0.044092 model2 loss : 0.045826
[20:27:41.915] iteration 1529 : model1 loss : 0.073158 model2 loss : 0.084717
[20:27:42.689] iteration 1530 : model1 loss : 0.225157 model2 loss : 0.211453
[20:27:43.400] iteration 1531 : model1 loss : 0.067921 model2 loss : 0.049002
[20:27:44.077] iteration 1532 : model1 loss : 0.062457 model2 loss : 0.048887
[20:27:44.750] iteration 1533 : model1 loss : 0.136021 model2 loss : 0.146588
[20:27:45.428] iteration 1534 : model1 loss : 0.078447 model2 loss : 0.047076
[20:27:46.117] iteration 1535 : model1 loss : 0.094175 model2 loss : 0.074201
[20:27:46.780] iteration 1536 : model1 loss : 0.069695 model2 loss : 0.052082
[20:27:47.442] iteration 1537 : model1 loss : 0.060177 model2 loss : 0.062307
[20:27:48.120] iteration 1538 : model1 loss : 0.064788 model2 loss : 0.059242
[20:27:48.798] iteration 1539 : model1 loss : 0.056966 model2 loss : 0.056291
[20:27:49.477] iteration 1540 : model1 loss : 0.104549 model2 loss : 0.060465
[20:27:50.146] iteration 1541 : model1 loss : 0.063355 model2 loss : 0.051581
[20:27:50.823] iteration 1542 : model1 loss : 0.107814 model2 loss : 0.086753
[20:27:51.493] iteration 1543 : model1 loss : 0.041398 model2 loss : 0.047515
[20:27:52.158] iteration 1544 : model1 loss : 0.236977 model2 loss : 0.187903
[20:27:52.838] iteration 1545 : model1 loss : 0.134037 model2 loss : 0.122643
[20:27:53.503] iteration 1546 : model1 loss : 0.082458 model2 loss : 0.087721
[20:27:54.173] iteration 1547 : model1 loss : 0.141128 model2 loss : 0.118768
[20:27:54.864] iteration 1548 : model1 loss : 0.046864 model2 loss : 0.039586
[20:27:55.544] iteration 1549 : model1 loss : 0.059793 model2 loss : 0.039789
[20:27:56.207] iteration 1550 : model1 loss : 0.064350 model2 loss : 0.070905
[20:27:56.911] iteration 1551 : model1 loss : 0.107516 model2 loss : 0.151642
[20:27:57.584] iteration 1552 : model1 loss : 0.095564 model2 loss : 0.069128
[20:27:58.258] iteration 1553 : model1 loss : 0.087812 model2 loss : 0.092035
[20:27:58.930] iteration 1554 : model1 loss : 0.170855 model2 loss : 0.146085
[20:27:59.612] iteration 1555 : model1 loss : 0.052038 model2 loss : 0.041715
[20:28:00.286] iteration 1556 : model1 loss : 0.046950 model2 loss : 0.064332
[20:28:00.950] iteration 1557 : model1 loss : 0.141943 model2 loss : 0.090190
[20:28:01.623] iteration 1558 : model1 loss : 0.092065 model2 loss : 0.078699
[20:28:02.295] iteration 1559 : model1 loss : 0.042882 model2 loss : 0.039345
[20:28:02.955] iteration 1560 : model1 loss : 0.089934 model2 loss : 0.058771
[20:28:03.640] iteration 1561 : model1 loss : 0.057549 model2 loss : 0.039543
[20:28:04.311] iteration 1562 : model1 loss : 0.047332 model2 loss : 0.045879
[20:28:04.991] iteration 1563 : model1 loss : 0.086152 model2 loss : 0.070039
[20:28:05.651] iteration 1564 : model1 loss : 0.046306 model2 loss : 0.047474
[20:28:06.320] iteration 1565 : model1 loss : 0.059696 model2 loss : 0.063414
[20:28:06.996] iteration 1566 : model1 loss : 0.065361 model2 loss : 0.049897
[20:28:07.663] iteration 1567 : model1 loss : 0.082093 model2 loss : 0.074071
[20:28:08.375] iteration 1568 : model1 loss : 0.120155 model2 loss : 0.141656
[20:28:09.056] iteration 1569 : model1 loss : 0.037397 model2 loss : 0.046705
[20:28:09.741] iteration 1570 : model1 loss : 0.121571 model2 loss : 0.098729
[20:28:10.427] iteration 1571 : model1 loss : 0.087641 model2 loss : 0.096932
[20:28:11.108] iteration 1572 : model1 loss : 0.044914 model2 loss : 0.077107
[20:28:11.779] iteration 1573 : model1 loss : 0.076959 model2 loss : 0.076837
[20:28:12.470] iteration 1574 : model1 loss : 0.095042 model2 loss : 0.091729
[20:28:13.149] iteration 1575 : model1 loss : 0.124284 model2 loss : 0.110392
[20:28:13.838] iteration 1576 : model1 loss : 0.056533 model2 loss : 0.055872
[20:28:14.513] iteration 1577 : model1 loss : 0.056277 model2 loss : 0.066063
[20:28:15.189] iteration 1578 : model1 loss : 0.051508 model2 loss : 0.049796
[20:28:15.860] iteration 1579 : model1 loss : 0.056400 model2 loss : 0.052927
[20:28:16.556] iteration 1580 : model1 loss : 0.051688 model2 loss : 0.047789
[20:28:17.229] iteration 1581 : model1 loss : 0.050082 model2 loss : 0.062068
[20:28:17.898] iteration 1582 : model1 loss : 0.041278 model2 loss : 0.045103
[20:28:18.581] iteration 1583 : model1 loss : 0.034916 model2 loss : 0.033344
[20:28:19.268] iteration 1584 : model1 loss : 0.074466 model2 loss : 0.077791
[20:28:19.933] iteration 1585 : model1 loss : 0.106746 model2 loss : 0.137291
[20:28:20.619] iteration 1586 : model1 loss : 0.059242 model2 loss : 0.058569
[20:28:21.300] iteration 1587 : model1 loss : 0.240217 model2 loss : 0.210751
[20:28:21.962] iteration 1588 : model1 loss : 0.160543 model2 loss : 0.144775
[20:28:22.650] iteration 1589 : model1 loss : 0.036240 model2 loss : 0.037154
[20:28:23.320] iteration 1590 : model1 loss : 0.078081 model2 loss : 0.059932
[20:28:23.996] iteration 1591 : model1 loss : 0.083011 model2 loss : 0.082047
[20:28:24.664] iteration 1592 : model1 loss : 0.092301 model2 loss : 0.090029
[20:28:25.341] iteration 1593 : model1 loss : 0.039810 model2 loss : 0.042861
[20:28:26.016] iteration 1594 : model1 loss : 0.064685 model2 loss : 0.070386
[20:28:26.677] iteration 1595 : model1 loss : 0.176806 model2 loss : 0.173196
[20:28:27.352] iteration 1596 : model1 loss : 0.057641 model2 loss : 0.051881
[20:28:28.037] iteration 1597 : model1 loss : 0.063526 model2 loss : 0.073183
[20:28:28.722] iteration 1598 : model1 loss : 0.053909 model2 loss : 0.058417
[20:28:29.406] iteration 1599 : model1 loss : 0.049154 model2 loss : 0.069800
[20:28:30.080] iteration 1600 : model1 loss : 0.033417 model2 loss : 0.036579
[20:28:49.001] iteration 1600 : model1_mean_dice : 0.786772 model1_mean_hd95 : 5.705706
[20:29:08.094] iteration 1600 : model2_mean_dice : 0.750212 model2_mean_hd95 : 11.036526
[20:29:08.838] iteration 1601 : model1 loss : 0.044556 model2 loss : 0.037359
[20:29:09.520] iteration 1602 : model1 loss : 0.039609 model2 loss : 0.038480
[20:29:10.200] iteration 1603 : model1 loss : 0.031181 model2 loss : 0.034986
[20:29:10.869] iteration 1604 : model1 loss : 0.045410 model2 loss : 0.043823
[20:29:11.552] iteration 1605 : model1 loss : 0.033618 model2 loss : 0.035888
[20:29:12.223] iteration 1606 : model1 loss : 0.044986 model2 loss : 0.052858
[20:29:12.894] iteration 1607 : model1 loss : 0.037446 model2 loss : 0.044503
[20:29:13.574] iteration 1608 : model1 loss : 0.058583 model2 loss : 0.063941
[20:29:14.260] iteration 1609 : model1 loss : 0.039030 model2 loss : 0.042217
[20:29:14.930] iteration 1610 : model1 loss : 0.071607 model2 loss : 0.051199
[20:29:15.615] iteration 1611 : model1 loss : 0.056404 model2 loss : 0.046947
[20:29:16.295] iteration 1612 : model1 loss : 0.050642 model2 loss : 0.059514
[20:29:16.962] iteration 1613 : model1 loss : 0.027101 model2 loss : 0.027105
[20:29:17.635] iteration 1614 : model1 loss : 0.054366 model2 loss : 0.038526
[20:29:18.305] iteration 1615 : model1 loss : 0.057512 model2 loss : 0.052760
[20:29:18.984] iteration 1616 : model1 loss : 0.053026 model2 loss : 0.049703
[20:29:19.667] iteration 1617 : model1 loss : 0.098203 model2 loss : 0.101068
[20:29:20.337] iteration 1618 : model1 loss : 0.071129 model2 loss : 0.060127
[20:29:21.017] iteration 1619 : model1 loss : 0.036527 model2 loss : 0.043615
[20:29:21.689] iteration 1620 : model1 loss : 0.039148 model2 loss : 0.037063
[20:29:22.359] iteration 1621 : model1 loss : 0.040643 model2 loss : 0.041379
[20:29:23.027] iteration 1622 : model1 loss : 0.064025 model2 loss : 0.071299
[20:29:23.708] iteration 1623 : model1 loss : 0.071672 model2 loss : 0.076578
[20:29:24.383] iteration 1624 : model1 loss : 0.158434 model2 loss : 0.104519
[20:29:25.054] iteration 1625 : model1 loss : 0.087565 model2 loss : 0.058449
[20:29:25.727] iteration 1626 : model1 loss : 0.175862 model2 loss : 0.186209
[20:29:26.406] iteration 1627 : model1 loss : 0.052622 model2 loss : 0.047422
[20:29:27.075] iteration 1628 : model1 loss : 0.061799 model2 loss : 0.078752
[20:29:27.740] iteration 1629 : model1 loss : 0.045041 model2 loss : 0.043222
[20:29:28.406] iteration 1630 : model1 loss : 0.066789 model2 loss : 0.077084
[20:29:29.088] iteration 1631 : model1 loss : 0.064947 model2 loss : 0.043667
[20:29:29.753] iteration 1632 : model1 loss : 0.112573 model2 loss : 0.076811
[20:29:30.415] iteration 1633 : model1 loss : 0.045200 model2 loss : 0.046948
[20:29:31.085] iteration 1634 : model1 loss : 0.092297 model2 loss : 0.108997
[20:29:31.755] iteration 1635 : model1 loss : 0.060212 model2 loss : 0.060890
[20:29:32.429] iteration 1636 : model1 loss : 0.093974 model2 loss : 0.057003
[20:29:33.101] iteration 1637 : model1 loss : 0.036935 model2 loss : 0.031373
[20:29:33.776] iteration 1638 : model1 loss : 0.061781 model2 loss : 0.060381
[20:29:34.457] iteration 1639 : model1 loss : 0.061445 model2 loss : 0.045389
[20:29:35.135] iteration 1640 : model1 loss : 0.045569 model2 loss : 0.038511
[20:29:35.805] iteration 1641 : model1 loss : 0.195146 model2 loss : 0.158466
[20:29:36.483] iteration 1642 : model1 loss : 0.105319 model2 loss : 0.071711
[20:29:37.149] iteration 1643 : model1 loss : 0.062473 model2 loss : 0.041542
[20:29:37.832] iteration 1644 : model1 loss : 0.079869 model2 loss : 0.077261
[20:29:38.502] iteration 1645 : model1 loss : 0.043899 model2 loss : 0.045998
[20:29:39.172] iteration 1646 : model1 loss : 0.053931 model2 loss : 0.051119
[20:29:39.847] iteration 1647 : model1 loss : 0.046692 model2 loss : 0.036393
[20:29:40.521] iteration 1648 : model1 loss : 0.055120 model2 loss : 0.052761
[20:29:41.205] iteration 1649 : model1 loss : 0.042586 model2 loss : 0.043324
[20:29:41.876] iteration 1650 : model1 loss : 0.087882 model2 loss : 0.071277
[20:29:42.602] iteration 1651 : model1 loss : 0.048287 model2 loss : 0.042545
[20:29:43.283] iteration 1652 : model1 loss : 0.078325 model2 loss : 0.091290
[20:29:43.944] iteration 1653 : model1 loss : 0.071860 model2 loss : 0.063008
[20:29:44.631] iteration 1654 : model1 loss : 0.082636 model2 loss : 0.103515
[20:29:45.309] iteration 1655 : model1 loss : 0.060852 model2 loss : 0.054268
[20:29:45.975] iteration 1656 : model1 loss : 0.034973 model2 loss : 0.040146
[20:29:46.644] iteration 1657 : model1 loss : 0.069131 model2 loss : 0.048471
[20:29:47.315] iteration 1658 : model1 loss : 0.053538 model2 loss : 0.044798
[20:29:48.004] iteration 1659 : model1 loss : 0.047456 model2 loss : 0.048830
[20:29:48.669] iteration 1660 : model1 loss : 0.098747 model2 loss : 0.130307
[20:29:49.348] iteration 1661 : model1 loss : 0.044995 model2 loss : 0.038756
[20:29:50.035] iteration 1662 : model1 loss : 0.084840 model2 loss : 0.189435
[20:29:50.710] iteration 1663 : model1 loss : 0.058654 model2 loss : 0.037434
[20:29:51.379] iteration 1664 : model1 loss : 0.042790 model2 loss : 0.043438
[20:29:52.055] iteration 1665 : model1 loss : 0.084626 model2 loss : 0.084441
[20:29:52.741] iteration 1666 : model1 loss : 0.074108 model2 loss : 0.090707
[20:29:53.426] iteration 1667 : model1 loss : 0.039070 model2 loss : 0.047201
[20:29:54.104] iteration 1668 : model1 loss : 0.063031 model2 loss : 0.068149
[20:29:54.780] iteration 1669 : model1 loss : 0.077626 model2 loss : 0.073696
[20:29:55.464] iteration 1670 : model1 loss : 0.149073 model2 loss : 0.184522
[20:29:56.148] iteration 1671 : model1 loss : 0.037105 model2 loss : 0.056419
[20:29:56.827] iteration 1672 : model1 loss : 0.169487 model2 loss : 0.182675
[20:29:57.492] iteration 1673 : model1 loss : 0.055956 model2 loss : 0.105154
[20:29:58.162] iteration 1674 : model1 loss : 0.062944 model2 loss : 0.060365
[20:29:58.841] iteration 1675 : model1 loss : 0.046886 model2 loss : 0.049172
[20:29:59.523] iteration 1676 : model1 loss : 0.060831 model2 loss : 0.065965
[20:30:00.198] iteration 1677 : model1 loss : 0.183027 model2 loss : 0.172761
[20:30:00.872] iteration 1678 : model1 loss : 0.048149 model2 loss : 0.127402
[20:30:01.561] iteration 1679 : model1 loss : 0.052622 model2 loss : 0.077351
[20:30:02.243] iteration 1680 : model1 loss : 0.040248 model2 loss : 0.049142
[20:30:02.908] iteration 1681 : model1 loss : 0.057409 model2 loss : 0.080184
[20:30:03.601] iteration 1682 : model1 loss : 0.037485 model2 loss : 0.077956
[20:30:04.289] iteration 1683 : model1 loss : 0.082953 model2 loss : 0.120593
[20:30:04.973] iteration 1684 : model1 loss : 0.081220 model2 loss : 0.065750
[20:30:05.700] iteration 1685 : model1 loss : 0.113838 model2 loss : 0.097001
[20:30:06.420] iteration 1686 : model1 loss : 0.088245 model2 loss : 0.087354
[20:30:07.103] iteration 1687 : model1 loss : 0.036531 model2 loss : 0.039788
[20:30:07.783] iteration 1688 : model1 loss : 0.048928 model2 loss : 0.053390
[20:30:08.452] iteration 1689 : model1 loss : 0.070407 model2 loss : 0.096489
[20:30:09.170] iteration 1690 : model1 loss : 0.064350 model2 loss : 0.057160
[20:30:09.847] iteration 1691 : model1 loss : 0.025249 model2 loss : 0.034404
[20:30:10.523] iteration 1692 : model1 loss : 0.042749 model2 loss : 0.059106
[20:30:11.205] iteration 1693 : model1 loss : 0.039098 model2 loss : 0.052619
[20:30:11.890] iteration 1694 : model1 loss : 0.041057 model2 loss : 0.050496
[20:30:12.577] iteration 1695 : model1 loss : 0.046258 model2 loss : 0.047679
[20:30:13.261] iteration 1696 : model1 loss : 0.082877 model2 loss : 0.068026
[20:30:13.941] iteration 1697 : model1 loss : 0.059684 model2 loss : 0.045857
[20:30:14.651] iteration 1698 : model1 loss : 0.040360 model2 loss : 0.041807
[20:30:15.328] iteration 1699 : model1 loss : 0.112665 model2 loss : 0.100483
[20:30:16.002] iteration 1700 : model1 loss : 0.040193 model2 loss : 0.036258
[20:30:16.714] iteration 1701 : model1 loss : 0.105723 model2 loss : 0.110276
[20:30:17.397] iteration 1702 : model1 loss : 0.106833 model2 loss : 0.082058
[20:30:18.065] iteration 1703 : model1 loss : 0.110796 model2 loss : 0.128033
[20:30:18.750] iteration 1704 : model1 loss : 0.053923 model2 loss : 0.084226
[20:30:19.425] iteration 1705 : model1 loss : 0.158290 model2 loss : 0.186754
[20:30:20.100] iteration 1706 : model1 loss : 0.061885 model2 loss : 0.043488
[20:30:20.781] iteration 1707 : model1 loss : 0.050342 model2 loss : 0.044068
[20:30:21.461] iteration 1708 : model1 loss : 0.050707 model2 loss : 0.044330
[20:30:22.119] iteration 1709 : model1 loss : 0.133543 model2 loss : 0.146679
[20:30:22.785] iteration 1710 : model1 loss : 0.115642 model2 loss : 0.072914
[20:30:23.458] iteration 1711 : model1 loss : 0.084320 model2 loss : 0.052494
[20:30:24.127] iteration 1712 : model1 loss : 0.176742 model2 loss : 0.166775
[20:30:24.791] iteration 1713 : model1 loss : 0.035538 model2 loss : 0.039700
[20:30:25.480] iteration 1714 : model1 loss : 0.043073 model2 loss : 0.055776
[20:30:26.148] iteration 1715 : model1 loss : 0.069159 model2 loss : 0.059218
[20:30:26.825] iteration 1716 : model1 loss : 0.056768 model2 loss : 0.052567
[20:30:27.503] iteration 1717 : model1 loss : 0.072777 model2 loss : 0.047884
[20:30:28.167] iteration 1718 : model1 loss : 0.046723 model2 loss : 0.044018
[20:30:28.853] iteration 1719 : model1 loss : 0.037105 model2 loss : 0.053660
[20:30:29.535] iteration 1720 : model1 loss : 0.064012 model2 loss : 0.072403
[20:30:30.209] iteration 1721 : model1 loss : 0.045046 model2 loss : 0.043238
[20:30:30.878] iteration 1722 : model1 loss : 0.185214 model2 loss : 0.149110
[20:30:31.558] iteration 1723 : model1 loss : 0.079893 model2 loss : 0.064730
[20:30:32.223] iteration 1724 : model1 loss : 0.075270 model2 loss : 0.074216
[20:30:32.894] iteration 1725 : model1 loss : 0.039095 model2 loss : 0.040983
[20:30:33.575] iteration 1726 : model1 loss : 0.063054 model2 loss : 0.068325
[20:30:34.237] iteration 1727 : model1 loss : 0.066190 model2 loss : 0.049787
[20:30:34.905] iteration 1728 : model1 loss : 0.083937 model2 loss : 0.074961
[20:30:35.586] iteration 1729 : model1 loss : 0.044900 model2 loss : 0.046757
[20:30:36.263] iteration 1730 : model1 loss : 0.043694 model2 loss : 0.049524
[20:30:36.928] iteration 1731 : model1 loss : 0.050950 model2 loss : 0.058699
[20:30:37.595] iteration 1732 : model1 loss : 0.034547 model2 loss : 0.036466
[20:30:38.265] iteration 1733 : model1 loss : 0.038948 model2 loss : 0.048019
[20:30:38.937] iteration 1734 : model1 loss : 0.059353 model2 loss : 0.061195
[20:30:39.609] iteration 1735 : model1 loss : 0.035954 model2 loss : 0.039852
[20:30:40.292] iteration 1736 : model1 loss : 0.180027 model2 loss : 0.103670
[20:30:40.991] iteration 1737 : model1 loss : 0.073277 model2 loss : 0.065920
[20:30:41.684] iteration 1738 : model1 loss : 0.051618 model2 loss : 0.053498
[20:30:42.383] iteration 1739 : model1 loss : 0.039239 model2 loss : 0.047497
[20:30:43.076] iteration 1740 : model1 loss : 0.048465 model2 loss : 0.058413
[20:30:43.744] iteration 1741 : model1 loss : 0.054828 model2 loss : 0.051520
[20:30:44.415] iteration 1742 : model1 loss : 0.048842 model2 loss : 0.053652
[20:30:45.087] iteration 1743 : model1 loss : 0.052835 model2 loss : 0.042241
[20:30:45.759] iteration 1744 : model1 loss : 0.070184 model2 loss : 0.065360
[20:30:46.440] iteration 1745 : model1 loss : 0.058781 model2 loss : 0.057513
[20:30:47.115] iteration 1746 : model1 loss : 0.042569 model2 loss : 0.057448
[20:30:47.783] iteration 1747 : model1 loss : 0.044284 model2 loss : 0.053988
[20:30:48.446] iteration 1748 : model1 loss : 0.049364 model2 loss : 0.044598
[20:30:49.101] iteration 1749 : model1 loss : 0.026527 model2 loss : 0.026334
[20:30:49.782] iteration 1750 : model1 loss : 0.138814 model2 loss : 0.119392
[20:30:50.494] iteration 1751 : model1 loss : 0.041177 model2 loss : 0.042323
[20:30:51.172] iteration 1752 : model1 loss : 0.066695 model2 loss : 0.046395
[20:30:51.844] iteration 1753 : model1 loss : 0.054880 model2 loss : 0.061397
[20:30:52.526] iteration 1754 : model1 loss : 0.072454 model2 loss : 0.067937
[20:30:53.214] iteration 1755 : model1 loss : 0.051996 model2 loss : 0.043428
[20:30:53.886] iteration 1756 : model1 loss : 0.062913 model2 loss : 0.049439
[20:30:54.559] iteration 1757 : model1 loss : 0.054467 model2 loss : 0.050045
[20:30:55.238] iteration 1758 : model1 loss : 0.058350 model2 loss : 0.075861
[20:30:55.900] iteration 1759 : model1 loss : 0.049496 model2 loss : 0.053392
[20:30:56.585] iteration 1760 : model1 loss : 0.058255 model2 loss : 0.042291
[20:30:57.263] iteration 1761 : model1 loss : 0.066925 model2 loss : 0.045146
[20:30:57.943] iteration 1762 : model1 loss : 0.093084 model2 loss : 0.107460
[20:30:58.622] iteration 1763 : model1 loss : 0.059433 model2 loss : 0.063908
[20:30:59.291] iteration 1764 : model1 loss : 0.038460 model2 loss : 0.043024
[20:30:59.966] iteration 1765 : model1 loss : 0.039289 model2 loss : 0.053731
[20:31:00.638] iteration 1766 : model1 loss : 0.064376 model2 loss : 0.059797
[20:31:01.308] iteration 1767 : model1 loss : 0.039399 model2 loss : 0.043345
[20:31:01.995] iteration 1768 : model1 loss : 0.057547 model2 loss : 0.044965
[20:31:02.673] iteration 1769 : model1 loss : 0.061346 model2 loss : 0.067119
[20:31:03.337] iteration 1770 : model1 loss : 0.063618 model2 loss : 0.055878
[20:31:04.008] iteration 1771 : model1 loss : 0.081842 model2 loss : 0.089111
[20:31:04.691] iteration 1772 : model1 loss : 0.045300 model2 loss : 0.044117
[20:31:05.368] iteration 1773 : model1 loss : 0.053914 model2 loss : 0.060970
[20:31:06.038] iteration 1774 : model1 loss : 0.120353 model2 loss : 0.164229
[20:31:06.713] iteration 1775 : model1 loss : 0.050969 model2 loss : 0.056874
[20:31:07.387] iteration 1776 : model1 loss : 0.092305 model2 loss : 0.032133
[20:31:08.057] iteration 1777 : model1 loss : 0.043080 model2 loss : 0.041609
[20:31:08.743] iteration 1778 : model1 loss : 0.034762 model2 loss : 0.034589
[20:31:09.447] iteration 1779 : model1 loss : 0.053266 model2 loss : 0.079078
[20:31:10.132] iteration 1780 : model1 loss : 0.050150 model2 loss : 0.041910
[20:31:10.812] iteration 1781 : model1 loss : 0.083726 model2 loss : 0.062073
[20:31:11.480] iteration 1782 : model1 loss : 0.066869 model2 loss : 0.094692
[20:31:12.153] iteration 1783 : model1 loss : 0.105030 model2 loss : 0.093023
[20:31:12.824] iteration 1784 : model1 loss : 0.041588 model2 loss : 0.044491
[20:31:13.506] iteration 1785 : model1 loss : 0.048711 model2 loss : 0.046076
[20:31:14.182] iteration 1786 : model1 loss : 0.050037 model2 loss : 0.042170
[20:31:14.867] iteration 1787 : model1 loss : 0.056965 model2 loss : 0.036832
[20:31:15.547] iteration 1788 : model1 loss : 0.056410 model2 loss : 0.042250
[20:31:16.230] iteration 1789 : model1 loss : 0.042704 model2 loss : 0.035014
[20:31:16.901] iteration 1790 : model1 loss : 0.125706 model2 loss : 0.047845
[20:31:17.576] iteration 1791 : model1 loss : 0.067105 model2 loss : 0.046861
[20:31:18.247] iteration 1792 : model1 loss : 0.082746 model2 loss : 0.103838
[20:31:18.931] iteration 1793 : model1 loss : 0.049990 model2 loss : 0.051679
[20:31:19.603] iteration 1794 : model1 loss : 0.110988 model2 loss : 0.061647
[20:31:20.280] iteration 1795 : model1 loss : 0.030870 model2 loss : 0.032300
[20:31:20.958] iteration 1796 : model1 loss : 0.096048 model2 loss : 0.063239
[20:31:21.623] iteration 1797 : model1 loss : 0.039819 model2 loss : 0.034618
[20:31:22.283] iteration 1798 : model1 loss : 0.055096 model2 loss : 0.051098
[20:31:22.948] iteration 1799 : model1 loss : 0.041951 model2 loss : 0.039211
[20:31:23.631] iteration 1800 : model1 loss : 0.078111 model2 loss : 0.053406
[20:31:42.356] iteration 1800 : model1_mean_dice : 0.759692 model1_mean_hd95 : 3.853410
[20:32:01.215] iteration 1800 : model2_mean_dice : 0.782578 model2_mean_hd95 : 5.476302
[20:32:01.913] iteration 1801 : model1 loss : 0.130675 model2 loss : 0.130050
[20:32:02.593] iteration 1802 : model1 loss : 0.058702 model2 loss : 0.050972
[20:32:03.256] iteration 1803 : model1 loss : 0.069516 model2 loss : 0.065123
[20:32:03.926] iteration 1804 : model1 loss : 0.100896 model2 loss : 0.083751
[20:32:04.584] iteration 1805 : model1 loss : 0.041847 model2 loss : 0.046029
[20:32:05.254] iteration 1806 : model1 loss : 0.045656 model2 loss : 0.041414
[20:32:05.913] iteration 1807 : model1 loss : 0.042609 model2 loss : 0.040086
[20:32:06.572] iteration 1808 : model1 loss : 0.058915 model2 loss : 0.050182
[20:32:07.256] iteration 1809 : model1 loss : 0.055984 model2 loss : 0.034476
[20:32:07.937] iteration 1810 : model1 loss : 0.113232 model2 loss : 0.100817
[20:32:08.615] iteration 1811 : model1 loss : 0.068393 model2 loss : 0.066476
[20:32:09.285] iteration 1812 : model1 loss : 0.058544 model2 loss : 0.058127
[20:32:09.975] iteration 1813 : model1 loss : 0.067637 model2 loss : 0.057168
[20:32:10.646] iteration 1814 : model1 loss : 0.047778 model2 loss : 0.053254
[20:32:11.317] iteration 1815 : model1 loss : 0.030792 model2 loss : 0.038632
[20:32:11.998] iteration 1816 : model1 loss : 0.071725 model2 loss : 0.051872
[20:32:12.660] iteration 1817 : model1 loss : 0.040181 model2 loss : 0.034077
[20:32:13.335] iteration 1818 : model1 loss : 0.050292 model2 loss : 0.082659
[20:32:14.007] iteration 1819 : model1 loss : 0.045972 model2 loss : 0.054674
[20:32:14.680] iteration 1820 : model1 loss : 0.040533 model2 loss : 0.056714
[20:32:15.351] iteration 1821 : model1 loss : 0.058243 model2 loss : 0.065578
[20:32:16.020] iteration 1822 : model1 loss : 0.047311 model2 loss : 0.044520
[20:32:16.708] iteration 1823 : model1 loss : 0.060545 model2 loss : 0.035413
[20:32:17.379] iteration 1824 : model1 loss : 0.051211 model2 loss : 0.050493
[20:32:18.054] iteration 1825 : model1 loss : 0.040976 model2 loss : 0.043272
[20:32:18.732] iteration 1826 : model1 loss : 0.100681 model2 loss : 0.116362
[20:32:19.396] iteration 1827 : model1 loss : 0.047225 model2 loss : 0.054418
[20:32:20.059] iteration 1828 : model1 loss : 0.037213 model2 loss : 0.051123
[20:32:20.731] iteration 1829 : model1 loss : 0.053565 model2 loss : 0.066925
[20:32:21.416] iteration 1830 : model1 loss : 0.044080 model2 loss : 0.056363
[20:32:22.082] iteration 1831 : model1 loss : 0.029910 model2 loss : 0.037584
[20:32:22.746] iteration 1832 : model1 loss : 0.051695 model2 loss : 0.115082
[20:32:23.425] iteration 1833 : model1 loss : 0.065503 model2 loss : 0.044400
[20:32:24.102] iteration 1834 : model1 loss : 0.083655 model2 loss : 0.057385
[20:32:24.776] iteration 1835 : model1 loss : 0.060273 model2 loss : 0.060479
[20:32:25.455] iteration 1836 : model1 loss : 0.061243 model2 loss : 0.034845
[20:32:26.127] iteration 1837 : model1 loss : 0.071072 model2 loss : 0.054781
[20:32:26.792] iteration 1838 : model1 loss : 0.078071 model2 loss : 0.061958
[20:32:27.466] iteration 1839 : model1 loss : 0.104300 model2 loss : 0.126718
[20:32:28.140] iteration 1840 : model1 loss : 0.085294 model2 loss : 0.093098
[20:32:28.812] iteration 1841 : model1 loss : 0.067589 model2 loss : 0.065580
[20:32:29.486] iteration 1842 : model1 loss : 0.190117 model2 loss : 0.180680
[20:32:30.153] iteration 1843 : model1 loss : 0.053506 model2 loss : 0.058195
[20:32:30.820] iteration 1844 : model1 loss : 0.162051 model2 loss : 0.078242
[20:32:31.512] iteration 1845 : model1 loss : 0.037178 model2 loss : 0.053386
[20:32:32.180] iteration 1846 : model1 loss : 0.092439 model2 loss : 0.119298
[20:32:32.854] iteration 1847 : model1 loss : 0.040393 model2 loss : 0.043970
[20:32:33.524] iteration 1848 : model1 loss : 0.035218 model2 loss : 0.037291
[20:32:34.227] iteration 1849 : model1 loss : 0.055262 model2 loss : 0.050981
[20:32:34.919] iteration 1850 : model1 loss : 0.055544 model2 loss : 0.110129
[20:32:35.655] iteration 1851 : model1 loss : 0.062165 model2 loss : 0.076053
[20:32:36.327] iteration 1852 : model1 loss : 0.082391 model2 loss : 0.085416
[20:32:37.003] iteration 1853 : model1 loss : 0.169689 model2 loss : 0.220410
[20:32:37.692] iteration 1854 : model1 loss : 0.061862 model2 loss : 0.055423
[20:32:38.386] iteration 1855 : model1 loss : 0.043802 model2 loss : 0.038117
[20:32:39.067] iteration 1856 : model1 loss : 0.084834 model2 loss : 0.089334
[20:32:39.755] iteration 1857 : model1 loss : 0.023519 model2 loss : 0.031153
[20:32:40.432] iteration 1858 : model1 loss : 0.108311 model2 loss : 0.112861
[20:32:41.112] iteration 1859 : model1 loss : 0.053803 model2 loss : 0.065531
[20:32:41.788] iteration 1860 : model1 loss : 0.057134 model2 loss : 0.071511
[20:32:42.464] iteration 1861 : model1 loss : 0.047318 model2 loss : 0.042457
[20:32:43.125] iteration 1862 : model1 loss : 0.040345 model2 loss : 0.035405
[20:32:43.794] iteration 1863 : model1 loss : 0.106870 model2 loss : 0.082761
[20:32:44.462] iteration 1864 : model1 loss : 0.099093 model2 loss : 0.088010
[20:32:45.148] iteration 1865 : model1 loss : 0.078868 model2 loss : 0.056026
[20:32:45.827] iteration 1866 : model1 loss : 0.047862 model2 loss : 0.055888
[20:32:46.510] iteration 1867 : model1 loss : 0.078357 model2 loss : 0.067456
[20:32:47.218] iteration 1868 : model1 loss : 0.049687 model2 loss : 0.048816
[20:32:47.892] iteration 1869 : model1 loss : 0.070179 model2 loss : 0.054294
[20:32:48.577] iteration 1870 : model1 loss : 0.055986 model2 loss : 0.070658
[20:32:49.261] iteration 1871 : model1 loss : 0.034148 model2 loss : 0.042543
[20:32:49.930] iteration 1872 : model1 loss : 0.056508 model2 loss : 0.055084
[20:32:50.600] iteration 1873 : model1 loss : 0.159950 model2 loss : 0.073766
[20:32:51.270] iteration 1874 : model1 loss : 0.036803 model2 loss : 0.059629
[20:32:51.953] iteration 1875 : model1 loss : 0.035580 model2 loss : 0.044475
[20:32:52.632] iteration 1876 : model1 loss : 0.095303 model2 loss : 0.098997
[20:32:53.300] iteration 1877 : model1 loss : 0.070211 model2 loss : 0.081223
[20:32:53.978] iteration 1878 : model1 loss : 0.060966 model2 loss : 0.054319
[20:32:54.639] iteration 1879 : model1 loss : 0.046439 model2 loss : 0.051121
[20:32:55.309] iteration 1880 : model1 loss : 0.093033 model2 loss : 0.098357
[20:32:55.989] iteration 1881 : model1 loss : 0.038336 model2 loss : 0.046296
[20:32:56.663] iteration 1882 : model1 loss : 0.039196 model2 loss : 0.039410
[20:32:57.344] iteration 1883 : model1 loss : 0.075538 model2 loss : 0.067097
[20:32:58.013] iteration 1884 : model1 loss : 0.037025 model2 loss : 0.035112
[20:32:58.694] iteration 1885 : model1 loss : 0.104871 model2 loss : 0.060665
[20:32:59.376] iteration 1886 : model1 loss : 0.042281 model2 loss : 0.049034
[20:33:00.054] iteration 1887 : model1 loss : 0.047198 model2 loss : 0.030448
[20:33:00.728] iteration 1888 : model1 loss : 0.065976 model2 loss : 0.060582
[20:33:01.403] iteration 1889 : model1 loss : 0.058811 model2 loss : 0.042868
[20:33:02.081] iteration 1890 : model1 loss : 0.066194 model2 loss : 0.051838
[20:33:02.749] iteration 1891 : model1 loss : 0.078718 model2 loss : 0.081055
[20:33:03.434] iteration 1892 : model1 loss : 0.037920 model2 loss : 0.046810
[20:33:04.106] iteration 1893 : model1 loss : 0.056874 model2 loss : 0.049330
[20:33:04.770] iteration 1894 : model1 loss : 0.068753 model2 loss : 0.060585
[20:33:05.451] iteration 1895 : model1 loss : 0.065687 model2 loss : 0.070712
[20:33:06.137] iteration 1896 : model1 loss : 0.088668 model2 loss : 0.099665
[20:33:06.806] iteration 1897 : model1 loss : 0.084070 model2 loss : 0.061660
[20:33:07.479] iteration 1898 : model1 loss : 0.053773 model2 loss : 0.079234
[20:33:08.145] iteration 1899 : model1 loss : 0.036946 model2 loss : 0.036240
[20:33:08.824] iteration 1900 : model1 loss : 0.100079 model2 loss : 0.078217
[20:33:09.549] iteration 1901 : model1 loss : 0.051890 model2 loss : 0.048588
[20:33:10.216] iteration 1902 : model1 loss : 0.094543 model2 loss : 0.067100
[20:33:10.900] iteration 1903 : model1 loss : 0.076370 model2 loss : 0.052737
[20:33:11.581] iteration 1904 : model1 loss : 0.027600 model2 loss : 0.037941
[20:33:12.265] iteration 1905 : model1 loss : 0.056509 model2 loss : 0.056395
[20:33:12.936] iteration 1906 : model1 loss : 0.059952 model2 loss : 0.072633
[20:33:13.619] iteration 1907 : model1 loss : 0.039191 model2 loss : 0.050300
[20:33:14.305] iteration 1908 : model1 loss : 0.078523 model2 loss : 0.101138
[20:33:14.988] iteration 1909 : model1 loss : 0.033697 model2 loss : 0.031137
[20:33:15.647] iteration 1910 : model1 loss : 0.037965 model2 loss : 0.040023
[20:33:16.326] iteration 1911 : model1 loss : 0.037739 model2 loss : 0.044647
[20:33:16.989] iteration 1912 : model1 loss : 0.029830 model2 loss : 0.027402
[20:33:17.650] iteration 1913 : model1 loss : 0.038474 model2 loss : 0.038606
[20:33:18.327] iteration 1914 : model1 loss : 0.045449 model2 loss : 0.036098
[20:33:19.018] iteration 1915 : model1 loss : 0.098597 model2 loss : 0.069175
[20:33:19.694] iteration 1916 : model1 loss : 0.123044 model2 loss : 0.121930
[20:33:20.375] iteration 1917 : model1 loss : 0.037171 model2 loss : 0.039043
[20:33:21.057] iteration 1918 : model1 loss : 0.032090 model2 loss : 0.033996
[20:33:21.728] iteration 1919 : model1 loss : 0.063231 model2 loss : 0.074005
[20:33:22.390] iteration 1920 : model1 loss : 0.050273 model2 loss : 0.099441
[20:33:23.081] iteration 1921 : model1 loss : 0.048340 model2 loss : 0.049429
[20:33:23.760] iteration 1922 : model1 loss : 0.048083 model2 loss : 0.058977
[20:33:24.430] iteration 1923 : model1 loss : 0.059659 model2 loss : 0.056906
[20:33:25.102] iteration 1924 : model1 loss : 0.057778 model2 loss : 0.056427
[20:33:25.776] iteration 1925 : model1 loss : 0.147601 model2 loss : 0.115009
[20:33:26.448] iteration 1926 : model1 loss : 0.034472 model2 loss : 0.037935
[20:33:27.120] iteration 1927 : model1 loss : 0.040363 model2 loss : 0.052833
[20:33:27.788] iteration 1928 : model1 loss : 0.040728 model2 loss : 0.049856
[20:33:28.463] iteration 1929 : model1 loss : 0.077634 model2 loss : 0.086524
[20:33:29.145] iteration 1930 : model1 loss : 0.151006 model2 loss : 0.165897
[20:33:29.818] iteration 1931 : model1 loss : 0.055947 model2 loss : 0.042510
[20:33:30.521] iteration 1932 : model1 loss : 0.162691 model2 loss : 0.125639
[20:33:31.195] iteration 1933 : model1 loss : 0.030749 model2 loss : 0.040946
[20:33:31.863] iteration 1934 : model1 loss : 0.038437 model2 loss : 0.038459
[20:33:32.543] iteration 1935 : model1 loss : 0.034620 model2 loss : 0.041580
[20:33:33.225] iteration 1936 : model1 loss : 0.079606 model2 loss : 0.114633
[20:33:33.904] iteration 1937 : model1 loss : 0.045463 model2 loss : 0.049826
[20:33:34.579] iteration 1938 : model1 loss : 0.082093 model2 loss : 0.099706
[20:33:35.261] iteration 1939 : model1 loss : 0.095210 model2 loss : 0.096268
[20:33:35.929] iteration 1940 : model1 loss : 0.048249 model2 loss : 0.042235
[20:33:36.602] iteration 1941 : model1 loss : 0.052997 model2 loss : 0.057079
[20:33:37.274] iteration 1942 : model1 loss : 0.157992 model2 loss : 0.154820
[20:33:37.948] iteration 1943 : model1 loss : 0.050402 model2 loss : 0.047742
[20:33:38.614] iteration 1944 : model1 loss : 0.048389 model2 loss : 0.050662
[20:33:39.285] iteration 1945 : model1 loss : 0.098376 model2 loss : 0.095188
[20:33:39.959] iteration 1946 : model1 loss : 0.048127 model2 loss : 0.043435
[20:33:40.635] iteration 1947 : model1 loss : 0.088578 model2 loss : 0.131005
[20:33:41.311] iteration 1948 : model1 loss : 0.059270 model2 loss : 0.056166
[20:33:41.984] iteration 1949 : model1 loss : 0.057749 model2 loss : 0.053233
[20:33:42.687] iteration 1950 : model1 loss : 0.087762 model2 loss : 0.062718
[20:33:43.397] iteration 1951 : model1 loss : 0.069656 model2 loss : 0.070708
[20:33:44.059] iteration 1952 : model1 loss : 0.036798 model2 loss : 0.036950
[20:33:44.747] iteration 1953 : model1 loss : 0.055524 model2 loss : 0.057383
[20:33:45.422] iteration 1954 : model1 loss : 0.062937 model2 loss : 0.059074
[20:33:46.099] iteration 1955 : model1 loss : 0.056114 model2 loss : 0.067789
[20:33:46.772] iteration 1956 : model1 loss : 0.067027 model2 loss : 0.073778
[20:33:47.457] iteration 1957 : model1 loss : 0.040727 model2 loss : 0.036428
[20:33:48.143] iteration 1958 : model1 loss : 0.048847 model2 loss : 0.049052
[20:33:48.803] iteration 1959 : model1 loss : 0.054136 model2 loss : 0.052037
[20:33:49.473] iteration 1960 : model1 loss : 0.082567 model2 loss : 0.064807
[20:33:50.149] iteration 1961 : model1 loss : 0.053767 model2 loss : 0.054836
[20:33:50.826] iteration 1962 : model1 loss : 0.051572 model2 loss : 0.049553
[20:33:51.489] iteration 1963 : model1 loss : 0.054620 model2 loss : 0.047727
[20:33:52.163] iteration 1964 : model1 loss : 0.034607 model2 loss : 0.039865
[20:33:52.831] iteration 1965 : model1 loss : 0.053289 model2 loss : 0.049846
[20:33:53.509] iteration 1966 : model1 loss : 0.043440 model2 loss : 0.035294
[20:33:54.178] iteration 1967 : model1 loss : 0.149088 model2 loss : 0.134252
[20:33:54.855] iteration 1968 : model1 loss : 0.046433 model2 loss : 0.045373
[20:33:55.550] iteration 1969 : model1 loss : 0.079191 model2 loss : 0.061497
[20:33:56.213] iteration 1970 : model1 loss : 0.046244 model2 loss : 0.054338
[20:33:56.905] iteration 1971 : model1 loss : 0.051548 model2 loss : 0.049209
[20:33:57.590] iteration 1972 : model1 loss : 0.046143 model2 loss : 0.049604
[20:33:58.275] iteration 1973 : model1 loss : 0.047566 model2 loss : 0.056193
[20:33:58.958] iteration 1974 : model1 loss : 0.077975 model2 loss : 0.065980
[20:33:59.631] iteration 1975 : model1 loss : 0.051118 model2 loss : 0.040950
[20:34:00.309] iteration 1976 : model1 loss : 0.036647 model2 loss : 0.038275
[20:34:00.987] iteration 1977 : model1 loss : 0.048373 model2 loss : 0.045869
[20:34:01.650] iteration 1978 : model1 loss : 0.046067 model2 loss : 0.042190
[20:34:02.326] iteration 1979 : model1 loss : 0.054841 model2 loss : 0.056479
[20:34:02.983] iteration 1980 : model1 loss : 0.160846 model2 loss : 0.145156
[20:34:03.663] iteration 1981 : model1 loss : 0.049986 model2 loss : 0.041932
[20:34:04.341] iteration 1982 : model1 loss : 0.031745 model2 loss : 0.036476
[20:34:05.014] iteration 1983 : model1 loss : 0.038666 model2 loss : 0.042904
[20:34:05.689] iteration 1984 : model1 loss : 0.290613 model2 loss : 0.263083
[20:34:06.381] iteration 1985 : model1 loss : 0.041742 model2 loss : 0.040664
[20:34:07.055] iteration 1986 : model1 loss : 0.058327 model2 loss : 0.071834
[20:34:07.726] iteration 1987 : model1 loss : 0.074807 model2 loss : 0.082718
[20:34:08.405] iteration 1988 : model1 loss : 0.059437 model2 loss : 0.078512
[20:34:09.097] iteration 1989 : model1 loss : 0.091242 model2 loss : 0.075860
[20:34:09.779] iteration 1990 : model1 loss : 0.046382 model2 loss : 0.044055
[20:34:10.454] iteration 1991 : model1 loss : 0.045644 model2 loss : 0.043667
[20:34:11.163] iteration 1992 : model1 loss : 0.038709 model2 loss : 0.035330
[20:34:11.848] iteration 1993 : model1 loss : 0.057187 model2 loss : 0.065553
[20:34:12.534] iteration 1994 : model1 loss : 0.187372 model2 loss : 0.256146
[20:34:13.197] iteration 1995 : model1 loss : 0.067597 model2 loss : 0.052789
[20:34:13.869] iteration 1996 : model1 loss : 0.111351 model2 loss : 0.111642
[20:34:14.544] iteration 1997 : model1 loss : 0.046093 model2 loss : 0.048339
[20:34:15.211] iteration 1998 : model1 loss : 0.082124 model2 loss : 0.086691
[20:34:15.880] iteration 1999 : model1 loss : 0.041116 model2 loss : 0.045455
[20:34:16.555] iteration 2000 : model1 loss : 0.043734 model2 loss : 0.050327
[20:34:35.472] iteration 2000 : model1_mean_dice : 0.770247 model1_mean_hd95 : 7.048151
[20:34:54.631] iteration 2000 : model2_mean_dice : 0.742154 model2_mean_hd95 : 14.604642
[20:34:55.322] iteration 2001 : model1 loss : 0.056033 model2 loss : 0.077076
[20:34:55.985] iteration 2002 : model1 loss : 0.034715 model2 loss : 0.035761
[20:34:56.636] iteration 2003 : model1 loss : 0.044556 model2 loss : 0.065631
[20:34:57.322] iteration 2004 : model1 loss : 0.112891 model2 loss : 0.131063
[20:34:57.995] iteration 2005 : model1 loss : 0.039656 model2 loss : 0.043398
[20:34:58.666] iteration 2006 : model1 loss : 0.023693 model2 loss : 0.027454
[20:34:59.358] iteration 2007 : model1 loss : 0.026063 model2 loss : 0.030175
[20:35:00.026] iteration 2008 : model1 loss : 0.064586 model2 loss : 0.064182
[20:35:00.701] iteration 2009 : model1 loss : 0.038173 model2 loss : 0.036733
[20:35:01.373] iteration 2010 : model1 loss : 0.046988 model2 loss : 0.048895
[20:35:02.045] iteration 2011 : model1 loss : 0.034741 model2 loss : 0.040989
[20:35:02.722] iteration 2012 : model1 loss : 0.051468 model2 loss : 0.058118
[20:35:03.393] iteration 2013 : model1 loss : 0.097827 model2 loss : 0.081232
[20:35:04.060] iteration 2014 : model1 loss : 0.053155 model2 loss : 0.049974
[20:35:04.728] iteration 2015 : model1 loss : 0.073930 model2 loss : 0.083999
[20:35:05.397] iteration 2016 : model1 loss : 0.047906 model2 loss : 0.045494
[20:35:06.066] iteration 2017 : model1 loss : 0.070026 model2 loss : 0.059203
[20:35:06.791] iteration 2018 : model1 loss : 0.063158 model2 loss : 0.091861
[20:35:07.509] iteration 2019 : model1 loss : 0.040602 model2 loss : 0.043931
[20:35:08.222] iteration 2020 : model1 loss : 0.065809 model2 loss : 0.048428
[20:35:08.938] iteration 2021 : model1 loss : 0.044195 model2 loss : 0.052155
[20:35:09.651] iteration 2022 : model1 loss : 0.051447 model2 loss : 0.058176
[20:35:10.347] iteration 2023 : model1 loss : 0.096043 model2 loss : 0.102060
[20:35:11.010] iteration 2024 : model1 loss : 0.053890 model2 loss : 0.057029
[20:35:11.691] iteration 2025 : model1 loss : 0.048943 model2 loss : 0.052647
[20:35:12.370] iteration 2026 : model1 loss : 0.151153 model2 loss : 0.064925
[20:35:13.043] iteration 2027 : model1 loss : 0.044016 model2 loss : 0.047937
[20:35:13.723] iteration 2028 : model1 loss : 0.177363 model2 loss : 0.169207
[20:35:14.412] iteration 2029 : model1 loss : 0.055132 model2 loss : 0.049953
[20:35:15.097] iteration 2030 : model1 loss : 0.048677 model2 loss : 0.043419
[20:35:15.774] iteration 2031 : model1 loss : 0.081122 model2 loss : 0.076880
[20:35:16.443] iteration 2032 : model1 loss : 0.057479 model2 loss : 0.079438
[20:35:17.128] iteration 2033 : model1 loss : 0.061075 model2 loss : 0.074844
[20:35:17.797] iteration 2034 : model1 loss : 0.043700 model2 loss : 0.054509
[20:35:18.461] iteration 2035 : model1 loss : 0.034794 model2 loss : 0.033899
[20:35:19.149] iteration 2036 : model1 loss : 0.039428 model2 loss : 0.046309
[20:35:19.823] iteration 2037 : model1 loss : 0.030013 model2 loss : 0.044725
[20:35:20.502] iteration 2038 : model1 loss : 0.158963 model2 loss : 0.127329
[20:35:21.175] iteration 2039 : model1 loss : 0.040346 model2 loss : 0.037712
[20:35:21.850] iteration 2040 : model1 loss : 0.094089 model2 loss : 0.088456
[20:35:22.534] iteration 2041 : model1 loss : 0.037421 model2 loss : 0.030752
[20:35:23.204] iteration 2042 : model1 loss : 0.080186 model2 loss : 0.054816
[20:35:23.881] iteration 2043 : model1 loss : 0.060801 model2 loss : 0.068405
[20:35:24.542] iteration 2044 : model1 loss : 0.036527 model2 loss : 0.034026
[20:35:25.209] iteration 2045 : model1 loss : 0.045838 model2 loss : 0.038488
[20:35:25.893] iteration 2046 : model1 loss : 0.045007 model2 loss : 0.051471
[20:35:26.560] iteration 2047 : model1 loss : 0.050165 model2 loss : 0.064745
[20:35:27.226] iteration 2048 : model1 loss : 0.033177 model2 loss : 0.037657
[20:35:27.907] iteration 2049 : model1 loss : 0.040521 model2 loss : 0.052761
[20:35:28.609] iteration 2050 : model1 loss : 0.035901 model2 loss : 0.035564
[20:35:29.356] iteration 2051 : model1 loss : 0.042394 model2 loss : 0.043994
[20:35:30.037] iteration 2052 : model1 loss : 0.088595 model2 loss : 0.089198
[20:35:30.710] iteration 2053 : model1 loss : 0.043575 model2 loss : 0.035879
[20:35:31.394] iteration 2054 : model1 loss : 0.047646 model2 loss : 0.050233
[20:35:32.048] iteration 2055 : model1 loss : 0.062932 model2 loss : 0.063344
[20:35:32.733] iteration 2056 : model1 loss : 0.034414 model2 loss : 0.036289
[20:35:33.403] iteration 2057 : model1 loss : 0.057119 model2 loss : 0.058395
[20:35:34.078] iteration 2058 : model1 loss : 0.037790 model2 loss : 0.038988
[20:35:34.742] iteration 2059 : model1 loss : 0.040460 model2 loss : 0.047280
[20:35:35.414] iteration 2060 : model1 loss : 0.106196 model2 loss : 0.101368
[20:35:36.080] iteration 2061 : model1 loss : 0.047839 model2 loss : 0.049451
[20:35:36.751] iteration 2062 : model1 loss : 0.045520 model2 loss : 0.080928
[20:35:37.431] iteration 2063 : model1 loss : 0.030670 model2 loss : 0.033545
[20:35:38.117] iteration 2064 : model1 loss : 0.048249 model2 loss : 0.051262
[20:35:38.790] iteration 2065 : model1 loss : 0.056047 model2 loss : 0.041615
[20:35:39.474] iteration 2066 : model1 loss : 0.165344 model2 loss : 0.159306
[20:35:40.143] iteration 2067 : model1 loss : 0.051311 model2 loss : 0.055232
[20:35:40.834] iteration 2068 : model1 loss : 0.029442 model2 loss : 0.048533
[20:35:41.504] iteration 2069 : model1 loss : 0.054370 model2 loss : 0.069973
[20:35:42.167] iteration 2070 : model1 loss : 0.073081 model2 loss : 0.097510
[20:35:42.836] iteration 2071 : model1 loss : 0.127056 model2 loss : 0.111689
[20:35:43.520] iteration 2072 : model1 loss : 0.036330 model2 loss : 0.041909
[20:35:44.182] iteration 2073 : model1 loss : 0.044398 model2 loss : 0.050091
[20:35:44.852] iteration 2074 : model1 loss : 0.102683 model2 loss : 0.069109
[20:35:45.548] iteration 2075 : model1 loss : 0.059384 model2 loss : 0.059734
[20:35:46.216] iteration 2076 : model1 loss : 0.042647 model2 loss : 0.034629
[20:35:46.882] iteration 2077 : model1 loss : 0.040789 model2 loss : 0.044172
[20:35:47.549] iteration 2078 : model1 loss : 0.040991 model2 loss : 0.034614
[20:35:48.225] iteration 2079 : model1 loss : 0.044788 model2 loss : 0.045824
[20:35:48.901] iteration 2080 : model1 loss : 0.073147 model2 loss : 0.052134
[20:35:49.576] iteration 2081 : model1 loss : 0.078715 model2 loss : 0.060659
[20:35:50.251] iteration 2082 : model1 loss : 0.078688 model2 loss : 0.112185
[20:35:50.930] iteration 2083 : model1 loss : 0.050718 model2 loss : 0.040616
[20:35:51.604] iteration 2084 : model1 loss : 0.048707 model2 loss : 0.049137
[20:35:52.292] iteration 2085 : model1 loss : 0.038096 model2 loss : 0.058358
[20:35:52.960] iteration 2086 : model1 loss : 0.033943 model2 loss : 0.045868
[20:35:53.622] iteration 2087 : model1 loss : 0.042192 model2 loss : 0.039305
[20:35:54.290] iteration 2088 : model1 loss : 0.060137 model2 loss : 0.058696
[20:35:54.952] iteration 2089 : model1 loss : 0.072226 model2 loss : 0.074644
[20:35:55.630] iteration 2090 : model1 loss : 0.036724 model2 loss : 0.039468
[20:35:56.300] iteration 2091 : model1 loss : 0.036664 model2 loss : 0.050997
[20:35:56.978] iteration 2092 : model1 loss : 0.032564 model2 loss : 0.031747
[20:35:57.660] iteration 2093 : model1 loss : 0.051461 model2 loss : 0.047098
[20:35:58.342] iteration 2094 : model1 loss : 0.037014 model2 loss : 0.039789
[20:35:59.034] iteration 2095 : model1 loss : 0.067213 model2 loss : 0.086677
[20:35:59.714] iteration 2096 : model1 loss : 0.026830 model2 loss : 0.032714
[20:36:00.391] iteration 2097 : model1 loss : 0.135221 model2 loss : 0.141552
[20:36:01.119] iteration 2098 : model1 loss : 0.048772 model2 loss : 0.055506
[20:36:01.883] iteration 2099 : model1 loss : 0.056878 model2 loss : 0.047802
[20:36:02.663] iteration 2100 : model1 loss : 0.064461 model2 loss : 0.058890
[20:36:03.487] iteration 2101 : model1 loss : 0.151010 model2 loss : 0.147569
[20:36:04.260] iteration 2102 : model1 loss : 0.052831 model2 loss : 0.056071
[20:36:04.990] iteration 2103 : model1 loss : 0.052184 model2 loss : 0.055065
[20:36:05.764] iteration 2104 : model1 loss : 0.030855 model2 loss : 0.041551
[20:36:06.565] iteration 2105 : model1 loss : 0.084993 model2 loss : 0.101555
[20:36:07.349] iteration 2106 : model1 loss : 0.048548 model2 loss : 0.054042
[20:36:08.124] iteration 2107 : model1 loss : 0.029797 model2 loss : 0.039753
[20:36:08.843] iteration 2108 : model1 loss : 0.037346 model2 loss : 0.054306
[20:36:09.592] iteration 2109 : model1 loss : 0.061831 model2 loss : 0.167429
[20:36:10.379] iteration 2110 : model1 loss : 0.066603 model2 loss : 0.075754
[20:36:11.237] iteration 2111 : model1 loss : 0.142930 model2 loss : 0.094260
[20:36:12.159] iteration 2112 : model1 loss : 0.029763 model2 loss : 0.039470
[20:36:12.934] iteration 2113 : model1 loss : 0.172135 model2 loss : 0.203814
[20:36:13.774] iteration 2114 : model1 loss : 0.050208 model2 loss : 0.064447
[20:36:14.650] iteration 2115 : model1 loss : 0.033586 model2 loss : 0.038253
[20:36:15.495] iteration 2116 : model1 loss : 0.076845 model2 loss : 0.072023
[20:36:16.266] iteration 2117 : model1 loss : 0.086999 model2 loss : 0.048825
[20:36:17.038] iteration 2118 : model1 loss : 0.105333 model2 loss : 0.087815
[20:36:17.790] iteration 2119 : model1 loss : 0.059242 model2 loss : 0.060814
[20:36:18.540] iteration 2120 : model1 loss : 0.039293 model2 loss : 0.034717
[20:36:19.310] iteration 2121 : model1 loss : 0.045777 model2 loss : 0.042545
[20:36:20.060] iteration 2122 : model1 loss : 0.064693 model2 loss : 0.083608
[20:36:20.890] iteration 2123 : model1 loss : 0.048821 model2 loss : 0.062206
[20:36:21.661] iteration 2124 : model1 loss : 0.068580 model2 loss : 0.057864
[20:36:22.436] iteration 2125 : model1 loss : 0.054506 model2 loss : 0.046107
[20:36:23.213] iteration 2126 : model1 loss : 0.138646 model2 loss : 0.123974
[20:36:24.338] iteration 2127 : model1 loss : 0.039622 model2 loss : 0.044476
[20:36:25.165] iteration 2128 : model1 loss : 0.036513 model2 loss : 0.038635
[20:36:25.955] iteration 2129 : model1 loss : 0.040301 model2 loss : 0.042480
[20:36:26.704] iteration 2130 : model1 loss : 0.029570 model2 loss : 0.032745
[20:36:27.476] iteration 2131 : model1 loss : 0.052915 model2 loss : 0.074082
[20:36:28.243] iteration 2132 : model1 loss : 0.178066 model2 loss : 0.137455
[20:36:29.073] iteration 2133 : model1 loss : 0.030611 model2 loss : 0.026080
[20:36:29.919] iteration 2134 : model1 loss : 0.043911 model2 loss : 0.050519
[20:36:30.689] iteration 2135 : model1 loss : 0.122235 model2 loss : 0.078500
[20:36:31.410] iteration 2136 : model1 loss : 0.039274 model2 loss : 0.035582
[20:36:32.117] iteration 2137 : model1 loss : 0.032616 model2 loss : 0.034554
[20:36:32.816] iteration 2138 : model1 loss : 0.102268 model2 loss : 0.116458
[20:36:33.525] iteration 2139 : model1 loss : 0.039116 model2 loss : 0.044549
[20:36:34.226] iteration 2140 : model1 loss : 0.170368 model2 loss : 0.214234
[20:36:34.948] iteration 2141 : model1 loss : 0.050230 model2 loss : 0.074416
[20:36:35.696] iteration 2142 : model1 loss : 0.035108 model2 loss : 0.061141
[20:36:36.425] iteration 2143 : model1 loss : 0.057476 model2 loss : 0.066323
[20:36:37.101] iteration 2144 : model1 loss : 0.039694 model2 loss : 0.039863
[20:36:37.818] iteration 2145 : model1 loss : 0.038757 model2 loss : 0.038567
[20:36:38.570] iteration 2146 : model1 loss : 0.051772 model2 loss : 0.093972
[20:36:39.241] iteration 2147 : model1 loss : 0.032346 model2 loss : 0.037057
[20:36:39.924] iteration 2148 : model1 loss : 0.065364 model2 loss : 0.086646
[20:36:40.656] iteration 2149 : model1 loss : 0.052323 model2 loss : 0.058066
[20:36:41.379] iteration 2150 : model1 loss : 0.043786 model2 loss : 0.047475
[20:36:42.187] iteration 2151 : model1 loss : 0.052750 model2 loss : 0.074024
[20:36:42.965] iteration 2152 : model1 loss : 0.052305 model2 loss : 0.082180
[20:36:43.692] iteration 2153 : model1 loss : 0.053904 model2 loss : 0.054478
[20:36:44.422] iteration 2154 : model1 loss : 0.041416 model2 loss : 0.045507
[20:36:45.172] iteration 2155 : model1 loss : 0.051091 model2 loss : 0.049331
[20:36:45.946] iteration 2156 : model1 loss : 0.103302 model2 loss : 0.045825
[20:36:46.665] iteration 2157 : model1 loss : 0.110498 model2 loss : 0.157510
[20:36:47.386] iteration 2158 : model1 loss : 0.052502 model2 loss : 0.053809
[20:36:48.115] iteration 2159 : model1 loss : 0.109228 model2 loss : 0.086858
[20:36:48.865] iteration 2160 : model1 loss : 0.059015 model2 loss : 0.058988
[20:36:49.603] iteration 2161 : model1 loss : 0.027327 model2 loss : 0.030199
[20:36:50.337] iteration 2162 : model1 loss : 0.042536 model2 loss : 0.047131
[20:36:51.099] iteration 2163 : model1 loss : 0.043545 model2 loss : 0.042219
[20:36:51.821] iteration 2164 : model1 loss : 0.097017 model2 loss : 0.071199
[20:36:52.553] iteration 2165 : model1 loss : 0.067702 model2 loss : 0.067749
[20:36:53.258] iteration 2166 : model1 loss : 0.064525 model2 loss : 0.061600
[20:36:53.982] iteration 2167 : model1 loss : 0.054491 model2 loss : 0.051441
[20:36:54.727] iteration 2168 : model1 loss : 0.069952 model2 loss : 0.038622
[20:36:55.489] iteration 2169 : model1 loss : 0.029154 model2 loss : 0.030549
[20:36:56.240] iteration 2170 : model1 loss : 0.123712 model2 loss : 0.071259
[20:36:57.002] iteration 2171 : model1 loss : 0.062677 model2 loss : 0.054761
[20:36:57.713] iteration 2172 : model1 loss : 0.044269 model2 loss : 0.052186
[20:36:58.420] iteration 2173 : model1 loss : 0.048478 model2 loss : 0.060309
[20:36:59.140] iteration 2174 : model1 loss : 0.039607 model2 loss : 0.044179
[20:36:59.893] iteration 2175 : model1 loss : 0.087272 model2 loss : 0.088178
[20:37:00.686] iteration 2176 : model1 loss : 0.023514 model2 loss : 0.021681
[20:37:01.453] iteration 2177 : model1 loss : 0.055515 model2 loss : 0.036989
[20:37:02.187] iteration 2178 : model1 loss : 0.157419 model2 loss : 0.147388
[20:37:02.947] iteration 2179 : model1 loss : 0.044169 model2 loss : 0.047911
[20:37:03.666] iteration 2180 : model1 loss : 0.043123 model2 loss : 0.035827
[20:37:04.386] iteration 2181 : model1 loss : 0.050635 model2 loss : 0.040486
[20:37:05.090] iteration 2182 : model1 loss : 0.067052 model2 loss : 0.052129
[20:37:05.791] iteration 2183 : model1 loss : 0.035612 model2 loss : 0.034480
[20:37:06.499] iteration 2184 : model1 loss : 0.049090 model2 loss : 0.046149
[20:37:07.205] iteration 2185 : model1 loss : 0.350399 model2 loss : 0.217103
[20:37:07.909] iteration 2186 : model1 loss : 0.033826 model2 loss : 0.032072
[20:37:08.630] iteration 2187 : model1 loss : 0.032633 model2 loss : 0.038254
[20:37:09.345] iteration 2188 : model1 loss : 0.058437 model2 loss : 0.040722
[20:37:10.064] iteration 2189 : model1 loss : 0.119140 model2 loss : 0.129639
[20:37:10.766] iteration 2190 : model1 loss : 0.043671 model2 loss : 0.063568
[20:37:11.486] iteration 2191 : model1 loss : 0.044543 model2 loss : 0.091439
[20:37:12.199] iteration 2192 : model1 loss : 0.042487 model2 loss : 0.048526
[20:37:12.909] iteration 2193 : model1 loss : 0.057019 model2 loss : 0.054658
[20:37:13.612] iteration 2194 : model1 loss : 0.132159 model2 loss : 0.134619
[20:37:14.317] iteration 2195 : model1 loss : 0.058375 model2 loss : 0.076768
[20:37:14.993] iteration 2196 : model1 loss : 0.050326 model2 loss : 0.066126
[20:37:15.709] iteration 2197 : model1 loss : 0.088509 model2 loss : 0.091825
[20:37:16.422] iteration 2198 : model1 loss : 0.042791 model2 loss : 0.070442
[20:37:17.133] iteration 2199 : model1 loss : 0.076610 model2 loss : 0.116334
[20:37:17.821] iteration 2200 : model1 loss : 0.052138 model2 loss : 0.059572
[20:37:37.243] iteration 2200 : model1_mean_dice : 0.785133 model1_mean_hd95 : 7.979516
[20:37:56.964] iteration 2200 : model2_mean_dice : 0.757647 model2_mean_hd95 : 42.442803
[20:37:57.678] iteration 2201 : model1 loss : 0.067727 model2 loss : 0.070134
[20:37:58.363] iteration 2202 : model1 loss : 0.042374 model2 loss : 0.061071
[20:37:59.062] iteration 2203 : model1 loss : 0.039676 model2 loss : 0.053320
[20:37:59.743] iteration 2204 : model1 loss : 0.040744 model2 loss : 0.058089
[20:38:00.426] iteration 2205 : model1 loss : 0.051551 model2 loss : 0.044686
[20:38:01.120] iteration 2206 : model1 loss : 0.041849 model2 loss : 0.040794
[20:38:01.816] iteration 2207 : model1 loss : 0.049067 model2 loss : 0.052669
[20:38:02.511] iteration 2208 : model1 loss : 0.039934 model2 loss : 0.041746
[20:38:03.198] iteration 2209 : model1 loss : 0.087580 model2 loss : 0.110918
[20:38:03.885] iteration 2210 : model1 loss : 0.056027 model2 loss : 0.049083
[20:38:04.584] iteration 2211 : model1 loss : 0.037143 model2 loss : 0.047321
[20:38:05.300] iteration 2212 : model1 loss : 0.047588 model2 loss : 0.047471
[20:38:05.980] iteration 2213 : model1 loss : 0.091534 model2 loss : 0.072641
[20:38:06.681] iteration 2214 : model1 loss : 0.062972 model2 loss : 0.074137
[20:38:07.367] iteration 2215 : model1 loss : 0.039789 model2 loss : 0.045634
[20:38:08.053] iteration 2216 : model1 loss : 0.046736 model2 loss : 0.034238
[20:38:08.735] iteration 2217 : model1 loss : 0.043332 model2 loss : 0.092190
[20:38:09.423] iteration 2218 : model1 loss : 0.046313 model2 loss : 0.067108
[20:38:10.120] iteration 2219 : model1 loss : 0.050781 model2 loss : 0.086326
[20:38:10.800] iteration 2220 : model1 loss : 0.046059 model2 loss : 0.060329
[20:38:11.490] iteration 2221 : model1 loss : 0.051576 model2 loss : 0.051284
[20:38:12.180] iteration 2222 : model1 loss : 0.047833 model2 loss : 0.069372
[20:38:12.866] iteration 2223 : model1 loss : 0.032832 model2 loss : 0.035869
[20:38:13.562] iteration 2224 : model1 loss : 0.054137 model2 loss : 0.094442
[20:38:14.251] iteration 2225 : model1 loss : 0.046726 model2 loss : 0.052659
[20:38:14.934] iteration 2226 : model1 loss : 0.040068 model2 loss : 0.040984
[20:38:15.631] iteration 2227 : model1 loss : 0.043926 model2 loss : 0.046996
[20:38:16.325] iteration 2228 : model1 loss : 0.046387 model2 loss : 0.043820
[20:38:17.011] iteration 2229 : model1 loss : 0.031592 model2 loss : 0.026610
[20:38:17.701] iteration 2230 : model1 loss : 0.069112 model2 loss : 0.077168
[20:38:18.414] iteration 2231 : model1 loss : 0.034960 model2 loss : 0.031531
[20:38:19.116] iteration 2232 : model1 loss : 0.059887 model2 loss : 0.051269
[20:38:19.813] iteration 2233 : model1 loss : 0.036754 model2 loss : 0.035777
[20:38:20.506] iteration 2234 : model1 loss : 0.032155 model2 loss : 0.043836
[20:38:21.214] iteration 2235 : model1 loss : 0.064617 model2 loss : 0.049674
[20:38:21.914] iteration 2236 : model1 loss : 0.075363 model2 loss : 0.158646
[20:38:22.620] iteration 2237 : model1 loss : 0.071575 model2 loss : 0.068836
[20:38:23.327] iteration 2238 : model1 loss : 0.095497 model2 loss : 0.103332
[20:38:24.019] iteration 2239 : model1 loss : 0.089045 model2 loss : 0.102884
[20:38:24.704] iteration 2240 : model1 loss : 0.042118 model2 loss : 0.057251
[20:38:25.386] iteration 2241 : model1 loss : 0.127075 model2 loss : 0.129239
[20:38:26.086] iteration 2242 : model1 loss : 0.033106 model2 loss : 0.039077
[20:38:26.779] iteration 2243 : model1 loss : 0.036889 model2 loss : 0.036281
[20:38:27.465] iteration 2244 : model1 loss : 0.138060 model2 loss : 0.099370
[20:38:28.169] iteration 2245 : model1 loss : 0.046239 model2 loss : 0.034296
[20:38:28.870] iteration 2246 : model1 loss : 0.045865 model2 loss : 0.039924
[20:38:29.559] iteration 2247 : model1 loss : 0.057961 model2 loss : 0.047885
[20:38:30.262] iteration 2248 : model1 loss : 0.063720 model2 loss : 0.050643
[20:38:30.956] iteration 2249 : model1 loss : 0.064448 model2 loss : 0.085235
[20:38:31.649] iteration 2250 : model1 loss : 0.050328 model2 loss : 0.054444
[20:38:32.394] iteration 2251 : model1 loss : 0.036707 model2 loss : 0.036098
[20:38:33.074] iteration 2252 : model1 loss : 0.037585 model2 loss : 0.038535
[20:38:33.786] iteration 2253 : model1 loss : 0.031759 model2 loss : 0.034650
[20:38:34.484] iteration 2254 : model1 loss : 0.035135 model2 loss : 0.036775
[20:38:35.181] iteration 2255 : model1 loss : 0.036870 model2 loss : 0.043296
[20:38:35.890] iteration 2256 : model1 loss : 0.041383 model2 loss : 0.040120
[20:38:36.587] iteration 2257 : model1 loss : 0.059643 model2 loss : 0.092986
[20:38:37.274] iteration 2258 : model1 loss : 0.030528 model2 loss : 0.035303
[20:38:37.973] iteration 2259 : model1 loss : 0.107795 model2 loss : 0.093565
[20:38:38.665] iteration 2260 : model1 loss : 0.047287 model2 loss : 0.036473
[20:38:39.340] iteration 2261 : model1 loss : 0.050234 model2 loss : 0.066337
[20:38:40.043] iteration 2262 : model1 loss : 0.043838 model2 loss : 0.051550
[20:38:40.751] iteration 2263 : model1 loss : 0.039718 model2 loss : 0.036593
[20:38:41.459] iteration 2264 : model1 loss : 0.036619 model2 loss : 0.036171
[20:38:42.154] iteration 2265 : model1 loss : 0.029829 model2 loss : 0.036006
[20:38:42.837] iteration 2266 : model1 loss : 0.031693 model2 loss : 0.037636
[20:38:43.529] iteration 2267 : model1 loss : 0.164160 model2 loss : 0.163774
[20:38:44.205] iteration 2268 : model1 loss : 0.035984 model2 loss : 0.038530
[20:38:44.890] iteration 2269 : model1 loss : 0.031578 model2 loss : 0.035207
[20:38:45.581] iteration 2270 : model1 loss : 0.034788 model2 loss : 0.031319
[20:38:46.266] iteration 2271 : model1 loss : 0.059546 model2 loss : 0.058487
[20:38:46.956] iteration 2272 : model1 loss : 0.071619 model2 loss : 0.026464
[20:38:47.655] iteration 2273 : model1 loss : 0.071405 model2 loss : 0.086647
[20:38:48.336] iteration 2274 : model1 loss : 0.071929 model2 loss : 0.068702
[20:38:49.052] iteration 2275 : model1 loss : 0.045721 model2 loss : 0.050400
[20:38:49.737] iteration 2276 : model1 loss : 0.067391 model2 loss : 0.061433
[20:38:50.429] iteration 2277 : model1 loss : 0.032029 model2 loss : 0.031340
[20:38:51.116] iteration 2278 : model1 loss : 0.067090 model2 loss : 0.057068
[20:38:51.800] iteration 2279 : model1 loss : 0.053412 model2 loss : 0.048302
[20:38:52.497] iteration 2280 : model1 loss : 0.035220 model2 loss : 0.047253
[20:38:53.183] iteration 2281 : model1 loss : 0.078739 model2 loss : 0.081101
[20:38:53.876] iteration 2282 : model1 loss : 0.065951 model2 loss : 0.138696
[20:38:54.585] iteration 2283 : model1 loss : 0.027404 model2 loss : 0.028852
[20:38:55.282] iteration 2284 : model1 loss : 0.082088 model2 loss : 0.068606
[20:38:55.960] iteration 2285 : model1 loss : 0.137646 model2 loss : 0.156167
[20:38:56.662] iteration 2286 : model1 loss : 0.139473 model2 loss : 0.150990
[20:38:57.365] iteration 2287 : model1 loss : 0.046486 model2 loss : 0.042649
[20:38:58.043] iteration 2288 : model1 loss : 0.054155 model2 loss : 0.030914
[20:38:58.755] iteration 2289 : model1 loss : 0.056051 model2 loss : 0.063982
[20:38:59.450] iteration 2290 : model1 loss : 0.037537 model2 loss : 0.039509
[20:39:00.149] iteration 2291 : model1 loss : 0.037057 model2 loss : 0.034604
[20:39:00.838] iteration 2292 : model1 loss : 0.076340 model2 loss : 0.078178
[20:39:01.555] iteration 2293 : model1 loss : 0.049999 model2 loss : 0.062713
[20:39:02.264] iteration 2294 : model1 loss : 0.042485 model2 loss : 0.040212
[20:39:02.963] iteration 2295 : model1 loss : 0.080005 model2 loss : 0.086711
[20:39:03.650] iteration 2296 : model1 loss : 0.050458 model2 loss : 0.040955
[20:39:04.353] iteration 2297 : model1 loss : 0.061137 model2 loss : 0.102115
[20:39:05.052] iteration 2298 : model1 loss : 0.050178 model2 loss : 0.054069
[20:39:05.755] iteration 2299 : model1 loss : 0.041118 model2 loss : 0.056930
[20:39:06.442] iteration 2300 : model1 loss : 0.044000 model2 loss : 0.048840
[20:39:07.195] iteration 2301 : model1 loss : 0.045178 model2 loss : 0.047804
[20:39:07.893] iteration 2302 : model1 loss : 0.074319 model2 loss : 0.066860
[20:39:08.585] iteration 2303 : model1 loss : 0.033804 model2 loss : 0.029130
[20:39:09.285] iteration 2304 : model1 loss : 0.030020 model2 loss : 0.032330
[20:39:09.974] iteration 2305 : model1 loss : 0.182921 model2 loss : 0.175649
[20:39:10.657] iteration 2306 : model1 loss : 0.168206 model2 loss : 0.182096
[20:39:11.367] iteration 2307 : model1 loss : 0.036405 model2 loss : 0.042180
[20:39:12.064] iteration 2308 : model1 loss : 0.149061 model2 loss : 0.097980
[20:39:12.763] iteration 2309 : model1 loss : 0.046810 model2 loss : 0.053187
[20:39:13.464] iteration 2310 : model1 loss : 0.043027 model2 loss : 0.039377
[20:39:14.160] iteration 2311 : model1 loss : 0.065451 model2 loss : 0.049168
[20:39:14.858] iteration 2312 : model1 loss : 0.044902 model2 loss : 0.055243
[20:39:15.566] iteration 2313 : model1 loss : 0.044348 model2 loss : 0.048761
[20:39:16.267] iteration 2314 : model1 loss : 0.039919 model2 loss : 0.045701
[20:39:16.965] iteration 2315 : model1 loss : 0.046084 model2 loss : 0.040386
[20:39:17.655] iteration 2316 : model1 loss : 0.100248 model2 loss : 0.076415
[20:39:18.358] iteration 2317 : model1 loss : 0.045173 model2 loss : 0.056389
[20:39:19.060] iteration 2318 : model1 loss : 0.061656 model2 loss : 0.071149
[20:39:19.749] iteration 2319 : model1 loss : 0.047481 model2 loss : 0.046619
[20:39:20.446] iteration 2320 : model1 loss : 0.067935 model2 loss : 0.052835
[20:39:21.148] iteration 2321 : model1 loss : 0.040515 model2 loss : 0.037958
[20:39:21.843] iteration 2322 : model1 loss : 0.031340 model2 loss : 0.038979
[20:39:22.532] iteration 2323 : model1 loss : 0.057202 model2 loss : 0.044504
[20:39:23.231] iteration 2324 : model1 loss : 0.136309 model2 loss : 0.126184
[20:39:23.918] iteration 2325 : model1 loss : 0.046030 model2 loss : 0.050334
[20:39:24.609] iteration 2326 : model1 loss : 0.030302 model2 loss : 0.028769
[20:39:25.315] iteration 2327 : model1 loss : 0.071948 model2 loss : 0.046672
[20:39:26.004] iteration 2328 : model1 loss : 0.035095 model2 loss : 0.028371
[20:39:26.695] iteration 2329 : model1 loss : 0.061397 model2 loss : 0.059728
[20:39:27.396] iteration 2330 : model1 loss : 0.058900 model2 loss : 0.048536
[20:39:28.094] iteration 2331 : model1 loss : 0.069363 model2 loss : 0.051277
[20:39:28.789] iteration 2332 : model1 loss : 0.067297 model2 loss : 0.041696
[20:39:29.484] iteration 2333 : model1 loss : 0.043122 model2 loss : 0.049577
[20:39:30.173] iteration 2334 : model1 loss : 0.039096 model2 loss : 0.049792
[20:39:30.893] iteration 2335 : model1 loss : 0.043382 model2 loss : 0.141048
[20:39:31.600] iteration 2336 : model1 loss : 0.046062 model2 loss : 0.055741
[20:39:32.282] iteration 2337 : model1 loss : 0.041253 model2 loss : 0.049834
[20:39:32.978] iteration 2338 : model1 loss : 0.074508 model2 loss : 0.080311
[20:39:33.671] iteration 2339 : model1 loss : 0.040947 model2 loss : 0.041159
[20:39:34.361] iteration 2340 : model1 loss : 0.049745 model2 loss : 0.050173
[20:39:35.052] iteration 2341 : model1 loss : 0.035833 model2 loss : 0.040504
[20:39:35.738] iteration 2342 : model1 loss : 0.069463 model2 loss : 0.040290
[20:39:36.438] iteration 2343 : model1 loss : 0.085693 model2 loss : 0.085218
[20:39:37.113] iteration 2344 : model1 loss : 0.086634 model2 loss : 0.085080
[20:39:37.810] iteration 2345 : model1 loss : 0.043280 model2 loss : 0.063691
[20:39:38.521] iteration 2346 : model1 loss : 0.048965 model2 loss : 0.049237
[20:39:39.195] iteration 2347 : model1 loss : 0.038879 model2 loss : 0.050896
[20:39:39.936] iteration 2348 : model1 loss : 0.063136 model2 loss : 0.053375
[20:39:40.622] iteration 2349 : model1 loss : 0.044542 model2 loss : 0.050231
[20:39:41.319] iteration 2350 : model1 loss : 0.110657 model2 loss : 0.081094
[20:39:42.087] iteration 2351 : model1 loss : 0.056606 model2 loss : 0.038221
[20:39:42.779] iteration 2352 : model1 loss : 0.078231 model2 loss : 0.063230
[20:39:43.464] iteration 2353 : model1 loss : 0.063431 model2 loss : 0.055798
[20:39:44.162] iteration 2354 : model1 loss : 0.044797 model2 loss : 0.050077
[20:39:44.855] iteration 2355 : model1 loss : 0.041793 model2 loss : 0.035956
[20:39:45.557] iteration 2356 : model1 loss : 0.030511 model2 loss : 0.028550
[20:39:46.238] iteration 2357 : model1 loss : 0.047162 model2 loss : 0.044045
[20:39:46.919] iteration 2358 : model1 loss : 0.066115 model2 loss : 0.046406
[20:39:47.615] iteration 2359 : model1 loss : 0.117943 model2 loss : 0.068816
[20:39:48.310] iteration 2360 : model1 loss : 0.030988 model2 loss : 0.025762
[20:39:49.002] iteration 2361 : model1 loss : 0.044842 model2 loss : 0.061646
[20:39:49.703] iteration 2362 : model1 loss : 0.045336 model2 loss : 0.037291
[20:39:50.399] iteration 2363 : model1 loss : 0.104543 model2 loss : 0.051420
[20:39:51.082] iteration 2364 : model1 loss : 0.110992 model2 loss : 0.075687
[20:39:51.785] iteration 2365 : model1 loss : 0.061763 model2 loss : 0.042676
[20:39:52.507] iteration 2366 : model1 loss : 0.029074 model2 loss : 0.033748
[20:39:53.205] iteration 2367 : model1 loss : 0.051465 model2 loss : 0.056535
[20:39:53.889] iteration 2368 : model1 loss : 0.062612 model2 loss : 0.058750
[20:39:54.583] iteration 2369 : model1 loss : 0.062941 model2 loss : 0.067174
[20:39:55.274] iteration 2370 : model1 loss : 0.036368 model2 loss : 0.048121
[20:39:55.955] iteration 2371 : model1 loss : 0.045711 model2 loss : 0.035741
[20:39:56.656] iteration 2372 : model1 loss : 0.149875 model2 loss : 0.087559
[20:39:57.354] iteration 2373 : model1 loss : 0.035215 model2 loss : 0.040473
[20:39:58.039] iteration 2374 : model1 loss : 0.035862 model2 loss : 0.035357
[20:39:58.742] iteration 2375 : model1 loss : 0.044298 model2 loss : 0.038343
[20:39:59.428] iteration 2376 : model1 loss : 0.045824 model2 loss : 0.040553
[20:40:00.117] iteration 2377 : model1 loss : 0.039923 model2 loss : 0.036302
[20:40:00.816] iteration 2378 : model1 loss : 0.059130 model2 loss : 0.047449
[20:40:01.518] iteration 2379 : model1 loss : 0.063110 model2 loss : 0.056500
[20:40:02.215] iteration 2380 : model1 loss : 0.075552 model2 loss : 0.056272
[20:40:02.910] iteration 2381 : model1 loss : 0.061304 model2 loss : 0.055111
[20:40:03.610] iteration 2382 : model1 loss : 0.038586 model2 loss : 0.029304
[20:40:04.316] iteration 2383 : model1 loss : 0.040802 model2 loss : 0.038820
[20:40:05.018] iteration 2384 : model1 loss : 0.038946 model2 loss : 0.032044
[20:40:05.709] iteration 2385 : model1 loss : 0.054957 model2 loss : 0.039085
[20:40:06.397] iteration 2386 : model1 loss : 0.052336 model2 loss : 0.050959
[20:40:07.090] iteration 2387 : model1 loss : 0.084923 model2 loss : 0.092069
[20:40:07.791] iteration 2388 : model1 loss : 0.109136 model2 loss : 0.119382
[20:40:08.508] iteration 2389 : model1 loss : 0.057400 model2 loss : 0.041356
[20:40:09.239] iteration 2390 : model1 loss : 0.102184 model2 loss : 0.093455
[20:40:09.964] iteration 2391 : model1 loss : 0.040174 model2 loss : 0.032373
[20:40:10.684] iteration 2392 : model1 loss : 0.070349 model2 loss : 0.053655
[20:40:11.418] iteration 2393 : model1 loss : 0.066423 model2 loss : 0.051097
[20:40:12.173] iteration 2394 : model1 loss : 0.112479 model2 loss : 0.105766
[20:40:12.902] iteration 2395 : model1 loss : 0.045726 model2 loss : 0.045306
[20:40:13.643] iteration 2396 : model1 loss : 0.093362 model2 loss : 0.113888
[20:40:14.440] iteration 2397 : model1 loss : 0.060380 model2 loss : 0.057023
[20:40:15.139] iteration 2398 : model1 loss : 0.142805 model2 loss : 0.092824
[20:40:15.841] iteration 2399 : model1 loss : 0.109267 model2 loss : 0.068325
[20:40:16.545] iteration 2400 : model1 loss : 0.032862 model2 loss : 0.041717
[20:40:36.391] iteration 2400 : model1_mean_dice : 0.758913 model1_mean_hd95 : 11.012864
[20:40:55.977] iteration 2400 : model2_mean_dice : 0.773888 model2_mean_hd95 : 17.330133
[20:40:56.693] iteration 2401 : model1 loss : 0.053169 model2 loss : 0.047591
[20:40:57.384] iteration 2402 : model1 loss : 0.057962 model2 loss : 0.057056
[20:40:58.070] iteration 2403 : model1 loss : 0.032664 model2 loss : 0.031762
[20:40:58.758] iteration 2404 : model1 loss : 0.053408 model2 loss : 0.067881
[20:40:59.447] iteration 2405 : model1 loss : 0.057387 model2 loss : 0.054050
[20:41:00.150] iteration 2406 : model1 loss : 0.040784 model2 loss : 0.037131
[20:41:00.827] iteration 2407 : model1 loss : 0.059094 model2 loss : 0.060642
[20:41:01.516] iteration 2408 : model1 loss : 0.038358 model2 loss : 0.031583
[20:41:02.203] iteration 2409 : model1 loss : 0.031911 model2 loss : 0.035663
[20:41:02.885] iteration 2410 : model1 loss : 0.055339 model2 loss : 0.063558
[20:41:03.561] iteration 2411 : model1 loss : 0.025942 model2 loss : 0.024963
[20:41:04.258] iteration 2412 : model1 loss : 0.039194 model2 loss : 0.034504
[20:41:04.943] iteration 2413 : model1 loss : 0.059921 model2 loss : 0.053291
[20:41:05.630] iteration 2414 : model1 loss : 0.067922 model2 loss : 0.064729
[20:41:06.394] iteration 2415 : model1 loss : 0.053455 model2 loss : 0.050088
[20:41:07.133] iteration 2416 : model1 loss : 0.036770 model2 loss : 0.047424
[20:41:07.834] iteration 2417 : model1 loss : 0.030163 model2 loss : 0.035676
[20:41:08.521] iteration 2418 : model1 loss : 0.045812 model2 loss : 0.056508
[20:41:09.209] iteration 2419 : model1 loss : 0.053690 model2 loss : 0.052134
[20:41:09.895] iteration 2420 : model1 loss : 0.036575 model2 loss : 0.051951
[20:41:10.573] iteration 2421 : model1 loss : 0.041229 model2 loss : 0.043603
[20:41:11.284] iteration 2422 : model1 loss : 0.035839 model2 loss : 0.044589
[20:41:11.978] iteration 2423 : model1 loss : 0.103446 model2 loss : 0.096702
[20:41:12.692] iteration 2424 : model1 loss : 0.028916 model2 loss : 0.033335
[20:41:13.392] iteration 2425 : model1 loss : 0.049795 model2 loss : 0.047925
[20:41:14.076] iteration 2426 : model1 loss : 0.091306 model2 loss : 0.075232
[20:41:14.812] iteration 2427 : model1 loss : 0.064798 model2 loss : 0.080678
[20:41:15.506] iteration 2428 : model1 loss : 0.034878 model2 loss : 0.053801
[20:41:16.211] iteration 2429 : model1 loss : 0.036500 model2 loss : 0.033454
[20:41:16.905] iteration 2430 : model1 loss : 0.051974 model2 loss : 0.071152
[20:41:17.591] iteration 2431 : model1 loss : 0.028787 model2 loss : 0.031858
[20:41:18.288] iteration 2432 : model1 loss : 0.037204 model2 loss : 0.031172
[20:41:18.995] iteration 2433 : model1 loss : 0.070628 model2 loss : 0.083424
[20:41:19.676] iteration 2434 : model1 loss : 0.051386 model2 loss : 0.054249
[20:41:20.357] iteration 2435 : model1 loss : 0.259428 model2 loss : 0.208895
[20:41:21.052] iteration 2436 : model1 loss : 0.038504 model2 loss : 0.064139
[20:41:21.741] iteration 2437 : model1 loss : 0.118481 model2 loss : 0.118454
[20:41:22.434] iteration 2438 : model1 loss : 0.158721 model2 loss : 0.138509
[20:41:23.128] iteration 2439 : model1 loss : 0.053882 model2 loss : 0.052260
[20:41:23.828] iteration 2440 : model1 loss : 0.031339 model2 loss : 0.037019
[20:41:24.524] iteration 2441 : model1 loss : 0.059714 model2 loss : 0.066650
[20:41:25.214] iteration 2442 : model1 loss : 0.069482 model2 loss : 0.060023
[20:41:25.913] iteration 2443 : model1 loss : 0.063879 model2 loss : 0.048294
[20:41:26.600] iteration 2444 : model1 loss : 0.073096 model2 loss : 0.071720
[20:41:27.289] iteration 2445 : model1 loss : 0.053596 model2 loss : 0.107602
[20:41:27.996] iteration 2446 : model1 loss : 0.046679 model2 loss : 0.071613
[20:41:28.689] iteration 2447 : model1 loss : 0.041896 model2 loss : 0.043550
[20:41:29.387] iteration 2448 : model1 loss : 0.051296 model2 loss : 0.048387
[20:41:30.075] iteration 2449 : model1 loss : 0.120614 model2 loss : 0.118468
[20:41:30.776] iteration 2450 : model1 loss : 0.070310 model2 loss : 0.088275
[20:41:31.541] iteration 2451 : model1 loss : 0.063118 model2 loss : 0.052150
[20:41:32.229] iteration 2452 : model1 loss : 0.083567 model2 loss : 0.094233
[20:41:32.944] iteration 2453 : model1 loss : 0.060663 model2 loss : 0.044236
[20:41:33.643] iteration 2454 : model1 loss : 0.039050 model2 loss : 0.035993
[20:41:34.332] iteration 2455 : model1 loss : 0.051182 model2 loss : 0.044287
[20:41:35.022] iteration 2456 : model1 loss : 0.091517 model2 loss : 0.096315
[20:41:35.715] iteration 2457 : model1 loss : 0.138557 model2 loss : 0.172951
[20:41:36.401] iteration 2458 : model1 loss : 0.061699 model2 loss : 0.055209
[20:41:37.090] iteration 2459 : model1 loss : 0.063146 model2 loss : 0.060406
[20:41:37.793] iteration 2460 : model1 loss : 0.042192 model2 loss : 0.041994
[20:41:38.483] iteration 2461 : model1 loss : 0.043511 model2 loss : 0.035404
[20:41:39.165] iteration 2462 : model1 loss : 0.075234 model2 loss : 0.068556
[20:41:39.888] iteration 2463 : model1 loss : 0.044662 model2 loss : 0.046790
[20:41:40.600] iteration 2464 : model1 loss : 0.101464 model2 loss : 0.098604
[20:41:41.305] iteration 2465 : model1 loss : 0.097938 model2 loss : 0.124031
[20:41:42.031] iteration 2466 : model1 loss : 0.044649 model2 loss : 0.048859
[20:41:42.741] iteration 2467 : model1 loss : 0.065639 model2 loss : 0.061485
[20:41:43.434] iteration 2468 : model1 loss : 0.052856 model2 loss : 0.045852
[20:41:44.119] iteration 2469 : model1 loss : 0.069508 model2 loss : 0.039818
[20:41:44.818] iteration 2470 : model1 loss : 0.070448 model2 loss : 0.059181
[20:41:45.516] iteration 2471 : model1 loss : 0.034574 model2 loss : 0.036901
[20:41:46.211] iteration 2472 : model1 loss : 0.050469 model2 loss : 0.051796
[20:41:46.901] iteration 2473 : model1 loss : 0.044584 model2 loss : 0.045259
[20:41:47.606] iteration 2474 : model1 loss : 0.046768 model2 loss : 0.040544
[20:41:48.296] iteration 2475 : model1 loss : 0.050081 model2 loss : 0.039305
[20:41:48.967] iteration 2476 : model1 loss : 0.050533 model2 loss : 0.044527
[20:41:49.657] iteration 2477 : model1 loss : 0.057588 model2 loss : 0.081006
[20:41:50.356] iteration 2478 : model1 loss : 0.049831 model2 loss : 0.037924
[20:41:51.045] iteration 2479 : model1 loss : 0.099079 model2 loss : 0.051781
[20:41:51.753] iteration 2480 : model1 loss : 0.053761 model2 loss : 0.039347
[20:41:52.448] iteration 2481 : model1 loss : 0.037735 model2 loss : 0.033407
[20:41:53.139] iteration 2482 : model1 loss : 0.053639 model2 loss : 0.048768
[20:41:53.826] iteration 2483 : model1 loss : 0.161919 model2 loss : 0.179674
[20:41:54.526] iteration 2484 : model1 loss : 0.043882 model2 loss : 0.042390
[20:41:55.211] iteration 2485 : model1 loss : 0.042045 model2 loss : 0.046372
[20:41:55.890] iteration 2486 : model1 loss : 0.028084 model2 loss : 0.029873
[20:41:56.607] iteration 2487 : model1 loss : 0.057727 model2 loss : 0.052935
[20:41:57.300] iteration 2488 : model1 loss : 0.146629 model2 loss : 0.130166
[20:41:57.995] iteration 2489 : model1 loss : 0.028726 model2 loss : 0.035659
[20:41:58.682] iteration 2490 : model1 loss : 0.077597 model2 loss : 0.085666
[20:41:59.407] iteration 2491 : model1 loss : 0.041824 model2 loss : 0.044876
[20:42:00.117] iteration 2492 : model1 loss : 0.061619 model2 loss : 0.049914
[20:42:00.824] iteration 2493 : model1 loss : 0.065865 model2 loss : 0.048621
[20:42:01.523] iteration 2494 : model1 loss : 0.036666 model2 loss : 0.035958
[20:42:02.209] iteration 2495 : model1 loss : 0.030328 model2 loss : 0.032639
[20:42:02.907] iteration 2496 : model1 loss : 0.047142 model2 loss : 0.049350
[20:42:03.604] iteration 2497 : model1 loss : 0.056789 model2 loss : 0.036568
[20:42:04.304] iteration 2498 : model1 loss : 0.032771 model2 loss : 0.043165
[20:42:04.996] iteration 2499 : model1 loss : 0.054971 model2 loss : 0.045126
[20:42:05.680] iteration 2500 : model1 loss : 0.104068 model2 loss : 0.089937
[20:42:06.429] iteration 2501 : model1 loss : 0.038902 model2 loss : 0.044953
[20:42:07.117] iteration 2502 : model1 loss : 0.044224 model2 loss : 0.102149
[20:42:07.807] iteration 2503 : model1 loss : 0.038600 model2 loss : 0.065763
[20:42:08.495] iteration 2504 : model1 loss : 0.053363 model2 loss : 0.063497
[20:42:09.266] iteration 2505 : model1 loss : 0.059343 model2 loss : 0.065861
[20:42:09.991] iteration 2506 : model1 loss : 0.042862 model2 loss : 0.055654
[20:42:10.665] iteration 2507 : model1 loss : 0.040440 model2 loss : 0.048821
[20:42:11.359] iteration 2508 : model1 loss : 0.030632 model2 loss : 0.038849
[20:42:12.052] iteration 2509 : model1 loss : 0.045097 model2 loss : 0.052997
[20:42:12.735] iteration 2510 : model1 loss : 0.068486 model2 loss : 0.078848
[20:42:13.436] iteration 2511 : model1 loss : 0.024905 model2 loss : 0.028475
[20:42:14.130] iteration 2512 : model1 loss : 0.023116 model2 loss : 0.026863
[20:42:14.829] iteration 2513 : model1 loss : 0.031760 model2 loss : 0.034109
[20:42:15.527] iteration 2514 : model1 loss : 0.074568 model2 loss : 0.056785
[20:42:16.239] iteration 2515 : model1 loss : 0.034764 model2 loss : 0.045303
[20:42:16.940] iteration 2516 : model1 loss : 0.036856 model2 loss : 0.035433
[20:42:17.633] iteration 2517 : model1 loss : 0.089926 model2 loss : 0.141300
[20:42:18.334] iteration 2518 : model1 loss : 0.041745 model2 loss : 0.073536
[20:42:19.035] iteration 2519 : model1 loss : 0.047786 model2 loss : 0.046805
[20:42:19.714] iteration 2520 : model1 loss : 0.050843 model2 loss : 0.061813
[20:42:20.402] iteration 2521 : model1 loss : 0.043387 model2 loss : 0.072446
[20:42:21.100] iteration 2522 : model1 loss : 0.046351 model2 loss : 0.064001
[20:42:21.784] iteration 2523 : model1 loss : 0.039834 model2 loss : 0.092660
[20:42:22.483] iteration 2524 : model1 loss : 0.035858 model2 loss : 0.055076
[20:42:23.180] iteration 2525 : model1 loss : 0.027040 model2 loss : 0.029776
[20:42:23.862] iteration 2526 : model1 loss : 0.038117 model2 loss : 0.045762
[20:42:24.552] iteration 2527 : model1 loss : 0.070476 model2 loss : 0.062761
[20:42:25.234] iteration 2528 : model1 loss : 0.051454 model2 loss : 0.053789
[20:42:25.921] iteration 2529 : model1 loss : 0.061009 model2 loss : 0.068422
[20:42:26.617] iteration 2530 : model1 loss : 0.046446 model2 loss : 0.051553
[20:42:27.298] iteration 2531 : model1 loss : 0.036424 model2 loss : 0.040019
[20:42:27.996] iteration 2532 : model1 loss : 0.050500 model2 loss : 0.052408
[20:42:28.688] iteration 2533 : model1 loss : 0.142062 model2 loss : 0.068196
[20:42:29.373] iteration 2534 : model1 loss : 0.029009 model2 loss : 0.039504
[20:42:30.069] iteration 2535 : model1 loss : 0.072560 model2 loss : 0.043910
[20:42:30.777] iteration 2536 : model1 loss : 0.053449 model2 loss : 0.046579
[20:42:31.465] iteration 2537 : model1 loss : 0.105666 model2 loss : 0.111619
[20:42:32.145] iteration 2538 : model1 loss : 0.036158 model2 loss : 0.032419
[20:42:32.849] iteration 2539 : model1 loss : 0.044996 model2 loss : 0.040207
[20:42:33.545] iteration 2540 : model1 loss : 0.031086 model2 loss : 0.033264
[20:42:34.227] iteration 2541 : model1 loss : 0.034182 model2 loss : 0.056800
[20:42:34.905] iteration 2542 : model1 loss : 0.045304 model2 loss : 0.038791
[20:42:35.592] iteration 2543 : model1 loss : 0.037257 model2 loss : 0.042070
[20:42:36.289] iteration 2544 : model1 loss : 0.073523 model2 loss : 0.072899
[20:42:36.963] iteration 2545 : model1 loss : 0.077544 model2 loss : 0.066887
[20:42:37.653] iteration 2546 : model1 loss : 0.035810 model2 loss : 0.039942
[20:42:38.363] iteration 2547 : model1 loss : 0.044807 model2 loss : 0.042162
[20:42:39.051] iteration 2548 : model1 loss : 0.139655 model2 loss : 0.138586
[20:42:39.744] iteration 2549 : model1 loss : 0.031217 model2 loss : 0.037629
[20:42:40.445] iteration 2550 : model1 loss : 0.105239 model2 loss : 0.132789
[20:42:41.195] iteration 2551 : model1 loss : 0.054501 model2 loss : 0.078435
[20:42:41.889] iteration 2552 : model1 loss : 0.048296 model2 loss : 0.046279
[20:42:42.597] iteration 2553 : model1 loss : 0.039276 model2 loss : 0.036801
[20:42:43.306] iteration 2554 : model1 loss : 0.037683 model2 loss : 0.030468
[20:42:43.982] iteration 2555 : model1 loss : 0.124555 model2 loss : 0.151892
[20:42:44.677] iteration 2556 : model1 loss : 0.049764 model2 loss : 0.064135
[20:42:45.373] iteration 2557 : model1 loss : 0.162016 model2 loss : 0.159579
[20:42:46.069] iteration 2558 : model1 loss : 0.043512 model2 loss : 0.046878
[20:42:46.765] iteration 2559 : model1 loss : 0.049589 model2 loss : 0.052502
[20:42:47.462] iteration 2560 : model1 loss : 0.056774 model2 loss : 0.040247
[20:42:48.138] iteration 2561 : model1 loss : 0.030769 model2 loss : 0.039164
[20:42:48.824] iteration 2562 : model1 loss : 0.059532 model2 loss : 0.072569
[20:42:49.520] iteration 2563 : model1 loss : 0.033215 model2 loss : 0.033460
[20:42:50.231] iteration 2564 : model1 loss : 0.041815 model2 loss : 0.030478
[20:42:50.926] iteration 2565 : model1 loss : 0.054276 model2 loss : 0.069492
[20:42:51.623] iteration 2566 : model1 loss : 0.046948 model2 loss : 0.046857
[20:42:52.336] iteration 2567 : model1 loss : 0.056565 model2 loss : 0.070096
[20:42:53.024] iteration 2568 : model1 loss : 0.024495 model2 loss : 0.027740
[20:42:53.717] iteration 2569 : model1 loss : 0.026349 model2 loss : 0.031835
[20:42:54.417] iteration 2570 : model1 loss : 0.030789 model2 loss : 0.043721
[20:42:55.125] iteration 2571 : model1 loss : 0.057191 model2 loss : 0.067802
[20:42:55.812] iteration 2572 : model1 loss : 0.038661 model2 loss : 0.036482
[20:42:56.517] iteration 2573 : model1 loss : 0.089909 model2 loss : 0.120817
[20:42:57.211] iteration 2574 : model1 loss : 0.028226 model2 loss : 0.027509
[20:42:57.913] iteration 2575 : model1 loss : 0.042028 model2 loss : 0.044189
[20:42:58.619] iteration 2576 : model1 loss : 0.059015 model2 loss : 0.050082
[20:42:59.311] iteration 2577 : model1 loss : 0.045688 model2 loss : 0.053416
[20:43:00.004] iteration 2578 : model1 loss : 0.127634 model2 loss : 0.070857
[20:43:00.696] iteration 2579 : model1 loss : 0.033659 model2 loss : 0.040209
[20:43:01.383] iteration 2580 : model1 loss : 0.038618 model2 loss : 0.032957
[20:43:02.091] iteration 2581 : model1 loss : 0.040613 model2 loss : 0.039187
[20:43:02.797] iteration 2582 : model1 loss : 0.044176 model2 loss : 0.042504
[20:43:03.492] iteration 2583 : model1 loss : 0.056137 model2 loss : 0.038976
[20:43:04.179] iteration 2584 : model1 loss : 0.038956 model2 loss : 0.042209
[20:43:04.875] iteration 2585 : model1 loss : 0.061343 model2 loss : 0.067870
[20:43:05.572] iteration 2586 : model1 loss : 0.062755 model2 loss : 0.040146
[20:43:06.264] iteration 2587 : model1 loss : 0.063609 model2 loss : 0.059747
[20:43:06.963] iteration 2588 : model1 loss : 0.052464 model2 loss : 0.062270
[20:43:07.658] iteration 2589 : model1 loss : 0.046616 model2 loss : 0.039826
[20:43:08.345] iteration 2590 : model1 loss : 0.086986 model2 loss : 0.068496
[20:43:09.059] iteration 2591 : model1 loss : 0.032706 model2 loss : 0.033029
[20:43:09.745] iteration 2592 : model1 loss : 0.048908 model2 loss : 0.041555
[20:43:10.447] iteration 2593 : model1 loss : 0.064373 model2 loss : 0.051172
[20:43:11.145] iteration 2594 : model1 loss : 0.025489 model2 loss : 0.026988
[20:43:11.836] iteration 2595 : model1 loss : 0.131880 model2 loss : 0.132462
[20:43:12.547] iteration 2596 : model1 loss : 0.089717 model2 loss : 0.086469
[20:43:13.245] iteration 2597 : model1 loss : 0.044536 model2 loss : 0.049993
[20:43:13.950] iteration 2598 : model1 loss : 0.041403 model2 loss : 0.034525
[20:43:14.652] iteration 2599 : model1 loss : 0.046015 model2 loss : 0.031206
[20:43:15.356] iteration 2600 : model1 loss : 0.047085 model2 loss : 0.048276
[20:43:35.331] iteration 2600 : model1_mean_dice : 0.804758 model1_mean_hd95 : 16.796239
[20:43:54.958] iteration 2600 : model2_mean_dice : 0.817636 model2_mean_hd95 : 9.381317
[20:43:55.686] iteration 2601 : model1 loss : 0.031066 model2 loss : 0.042701
[20:43:56.390] iteration 2602 : model1 loss : 0.063982 model2 loss : 0.072963
[20:43:57.070] iteration 2603 : model1 loss : 0.053577 model2 loss : 0.069948
[20:43:57.747] iteration 2604 : model1 loss : 0.054572 model2 loss : 0.056464
[20:43:58.434] iteration 2605 : model1 loss : 0.043319 model2 loss : 0.049535
[20:43:59.131] iteration 2606 : model1 loss : 0.079475 model2 loss : 0.083914
[20:43:59.822] iteration 2607 : model1 loss : 0.078209 model2 loss : 0.053934
[20:44:00.504] iteration 2608 : model1 loss : 0.046991 model2 loss : 0.063857
[20:44:01.187] iteration 2609 : model1 loss : 0.025303 model2 loss : 0.028082
[20:44:01.882] iteration 2610 : model1 loss : 0.052351 model2 loss : 0.044374
[20:44:02.596] iteration 2611 : model1 loss : 0.050495 model2 loss : 0.048844
[20:44:03.276] iteration 2612 : model1 loss : 0.089006 model2 loss : 0.045054
[20:44:03.986] iteration 2613 : model1 loss : 0.032686 model2 loss : 0.035702
[20:44:04.692] iteration 2614 : model1 loss : 0.053264 model2 loss : 0.046116
[20:44:05.376] iteration 2615 : model1 loss : 0.031243 model2 loss : 0.035618
[20:44:06.054] iteration 2616 : model1 loss : 0.031488 model2 loss : 0.036614
[20:44:06.744] iteration 2617 : model1 loss : 0.044137 model2 loss : 0.047304
[20:44:07.438] iteration 2618 : model1 loss : 0.046958 model2 loss : 0.038642
[20:44:08.113] iteration 2619 : model1 loss : 0.041347 model2 loss : 0.041185
[20:44:08.794] iteration 2620 : model1 loss : 0.078130 model2 loss : 0.060966
[20:44:09.492] iteration 2621 : model1 loss : 0.029318 model2 loss : 0.036737
[20:44:10.179] iteration 2622 : model1 loss : 0.056233 model2 loss : 0.070202
[20:44:10.858] iteration 2623 : model1 loss : 0.043196 model2 loss : 0.050642
[20:44:11.556] iteration 2624 : model1 loss : 0.053361 model2 loss : 0.048126
[20:44:12.259] iteration 2625 : model1 loss : 0.057205 model2 loss : 0.039895
[20:44:12.938] iteration 2626 : model1 loss : 0.032921 model2 loss : 0.029244
[20:44:13.633] iteration 2627 : model1 loss : 0.044652 model2 loss : 0.040571
[20:44:14.332] iteration 2628 : model1 loss : 0.034731 model2 loss : 0.032880
[20:44:15.017] iteration 2629 : model1 loss : 0.043775 model2 loss : 0.032187
[20:44:15.707] iteration 2630 : model1 loss : 0.031169 model2 loss : 0.032455
[20:44:16.422] iteration 2631 : model1 loss : 0.037930 model2 loss : 0.041339
[20:44:17.128] iteration 2632 : model1 loss : 0.049901 model2 loss : 0.062698
[20:44:17.813] iteration 2633 : model1 loss : 0.048979 model2 loss : 0.046289
[20:44:18.498] iteration 2634 : model1 loss : 0.041721 model2 loss : 0.036416
[20:44:19.188] iteration 2635 : model1 loss : 0.044008 model2 loss : 0.045585
[20:44:19.882] iteration 2636 : model1 loss : 0.033573 model2 loss : 0.045299
[20:44:20.556] iteration 2637 : model1 loss : 0.034495 model2 loss : 0.037643
[20:44:21.260] iteration 2638 : model1 loss : 0.097951 model2 loss : 0.069274
[20:44:21.945] iteration 2639 : model1 loss : 0.050652 model2 loss : 0.051453
[20:44:22.644] iteration 2640 : model1 loss : 0.037231 model2 loss : 0.033934
[20:44:23.352] iteration 2641 : model1 loss : 0.052099 model2 loss : 0.046164
[20:44:24.042] iteration 2642 : model1 loss : 0.067130 model2 loss : 0.083293
[20:44:24.742] iteration 2643 : model1 loss : 0.085198 model2 loss : 0.073346
[20:44:25.423] iteration 2644 : model1 loss : 0.051143 model2 loss : 0.085078
[20:44:26.102] iteration 2645 : model1 loss : 0.062863 model2 loss : 0.063682
[20:44:26.789] iteration 2646 : model1 loss : 0.027197 model2 loss : 0.028998
[20:44:27.466] iteration 2647 : model1 loss : 0.039275 model2 loss : 0.034183
[20:44:28.161] iteration 2648 : model1 loss : 0.042717 model2 loss : 0.043502
[20:44:28.845] iteration 2649 : model1 loss : 0.090629 model2 loss : 0.056238
[20:44:29.527] iteration 2650 : model1 loss : 0.050232 model2 loss : 0.048391
[20:44:30.265] iteration 2651 : model1 loss : 0.028385 model2 loss : 0.029655
[20:44:30.954] iteration 2652 : model1 loss : 0.026959 model2 loss : 0.033347
[20:44:31.647] iteration 2653 : model1 loss : 0.029151 model2 loss : 0.031488
[20:44:32.336] iteration 2654 : model1 loss : 0.037543 model2 loss : 0.040950
[20:44:33.033] iteration 2655 : model1 loss : 0.064369 model2 loss : 0.057836
[20:44:33.726] iteration 2656 : model1 loss : 0.081393 model2 loss : 0.095147
[20:44:34.417] iteration 2657 : model1 loss : 0.046047 model2 loss : 0.046795
[20:44:35.103] iteration 2658 : model1 loss : 0.039703 model2 loss : 0.043489
[20:44:35.799] iteration 2659 : model1 loss : 0.039087 model2 loss : 0.030194
[20:44:36.487] iteration 2660 : model1 loss : 0.026998 model2 loss : 0.032015
[20:44:37.182] iteration 2661 : model1 loss : 0.030530 model2 loss : 0.039593
[20:44:37.880] iteration 2662 : model1 loss : 0.050447 model2 loss : 0.058224
[20:44:38.565] iteration 2663 : model1 loss : 0.031925 model2 loss : 0.032569
[20:44:39.251] iteration 2664 : model1 loss : 0.034939 model2 loss : 0.038340
[20:44:39.971] iteration 2665 : model1 loss : 0.031094 model2 loss : 0.032628
[20:44:40.664] iteration 2666 : model1 loss : 0.034584 model2 loss : 0.037686
[20:44:41.368] iteration 2667 : model1 loss : 0.127231 model2 loss : 0.104530
[20:44:42.063] iteration 2668 : model1 loss : 0.049232 model2 loss : 0.077404
[20:44:42.761] iteration 2669 : model1 loss : 0.030220 model2 loss : 0.032587
[20:44:43.459] iteration 2670 : model1 loss : 0.025821 model2 loss : 0.028022
[20:44:44.149] iteration 2671 : model1 loss : 0.071002 model2 loss : 0.066763
[20:44:44.847] iteration 2672 : model1 loss : 0.060139 model2 loss : 0.047789
[20:44:45.543] iteration 2673 : model1 loss : 0.083056 model2 loss : 0.045077
[20:44:46.222] iteration 2674 : model1 loss : 0.055110 model2 loss : 0.081253
[20:44:46.915] iteration 2675 : model1 loss : 0.040141 model2 loss : 0.044532
[20:44:47.612] iteration 2676 : model1 loss : 0.033319 model2 loss : 0.064239
[20:44:48.316] iteration 2677 : model1 loss : 0.025888 model2 loss : 0.031355
[20:44:49.001] iteration 2678 : model1 loss : 0.147016 model2 loss : 0.070259
[20:44:49.693] iteration 2679 : model1 loss : 0.046574 model2 loss : 0.051829
[20:44:50.389] iteration 2680 : model1 loss : 0.028844 model2 loss : 0.033585
[20:44:51.079] iteration 2681 : model1 loss : 0.095132 model2 loss : 0.103764
[20:44:51.770] iteration 2682 : model1 loss : 0.040739 model2 loss : 0.039391
[20:44:52.517] iteration 2683 : model1 loss : 0.037655 model2 loss : 0.037113
[20:44:53.213] iteration 2684 : model1 loss : 0.060772 model2 loss : 0.058603
[20:44:53.900] iteration 2685 : model1 loss : 0.055464 model2 loss : 0.039596
[20:44:54.604] iteration 2686 : model1 loss : 0.027210 model2 loss : 0.029520
[20:44:55.298] iteration 2687 : model1 loss : 0.061021 model2 loss : 0.073339
[20:44:55.988] iteration 2688 : model1 loss : 0.048270 model2 loss : 0.046400
[20:44:56.701] iteration 2689 : model1 loss : 0.029404 model2 loss : 0.030232
[20:44:57.402] iteration 2690 : model1 loss : 0.041772 model2 loss : 0.046051
[20:44:58.092] iteration 2691 : model1 loss : 0.047552 model2 loss : 0.044599
[20:44:58.789] iteration 2692 : model1 loss : 0.029446 model2 loss : 0.030767
[20:44:59.479] iteration 2693 : model1 loss : 0.064167 model2 loss : 0.033249
[20:45:00.175] iteration 2694 : model1 loss : 0.033644 model2 loss : 0.031022
[20:45:00.862] iteration 2695 : model1 loss : 0.051576 model2 loss : 0.053781
[20:45:01.550] iteration 2696 : model1 loss : 0.055525 model2 loss : 0.049698
[20:45:02.243] iteration 2697 : model1 loss : 0.068311 model2 loss : 0.075366
[20:45:02.933] iteration 2698 : model1 loss : 0.032632 model2 loss : 0.036601
[20:45:03.618] iteration 2699 : model1 loss : 0.036672 model2 loss : 0.049662
[20:45:04.316] iteration 2700 : model1 loss : 0.054819 model2 loss : 0.101139
[20:45:05.073] iteration 2701 : model1 loss : 0.056403 model2 loss : 0.084770
[20:45:05.777] iteration 2702 : model1 loss : 0.022543 model2 loss : 0.026046
[20:45:06.461] iteration 2703 : model1 loss : 0.051972 model2 loss : 0.047947
[20:45:07.149] iteration 2704 : model1 loss : 0.025123 model2 loss : 0.029063
[20:45:07.843] iteration 2705 : model1 loss : 0.028588 model2 loss : 0.034051
[20:45:08.553] iteration 2706 : model1 loss : 0.036325 model2 loss : 0.037181
[20:45:09.266] iteration 2707 : model1 loss : 0.048531 model2 loss : 0.037964
[20:45:09.985] iteration 2708 : model1 loss : 0.040202 model2 loss : 0.097641
[20:45:10.666] iteration 2709 : model1 loss : 0.069638 model2 loss : 0.071921
[20:45:11.358] iteration 2710 : model1 loss : 0.031608 model2 loss : 0.032961
[20:45:12.059] iteration 2711 : model1 loss : 0.031284 model2 loss : 0.029880
[20:45:12.744] iteration 2712 : model1 loss : 0.061207 model2 loss : 0.044708
[20:45:13.449] iteration 2713 : model1 loss : 0.030847 model2 loss : 0.035699
[20:45:14.149] iteration 2714 : model1 loss : 0.045644 model2 loss : 0.068084
[20:45:14.838] iteration 2715 : model1 loss : 0.060139 model2 loss : 0.060804
[20:45:15.532] iteration 2716 : model1 loss : 0.033396 model2 loss : 0.051960
[20:45:16.233] iteration 2717 : model1 loss : 0.029960 model2 loss : 0.029134
[20:45:16.966] iteration 2718 : model1 loss : 0.041954 model2 loss : 0.048638
[20:45:17.656] iteration 2719 : model1 loss : 0.038038 model2 loss : 0.036759
[20:45:18.355] iteration 2720 : model1 loss : 0.042118 model2 loss : 0.044936
[20:45:19.055] iteration 2721 : model1 loss : 0.076151 model2 loss : 0.099299
[20:45:19.746] iteration 2722 : model1 loss : 0.167787 model2 loss : 0.112838
[20:45:20.444] iteration 2723 : model1 loss : 0.031516 model2 loss : 0.036942
[20:45:21.142] iteration 2724 : model1 loss : 0.023362 model2 loss : 0.028136
[20:45:21.843] iteration 2725 : model1 loss : 0.097065 model2 loss : 0.095642
[20:45:22.530] iteration 2726 : model1 loss : 0.026928 model2 loss : 0.030085
[20:45:23.227] iteration 2727 : model1 loss : 0.027259 model2 loss : 0.027637
[20:45:23.919] iteration 2728 : model1 loss : 0.026612 model2 loss : 0.039504
[20:45:24.614] iteration 2729 : model1 loss : 0.056672 model2 loss : 0.096727
[20:45:25.313] iteration 2730 : model1 loss : 0.038692 model2 loss : 0.031753
[20:45:26.001] iteration 2731 : model1 loss : 0.046039 model2 loss : 0.053385
[20:45:26.694] iteration 2732 : model1 loss : 0.142110 model2 loss : 0.116751
[20:45:27.380] iteration 2733 : model1 loss : 0.046433 model2 loss : 0.064338
[20:45:28.072] iteration 2734 : model1 loss : 0.027526 model2 loss : 0.025446
[20:45:28.765] iteration 2735 : model1 loss : 0.051528 model2 loss : 0.080785
[20:45:29.450] iteration 2736 : model1 loss : 0.040012 model2 loss : 0.044609
[20:45:30.144] iteration 2737 : model1 loss : 0.032762 model2 loss : 0.029740
[20:45:30.823] iteration 2738 : model1 loss : 0.031741 model2 loss : 0.028207
[20:45:31.521] iteration 2739 : model1 loss : 0.045934 model2 loss : 0.041511
[20:45:32.238] iteration 2740 : model1 loss : 0.049847 model2 loss : 0.034754
[20:45:32.933] iteration 2741 : model1 loss : 0.041111 model2 loss : 0.043437
[20:45:33.634] iteration 2742 : model1 loss : 0.042000 model2 loss : 0.059872
[20:45:34.336] iteration 2743 : model1 loss : 0.035310 model2 loss : 0.054203
[20:45:35.046] iteration 2744 : model1 loss : 0.160619 model2 loss : 0.177727
[20:45:35.749] iteration 2745 : model1 loss : 0.039646 model2 loss : 0.044104
[20:45:36.437] iteration 2746 : model1 loss : 0.034241 model2 loss : 0.030002
[20:45:37.108] iteration 2747 : model1 loss : 0.030693 model2 loss : 0.035380
[20:45:37.806] iteration 2748 : model1 loss : 0.045561 model2 loss : 0.054165
[20:45:38.505] iteration 2749 : model1 loss : 0.043386 model2 loss : 0.042987
[20:45:39.189] iteration 2750 : model1 loss : 0.033924 model2 loss : 0.035238
[20:45:39.949] iteration 2751 : model1 loss : 0.074606 model2 loss : 0.097758
[20:45:40.643] iteration 2752 : model1 loss : 0.034333 model2 loss : 0.049745
[20:45:41.354] iteration 2753 : model1 loss : 0.036940 model2 loss : 0.032783
[20:45:42.047] iteration 2754 : model1 loss : 0.127473 model2 loss : 0.104789
[20:45:42.746] iteration 2755 : model1 loss : 0.026866 model2 loss : 0.031693
[20:45:43.442] iteration 2756 : model1 loss : 0.183723 model2 loss : 0.171721
[20:45:44.125] iteration 2757 : model1 loss : 0.107610 model2 loss : 0.113756
[20:45:44.816] iteration 2758 : model1 loss : 0.039533 model2 loss : 0.039533
[20:45:45.509] iteration 2759 : model1 loss : 0.031448 model2 loss : 0.034498
[20:45:46.196] iteration 2760 : model1 loss : 0.030699 model2 loss : 0.039952
[20:45:46.888] iteration 2761 : model1 loss : 0.080394 model2 loss : 0.069177
[20:45:47.599] iteration 2762 : model1 loss : 0.042261 model2 loss : 0.074976
[20:45:48.302] iteration 2763 : model1 loss : 0.030055 model2 loss : 0.031197
[20:45:48.989] iteration 2764 : model1 loss : 0.088408 model2 loss : 0.144587
[20:45:49.709] iteration 2765 : model1 loss : 0.032758 model2 loss : 0.045795
[20:45:50.400] iteration 2766 : model1 loss : 0.036987 model2 loss : 0.032234
[20:45:51.108] iteration 2767 : model1 loss : 0.027801 model2 loss : 0.034370
[20:45:51.826] iteration 2768 : model1 loss : 0.029425 model2 loss : 0.036166
[20:45:52.548] iteration 2769 : model1 loss : 0.047857 model2 loss : 0.066953
[20:45:53.245] iteration 2770 : model1 loss : 0.018827 model2 loss : 0.021513
[20:45:53.927] iteration 2771 : model1 loss : 0.043858 model2 loss : 0.036566
[20:45:54.624] iteration 2772 : model1 loss : 0.042726 model2 loss : 0.045691
[20:45:55.326] iteration 2773 : model1 loss : 0.107220 model2 loss : 0.037865
[20:45:56.012] iteration 2774 : model1 loss : 0.046802 model2 loss : 0.062599
[20:45:56.714] iteration 2775 : model1 loss : 0.057777 model2 loss : 0.036877
[20:45:57.444] iteration 2776 : model1 loss : 0.088488 model2 loss : 0.079602
[20:45:58.154] iteration 2777 : model1 loss : 0.042852 model2 loss : 0.053536
[20:45:58.879] iteration 2778 : model1 loss : 0.027401 model2 loss : 0.030705
[20:45:59.590] iteration 2779 : model1 loss : 0.033646 model2 loss : 0.041531
[20:46:00.297] iteration 2780 : model1 loss : 0.055485 model2 loss : 0.058992
[20:46:00.989] iteration 2781 : model1 loss : 0.055758 model2 loss : 0.062630
[20:46:01.692] iteration 2782 : model1 loss : 0.081058 model2 loss : 0.074128
[20:46:02.383] iteration 2783 : model1 loss : 0.152756 model2 loss : 0.128472
[20:46:03.062] iteration 2784 : model1 loss : 0.039148 model2 loss : 0.042892
[20:46:03.752] iteration 2785 : model1 loss : 0.131082 model2 loss : 0.081815
[20:46:04.460] iteration 2786 : model1 loss : 0.032235 model2 loss : 0.036181
[20:46:05.143] iteration 2787 : model1 loss : 0.077224 model2 loss : 0.072214
[20:46:05.828] iteration 2788 : model1 loss : 0.035660 model2 loss : 0.038351
[20:46:06.532] iteration 2789 : model1 loss : 0.041842 model2 loss : 0.044508
[20:46:07.214] iteration 2790 : model1 loss : 0.022776 model2 loss : 0.022278
[20:46:07.897] iteration 2791 : model1 loss : 0.058925 model2 loss : 0.047959
[20:46:08.590] iteration 2792 : model1 loss : 0.027949 model2 loss : 0.033497
[20:46:09.295] iteration 2793 : model1 loss : 0.166904 model2 loss : 0.154200
[20:46:09.990] iteration 2794 : model1 loss : 0.057839 model2 loss : 0.052609
[20:46:10.670] iteration 2795 : model1 loss : 0.121424 model2 loss : 0.087220
[20:46:11.366] iteration 2796 : model1 loss : 0.060737 model2 loss : 0.054849
[20:46:12.079] iteration 2797 : model1 loss : 0.025355 model2 loss : 0.027823
[20:46:12.761] iteration 2798 : model1 loss : 0.064334 model2 loss : 0.103708
[20:46:13.458] iteration 2799 : model1 loss : 0.025059 model2 loss : 0.028817
[20:46:14.158] iteration 2800 : model1 loss : 0.065096 model2 loss : 0.129740
[20:46:33.999] iteration 2800 : model1_mean_dice : 0.826924 model1_mean_hd95 : 6.434235
[20:46:54.502] iteration 2800 : model2_mean_dice : 0.807317 model2_mean_hd95 : 6.908359
[20:46:55.275] iteration 2801 : model1 loss : 0.044115 model2 loss : 0.085052
[20:46:55.973] iteration 2802 : model1 loss : 0.045009 model2 loss : 0.044764
[20:46:56.667] iteration 2803 : model1 loss : 0.046961 model2 loss : 0.048597
[20:46:57.352] iteration 2804 : model1 loss : 0.042576 model2 loss : 0.051972
[20:46:58.033] iteration 2805 : model1 loss : 0.033547 model2 loss : 0.047149
[20:46:58.711] iteration 2806 : model1 loss : 0.051730 model2 loss : 0.063898
[20:46:59.402] iteration 2807 : model1 loss : 0.028778 model2 loss : 0.038193
[20:47:00.077] iteration 2808 : model1 loss : 0.027889 model2 loss : 0.037288
[20:47:00.759] iteration 2809 : model1 loss : 0.059967 model2 loss : 0.064070
[20:47:01.478] iteration 2810 : model1 loss : 0.049306 model2 loss : 0.045651
[20:47:02.163] iteration 2811 : model1 loss : 0.035831 model2 loss : 0.043412
[20:47:02.841] iteration 2812 : model1 loss : 0.046185 model2 loss : 0.068658
[20:47:03.535] iteration 2813 : model1 loss : 0.041466 model2 loss : 0.052811
[20:47:04.217] iteration 2814 : model1 loss : 0.034753 model2 loss : 0.032949
[20:47:04.919] iteration 2815 : model1 loss : 0.025014 model2 loss : 0.045438
[20:47:05.600] iteration 2816 : model1 loss : 0.037605 model2 loss : 0.030037
[20:47:06.285] iteration 2817 : model1 loss : 0.032002 model2 loss : 0.031068
[20:47:06.975] iteration 2818 : model1 loss : 0.045303 model2 loss : 0.052564
[20:47:07.653] iteration 2819 : model1 loss : 0.056555 model2 loss : 0.096304
[20:47:08.342] iteration 2820 : model1 loss : 0.090616 model2 loss : 0.086221
[20:47:09.033] iteration 2821 : model1 loss : 0.029924 model2 loss : 0.042621
[20:47:09.716] iteration 2822 : model1 loss : 0.053955 model2 loss : 0.040080
[20:47:10.397] iteration 2823 : model1 loss : 0.037233 model2 loss : 0.031406
[20:47:11.067] iteration 2824 : model1 loss : 0.038235 model2 loss : 0.037999
[20:47:11.760] iteration 2825 : model1 loss : 0.044478 model2 loss : 0.053037
[20:47:12.458] iteration 2826 : model1 loss : 0.050405 model2 loss : 0.071336
[20:47:13.131] iteration 2827 : model1 loss : 0.038381 model2 loss : 0.040490
[20:47:13.810] iteration 2828 : model1 loss : 0.054188 model2 loss : 0.047804
[20:47:14.493] iteration 2829 : model1 loss : 0.035606 model2 loss : 0.032985
[20:47:15.158] iteration 2830 : model1 loss : 0.061497 model2 loss : 0.071413
[20:47:15.852] iteration 2831 : model1 loss : 0.024752 model2 loss : 0.024042
[20:47:16.541] iteration 2832 : model1 loss : 0.033746 model2 loss : 0.029212
[20:47:17.226] iteration 2833 : model1 loss : 0.101959 model2 loss : 0.096426
[20:47:17.936] iteration 2834 : model1 loss : 0.038086 model2 loss : 0.037696
[20:47:18.634] iteration 2835 : model1 loss : 0.034202 model2 loss : 0.041143
[20:47:19.321] iteration 2836 : model1 loss : 0.050985 model2 loss : 0.048941
[20:47:19.991] iteration 2837 : model1 loss : 0.039027 model2 loss : 0.041851
[20:47:20.670] iteration 2838 : model1 loss : 0.052795 model2 loss : 0.045262
[20:47:21.356] iteration 2839 : model1 loss : 0.053699 model2 loss : 0.090600
[20:47:22.036] iteration 2840 : model1 loss : 0.031300 model2 loss : 0.032082
[20:47:22.716] iteration 2841 : model1 loss : 0.043326 model2 loss : 0.046946
[20:47:23.412] iteration 2842 : model1 loss : 0.038551 model2 loss : 0.053856
[20:47:24.100] iteration 2843 : model1 loss : 0.034556 model2 loss : 0.046701
[20:47:24.801] iteration 2844 : model1 loss : 0.026412 model2 loss : 0.048955
[20:47:25.480] iteration 2845 : model1 loss : 0.032728 model2 loss : 0.039343
[20:47:26.169] iteration 2846 : model1 loss : 0.028771 model2 loss : 0.029138
[20:47:26.862] iteration 2847 : model1 loss : 0.024465 model2 loss : 0.025388
[20:47:27.540] iteration 2848 : model1 loss : 0.030766 model2 loss : 0.033371
[20:47:28.222] iteration 2849 : model1 loss : 0.029750 model2 loss : 0.030344
[20:47:28.919] iteration 2850 : model1 loss : 0.032793 model2 loss : 0.034727
[20:47:29.651] iteration 2851 : model1 loss : 0.039558 model2 loss : 0.043332
[20:47:30.338] iteration 2852 : model1 loss : 0.028191 model2 loss : 0.040725
[20:47:31.022] iteration 2853 : model1 loss : 0.114291 model2 loss : 0.125219
[20:47:31.696] iteration 2854 : model1 loss : 0.028726 model2 loss : 0.045003
[20:47:32.381] iteration 2855 : model1 loss : 0.074543 model2 loss : 0.127665
[20:47:33.059] iteration 2856 : model1 loss : 0.119090 model2 loss : 0.110254
[20:47:33.742] iteration 2857 : model1 loss : 0.026286 model2 loss : 0.030396
[20:47:34.434] iteration 2858 : model1 loss : 0.032728 model2 loss : 0.052728
[20:47:35.115] iteration 2859 : model1 loss : 0.033668 model2 loss : 0.044681
[20:47:35.797] iteration 2860 : model1 loss : 0.052958 model2 loss : 0.052630
[20:47:36.489] iteration 2861 : model1 loss : 0.049297 model2 loss : 0.044116
[20:47:37.182] iteration 2862 : model1 loss : 0.061323 model2 loss : 0.047620
[20:47:37.863] iteration 2863 : model1 loss : 0.067614 model2 loss : 0.053638
[20:47:38.568] iteration 2864 : model1 loss : 0.039877 model2 loss : 0.044164
[20:47:39.251] iteration 2865 : model1 loss : 0.183249 model2 loss : 0.189490
[20:47:39.940] iteration 2866 : model1 loss : 0.037752 model2 loss : 0.042612
[20:47:40.625] iteration 2867 : model1 loss : 0.029615 model2 loss : 0.031828
[20:47:41.306] iteration 2868 : model1 loss : 0.045214 model2 loss : 0.044392
[20:47:41.994] iteration 2869 : model1 loss : 0.044680 model2 loss : 0.040808
[20:47:42.696] iteration 2870 : model1 loss : 0.043577 model2 loss : 0.044718
[20:47:43.398] iteration 2871 : model1 loss : 0.048481 model2 loss : 0.048033
[20:47:44.081] iteration 2872 : model1 loss : 0.033573 model2 loss : 0.037685
[20:47:44.764] iteration 2873 : model1 loss : 0.033681 model2 loss : 0.039131
[20:47:45.458] iteration 2874 : model1 loss : 0.227174 model2 loss : 0.121777
[20:47:46.151] iteration 2875 : model1 loss : 0.032258 model2 loss : 0.035720
[20:47:46.848] iteration 2876 : model1 loss : 0.063346 model2 loss : 0.056023
[20:47:47.530] iteration 2877 : model1 loss : 0.109133 model2 loss : 0.121584
[20:47:48.207] iteration 2878 : model1 loss : 0.025985 model2 loss : 0.026003
[20:47:48.896] iteration 2879 : model1 loss : 0.054587 model2 loss : 0.059283
[20:47:49.574] iteration 2880 : model1 loss : 0.040539 model2 loss : 0.048191
[20:47:50.267] iteration 2881 : model1 loss : 0.064296 model2 loss : 0.065397
[20:47:50.947] iteration 2882 : model1 loss : 0.042570 model2 loss : 0.043353
[20:47:51.636] iteration 2883 : model1 loss : 0.053765 model2 loss : 0.047417
[20:47:52.325] iteration 2884 : model1 loss : 0.071355 model2 loss : 0.038878
[20:47:53.013] iteration 2885 : model1 loss : 0.059619 model2 loss : 0.052123
[20:47:53.699] iteration 2886 : model1 loss : 0.064018 model2 loss : 0.072476
[20:47:54.414] iteration 2887 : model1 loss : 0.062448 model2 loss : 0.054939
[20:47:55.121] iteration 2888 : model1 loss : 0.031467 model2 loss : 0.031416
[20:47:55.811] iteration 2889 : model1 loss : 0.058027 model2 loss : 0.051341
[20:47:56.505] iteration 2890 : model1 loss : 0.109855 model2 loss : 0.110593
[20:47:57.182] iteration 2891 : model1 loss : 0.047786 model2 loss : 0.047464
[20:47:57.854] iteration 2892 : model1 loss : 0.051011 model2 loss : 0.051607
[20:47:58.539] iteration 2893 : model1 loss : 0.070004 model2 loss : 0.045680
[20:47:59.222] iteration 2894 : model1 loss : 0.039185 model2 loss : 0.042211
[20:47:59.894] iteration 2895 : model1 loss : 0.042979 model2 loss : 0.047948
[20:48:00.580] iteration 2896 : model1 loss : 0.030720 model2 loss : 0.036675
[20:48:01.267] iteration 2897 : model1 loss : 0.039086 model2 loss : 0.042148
[20:48:01.953] iteration 2898 : model1 loss : 0.035317 model2 loss : 0.036316
[20:48:02.645] iteration 2899 : model1 loss : 0.051064 model2 loss : 0.066434
[20:48:03.337] iteration 2900 : model1 loss : 0.059020 model2 loss : 0.066850
[20:48:04.070] iteration 2901 : model1 loss : 0.046395 model2 loss : 0.043144
[20:48:04.750] iteration 2902 : model1 loss : 0.048425 model2 loss : 0.118785
[20:48:05.429] iteration 2903 : model1 loss : 0.044899 model2 loss : 0.047615
[20:48:06.118] iteration 2904 : model1 loss : 0.106464 model2 loss : 0.130854
[20:48:06.798] iteration 2905 : model1 loss : 0.052865 model2 loss : 0.040243
[20:48:07.478] iteration 2906 : model1 loss : 0.052658 model2 loss : 0.057803
[20:48:08.163] iteration 2907 : model1 loss : 0.035367 model2 loss : 0.032086
[20:48:08.847] iteration 2908 : model1 loss : 0.058681 model2 loss : 0.051252
[20:48:09.525] iteration 2909 : model1 loss : 0.100828 model2 loss : 0.072668
[20:48:10.194] iteration 2910 : model1 loss : 0.090567 model2 loss : 0.075827
[20:48:10.880] iteration 2911 : model1 loss : 0.039604 model2 loss : 0.076092
[20:48:11.565] iteration 2912 : model1 loss : 0.033988 model2 loss : 0.064528
[20:48:12.257] iteration 2913 : model1 loss : 0.051031 model2 loss : 0.037098
[20:48:12.950] iteration 2914 : model1 loss : 0.100376 model2 loss : 0.082136
[20:48:13.643] iteration 2915 : model1 loss : 0.029447 model2 loss : 0.029501
[20:48:14.324] iteration 2916 : model1 loss : 0.039479 model2 loss : 0.045879
[20:48:15.002] iteration 2917 : model1 loss : 0.033535 model2 loss : 0.033562
[20:48:15.683] iteration 2918 : model1 loss : 0.065116 model2 loss : 0.131132
[20:48:16.378] iteration 2919 : model1 loss : 0.035078 model2 loss : 0.050225
[20:48:17.057] iteration 2920 : model1 loss : 0.094787 model2 loss : 0.076492
[20:48:17.749] iteration 2921 : model1 loss : 0.054357 model2 loss : 0.036359
[20:48:18.454] iteration 2922 : model1 loss : 0.166673 model2 loss : 0.136149
[20:48:19.136] iteration 2923 : model1 loss : 0.062341 model2 loss : 0.061589
[20:48:19.809] iteration 2924 : model1 loss : 0.055941 model2 loss : 0.059500
[20:48:20.485] iteration 2925 : model1 loss : 0.049445 model2 loss : 0.053226
[20:48:21.166] iteration 2926 : model1 loss : 0.043773 model2 loss : 0.034200
[20:48:21.850] iteration 2927 : model1 loss : 0.029736 model2 loss : 0.032077
[20:48:22.525] iteration 2928 : model1 loss : 0.039010 model2 loss : 0.040016
[20:48:23.212] iteration 2929 : model1 loss : 0.043192 model2 loss : 0.056365
[20:48:23.891] iteration 2930 : model1 loss : 0.071445 model2 loss : 0.089647
[20:48:24.581] iteration 2931 : model1 loss : 0.028180 model2 loss : 0.033247
[20:48:25.254] iteration 2932 : model1 loss : 0.037845 model2 loss : 0.035505
[20:48:25.934] iteration 2933 : model1 loss : 0.035086 model2 loss : 0.038963
[20:48:26.609] iteration 2934 : model1 loss : 0.038733 model2 loss : 0.044489
[20:48:27.283] iteration 2935 : model1 loss : 0.137139 model2 loss : 0.145227
[20:48:27.960] iteration 2936 : model1 loss : 0.037672 model2 loss : 0.049743
[20:48:28.656] iteration 2937 : model1 loss : 0.030710 model2 loss : 0.037094
[20:48:29.334] iteration 2938 : model1 loss : 0.079825 model2 loss : 0.068968
[20:48:30.010] iteration 2939 : model1 loss : 0.026931 model2 loss : 0.025485
[20:48:30.684] iteration 2940 : model1 loss : 0.027609 model2 loss : 0.035363
[20:48:31.366] iteration 2941 : model1 loss : 0.035736 model2 loss : 0.038475
[20:48:32.044] iteration 2942 : model1 loss : 0.030069 model2 loss : 0.049878
[20:48:32.729] iteration 2943 : model1 loss : 0.037221 model2 loss : 0.045312
[20:48:33.417] iteration 2944 : model1 loss : 0.071143 model2 loss : 0.076498
[20:48:34.109] iteration 2945 : model1 loss : 0.188737 model2 loss : 0.230452
[20:48:34.780] iteration 2946 : model1 loss : 0.038675 model2 loss : 0.039019
[20:48:35.522] iteration 2947 : model1 loss : 0.054616 model2 loss : 0.094580
[20:48:36.198] iteration 2948 : model1 loss : 0.034850 model2 loss : 0.035973
[20:48:36.878] iteration 2949 : model1 loss : 0.030457 model2 loss : 0.030693
[20:48:37.575] iteration 2950 : model1 loss : 0.030717 model2 loss : 0.042636
[20:48:38.305] iteration 2951 : model1 loss : 0.041288 model2 loss : 0.046295
[20:48:38.979] iteration 2952 : model1 loss : 0.035678 model2 loss : 0.054425
[20:48:39.652] iteration 2953 : model1 loss : 0.052228 model2 loss : 0.046176
[20:48:40.343] iteration 2954 : model1 loss : 0.077255 model2 loss : 0.048029
[20:48:41.041] iteration 2955 : model1 loss : 0.042849 model2 loss : 0.034450
[20:48:41.711] iteration 2956 : model1 loss : 0.093229 model2 loss : 0.049325
[20:48:42.401] iteration 2957 : model1 loss : 0.043160 model2 loss : 0.036830
[20:48:43.081] iteration 2958 : model1 loss : 0.073941 model2 loss : 0.061955
[20:48:43.758] iteration 2959 : model1 loss : 0.043813 model2 loss : 0.046580
[20:48:44.434] iteration 2960 : model1 loss : 0.035752 model2 loss : 0.041474
[20:48:45.116] iteration 2961 : model1 loss : 0.040072 model2 loss : 0.047972
[20:48:45.849] iteration 2962 : model1 loss : 0.052570 model2 loss : 0.047096
[20:48:46.553] iteration 2963 : model1 loss : 0.059745 model2 loss : 0.067593
[20:48:47.266] iteration 2964 : model1 loss : 0.027754 model2 loss : 0.031839
[20:48:47.992] iteration 2965 : model1 loss : 0.162892 model2 loss : 0.090692
[20:48:48.712] iteration 2966 : model1 loss : 0.058130 model2 loss : 0.051003
[20:48:49.434] iteration 2967 : model1 loss : 0.067566 model2 loss : 0.108381
[20:48:50.160] iteration 2968 : model1 loss : 0.031548 model2 loss : 0.027429
[20:48:50.876] iteration 2969 : model1 loss : 0.045313 model2 loss : 0.043102
[20:48:51.588] iteration 2970 : model1 loss : 0.070431 model2 loss : 0.063191
[20:48:52.315] iteration 2971 : model1 loss : 0.051326 model2 loss : 0.053232
[20:48:53.069] iteration 2972 : model1 loss : 0.037626 model2 loss : 0.031942
[20:48:53.775] iteration 2973 : model1 loss : 0.054725 model2 loss : 0.049431
[20:48:54.492] iteration 2974 : model1 loss : 0.076034 model2 loss : 0.098106
[20:48:55.225] iteration 2975 : model1 loss : 0.038385 model2 loss : 0.044196
[20:48:55.935] iteration 2976 : model1 loss : 0.168255 model2 loss : 0.166314
[20:48:56.681] iteration 2977 : model1 loss : 0.034155 model2 loss : 0.034357
[20:48:57.414] iteration 2978 : model1 loss : 0.123134 model2 loss : 0.071582
[20:48:58.108] iteration 2979 : model1 loss : 0.038744 model2 loss : 0.035484
[20:48:58.793] iteration 2980 : model1 loss : 0.030097 model2 loss : 0.031801
[20:48:59.474] iteration 2981 : model1 loss : 0.091219 model2 loss : 0.089228
[20:49:00.153] iteration 2982 : model1 loss : 0.028933 model2 loss : 0.030895
[20:49:00.844] iteration 2983 : model1 loss : 0.040501 model2 loss : 0.042047
[20:49:01.528] iteration 2984 : model1 loss : 0.128902 model2 loss : 0.115939
[20:49:02.213] iteration 2985 : model1 loss : 0.036540 model2 loss : 0.031141
[20:49:02.895] iteration 2986 : model1 loss : 0.043713 model2 loss : 0.048334
[20:49:03.569] iteration 2987 : model1 loss : 0.043610 model2 loss : 0.036587
[20:49:04.260] iteration 2988 : model1 loss : 0.046560 model2 loss : 0.040480
[20:49:04.957] iteration 2989 : model1 loss : 0.051026 model2 loss : 0.041864
[20:49:05.654] iteration 2990 : model1 loss : 0.053595 model2 loss : 0.056401
[20:49:06.376] iteration 2991 : model1 loss : 0.037954 model2 loss : 0.050440
[20:49:07.290] iteration 2992 : model1 loss : 0.072326 model2 loss : 0.069024
[20:49:08.021] iteration 2993 : model1 loss : 0.027225 model2 loss : 0.031048
[20:49:08.735] iteration 2994 : model1 loss : 0.036401 model2 loss : 0.034777
[20:49:09.461] iteration 2995 : model1 loss : 0.034909 model2 loss : 0.049127
[20:49:10.181] iteration 2996 : model1 loss : 0.164705 model2 loss : 0.172495
[20:49:10.893] iteration 2997 : model1 loss : 0.070829 model2 loss : 0.068543
[20:49:11.608] iteration 2998 : model1 loss : 0.051794 model2 loss : 0.057020
[20:49:12.334] iteration 2999 : model1 loss : 0.102523 model2 loss : 0.110474
[20:49:13.071] iteration 3000 : model1 loss : 0.038157 model2 loss : 0.037810
[20:49:34.865] iteration 3000 : model1_mean_dice : 0.829963 model1_mean_hd95 : 11.786781
[20:49:56.346] iteration 3000 : model2_mean_dice : 0.817084 model2_mean_hd95 : 9.234409
[20:49:56.419] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_3000.pth
[20:49:56.486] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_3000.pth
[20:49:57.210] iteration 3001 : model1 loss : 0.028413 model2 loss : 0.027058
[20:49:57.915] iteration 3002 : model1 loss : 0.160122 model2 loss : 0.168922
[20:49:58.606] iteration 3003 : model1 loss : 0.041639 model2 loss : 0.038566
[20:49:59.300] iteration 3004 : model1 loss : 0.043910 model2 loss : 0.042525
[20:50:00.037] iteration 3005 : model1 loss : 0.035816 model2 loss : 0.031869
[20:50:00.754] iteration 3006 : model1 loss : 0.032810 model2 loss : 0.036193
[20:50:01.472] iteration 3007 : model1 loss : 0.034151 model2 loss : 0.034780
[20:50:02.179] iteration 3008 : model1 loss : 0.029833 model2 loss : 0.027510
[20:50:02.889] iteration 3009 : model1 loss : 0.165431 model2 loss : 0.178492
[20:50:03.578] iteration 3010 : model1 loss : 0.035342 model2 loss : 0.035493
[20:50:04.287] iteration 3011 : model1 loss : 0.034996 model2 loss : 0.032193
[20:50:04.996] iteration 3012 : model1 loss : 0.027599 model2 loss : 0.032767
[20:50:05.676] iteration 3013 : model1 loss : 0.044027 model2 loss : 0.048827
[20:50:06.391] iteration 3014 : model1 loss : 0.048863 model2 loss : 0.039639
[20:50:07.101] iteration 3015 : model1 loss : 0.034176 model2 loss : 0.036213
[20:50:07.807] iteration 3016 : model1 loss : 0.057513 model2 loss : 0.051616
[20:50:08.500] iteration 3017 : model1 loss : 0.104362 model2 loss : 0.036947
[20:50:09.201] iteration 3018 : model1 loss : 0.029238 model2 loss : 0.027805
[20:50:09.932] iteration 3019 : model1 loss : 0.029451 model2 loss : 0.032089
[20:50:10.628] iteration 3020 : model1 loss : 0.049628 model2 loss : 0.051919
[20:50:11.360] iteration 3021 : model1 loss : 0.062215 model2 loss : 0.070455
[20:50:12.103] iteration 3022 : model1 loss : 0.054534 model2 loss : 0.054681
[20:50:12.836] iteration 3023 : model1 loss : 0.026946 model2 loss : 0.032265
[20:50:13.547] iteration 3024 : model1 loss : 0.024017 model2 loss : 0.025492
[20:50:14.252] iteration 3025 : model1 loss : 0.031314 model2 loss : 0.031420
[20:50:14.943] iteration 3026 : model1 loss : 0.049804 model2 loss : 0.056787
[20:50:15.626] iteration 3027 : model1 loss : 0.032665 model2 loss : 0.033977
[20:50:16.363] iteration 3028 : model1 loss : 0.056846 model2 loss : 0.051778
[20:50:17.053] iteration 3029 : model1 loss : 0.042138 model2 loss : 0.040809
[20:50:17.745] iteration 3030 : model1 loss : 0.039653 model2 loss : 0.035940
[20:50:18.438] iteration 3031 : model1 loss : 0.025074 model2 loss : 0.026739
[20:50:19.183] iteration 3032 : model1 loss : 0.041171 model2 loss : 0.039529
[20:50:19.871] iteration 3033 : model1 loss : 0.030873 model2 loss : 0.034366
[20:50:20.557] iteration 3034 : model1 loss : 0.024709 model2 loss : 0.026511
[20:50:21.258] iteration 3035 : model1 loss : 0.058187 model2 loss : 0.078916
[20:50:21.943] iteration 3036 : model1 loss : 0.037665 model2 loss : 0.044403
[20:50:22.647] iteration 3037 : model1 loss : 0.064657 model2 loss : 0.052506
[20:50:23.344] iteration 3038 : model1 loss : 0.065908 model2 loss : 0.039099
[20:50:24.052] iteration 3039 : model1 loss : 0.038761 model2 loss : 0.032692
[20:50:24.755] iteration 3040 : model1 loss : 0.026996 model2 loss : 0.026695
[20:50:25.458] iteration 3041 : model1 loss : 0.044172 model2 loss : 0.046097
[20:50:26.147] iteration 3042 : model1 loss : 0.057917 model2 loss : 0.066619
[20:50:26.843] iteration 3043 : model1 loss : 0.022688 model2 loss : 0.028118
[20:50:27.546] iteration 3044 : model1 loss : 0.101879 model2 loss : 0.082155
[20:50:28.236] iteration 3045 : model1 loss : 0.035452 model2 loss : 0.033972
[20:50:28.935] iteration 3046 : model1 loss : 0.029296 model2 loss : 0.027963
[20:50:29.624] iteration 3047 : model1 loss : 0.030160 model2 loss : 0.029795
[20:50:30.317] iteration 3048 : model1 loss : 0.029550 model2 loss : 0.037193
[20:50:31.003] iteration 3049 : model1 loss : 0.032359 model2 loss : 0.031712
[20:50:31.699] iteration 3050 : model1 loss : 0.078230 model2 loss : 0.071768
[20:50:32.450] iteration 3051 : model1 loss : 0.045693 model2 loss : 0.050083
[20:50:33.167] iteration 3052 : model1 loss : 0.046591 model2 loss : 0.045383
[20:50:33.876] iteration 3053 : model1 loss : 0.141024 model2 loss : 0.090449
[20:50:34.565] iteration 3054 : model1 loss : 0.034640 model2 loss : 0.031175
[20:50:35.280] iteration 3055 : model1 loss : 0.034740 model2 loss : 0.042421
[20:50:35.975] iteration 3056 : model1 loss : 0.093329 model2 loss : 0.066525
[20:50:36.665] iteration 3057 : model1 loss : 0.085061 model2 loss : 0.059016
[20:50:37.353] iteration 3058 : model1 loss : 0.042023 model2 loss : 0.041262
[20:50:38.054] iteration 3059 : model1 loss : 0.047259 model2 loss : 0.059744
[20:50:38.739] iteration 3060 : model1 loss : 0.042916 model2 loss : 0.040636
[20:50:39.430] iteration 3061 : model1 loss : 0.029012 model2 loss : 0.030485
[20:50:40.128] iteration 3062 : model1 loss : 0.066272 model2 loss : 0.065939
[20:50:40.820] iteration 3063 : model1 loss : 0.039787 model2 loss : 0.047235
[20:50:41.516] iteration 3064 : model1 loss : 0.130715 model2 loss : 0.162096
[20:50:42.201] iteration 3065 : model1 loss : 0.031060 model2 loss : 0.034472
[20:50:42.893] iteration 3066 : model1 loss : 0.028578 model2 loss : 0.037666
[20:50:43.589] iteration 3067 : model1 loss : 0.039918 model2 loss : 0.035370
[20:50:44.285] iteration 3068 : model1 loss : 0.043364 model2 loss : 0.051510
[20:50:44.983] iteration 3069 : model1 loss : 0.036794 model2 loss : 0.033127
[20:50:45.683] iteration 3070 : model1 loss : 0.033731 model2 loss : 0.029270
[20:50:46.373] iteration 3071 : model1 loss : 0.028595 model2 loss : 0.029632
[20:50:47.060] iteration 3072 : model1 loss : 0.039498 model2 loss : 0.038025
[20:50:47.760] iteration 3073 : model1 loss : 0.038738 model2 loss : 0.048373
[20:50:48.467] iteration 3074 : model1 loss : 0.049606 model2 loss : 0.038658
[20:50:49.162] iteration 3075 : model1 loss : 0.035822 model2 loss : 0.032088
[20:50:49.849] iteration 3076 : model1 loss : 0.040926 model2 loss : 0.046974
[20:50:50.542] iteration 3077 : model1 loss : 0.028415 model2 loss : 0.024625
[20:50:51.233] iteration 3078 : model1 loss : 0.025732 model2 loss : 0.026331
[20:50:51.929] iteration 3079 : model1 loss : 0.028751 model2 loss : 0.029071
[20:50:52.624] iteration 3080 : model1 loss : 0.032670 model2 loss : 0.030709
[20:50:53.321] iteration 3081 : model1 loss : 0.067810 model2 loss : 0.094095
[20:50:54.020] iteration 3082 : model1 loss : 0.041169 model2 loss : 0.041264
[20:50:54.726] iteration 3083 : model1 loss : 0.041982 model2 loss : 0.035462
[20:50:55.420] iteration 3084 : model1 loss : 0.057871 model2 loss : 0.053524
[20:50:56.093] iteration 3085 : model1 loss : 0.046082 model2 loss : 0.047230
[20:50:56.782] iteration 3086 : model1 loss : 0.036609 model2 loss : 0.037211
[20:50:57.487] iteration 3087 : model1 loss : 0.026134 model2 loss : 0.032633
[20:50:58.173] iteration 3088 : model1 loss : 0.125528 model2 loss : 0.154593
[20:50:58.865] iteration 3089 : model1 loss : 0.050879 model2 loss : 0.052285
[20:50:59.565] iteration 3090 : model1 loss : 0.059299 model2 loss : 0.061542
[20:51:00.252] iteration 3091 : model1 loss : 0.066477 model2 loss : 0.063038
[20:51:00.945] iteration 3092 : model1 loss : 0.033144 model2 loss : 0.036556
[20:51:01.643] iteration 3093 : model1 loss : 0.032954 model2 loss : 0.036986
[20:51:02.338] iteration 3094 : model1 loss : 0.046665 model2 loss : 0.037796
[20:51:03.032] iteration 3095 : model1 loss : 0.030436 model2 loss : 0.041531
[20:51:03.723] iteration 3096 : model1 loss : 0.046943 model2 loss : 0.050349
[20:51:04.417] iteration 3097 : model1 loss : 0.046180 model2 loss : 0.043088
[20:51:05.114] iteration 3098 : model1 loss : 0.045257 model2 loss : 0.047840
[20:51:05.792] iteration 3099 : model1 loss : 0.024269 model2 loss : 0.028751
[20:51:06.490] iteration 3100 : model1 loss : 0.081360 model2 loss : 0.049349
[20:51:07.213] iteration 3101 : model1 loss : 0.038360 model2 loss : 0.038226
[20:51:07.896] iteration 3102 : model1 loss : 0.036675 model2 loss : 0.038207
[20:51:08.598] iteration 3103 : model1 loss : 0.048026 model2 loss : 0.105073
[20:51:09.297] iteration 3104 : model1 loss : 0.021000 model2 loss : 0.023776
[20:51:09.985] iteration 3105 : model1 loss : 0.031718 model2 loss : 0.035505
[20:51:10.668] iteration 3106 : model1 loss : 0.031770 model2 loss : 0.032662
[20:51:11.348] iteration 3107 : model1 loss : 0.042541 model2 loss : 0.034707
[20:51:12.050] iteration 3108 : model1 loss : 0.050978 model2 loss : 0.050814
[20:51:12.751] iteration 3109 : model1 loss : 0.087293 model2 loss : 0.085399
[20:51:13.446] iteration 3110 : model1 loss : 0.048011 model2 loss : 0.060625
[20:51:14.130] iteration 3111 : model1 loss : 0.030719 model2 loss : 0.029806
[20:51:14.838] iteration 3112 : model1 loss : 0.080131 model2 loss : 0.077309
[20:51:15.519] iteration 3113 : model1 loss : 0.029513 model2 loss : 0.039155
[20:51:16.215] iteration 3114 : model1 loss : 0.039810 model2 loss : 0.044001
[20:51:16.915] iteration 3115 : model1 loss : 0.029899 model2 loss : 0.031438
[20:51:17.613] iteration 3116 : model1 loss : 0.051971 model2 loss : 0.048524
[20:51:18.305] iteration 3117 : model1 loss : 0.038747 model2 loss : 0.040717
[20:51:19.010] iteration 3118 : model1 loss : 0.033032 model2 loss : 0.027982
[20:51:19.744] iteration 3119 : model1 loss : 0.042357 model2 loss : 0.038899
[20:51:20.442] iteration 3120 : model1 loss : 0.031097 model2 loss : 0.034200
[20:51:21.153] iteration 3121 : model1 loss : 0.108331 model2 loss : 0.089688
[20:51:21.845] iteration 3122 : model1 loss : 0.052347 model2 loss : 0.050919
[20:51:22.532] iteration 3123 : model1 loss : 0.035811 model2 loss : 0.035510
[20:51:23.320] iteration 3124 : model1 loss : 0.049251 model2 loss : 0.051892
[20:51:24.071] iteration 3125 : model1 loss : 0.031405 model2 loss : 0.027837
[20:51:24.944] iteration 3126 : model1 loss : 0.036022 model2 loss : 0.044456
[20:51:25.682] iteration 3127 : model1 loss : 0.021864 model2 loss : 0.022830
[20:51:26.383] iteration 3128 : model1 loss : 0.044828 model2 loss : 0.047864
[20:51:27.074] iteration 3129 : model1 loss : 0.054560 model2 loss : 0.065008
[20:51:27.772] iteration 3130 : model1 loss : 0.027524 model2 loss : 0.027720
[20:51:28.485] iteration 3131 : model1 loss : 0.040023 model2 loss : 0.041675
[20:51:29.187] iteration 3132 : model1 loss : 0.041741 model2 loss : 0.041508
[20:51:29.867] iteration 3133 : model1 loss : 0.030828 model2 loss : 0.030838
[20:51:30.561] iteration 3134 : model1 loss : 0.035695 model2 loss : 0.032175
[20:51:31.260] iteration 3135 : model1 loss : 0.027749 model2 loss : 0.030420
[20:51:31.944] iteration 3136 : model1 loss : 0.043423 model2 loss : 0.052044
[20:51:32.653] iteration 3137 : model1 loss : 0.040260 model2 loss : 0.039116
[20:51:33.353] iteration 3138 : model1 loss : 0.025569 model2 loss : 0.030768
[20:51:34.030] iteration 3139 : model1 loss : 0.032445 model2 loss : 0.030332
[20:51:34.717] iteration 3140 : model1 loss : 0.029283 model2 loss : 0.031085
[20:51:35.412] iteration 3141 : model1 loss : 0.035897 model2 loss : 0.035730
[20:51:36.110] iteration 3142 : model1 loss : 0.037229 model2 loss : 0.038382
[20:51:36.793] iteration 3143 : model1 loss : 0.025737 model2 loss : 0.025283
[20:51:37.508] iteration 3144 : model1 loss : 0.040205 model2 loss : 0.044785
[20:51:38.259] iteration 3145 : model1 loss : 0.034923 model2 loss : 0.025573
[20:51:38.967] iteration 3146 : model1 loss : 0.023271 model2 loss : 0.023859
[20:51:39.666] iteration 3147 : model1 loss : 0.034141 model2 loss : 0.030946
[20:51:40.366] iteration 3148 : model1 loss : 0.041234 model2 loss : 0.039390
[20:51:41.047] iteration 3149 : model1 loss : 0.053031 model2 loss : 0.062189
[20:51:41.730] iteration 3150 : model1 loss : 0.037665 model2 loss : 0.042214
[20:51:42.473] iteration 3151 : model1 loss : 0.023499 model2 loss : 0.026559
[20:51:43.166] iteration 3152 : model1 loss : 0.028437 model2 loss : 0.032526
[20:51:43.867] iteration 3153 : model1 loss : 0.045577 model2 loss : 0.081666
[20:51:44.558] iteration 3154 : model1 loss : 0.032901 model2 loss : 0.033757
[20:51:45.260] iteration 3155 : model1 loss : 0.020255 model2 loss : 0.021329
[20:51:45.948] iteration 3156 : model1 loss : 0.060950 model2 loss : 0.060187
[20:51:46.641] iteration 3157 : model1 loss : 0.057499 model2 loss : 0.069837
[20:51:47.347] iteration 3158 : model1 loss : 0.047518 model2 loss : 0.048926
[20:51:48.074] iteration 3159 : model1 loss : 0.031631 model2 loss : 0.040283
[20:51:48.787] iteration 3160 : model1 loss : 0.057395 model2 loss : 0.053041
[20:51:49.476] iteration 3161 : model1 loss : 0.035169 model2 loss : 0.034869
[20:51:50.205] iteration 3162 : model1 loss : 0.023191 model2 loss : 0.027362
[20:51:50.934] iteration 3163 : model1 loss : 0.043658 model2 loss : 0.041289
[20:51:51.647] iteration 3164 : model1 loss : 0.041108 model2 loss : 0.035272
[20:51:52.351] iteration 3165 : model1 loss : 0.022242 model2 loss : 0.025339
[20:51:53.076] iteration 3166 : model1 loss : 0.050806 model2 loss : 0.053541
[20:51:53.787] iteration 3167 : model1 loss : 0.031899 model2 loss : 0.030649
[20:51:54.530] iteration 3168 : model1 loss : 0.035748 model2 loss : 0.042792
[20:51:55.237] iteration 3169 : model1 loss : 0.032140 model2 loss : 0.027066
[20:51:55.955] iteration 3170 : model1 loss : 0.037462 model2 loss : 0.034497
[20:51:56.649] iteration 3171 : model1 loss : 0.043720 model2 loss : 0.040390
[20:51:57.346] iteration 3172 : model1 loss : 0.038212 model2 loss : 0.040345
[20:51:58.040] iteration 3173 : model1 loss : 0.027896 model2 loss : 0.023491
[20:51:58.738] iteration 3174 : model1 loss : 0.048905 model2 loss : 0.053570
[20:51:59.420] iteration 3175 : model1 loss : 0.043663 model2 loss : 0.046694
[20:52:00.123] iteration 3176 : model1 loss : 0.042040 model2 loss : 0.043473
[20:52:00.801] iteration 3177 : model1 loss : 0.103152 model2 loss : 0.089605
[20:52:01.491] iteration 3178 : model1 loss : 0.032657 model2 loss : 0.028703
[20:52:02.174] iteration 3179 : model1 loss : 0.039330 model2 loss : 0.055366
[20:52:02.859] iteration 3180 : model1 loss : 0.033797 model2 loss : 0.039972
[20:52:03.532] iteration 3181 : model1 loss : 0.063467 model2 loss : 0.082122
[20:52:04.220] iteration 3182 : model1 loss : 0.043066 model2 loss : 0.038890
[20:52:04.906] iteration 3183 : model1 loss : 0.050467 model2 loss : 0.038699
[20:52:05.608] iteration 3184 : model1 loss : 0.028375 model2 loss : 0.038751
[20:52:06.290] iteration 3185 : model1 loss : 0.062456 model2 loss : 0.055784
[20:52:06.964] iteration 3186 : model1 loss : 0.053711 model2 loss : 0.054259
[20:52:07.644] iteration 3187 : model1 loss : 0.110606 model2 loss : 0.119310
[20:52:08.335] iteration 3188 : model1 loss : 0.050968 model2 loss : 0.076275
[20:52:09.023] iteration 3189 : model1 loss : 0.038164 model2 loss : 0.041215
[20:52:09.704] iteration 3190 : model1 loss : 0.109047 model2 loss : 0.063985
[20:52:10.391] iteration 3191 : model1 loss : 0.058698 model2 loss : 0.038413
[20:52:11.067] iteration 3192 : model1 loss : 0.035390 model2 loss : 0.034031
[20:52:11.750] iteration 3193 : model1 loss : 0.058860 model2 loss : 0.045682
[20:52:12.424] iteration 3194 : model1 loss : 0.032151 model2 loss : 0.029952
[20:52:13.105] iteration 3195 : model1 loss : 0.071705 model2 loss : 0.066864
[20:52:13.785] iteration 3196 : model1 loss : 0.049438 model2 loss : 0.057114
[20:52:14.475] iteration 3197 : model1 loss : 0.028693 model2 loss : 0.031282
[20:52:15.161] iteration 3198 : model1 loss : 0.080346 model2 loss : 0.043055
[20:52:15.841] iteration 3199 : model1 loss : 0.069336 model2 loss : 0.074971
[20:52:16.522] iteration 3200 : model1 loss : 0.040436 model2 loss : 0.035913
[20:52:36.036] iteration 3200 : model1_mean_dice : 0.806741 model1_mean_hd95 : 3.202095
[20:52:55.554] iteration 3200 : model2_mean_dice : 0.826509 model2_mean_hd95 : 4.907913
[20:52:56.250] iteration 3201 : model1 loss : 0.037809 model2 loss : 0.033665
[20:52:56.934] iteration 3202 : model1 loss : 0.037657 model2 loss : 0.036411
[20:52:57.619] iteration 3203 : model1 loss : 0.051504 model2 loss : 0.061244
[20:52:58.289] iteration 3204 : model1 loss : 0.092835 model2 loss : 0.073884
[20:52:58.962] iteration 3205 : model1 loss : 0.032104 model2 loss : 0.030667
[20:52:59.642] iteration 3206 : model1 loss : 0.033384 model2 loss : 0.037406
[20:53:00.320] iteration 3207 : model1 loss : 0.053685 model2 loss : 0.036968
[20:53:00.995] iteration 3208 : model1 loss : 0.080807 model2 loss : 0.098353
[20:53:01.667] iteration 3209 : model1 loss : 0.056285 model2 loss : 0.035496
[20:53:02.349] iteration 3210 : model1 loss : 0.057498 model2 loss : 0.059740
[20:53:03.014] iteration 3211 : model1 loss : 0.024860 model2 loss : 0.023255
[20:53:03.692] iteration 3212 : model1 loss : 0.091108 model2 loss : 0.067395
[20:53:04.380] iteration 3213 : model1 loss : 0.046304 model2 loss : 0.053313
[20:53:05.051] iteration 3214 : model1 loss : 0.046975 model2 loss : 0.042624
[20:53:05.715] iteration 3215 : model1 loss : 0.067495 model2 loss : 0.080227
[20:53:06.397] iteration 3216 : model1 loss : 0.035325 model2 loss : 0.036487
[20:53:07.071] iteration 3217 : model1 loss : 0.034570 model2 loss : 0.033284
[20:53:07.757] iteration 3218 : model1 loss : 0.032100 model2 loss : 0.030078
[20:53:08.423] iteration 3219 : model1 loss : 0.027252 model2 loss : 0.032564
[20:53:09.116] iteration 3220 : model1 loss : 0.032676 model2 loss : 0.031034
[20:53:09.787] iteration 3221 : model1 loss : 0.042686 model2 loss : 0.038805
[20:53:10.460] iteration 3222 : model1 loss : 0.153315 model2 loss : 0.146432
[20:53:11.137] iteration 3223 : model1 loss : 0.034953 model2 loss : 0.035113
[20:53:11.825] iteration 3224 : model1 loss : 0.050368 model2 loss : 0.065147
[20:53:12.508] iteration 3225 : model1 loss : 0.037116 model2 loss : 0.037685
[20:53:13.187] iteration 3226 : model1 loss : 0.034143 model2 loss : 0.031241
[20:53:13.862] iteration 3227 : model1 loss : 0.044159 model2 loss : 0.045867
[20:53:14.548] iteration 3228 : model1 loss : 0.062945 model2 loss : 0.056714
[20:53:15.225] iteration 3229 : model1 loss : 0.034555 model2 loss : 0.040387
[20:53:15.909] iteration 3230 : model1 loss : 0.025325 model2 loss : 0.028509
[20:53:16.591] iteration 3231 : model1 loss : 0.026935 model2 loss : 0.030131
[20:53:17.285] iteration 3232 : model1 loss : 0.033171 model2 loss : 0.046676
[20:53:17.956] iteration 3233 : model1 loss : 0.126861 model2 loss : 0.062432
[20:53:18.650] iteration 3234 : model1 loss : 0.026928 model2 loss : 0.028706
[20:53:19.336] iteration 3235 : model1 loss : 0.048574 model2 loss : 0.044585
[20:53:20.018] iteration 3236 : model1 loss : 0.035018 model2 loss : 0.036175
[20:53:20.727] iteration 3237 : model1 loss : 0.031020 model2 loss : 0.028677
[20:53:21.411] iteration 3238 : model1 loss : 0.027802 model2 loss : 0.026792
[20:53:22.110] iteration 3239 : model1 loss : 0.030851 model2 loss : 0.033511
[20:53:22.796] iteration 3240 : model1 loss : 0.040001 model2 loss : 0.046411
[20:53:23.490] iteration 3241 : model1 loss : 0.048832 model2 loss : 0.036386
[20:53:24.183] iteration 3242 : model1 loss : 0.038014 model2 loss : 0.041074
[20:53:24.852] iteration 3243 : model1 loss : 0.044949 model2 loss : 0.037177
[20:53:25.541] iteration 3244 : model1 loss : 0.047492 model2 loss : 0.057282
[20:53:26.225] iteration 3245 : model1 loss : 0.059634 model2 loss : 0.101555
[20:53:26.907] iteration 3246 : model1 loss : 0.036064 model2 loss : 0.040490
[20:53:27.594] iteration 3247 : model1 loss : 0.073852 model2 loss : 0.088521
[20:53:28.272] iteration 3248 : model1 loss : 0.093938 model2 loss : 0.074180
[20:53:28.947] iteration 3249 : model1 loss : 0.046961 model2 loss : 0.039442
[20:53:29.626] iteration 3250 : model1 loss : 0.065397 model2 loss : 0.040364
[20:53:30.353] iteration 3251 : model1 loss : 0.026183 model2 loss : 0.026104
[20:53:31.041] iteration 3252 : model1 loss : 0.039657 model2 loss : 0.035847
[20:53:31.714] iteration 3253 : model1 loss : 0.037250 model2 loss : 0.034222
[20:53:32.386] iteration 3254 : model1 loss : 0.027682 model2 loss : 0.027032
[20:53:33.073] iteration 3255 : model1 loss : 0.040379 model2 loss : 0.036157
[20:53:33.757] iteration 3256 : model1 loss : 0.056273 model2 loss : 0.051956
[20:53:34.434] iteration 3257 : model1 loss : 0.069120 model2 loss : 0.042702
[20:53:35.127] iteration 3258 : model1 loss : 0.026896 model2 loss : 0.028012
[20:53:35.810] iteration 3259 : model1 loss : 0.071269 model2 loss : 0.056827
[20:53:36.480] iteration 3260 : model1 loss : 0.067666 model2 loss : 0.085520
[20:53:37.160] iteration 3261 : model1 loss : 0.077773 model2 loss : 0.048583
[20:53:37.845] iteration 3262 : model1 loss : 0.038375 model2 loss : 0.035538
[20:53:38.553] iteration 3263 : model1 loss : 0.025884 model2 loss : 0.029155
[20:53:39.222] iteration 3264 : model1 loss : 0.046354 model2 loss : 0.058155
[20:53:39.923] iteration 3265 : model1 loss : 0.057950 model2 loss : 0.043034
[20:53:40.601] iteration 3266 : model1 loss : 0.046325 model2 loss : 0.042258
[20:53:41.288] iteration 3267 : model1 loss : 0.059189 model2 loss : 0.061947
[20:53:41.963] iteration 3268 : model1 loss : 0.028932 model2 loss : 0.030298
[20:53:42.663] iteration 3269 : model1 loss : 0.037417 model2 loss : 0.041087
[20:53:43.336] iteration 3270 : model1 loss : 0.043001 model2 loss : 0.040360
[20:53:44.019] iteration 3271 : model1 loss : 0.036946 model2 loss : 0.030178
[20:53:44.697] iteration 3272 : model1 loss : 0.061594 model2 loss : 0.048967
[20:53:45.382] iteration 3273 : model1 loss : 0.039513 model2 loss : 0.032731
[20:53:46.057] iteration 3274 : model1 loss : 0.035718 model2 loss : 0.037099
[20:53:46.736] iteration 3275 : model1 loss : 0.042731 model2 loss : 0.038560
[20:53:47.415] iteration 3276 : model1 loss : 0.040283 model2 loss : 0.039101
[20:53:48.119] iteration 3277 : model1 loss : 0.031960 model2 loss : 0.029377
[20:53:48.802] iteration 3278 : model1 loss : 0.032011 model2 loss : 0.030882
[20:53:49.482] iteration 3279 : model1 loss : 0.030782 model2 loss : 0.034230
[20:53:50.152] iteration 3280 : model1 loss : 0.046967 model2 loss : 0.041375
[20:53:50.848] iteration 3281 : model1 loss : 0.092193 model2 loss : 0.078558
[20:53:51.524] iteration 3282 : model1 loss : 0.033595 model2 loss : 0.036112
[20:53:52.209] iteration 3283 : model1 loss : 0.032287 model2 loss : 0.030338
[20:53:52.894] iteration 3284 : model1 loss : 0.094410 model2 loss : 0.092166
[20:53:53.582] iteration 3285 : model1 loss : 0.040329 model2 loss : 0.046507
[20:53:54.274] iteration 3286 : model1 loss : 0.036767 model2 loss : 0.035633
[20:53:54.950] iteration 3287 : model1 loss : 0.040394 model2 loss : 0.073311
[20:53:55.636] iteration 3288 : model1 loss : 0.037608 model2 loss : 0.041217
[20:53:56.332] iteration 3289 : model1 loss : 0.063962 model2 loss : 0.085909
[20:53:57.024] iteration 3290 : model1 loss : 0.047717 model2 loss : 0.057766
[20:53:57.714] iteration 3291 : model1 loss : 0.040943 model2 loss : 0.048214
[20:53:58.383] iteration 3292 : model1 loss : 0.053468 model2 loss : 0.064788
[20:53:59.068] iteration 3293 : model1 loss : 0.043052 model2 loss : 0.035415
[20:53:59.753] iteration 3294 : model1 loss : 0.030787 model2 loss : 0.026492
[20:54:00.444] iteration 3295 : model1 loss : 0.029357 model2 loss : 0.037075
[20:54:01.118] iteration 3296 : model1 loss : 0.038455 model2 loss : 0.034984
[20:54:01.798] iteration 3297 : model1 loss : 0.040081 model2 loss : 0.047554
[20:54:02.475] iteration 3298 : model1 loss : 0.064755 model2 loss : 0.076492
[20:54:03.158] iteration 3299 : model1 loss : 0.086596 model2 loss : 0.070331
[20:54:03.848] iteration 3300 : model1 loss : 0.035957 model2 loss : 0.029940
[20:54:04.566] iteration 3301 : model1 loss : 0.034813 model2 loss : 0.036533
[20:54:05.247] iteration 3302 : model1 loss : 0.028344 model2 loss : 0.030426
[20:54:05.930] iteration 3303 : model1 loss : 0.039802 model2 loss : 0.051879
[20:54:06.618] iteration 3304 : model1 loss : 0.056443 model2 loss : 0.057929
[20:54:07.291] iteration 3305 : model1 loss : 0.048636 model2 loss : 0.035182
[20:54:07.967] iteration 3306 : model1 loss : 0.036524 model2 loss : 0.035270
[20:54:08.664] iteration 3307 : model1 loss : 0.027029 model2 loss : 0.032927
[20:54:09.353] iteration 3308 : model1 loss : 0.029161 model2 loss : 0.039572
[20:54:10.027] iteration 3309 : model1 loss : 0.027704 model2 loss : 0.026330
[20:54:10.710] iteration 3310 : model1 loss : 0.035877 model2 loss : 0.045120
[20:54:11.392] iteration 3311 : model1 loss : 0.042814 model2 loss : 0.088604
[20:54:12.078] iteration 3312 : model1 loss : 0.042790 model2 loss : 0.040749
[20:54:12.755] iteration 3313 : model1 loss : 0.038602 model2 loss : 0.036740
[20:54:13.448] iteration 3314 : model1 loss : 0.026707 model2 loss : 0.029105
[20:54:14.131] iteration 3315 : model1 loss : 0.024146 model2 loss : 0.024107
[20:54:14.809] iteration 3316 : model1 loss : 0.038072 model2 loss : 0.025782
[20:54:15.489] iteration 3317 : model1 loss : 0.040891 model2 loss : 0.035872
[20:54:16.169] iteration 3318 : model1 loss : 0.054264 model2 loss : 0.085214
[20:54:16.852] iteration 3319 : model1 loss : 0.050962 model2 loss : 0.031099
[20:54:17.543] iteration 3320 : model1 loss : 0.040204 model2 loss : 0.041633
[20:54:18.221] iteration 3321 : model1 loss : 0.048844 model2 loss : 0.046297
[20:54:18.912] iteration 3322 : model1 loss : 0.025322 model2 loss : 0.024929
[20:54:19.613] iteration 3323 : model1 loss : 0.087285 model2 loss : 0.088559
[20:54:20.294] iteration 3324 : model1 loss : 0.049370 model2 loss : 0.090379
[20:54:20.990] iteration 3325 : model1 loss : 0.070178 model2 loss : 0.067364
[20:54:21.683] iteration 3326 : model1 loss : 0.038324 model2 loss : 0.040744
[20:54:22.363] iteration 3327 : model1 loss : 0.045313 model2 loss : 0.056074
[20:54:23.048] iteration 3328 : model1 loss : 0.029581 model2 loss : 0.038437
[20:54:23.728] iteration 3329 : model1 loss : 0.037098 model2 loss : 0.052760
[20:54:24.413] iteration 3330 : model1 loss : 0.039698 model2 loss : 0.036172
[20:54:25.086] iteration 3331 : model1 loss : 0.117491 model2 loss : 0.204804
[20:54:25.771] iteration 3332 : model1 loss : 0.042705 model2 loss : 0.034345
[20:54:26.454] iteration 3333 : model1 loss : 0.064418 model2 loss : 0.050236
[20:54:27.130] iteration 3334 : model1 loss : 0.021529 model2 loss : 0.026323
[20:54:27.820] iteration 3335 : model1 loss : 0.043223 model2 loss : 0.045345
[20:54:28.519] iteration 3336 : model1 loss : 0.054016 model2 loss : 0.045225
[20:54:29.209] iteration 3337 : model1 loss : 0.035785 model2 loss : 0.034770
[20:54:29.894] iteration 3338 : model1 loss : 0.070371 model2 loss : 0.113288
[20:54:30.567] iteration 3339 : model1 loss : 0.027947 model2 loss : 0.028306
[20:54:31.256] iteration 3340 : model1 loss : 0.042389 model2 loss : 0.034549
[20:54:31.942] iteration 3341 : model1 loss : 0.042900 model2 loss : 0.080028
[20:54:32.635] iteration 3342 : model1 loss : 0.052316 model2 loss : 0.038328
[20:54:33.322] iteration 3343 : model1 loss : 0.057282 model2 loss : 0.064304
[20:54:34.006] iteration 3344 : model1 loss : 0.036579 model2 loss : 0.039763
[20:54:34.682] iteration 3345 : model1 loss : 0.024883 model2 loss : 0.033533
[20:54:35.365] iteration 3346 : model1 loss : 0.027028 model2 loss : 0.034124
[20:54:36.053] iteration 3347 : model1 loss : 0.042272 model2 loss : 0.047827
[20:54:36.730] iteration 3348 : model1 loss : 0.043803 model2 loss : 0.051426
[20:54:37.411] iteration 3349 : model1 loss : 0.104238 model2 loss : 0.133106
[20:54:38.082] iteration 3350 : model1 loss : 0.054091 model2 loss : 0.043253
[20:54:38.808] iteration 3351 : model1 loss : 0.030482 model2 loss : 0.031446
[20:54:39.505] iteration 3352 : model1 loss : 0.031778 model2 loss : 0.026952
[20:54:40.201] iteration 3353 : model1 loss : 0.059551 model2 loss : 0.067539
[20:54:40.885] iteration 3354 : model1 loss : 0.058156 model2 loss : 0.052361
[20:54:41.558] iteration 3355 : model1 loss : 0.038569 model2 loss : 0.031664
[20:54:42.239] iteration 3356 : model1 loss : 0.039660 model2 loss : 0.040733
[20:54:42.932] iteration 3357 : model1 loss : 0.027715 model2 loss : 0.109300
[20:54:43.613] iteration 3358 : model1 loss : 0.060974 model2 loss : 0.057213
[20:54:44.295] iteration 3359 : model1 loss : 0.056054 model2 loss : 0.095674
[20:54:44.981] iteration 3360 : model1 loss : 0.034101 model2 loss : 0.058077
[20:54:45.659] iteration 3361 : model1 loss : 0.036432 model2 loss : 0.037317
[20:54:46.350] iteration 3362 : model1 loss : 0.044614 model2 loss : 0.060782
[20:54:47.036] iteration 3363 : model1 loss : 0.027777 model2 loss : 0.029872
[20:54:47.713] iteration 3364 : model1 loss : 0.030313 model2 loss : 0.031618
[20:54:48.411] iteration 3365 : model1 loss : 0.038431 model2 loss : 0.041224
[20:54:49.091] iteration 3366 : model1 loss : 0.046651 model2 loss : 0.041065
[20:54:49.766] iteration 3367 : model1 loss : 0.024437 model2 loss : 0.039207
[20:54:50.461] iteration 3368 : model1 loss : 0.028201 model2 loss : 0.031842
[20:54:51.138] iteration 3369 : model1 loss : 0.064446 model2 loss : 0.051792
[20:54:51.827] iteration 3370 : model1 loss : 0.033424 model2 loss : 0.031057
[20:54:52.512] iteration 3371 : model1 loss : 0.156996 model2 loss : 0.164641
[20:54:53.204] iteration 3372 : model1 loss : 0.056078 model2 loss : 0.047146
[20:54:53.884] iteration 3373 : model1 loss : 0.032707 model2 loss : 0.033292
[20:54:54.568] iteration 3374 : model1 loss : 0.095637 model2 loss : 0.053058
[20:54:55.261] iteration 3375 : model1 loss : 0.047288 model2 loss : 0.042192
[20:54:55.940] iteration 3376 : model1 loss : 0.058331 model2 loss : 0.042145
[20:54:56.620] iteration 3377 : model1 loss : 0.031562 model2 loss : 0.046964
[20:54:57.320] iteration 3378 : model1 loss : 0.039409 model2 loss : 0.048779
[20:54:58.004] iteration 3379 : model1 loss : 0.039847 model2 loss : 0.052639
[20:54:58.694] iteration 3380 : model1 loss : 0.050937 model2 loss : 0.047794
[20:54:59.395] iteration 3381 : model1 loss : 0.028896 model2 loss : 0.026456
[20:55:00.074] iteration 3382 : model1 loss : 0.043308 model2 loss : 0.039374
[20:55:00.758] iteration 3383 : model1 loss : 0.066199 model2 loss : 0.047396
[20:55:01.444] iteration 3384 : model1 loss : 0.031290 model2 loss : 0.026846
[20:55:02.132] iteration 3385 : model1 loss : 0.077708 model2 loss : 0.042145
[20:55:02.822] iteration 3386 : model1 loss : 0.066587 model2 loss : 0.092428
[20:55:03.499] iteration 3387 : model1 loss : 0.066080 model2 loss : 0.051461
[20:55:04.192] iteration 3388 : model1 loss : 0.037433 model2 loss : 0.030984
[20:55:04.878] iteration 3389 : model1 loss : 0.025364 model2 loss : 0.028059
[20:55:05.562] iteration 3390 : model1 loss : 0.030352 model2 loss : 0.027872
[20:55:06.258] iteration 3391 : model1 loss : 0.030121 model2 loss : 0.033291
[20:55:06.933] iteration 3392 : model1 loss : 0.041524 model2 loss : 0.036161
[20:55:07.631] iteration 3393 : model1 loss : 0.061223 model2 loss : 0.075576
[20:55:08.336] iteration 3394 : model1 loss : 0.030889 model2 loss : 0.024977
[20:55:09.025] iteration 3395 : model1 loss : 0.043567 model2 loss : 0.041853
[20:55:09.722] iteration 3396 : model1 loss : 0.037841 model2 loss : 0.046809
[20:55:10.412] iteration 3397 : model1 loss : 0.053267 model2 loss : 0.073283
[20:55:11.103] iteration 3398 : model1 loss : 0.106578 model2 loss : 0.118939
[20:55:11.832] iteration 3399 : model1 loss : 0.053972 model2 loss : 0.038080
[20:55:12.555] iteration 3400 : model1 loss : 0.025518 model2 loss : 0.028888
[20:55:31.998] iteration 3400 : model1_mean_dice : 0.823015 model1_mean_hd95 : 8.650947
[20:55:51.296] iteration 3400 : model2_mean_dice : 0.807119 model2_mean_hd95 : 10.735810
[20:55:52.000] iteration 3401 : model1 loss : 0.025360 model2 loss : 0.026513
[20:55:52.673] iteration 3402 : model1 loss : 0.039239 model2 loss : 0.042540
[20:55:53.350] iteration 3403 : model1 loss : 0.039816 model2 loss : 0.031006
[20:55:54.028] iteration 3404 : model1 loss : 0.031935 model2 loss : 0.028988
[20:55:54.703] iteration 3405 : model1 loss : 0.024798 model2 loss : 0.025214
[20:55:55.394] iteration 3406 : model1 loss : 0.032065 model2 loss : 0.039422
[20:55:56.067] iteration 3407 : model1 loss : 0.058399 model2 loss : 0.041926
[20:55:56.740] iteration 3408 : model1 loss : 0.064015 model2 loss : 0.064583
[20:55:57.438] iteration 3409 : model1 loss : 0.037330 model2 loss : 0.041320
[20:55:58.118] iteration 3410 : model1 loss : 0.049081 model2 loss : 0.035456
[20:55:58.790] iteration 3411 : model1 loss : 0.062607 model2 loss : 0.039820
[20:55:59.460] iteration 3412 : model1 loss : 0.037791 model2 loss : 0.033965
[20:56:00.151] iteration 3413 : model1 loss : 0.033397 model2 loss : 0.033598
[20:56:00.832] iteration 3414 : model1 loss : 0.033053 model2 loss : 0.037777
[20:56:01.518] iteration 3415 : model1 loss : 0.034616 model2 loss : 0.035779
[20:56:02.187] iteration 3416 : model1 loss : 0.034061 model2 loss : 0.035602
[20:56:02.858] iteration 3417 : model1 loss : 0.041013 model2 loss : 0.043468
[20:56:03.536] iteration 3418 : model1 loss : 0.048772 model2 loss : 0.041351
[20:56:04.230] iteration 3419 : model1 loss : 0.032666 model2 loss : 0.041066
[20:56:04.924] iteration 3420 : model1 loss : 0.047006 model2 loss : 0.043624
[20:56:05.597] iteration 3421 : model1 loss : 0.047723 model2 loss : 0.078539
[20:56:06.270] iteration 3422 : model1 loss : 0.067010 model2 loss : 0.044565
[20:56:06.959] iteration 3423 : model1 loss : 0.038228 model2 loss : 0.034499
[20:56:07.623] iteration 3424 : model1 loss : 0.031409 model2 loss : 0.029225
[20:56:08.290] iteration 3425 : model1 loss : 0.035718 model2 loss : 0.026736
[20:56:08.977] iteration 3426 : model1 loss : 0.030699 model2 loss : 0.027728
[20:56:09.648] iteration 3427 : model1 loss : 0.036850 model2 loss : 0.062333
[20:56:10.337] iteration 3428 : model1 loss : 0.055799 model2 loss : 0.031020
[20:56:11.025] iteration 3429 : model1 loss : 0.025618 model2 loss : 0.030911
[20:56:11.712] iteration 3430 : model1 loss : 0.053403 model2 loss : 0.052947
[20:56:12.382] iteration 3431 : model1 loss : 0.169813 model2 loss : 0.155104
[20:56:13.062] iteration 3432 : model1 loss : 0.037153 model2 loss : 0.030417
[20:56:13.748] iteration 3433 : model1 loss : 0.043560 model2 loss : 0.038233
[20:56:14.433] iteration 3434 : model1 loss : 0.036268 model2 loss : 0.046874
[20:56:15.111] iteration 3435 : model1 loss : 0.053494 model2 loss : 0.077157
[20:56:15.785] iteration 3436 : model1 loss : 0.028119 model2 loss : 0.026162
[20:56:16.473] iteration 3437 : model1 loss : 0.067770 model2 loss : 0.055069
[20:56:17.151] iteration 3438 : model1 loss : 0.031474 model2 loss : 0.027517
[20:56:17.824] iteration 3439 : model1 loss : 0.036794 model2 loss : 0.039348
[20:56:18.496] iteration 3440 : model1 loss : 0.029349 model2 loss : 0.027307
[20:56:19.183] iteration 3441 : model1 loss : 0.068965 model2 loss : 0.057624
[20:56:19.858] iteration 3442 : model1 loss : 0.036521 model2 loss : 0.036379
[20:56:20.544] iteration 3443 : model1 loss : 0.026889 model2 loss : 0.025949
[20:56:21.238] iteration 3444 : model1 loss : 0.058289 model2 loss : 0.048035
[20:56:21.941] iteration 3445 : model1 loss : 0.038222 model2 loss : 0.031832
[20:56:22.646] iteration 3446 : model1 loss : 0.025839 model2 loss : 0.024868
[20:56:23.339] iteration 3447 : model1 loss : 0.034785 model2 loss : 0.032726
[20:56:24.019] iteration 3448 : model1 loss : 0.042579 model2 loss : 0.046986
[20:56:24.684] iteration 3449 : model1 loss : 0.041347 model2 loss : 0.032649
[20:56:25.378] iteration 3450 : model1 loss : 0.032064 model2 loss : 0.030386
[20:56:26.113] iteration 3451 : model1 loss : 0.030842 model2 loss : 0.027573
[20:56:26.778] iteration 3452 : model1 loss : 0.031389 model2 loss : 0.026867
[20:56:27.463] iteration 3453 : model1 loss : 0.023731 model2 loss : 0.025259
[20:56:28.131] iteration 3454 : model1 loss : 0.034238 model2 loss : 0.035497
[20:56:28.822] iteration 3455 : model1 loss : 0.047324 model2 loss : 0.036658
[20:56:29.497] iteration 3456 : model1 loss : 0.033845 model2 loss : 0.049459
[20:56:30.175] iteration 3457 : model1 loss : 0.028084 model2 loss : 0.033794
[20:56:30.860] iteration 3458 : model1 loss : 0.023643 model2 loss : 0.023888
[20:56:31.533] iteration 3459 : model1 loss : 0.068431 model2 loss : 0.076030
[20:56:32.215] iteration 3460 : model1 loss : 0.024847 model2 loss : 0.025903
[20:56:32.897] iteration 3461 : model1 loss : 0.041146 model2 loss : 0.041247
[20:56:33.589] iteration 3462 : model1 loss : 0.057941 model2 loss : 0.041728
[20:56:34.258] iteration 3463 : model1 loss : 0.038691 model2 loss : 0.032508
[20:56:34.937] iteration 3464 : model1 loss : 0.039938 model2 loss : 0.037108
[20:56:35.621] iteration 3465 : model1 loss : 0.042498 model2 loss : 0.028790
[20:56:36.292] iteration 3466 : model1 loss : 0.026367 model2 loss : 0.028237
[20:56:36.980] iteration 3467 : model1 loss : 0.035498 model2 loss : 0.035105
[20:56:37.660] iteration 3468 : model1 loss : 0.033782 model2 loss : 0.050936
[20:56:38.346] iteration 3469 : model1 loss : 0.028120 model2 loss : 0.029514
[20:56:39.018] iteration 3470 : model1 loss : 0.040499 model2 loss : 0.040872
[20:56:39.717] iteration 3471 : model1 loss : 0.036858 model2 loss : 0.029710
[20:56:40.416] iteration 3472 : model1 loss : 0.049894 model2 loss : 0.034841
[20:56:41.097] iteration 3473 : model1 loss : 0.044090 model2 loss : 0.032955
[20:56:41.789] iteration 3474 : model1 loss : 0.024448 model2 loss : 0.029461
[20:56:42.519] iteration 3475 : model1 loss : 0.047820 model2 loss : 0.043268
[20:56:43.216] iteration 3476 : model1 loss : 0.029697 model2 loss : 0.033849
[20:56:43.907] iteration 3477 : model1 loss : 0.077309 model2 loss : 0.061607
[20:56:44.588] iteration 3478 : model1 loss : 0.043183 model2 loss : 0.042932
[20:56:45.291] iteration 3479 : model1 loss : 0.061586 model2 loss : 0.039982
[20:56:45.978] iteration 3480 : model1 loss : 0.034449 model2 loss : 0.032771
[20:56:46.688] iteration 3481 : model1 loss : 0.037223 model2 loss : 0.044174
[20:56:47.386] iteration 3482 : model1 loss : 0.050305 model2 loss : 0.042118
[20:56:48.069] iteration 3483 : model1 loss : 0.038467 model2 loss : 0.035365
[20:56:48.769] iteration 3484 : model1 loss : 0.045850 model2 loss : 0.038859
[20:56:49.458] iteration 3485 : model1 loss : 0.036304 model2 loss : 0.052310
[20:56:50.156] iteration 3486 : model1 loss : 0.041557 model2 loss : 0.036783
[20:56:50.877] iteration 3487 : model1 loss : 0.032440 model2 loss : 0.028057
[20:56:51.593] iteration 3488 : model1 loss : 0.056235 model2 loss : 0.045724
[20:56:52.302] iteration 3489 : model1 loss : 0.079928 model2 loss : 0.039838
[20:56:52.986] iteration 3490 : model1 loss : 0.035886 model2 loss : 0.034995
[20:56:53.651] iteration 3491 : model1 loss : 0.030539 model2 loss : 0.026022
[20:56:54.342] iteration 3492 : model1 loss : 0.045145 model2 loss : 0.052494
[20:56:55.021] iteration 3493 : model1 loss : 0.032113 model2 loss : 0.030941
[20:56:55.692] iteration 3494 : model1 loss : 0.033307 model2 loss : 0.033203
[20:56:56.382] iteration 3495 : model1 loss : 0.029534 model2 loss : 0.028774
[20:56:57.069] iteration 3496 : model1 loss : 0.039906 model2 loss : 0.048000
[20:56:57.744] iteration 3497 : model1 loss : 0.032671 model2 loss : 0.030338
[20:56:58.411] iteration 3498 : model1 loss : 0.058034 model2 loss : 0.048442
[20:56:59.088] iteration 3499 : model1 loss : 0.036422 model2 loss : 0.039950
[20:56:59.766] iteration 3500 : model1 loss : 0.028943 model2 loss : 0.031194
[20:57:00.506] iteration 3501 : model1 loss : 0.028489 model2 loss : 0.028933
[20:57:01.189] iteration 3502 : model1 loss : 0.036200 model2 loss : 0.030122
[20:57:01.965] iteration 3503 : model1 loss : 0.027854 model2 loss : 0.028931
[20:57:02.696] iteration 3504 : model1 loss : 0.035785 model2 loss : 0.030731
[20:57:03.411] iteration 3505 : model1 loss : 0.037908 model2 loss : 0.034888
[20:57:04.101] iteration 3506 : model1 loss : 0.022699 model2 loss : 0.023201
[20:57:04.791] iteration 3507 : model1 loss : 0.028130 model2 loss : 0.042935
[20:57:05.493] iteration 3508 : model1 loss : 0.066495 model2 loss : 0.061705
[20:57:06.163] iteration 3509 : model1 loss : 0.061481 model2 loss : 0.028648
[20:57:06.843] iteration 3510 : model1 loss : 0.033384 model2 loss : 0.032385
[20:57:07.542] iteration 3511 : model1 loss : 0.024401 model2 loss : 0.028483
[20:57:08.209] iteration 3512 : model1 loss : 0.054432 model2 loss : 0.045498
[20:57:08.889] iteration 3513 : model1 loss : 0.136398 model2 loss : 0.129269
[20:57:09.584] iteration 3514 : model1 loss : 0.031463 model2 loss : 0.026323
[20:57:10.249] iteration 3515 : model1 loss : 0.031441 model2 loss : 0.036994
[20:57:10.950] iteration 3516 : model1 loss : 0.020088 model2 loss : 0.022166
[20:57:11.627] iteration 3517 : model1 loss : 0.033171 model2 loss : 0.044803
[20:57:12.312] iteration 3518 : model1 loss : 0.054986 model2 loss : 0.053910
[20:57:13.005] iteration 3519 : model1 loss : 0.039594 model2 loss : 0.024667
[20:57:13.695] iteration 3520 : model1 loss : 0.043045 model2 loss : 0.035055
[20:57:14.379] iteration 3521 : model1 loss : 0.041931 model2 loss : 0.031424
[20:57:15.052] iteration 3522 : model1 loss : 0.031471 model2 loss : 0.030780
[20:57:15.742] iteration 3523 : model1 loss : 0.047229 model2 loss : 0.038031
[20:57:16.429] iteration 3524 : model1 loss : 0.029754 model2 loss : 0.033876
[20:57:17.104] iteration 3525 : model1 loss : 0.104290 model2 loss : 0.087797
[20:57:17.780] iteration 3526 : model1 loss : 0.048950 model2 loss : 0.056655
[20:57:18.462] iteration 3527 : model1 loss : 0.061232 model2 loss : 0.046501
[20:57:19.152] iteration 3528 : model1 loss : 0.040899 model2 loss : 0.044600
[20:57:19.836] iteration 3529 : model1 loss : 0.195896 model2 loss : 0.167516
[20:57:20.522] iteration 3530 : model1 loss : 0.037076 model2 loss : 0.044573
[20:57:21.198] iteration 3531 : model1 loss : 0.155596 model2 loss : 0.156921
[20:57:21.886] iteration 3532 : model1 loss : 0.061851 model2 loss : 0.084673
[20:57:22.592] iteration 3533 : model1 loss : 0.037074 model2 loss : 0.041462
[20:57:23.278] iteration 3534 : model1 loss : 0.051884 model2 loss : 0.048670
[20:57:23.950] iteration 3535 : model1 loss : 0.048528 model2 loss : 0.042273
[20:57:24.631] iteration 3536 : model1 loss : 0.036454 model2 loss : 0.041013
[20:57:25.312] iteration 3537 : model1 loss : 0.026076 model2 loss : 0.025646
[20:57:25.991] iteration 3538 : model1 loss : 0.051005 model2 loss : 0.055729
[20:57:26.666] iteration 3539 : model1 loss : 0.044262 model2 loss : 0.034542
[20:57:27.358] iteration 3540 : model1 loss : 0.041482 model2 loss : 0.035313
[20:57:28.036] iteration 3541 : model1 loss : 0.028385 model2 loss : 0.021903
[20:57:28.729] iteration 3542 : model1 loss : 0.030804 model2 loss : 0.032248
[20:57:29.414] iteration 3543 : model1 loss : 0.075587 model2 loss : 0.053939
[20:57:30.092] iteration 3544 : model1 loss : 0.053156 model2 loss : 0.034441
[20:57:30.787] iteration 3545 : model1 loss : 0.041129 model2 loss : 0.040472
[20:57:31.460] iteration 3546 : model1 loss : 0.040213 model2 loss : 0.041490
[20:57:32.151] iteration 3547 : model1 loss : 0.050081 model2 loss : 0.047627
[20:57:32.837] iteration 3548 : model1 loss : 0.045240 model2 loss : 0.060923
[20:57:33.524] iteration 3549 : model1 loss : 0.031678 model2 loss : 0.031399
[20:57:34.214] iteration 3550 : model1 loss : 0.023072 model2 loss : 0.023145
[20:57:34.935] iteration 3551 : model1 loss : 0.038487 model2 loss : 0.033062
[20:57:35.614] iteration 3552 : model1 loss : 0.042508 model2 loss : 0.057359
[20:57:36.300] iteration 3553 : model1 loss : 0.046712 model2 loss : 0.041594
[20:57:36.964] iteration 3554 : model1 loss : 0.030409 model2 loss : 0.033963
[20:57:37.649] iteration 3555 : model1 loss : 0.045113 model2 loss : 0.037565
[20:57:38.339] iteration 3556 : model1 loss : 0.057101 model2 loss : 0.032949
[20:57:39.009] iteration 3557 : model1 loss : 0.029206 model2 loss : 0.028431
[20:57:39.694] iteration 3558 : model1 loss : 0.036430 model2 loss : 0.037259
[20:57:40.384] iteration 3559 : model1 loss : 0.029985 model2 loss : 0.035604
[20:57:41.074] iteration 3560 : model1 loss : 0.064860 model2 loss : 0.032649
[20:57:41.754] iteration 3561 : model1 loss : 0.059724 model2 loss : 0.055625
[20:57:42.445] iteration 3562 : model1 loss : 0.023687 model2 loss : 0.026019
[20:57:43.128] iteration 3563 : model1 loss : 0.024322 model2 loss : 0.023436
[20:57:43.811] iteration 3564 : model1 loss : 0.025983 model2 loss : 0.029588
[20:57:44.483] iteration 3565 : model1 loss : 0.028264 model2 loss : 0.030601
[20:57:45.192] iteration 3566 : model1 loss : 0.029312 model2 loss : 0.028805
[20:57:45.869] iteration 3567 : model1 loss : 0.074978 model2 loss : 0.047447
[20:57:46.537] iteration 3568 : model1 loss : 0.025845 model2 loss : 0.027671
[20:57:47.222] iteration 3569 : model1 loss : 0.027468 model2 loss : 0.027519
[20:57:47.910] iteration 3570 : model1 loss : 0.031941 model2 loss : 0.035588
[20:57:48.588] iteration 3571 : model1 loss : 0.032987 model2 loss : 0.038660
[20:57:49.262] iteration 3572 : model1 loss : 0.029166 model2 loss : 0.026346
[20:57:49.931] iteration 3573 : model1 loss : 0.028706 model2 loss : 0.028877
[20:57:50.609] iteration 3574 : model1 loss : 0.038125 model2 loss : 0.027518
[20:57:51.293] iteration 3575 : model1 loss : 0.034770 model2 loss : 0.035594
[20:57:51.978] iteration 3576 : model1 loss : 0.055268 model2 loss : 0.059006
[20:57:52.672] iteration 3577 : model1 loss : 0.043067 model2 loss : 0.034586
[20:57:53.354] iteration 3578 : model1 loss : 0.069788 model2 loss : 0.039566
[20:57:54.038] iteration 3579 : model1 loss : 0.032669 model2 loss : 0.028648
[20:57:54.729] iteration 3580 : model1 loss : 0.041923 model2 loss : 0.062470
[20:57:55.407] iteration 3581 : model1 loss : 0.101577 model2 loss : 0.146782
[20:57:56.082] iteration 3582 : model1 loss : 0.035673 model2 loss : 0.030390
[20:57:56.770] iteration 3583 : model1 loss : 0.039204 model2 loss : 0.038110
[20:57:57.461] iteration 3584 : model1 loss : 0.023020 model2 loss : 0.026752
[20:57:58.130] iteration 3585 : model1 loss : 0.025118 model2 loss : 0.024471
[20:57:58.810] iteration 3586 : model1 loss : 0.031759 model2 loss : 0.031567
[20:57:59.492] iteration 3587 : model1 loss : 0.028559 model2 loss : 0.025205
[20:58:00.175] iteration 3588 : model1 loss : 0.037865 model2 loss : 0.035289
[20:58:00.855] iteration 3589 : model1 loss : 0.032349 model2 loss : 0.047689
[20:58:01.545] iteration 3590 : model1 loss : 0.035972 model2 loss : 0.036331
[20:58:02.242] iteration 3591 : model1 loss : 0.024875 model2 loss : 0.025936
[20:58:02.932] iteration 3592 : model1 loss : 0.049950 model2 loss : 0.046326
[20:58:03.616] iteration 3593 : model1 loss : 0.030751 model2 loss : 0.034606
[20:58:04.286] iteration 3594 : model1 loss : 0.029258 model2 loss : 0.030815
[20:58:04.971] iteration 3595 : model1 loss : 0.047291 model2 loss : 0.044862
[20:58:05.649] iteration 3596 : model1 loss : 0.040756 model2 loss : 0.037904
[20:58:06.318] iteration 3597 : model1 loss : 0.042211 model2 loss : 0.026460
[20:58:06.985] iteration 3598 : model1 loss : 0.034737 model2 loss : 0.036402
[20:58:07.654] iteration 3599 : model1 loss : 0.052069 model2 loss : 0.053170
[20:58:08.339] iteration 3600 : model1 loss : 0.031906 model2 loss : 0.029255
[20:58:27.854] iteration 3600 : model1_mean_dice : 0.834460 model1_mean_hd95 : 10.909961
[20:58:47.173] iteration 3600 : model2_mean_dice : 0.829347 model2_mean_hd95 : 7.994307
[20:58:47.854] iteration 3601 : model1 loss : 0.050914 model2 loss : 0.035141
[20:58:48.554] iteration 3602 : model1 loss : 0.032272 model2 loss : 0.033860
[20:58:49.219] iteration 3603 : model1 loss : 0.065342 model2 loss : 0.034931
[20:58:49.907] iteration 3604 : model1 loss : 0.032010 model2 loss : 0.032389
[20:58:50.586] iteration 3605 : model1 loss : 0.029372 model2 loss : 0.026198
[20:58:51.271] iteration 3606 : model1 loss : 0.075270 model2 loss : 0.070398
[20:58:51.949] iteration 3607 : model1 loss : 0.165602 model2 loss : 0.160870
[20:58:52.651] iteration 3608 : model1 loss : 0.031792 model2 loss : 0.060396
[20:58:53.334] iteration 3609 : model1 loss : 0.025472 model2 loss : 0.028382
[20:58:54.029] iteration 3610 : model1 loss : 0.026754 model2 loss : 0.026546
[20:58:54.713] iteration 3611 : model1 loss : 0.059764 model2 loss : 0.056514
[20:58:55.386] iteration 3612 : model1 loss : 0.042372 model2 loss : 0.036481
[20:58:56.064] iteration 3613 : model1 loss : 0.049860 model2 loss : 0.036593
[20:58:56.726] iteration 3614 : model1 loss : 0.032710 model2 loss : 0.032487
[20:58:57.405] iteration 3615 : model1 loss : 0.038779 model2 loss : 0.030994
[20:58:58.079] iteration 3616 : model1 loss : 0.047372 model2 loss : 0.041179
[20:58:58.760] iteration 3617 : model1 loss : 0.026477 model2 loss : 0.029694
[20:58:59.441] iteration 3618 : model1 loss : 0.023559 model2 loss : 0.022485
[20:59:00.111] iteration 3619 : model1 loss : 0.031461 model2 loss : 0.026723
[20:59:00.787] iteration 3620 : model1 loss : 0.026938 model2 loss : 0.036127
[20:59:01.458] iteration 3621 : model1 loss : 0.025651 model2 loss : 0.026723
[20:59:02.125] iteration 3622 : model1 loss : 0.053848 model2 loss : 0.051822
[20:59:02.807] iteration 3623 : model1 loss : 0.067122 model2 loss : 0.046957
[20:59:03.491] iteration 3624 : model1 loss : 0.031869 model2 loss : 0.037135
[20:59:04.174] iteration 3625 : model1 loss : 0.037652 model2 loss : 0.037846
[20:59:04.853] iteration 3626 : model1 loss : 0.029300 model2 loss : 0.028884
[20:59:05.539] iteration 3627 : model1 loss : 0.034701 model2 loss : 0.030744
[20:59:06.217] iteration 3628 : model1 loss : 0.035464 model2 loss : 0.038483
[20:59:06.894] iteration 3629 : model1 loss : 0.047476 model2 loss : 0.045399
[20:59:07.573] iteration 3630 : model1 loss : 0.048479 model2 loss : 0.057562
[20:59:08.242] iteration 3631 : model1 loss : 0.046503 model2 loss : 0.048606
[20:59:08.925] iteration 3632 : model1 loss : 0.034500 model2 loss : 0.033162
[20:59:09.614] iteration 3633 : model1 loss : 0.053968 model2 loss : 0.051344
[20:59:10.289] iteration 3634 : model1 loss : 0.049997 model2 loss : 0.047034
[20:59:10.962] iteration 3635 : model1 loss : 0.042894 model2 loss : 0.045923
[20:59:11.632] iteration 3636 : model1 loss : 0.033148 model2 loss : 0.023932
[20:59:12.306] iteration 3637 : model1 loss : 0.042465 model2 loss : 0.028090
[20:59:12.981] iteration 3638 : model1 loss : 0.031228 model2 loss : 0.039736
[20:59:13.664] iteration 3639 : model1 loss : 0.025617 model2 loss : 0.029463
[20:59:14.367] iteration 3640 : model1 loss : 0.036487 model2 loss : 0.038296
[20:59:15.051] iteration 3641 : model1 loss : 0.097972 model2 loss : 0.120095
[20:59:15.735] iteration 3642 : model1 loss : 0.042401 model2 loss : 0.047334
[20:59:16.427] iteration 3643 : model1 loss : 0.133762 model2 loss : 0.122010
[20:59:17.107] iteration 3644 : model1 loss : 0.042109 model2 loss : 0.034524
[20:59:17.786] iteration 3645 : model1 loss : 0.041667 model2 loss : 0.035251
[20:59:18.469] iteration 3646 : model1 loss : 0.029604 model2 loss : 0.027567
[20:59:19.154] iteration 3647 : model1 loss : 0.031460 model2 loss : 0.029887
[20:59:19.841] iteration 3648 : model1 loss : 0.036345 model2 loss : 0.024535
[20:59:20.521] iteration 3649 : model1 loss : 0.036065 model2 loss : 0.033373
[20:59:21.209] iteration 3650 : model1 loss : 0.031524 model2 loss : 0.032005
[20:59:21.925] iteration 3651 : model1 loss : 0.067855 model2 loss : 0.075722
[20:59:22.607] iteration 3652 : model1 loss : 0.043574 model2 loss : 0.043184
[20:59:23.303] iteration 3653 : model1 loss : 0.036983 model2 loss : 0.044212
[20:59:24.009] iteration 3654 : model1 loss : 0.167431 model2 loss : 0.168686
[20:59:24.690] iteration 3655 : model1 loss : 0.045290 model2 loss : 0.038084
[20:59:25.377] iteration 3656 : model1 loss : 0.028688 model2 loss : 0.029873
[20:59:26.050] iteration 3657 : model1 loss : 0.024723 model2 loss : 0.028897
[20:59:26.729] iteration 3658 : model1 loss : 0.066911 model2 loss : 0.137568
[20:59:27.434] iteration 3659 : model1 loss : 0.031139 model2 loss : 0.031440
[20:59:28.114] iteration 3660 : model1 loss : 0.070044 model2 loss : 0.056573
[20:59:28.808] iteration 3661 : model1 loss : 0.023727 model2 loss : 0.035117
[20:59:29.489] iteration 3662 : model1 loss : 0.029959 model2 loss : 0.028568
[20:59:30.160] iteration 3663 : model1 loss : 0.022614 model2 loss : 0.022961
[20:59:30.862] iteration 3664 : model1 loss : 0.033763 model2 loss : 0.045367
[20:59:31.539] iteration 3665 : model1 loss : 0.028540 model2 loss : 0.038083
[20:59:32.220] iteration 3666 : model1 loss : 0.029757 model2 loss : 0.030904
[20:59:32.914] iteration 3667 : model1 loss : 0.029134 model2 loss : 0.029774
[20:59:33.614] iteration 3668 : model1 loss : 0.026377 model2 loss : 0.026603
[20:59:34.321] iteration 3669 : model1 loss : 0.063559 model2 loss : 0.033816
[20:59:35.035] iteration 3670 : model1 loss : 0.030492 model2 loss : 0.029124
[20:59:35.750] iteration 3671 : model1 loss : 0.150135 model2 loss : 0.151149
[20:59:36.451] iteration 3672 : model1 loss : 0.046548 model2 loss : 0.042726
[20:59:37.137] iteration 3673 : model1 loss : 0.026270 model2 loss : 0.028287
[20:59:37.818] iteration 3674 : model1 loss : 0.034247 model2 loss : 0.037711
[20:59:38.523] iteration 3675 : model1 loss : 0.146471 model2 loss : 0.150425
[20:59:39.196] iteration 3676 : model1 loss : 0.039443 model2 loss : 0.038030
[20:59:39.868] iteration 3677 : model1 loss : 0.026117 model2 loss : 0.027829
[20:59:40.543] iteration 3678 : model1 loss : 0.043982 model2 loss : 0.051711
[20:59:41.220] iteration 3679 : model1 loss : 0.042308 model2 loss : 0.041823
[20:59:41.902] iteration 3680 : model1 loss : 0.035248 model2 loss : 0.035148
[20:59:42.596] iteration 3681 : model1 loss : 0.028174 model2 loss : 0.033531
[20:59:43.283] iteration 3682 : model1 loss : 0.029084 model2 loss : 0.036548
[20:59:43.966] iteration 3683 : model1 loss : 0.036688 model2 loss : 0.034488
[20:59:44.646] iteration 3684 : model1 loss : 0.035743 model2 loss : 0.042526
[20:59:45.339] iteration 3685 : model1 loss : 0.031712 model2 loss : 0.033338
[20:59:46.021] iteration 3686 : model1 loss : 0.035368 model2 loss : 0.022488
[20:59:46.706] iteration 3687 : model1 loss : 0.042954 model2 loss : 0.038055
[20:59:47.389] iteration 3688 : model1 loss : 0.031120 model2 loss : 0.034550
[20:59:48.070] iteration 3689 : model1 loss : 0.050183 model2 loss : 0.039166
[20:59:48.746] iteration 3690 : model1 loss : 0.034068 model2 loss : 0.038866
[20:59:49.427] iteration 3691 : model1 loss : 0.051863 model2 loss : 0.036612
[20:59:50.120] iteration 3692 : model1 loss : 0.030028 model2 loss : 0.036945
[20:59:50.797] iteration 3693 : model1 loss : 0.044564 model2 loss : 0.036808
[20:59:51.487] iteration 3694 : model1 loss : 0.037620 model2 loss : 0.033902
[20:59:52.166] iteration 3695 : model1 loss : 0.030661 model2 loss : 0.031180
[20:59:52.837] iteration 3696 : model1 loss : 0.027015 model2 loss : 0.031739
[20:59:53.536] iteration 3697 : model1 loss : 0.024194 model2 loss : 0.029094
[20:59:54.225] iteration 3698 : model1 loss : 0.030632 model2 loss : 0.026883
[20:59:54.912] iteration 3699 : model1 loss : 0.047768 model2 loss : 0.029841
[20:59:55.594] iteration 3700 : model1 loss : 0.043802 model2 loss : 0.041911
[20:59:56.306] iteration 3701 : model1 loss : 0.032385 model2 loss : 0.034511
[20:59:56.990] iteration 3702 : model1 loss : 0.045239 model2 loss : 0.042355
[20:59:57.656] iteration 3703 : model1 loss : 0.032124 model2 loss : 0.022689
[20:59:58.343] iteration 3704 : model1 loss : 0.042222 model2 loss : 0.047088
[20:59:59.026] iteration 3705 : model1 loss : 0.041392 model2 loss : 0.035034
[20:59:59.708] iteration 3706 : model1 loss : 0.084862 model2 loss : 0.076373
[21:00:00.410] iteration 3707 : model1 loss : 0.054602 model2 loss : 0.051152
[21:00:01.085] iteration 3708 : model1 loss : 0.031495 model2 loss : 0.032293
[21:00:01.762] iteration 3709 : model1 loss : 0.046896 model2 loss : 0.044601
[21:00:02.460] iteration 3710 : model1 loss : 0.059923 model2 loss : 0.053753
[21:00:03.139] iteration 3711 : model1 loss : 0.046173 model2 loss : 0.047297
[21:00:03.821] iteration 3712 : model1 loss : 0.040208 model2 loss : 0.045104
[21:00:04.503] iteration 3713 : model1 loss : 0.044015 model2 loss : 0.052891
[21:00:05.192] iteration 3714 : model1 loss : 0.065675 model2 loss : 0.043989
[21:00:05.880] iteration 3715 : model1 loss : 0.022931 model2 loss : 0.024311
[21:00:06.560] iteration 3716 : model1 loss : 0.032473 model2 loss : 0.053252
[21:00:07.255] iteration 3717 : model1 loss : 0.023656 model2 loss : 0.022349
[21:00:07.921] iteration 3718 : model1 loss : 0.029450 model2 loss : 0.032552
[21:00:08.616] iteration 3719 : model1 loss : 0.062280 model2 loss : 0.069071
[21:00:09.293] iteration 3720 : model1 loss : 0.114881 model2 loss : 0.076808
[21:00:09.975] iteration 3721 : model1 loss : 0.030670 model2 loss : 0.041132
[21:00:10.645] iteration 3722 : model1 loss : 0.025603 model2 loss : 0.023923
[21:00:11.329] iteration 3723 : model1 loss : 0.091923 model2 loss : 0.083387
[21:00:12.019] iteration 3724 : model1 loss : 0.040776 model2 loss : 0.041048
[21:00:12.698] iteration 3725 : model1 loss : 0.032032 model2 loss : 0.036417
[21:00:13.392] iteration 3726 : model1 loss : 0.021886 model2 loss : 0.036594
[21:00:14.088] iteration 3727 : model1 loss : 0.033048 model2 loss : 0.028065
[21:00:14.772] iteration 3728 : model1 loss : 0.060735 model2 loss : 0.054456
[21:00:15.439] iteration 3729 : model1 loss : 0.025471 model2 loss : 0.027573
[21:00:16.123] iteration 3730 : model1 loss : 0.033874 model2 loss : 0.033531
[21:00:16.806] iteration 3731 : model1 loss : 0.052848 model2 loss : 0.049833
[21:00:17.485] iteration 3732 : model1 loss : 0.045042 model2 loss : 0.046096
[21:00:18.171] iteration 3733 : model1 loss : 0.058958 model2 loss : 0.058426
[21:00:18.856] iteration 3734 : model1 loss : 0.039491 model2 loss : 0.038742
[21:00:19.545] iteration 3735 : model1 loss : 0.245521 model2 loss : 0.225306
[21:00:20.232] iteration 3736 : model1 loss : 0.036344 model2 loss : 0.028807
[21:00:20.900] iteration 3737 : model1 loss : 0.059452 model2 loss : 0.058325
[21:00:21.581] iteration 3738 : model1 loss : 0.032249 model2 loss : 0.047345
[21:00:22.260] iteration 3739 : model1 loss : 0.035819 model2 loss : 0.035059
[21:00:22.927] iteration 3740 : model1 loss : 0.028576 model2 loss : 0.029743
[21:00:23.619] iteration 3741 : model1 loss : 0.034353 model2 loss : 0.041015
[21:00:24.331] iteration 3742 : model1 loss : 0.041385 model2 loss : 0.032455
[21:00:25.006] iteration 3743 : model1 loss : 0.047662 model2 loss : 0.034501
[21:00:25.681] iteration 3744 : model1 loss : 0.054428 model2 loss : 0.031115
[21:00:26.364] iteration 3745 : model1 loss : 0.030638 model2 loss : 0.027816
[21:00:27.049] iteration 3746 : model1 loss : 0.047327 model2 loss : 0.038089
[21:00:27.733] iteration 3747 : model1 loss : 0.040134 model2 loss : 0.051277
[21:00:28.414] iteration 3748 : model1 loss : 0.029459 model2 loss : 0.027641
[21:00:29.112] iteration 3749 : model1 loss : 0.049552 model2 loss : 0.039559
[21:00:29.786] iteration 3750 : model1 loss : 0.059965 model2 loss : 0.082789
[21:00:30.510] iteration 3751 : model1 loss : 0.044119 model2 loss : 0.048627
[21:00:31.186] iteration 3752 : model1 loss : 0.032242 model2 loss : 0.036531
[21:00:31.867] iteration 3753 : model1 loss : 0.033513 model2 loss : 0.035135
[21:00:32.554] iteration 3754 : model1 loss : 0.048004 model2 loss : 0.058530
[21:00:33.227] iteration 3755 : model1 loss : 0.032365 model2 loss : 0.036221
[21:00:33.925] iteration 3756 : model1 loss : 0.047585 model2 loss : 0.045408
[21:00:34.593] iteration 3757 : model1 loss : 0.032426 model2 loss : 0.029434
[21:00:35.272] iteration 3758 : model1 loss : 0.059937 model2 loss : 0.043285
[21:00:35.948] iteration 3759 : model1 loss : 0.028295 model2 loss : 0.042993
[21:00:36.631] iteration 3760 : model1 loss : 0.040558 model2 loss : 0.040419
[21:00:37.335] iteration 3761 : model1 loss : 0.036211 model2 loss : 0.055598
[21:00:38.021] iteration 3762 : model1 loss : 0.023864 model2 loss : 0.024578
[21:00:38.718] iteration 3763 : model1 loss : 0.041102 model2 loss : 0.052595
[21:00:39.404] iteration 3764 : model1 loss : 0.031933 model2 loss : 0.034614
[21:00:40.086] iteration 3765 : model1 loss : 0.033540 model2 loss : 0.028567
[21:00:40.772] iteration 3766 : model1 loss : 0.027384 model2 loss : 0.028958
[21:00:41.456] iteration 3767 : model1 loss : 0.039135 model2 loss : 0.032920
[21:00:42.139] iteration 3768 : model1 loss : 0.033835 model2 loss : 0.030867
[21:00:42.820] iteration 3769 : model1 loss : 0.028442 model2 loss : 0.027043
[21:00:43.501] iteration 3770 : model1 loss : 0.029759 model2 loss : 0.026621
[21:00:44.183] iteration 3771 : model1 loss : 0.090826 model2 loss : 0.095525
[21:00:44.863] iteration 3772 : model1 loss : 0.042185 model2 loss : 0.038489
[21:00:45.545] iteration 3773 : model1 loss : 0.055747 model2 loss : 0.050031
[21:00:46.230] iteration 3774 : model1 loss : 0.057536 model2 loss : 0.041936
[21:00:46.910] iteration 3775 : model1 loss : 0.027164 model2 loss : 0.028608
[21:00:47.587] iteration 3776 : model1 loss : 0.029284 model2 loss : 0.049280
[21:00:48.267] iteration 3777 : model1 loss : 0.025023 model2 loss : 0.024885
[21:00:48.956] iteration 3778 : model1 loss : 0.026824 model2 loss : 0.026063
[21:00:49.653] iteration 3779 : model1 loss : 0.035859 model2 loss : 0.033213
[21:00:50.333] iteration 3780 : model1 loss : 0.026841 model2 loss : 0.027553
[21:00:51.008] iteration 3781 : model1 loss : 0.031743 model2 loss : 0.027529
[21:00:51.688] iteration 3782 : model1 loss : 0.056043 model2 loss : 0.042865
[21:00:52.374] iteration 3783 : model1 loss : 0.030225 model2 loss : 0.030523
[21:00:53.047] iteration 3784 : model1 loss : 0.028527 model2 loss : 0.030606
[21:00:53.732] iteration 3785 : model1 loss : 0.055311 model2 loss : 0.041993
[21:00:54.406] iteration 3786 : model1 loss : 0.029128 model2 loss : 0.028555
[21:00:55.089] iteration 3787 : model1 loss : 0.032019 model2 loss : 0.031365
[21:00:55.771] iteration 3788 : model1 loss : 0.038220 model2 loss : 0.043123
[21:00:56.458] iteration 3789 : model1 loss : 0.070583 model2 loss : 0.098642
[21:00:57.139] iteration 3790 : model1 loss : 0.021113 model2 loss : 0.024796
[21:00:57.816] iteration 3791 : model1 loss : 0.039486 model2 loss : 0.033059
[21:00:58.490] iteration 3792 : model1 loss : 0.053139 model2 loss : 0.043027
[21:00:59.168] iteration 3793 : model1 loss : 0.029360 model2 loss : 0.055075
[21:00:59.850] iteration 3794 : model1 loss : 0.047605 model2 loss : 0.034136
[21:01:00.564] iteration 3795 : model1 loss : 0.034528 model2 loss : 0.046348
[21:01:01.279] iteration 3796 : model1 loss : 0.038906 model2 loss : 0.032885
[21:01:01.975] iteration 3797 : model1 loss : 0.034684 model2 loss : 0.034556
[21:01:02.778] iteration 3798 : model1 loss : 0.029657 model2 loss : 0.026675
[21:01:03.494] iteration 3799 : model1 loss : 0.033835 model2 loss : 0.036504
[21:01:04.185] iteration 3800 : model1 loss : 0.037194 model2 loss : 0.039442
[21:01:23.972] iteration 3800 : model1_mean_dice : 0.789007 model1_mean_hd95 : 12.145920
[21:01:43.346] iteration 3800 : model2_mean_dice : 0.822898 model2_mean_hd95 : 8.341806
[21:01:44.059] iteration 3801 : model1 loss : 0.047328 model2 loss : 0.036642
[21:01:44.733] iteration 3802 : model1 loss : 0.045734 model2 loss : 0.036962
[21:01:45.426] iteration 3803 : model1 loss : 0.061866 model2 loss : 0.081463
[21:01:46.105] iteration 3804 : model1 loss : 0.038955 model2 loss : 0.037938
[21:01:46.763] iteration 3805 : model1 loss : 0.030618 model2 loss : 0.035363
[21:01:47.443] iteration 3806 : model1 loss : 0.034162 model2 loss : 0.036579
[21:01:48.126] iteration 3807 : model1 loss : 0.039832 model2 loss : 0.052726
[21:01:48.818] iteration 3808 : model1 loss : 0.028909 model2 loss : 0.033582
[21:01:49.492] iteration 3809 : model1 loss : 0.026409 model2 loss : 0.029325
[21:01:50.163] iteration 3810 : model1 loss : 0.053540 model2 loss : 0.076287
[21:01:50.841] iteration 3811 : model1 loss : 0.039907 model2 loss : 0.037545
[21:01:51.528] iteration 3812 : model1 loss : 0.022885 model2 loss : 0.032064
[21:01:52.202] iteration 3813 : model1 loss : 0.037821 model2 loss : 0.037419
[21:01:52.883] iteration 3814 : model1 loss : 0.030287 model2 loss : 0.034780
[21:01:53.553] iteration 3815 : model1 loss : 0.025591 model2 loss : 0.026758
[21:01:54.230] iteration 3816 : model1 loss : 0.056296 model2 loss : 0.050606
[21:01:54.917] iteration 3817 : model1 loss : 0.027608 model2 loss : 0.032353
[21:01:55.601] iteration 3818 : model1 loss : 0.043272 model2 loss : 0.039456
[21:01:56.303] iteration 3819 : model1 loss : 0.025312 model2 loss : 0.026063
[21:01:56.981] iteration 3820 : model1 loss : 0.048268 model2 loss : 0.036909
[21:01:57.661] iteration 3821 : model1 loss : 0.038277 model2 loss : 0.033798
[21:01:58.331] iteration 3822 : model1 loss : 0.031782 model2 loss : 0.053928
[21:01:59.003] iteration 3823 : model1 loss : 0.036764 model2 loss : 0.035780
[21:01:59.705] iteration 3824 : model1 loss : 0.034622 model2 loss : 0.032969
[21:02:00.376] iteration 3825 : model1 loss : 0.027898 model2 loss : 0.030620
[21:02:01.056] iteration 3826 : model1 loss : 0.043019 model2 loss : 0.032425
[21:02:01.734] iteration 3827 : model1 loss : 0.035857 model2 loss : 0.035880
[21:02:02.426] iteration 3828 : model1 loss : 0.026599 model2 loss : 0.023956
[21:02:03.123] iteration 3829 : model1 loss : 0.036662 model2 loss : 0.038425
[21:02:03.794] iteration 3830 : model1 loss : 0.020014 model2 loss : 0.020799
[21:02:04.470] iteration 3831 : model1 loss : 0.038213 model2 loss : 0.040374
[21:02:05.149] iteration 3832 : model1 loss : 0.029437 model2 loss : 0.030019
[21:02:05.817] iteration 3833 : model1 loss : 0.047360 model2 loss : 0.047414
[21:02:06.500] iteration 3834 : model1 loss : 0.022252 model2 loss : 0.021647
[21:02:07.182] iteration 3835 : model1 loss : 0.032858 model2 loss : 0.035486
[21:02:07.864] iteration 3836 : model1 loss : 0.028712 model2 loss : 0.030584
[21:02:08.555] iteration 3837 : model1 loss : 0.024474 model2 loss : 0.026554
[21:02:09.242] iteration 3838 : model1 loss : 0.047426 model2 loss : 0.047177
[21:02:09.920] iteration 3839 : model1 loss : 0.040720 model2 loss : 0.049047
[21:02:10.588] iteration 3840 : model1 loss : 0.036564 model2 loss : 0.027841
[21:02:11.278] iteration 3841 : model1 loss : 0.024900 model2 loss : 0.025168
[21:02:11.970] iteration 3842 : model1 loss : 0.027348 model2 loss : 0.031163
[21:02:12.638] iteration 3843 : model1 loss : 0.023302 model2 loss : 0.040325
[21:02:13.323] iteration 3844 : model1 loss : 0.045874 model2 loss : 0.048414
[21:02:14.004] iteration 3845 : model1 loss : 0.038386 model2 loss : 0.036623
[21:02:14.698] iteration 3846 : model1 loss : 0.034704 model2 loss : 0.035732
[21:02:15.390] iteration 3847 : model1 loss : 0.034455 model2 loss : 0.040833
[21:02:16.080] iteration 3848 : model1 loss : 0.026724 model2 loss : 0.024349
[21:02:16.757] iteration 3849 : model1 loss : 0.027260 model2 loss : 0.025381
[21:02:17.446] iteration 3850 : model1 loss : 0.035560 model2 loss : 0.033816
[21:02:18.164] iteration 3851 : model1 loss : 0.036873 model2 loss : 0.048058
[21:02:18.839] iteration 3852 : model1 loss : 0.030681 model2 loss : 0.031281
[21:02:19.534] iteration 3853 : model1 loss : 0.025344 model2 loss : 0.029247
[21:02:20.213] iteration 3854 : model1 loss : 0.028068 model2 loss : 0.029435
[21:02:20.899] iteration 3855 : model1 loss : 0.030647 model2 loss : 0.031316
[21:02:21.573] iteration 3856 : model1 loss : 0.101531 model2 loss : 0.085437
[21:02:22.238] iteration 3857 : model1 loss : 0.030027 model2 loss : 0.033041
[21:02:22.932] iteration 3858 : model1 loss : 0.059457 model2 loss : 0.064181
[21:02:23.611] iteration 3859 : model1 loss : 0.034433 model2 loss : 0.031068
[21:02:24.287] iteration 3860 : model1 loss : 0.033068 model2 loss : 0.034514
[21:02:25.009] iteration 3861 : model1 loss : 0.041566 model2 loss : 0.035220
[21:02:25.703] iteration 3862 : model1 loss : 0.037923 model2 loss : 0.039324
[21:02:26.391] iteration 3863 : model1 loss : 0.028761 model2 loss : 0.035016
[21:02:27.069] iteration 3864 : model1 loss : 0.022102 model2 loss : 0.022432
[21:02:27.752] iteration 3865 : model1 loss : 0.061825 model2 loss : 0.056480
[21:02:28.446] iteration 3866 : model1 loss : 0.052515 model2 loss : 0.039416
[21:02:29.116] iteration 3867 : model1 loss : 0.050634 model2 loss : 0.052592
[21:02:29.796] iteration 3868 : model1 loss : 0.035367 model2 loss : 0.032571
[21:02:30.475] iteration 3869 : model1 loss : 0.034537 model2 loss : 0.036306
[21:02:31.164] iteration 3870 : model1 loss : 0.061344 model2 loss : 0.086572
[21:02:31.847] iteration 3871 : model1 loss : 0.073498 model2 loss : 0.064680
[21:02:32.541] iteration 3872 : model1 loss : 0.040284 model2 loss : 0.039274
[21:02:33.221] iteration 3873 : model1 loss : 0.023384 model2 loss : 0.026667
[21:02:33.896] iteration 3874 : model1 loss : 0.077837 model2 loss : 0.063368
[21:02:34.574] iteration 3875 : model1 loss : 0.048576 model2 loss : 0.056787
[21:02:35.257] iteration 3876 : model1 loss : 0.024561 model2 loss : 0.027997
[21:02:35.937] iteration 3877 : model1 loss : 0.032150 model2 loss : 0.031628
[21:02:36.643] iteration 3878 : model1 loss : 0.033589 model2 loss : 0.037142
[21:02:37.322] iteration 3879 : model1 loss : 0.026853 model2 loss : 0.024126
[21:02:38.005] iteration 3880 : model1 loss : 0.070181 model2 loss : 0.052999
[21:02:38.688] iteration 3881 : model1 loss : 0.031739 model2 loss : 0.030892
[21:02:39.366] iteration 3882 : model1 loss : 0.145380 model2 loss : 0.067795
[21:02:40.035] iteration 3883 : model1 loss : 0.024699 model2 loss : 0.024941
[21:02:40.709] iteration 3884 : model1 loss : 0.052279 model2 loss : 0.052936
[21:02:41.384] iteration 3885 : model1 loss : 0.031312 model2 loss : 0.064333
[21:02:42.078] iteration 3886 : model1 loss : 0.029475 model2 loss : 0.028577
[21:02:42.767] iteration 3887 : model1 loss : 0.035254 model2 loss : 0.034129
[21:02:43.457] iteration 3888 : model1 loss : 0.035859 model2 loss : 0.043614
[21:02:44.130] iteration 3889 : model1 loss : 0.030391 model2 loss : 0.044484
[21:02:44.815] iteration 3890 : model1 loss : 0.041067 model2 loss : 0.039283
[21:02:45.557] iteration 3891 : model1 loss : 0.037084 model2 loss : 0.042403
[21:02:46.239] iteration 3892 : model1 loss : 0.030430 model2 loss : 0.031776
[21:02:46.922] iteration 3893 : model1 loss : 0.050603 model2 loss : 0.089123
[21:02:47.604] iteration 3894 : model1 loss : 0.026636 model2 loss : 0.027406
[21:02:48.287] iteration 3895 : model1 loss : 0.137109 model2 loss : 0.184550
[21:02:48.963] iteration 3896 : model1 loss : 0.040702 model2 loss : 0.026221
[21:02:49.636] iteration 3897 : model1 loss : 0.044436 model2 loss : 0.042084
[21:02:50.323] iteration 3898 : model1 loss : 0.028161 model2 loss : 0.034047
[21:02:51.017] iteration 3899 : model1 loss : 0.046691 model2 loss : 0.034674
[21:02:51.708] iteration 3900 : model1 loss : 0.039516 model2 loss : 0.051607
[21:02:52.578] iteration 3901 : model1 loss : 0.031334 model2 loss : 0.027365
[21:02:53.323] iteration 3902 : model1 loss : 0.044180 model2 loss : 0.058128
[21:02:54.068] iteration 3903 : model1 loss : 0.162980 model2 loss : 0.174526
[21:02:54.818] iteration 3904 : model1 loss : 0.036994 model2 loss : 0.029425
[21:02:55.629] iteration 3905 : model1 loss : 0.026979 model2 loss : 0.033837
[21:02:56.345] iteration 3906 : model1 loss : 0.034198 model2 loss : 0.029988
[21:02:57.066] iteration 3907 : model1 loss : 0.153803 model2 loss : 0.152669
[21:02:57.773] iteration 3908 : model1 loss : 0.034575 model2 loss : 0.038997
[21:02:58.496] iteration 3909 : model1 loss : 0.107672 model2 loss : 0.080278
[21:02:59.211] iteration 3910 : model1 loss : 0.034137 model2 loss : 0.034507
[21:02:59.935] iteration 3911 : model1 loss : 0.030696 model2 loss : 0.028529
[21:03:00.655] iteration 3912 : model1 loss : 0.037517 model2 loss : 0.043383
[21:03:01.398] iteration 3913 : model1 loss : 0.082911 model2 loss : 0.050691
[21:03:02.139] iteration 3914 : model1 loss : 0.029062 model2 loss : 0.030021
[21:03:02.894] iteration 3915 : model1 loss : 0.111512 model2 loss : 0.090296
[21:03:03.681] iteration 3916 : model1 loss : 0.027793 model2 loss : 0.041571
[21:03:04.400] iteration 3917 : model1 loss : 0.026403 model2 loss : 0.028831
[21:03:05.101] iteration 3918 : model1 loss : 0.028743 model2 loss : 0.029948
[21:03:05.786] iteration 3919 : model1 loss : 0.025274 model2 loss : 0.029505
[21:03:06.462] iteration 3920 : model1 loss : 0.035856 model2 loss : 0.041088
[21:03:07.135] iteration 3921 : model1 loss : 0.048838 model2 loss : 0.040340
[21:03:07.805] iteration 3922 : model1 loss : 0.025597 model2 loss : 0.026310
[21:03:08.483] iteration 3923 : model1 loss : 0.023799 model2 loss : 0.021565
[21:03:09.160] iteration 3924 : model1 loss : 0.050156 model2 loss : 0.062841
[21:03:09.847] iteration 3925 : model1 loss : 0.021379 model2 loss : 0.020576
[21:03:10.523] iteration 3926 : model1 loss : 0.065389 model2 loss : 0.052498
[21:03:11.201] iteration 3927 : model1 loss : 0.033343 model2 loss : 0.033834
[21:03:11.874] iteration 3928 : model1 loss : 0.031050 model2 loss : 0.033803
[21:03:12.549] iteration 3929 : model1 loss : 0.028802 model2 loss : 0.036320
[21:03:13.228] iteration 3930 : model1 loss : 0.023741 model2 loss : 0.028790
[21:03:13.902] iteration 3931 : model1 loss : 0.044066 model2 loss : 0.035681
[21:03:14.585] iteration 3932 : model1 loss : 0.026545 model2 loss : 0.025731
[21:03:15.272] iteration 3933 : model1 loss : 0.121308 model2 loss : 0.143549
[21:03:15.954] iteration 3934 : model1 loss : 0.033055 model2 loss : 0.035319
[21:03:16.643] iteration 3935 : model1 loss : 0.030693 model2 loss : 0.032941
[21:03:17.323] iteration 3936 : model1 loss : 0.046582 model2 loss : 0.068850
[21:03:18.006] iteration 3937 : model1 loss : 0.029538 model2 loss : 0.031248
[21:03:18.691] iteration 3938 : model1 loss : 0.037220 model2 loss : 0.036151
[21:03:19.387] iteration 3939 : model1 loss : 0.059638 model2 loss : 0.044560
[21:03:20.076] iteration 3940 : model1 loss : 0.047090 model2 loss : 0.041156
[21:03:20.777] iteration 3941 : model1 loss : 0.066572 model2 loss : 0.067685
[21:03:21.466] iteration 3942 : model1 loss : 0.040513 model2 loss : 0.038190
[21:03:22.138] iteration 3943 : model1 loss : 0.057891 model2 loss : 0.077033
[21:03:22.830] iteration 3944 : model1 loss : 0.067458 model2 loss : 0.048516
[21:03:23.513] iteration 3945 : model1 loss : 0.026776 model2 loss : 0.025659
[21:03:24.188] iteration 3946 : model1 loss : 0.062694 model2 loss : 0.049469
[21:03:24.866] iteration 3947 : model1 loss : 0.043369 model2 loss : 0.025360
[21:03:25.585] iteration 3948 : model1 loss : 0.042478 model2 loss : 0.046481
[21:03:26.281] iteration 3949 : model1 loss : 0.031304 model2 loss : 0.033382
[21:03:26.961] iteration 3950 : model1 loss : 0.027132 model2 loss : 0.026661
[21:03:27.681] iteration 3951 : model1 loss : 0.033831 model2 loss : 0.031635
[21:03:28.371] iteration 3952 : model1 loss : 0.031476 model2 loss : 0.029489
[21:03:29.051] iteration 3953 : model1 loss : 0.029438 model2 loss : 0.032406
[21:03:29.740] iteration 3954 : model1 loss : 0.030984 model2 loss : 0.030783
[21:03:30.420] iteration 3955 : model1 loss : 0.046107 model2 loss : 0.040240
[21:03:31.107] iteration 3956 : model1 loss : 0.064025 model2 loss : 0.072015
[21:03:31.789] iteration 3957 : model1 loss : 0.047237 model2 loss : 0.057243
[21:03:32.474] iteration 3958 : model1 loss : 0.025044 model2 loss : 0.029041
[21:03:33.159] iteration 3959 : model1 loss : 0.045415 model2 loss : 0.043825
[21:03:33.849] iteration 3960 : model1 loss : 0.053974 model2 loss : 0.081527
[21:03:34.521] iteration 3961 : model1 loss : 0.031998 model2 loss : 0.035639
[21:03:35.213] iteration 3962 : model1 loss : 0.087464 model2 loss : 0.108673
[21:03:35.891] iteration 3963 : model1 loss : 0.053366 model2 loss : 0.073035
[21:03:36.568] iteration 3964 : model1 loss : 0.038799 model2 loss : 0.040677
[21:03:37.255] iteration 3965 : model1 loss : 0.031009 model2 loss : 0.044412
[21:03:37.944] iteration 3966 : model1 loss : 0.056852 model2 loss : 0.058777
[21:03:38.617] iteration 3967 : model1 loss : 0.074293 model2 loss : 0.097684
[21:03:39.298] iteration 3968 : model1 loss : 0.035580 model2 loss : 0.036808
[21:03:39.974] iteration 3969 : model1 loss : 0.035978 model2 loss : 0.033281
[21:03:40.648] iteration 3970 : model1 loss : 0.023213 model2 loss : 0.028482
[21:03:41.325] iteration 3971 : model1 loss : 0.069843 model2 loss : 0.069296
[21:03:42.014] iteration 3972 : model1 loss : 0.035700 model2 loss : 0.039616
[21:03:42.704] iteration 3973 : model1 loss : 0.048371 model2 loss : 0.083370
[21:03:43.388] iteration 3974 : model1 loss : 0.039394 model2 loss : 0.034587
[21:03:44.068] iteration 3975 : model1 loss : 0.057244 model2 loss : 0.058670
[21:03:44.751] iteration 3976 : model1 loss : 0.029637 model2 loss : 0.031848
[21:03:45.440] iteration 3977 : model1 loss : 0.042502 model2 loss : 0.041364
[21:03:46.129] iteration 3978 : model1 loss : 0.025855 model2 loss : 0.030808
[21:03:46.818] iteration 3979 : model1 loss : 0.025524 model2 loss : 0.046742
[21:03:47.495] iteration 3980 : model1 loss : 0.054149 model2 loss : 0.061062
[21:03:48.180] iteration 3981 : model1 loss : 0.032358 model2 loss : 0.075701
[21:03:48.875] iteration 3982 : model1 loss : 0.026484 model2 loss : 0.047597
[21:03:49.550] iteration 3983 : model1 loss : 0.037556 model2 loss : 0.039931
[21:03:50.240] iteration 3984 : model1 loss : 0.077239 model2 loss : 0.081354
[21:03:50.919] iteration 3985 : model1 loss : 0.029613 model2 loss : 0.037983
[21:03:51.599] iteration 3986 : model1 loss : 0.023521 model2 loss : 0.024846
[21:03:52.294] iteration 3987 : model1 loss : 0.034085 model2 loss : 0.041742
[21:03:52.978] iteration 3988 : model1 loss : 0.057452 model2 loss : 0.106805
[21:03:53.662] iteration 3989 : model1 loss : 0.033073 model2 loss : 0.044080
[21:03:54.346] iteration 3990 : model1 loss : 0.024649 model2 loss : 0.026539
[21:03:55.017] iteration 3991 : model1 loss : 0.035888 model2 loss : 0.037546
[21:03:55.698] iteration 3992 : model1 loss : 0.053097 model2 loss : 0.098130
[21:03:56.378] iteration 3993 : model1 loss : 0.029757 model2 loss : 0.037492
[21:03:57.058] iteration 3994 : model1 loss : 0.026128 model2 loss : 0.033703
[21:03:57.742] iteration 3995 : model1 loss : 0.050087 model2 loss : 0.037231
[21:03:58.422] iteration 3996 : model1 loss : 0.112572 model2 loss : 0.090041
[21:03:59.105] iteration 3997 : model1 loss : 0.030710 model2 loss : 0.063261
[21:03:59.788] iteration 3998 : model1 loss : 0.055842 model2 loss : 0.055534
[21:04:00.477] iteration 3999 : model1 loss : 0.035957 model2 loss : 0.035866
[21:04:01.149] iteration 4000 : model1 loss : 0.029480 model2 loss : 0.039935
[21:04:19.715] iteration 4000 : model1_mean_dice : 0.819633 model1_mean_hd95 : 3.915628
[21:04:38.723] iteration 4000 : model2_mean_dice : 0.802309 model2_mean_hd95 : 3.603527
[21:04:39.431] iteration 4001 : model1 loss : 0.039068 model2 loss : 0.050744
[21:04:40.116] iteration 4002 : model1 loss : 0.055774 model2 loss : 0.118405
[21:04:40.786] iteration 4003 : model1 loss : 0.030347 model2 loss : 0.052061
[21:04:41.467] iteration 4004 : model1 loss : 0.036024 model2 loss : 0.041503
[21:04:42.149] iteration 4005 : model1 loss : 0.035470 model2 loss : 0.046519
[21:04:42.835] iteration 4006 : model1 loss : 0.033161 model2 loss : 0.037080
[21:04:43.517] iteration 4007 : model1 loss : 0.060074 model2 loss : 0.033584
[21:04:44.198] iteration 4008 : model1 loss : 0.057616 model2 loss : 0.033385
[21:04:44.880] iteration 4009 : model1 loss : 0.101356 model2 loss : 0.075946
[21:04:45.541] iteration 4010 : model1 loss : 0.040245 model2 loss : 0.051212
[21:04:46.227] iteration 4011 : model1 loss : 0.046422 model2 loss : 0.047366
[21:04:46.906] iteration 4012 : model1 loss : 0.034747 model2 loss : 0.063804
[21:04:47.590] iteration 4013 : model1 loss : 0.029105 model2 loss : 0.035360
[21:04:48.260] iteration 4014 : model1 loss : 0.073154 model2 loss : 0.084065
[21:04:48.937] iteration 4015 : model1 loss : 0.070405 model2 loss : 0.050422
[21:04:49.605] iteration 4016 : model1 loss : 0.046390 model2 loss : 0.050887
[21:04:50.284] iteration 4017 : model1 loss : 0.045968 model2 loss : 0.043056
[21:04:50.956] iteration 4018 : model1 loss : 0.036445 model2 loss : 0.046704
[21:04:51.631] iteration 4019 : model1 loss : 0.045787 model2 loss : 0.044085
[21:04:52.323] iteration 4020 : model1 loss : 0.058626 model2 loss : 0.047172
[21:04:52.987] iteration 4021 : model1 loss : 0.060736 model2 loss : 0.065658
[21:04:53.650] iteration 4022 : model1 loss : 0.030149 model2 loss : 0.031051
[21:04:54.328] iteration 4023 : model1 loss : 0.033141 model2 loss : 0.033848
[21:04:55.006] iteration 4024 : model1 loss : 0.047048 model2 loss : 0.042591
[21:04:55.680] iteration 4025 : model1 loss : 0.024135 model2 loss : 0.025856
[21:04:56.365] iteration 4026 : model1 loss : 0.092178 model2 loss : 0.081838
[21:04:57.037] iteration 4027 : model1 loss : 0.023980 model2 loss : 0.031370
[21:04:57.736] iteration 4028 : model1 loss : 0.021766 model2 loss : 0.023908
[21:04:58.410] iteration 4029 : model1 loss : 0.051306 model2 loss : 0.056797
[21:04:59.093] iteration 4030 : model1 loss : 0.038454 model2 loss : 0.035215
[21:04:59.766] iteration 4031 : model1 loss : 0.035536 model2 loss : 0.035786
[21:05:00.444] iteration 4032 : model1 loss : 0.028124 model2 loss : 0.032217
[21:05:01.132] iteration 4033 : model1 loss : 0.061777 model2 loss : 0.031512
[21:05:01.805] iteration 4034 : model1 loss : 0.044550 model2 loss : 0.034821
[21:05:02.490] iteration 4035 : model1 loss : 0.105691 model2 loss : 0.090546
[21:05:03.163] iteration 4036 : model1 loss : 0.038128 model2 loss : 0.029739
[21:05:03.836] iteration 4037 : model1 loss : 0.034817 model2 loss : 0.031288
[21:05:04.522] iteration 4038 : model1 loss : 0.026033 model2 loss : 0.028209
[21:05:05.199] iteration 4039 : model1 loss : 0.051762 model2 loss : 0.049245
[21:05:05.874] iteration 4040 : model1 loss : 0.031595 model2 loss : 0.037425
[21:05:06.559] iteration 4041 : model1 loss : 0.029437 model2 loss : 0.031891
[21:05:07.234] iteration 4042 : model1 loss : 0.024056 model2 loss : 0.022930
[21:05:07.907] iteration 4043 : model1 loss : 0.054763 model2 loss : 0.044596
[21:05:08.585] iteration 4044 : model1 loss : 0.023917 model2 loss : 0.024450
[21:05:09.267] iteration 4045 : model1 loss : 0.037984 model2 loss : 0.038215
[21:05:09.949] iteration 4046 : model1 loss : 0.061543 model2 loss : 0.068254
[21:05:10.642] iteration 4047 : model1 loss : 0.027484 model2 loss : 0.025380
[21:05:11.316] iteration 4048 : model1 loss : 0.082393 model2 loss : 0.086159
[21:05:11.992] iteration 4049 : model1 loss : 0.094496 model2 loss : 0.071977
[21:05:12.697] iteration 4050 : model1 loss : 0.048030 model2 loss : 0.035595
[21:05:13.433] iteration 4051 : model1 loss : 0.052614 model2 loss : 0.054359
[21:05:14.117] iteration 4052 : model1 loss : 0.033205 model2 loss : 0.029660
[21:05:14.785] iteration 4053 : model1 loss : 0.038638 model2 loss : 0.038089
[21:05:15.469] iteration 4054 : model1 loss : 0.027722 model2 loss : 0.041363
[21:05:16.151] iteration 4055 : model1 loss : 0.026641 model2 loss : 0.031221
[21:05:16.830] iteration 4056 : model1 loss : 0.030725 model2 loss : 0.028591
[21:05:17.503] iteration 4057 : model1 loss : 0.046590 model2 loss : 0.064112
[21:05:18.187] iteration 4058 : model1 loss : 0.035567 model2 loss : 0.035389
[21:05:18.866] iteration 4059 : model1 loss : 0.027221 model2 loss : 0.026873
[21:05:19.551] iteration 4060 : model1 loss : 0.032496 model2 loss : 0.035561
[21:05:20.236] iteration 4061 : model1 loss : 0.028612 model2 loss : 0.031736
[21:05:20.928] iteration 4062 : model1 loss : 0.028044 model2 loss : 0.031973
[21:05:21.605] iteration 4063 : model1 loss : 0.026178 model2 loss : 0.027664
[21:05:22.292] iteration 4064 : model1 loss : 0.028695 model2 loss : 0.032332
[21:05:22.969] iteration 4065 : model1 loss : 0.045215 model2 loss : 0.050071
[21:05:23.653] iteration 4066 : model1 loss : 0.023508 model2 loss : 0.030865
[21:05:24.329] iteration 4067 : model1 loss : 0.038166 model2 loss : 0.039648
[21:05:25.003] iteration 4068 : model1 loss : 0.026524 model2 loss : 0.029336
[21:05:25.683] iteration 4069 : model1 loss : 0.079392 model2 loss : 0.071061
[21:05:26.408] iteration 4070 : model1 loss : 0.033701 model2 loss : 0.037472
[21:05:27.095] iteration 4071 : model1 loss : 0.033554 model2 loss : 0.027558
[21:05:27.778] iteration 4072 : model1 loss : 0.040011 model2 loss : 0.038636
[21:05:28.457] iteration 4073 : model1 loss : 0.023170 model2 loss : 0.023759
[21:05:29.127] iteration 4074 : model1 loss : 0.038380 model2 loss : 0.035240
[21:05:29.809] iteration 4075 : model1 loss : 0.089164 model2 loss : 0.049084
[21:05:30.479] iteration 4076 : model1 loss : 0.029076 model2 loss : 0.025267
[21:05:31.167] iteration 4077 : model1 loss : 0.042991 model2 loss : 0.035621
[21:05:31.841] iteration 4078 : model1 loss : 0.081889 model2 loss : 0.093899
[21:05:32.525] iteration 4079 : model1 loss : 0.021319 model2 loss : 0.023678
[21:05:33.209] iteration 4080 : model1 loss : 0.024325 model2 loss : 0.027794
[21:05:33.894] iteration 4081 : model1 loss : 0.022456 model2 loss : 0.024417
[21:05:34.566] iteration 4082 : model1 loss : 0.030399 model2 loss : 0.031299
[21:05:35.258] iteration 4083 : model1 loss : 0.041276 model2 loss : 0.043332
[21:05:35.931] iteration 4084 : model1 loss : 0.041845 model2 loss : 0.044389
[21:05:36.611] iteration 4085 : model1 loss : 0.037378 model2 loss : 0.034553
[21:05:37.291] iteration 4086 : model1 loss : 0.031567 model2 loss : 0.032618
[21:05:37.968] iteration 4087 : model1 loss : 0.035142 model2 loss : 0.035680
[21:05:38.651] iteration 4088 : model1 loss : 0.058566 model2 loss : 0.048130
[21:05:39.343] iteration 4089 : model1 loss : 0.024794 model2 loss : 0.029002
[21:05:40.034] iteration 4090 : model1 loss : 0.041222 model2 loss : 0.045322
[21:05:40.712] iteration 4091 : model1 loss : 0.057951 model2 loss : 0.070608
[21:05:41.394] iteration 4092 : model1 loss : 0.032415 model2 loss : 0.030514
[21:05:42.075] iteration 4093 : model1 loss : 0.077020 model2 loss : 0.066544
[21:05:42.758] iteration 4094 : model1 loss : 0.026961 model2 loss : 0.026820
[21:05:43.446] iteration 4095 : model1 loss : 0.038348 model2 loss : 0.040901
[21:05:44.129] iteration 4096 : model1 loss : 0.040235 model2 loss : 0.034359
[21:05:44.806] iteration 4097 : model1 loss : 0.047178 model2 loss : 0.035935
[21:05:45.478] iteration 4098 : model1 loss : 0.025920 model2 loss : 0.029523
[21:05:46.172] iteration 4099 : model1 loss : 0.027862 model2 loss : 0.035181
[21:05:46.849] iteration 4100 : model1 loss : 0.036647 model2 loss : 0.067846
[21:05:47.580] iteration 4101 : model1 loss : 0.036709 model2 loss : 0.029009
[21:05:48.257] iteration 4102 : model1 loss : 0.025257 model2 loss : 0.023228
[21:05:48.935] iteration 4103 : model1 loss : 0.041077 model2 loss : 0.059090
[21:05:49.621] iteration 4104 : model1 loss : 0.028036 model2 loss : 0.031007
[21:05:50.299] iteration 4105 : model1 loss : 0.028166 model2 loss : 0.026167
[21:05:50.974] iteration 4106 : model1 loss : 0.037372 model2 loss : 0.042041
[21:05:51.657] iteration 4107 : model1 loss : 0.040229 model2 loss : 0.035459
[21:05:52.339] iteration 4108 : model1 loss : 0.035346 model2 loss : 0.039991
[21:05:53.036] iteration 4109 : model1 loss : 0.042422 model2 loss : 0.079859
[21:05:53.710] iteration 4110 : model1 loss : 0.034496 model2 loss : 0.034966
[21:05:54.395] iteration 4111 : model1 loss : 0.024500 model2 loss : 0.024880
[21:05:55.085] iteration 4112 : model1 loss : 0.021917 model2 loss : 0.025160
[21:05:55.765] iteration 4113 : model1 loss : 0.042400 model2 loss : 0.031870
[21:05:56.450] iteration 4114 : model1 loss : 0.036789 model2 loss : 0.038202
[21:05:57.129] iteration 4115 : model1 loss : 0.026453 model2 loss : 0.026752
[21:05:57.811] iteration 4116 : model1 loss : 0.030471 model2 loss : 0.036639
[21:05:58.507] iteration 4117 : model1 loss : 0.033883 model2 loss : 0.040933
[21:05:59.195] iteration 4118 : model1 loss : 0.026076 model2 loss : 0.031266
[21:05:59.870] iteration 4119 : model1 loss : 0.040953 model2 loss : 0.033866
[21:06:00.555] iteration 4120 : model1 loss : 0.028325 model2 loss : 0.036041
[21:06:01.240] iteration 4121 : model1 loss : 0.024534 model2 loss : 0.100380
[21:06:01.933] iteration 4122 : model1 loss : 0.032806 model2 loss : 0.032045
[21:06:02.620] iteration 4123 : model1 loss : 0.029086 model2 loss : 0.036828
[21:06:03.302] iteration 4124 : model1 loss : 0.044334 model2 loss : 0.103479
[21:06:03.985] iteration 4125 : model1 loss : 0.026519 model2 loss : 0.027803
[21:06:04.658] iteration 4126 : model1 loss : 0.056343 model2 loss : 0.075760
[21:06:05.340] iteration 4127 : model1 loss : 0.031647 model2 loss : 0.030114
[21:06:06.020] iteration 4128 : model1 loss : 0.050358 model2 loss : 0.072152
[21:06:06.695] iteration 4129 : model1 loss : 0.027048 model2 loss : 0.033645
[21:06:07.372] iteration 4130 : model1 loss : 0.024078 model2 loss : 0.022095
[21:06:08.051] iteration 4131 : model1 loss : 0.023500 model2 loss : 0.034371
[21:06:08.733] iteration 4132 : model1 loss : 0.031567 model2 loss : 0.052260
[21:06:09.419] iteration 4133 : model1 loss : 0.032686 model2 loss : 0.025543
[21:06:10.097] iteration 4134 : model1 loss : 0.037628 model2 loss : 0.026989
[21:06:10.777] iteration 4135 : model1 loss : 0.034041 model2 loss : 0.039408
[21:06:11.461] iteration 4136 : model1 loss : 0.023523 model2 loss : 0.033192
[21:06:12.132] iteration 4137 : model1 loss : 0.044316 model2 loss : 0.040281
[21:06:12.820] iteration 4138 : model1 loss : 0.037319 model2 loss : 0.053221
[21:06:13.495] iteration 4139 : model1 loss : 0.043757 model2 loss : 0.070797
[21:06:14.178] iteration 4140 : model1 loss : 0.025428 model2 loss : 0.025151
[21:06:14.859] iteration 4141 : model1 loss : 0.037973 model2 loss : 0.049417
[21:06:15.552] iteration 4142 : model1 loss : 0.027733 model2 loss : 0.030844
[21:06:16.237] iteration 4143 : model1 loss : 0.045157 model2 loss : 0.043729
[21:06:16.934] iteration 4144 : model1 loss : 0.032662 model2 loss : 0.050848
[21:06:17.609] iteration 4145 : model1 loss : 0.027890 model2 loss : 0.030843
[21:06:18.295] iteration 4146 : model1 loss : 0.031956 model2 loss : 0.035774
[21:06:18.964] iteration 4147 : model1 loss : 0.025730 model2 loss : 0.031625
[21:06:19.651] iteration 4148 : model1 loss : 0.079225 model2 loss : 0.066577
[21:06:20.342] iteration 4149 : model1 loss : 0.033162 model2 loss : 0.035961
[21:06:21.031] iteration 4150 : model1 loss : 0.045690 model2 loss : 0.050587
[21:06:21.759] iteration 4151 : model1 loss : 0.033481 model2 loss : 0.040249
[21:06:22.450] iteration 4152 : model1 loss : 0.029709 model2 loss : 0.036718
[21:06:23.224] iteration 4153 : model1 loss : 0.046716 model2 loss : 0.059197
[21:06:23.940] iteration 4154 : model1 loss : 0.027551 model2 loss : 0.030166
[21:06:24.681] iteration 4155 : model1 loss : 0.025922 model2 loss : 0.026153
[21:06:25.398] iteration 4156 : model1 loss : 0.026682 model2 loss : 0.028380
[21:06:26.078] iteration 4157 : model1 loss : 0.030587 model2 loss : 0.030614
[21:06:26.761] iteration 4158 : model1 loss : 0.031039 model2 loss : 0.035131
[21:06:27.465] iteration 4159 : model1 loss : 0.036333 model2 loss : 0.043524
[21:06:28.141] iteration 4160 : model1 loss : 0.039632 model2 loss : 0.036359
[21:06:28.823] iteration 4161 : model1 loss : 0.046365 model2 loss : 0.046709
[21:06:29.508] iteration 4162 : model1 loss : 0.041842 model2 loss : 0.042940
[21:06:30.182] iteration 4163 : model1 loss : 0.052241 model2 loss : 0.049261
[21:06:30.865] iteration 4164 : model1 loss : 0.037521 model2 loss : 0.032009
[21:06:31.543] iteration 4165 : model1 loss : 0.033242 model2 loss : 0.063430
[21:06:32.212] iteration 4166 : model1 loss : 0.056678 model2 loss : 0.038394
[21:06:32.890] iteration 4167 : model1 loss : 0.058198 model2 loss : 0.059867
[21:06:33.570] iteration 4168 : model1 loss : 0.033533 model2 loss : 0.037447
[21:06:34.255] iteration 4169 : model1 loss : 0.041694 model2 loss : 0.041460
[21:06:34.937] iteration 4170 : model1 loss : 0.024284 model2 loss : 0.039308
[21:06:35.624] iteration 4171 : model1 loss : 0.040989 model2 loss : 0.042461
[21:06:36.306] iteration 4172 : model1 loss : 0.027979 model2 loss : 0.029953
[21:06:37.008] iteration 4173 : model1 loss : 0.021764 model2 loss : 0.024023
[21:06:37.699] iteration 4174 : model1 loss : 0.045308 model2 loss : 0.068219
[21:06:38.423] iteration 4175 : model1 loss : 0.025119 model2 loss : 0.026265
[21:06:39.103] iteration 4176 : model1 loss : 0.024973 model2 loss : 0.025440
[21:06:39.777] iteration 4177 : model1 loss : 0.027525 model2 loss : 0.029082
[21:06:40.451] iteration 4178 : model1 loss : 0.019783 model2 loss : 0.022784
[21:06:41.131] iteration 4179 : model1 loss : 0.064716 model2 loss : 0.055007
[21:06:41.813] iteration 4180 : model1 loss : 0.028821 model2 loss : 0.025189
[21:06:42.508] iteration 4181 : model1 loss : 0.045388 model2 loss : 0.048959
[21:06:43.191] iteration 4182 : model1 loss : 0.030340 model2 loss : 0.037454
[21:06:43.883] iteration 4183 : model1 loss : 0.024224 model2 loss : 0.026437
[21:06:44.574] iteration 4184 : model1 loss : 0.050518 model2 loss : 0.045923
[21:06:45.242] iteration 4185 : model1 loss : 0.034735 model2 loss : 0.034678
[21:06:45.925] iteration 4186 : model1 loss : 0.028580 model2 loss : 0.022629
[21:06:46.615] iteration 4187 : model1 loss : 0.047283 model2 loss : 0.039198
[21:06:47.299] iteration 4188 : model1 loss : 0.035611 model2 loss : 0.047411
[21:06:47.985] iteration 4189 : model1 loss : 0.031526 model2 loss : 0.028242
[21:06:48.670] iteration 4190 : model1 loss : 0.033381 model2 loss : 0.035064
[21:06:49.358] iteration 4191 : model1 loss : 0.058089 model2 loss : 0.053742
[21:06:50.038] iteration 4192 : model1 loss : 0.029565 model2 loss : 0.027993
[21:06:50.720] iteration 4193 : model1 loss : 0.042343 model2 loss : 0.040188
[21:06:51.408] iteration 4194 : model1 loss : 0.081301 model2 loss : 0.032948
[21:06:52.093] iteration 4195 : model1 loss : 0.023962 model2 loss : 0.019659
[21:06:52.781] iteration 4196 : model1 loss : 0.134981 model2 loss : 0.098147
[21:06:53.476] iteration 4197 : model1 loss : 0.030975 model2 loss : 0.029212
[21:06:54.147] iteration 4198 : model1 loss : 0.033990 model2 loss : 0.031551
[21:06:54.828] iteration 4199 : model1 loss : 0.032735 model2 loss : 0.028033
[21:06:55.517] iteration 4200 : model1 loss : 0.028437 model2 loss : 0.037712
[21:07:14.313] iteration 4200 : model1_mean_dice : 0.775970 model1_mean_hd95 : 15.975141
[21:07:33.140] iteration 4200 : model2_mean_dice : 0.794986 model2_mean_hd95 : 7.359239
[21:07:33.851] iteration 4201 : model1 loss : 0.041838 model2 loss : 0.043991
[21:07:34.531] iteration 4202 : model1 loss : 0.029102 model2 loss : 0.026300
[21:07:35.202] iteration 4203 : model1 loss : 0.042424 model2 loss : 0.035404
[21:07:35.863] iteration 4204 : model1 loss : 0.035286 model2 loss : 0.030619
[21:07:36.545] iteration 4205 : model1 loss : 0.073052 model2 loss : 0.040674
[21:07:37.229] iteration 4206 : model1 loss : 0.050917 model2 loss : 0.052638
[21:07:37.914] iteration 4207 : model1 loss : 0.035816 model2 loss : 0.029438
[21:07:38.594] iteration 4208 : model1 loss : 0.034610 model2 loss : 0.038647
[21:07:39.274] iteration 4209 : model1 loss : 0.027904 model2 loss : 0.031200
[21:07:39.958] iteration 4210 : model1 loss : 0.026515 model2 loss : 0.039003
[21:07:40.625] iteration 4211 : model1 loss : 0.038938 model2 loss : 0.047021
[21:07:41.310] iteration 4212 : model1 loss : 0.029778 model2 loss : 0.033755
[21:07:41.995] iteration 4213 : model1 loss : 0.030148 model2 loss : 0.035059
[21:07:42.668] iteration 4214 : model1 loss : 0.029763 model2 loss : 0.025267
[21:07:43.345] iteration 4215 : model1 loss : 0.029846 model2 loss : 0.039219
[21:07:44.009] iteration 4216 : model1 loss : 0.025890 model2 loss : 0.028472
[21:07:44.676] iteration 4217 : model1 loss : 0.031817 model2 loss : 0.029521
[21:07:45.356] iteration 4218 : model1 loss : 0.033443 model2 loss : 0.027732
[21:07:46.038] iteration 4219 : model1 loss : 0.103137 model2 loss : 0.140104
[21:07:46.738] iteration 4220 : model1 loss : 0.036811 model2 loss : 0.029376
[21:07:47.421] iteration 4221 : model1 loss : 0.025169 model2 loss : 0.026834
[21:07:48.089] iteration 4222 : model1 loss : 0.092898 model2 loss : 0.124330
[21:07:48.778] iteration 4223 : model1 loss : 0.033353 model2 loss : 0.039029
[21:07:49.451] iteration 4224 : model1 loss : 0.051445 model2 loss : 0.039609
[21:07:50.122] iteration 4225 : model1 loss : 0.025904 model2 loss : 0.028514
[21:07:50.805] iteration 4226 : model1 loss : 0.038438 model2 loss : 0.038426
[21:07:51.479] iteration 4227 : model1 loss : 0.033720 model2 loss : 0.032692
[21:07:52.144] iteration 4228 : model1 loss : 0.033283 model2 loss : 0.030921
[21:07:52.813] iteration 4229 : model1 loss : 0.046344 model2 loss : 0.061262
[21:07:53.488] iteration 4230 : model1 loss : 0.039526 model2 loss : 0.034478
[21:07:54.166] iteration 4231 : model1 loss : 0.043400 model2 loss : 0.037333
[21:07:54.839] iteration 4232 : model1 loss : 0.039260 model2 loss : 0.027716
[21:07:55.510] iteration 4233 : model1 loss : 0.023686 model2 loss : 0.025800
[21:07:56.180] iteration 4234 : model1 loss : 0.051868 model2 loss : 0.050708
[21:07:56.849] iteration 4235 : model1 loss : 0.029421 model2 loss : 0.030106
[21:07:57.549] iteration 4236 : model1 loss : 0.029028 model2 loss : 0.028645
[21:07:58.228] iteration 4237 : model1 loss : 0.036897 model2 loss : 0.027830
[21:07:58.918] iteration 4238 : model1 loss : 0.028952 model2 loss : 0.026925
[21:07:59.602] iteration 4239 : model1 loss : 0.027599 model2 loss : 0.026607
[21:08:00.285] iteration 4240 : model1 loss : 0.021685 model2 loss : 0.023732
[21:08:00.950] iteration 4241 : model1 loss : 0.043762 model2 loss : 0.042798
[21:08:01.626] iteration 4242 : model1 loss : 0.042632 model2 loss : 0.040263
[21:08:02.308] iteration 4243 : model1 loss : 0.078335 model2 loss : 0.034529
[21:08:02.991] iteration 4244 : model1 loss : 0.044776 model2 loss : 0.045402
[21:08:03.656] iteration 4245 : model1 loss : 0.029660 model2 loss : 0.031086
[21:08:04.350] iteration 4246 : model1 loss : 0.024316 model2 loss : 0.030835
[21:08:05.044] iteration 4247 : model1 loss : 0.039700 model2 loss : 0.034334
[21:08:05.742] iteration 4248 : model1 loss : 0.027190 model2 loss : 0.022801
[21:08:06.415] iteration 4249 : model1 loss : 0.029435 model2 loss : 0.028361
[21:08:07.094] iteration 4250 : model1 loss : 0.045449 model2 loss : 0.033013
[21:08:07.829] iteration 4251 : model1 loss : 0.047941 model2 loss : 0.050306
[21:08:08.510] iteration 4252 : model1 loss : 0.025074 model2 loss : 0.024541
[21:08:09.197] iteration 4253 : model1 loss : 0.034273 model2 loss : 0.032537
[21:08:09.888] iteration 4254 : model1 loss : 0.035485 model2 loss : 0.038303
[21:08:10.600] iteration 4255 : model1 loss : 0.030508 model2 loss : 0.030722
[21:08:11.313] iteration 4256 : model1 loss : 0.030065 model2 loss : 0.030576
[21:08:12.003] iteration 4257 : model1 loss : 0.054769 model2 loss : 0.053513
[21:08:12.690] iteration 4258 : model1 loss : 0.035916 model2 loss : 0.035370
[21:08:13.369] iteration 4259 : model1 loss : 0.027872 model2 loss : 0.033046
[21:08:14.054] iteration 4260 : model1 loss : 0.025248 model2 loss : 0.027869
[21:08:14.741] iteration 4261 : model1 loss : 0.030025 model2 loss : 0.033744
[21:08:15.424] iteration 4262 : model1 loss : 0.041799 model2 loss : 0.040707
[21:08:16.108] iteration 4263 : model1 loss : 0.033008 model2 loss : 0.029854
[21:08:16.777] iteration 4264 : model1 loss : 0.026030 model2 loss : 0.038325
[21:08:17.466] iteration 4265 : model1 loss : 0.044916 model2 loss : 0.041443
[21:08:18.149] iteration 4266 : model1 loss : 0.112700 model2 loss : 0.075108
[21:08:18.831] iteration 4267 : model1 loss : 0.059218 model2 loss : 0.032830
[21:08:19.520] iteration 4268 : model1 loss : 0.024657 model2 loss : 0.022242
[21:08:20.201] iteration 4269 : model1 loss : 0.039575 model2 loss : 0.038115
[21:08:20.875] iteration 4270 : model1 loss : 0.041478 model2 loss : 0.038896
[21:08:21.574] iteration 4271 : model1 loss : 0.028374 model2 loss : 0.027787
[21:08:22.251] iteration 4272 : model1 loss : 0.044875 model2 loss : 0.027549
[21:08:22.929] iteration 4273 : model1 loss : 0.036989 model2 loss : 0.029899
[21:08:23.601] iteration 4274 : model1 loss : 0.031577 model2 loss : 0.034458
[21:08:24.283] iteration 4275 : model1 loss : 0.023153 model2 loss : 0.021797
[21:08:24.957] iteration 4276 : model1 loss : 0.037504 model2 loss : 0.030495
[21:08:25.645] iteration 4277 : model1 loss : 0.029531 model2 loss : 0.035857
[21:08:26.319] iteration 4278 : model1 loss : 0.039323 model2 loss : 0.034208
[21:08:27.006] iteration 4279 : model1 loss : 0.033539 model2 loss : 0.046950
[21:08:27.682] iteration 4280 : model1 loss : 0.025216 model2 loss : 0.055873
[21:08:28.379] iteration 4281 : model1 loss : 0.033685 model2 loss : 0.028721
[21:08:29.046] iteration 4282 : model1 loss : 0.033118 model2 loss : 0.030862
[21:08:29.724] iteration 4283 : model1 loss : 0.035781 model2 loss : 0.053184
[21:08:30.399] iteration 4284 : model1 loss : 0.029653 model2 loss : 0.030620
[21:08:31.084] iteration 4285 : model1 loss : 0.030554 model2 loss : 0.032402
[21:08:31.757] iteration 4286 : model1 loss : 0.022175 model2 loss : 0.035756
[21:08:32.444] iteration 4287 : model1 loss : 0.037189 model2 loss : 0.038062
[21:08:33.119] iteration 4288 : model1 loss : 0.053765 model2 loss : 0.032215
[21:08:33.805] iteration 4289 : model1 loss : 0.031580 model2 loss : 0.024001
[21:08:34.493] iteration 4290 : model1 loss : 0.032621 model2 loss : 0.032334
[21:08:35.168] iteration 4291 : model1 loss : 0.100204 model2 loss : 0.058645
[21:08:35.850] iteration 4292 : model1 loss : 0.029848 model2 loss : 0.024699
[21:08:36.528] iteration 4293 : model1 loss : 0.029191 model2 loss : 0.032171
[21:08:37.207] iteration 4294 : model1 loss : 0.034661 model2 loss : 0.029005
[21:08:37.885] iteration 4295 : model1 loss : 0.036660 model2 loss : 0.036718
[21:08:38.569] iteration 4296 : model1 loss : 0.026808 model2 loss : 0.025551
[21:08:39.255] iteration 4297 : model1 loss : 0.025372 model2 loss : 0.027285
[21:08:39.932] iteration 4298 : model1 loss : 0.033870 model2 loss : 0.032480
[21:08:40.613] iteration 4299 : model1 loss : 0.098438 model2 loss : 0.098941
[21:08:41.297] iteration 4300 : model1 loss : 0.055261 model2 loss : 0.040703
[21:08:42.005] iteration 4301 : model1 loss : 0.037014 model2 loss : 0.030972
[21:08:42.694] iteration 4302 : model1 loss : 0.028087 model2 loss : 0.032428
[21:08:43.380] iteration 4303 : model1 loss : 0.036765 model2 loss : 0.064382
[21:08:44.063] iteration 4304 : model1 loss : 0.049274 model2 loss : 0.035811
[21:08:44.747] iteration 4305 : model1 loss : 0.028775 model2 loss : 0.035477
[21:08:45.476] iteration 4306 : model1 loss : 0.042392 model2 loss : 0.032323
[21:08:46.138] iteration 4307 : model1 loss : 0.044006 model2 loss : 0.039208
[21:08:46.817] iteration 4308 : model1 loss : 0.037503 model2 loss : 0.037520
[21:08:47.499] iteration 4309 : model1 loss : 0.029892 model2 loss : 0.034946
[21:08:48.186] iteration 4310 : model1 loss : 0.025320 model2 loss : 0.026999
[21:08:48.858] iteration 4311 : model1 loss : 0.053372 model2 loss : 0.046558
[21:08:49.536] iteration 4312 : model1 loss : 0.057570 model2 loss : 0.042980
[21:08:50.215] iteration 4313 : model1 loss : 0.037922 model2 loss : 0.036702
[21:08:50.901] iteration 4314 : model1 loss : 0.025078 model2 loss : 0.023167
[21:08:51.574] iteration 4315 : model1 loss : 0.035376 model2 loss : 0.039253
[21:08:52.252] iteration 4316 : model1 loss : 0.022101 model2 loss : 0.023815
[21:08:52.934] iteration 4317 : model1 loss : 0.047201 model2 loss : 0.061096
[21:08:53.613] iteration 4318 : model1 loss : 0.024398 model2 loss : 0.028237
[21:08:54.284] iteration 4319 : model1 loss : 0.028561 model2 loss : 0.025139
[21:08:54.949] iteration 4320 : model1 loss : 0.030248 model2 loss : 0.026597
[21:08:55.639] iteration 4321 : model1 loss : 0.042326 model2 loss : 0.035922
[21:08:56.328] iteration 4322 : model1 loss : 0.082007 model2 loss : 0.048644
[21:08:56.999] iteration 4323 : model1 loss : 0.038897 model2 loss : 0.038792
[21:08:57.694] iteration 4324 : model1 loss : 0.064066 model2 loss : 0.041497
[21:08:58.400] iteration 4325 : model1 loss : 0.028253 model2 loss : 0.030151
[21:08:59.090] iteration 4326 : model1 loss : 0.027109 model2 loss : 0.023674
[21:08:59.790] iteration 4327 : model1 loss : 0.025286 model2 loss : 0.029432
[21:09:00.460] iteration 4328 : model1 loss : 0.033297 model2 loss : 0.034172
[21:09:01.143] iteration 4329 : model1 loss : 0.029286 model2 loss : 0.034250
[21:09:01.821] iteration 4330 : model1 loss : 0.029355 model2 loss : 0.027703
[21:09:02.506] iteration 4331 : model1 loss : 0.043344 model2 loss : 0.031824
[21:09:03.180] iteration 4332 : model1 loss : 0.041484 model2 loss : 0.037517
[21:09:03.864] iteration 4333 : model1 loss : 0.036060 model2 loss : 0.036356
[21:09:04.554] iteration 4334 : model1 loss : 0.046009 model2 loss : 0.035475
[21:09:05.233] iteration 4335 : model1 loss : 0.036745 model2 loss : 0.043810
[21:09:05.910] iteration 4336 : model1 loss : 0.034907 model2 loss : 0.034901
[21:09:06.583] iteration 4337 : model1 loss : 0.032142 model2 loss : 0.029328
[21:09:07.264] iteration 4338 : model1 loss : 0.041903 model2 loss : 0.060394
[21:09:07.939] iteration 4339 : model1 loss : 0.028577 model2 loss : 0.025341
[21:09:08.616] iteration 4340 : model1 loss : 0.033816 model2 loss : 0.034116
[21:09:09.302] iteration 4341 : model1 loss : 0.039122 model2 loss : 0.031058
[21:09:09.986] iteration 4342 : model1 loss : 0.041723 model2 loss : 0.034985
[21:09:10.666] iteration 4343 : model1 loss : 0.031936 model2 loss : 0.032417
[21:09:11.354] iteration 4344 : model1 loss : 0.035777 model2 loss : 0.038522
[21:09:12.038] iteration 4345 : model1 loss : 0.019597 model2 loss : 0.020322
[21:09:12.726] iteration 4346 : model1 loss : 0.032210 model2 loss : 0.026731
[21:09:13.407] iteration 4347 : model1 loss : 0.027538 model2 loss : 0.033068
[21:09:14.084] iteration 4348 : model1 loss : 0.060748 model2 loss : 0.055467
[21:09:14.770] iteration 4349 : model1 loss : 0.028221 model2 loss : 0.027952
[21:09:15.471] iteration 4350 : model1 loss : 0.042139 model2 loss : 0.063265
[21:09:16.224] iteration 4351 : model1 loss : 0.038975 model2 loss : 0.034911
[21:09:16.893] iteration 4352 : model1 loss : 0.031392 model2 loss : 0.034185
[21:09:17.575] iteration 4353 : model1 loss : 0.030530 model2 loss : 0.028224
[21:09:18.259] iteration 4354 : model1 loss : 0.027013 model2 loss : 0.028552
[21:09:18.942] iteration 4355 : model1 loss : 0.031582 model2 loss : 0.031783
[21:09:19.622] iteration 4356 : model1 loss : 0.036062 model2 loss : 0.035060
[21:09:20.322] iteration 4357 : model1 loss : 0.056376 model2 loss : 0.086235
[21:09:21.003] iteration 4358 : model1 loss : 0.034370 model2 loss : 0.033658
[21:09:21.683] iteration 4359 : model1 loss : 0.035298 model2 loss : 0.073606
[21:09:22.364] iteration 4360 : model1 loss : 0.027645 model2 loss : 0.033416
[21:09:23.042] iteration 4361 : model1 loss : 0.033285 model2 loss : 0.037100
[21:09:23.720] iteration 4362 : model1 loss : 0.034158 model2 loss : 0.032650
[21:09:24.407] iteration 4363 : model1 loss : 0.031558 model2 loss : 0.030532
[21:09:25.091] iteration 4364 : model1 loss : 0.050993 model2 loss : 0.055038
[21:09:25.756] iteration 4365 : model1 loss : 0.043509 model2 loss : 0.032553
[21:09:26.444] iteration 4366 : model1 loss : 0.040551 model2 loss : 0.053213
[21:09:27.132] iteration 4367 : model1 loss : 0.064671 model2 loss : 0.059737
[21:09:27.809] iteration 4368 : model1 loss : 0.028068 model2 loss : 0.029491
[21:09:28.522] iteration 4369 : model1 loss : 0.062697 model2 loss : 0.046856
[21:09:29.205] iteration 4370 : model1 loss : 0.032444 model2 loss : 0.040205
[21:09:29.908] iteration 4371 : model1 loss : 0.028796 model2 loss : 0.051034
[21:09:30.583] iteration 4372 : model1 loss : 0.024380 model2 loss : 0.025980
[21:09:31.259] iteration 4373 : model1 loss : 0.029598 model2 loss : 0.038366
[21:09:31.940] iteration 4374 : model1 loss : 0.031292 model2 loss : 0.028964
[21:09:32.625] iteration 4375 : model1 loss : 0.027994 model2 loss : 0.026038
[21:09:33.306] iteration 4376 : model1 loss : 0.025639 model2 loss : 0.032680
[21:09:33.975] iteration 4377 : model1 loss : 0.070790 model2 loss : 0.036592
[21:09:34.656] iteration 4378 : model1 loss : 0.022362 model2 loss : 0.025541
[21:09:35.365] iteration 4379 : model1 loss : 0.025154 model2 loss : 0.022180
[21:09:36.038] iteration 4380 : model1 loss : 0.100859 model2 loss : 0.087168
[21:09:36.713] iteration 4381 : model1 loss : 0.031770 model2 loss : 0.048857
[21:09:37.390] iteration 4382 : model1 loss : 0.026852 model2 loss : 0.038770
[21:09:38.069] iteration 4383 : model1 loss : 0.026505 model2 loss : 0.041221
[21:09:38.755] iteration 4384 : model1 loss : 0.032654 model2 loss : 0.025981
[21:09:39.447] iteration 4385 : model1 loss : 0.035106 model2 loss : 0.038238
[21:09:40.139] iteration 4386 : model1 loss : 0.033705 model2 loss : 0.031694
[21:09:40.825] iteration 4387 : model1 loss : 0.033890 model2 loss : 0.037828
[21:09:41.503] iteration 4388 : model1 loss : 0.031006 model2 loss : 0.033089
[21:09:42.189] iteration 4389 : model1 loss : 0.064916 model2 loss : 0.078565
[21:09:42.882] iteration 4390 : model1 loss : 0.032259 model2 loss : 0.038652
[21:09:43.556] iteration 4391 : model1 loss : 0.025014 model2 loss : 0.032215
[21:09:44.249] iteration 4392 : model1 loss : 0.096120 model2 loss : 0.079587
[21:09:44.935] iteration 4393 : model1 loss : 0.039766 model2 loss : 0.042314
[21:09:45.612] iteration 4394 : model1 loss : 0.030464 model2 loss : 0.030546
[21:09:46.288] iteration 4395 : model1 loss : 0.029460 model2 loss : 0.033468
[21:09:46.973] iteration 4396 : model1 loss : 0.027854 model2 loss : 0.030743
[21:09:47.657] iteration 4397 : model1 loss : 0.038338 model2 loss : 0.037686
[21:09:48.353] iteration 4398 : model1 loss : 0.059318 model2 loss : 0.062437
[21:09:49.036] iteration 4399 : model1 loss : 0.032498 model2 loss : 0.034087
[21:09:49.749] iteration 4400 : model1 loss : 0.037047 model2 loss : 0.030316
[21:10:08.522] iteration 4400 : model1_mean_dice : 0.827085 model1_mean_hd95 : 2.764411
[21:10:27.431] iteration 4400 : model2_mean_dice : 0.830857 model2_mean_hd95 : 12.041051
[21:10:28.138] iteration 4401 : model1 loss : 0.031060 model2 loss : 0.031186
[21:10:28.824] iteration 4402 : model1 loss : 0.028495 model2 loss : 0.032492
[21:10:29.504] iteration 4403 : model1 loss : 0.024418 model2 loss : 0.023794
[21:10:30.191] iteration 4404 : model1 loss : 0.042805 model2 loss : 0.033386
[21:10:30.858] iteration 4405 : model1 loss : 0.071096 model2 loss : 0.074936
[21:10:31.546] iteration 4406 : model1 loss : 0.034171 model2 loss : 0.039089
[21:10:32.225] iteration 4407 : model1 loss : 0.089238 model2 loss : 0.067165
[21:10:32.898] iteration 4408 : model1 loss : 0.023785 model2 loss : 0.026125
[21:10:33.588] iteration 4409 : model1 loss : 0.060586 model2 loss : 0.044193
[21:10:34.273] iteration 4410 : model1 loss : 0.036183 model2 loss : 0.030012
[21:10:34.934] iteration 4411 : model1 loss : 0.026621 model2 loss : 0.029476
[21:10:35.605] iteration 4412 : model1 loss : 0.029215 model2 loss : 0.045806
[21:10:36.291] iteration 4413 : model1 loss : 0.027904 model2 loss : 0.030830
[21:10:36.959] iteration 4414 : model1 loss : 0.025242 model2 loss : 0.030613
[21:10:37.652] iteration 4415 : model1 loss : 0.027926 model2 loss : 0.027369
[21:10:38.329] iteration 4416 : model1 loss : 0.027763 model2 loss : 0.030891
[21:10:38.994] iteration 4417 : model1 loss : 0.031465 model2 loss : 0.035042
[21:10:39.679] iteration 4418 : model1 loss : 0.027299 model2 loss : 0.028156
[21:10:40.359] iteration 4419 : model1 loss : 0.035120 model2 loss : 0.032895
[21:10:41.024] iteration 4420 : model1 loss : 0.025762 model2 loss : 0.028880
[21:10:41.706] iteration 4421 : model1 loss : 0.033152 model2 loss : 0.035452
[21:10:42.387] iteration 4422 : model1 loss : 0.032666 model2 loss : 0.035128
[21:10:43.069] iteration 4423 : model1 loss : 0.026160 model2 loss : 0.029865
[21:10:43.755] iteration 4424 : model1 loss : 0.058864 model2 loss : 0.041532
[21:10:44.438] iteration 4425 : model1 loss : 0.018217 model2 loss : 0.019278
[21:10:45.127] iteration 4426 : model1 loss : 0.023950 model2 loss : 0.027479
[21:10:45.802] iteration 4427 : model1 loss : 0.033798 model2 loss : 0.030733
[21:10:46.481] iteration 4428 : model1 loss : 0.030906 model2 loss : 0.029869
[21:10:47.157] iteration 4429 : model1 loss : 0.029202 model2 loss : 0.045400
[21:10:47.839] iteration 4430 : model1 loss : 0.148169 model2 loss : 0.154513
[21:10:48.527] iteration 4431 : model1 loss : 0.068612 model2 loss : 0.030009
[21:10:49.203] iteration 4432 : model1 loss : 0.039080 model2 loss : 0.039342
[21:10:49.882] iteration 4433 : model1 loss : 0.030364 model2 loss : 0.030038
[21:10:50.586] iteration 4434 : model1 loss : 0.041621 model2 loss : 0.034618
[21:10:51.257] iteration 4435 : model1 loss : 0.034716 model2 loss : 0.027101
[21:10:51.935] iteration 4436 : model1 loss : 0.039098 model2 loss : 0.040662
[21:10:52.619] iteration 4437 : model1 loss : 0.034144 model2 loss : 0.031605
[21:10:53.293] iteration 4438 : model1 loss : 0.046804 model2 loss : 0.051889
[21:10:53.963] iteration 4439 : model1 loss : 0.040411 model2 loss : 0.056469
[21:10:54.641] iteration 4440 : model1 loss : 0.036039 model2 loss : 0.035194
[21:10:55.326] iteration 4441 : model1 loss : 0.028016 model2 loss : 0.036647
[21:10:56.007] iteration 4442 : model1 loss : 0.041851 model2 loss : 0.038602
[21:10:56.676] iteration 4443 : model1 loss : 0.017813 model2 loss : 0.016644
[21:10:57.367] iteration 4444 : model1 loss : 0.029556 model2 loss : 0.032971
[21:10:58.033] iteration 4445 : model1 loss : 0.035109 model2 loss : 0.033364
[21:10:58.705] iteration 4446 : model1 loss : 0.030820 model2 loss : 0.030185
[21:10:59.393] iteration 4447 : model1 loss : 0.035560 model2 loss : 0.037143
[21:11:00.068] iteration 4448 : model1 loss : 0.158170 model2 loss : 0.142293
[21:11:00.757] iteration 4449 : model1 loss : 0.038121 model2 loss : 0.039241
[21:11:01.436] iteration 4450 : model1 loss : 0.163350 model2 loss : 0.231467
[21:11:02.151] iteration 4451 : model1 loss : 0.164985 model2 loss : 0.165714
[21:11:02.842] iteration 4452 : model1 loss : 0.036176 model2 loss : 0.050906
[21:11:03.519] iteration 4453 : model1 loss : 0.052753 model2 loss : 0.057162
[21:11:04.192] iteration 4454 : model1 loss : 0.028235 model2 loss : 0.028002
[21:11:04.867] iteration 4455 : model1 loss : 0.022004 model2 loss : 0.023198
[21:11:05.547] iteration 4456 : model1 loss : 0.033590 model2 loss : 0.056412
[21:11:06.248] iteration 4457 : model1 loss : 0.052138 model2 loss : 0.072543
[21:11:06.938] iteration 4458 : model1 loss : 0.024623 model2 loss : 0.025368
[21:11:07.615] iteration 4459 : model1 loss : 0.040418 model2 loss : 0.047929
[21:11:08.305] iteration 4460 : model1 loss : 0.103206 model2 loss : 0.173228
[21:11:08.993] iteration 4461 : model1 loss : 0.026711 model2 loss : 0.029639
[21:11:09.671] iteration 4462 : model1 loss : 0.025212 model2 loss : 0.032427
[21:11:10.361] iteration 4463 : model1 loss : 0.025311 model2 loss : 0.022225
[21:11:11.031] iteration 4464 : model1 loss : 0.032670 model2 loss : 0.027739
[21:11:11.710] iteration 4465 : model1 loss : 0.045420 model2 loss : 0.038887
[21:11:12.390] iteration 4466 : model1 loss : 0.026034 model2 loss : 0.026078
[21:11:13.067] iteration 4467 : model1 loss : 0.037849 model2 loss : 0.039935
[21:11:13.743] iteration 4468 : model1 loss : 0.020637 model2 loss : 0.031611
[21:11:14.430] iteration 4469 : model1 loss : 0.046698 model2 loss : 0.049517
[21:11:15.099] iteration 4470 : model1 loss : 0.039832 model2 loss : 0.040357
[21:11:15.771] iteration 4471 : model1 loss : 0.047574 model2 loss : 0.043555
[21:11:16.453] iteration 4472 : model1 loss : 0.023620 model2 loss : 0.025532
[21:11:17.146] iteration 4473 : model1 loss : 0.039415 model2 loss : 0.036896
[21:11:17.829] iteration 4474 : model1 loss : 0.021117 model2 loss : 0.024737
[21:11:18.510] iteration 4475 : model1 loss : 0.031934 model2 loss : 0.029897
[21:11:19.192] iteration 4476 : model1 loss : 0.030328 model2 loss : 0.029661
[21:11:19.875] iteration 4477 : model1 loss : 0.034299 model2 loss : 0.038657
[21:11:20.555] iteration 4478 : model1 loss : 0.034746 model2 loss : 0.044595
[21:11:21.232] iteration 4479 : model1 loss : 0.024418 model2 loss : 0.029841
[21:11:21.918] iteration 4480 : model1 loss : 0.031289 model2 loss : 0.036373
[21:11:22.610] iteration 4481 : model1 loss : 0.047211 model2 loss : 0.044466
[21:11:23.298] iteration 4482 : model1 loss : 0.043146 model2 loss : 0.044175
[21:11:23.975] iteration 4483 : model1 loss : 0.035379 model2 loss : 0.031123
[21:11:24.661] iteration 4484 : model1 loss : 0.026569 model2 loss : 0.032188
[21:11:25.349] iteration 4485 : model1 loss : 0.033167 model2 loss : 0.038034
[21:11:26.022] iteration 4486 : model1 loss : 0.045659 model2 loss : 0.071432
[21:11:26.690] iteration 4487 : model1 loss : 0.035910 model2 loss : 0.065493
[21:11:27.373] iteration 4488 : model1 loss : 0.037876 model2 loss : 0.040862
[21:11:28.048] iteration 4489 : model1 loss : 0.039751 model2 loss : 0.046109
[21:11:28.741] iteration 4490 : model1 loss : 0.025068 model2 loss : 0.025562
[21:11:29.430] iteration 4491 : model1 loss : 0.027673 model2 loss : 0.033478
[21:11:30.112] iteration 4492 : model1 loss : 0.026699 model2 loss : 0.032545
[21:11:30.788] iteration 4493 : model1 loss : 0.039243 model2 loss : 0.034498
[21:11:31.479] iteration 4494 : model1 loss : 0.040397 model2 loss : 0.045019
[21:11:32.167] iteration 4495 : model1 loss : 0.029982 model2 loss : 0.034159
[21:11:32.842] iteration 4496 : model1 loss : 0.055510 model2 loss : 0.069918
[21:11:33.527] iteration 4497 : model1 loss : 0.026260 model2 loss : 0.025686
[21:11:34.206] iteration 4498 : model1 loss : 0.042288 model2 loss : 0.046930
[21:11:34.888] iteration 4499 : model1 loss : 0.032600 model2 loss : 0.038975
[21:11:35.566] iteration 4500 : model1 loss : 0.042211 model2 loss : 0.071101
[21:11:36.290] iteration 4501 : model1 loss : 0.048994 model2 loss : 0.054510
[21:11:36.979] iteration 4502 : model1 loss : 0.038794 model2 loss : 0.054788
[21:11:37.661] iteration 4503 : model1 loss : 0.029915 model2 loss : 0.034105
[21:11:38.338] iteration 4504 : model1 loss : 0.048793 model2 loss : 0.065501
[21:11:39.010] iteration 4505 : model1 loss : 0.028274 model2 loss : 0.028693
[21:11:39.690] iteration 4506 : model1 loss : 0.045166 model2 loss : 0.046966
[21:11:40.371] iteration 4507 : model1 loss : 0.018705 model2 loss : 0.031971
[21:11:41.053] iteration 4508 : model1 loss : 0.024925 model2 loss : 0.027152
[21:11:41.735] iteration 4509 : model1 loss : 0.029815 model2 loss : 0.028571
[21:11:42.427] iteration 4510 : model1 loss : 0.031319 model2 loss : 0.039859
[21:11:43.101] iteration 4511 : model1 loss : 0.042155 model2 loss : 0.035011
[21:11:43.789] iteration 4512 : model1 loss : 0.089436 model2 loss : 0.035470
[21:11:44.474] iteration 4513 : model1 loss : 0.072390 model2 loss : 0.066719
[21:11:45.159] iteration 4514 : model1 loss : 0.022611 model2 loss : 0.026613
[21:11:45.831] iteration 4515 : model1 loss : 0.027915 model2 loss : 0.028031
[21:11:46.506] iteration 4516 : model1 loss : 0.050535 model2 loss : 0.049326
[21:11:47.180] iteration 4517 : model1 loss : 0.049146 model2 loss : 0.063017
[21:11:47.853] iteration 4518 : model1 loss : 0.025715 model2 loss : 0.026285
[21:11:48.545] iteration 4519 : model1 loss : 0.026675 model2 loss : 0.027545
[21:11:49.243] iteration 4520 : model1 loss : 0.031760 model2 loss : 0.031372
[21:11:49.929] iteration 4521 : model1 loss : 0.032670 model2 loss : 0.037742
[21:11:50.610] iteration 4522 : model1 loss : 0.020227 model2 loss : 0.021881
[21:11:51.287] iteration 4523 : model1 loss : 0.027928 model2 loss : 0.027559
[21:11:51.976] iteration 4524 : model1 loss : 0.031755 model2 loss : 0.035128
[21:11:52.677] iteration 4525 : model1 loss : 0.053372 model2 loss : 0.044962
[21:11:53.368] iteration 4526 : model1 loss : 0.051168 model2 loss : 0.033791
[21:11:54.053] iteration 4527 : model1 loss : 0.025681 model2 loss : 0.028221
[21:11:54.731] iteration 4528 : model1 loss : 0.029039 model2 loss : 0.033688
[21:11:55.416] iteration 4529 : model1 loss : 0.046710 model2 loss : 0.060182
[21:11:56.089] iteration 4530 : model1 loss : 0.068694 model2 loss : 0.045143
[21:11:56.777] iteration 4531 : model1 loss : 0.022403 model2 loss : 0.021812
[21:11:57.453] iteration 4532 : model1 loss : 0.040465 model2 loss : 0.037558
[21:11:58.141] iteration 4533 : model1 loss : 0.033551 model2 loss : 0.032697
[21:11:58.825] iteration 4534 : model1 loss : 0.025912 model2 loss : 0.030534
[21:11:59.503] iteration 4535 : model1 loss : 0.024272 model2 loss : 0.032933
[21:12:00.173] iteration 4536 : model1 loss : 0.029100 model2 loss : 0.028440
[21:12:00.854] iteration 4537 : model1 loss : 0.064448 model2 loss : 0.081667
[21:12:01.534] iteration 4538 : model1 loss : 0.027854 model2 loss : 0.024786
[21:12:02.212] iteration 4539 : model1 loss : 0.071199 model2 loss : 0.071269
[21:12:02.895] iteration 4540 : model1 loss : 0.028761 model2 loss : 0.031813
[21:12:03.578] iteration 4541 : model1 loss : 0.023023 model2 loss : 0.026705
[21:12:04.282] iteration 4542 : model1 loss : 0.040457 model2 loss : 0.032740
[21:12:04.956] iteration 4543 : model1 loss : 0.031660 model2 loss : 0.027088
[21:12:05.652] iteration 4544 : model1 loss : 0.035134 model2 loss : 0.031840
[21:12:06.348] iteration 4545 : model1 loss : 0.022681 model2 loss : 0.024001
[21:12:07.028] iteration 4546 : model1 loss : 0.041881 model2 loss : 0.040735
[21:12:07.712] iteration 4547 : model1 loss : 0.037607 model2 loss : 0.040183
[21:12:08.398] iteration 4548 : model1 loss : 0.036573 model2 loss : 0.032077
[21:12:09.078] iteration 4549 : model1 loss : 0.026694 model2 loss : 0.029616
[21:12:09.759] iteration 4550 : model1 loss : 0.037399 model2 loss : 0.031576
[21:12:10.484] iteration 4551 : model1 loss : 0.041858 model2 loss : 0.040814
[21:12:11.161] iteration 4552 : model1 loss : 0.037113 model2 loss : 0.038872
[21:12:11.842] iteration 4553 : model1 loss : 0.051787 model2 loss : 0.043766
[21:12:12.521] iteration 4554 : model1 loss : 0.025702 model2 loss : 0.027342
[21:12:13.215] iteration 4555 : model1 loss : 0.060398 model2 loss : 0.059541
[21:12:13.897] iteration 4556 : model1 loss : 0.049623 model2 loss : 0.044264
[21:12:14.592] iteration 4557 : model1 loss : 0.032421 model2 loss : 0.031028
[21:12:15.286] iteration 4558 : model1 loss : 0.032067 model2 loss : 0.031172
[21:12:15.969] iteration 4559 : model1 loss : 0.045394 model2 loss : 0.033152
[21:12:16.646] iteration 4560 : model1 loss : 0.107730 model2 loss : 0.067398
[21:12:17.337] iteration 4561 : model1 loss : 0.026879 model2 loss : 0.024591
[21:12:18.020] iteration 4562 : model1 loss : 0.026606 model2 loss : 0.051290
[21:12:18.707] iteration 4563 : model1 loss : 0.028342 model2 loss : 0.027750
[21:12:19.397] iteration 4564 : model1 loss : 0.039926 model2 loss : 0.039006
[21:12:20.091] iteration 4565 : model1 loss : 0.076129 model2 loss : 0.064321
[21:12:20.773] iteration 4566 : model1 loss : 0.030945 model2 loss : 0.038941
[21:12:21.459] iteration 4567 : model1 loss : 0.031469 model2 loss : 0.028244
[21:12:22.150] iteration 4568 : model1 loss : 0.025372 model2 loss : 0.033209
[21:12:22.830] iteration 4569 : model1 loss : 0.092544 model2 loss : 0.139387
[21:12:23.519] iteration 4570 : model1 loss : 0.066383 model2 loss : 0.048594
[21:12:24.233] iteration 4571 : model1 loss : 0.028998 model2 loss : 0.031236
[21:12:24.913] iteration 4572 : model1 loss : 0.027231 model2 loss : 0.027634
[21:12:25.588] iteration 4573 : model1 loss : 0.036832 model2 loss : 0.025590
[21:12:26.280] iteration 4574 : model1 loss : 0.034376 model2 loss : 0.033645
[21:12:26.953] iteration 4575 : model1 loss : 0.035776 model2 loss : 0.033262
[21:12:27.621] iteration 4576 : model1 loss : 0.028240 model2 loss : 0.036203
[21:12:28.292] iteration 4577 : model1 loss : 0.038435 model2 loss : 0.044120
[21:12:28.977] iteration 4578 : model1 loss : 0.036079 model2 loss : 0.050056
[21:12:29.658] iteration 4579 : model1 loss : 0.033703 model2 loss : 0.032236
[21:12:30.361] iteration 4580 : model1 loss : 0.061967 model2 loss : 0.061815
[21:12:31.044] iteration 4581 : model1 loss : 0.036455 model2 loss : 0.044029
[21:12:31.722] iteration 4582 : model1 loss : 0.028166 model2 loss : 0.026558
[21:12:32.402] iteration 4583 : model1 loss : 0.025745 model2 loss : 0.030422
[21:12:33.090] iteration 4584 : model1 loss : 0.024557 model2 loss : 0.026353
[21:12:33.757] iteration 4585 : model1 loss : 0.021581 model2 loss : 0.021482
[21:12:34.425] iteration 4586 : model1 loss : 0.035952 model2 loss : 0.044316
[21:12:35.115] iteration 4587 : model1 loss : 0.067651 model2 loss : 0.085077
[21:12:35.789] iteration 4588 : model1 loss : 0.066328 model2 loss : 0.074896
[21:12:36.475] iteration 4589 : model1 loss : 0.037715 model2 loss : 0.036204
[21:12:37.140] iteration 4590 : model1 loss : 0.040078 model2 loss : 0.059767
[21:12:37.820] iteration 4591 : model1 loss : 0.033716 model2 loss : 0.038606
[21:12:38.504] iteration 4592 : model1 loss : 0.154512 model2 loss : 0.164530
[21:12:39.177] iteration 4593 : model1 loss : 0.037920 model2 loss : 0.034792
[21:12:39.870] iteration 4594 : model1 loss : 0.031763 model2 loss : 0.035983
[21:12:40.570] iteration 4595 : model1 loss : 0.027167 model2 loss : 0.032774
[21:12:41.254] iteration 4596 : model1 loss : 0.062194 model2 loss : 0.035749
[21:12:41.920] iteration 4597 : model1 loss : 0.024333 model2 loss : 0.028026
[21:12:42.605] iteration 4598 : model1 loss : 0.036624 model2 loss : 0.047302
[21:12:43.296] iteration 4599 : model1 loss : 0.035147 model2 loss : 0.043780
[21:12:43.994] iteration 4600 : model1 loss : 0.030346 model2 loss : 0.031085
[21:13:02.867] iteration 4600 : model1_mean_dice : 0.801280 model1_mean_hd95 : 6.797273
[21:13:21.707] iteration 4600 : model2_mean_dice : 0.833368 model2_mean_hd95 : 5.435050
[21:13:22.410] iteration 4601 : model1 loss : 0.043571 model2 loss : 0.039706
[21:13:23.082] iteration 4602 : model1 loss : 0.028041 model2 loss : 0.033469
[21:13:23.759] iteration 4603 : model1 loss : 0.058742 model2 loss : 0.053813
[21:13:24.432] iteration 4604 : model1 loss : 0.039732 model2 loss : 0.037254
[21:13:25.114] iteration 4605 : model1 loss : 0.024296 model2 loss : 0.024820
[21:13:25.786] iteration 4606 : model1 loss : 0.027095 model2 loss : 0.024841
[21:13:26.460] iteration 4607 : model1 loss : 0.027819 model2 loss : 0.026942
[21:13:27.139] iteration 4608 : model1 loss : 0.028000 model2 loss : 0.026212
[21:13:27.808] iteration 4609 : model1 loss : 0.051113 model2 loss : 0.049244
[21:13:28.489] iteration 4610 : model1 loss : 0.027375 model2 loss : 0.038026
[21:13:29.173] iteration 4611 : model1 loss : 0.034422 model2 loss : 0.032573
[21:13:29.848] iteration 4612 : model1 loss : 0.038084 model2 loss : 0.050349
[21:13:30.572] iteration 4613 : model1 loss : 0.031994 model2 loss : 0.026969
[21:13:31.263] iteration 4614 : model1 loss : 0.028421 model2 loss : 0.024587
[21:13:31.955] iteration 4615 : model1 loss : 0.050727 model2 loss : 0.036218
[21:13:32.634] iteration 4616 : model1 loss : 0.020652 model2 loss : 0.022772
[21:13:33.314] iteration 4617 : model1 loss : 0.075670 model2 loss : 0.044099
[21:13:33.987] iteration 4618 : model1 loss : 0.029622 model2 loss : 0.032731
[21:13:34.662] iteration 4619 : model1 loss : 0.045401 model2 loss : 0.041432
[21:13:35.348] iteration 4620 : model1 loss : 0.030622 model2 loss : 0.032169
[21:13:36.021] iteration 4621 : model1 loss : 0.035813 model2 loss : 0.033518
[21:13:36.695] iteration 4622 : model1 loss : 0.027412 model2 loss : 0.032995
[21:13:37.391] iteration 4623 : model1 loss : 0.113648 model2 loss : 0.074760
[21:13:38.111] iteration 4624 : model1 loss : 0.069951 model2 loss : 0.035545
[21:13:38.790] iteration 4625 : model1 loss : 0.024868 model2 loss : 0.025006
[21:13:39.461] iteration 4626 : model1 loss : 0.037971 model2 loss : 0.040298
[21:13:40.138] iteration 4627 : model1 loss : 0.061243 model2 loss : 0.058577
[21:13:40.815] iteration 4628 : model1 loss : 0.039413 model2 loss : 0.058800
[21:13:41.507] iteration 4629 : model1 loss : 0.034450 model2 loss : 0.034213
[21:13:42.181] iteration 4630 : model1 loss : 0.028611 model2 loss : 0.025772
[21:13:42.864] iteration 4631 : model1 loss : 0.165395 model2 loss : 0.162668
[21:13:43.554] iteration 4632 : model1 loss : 0.043969 model2 loss : 0.060886
[21:13:44.223] iteration 4633 : model1 loss : 0.024561 model2 loss : 0.022211
[21:13:44.908] iteration 4634 : model1 loss : 0.033475 model2 loss : 0.032710
[21:13:45.580] iteration 4635 : model1 loss : 0.030338 model2 loss : 0.033506
[21:13:46.256] iteration 4636 : model1 loss : 0.020051 model2 loss : 0.022327
[21:13:46.938] iteration 4637 : model1 loss : 0.035569 model2 loss : 0.035851
[21:13:47.616] iteration 4638 : model1 loss : 0.043888 model2 loss : 0.057710
[21:13:48.302] iteration 4639 : model1 loss : 0.041064 model2 loss : 0.055880
[21:13:48.979] iteration 4640 : model1 loss : 0.053483 model2 loss : 0.043362
[21:13:49.652] iteration 4641 : model1 loss : 0.023444 model2 loss : 0.027772
[21:13:50.391] iteration 4642 : model1 loss : 0.031895 model2 loss : 0.027134
[21:13:51.110] iteration 4643 : model1 loss : 0.025005 model2 loss : 0.026871
[21:13:51.807] iteration 4644 : model1 loss : 0.043518 model2 loss : 0.056230
[21:13:52.479] iteration 4645 : model1 loss : 0.044663 model2 loss : 0.054842
[21:13:53.165] iteration 4646 : model1 loss : 0.019510 model2 loss : 0.019657
[21:13:53.846] iteration 4647 : model1 loss : 0.021530 model2 loss : 0.022365
[21:13:54.526] iteration 4648 : model1 loss : 0.049412 model2 loss : 0.044258
[21:13:55.205] iteration 4649 : model1 loss : 0.053988 model2 loss : 0.065172
[21:13:55.887] iteration 4650 : model1 loss : 0.023257 model2 loss : 0.024494
[21:13:56.613] iteration 4651 : model1 loss : 0.033874 model2 loss : 0.042993
[21:13:57.288] iteration 4652 : model1 loss : 0.052915 model2 loss : 0.039656
[21:13:57.964] iteration 4653 : model1 loss : 0.045060 model2 loss : 0.053082
[21:13:58.648] iteration 4654 : model1 loss : 0.048670 model2 loss : 0.067219
[21:13:59.330] iteration 4655 : model1 loss : 0.032103 model2 loss : 0.030256
[21:14:00.005] iteration 4656 : model1 loss : 0.024770 model2 loss : 0.024881
[21:14:00.686] iteration 4657 : model1 loss : 0.025427 model2 loss : 0.027953
[21:14:01.378] iteration 4658 : model1 loss : 0.062935 model2 loss : 0.076362
[21:14:02.047] iteration 4659 : model1 loss : 0.030256 model2 loss : 0.029701
[21:14:02.718] iteration 4660 : model1 loss : 0.044664 model2 loss : 0.033000
[21:14:03.394] iteration 4661 : model1 loss : 0.024505 model2 loss : 0.018570
[21:14:04.100] iteration 4662 : model1 loss : 0.025715 model2 loss : 0.022275
[21:14:04.802] iteration 4663 : model1 loss : 0.050649 model2 loss : 0.049846
[21:14:05.489] iteration 4664 : model1 loss : 0.028569 model2 loss : 0.033470
[21:14:06.169] iteration 4665 : model1 loss : 0.031289 model2 loss : 0.033622
[21:14:06.859] iteration 4666 : model1 loss : 0.030354 model2 loss : 0.027235
[21:14:07.548] iteration 4667 : model1 loss : 0.028264 model2 loss : 0.030546
[21:14:08.225] iteration 4668 : model1 loss : 0.030050 model2 loss : 0.032217
[21:14:08.912] iteration 4669 : model1 loss : 0.023897 model2 loss : 0.025592
[21:14:09.596] iteration 4670 : model1 loss : 0.026286 model2 loss : 0.027610
[21:14:10.290] iteration 4671 : model1 loss : 0.039359 model2 loss : 0.030640
[21:14:10.986] iteration 4672 : model1 loss : 0.029465 model2 loss : 0.030573
[21:14:11.659] iteration 4673 : model1 loss : 0.027091 model2 loss : 0.031409
[21:14:12.341] iteration 4674 : model1 loss : 0.042253 model2 loss : 0.044179
[21:14:13.033] iteration 4675 : model1 loss : 0.029653 model2 loss : 0.032500
[21:14:13.717] iteration 4676 : model1 loss : 0.091266 model2 loss : 0.107308
[21:14:14.402] iteration 4677 : model1 loss : 0.018733 model2 loss : 0.020843
[21:14:15.083] iteration 4678 : model1 loss : 0.031989 model2 loss : 0.030390
[21:14:15.767] iteration 4679 : model1 loss : 0.030433 model2 loss : 0.029801
[21:14:16.448] iteration 4680 : model1 loss : 0.030083 model2 loss : 0.033264
[21:14:17.129] iteration 4681 : model1 loss : 0.035532 model2 loss : 0.029550
[21:14:17.812] iteration 4682 : model1 loss : 0.026114 model2 loss : 0.031197
[21:14:18.501] iteration 4683 : model1 loss : 0.029384 model2 loss : 0.026274
[21:14:19.184] iteration 4684 : model1 loss : 0.033611 model2 loss : 0.034742
[21:14:19.856] iteration 4685 : model1 loss : 0.028194 model2 loss : 0.028675
[21:14:20.548] iteration 4686 : model1 loss : 0.027445 model2 loss : 0.027284
[21:14:21.228] iteration 4687 : model1 loss : 0.028850 model2 loss : 0.029514
[21:14:21.895] iteration 4688 : model1 loss : 0.031428 model2 loss : 0.033600
[21:14:22.600] iteration 4689 : model1 loss : 0.025943 model2 loss : 0.023627
[21:14:23.283] iteration 4690 : model1 loss : 0.071021 model2 loss : 0.048049
[21:14:23.957] iteration 4691 : model1 loss : 0.033992 model2 loss : 0.042859
[21:14:24.648] iteration 4692 : model1 loss : 0.027833 model2 loss : 0.035529
[21:14:25.338] iteration 4693 : model1 loss : 0.030790 model2 loss : 0.028801
[21:14:26.036] iteration 4694 : model1 loss : 0.032248 model2 loss : 0.034218
[21:14:26.714] iteration 4695 : model1 loss : 0.030548 model2 loss : 0.026061
[21:14:27.383] iteration 4696 : model1 loss : 0.106102 model2 loss : 0.075482
[21:14:28.068] iteration 4697 : model1 loss : 0.028325 model2 loss : 0.030756
[21:14:28.747] iteration 4698 : model1 loss : 0.032490 model2 loss : 0.037220
[21:14:29.421] iteration 4699 : model1 loss : 0.034643 model2 loss : 0.028037
[21:14:30.097] iteration 4700 : model1 loss : 0.037729 model2 loss : 0.043976
[21:14:30.848] iteration 4701 : model1 loss : 0.026067 model2 loss : 0.034396
[21:14:31.535] iteration 4702 : model1 loss : 0.027728 model2 loss : 0.034542
[21:14:32.214] iteration 4703 : model1 loss : 0.034582 model2 loss : 0.032078
[21:14:32.907] iteration 4704 : model1 loss : 0.028843 model2 loss : 0.029327
[21:14:33.598] iteration 4705 : model1 loss : 0.034334 model2 loss : 0.040028
[21:14:34.284] iteration 4706 : model1 loss : 0.028192 model2 loss : 0.028645
[21:14:34.978] iteration 4707 : model1 loss : 0.031847 model2 loss : 0.032440
[21:14:35.672] iteration 4708 : model1 loss : 0.027026 model2 loss : 0.028486
[21:14:36.365] iteration 4709 : model1 loss : 0.051638 model2 loss : 0.050763
[21:14:37.037] iteration 4710 : model1 loss : 0.027473 model2 loss : 0.026623
[21:14:37.712] iteration 4711 : model1 loss : 0.041350 model2 loss : 0.055603
[21:14:38.386] iteration 4712 : model1 loss : 0.018577 model2 loss : 0.018137
[21:14:39.073] iteration 4713 : model1 loss : 0.047446 model2 loss : 0.053326
[21:14:39.741] iteration 4714 : model1 loss : 0.039947 model2 loss : 0.032219
[21:14:40.412] iteration 4715 : model1 loss : 0.033809 model2 loss : 0.024105
[21:14:41.101] iteration 4716 : model1 loss : 0.026839 model2 loss : 0.041926
[21:14:41.785] iteration 4717 : model1 loss : 0.119647 model2 loss : 0.140088
[21:14:42.480] iteration 4718 : model1 loss : 0.028802 model2 loss : 0.032314
[21:14:43.160] iteration 4719 : model1 loss : 0.028233 model2 loss : 0.027909
[21:14:43.843] iteration 4720 : model1 loss : 0.035546 model2 loss : 0.052460
[21:14:44.516] iteration 4721 : model1 loss : 0.033607 model2 loss : 0.034095
[21:14:45.185] iteration 4722 : model1 loss : 0.026375 model2 loss : 0.027705
[21:14:45.868] iteration 4723 : model1 loss : 0.023605 model2 loss : 0.025803
[21:14:46.557] iteration 4724 : model1 loss : 0.047470 model2 loss : 0.035942
[21:14:47.241] iteration 4725 : model1 loss : 0.025241 model2 loss : 0.031104
[21:14:47.928] iteration 4726 : model1 loss : 0.031662 model2 loss : 0.025784
[21:14:48.604] iteration 4727 : model1 loss : 0.023085 model2 loss : 0.024755
[21:14:49.297] iteration 4728 : model1 loss : 0.026165 model2 loss : 0.030068
[21:14:49.986] iteration 4729 : model1 loss : 0.038139 model2 loss : 0.031122
[21:14:50.658] iteration 4730 : model1 loss : 0.037419 model2 loss : 0.030895
[21:14:51.347] iteration 4731 : model1 loss : 0.043439 model2 loss : 0.049052
[21:14:52.026] iteration 4732 : model1 loss : 0.025644 model2 loss : 0.029471
[21:14:52.727] iteration 4733 : model1 loss : 0.081070 model2 loss : 0.066381
[21:14:53.418] iteration 4734 : model1 loss : 0.030280 model2 loss : 0.031800
[21:14:54.097] iteration 4735 : model1 loss : 0.030038 model2 loss : 0.034867
[21:14:54.771] iteration 4736 : model1 loss : 0.041899 model2 loss : 0.035659
[21:14:55.460] iteration 4737 : model1 loss : 0.037676 model2 loss : 0.042141
[21:14:56.129] iteration 4738 : model1 loss : 0.033355 model2 loss : 0.028295
[21:14:56.802] iteration 4739 : model1 loss : 0.022997 model2 loss : 0.024055
[21:14:57.497] iteration 4740 : model1 loss : 0.052507 model2 loss : 0.032923
[21:14:58.184] iteration 4741 : model1 loss : 0.037961 model2 loss : 0.031085
[21:14:58.878] iteration 4742 : model1 loss : 0.030837 model2 loss : 0.028117
[21:14:59.579] iteration 4743 : model1 loss : 0.046172 model2 loss : 0.048344
[21:15:00.257] iteration 4744 : model1 loss : 0.035140 model2 loss : 0.034166
[21:15:00.938] iteration 4745 : model1 loss : 0.020844 model2 loss : 0.021502
[21:15:01.619] iteration 4746 : model1 loss : 0.037050 model2 loss : 0.032350
[21:15:02.298] iteration 4747 : model1 loss : 0.030984 model2 loss : 0.033041
[21:15:02.987] iteration 4748 : model1 loss : 0.021299 model2 loss : 0.022784
[21:15:03.662] iteration 4749 : model1 loss : 0.043010 model2 loss : 0.038325
[21:15:04.348] iteration 4750 : model1 loss : 0.029143 model2 loss : 0.031020
[21:15:05.075] iteration 4751 : model1 loss : 0.033633 model2 loss : 0.031966
[21:15:05.755] iteration 4752 : model1 loss : 0.031152 model2 loss : 0.039377
[21:15:06.444] iteration 4753 : model1 loss : 0.041076 model2 loss : 0.033753
[21:15:07.126] iteration 4754 : model1 loss : 0.025241 model2 loss : 0.025122
[21:15:07.810] iteration 4755 : model1 loss : 0.030404 model2 loss : 0.033557
[21:15:08.491] iteration 4756 : model1 loss : 0.180373 model2 loss : 0.074797
[21:15:09.164] iteration 4757 : model1 loss : 0.025716 model2 loss : 0.025325
[21:15:09.853] iteration 4758 : model1 loss : 0.032197 model2 loss : 0.034988
[21:15:10.527] iteration 4759 : model1 loss : 0.040256 model2 loss : 0.046283
[21:15:11.204] iteration 4760 : model1 loss : 0.041812 model2 loss : 0.030703
[21:15:11.896] iteration 4761 : model1 loss : 0.039897 model2 loss : 0.037996
[21:15:12.574] iteration 4762 : model1 loss : 0.028556 model2 loss : 0.028119
[21:15:13.280] iteration 4763 : model1 loss : 0.032038 model2 loss : 0.027518
[21:15:13.962] iteration 4764 : model1 loss : 0.020335 model2 loss : 0.022995
[21:15:14.657] iteration 4765 : model1 loss : 0.033971 model2 loss : 0.030609
[21:15:15.340] iteration 4766 : model1 loss : 0.056540 model2 loss : 0.054383
[21:15:16.007] iteration 4767 : model1 loss : 0.045386 model2 loss : 0.041886
[21:15:16.691] iteration 4768 : model1 loss : 0.026033 model2 loss : 0.027825
[21:15:17.382] iteration 4769 : model1 loss : 0.039005 model2 loss : 0.030406
[21:15:18.054] iteration 4770 : model1 loss : 0.041226 model2 loss : 0.065212
[21:15:18.735] iteration 4771 : model1 loss : 0.034660 model2 loss : 0.031768
[21:15:19.407] iteration 4772 : model1 loss : 0.055942 model2 loss : 0.053712
[21:15:20.082] iteration 4773 : model1 loss : 0.027826 model2 loss : 0.038956
[21:15:20.769] iteration 4774 : model1 loss : 0.030647 model2 loss : 0.033167
[21:15:21.453] iteration 4775 : model1 loss : 0.033511 model2 loss : 0.038362
[21:15:22.129] iteration 4776 : model1 loss : 0.135333 model2 loss : 0.068350
[21:15:22.819] iteration 4777 : model1 loss : 0.033128 model2 loss : 0.034003
[21:15:23.499] iteration 4778 : model1 loss : 0.029209 model2 loss : 0.029290
[21:15:24.175] iteration 4779 : model1 loss : 0.026368 model2 loss : 0.027964
[21:15:24.849] iteration 4780 : model1 loss : 0.028141 model2 loss : 0.031078
[21:15:25.538] iteration 4781 : model1 loss : 0.025484 model2 loss : 0.024699
[21:15:26.214] iteration 4782 : model1 loss : 0.023973 model2 loss : 0.029581
[21:15:26.885] iteration 4783 : model1 loss : 0.042373 model2 loss : 0.034890
[21:15:27.567] iteration 4784 : model1 loss : 0.023088 model2 loss : 0.023721
[21:15:28.244] iteration 4785 : model1 loss : 0.025464 model2 loss : 0.029653
[21:15:28.925] iteration 4786 : model1 loss : 0.047731 model2 loss : 0.042534
[21:15:29.609] iteration 4787 : model1 loss : 0.035909 model2 loss : 0.031167
[21:15:30.291] iteration 4788 : model1 loss : 0.095700 model2 loss : 0.089030
[21:15:30.974] iteration 4789 : model1 loss : 0.059621 model2 loss : 0.064121
[21:15:31.697] iteration 4790 : model1 loss : 0.032231 model2 loss : 0.034573
[21:15:32.384] iteration 4791 : model1 loss : 0.031425 model2 loss : 0.032953
[21:15:33.053] iteration 4792 : model1 loss : 0.026346 model2 loss : 0.029015
[21:15:33.730] iteration 4793 : model1 loss : 0.042623 model2 loss : 0.037206
[21:15:34.413] iteration 4794 : model1 loss : 0.040410 model2 loss : 0.026927
[21:15:35.097] iteration 4795 : model1 loss : 0.033280 model2 loss : 0.038213
[21:15:35.761] iteration 4796 : model1 loss : 0.046938 model2 loss : 0.047461
[21:15:36.430] iteration 4797 : model1 loss : 0.057826 model2 loss : 0.049441
[21:15:37.119] iteration 4798 : model1 loss : 0.025565 model2 loss : 0.026821
[21:15:37.798] iteration 4799 : model1 loss : 0.029055 model2 loss : 0.027253
[21:15:38.493] iteration 4800 : model1 loss : 0.050411 model2 loss : 0.054252
[21:15:57.304] iteration 4800 : model1_mean_dice : 0.780078 model1_mean_hd95 : 13.998138
[21:16:16.692] iteration 4800 : model2_mean_dice : 0.836398 model2_mean_hd95 : 4.912158
[21:16:17.391] iteration 4801 : model1 loss : 0.034893 model2 loss : 0.029085
[21:16:18.071] iteration 4802 : model1 loss : 0.031987 model2 loss : 0.027713
[21:16:18.774] iteration 4803 : model1 loss : 0.035032 model2 loss : 0.025552
[21:16:19.457] iteration 4804 : model1 loss : 0.032010 model2 loss : 0.031450
[21:16:20.145] iteration 4805 : model1 loss : 0.031524 model2 loss : 0.035057
[21:16:20.819] iteration 4806 : model1 loss : 0.045112 model2 loss : 0.029621
[21:16:21.498] iteration 4807 : model1 loss : 0.031418 model2 loss : 0.037797
[21:16:22.172] iteration 4808 : model1 loss : 0.029560 model2 loss : 0.036952
[21:16:22.853] iteration 4809 : model1 loss : 0.030510 model2 loss : 0.026158
[21:16:23.522] iteration 4810 : model1 loss : 0.034013 model2 loss : 0.028692
[21:16:24.205] iteration 4811 : model1 loss : 0.043170 model2 loss : 0.045930
[21:16:24.880] iteration 4812 : model1 loss : 0.031549 model2 loss : 0.028064
[21:16:25.559] iteration 4813 : model1 loss : 0.050445 model2 loss : 0.041883
[21:16:26.222] iteration 4814 : model1 loss : 0.038577 model2 loss : 0.032748
[21:16:26.881] iteration 4815 : model1 loss : 0.045002 model2 loss : 0.033749
[21:16:27.563] iteration 4816 : model1 loss : 0.051119 model2 loss : 0.033939
[21:16:28.243] iteration 4817 : model1 loss : 0.033035 model2 loss : 0.030109
[21:16:28.910] iteration 4818 : model1 loss : 0.035923 model2 loss : 0.029238
[21:16:29.585] iteration 4819 : model1 loss : 0.047284 model2 loss : 0.037546
[21:16:30.257] iteration 4820 : model1 loss : 0.033790 model2 loss : 0.074124
[21:16:30.945] iteration 4821 : model1 loss : 0.041722 model2 loss : 0.030968
[21:16:31.642] iteration 4822 : model1 loss : 0.030704 model2 loss : 0.029013
[21:16:32.331] iteration 4823 : model1 loss : 0.033196 model2 loss : 0.029625
[21:16:33.008] iteration 4824 : model1 loss : 0.031748 model2 loss : 0.030674
[21:16:33.682] iteration 4825 : model1 loss : 0.026606 model2 loss : 0.029304
[21:16:34.363] iteration 4826 : model1 loss : 0.018317 model2 loss : 0.020366
[21:16:35.053] iteration 4827 : model1 loss : 0.026189 model2 loss : 0.036336
[21:16:35.720] iteration 4828 : model1 loss : 0.026041 model2 loss : 0.023890
[21:16:36.403] iteration 4829 : model1 loss : 0.019471 model2 loss : 0.018814
[21:16:37.085] iteration 4830 : model1 loss : 0.023787 model2 loss : 0.021508
[21:16:37.755] iteration 4831 : model1 loss : 0.026929 model2 loss : 0.025887
[21:16:38.442] iteration 4832 : model1 loss : 0.037677 model2 loss : 0.032868
[21:16:39.110] iteration 4833 : model1 loss : 0.023632 model2 loss : 0.031905
[21:16:39.793] iteration 4834 : model1 loss : 0.033998 model2 loss : 0.030706
[21:16:40.470] iteration 4835 : model1 loss : 0.035469 model2 loss : 0.035498
[21:16:41.139] iteration 4836 : model1 loss : 0.025399 model2 loss : 0.024141
[21:16:41.816] iteration 4837 : model1 loss : 0.055795 model2 loss : 0.058893
[21:16:42.508] iteration 4838 : model1 loss : 0.104968 model2 loss : 0.057276
[21:16:43.195] iteration 4839 : model1 loss : 0.055160 model2 loss : 0.032015
[21:16:43.881] iteration 4840 : model1 loss : 0.027796 model2 loss : 0.021739
[21:16:44.562] iteration 4841 : model1 loss : 0.029904 model2 loss : 0.028850
[21:16:45.235] iteration 4842 : model1 loss : 0.050048 model2 loss : 0.032223
[21:16:45.915] iteration 4843 : model1 loss : 0.038659 model2 loss : 0.033051
[21:16:46.590] iteration 4844 : model1 loss : 0.034800 model2 loss : 0.036695
[21:16:47.269] iteration 4845 : model1 loss : 0.038815 model2 loss : 0.032654
[21:16:47.934] iteration 4846 : model1 loss : 0.064253 model2 loss : 0.052216
[21:16:48.615] iteration 4847 : model1 loss : 0.037130 model2 loss : 0.037931
[21:16:49.308] iteration 4848 : model1 loss : 0.029657 model2 loss : 0.024791
[21:16:49.985] iteration 4849 : model1 loss : 0.027548 model2 loss : 0.030158
[21:16:50.658] iteration 4850 : model1 loss : 0.041457 model2 loss : 0.033451
[21:16:51.402] iteration 4851 : model1 loss : 0.033680 model2 loss : 0.032519
[21:16:52.086] iteration 4852 : model1 loss : 0.073714 model2 loss : 0.066516
[21:16:52.767] iteration 4853 : model1 loss : 0.024692 model2 loss : 0.020532
[21:16:53.459] iteration 4854 : model1 loss : 0.047656 model2 loss : 0.043653
[21:16:54.150] iteration 4855 : model1 loss : 0.054428 model2 loss : 0.038217
[21:16:54.826] iteration 4856 : model1 loss : 0.028987 model2 loss : 0.048213
[21:16:55.506] iteration 4857 : model1 loss : 0.035113 model2 loss : 0.040278
[21:16:56.188] iteration 4858 : model1 loss : 0.035595 model2 loss : 0.031226
[21:16:56.871] iteration 4859 : model1 loss : 0.023079 model2 loss : 0.020518
[21:16:57.559] iteration 4860 : model1 loss : 0.023709 model2 loss : 0.022900
[21:16:58.241] iteration 4861 : model1 loss : 0.029362 model2 loss : 0.028429
[21:16:58.923] iteration 4862 : model1 loss : 0.137488 model2 loss : 0.103443
[21:16:59.599] iteration 4863 : model1 loss : 0.033682 model2 loss : 0.030956
[21:17:00.272] iteration 4864 : model1 loss : 0.032022 model2 loss : 0.026491
[21:17:00.958] iteration 4865 : model1 loss : 0.134642 model2 loss : 0.147639
[21:17:01.639] iteration 4866 : model1 loss : 0.091181 model2 loss : 0.109292
[21:17:02.338] iteration 4867 : model1 loss : 0.046388 model2 loss : 0.045213
[21:17:03.009] iteration 4868 : model1 loss : 0.025909 model2 loss : 0.027045
[21:17:03.696] iteration 4869 : model1 loss : 0.028798 model2 loss : 0.031584
[21:17:04.373] iteration 4870 : model1 loss : 0.074375 model2 loss : 0.088650
[21:17:05.048] iteration 4871 : model1 loss : 0.026383 model2 loss : 0.028936
[21:17:05.735] iteration 4872 : model1 loss : 0.030648 model2 loss : 0.032608
[21:17:06.415] iteration 4873 : model1 loss : 0.032243 model2 loss : 0.031564
[21:17:07.097] iteration 4874 : model1 loss : 0.034332 model2 loss : 0.031128
[21:17:07.781] iteration 4875 : model1 loss : 0.019802 model2 loss : 0.022718
[21:17:08.451] iteration 4876 : model1 loss : 0.058530 model2 loss : 0.055391
[21:17:09.132] iteration 4877 : model1 loss : 0.036202 model2 loss : 0.028732
[21:17:09.809] iteration 4878 : model1 loss : 0.055508 model2 loss : 0.032676
[21:17:10.490] iteration 4879 : model1 loss : 0.025920 model2 loss : 0.025357
[21:17:11.170] iteration 4880 : model1 loss : 0.044988 model2 loss : 0.039250
[21:17:11.847] iteration 4881 : model1 loss : 0.025830 model2 loss : 0.022371
[21:17:12.548] iteration 4882 : model1 loss : 0.042813 model2 loss : 0.037994
[21:17:13.231] iteration 4883 : model1 loss : 0.023757 model2 loss : 0.030262
[21:17:13.911] iteration 4884 : model1 loss : 0.048992 model2 loss : 0.047102
[21:17:14.591] iteration 4885 : model1 loss : 0.030499 model2 loss : 0.034845
[21:17:15.276] iteration 4886 : model1 loss : 0.026639 model2 loss : 0.024963
[21:17:15.962] iteration 4887 : model1 loss : 0.035959 model2 loss : 0.068538
[21:17:16.649] iteration 4888 : model1 loss : 0.031348 model2 loss : 0.024225
[21:17:17.328] iteration 4889 : model1 loss : 0.047777 model2 loss : 0.034721
[21:17:18.001] iteration 4890 : model1 loss : 0.033253 model2 loss : 0.031678
[21:17:18.687] iteration 4891 : model1 loss : 0.025840 model2 loss : 0.024097
[21:17:19.383] iteration 4892 : model1 loss : 0.027125 model2 loss : 0.027411
[21:17:20.063] iteration 4893 : model1 loss : 0.033363 model2 loss : 0.034303
[21:17:20.731] iteration 4894 : model1 loss : 0.033736 model2 loss : 0.031825
[21:17:21.424] iteration 4895 : model1 loss : 0.028787 model2 loss : 0.028564
[21:17:22.118] iteration 4896 : model1 loss : 0.028757 model2 loss : 0.028892
[21:17:22.810] iteration 4897 : model1 loss : 0.029735 model2 loss : 0.028732
[21:17:23.490] iteration 4898 : model1 loss : 0.021801 model2 loss : 0.023672
[21:17:24.165] iteration 4899 : model1 loss : 0.039419 model2 loss : 0.051018
[21:17:24.842] iteration 4900 : model1 loss : 0.025612 model2 loss : 0.025106
[21:17:25.574] iteration 4901 : model1 loss : 0.062584 model2 loss : 0.031277
[21:17:26.240] iteration 4902 : model1 loss : 0.032726 model2 loss : 0.032593
[21:17:26.924] iteration 4903 : model1 loss : 0.033085 model2 loss : 0.036151
[21:17:27.614] iteration 4904 : model1 loss : 0.033375 model2 loss : 0.037054
[21:17:28.297] iteration 4905 : model1 loss : 0.049259 model2 loss : 0.031952
[21:17:29.004] iteration 4906 : model1 loss : 0.028443 model2 loss : 0.028424
[21:17:29.670] iteration 4907 : model1 loss : 0.029724 model2 loss : 0.027690
[21:17:30.344] iteration 4908 : model1 loss : 0.024918 model2 loss : 0.028185
[21:17:31.026] iteration 4909 : model1 loss : 0.031813 model2 loss : 0.032379
[21:17:31.700] iteration 4910 : model1 loss : 0.027150 model2 loss : 0.022563
[21:17:32.402] iteration 4911 : model1 loss : 0.035906 model2 loss : 0.042897
[21:17:33.092] iteration 4912 : model1 loss : 0.033213 model2 loss : 0.027975
[21:17:33.767] iteration 4913 : model1 loss : 0.042981 model2 loss : 0.045372
[21:17:34.457] iteration 4914 : model1 loss : 0.053792 model2 loss : 0.052457
[21:17:35.123] iteration 4915 : model1 loss : 0.035650 model2 loss : 0.035172
[21:17:35.821] iteration 4916 : model1 loss : 0.031081 model2 loss : 0.030677
[21:17:36.499] iteration 4917 : model1 loss : 0.029721 model2 loss : 0.031409
[21:17:37.182] iteration 4918 : model1 loss : 0.033513 model2 loss : 0.027188
[21:17:37.862] iteration 4919 : model1 loss : 0.020710 model2 loss : 0.023448
[21:17:38.550] iteration 4920 : model1 loss : 0.035268 model2 loss : 0.039270
[21:17:39.221] iteration 4921 : model1 loss : 0.179430 model2 loss : 0.068986
[21:17:39.908] iteration 4922 : model1 loss : 0.039397 model2 loss : 0.034090
[21:17:40.581] iteration 4923 : model1 loss : 0.045692 model2 loss : 0.035797
[21:17:41.263] iteration 4924 : model1 loss : 0.024862 model2 loss : 0.028453
[21:17:41.946] iteration 4925 : model1 loss : 0.026913 model2 loss : 0.027064
[21:17:42.641] iteration 4926 : model1 loss : 0.032356 model2 loss : 0.046069
[21:17:43.335] iteration 4927 : model1 loss : 0.048397 model2 loss : 0.049453
[21:17:44.021] iteration 4928 : model1 loss : 0.035010 model2 loss : 0.026669
[21:17:44.692] iteration 4929 : model1 loss : 0.033495 model2 loss : 0.033528
[21:17:45.382] iteration 4930 : model1 loss : 0.034397 model2 loss : 0.042451
[21:17:46.058] iteration 4931 : model1 loss : 0.026440 model2 loss : 0.023941
[21:17:46.742] iteration 4932 : model1 loss : 0.046264 model2 loss : 0.034439
[21:17:47.426] iteration 4933 : model1 loss : 0.050668 model2 loss : 0.081869
[21:17:48.105] iteration 4934 : model1 loss : 0.027314 model2 loss : 0.023226
[21:17:48.802] iteration 4935 : model1 loss : 0.019447 model2 loss : 0.017413
[21:17:49.489] iteration 4936 : model1 loss : 0.056222 model2 loss : 0.048882
[21:17:50.164] iteration 4937 : model1 loss : 0.025002 model2 loss : 0.023631
[21:17:50.850] iteration 4938 : model1 loss : 0.028584 model2 loss : 0.027455
[21:17:51.541] iteration 4939 : model1 loss : 0.031399 model2 loss : 0.031653
[21:17:52.213] iteration 4940 : model1 loss : 0.035632 model2 loss : 0.025669
[21:17:52.899] iteration 4941 : model1 loss : 0.038083 model2 loss : 0.049751
[21:17:53.584] iteration 4942 : model1 loss : 0.098639 model2 loss : 0.067718
[21:17:54.262] iteration 4943 : model1 loss : 0.022648 model2 loss : 0.028682
[21:17:54.933] iteration 4944 : model1 loss : 0.036373 model2 loss : 0.031101
[21:17:55.619] iteration 4945 : model1 loss : 0.034166 model2 loss : 0.048930
[21:17:56.312] iteration 4946 : model1 loss : 0.034756 model2 loss : 0.025079
[21:17:56.977] iteration 4947 : model1 loss : 0.026336 model2 loss : 0.024837
[21:17:57.669] iteration 4948 : model1 loss : 0.024076 model2 loss : 0.024397
[21:17:58.353] iteration 4949 : model1 loss : 0.043749 model2 loss : 0.043042
[21:17:59.038] iteration 4950 : model1 loss : 0.033920 model2 loss : 0.029504
[21:17:59.761] iteration 4951 : model1 loss : 0.037529 model2 loss : 0.033859
[21:18:00.439] iteration 4952 : model1 loss : 0.032307 model2 loss : 0.034435
[21:18:01.119] iteration 4953 : model1 loss : 0.032372 model2 loss : 0.028553
[21:18:01.800] iteration 4954 : model1 loss : 0.041723 model2 loss : 0.032816
[21:18:02.496] iteration 4955 : model1 loss : 0.026360 model2 loss : 0.023594
[21:18:03.196] iteration 4956 : model1 loss : 0.039072 model2 loss : 0.032223
[21:18:03.877] iteration 4957 : model1 loss : 0.028109 model2 loss : 0.028570
[21:18:04.555] iteration 4958 : model1 loss : 0.025319 model2 loss : 0.027680
[21:18:05.238] iteration 4959 : model1 loss : 0.033793 model2 loss : 0.044428
[21:18:05.911] iteration 4960 : model1 loss : 0.037323 model2 loss : 0.043873
[21:18:06.588] iteration 4961 : model1 loss : 0.021212 model2 loss : 0.024009
[21:18:07.267] iteration 4962 : model1 loss : 0.037405 model2 loss : 0.035911
[21:18:07.947] iteration 4963 : model1 loss : 0.029658 model2 loss : 0.030131
[21:18:08.636] iteration 4964 : model1 loss : 0.068018 model2 loss : 0.069956
[21:18:09.326] iteration 4965 : model1 loss : 0.019681 model2 loss : 0.021815
[21:18:10.012] iteration 4966 : model1 loss : 0.036008 model2 loss : 0.033742
[21:18:10.694] iteration 4967 : model1 loss : 0.065312 model2 loss : 0.036286
[21:18:11.367] iteration 4968 : model1 loss : 0.030718 model2 loss : 0.029615
[21:18:12.051] iteration 4969 : model1 loss : 0.025418 model2 loss : 0.028176
[21:18:12.737] iteration 4970 : model1 loss : 0.022781 model2 loss : 0.025687
[21:18:13.415] iteration 4971 : model1 loss : 0.040765 model2 loss : 0.057259
[21:18:14.096] iteration 4972 : model1 loss : 0.063336 model2 loss : 0.059137
[21:18:14.781] iteration 4973 : model1 loss : 0.049202 model2 loss : 0.050063
[21:18:15.456] iteration 4974 : model1 loss : 0.032334 model2 loss : 0.020998
[21:18:16.139] iteration 4975 : model1 loss : 0.083261 model2 loss : 0.107830
[21:18:16.846] iteration 4976 : model1 loss : 0.036622 model2 loss : 0.039533
[21:18:17.534] iteration 4977 : model1 loss : 0.028297 model2 loss : 0.033834
[21:18:18.221] iteration 4978 : model1 loss : 0.031434 model2 loss : 0.028266
[21:18:18.883] iteration 4979 : model1 loss : 0.108898 model2 loss : 0.051073
[21:18:19.572] iteration 4980 : model1 loss : 0.024152 model2 loss : 0.028225
[21:18:20.242] iteration 4981 : model1 loss : 0.026462 model2 loss : 0.024174
[21:18:20.914] iteration 4982 : model1 loss : 0.037191 model2 loss : 0.028005
[21:18:21.590] iteration 4983 : model1 loss : 0.037479 model2 loss : 0.036322
[21:18:22.265] iteration 4984 : model1 loss : 0.026767 model2 loss : 0.027106
[21:18:22.958] iteration 4985 : model1 loss : 0.039971 model2 loss : 0.033160
[21:18:23.643] iteration 4986 : model1 loss : 0.029321 model2 loss : 0.025121
[21:18:24.314] iteration 4987 : model1 loss : 0.022618 model2 loss : 0.024456
[21:18:24.988] iteration 4988 : model1 loss : 0.026275 model2 loss : 0.034066
[21:18:25.664] iteration 4989 : model1 loss : 0.025920 model2 loss : 0.040100
[21:18:26.342] iteration 4990 : model1 loss : 0.032319 model2 loss : 0.035101
[21:18:27.032] iteration 4991 : model1 loss : 0.038791 model2 loss : 0.038972
[21:18:27.705] iteration 4992 : model1 loss : 0.025212 model2 loss : 0.022761
[21:18:28.384] iteration 4993 : model1 loss : 0.043266 model2 loss : 0.038020
[21:18:29.061] iteration 4994 : model1 loss : 0.042790 model2 loss : 0.038818
[21:18:29.739] iteration 4995 : model1 loss : 0.059139 model2 loss : 0.097557
[21:18:30.434] iteration 4996 : model1 loss : 0.029138 model2 loss : 0.027759
[21:18:31.125] iteration 4997 : model1 loss : 0.029264 model2 loss : 0.028721
[21:18:31.802] iteration 4998 : model1 loss : 0.050416 model2 loss : 0.041501
[21:18:32.501] iteration 4999 : model1 loss : 0.027790 model2 loss : 0.029041
[21:18:33.207] iteration 5000 : model1 loss : 0.054315 model2 loss : 0.075652
[21:18:52.349] iteration 5000 : model1_mean_dice : 0.811321 model1_mean_hd95 : 13.469485
[21:19:11.193] iteration 5000 : model2_mean_dice : 0.826455 model2_mean_hd95 : 20.833992
[21:19:11.901] iteration 5001 : model1 loss : 0.150261 model2 loss : 0.163444
[21:19:12.588] iteration 5002 : model1 loss : 0.028066 model2 loss : 0.030836
[21:19:13.255] iteration 5003 : model1 loss : 0.035432 model2 loss : 0.029452
[21:19:13.929] iteration 5004 : model1 loss : 0.027920 model2 loss : 0.026165
[21:19:14.595] iteration 5005 : model1 loss : 0.019090 model2 loss : 0.024457
[21:19:15.279] iteration 5006 : model1 loss : 0.035150 model2 loss : 0.051291
[21:19:15.972] iteration 5007 : model1 loss : 0.141286 model2 loss : 0.151974
[21:19:16.637] iteration 5008 : model1 loss : 0.033306 model2 loss : 0.034941
[21:19:17.303] iteration 5009 : model1 loss : 0.025100 model2 loss : 0.026795
[21:19:17.993] iteration 5010 : model1 loss : 0.033219 model2 loss : 0.035389
[21:19:18.680] iteration 5011 : model1 loss : 0.031198 model2 loss : 0.033322
[21:19:19.367] iteration 5012 : model1 loss : 0.049413 model2 loss : 0.042379
[21:19:20.052] iteration 5013 : model1 loss : 0.030265 model2 loss : 0.036190
[21:19:20.724] iteration 5014 : model1 loss : 0.030646 model2 loss : 0.031087
[21:19:21.401] iteration 5015 : model1 loss : 0.039029 model2 loss : 0.038021
[21:19:22.060] iteration 5016 : model1 loss : 0.026400 model2 loss : 0.031384
[21:19:22.741] iteration 5017 : model1 loss : 0.036194 model2 loss : 0.046742
[21:19:23.416] iteration 5018 : model1 loss : 0.024199 model2 loss : 0.032886
[21:19:24.088] iteration 5019 : model1 loss : 0.030859 model2 loss : 0.028037
[21:19:24.780] iteration 5020 : model1 loss : 0.027089 model2 loss : 0.036307
[21:19:25.447] iteration 5021 : model1 loss : 0.024049 model2 loss : 0.026418
[21:19:26.134] iteration 5022 : model1 loss : 0.050269 model2 loss : 0.077221
[21:19:26.813] iteration 5023 : model1 loss : 0.026109 model2 loss : 0.028357
[21:19:27.484] iteration 5024 : model1 loss : 0.020915 model2 loss : 0.022620
[21:19:28.156] iteration 5025 : model1 loss : 0.029795 model2 loss : 0.031999
[21:19:28.835] iteration 5026 : model1 loss : 0.085497 model2 loss : 0.076094
[21:19:29.516] iteration 5027 : model1 loss : 0.037680 model2 loss : 0.046930
[21:19:30.190] iteration 5028 : model1 loss : 0.030318 model2 loss : 0.027880
[21:19:30.884] iteration 5029 : model1 loss : 0.035378 model2 loss : 0.041065
[21:19:31.557] iteration 5030 : model1 loss : 0.032316 model2 loss : 0.029099
[21:19:32.222] iteration 5031 : model1 loss : 0.028186 model2 loss : 0.030749
[21:19:32.906] iteration 5032 : model1 loss : 0.044049 model2 loss : 0.049110
[21:19:33.618] iteration 5033 : model1 loss : 0.023277 model2 loss : 0.021942
[21:19:34.290] iteration 5034 : model1 loss : 0.031192 model2 loss : 0.054326
[21:19:34.981] iteration 5035 : model1 loss : 0.022190 model2 loss : 0.024842
[21:19:35.670] iteration 5036 : model1 loss : 0.028053 model2 loss : 0.026787
[21:19:36.351] iteration 5037 : model1 loss : 0.042860 model2 loss : 0.037426
[21:19:37.015] iteration 5038 : model1 loss : 0.025348 model2 loss : 0.027168
[21:19:37.693] iteration 5039 : model1 loss : 0.021183 model2 loss : 0.023693
[21:19:38.365] iteration 5040 : model1 loss : 0.030860 model2 loss : 0.033171
[21:19:39.054] iteration 5041 : model1 loss : 0.025656 model2 loss : 0.026352
[21:19:39.726] iteration 5042 : model1 loss : 0.029823 model2 loss : 0.028801
[21:19:40.408] iteration 5043 : model1 loss : 0.036153 model2 loss : 0.033186
[21:19:41.085] iteration 5044 : model1 loss : 0.029743 model2 loss : 0.036293
[21:19:41.762] iteration 5045 : model1 loss : 0.036805 model2 loss : 0.031851
[21:19:42.452] iteration 5046 : model1 loss : 0.034144 model2 loss : 0.028342
[21:19:43.122] iteration 5047 : model1 loss : 0.029013 model2 loss : 0.027169
[21:19:43.815] iteration 5048 : model1 loss : 0.037901 model2 loss : 0.046542
[21:19:44.494] iteration 5049 : model1 loss : 0.039554 model2 loss : 0.047991
[21:19:45.170] iteration 5050 : model1 loss : 0.030607 model2 loss : 0.025010
[21:19:45.903] iteration 5051 : model1 loss : 0.029362 model2 loss : 0.030474
[21:19:46.575] iteration 5052 : model1 loss : 0.033017 model2 loss : 0.032661
[21:19:47.257] iteration 5053 : model1 loss : 0.054968 model2 loss : 0.063346
[21:19:47.935] iteration 5054 : model1 loss : 0.025243 model2 loss : 0.025815
[21:19:48.623] iteration 5055 : model1 loss : 0.026940 model2 loss : 0.023222
[21:19:49.314] iteration 5056 : model1 loss : 0.028107 model2 loss : 0.026918
[21:19:49.993] iteration 5057 : model1 loss : 0.022981 model2 loss : 0.026443
[21:19:50.678] iteration 5058 : model1 loss : 0.031901 model2 loss : 0.032190
[21:19:51.362] iteration 5059 : model1 loss : 0.028067 model2 loss : 0.028174
[21:19:52.055] iteration 5060 : model1 loss : 0.027380 model2 loss : 0.024941
[21:19:52.742] iteration 5061 : model1 loss : 0.032619 model2 loss : 0.034409
[21:19:53.429] iteration 5062 : model1 loss : 0.022391 model2 loss : 0.022564
[21:19:54.120] iteration 5063 : model1 loss : 0.046813 model2 loss : 0.037049
[21:19:54.814] iteration 5064 : model1 loss : 0.033640 model2 loss : 0.029539
[21:19:55.493] iteration 5065 : model1 loss : 0.021941 model2 loss : 0.022474
[21:19:56.175] iteration 5066 : model1 loss : 0.030718 model2 loss : 0.028451
[21:19:56.846] iteration 5067 : model1 loss : 0.034822 model2 loss : 0.046005
[21:19:57.524] iteration 5068 : model1 loss : 0.030832 model2 loss : 0.031075
[21:19:58.195] iteration 5069 : model1 loss : 0.038779 model2 loss : 0.030738
[21:19:58.880] iteration 5070 : model1 loss : 0.020793 model2 loss : 0.025305
[21:19:59.554] iteration 5071 : model1 loss : 0.030018 model2 loss : 0.028980
[21:20:00.240] iteration 5072 : model1 loss : 0.032408 model2 loss : 0.025574
[21:20:00.939] iteration 5073 : model1 loss : 0.035693 model2 loss : 0.036785
[21:20:01.611] iteration 5074 : model1 loss : 0.026082 model2 loss : 0.028662
[21:20:02.301] iteration 5075 : model1 loss : 0.031873 model2 loss : 0.029105
[21:20:02.978] iteration 5076 : model1 loss : 0.024685 model2 loss : 0.024891
[21:20:03.656] iteration 5077 : model1 loss : 0.031226 model2 loss : 0.029603
[21:20:04.343] iteration 5078 : model1 loss : 0.047417 model2 loss : 0.038200
[21:20:05.025] iteration 5079 : model1 loss : 0.044554 model2 loss : 0.040807
[21:20:05.695] iteration 5080 : model1 loss : 0.027178 model2 loss : 0.033756
[21:20:06.396] iteration 5081 : model1 loss : 0.027656 model2 loss : 0.030609
[21:20:07.078] iteration 5082 : model1 loss : 0.045980 model2 loss : 0.047356
[21:20:07.753] iteration 5083 : model1 loss : 0.026420 model2 loss : 0.030348
[21:20:08.428] iteration 5084 : model1 loss : 0.026983 model2 loss : 0.043690
[21:20:09.102] iteration 5085 : model1 loss : 0.053901 model2 loss : 0.067005
[21:20:09.782] iteration 5086 : model1 loss : 0.018618 model2 loss : 0.017166
[21:20:10.454] iteration 5087 : model1 loss : 0.031385 model2 loss : 0.031551
[21:20:11.138] iteration 5088 : model1 loss : 0.155049 model2 loss : 0.156593
[21:20:11.817] iteration 5089 : model1 loss : 0.042063 model2 loss : 0.050175
[21:20:12.494] iteration 5090 : model1 loss : 0.028933 model2 loss : 0.030061
[21:20:13.176] iteration 5091 : model1 loss : 0.024538 model2 loss : 0.029468
[21:20:13.854] iteration 5092 : model1 loss : 0.021384 model2 loss : 0.023056
[21:20:14.524] iteration 5093 : model1 loss : 0.032488 model2 loss : 0.028708
[21:20:15.212] iteration 5094 : model1 loss : 0.024902 model2 loss : 0.024328
[21:20:15.898] iteration 5095 : model1 loss : 0.030458 model2 loss : 0.031284
[21:20:16.582] iteration 5096 : model1 loss : 0.031821 model2 loss : 0.031097
[21:20:17.261] iteration 5097 : model1 loss : 0.030566 model2 loss : 0.075431
[21:20:17.943] iteration 5098 : model1 loss : 0.050098 model2 loss : 0.042756
[21:20:18.629] iteration 5099 : model1 loss : 0.027504 model2 loss : 0.032019
[21:20:19.317] iteration 5100 : model1 loss : 0.032573 model2 loss : 0.043865
[21:20:20.049] iteration 5101 : model1 loss : 0.020551 model2 loss : 0.023479
[21:20:20.738] iteration 5102 : model1 loss : 0.019633 model2 loss : 0.020807
[21:20:21.423] iteration 5103 : model1 loss : 0.021704 model2 loss : 0.022471
[21:20:22.102] iteration 5104 : model1 loss : 0.027188 model2 loss : 0.029530
[21:20:22.794] iteration 5105 : model1 loss : 0.028286 model2 loss : 0.026759
[21:20:23.471] iteration 5106 : model1 loss : 0.038797 model2 loss : 0.047454
[21:20:24.164] iteration 5107 : model1 loss : 0.029434 model2 loss : 0.031031
[21:20:24.844] iteration 5108 : model1 loss : 0.025708 model2 loss : 0.028238
[21:20:25.526] iteration 5109 : model1 loss : 0.069964 model2 loss : 0.069947
[21:20:26.212] iteration 5110 : model1 loss : 0.036111 model2 loss : 0.041905
[21:20:26.897] iteration 5111 : model1 loss : 0.032590 model2 loss : 0.029047
[21:20:27.565] iteration 5112 : model1 loss : 0.036043 model2 loss : 0.030584
[21:20:28.237] iteration 5113 : model1 loss : 0.028654 model2 loss : 0.029736
[21:20:28.912] iteration 5114 : model1 loss : 0.018503 model2 loss : 0.018105
[21:20:29.586] iteration 5115 : model1 loss : 0.054496 model2 loss : 0.076500
[21:20:30.274] iteration 5116 : model1 loss : 0.023441 model2 loss : 0.025856
[21:20:30.952] iteration 5117 : model1 loss : 0.021663 model2 loss : 0.029252
[21:20:31.631] iteration 5118 : model1 loss : 0.027476 model2 loss : 0.023321
[21:20:32.316] iteration 5119 : model1 loss : 0.020754 model2 loss : 0.020216
[21:20:33.004] iteration 5120 : model1 loss : 0.034129 model2 loss : 0.032739
[21:20:33.707] iteration 5121 : model1 loss : 0.028342 model2 loss : 0.030430
[21:20:34.396] iteration 5122 : model1 loss : 0.025346 model2 loss : 0.028040
[21:20:35.086] iteration 5123 : model1 loss : 0.051774 model2 loss : 0.041432
[21:20:35.768] iteration 5124 : model1 loss : 0.068518 model2 loss : 0.075837
[21:20:36.468] iteration 5125 : model1 loss : 0.040910 model2 loss : 0.060455
[21:20:37.154] iteration 5126 : model1 loss : 0.023662 model2 loss : 0.025012
[21:20:37.833] iteration 5127 : model1 loss : 0.033730 model2 loss : 0.029976
[21:20:38.536] iteration 5128 : model1 loss : 0.036559 model2 loss : 0.038078
[21:20:39.216] iteration 5129 : model1 loss : 0.035776 model2 loss : 0.034888
[21:20:39.894] iteration 5130 : model1 loss : 0.030397 model2 loss : 0.037283
[21:20:40.587] iteration 5131 : model1 loss : 0.034793 model2 loss : 0.042719
[21:20:41.260] iteration 5132 : model1 loss : 0.027252 model2 loss : 0.026772
[21:20:41.934] iteration 5133 : model1 loss : 0.025275 model2 loss : 0.026803
[21:20:42.624] iteration 5134 : model1 loss : 0.027933 model2 loss : 0.032051
[21:20:43.300] iteration 5135 : model1 loss : 0.065915 model2 loss : 0.073450
[21:20:43.994] iteration 5136 : model1 loss : 0.029448 model2 loss : 0.031516
[21:20:44.682] iteration 5137 : model1 loss : 0.046822 model2 loss : 0.059240
[21:20:45.365] iteration 5138 : model1 loss : 0.023940 model2 loss : 0.023731
[21:20:46.047] iteration 5139 : model1 loss : 0.055507 model2 loss : 0.057482
[21:20:46.720] iteration 5140 : model1 loss : 0.032665 model2 loss : 0.032564
[21:20:47.413] iteration 5141 : model1 loss : 0.022593 model2 loss : 0.025153
[21:20:48.088] iteration 5142 : model1 loss : 0.033777 model2 loss : 0.027369
[21:20:48.777] iteration 5143 : model1 loss : 0.031265 model2 loss : 0.037654
[21:20:49.466] iteration 5144 : model1 loss : 0.039940 model2 loss : 0.036693
[21:20:50.146] iteration 5145 : model1 loss : 0.021847 model2 loss : 0.027094
[21:20:50.818] iteration 5146 : model1 loss : 0.033673 model2 loss : 0.032731
[21:20:51.500] iteration 5147 : model1 loss : 0.024487 model2 loss : 0.025059
[21:20:52.181] iteration 5148 : model1 loss : 0.036520 model2 loss : 0.036999
[21:20:52.849] iteration 5149 : model1 loss : 0.024256 model2 loss : 0.024103
[21:20:53.519] iteration 5150 : model1 loss : 0.023953 model2 loss : 0.027859
[21:20:54.227] iteration 5151 : model1 loss : 0.070874 model2 loss : 0.081015
[21:20:54.908] iteration 5152 : model1 loss : 0.028175 model2 loss : 0.037174
[21:20:55.582] iteration 5153 : model1 loss : 0.034932 model2 loss : 0.043388
[21:20:56.272] iteration 5154 : model1 loss : 0.048230 model2 loss : 0.047485
[21:20:56.963] iteration 5155 : model1 loss : 0.028170 model2 loss : 0.029210
[21:20:57.653] iteration 5156 : model1 loss : 0.029323 model2 loss : 0.025351
[21:20:58.338] iteration 5157 : model1 loss : 0.030987 model2 loss : 0.033292
[21:20:59.018] iteration 5158 : model1 loss : 0.040867 model2 loss : 0.023196
[21:20:59.700] iteration 5159 : model1 loss : 0.026700 model2 loss : 0.024246
[21:21:00.388] iteration 5160 : model1 loss : 0.040463 model2 loss : 0.032321
[21:21:01.090] iteration 5161 : model1 loss : 0.034016 model2 loss : 0.039997
[21:21:01.772] iteration 5162 : model1 loss : 0.030307 model2 loss : 0.032568
[21:21:02.463] iteration 5163 : model1 loss : 0.054099 model2 loss : 0.047615
[21:21:03.144] iteration 5164 : model1 loss : 0.023772 model2 loss : 0.026755
[21:21:03.832] iteration 5165 : model1 loss : 0.025740 model2 loss : 0.029925
[21:21:04.504] iteration 5166 : model1 loss : 0.039323 model2 loss : 0.053272
[21:21:05.193] iteration 5167 : model1 loss : 0.043512 model2 loss : 0.032704
[21:21:05.889] iteration 5168 : model1 loss : 0.040432 model2 loss : 0.069486
[21:21:06.550] iteration 5169 : model1 loss : 0.026313 model2 loss : 0.026454
[21:21:07.236] iteration 5170 : model1 loss : 0.027247 model2 loss : 0.025600
[21:21:07.906] iteration 5171 : model1 loss : 0.066840 model2 loss : 0.106010
[21:21:08.592] iteration 5172 : model1 loss : 0.025537 model2 loss : 0.024501
[21:21:09.266] iteration 5173 : model1 loss : 0.032999 model2 loss : 0.027103
[21:21:09.952] iteration 5174 : model1 loss : 0.025905 model2 loss : 0.024963
[21:21:10.645] iteration 5175 : model1 loss : 0.034757 model2 loss : 0.028410
[21:21:11.329] iteration 5176 : model1 loss : 0.035138 model2 loss : 0.030680
[21:21:12.015] iteration 5177 : model1 loss : 0.023445 model2 loss : 0.021566
[21:21:12.700] iteration 5178 : model1 loss : 0.152524 model2 loss : 0.131841
[21:21:13.375] iteration 5179 : model1 loss : 0.031811 model2 loss : 0.023172
[21:21:14.067] iteration 5180 : model1 loss : 0.028476 model2 loss : 0.024637
[21:21:14.742] iteration 5181 : model1 loss : 0.027081 model2 loss : 0.032566
[21:21:15.433] iteration 5182 : model1 loss : 0.020882 model2 loss : 0.029250
[21:21:16.101] iteration 5183 : model1 loss : 0.037537 model2 loss : 0.069217
[21:21:16.789] iteration 5184 : model1 loss : 0.033916 model2 loss : 0.029078
[21:21:17.468] iteration 5185 : model1 loss : 0.033223 model2 loss : 0.037815
[21:21:18.156] iteration 5186 : model1 loss : 0.030505 model2 loss : 0.027182
[21:21:18.842] iteration 5187 : model1 loss : 0.021307 model2 loss : 0.023317
[21:21:19.525] iteration 5188 : model1 loss : 0.027086 model2 loss : 0.025978
[21:21:20.223] iteration 5189 : model1 loss : 0.041231 model2 loss : 0.040463
[21:21:20.906] iteration 5190 : model1 loss : 0.031324 model2 loss : 0.032992
[21:21:21.586] iteration 5191 : model1 loss : 0.027163 model2 loss : 0.036607
[21:21:22.278] iteration 5192 : model1 loss : 0.028191 model2 loss : 0.028788
[21:21:22.961] iteration 5193 : model1 loss : 0.044508 model2 loss : 0.036755
[21:21:23.904] iteration 5194 : model1 loss : 0.031200 model2 loss : 0.036863
[21:21:24.639] iteration 5195 : model1 loss : 0.025838 model2 loss : 0.028100
[21:21:25.332] iteration 5196 : model1 loss : 0.030233 model2 loss : 0.032910
[21:21:26.002] iteration 5197 : model1 loss : 0.038455 model2 loss : 0.036791
[21:21:26.676] iteration 5198 : model1 loss : 0.028010 model2 loss : 0.028564
[21:21:27.354] iteration 5199 : model1 loss : 0.033976 model2 loss : 0.040870
[21:21:28.036] iteration 5200 : model1 loss : 0.048238 model2 loss : 0.034738
[21:21:47.254] iteration 5200 : model1_mean_dice : 0.836738 model1_mean_hd95 : 8.080170
[21:22:06.032] iteration 5200 : model2_mean_dice : 0.838271 model2_mean_hd95 : 4.078249
[21:22:06.721] iteration 5201 : model1 loss : 0.040949 model2 loss : 0.036360
[21:22:07.396] iteration 5202 : model1 loss : 0.046406 model2 loss : 0.036613
[21:22:08.082] iteration 5203 : model1 loss : 0.038746 model2 loss : 0.030287
[21:22:08.765] iteration 5204 : model1 loss : 0.028200 model2 loss : 0.027689
[21:22:09.447] iteration 5205 : model1 loss : 0.043693 model2 loss : 0.053383
[21:22:10.128] iteration 5206 : model1 loss : 0.026409 model2 loss : 0.029525
[21:22:10.805] iteration 5207 : model1 loss : 0.036984 model2 loss : 0.056545
[21:22:11.483] iteration 5208 : model1 loss : 0.031543 model2 loss : 0.044579
[21:22:12.146] iteration 5209 : model1 loss : 0.035329 model2 loss : 0.033887
[21:22:12.818] iteration 5210 : model1 loss : 0.028818 model2 loss : 0.023602
[21:22:13.506] iteration 5211 : model1 loss : 0.042641 model2 loss : 0.052007
[21:22:14.166] iteration 5212 : model1 loss : 0.084786 model2 loss : 0.081060
[21:22:14.852] iteration 5213 : model1 loss : 0.023051 model2 loss : 0.024378
[21:22:15.528] iteration 5214 : model1 loss : 0.023788 model2 loss : 0.026294
[21:22:16.196] iteration 5215 : model1 loss : 0.027983 model2 loss : 0.028487
[21:22:16.893] iteration 5216 : model1 loss : 0.032838 model2 loss : 0.034901
[21:22:17.567] iteration 5217 : model1 loss : 0.058369 model2 loss : 0.026833
[21:22:18.242] iteration 5218 : model1 loss : 0.027099 model2 loss : 0.028753
[21:22:18.934] iteration 5219 : model1 loss : 0.024454 model2 loss : 0.025560
[21:22:19.606] iteration 5220 : model1 loss : 0.045671 model2 loss : 0.057291
[21:22:20.279] iteration 5221 : model1 loss : 0.037843 model2 loss : 0.030931
[21:22:20.949] iteration 5222 : model1 loss : 0.020412 model2 loss : 0.024038
[21:22:21.617] iteration 5223 : model1 loss : 0.027892 model2 loss : 0.041173
[21:22:22.292] iteration 5224 : model1 loss : 0.028431 model2 loss : 0.026196
[21:22:22.967] iteration 5225 : model1 loss : 0.021799 model2 loss : 0.022976
[21:22:23.642] iteration 5226 : model1 loss : 0.165157 model2 loss : 0.153488
[21:22:24.327] iteration 5227 : model1 loss : 0.023499 model2 loss : 0.024836
[21:22:25.024] iteration 5228 : model1 loss : 0.095469 model2 loss : 0.036951
[21:22:25.701] iteration 5229 : model1 loss : 0.024514 model2 loss : 0.023225
[21:22:26.372] iteration 5230 : model1 loss : 0.098889 model2 loss : 0.037847
[21:22:27.050] iteration 5231 : model1 loss : 0.070185 model2 loss : 0.070984
[21:22:27.736] iteration 5232 : model1 loss : 0.028961 model2 loss : 0.027819
[21:22:28.414] iteration 5233 : model1 loss : 0.045125 model2 loss : 0.049972
[21:22:29.103] iteration 5234 : model1 loss : 0.024702 model2 loss : 0.023367
[21:22:29.785] iteration 5235 : model1 loss : 0.073467 model2 loss : 0.062419
[21:22:30.470] iteration 5236 : model1 loss : 0.031406 model2 loss : 0.028893
[21:22:31.135] iteration 5237 : model1 loss : 0.031719 model2 loss : 0.030194
[21:22:31.811] iteration 5238 : model1 loss : 0.028026 model2 loss : 0.030549
[21:22:32.495] iteration 5239 : model1 loss : 0.024729 model2 loss : 0.023861
[21:22:33.172] iteration 5240 : model1 loss : 0.023939 model2 loss : 0.026502
[21:22:33.857] iteration 5241 : model1 loss : 0.023179 model2 loss : 0.019299
[21:22:34.551] iteration 5242 : model1 loss : 0.025511 model2 loss : 0.026780
[21:22:35.245] iteration 5243 : model1 loss : 0.038514 model2 loss : 0.037624
[21:22:35.932] iteration 5244 : model1 loss : 0.021166 model2 loss : 0.024710
[21:22:36.606] iteration 5245 : model1 loss : 0.027367 model2 loss : 0.024290
[21:22:37.290] iteration 5246 : model1 loss : 0.029265 model2 loss : 0.031597
[21:22:37.966] iteration 5247 : model1 loss : 0.026324 model2 loss : 0.022725
[21:22:38.636] iteration 5248 : model1 loss : 0.039699 model2 loss : 0.047853
[21:22:39.314] iteration 5249 : model1 loss : 0.034676 model2 loss : 0.032115
[21:22:39.986] iteration 5250 : model1 loss : 0.025519 model2 loss : 0.024424
[21:22:40.726] iteration 5251 : model1 loss : 0.031718 model2 loss : 0.033218
[21:22:41.411] iteration 5252 : model1 loss : 0.036523 model2 loss : 0.024272
[21:22:42.087] iteration 5253 : model1 loss : 0.036765 model2 loss : 0.033572
[21:22:42.770] iteration 5254 : model1 loss : 0.033745 model2 loss : 0.032367
[21:22:43.444] iteration 5255 : model1 loss : 0.023307 model2 loss : 0.022060
[21:22:44.130] iteration 5256 : model1 loss : 0.072895 model2 loss : 0.077994
[21:22:44.813] iteration 5257 : model1 loss : 0.123402 model2 loss : 0.127978
[21:22:45.506] iteration 5258 : model1 loss : 0.037849 model2 loss : 0.037962
[21:22:46.183] iteration 5259 : model1 loss : 0.022006 model2 loss : 0.024059
[21:22:46.849] iteration 5260 : model1 loss : 0.035582 model2 loss : 0.029544
[21:22:47.555] iteration 5261 : model1 loss : 0.031197 model2 loss : 0.040960
[21:22:48.236] iteration 5262 : model1 loss : 0.025534 model2 loss : 0.027518
[21:22:48.914] iteration 5263 : model1 loss : 0.045901 model2 loss : 0.037356
[21:22:49.586] iteration 5264 : model1 loss : 0.029512 model2 loss : 0.028571
[21:22:50.270] iteration 5265 : model1 loss : 0.025854 model2 loss : 0.025212
[21:22:50.965] iteration 5266 : model1 loss : 0.023633 model2 loss : 0.023987
[21:22:51.645] iteration 5267 : model1 loss : 0.030393 model2 loss : 0.027514
[21:22:52.314] iteration 5268 : model1 loss : 0.027192 model2 loss : 0.025573
[21:22:53.000] iteration 5269 : model1 loss : 0.032690 model2 loss : 0.030994
[21:22:53.689] iteration 5270 : model1 loss : 0.024830 model2 loss : 0.029074
[21:22:54.375] iteration 5271 : model1 loss : 0.031389 model2 loss : 0.027546
[21:22:55.057] iteration 5272 : model1 loss : 0.033124 model2 loss : 0.032280
[21:22:55.743] iteration 5273 : model1 loss : 0.024341 model2 loss : 0.029056
[21:22:56.429] iteration 5274 : model1 loss : 0.018452 model2 loss : 0.022872
[21:22:57.110] iteration 5275 : model1 loss : 0.036507 model2 loss : 0.026833
[21:22:57.794] iteration 5276 : model1 loss : 0.031598 model2 loss : 0.030330
[21:22:58.477] iteration 5277 : model1 loss : 0.028716 model2 loss : 0.028031
[21:22:59.154] iteration 5278 : model1 loss : 0.061218 model2 loss : 0.065237
[21:22:59.834] iteration 5279 : model1 loss : 0.029343 model2 loss : 0.027822
[21:23:00.530] iteration 5280 : model1 loss : 0.034100 model2 loss : 0.033073
[21:23:01.216] iteration 5281 : model1 loss : 0.034442 model2 loss : 0.036667
[21:23:01.897] iteration 5282 : model1 loss : 0.028390 model2 loss : 0.025257
[21:23:02.594] iteration 5283 : model1 loss : 0.067858 model2 loss : 0.058469
[21:23:03.292] iteration 5284 : model1 loss : 0.034782 model2 loss : 0.027799
[21:23:03.965] iteration 5285 : model1 loss : 0.035279 model2 loss : 0.037055
[21:23:04.653] iteration 5286 : model1 loss : 0.034062 model2 loss : 0.026284
[21:23:05.335] iteration 5287 : model1 loss : 0.053280 model2 loss : 0.045661
[21:23:06.010] iteration 5288 : model1 loss : 0.022875 model2 loss : 0.023627
[21:23:06.686] iteration 5289 : model1 loss : 0.030198 model2 loss : 0.032624
[21:23:07.368] iteration 5290 : model1 loss : 0.021424 model2 loss : 0.023338
[21:23:08.046] iteration 5291 : model1 loss : 0.033851 model2 loss : 0.030096
[21:23:08.734] iteration 5292 : model1 loss : 0.031516 model2 loss : 0.035298
[21:23:09.409] iteration 5293 : model1 loss : 0.103873 model2 loss : 0.074037
[21:23:10.087] iteration 5294 : model1 loss : 0.052069 model2 loss : 0.058206
[21:23:10.768] iteration 5295 : model1 loss : 0.022063 model2 loss : 0.021167
[21:23:11.441] iteration 5296 : model1 loss : 0.027100 model2 loss : 0.029482
[21:23:12.111] iteration 5297 : model1 loss : 0.024533 model2 loss : 0.026863
[21:23:12.801] iteration 5298 : model1 loss : 0.033878 model2 loss : 0.034489
[21:23:13.480] iteration 5299 : model1 loss : 0.022701 model2 loss : 0.022485
[21:23:14.160] iteration 5300 : model1 loss : 0.031651 model2 loss : 0.031225
[21:23:14.874] iteration 5301 : model1 loss : 0.026170 model2 loss : 0.022671
[21:23:15.555] iteration 5302 : model1 loss : 0.024633 model2 loss : 0.024058
[21:23:16.244] iteration 5303 : model1 loss : 0.057752 model2 loss : 0.086319
[21:23:16.928] iteration 5304 : model1 loss : 0.040445 model2 loss : 0.042285
[21:23:17.601] iteration 5305 : model1 loss : 0.020915 model2 loss : 0.020847
[21:23:18.280] iteration 5306 : model1 loss : 0.023818 model2 loss : 0.030407
[21:23:18.958] iteration 5307 : model1 loss : 0.023830 model2 loss : 0.024233
[21:23:19.644] iteration 5308 : model1 loss : 0.032678 model2 loss : 0.035339
[21:23:20.323] iteration 5309 : model1 loss : 0.037113 model2 loss : 0.034054
[21:23:21.004] iteration 5310 : model1 loss : 0.032439 model2 loss : 0.027507
[21:23:21.690] iteration 5311 : model1 loss : 0.036696 model2 loss : 0.036037
[21:23:22.370] iteration 5312 : model1 loss : 0.057555 model2 loss : 0.062704
[21:23:23.060] iteration 5313 : model1 loss : 0.030111 model2 loss : 0.030422
[21:23:23.740] iteration 5314 : model1 loss : 0.025729 model2 loss : 0.025685
[21:23:24.428] iteration 5315 : model1 loss : 0.032015 model2 loss : 0.035687
[21:23:25.117] iteration 5316 : model1 loss : 0.047163 model2 loss : 0.032062
[21:23:25.805] iteration 5317 : model1 loss : 0.026467 model2 loss : 0.032890
[21:23:26.480] iteration 5318 : model1 loss : 0.026018 model2 loss : 0.026307
[21:23:27.161] iteration 5319 : model1 loss : 0.027257 model2 loss : 0.028753
[21:23:27.842] iteration 5320 : model1 loss : 0.036229 model2 loss : 0.029315
[21:23:28.541] iteration 5321 : model1 loss : 0.034524 model2 loss : 0.027946
[21:23:29.218] iteration 5322 : model1 loss : 0.034407 model2 loss : 0.033021
[21:23:29.896] iteration 5323 : model1 loss : 0.025035 model2 loss : 0.029017
[21:23:30.585] iteration 5324 : model1 loss : 0.100046 model2 loss : 0.082433
[21:23:31.270] iteration 5325 : model1 loss : 0.026807 model2 loss : 0.034199
[21:23:31.945] iteration 5326 : model1 loss : 0.030515 model2 loss : 0.032808
[21:23:32.650] iteration 5327 : model1 loss : 0.025011 model2 loss : 0.028494
[21:23:33.329] iteration 5328 : model1 loss : 0.029497 model2 loss : 0.021049
[21:23:34.012] iteration 5329 : model1 loss : 0.050726 model2 loss : 0.035327
[21:23:34.693] iteration 5330 : model1 loss : 0.054501 model2 loss : 0.032706
[21:23:35.408] iteration 5331 : model1 loss : 0.026043 model2 loss : 0.022397
[21:23:36.100] iteration 5332 : model1 loss : 0.047564 model2 loss : 0.047999
[21:23:36.786] iteration 5333 : model1 loss : 0.046509 model2 loss : 0.034958
[21:23:37.463] iteration 5334 : model1 loss : 0.030049 model2 loss : 0.033056
[21:23:38.132] iteration 5335 : model1 loss : 0.032322 model2 loss : 0.039122
[21:23:38.817] iteration 5336 : model1 loss : 0.037474 model2 loss : 0.051071
[21:23:39.494] iteration 5337 : model1 loss : 0.022512 model2 loss : 0.021633
[21:23:40.191] iteration 5338 : model1 loss : 0.022169 model2 loss : 0.021315
[21:23:40.892] iteration 5339 : model1 loss : 0.027110 model2 loss : 0.028139
[21:23:41.585] iteration 5340 : model1 loss : 0.032804 model2 loss : 0.027297
[21:23:42.257] iteration 5341 : model1 loss : 0.027658 model2 loss : 0.029873
[21:23:42.945] iteration 5342 : model1 loss : 0.027364 model2 loss : 0.032913
[21:23:43.633] iteration 5343 : model1 loss : 0.021377 model2 loss : 0.053616
[21:23:44.327] iteration 5344 : model1 loss : 0.049525 model2 loss : 0.047743
[21:23:45.016] iteration 5345 : model1 loss : 0.028284 model2 loss : 0.029170
[21:23:45.703] iteration 5346 : model1 loss : 0.032675 model2 loss : 0.029643
[21:23:46.378] iteration 5347 : model1 loss : 0.024218 model2 loss : 0.025690
[21:23:47.064] iteration 5348 : model1 loss : 0.053944 model2 loss : 0.032375
[21:23:47.734] iteration 5349 : model1 loss : 0.030424 model2 loss : 0.027520
[21:23:48.415] iteration 5350 : model1 loss : 0.059790 model2 loss : 0.041937
[21:23:49.130] iteration 5351 : model1 loss : 0.026699 model2 loss : 0.027012
[21:23:49.811] iteration 5352 : model1 loss : 0.033649 model2 loss : 0.034669
[21:23:50.504] iteration 5353 : model1 loss : 0.029241 model2 loss : 0.027800
[21:23:51.177] iteration 5354 : model1 loss : 0.038878 model2 loss : 0.037830
[21:23:51.849] iteration 5355 : model1 loss : 0.028446 model2 loss : 0.027847
[21:23:52.544] iteration 5356 : model1 loss : 0.082925 model2 loss : 0.086090
[21:23:53.219] iteration 5357 : model1 loss : 0.024337 model2 loss : 0.025298
[21:23:53.900] iteration 5358 : model1 loss : 0.034294 model2 loss : 0.037377
[21:23:54.582] iteration 5359 : model1 loss : 0.038855 model2 loss : 0.039311
[21:23:55.261] iteration 5360 : model1 loss : 0.056494 model2 loss : 0.050736
[21:23:55.946] iteration 5361 : model1 loss : 0.023220 model2 loss : 0.021296
[21:23:56.631] iteration 5362 : model1 loss : 0.046651 model2 loss : 0.026305
[21:23:57.313] iteration 5363 : model1 loss : 0.032802 model2 loss : 0.031525
[21:23:57.982] iteration 5364 : model1 loss : 0.031600 model2 loss : 0.030288
[21:23:58.655] iteration 5365 : model1 loss : 0.028429 model2 loss : 0.027617
[21:23:59.338] iteration 5366 : model1 loss : 0.037168 model2 loss : 0.035153
[21:24:00.014] iteration 5367 : model1 loss : 0.031692 model2 loss : 0.031418
[21:24:00.701] iteration 5368 : model1 loss : 0.024017 model2 loss : 0.022686
[21:24:01.396] iteration 5369 : model1 loss : 0.027746 model2 loss : 0.027661
[21:24:02.076] iteration 5370 : model1 loss : 0.038449 model2 loss : 0.042398
[21:24:02.768] iteration 5371 : model1 loss : 0.023494 model2 loss : 0.021780
[21:24:03.457] iteration 5372 : model1 loss : 0.038392 model2 loss : 0.033267
[21:24:04.137] iteration 5373 : model1 loss : 0.027700 model2 loss : 0.027795
[21:24:04.815] iteration 5374 : model1 loss : 0.031043 model2 loss : 0.038748
[21:24:05.507] iteration 5375 : model1 loss : 0.028480 model2 loss : 0.030849
[21:24:06.193] iteration 5376 : model1 loss : 0.058451 model2 loss : 0.043141
[21:24:06.877] iteration 5377 : model1 loss : 0.033356 model2 loss : 0.036184
[21:24:07.542] iteration 5378 : model1 loss : 0.023275 model2 loss : 0.020999
[21:24:08.234] iteration 5379 : model1 loss : 0.036278 model2 loss : 0.029592
[21:24:08.913] iteration 5380 : model1 loss : 0.146014 model2 loss : 0.144750
[21:24:09.600] iteration 5381 : model1 loss : 0.031364 model2 loss : 0.034307
[21:24:10.289] iteration 5382 : model1 loss : 0.026666 model2 loss : 0.026317
[21:24:10.973] iteration 5383 : model1 loss : 0.038587 model2 loss : 0.052347
[21:24:11.644] iteration 5384 : model1 loss : 0.038150 model2 loss : 0.041982
[21:24:12.327] iteration 5385 : model1 loss : 0.065431 model2 loss : 0.039181
[21:24:13.005] iteration 5386 : model1 loss : 0.024950 model2 loss : 0.022201
[21:24:13.678] iteration 5387 : model1 loss : 0.046691 model2 loss : 0.059894
[21:24:14.360] iteration 5388 : model1 loss : 0.026115 model2 loss : 0.028358
[21:24:15.032] iteration 5389 : model1 loss : 0.029734 model2 loss : 0.032577
[21:24:15.712] iteration 5390 : model1 loss : 0.029776 model2 loss : 0.028078
[21:24:16.399] iteration 5391 : model1 loss : 0.021094 model2 loss : 0.032374
[21:24:17.080] iteration 5392 : model1 loss : 0.028502 model2 loss : 0.028216
[21:24:17.756] iteration 5393 : model1 loss : 0.020574 model2 loss : 0.023916
[21:24:18.436] iteration 5394 : model1 loss : 0.031198 model2 loss : 0.027112
[21:24:19.112] iteration 5395 : model1 loss : 0.044515 model2 loss : 0.032832
[21:24:19.781] iteration 5396 : model1 loss : 0.024975 model2 loss : 0.029664
[21:24:20.462] iteration 5397 : model1 loss : 0.045485 model2 loss : 0.032100
[21:24:21.147] iteration 5398 : model1 loss : 0.033019 model2 loss : 0.029922
[21:24:21.829] iteration 5399 : model1 loss : 0.032138 model2 loss : 0.031583
[21:24:22.515] iteration 5400 : model1 loss : 0.081311 model2 loss : 0.060532
[21:24:41.388] iteration 5400 : model1_mean_dice : 0.829398 model1_mean_hd95 : 8.181897
[21:25:00.038] iteration 5400 : model2_mean_dice : 0.837761 model2_mean_hd95 : 4.563769
[21:25:00.707] iteration 5401 : model1 loss : 0.046251 model2 loss : 0.031100
[21:25:01.373] iteration 5402 : model1 loss : 0.027046 model2 loss : 0.033776
[21:25:02.020] iteration 5403 : model1 loss : 0.021075 model2 loss : 0.021887
[21:25:02.673] iteration 5404 : model1 loss : 0.034767 model2 loss : 0.045191
[21:25:03.331] iteration 5405 : model1 loss : 0.036365 model2 loss : 0.032353
[21:25:03.983] iteration 5406 : model1 loss : 0.031259 model2 loss : 0.026729
[21:25:04.651] iteration 5407 : model1 loss : 0.049514 model2 loss : 0.037430
[21:25:05.298] iteration 5408 : model1 loss : 0.028466 model2 loss : 0.028226
[21:25:05.936] iteration 5409 : model1 loss : 0.068756 model2 loss : 0.118443
[21:25:06.599] iteration 5410 : model1 loss : 0.130253 model2 loss : 0.045091
[21:25:07.254] iteration 5411 : model1 loss : 0.025772 model2 loss : 0.022347
[21:25:07.905] iteration 5412 : model1 loss : 0.042950 model2 loss : 0.042608
[21:25:08.555] iteration 5413 : model1 loss : 0.023270 model2 loss : 0.024979
[21:25:09.207] iteration 5414 : model1 loss : 0.021776 model2 loss : 0.025220
[21:25:09.853] iteration 5415 : model1 loss : 0.020524 model2 loss : 0.020608
[21:25:10.507] iteration 5416 : model1 loss : 0.027722 model2 loss : 0.029828
[21:25:11.161] iteration 5417 : model1 loss : 0.023584 model2 loss : 0.024820
[21:25:11.818] iteration 5418 : model1 loss : 0.074388 model2 loss : 0.059722
[21:25:12.486] iteration 5419 : model1 loss : 0.029058 model2 loss : 0.030491
[21:25:13.143] iteration 5420 : model1 loss : 0.030094 model2 loss : 0.028583
[21:25:13.796] iteration 5421 : model1 loss : 0.048756 model2 loss : 0.043735
[21:25:14.455] iteration 5422 : model1 loss : 0.060165 model2 loss : 0.043837
[21:25:15.102] iteration 5423 : model1 loss : 0.034324 model2 loss : 0.050654
[21:25:15.754] iteration 5424 : model1 loss : 0.033377 model2 loss : 0.044702
[21:25:16.414] iteration 5425 : model1 loss : 0.067903 model2 loss : 0.059701
[21:25:17.073] iteration 5426 : model1 loss : 0.030611 model2 loss : 0.026402
[21:25:17.730] iteration 5427 : model1 loss : 0.028990 model2 loss : 0.031970
[21:25:18.381] iteration 5428 : model1 loss : 0.046671 model2 loss : 0.041261
[21:25:19.034] iteration 5429 : model1 loss : 0.016594 model2 loss : 0.022469
[21:25:19.710] iteration 5430 : model1 loss : 0.037923 model2 loss : 0.036306
[21:25:20.359] iteration 5431 : model1 loss : 0.033484 model2 loss : 0.032109
[21:25:21.013] iteration 5432 : model1 loss : 0.028676 model2 loss : 0.028823
[21:25:21.670] iteration 5433 : model1 loss : 0.026327 model2 loss : 0.026715
[21:25:22.334] iteration 5434 : model1 loss : 0.026372 model2 loss : 0.027745
[21:25:22.997] iteration 5435 : model1 loss : 0.030698 model2 loss : 0.035630
[21:25:23.647] iteration 5436 : model1 loss : 0.029140 model2 loss : 0.026956
[21:25:24.304] iteration 5437 : model1 loss : 0.041228 model2 loss : 0.031287
[21:25:24.980] iteration 5438 : model1 loss : 0.054929 model2 loss : 0.047976
[21:25:25.629] iteration 5439 : model1 loss : 0.033445 model2 loss : 0.040250
[21:25:26.293] iteration 5440 : model1 loss : 0.025886 model2 loss : 0.023102
[21:25:26.953] iteration 5441 : model1 loss : 0.024004 model2 loss : 0.020486
[21:25:27.604] iteration 5442 : model1 loss : 0.023643 model2 loss : 0.022962
[21:25:28.263] iteration 5443 : model1 loss : 0.036219 model2 loss : 0.035792
[21:25:28.924] iteration 5444 : model1 loss : 0.054712 model2 loss : 0.032058
[21:25:29.579] iteration 5445 : model1 loss : 0.146345 model2 loss : 0.068482
[21:25:30.224] iteration 5446 : model1 loss : 0.042175 model2 loss : 0.032652
[21:25:30.879] iteration 5447 : model1 loss : 0.031871 model2 loss : 0.027389
[21:25:31.536] iteration 5448 : model1 loss : 0.025552 model2 loss : 0.027075
[21:25:32.195] iteration 5449 : model1 loss : 0.028308 model2 loss : 0.030307
[21:25:32.850] iteration 5450 : model1 loss : 0.027111 model2 loss : 0.028947
[21:25:33.555] iteration 5451 : model1 loss : 0.033916 model2 loss : 0.026470
[21:25:34.213] iteration 5452 : model1 loss : 0.043975 model2 loss : 0.033682
[21:25:34.871] iteration 5453 : model1 loss : 0.025407 model2 loss : 0.023691
[21:25:35.538] iteration 5454 : model1 loss : 0.172983 model2 loss : 0.194116
[21:25:36.224] iteration 5455 : model1 loss : 0.029194 model2 loss : 0.028343
[21:25:36.888] iteration 5456 : model1 loss : 0.035365 model2 loss : 0.058241
[21:25:37.554] iteration 5457 : model1 loss : 0.033107 model2 loss : 0.033876
[21:25:38.211] iteration 5458 : model1 loss : 0.054394 model2 loss : 0.040434
[21:25:38.873] iteration 5459 : model1 loss : 0.035619 model2 loss : 0.040715
[21:25:39.529] iteration 5460 : model1 loss : 0.028284 model2 loss : 0.024833
[21:25:40.195] iteration 5461 : model1 loss : 0.023307 model2 loss : 0.024462
[21:25:40.878] iteration 5462 : model1 loss : 0.030479 model2 loss : 0.024045
[21:25:41.540] iteration 5463 : model1 loss : 0.032903 model2 loss : 0.034923
[21:25:42.195] iteration 5464 : model1 loss : 0.030297 model2 loss : 0.027966
[21:25:42.861] iteration 5465 : model1 loss : 0.023257 model2 loss : 0.025641
[21:25:43.534] iteration 5466 : model1 loss : 0.027593 model2 loss : 0.028649
[21:25:44.208] iteration 5467 : model1 loss : 0.034836 model2 loss : 0.034119
[21:25:44.863] iteration 5468 : model1 loss : 0.045027 model2 loss : 0.051095
[21:25:45.516] iteration 5469 : model1 loss : 0.033861 model2 loss : 0.039719
[21:25:46.165] iteration 5470 : model1 loss : 0.041003 model2 loss : 0.045475
[21:25:46.825] iteration 5471 : model1 loss : 0.050190 model2 loss : 0.045724
[21:25:47.482] iteration 5472 : model1 loss : 0.024813 model2 loss : 0.028317
[21:25:48.146] iteration 5473 : model1 loss : 0.022126 model2 loss : 0.021790
[21:25:48.811] iteration 5474 : model1 loss : 0.028042 model2 loss : 0.028360
[21:25:49.468] iteration 5475 : model1 loss : 0.024204 model2 loss : 0.024378
[21:25:50.119] iteration 5476 : model1 loss : 0.036547 model2 loss : 0.031936
[21:25:50.774] iteration 5477 : model1 loss : 0.027277 model2 loss : 0.027089
[21:25:51.439] iteration 5478 : model1 loss : 0.026648 model2 loss : 0.023471
[21:25:52.091] iteration 5479 : model1 loss : 0.034961 model2 loss : 0.025442
[21:25:52.746] iteration 5480 : model1 loss : 0.028739 model2 loss : 0.032493
[21:25:53.425] iteration 5481 : model1 loss : 0.023065 model2 loss : 0.024081
[21:25:54.082] iteration 5482 : model1 loss : 0.033869 model2 loss : 0.032487
[21:25:54.757] iteration 5483 : model1 loss : 0.030265 model2 loss : 0.031377
[21:25:55.424] iteration 5484 : model1 loss : 0.142980 model2 loss : 0.178180
[21:25:56.083] iteration 5485 : model1 loss : 0.028848 model2 loss : 0.031816
[21:25:56.744] iteration 5486 : model1 loss : 0.035184 model2 loss : 0.044101
[21:25:57.398] iteration 5487 : model1 loss : 0.046843 model2 loss : 0.043313
[21:25:58.056] iteration 5488 : model1 loss : 0.041907 model2 loss : 0.051427
[21:25:58.713] iteration 5489 : model1 loss : 0.034048 model2 loss : 0.023660
[21:25:59.366] iteration 5490 : model1 loss : 0.038686 model2 loss : 0.042825
[21:26:00.024] iteration 5491 : model1 loss : 0.038488 model2 loss : 0.065258
[21:26:00.669] iteration 5492 : model1 loss : 0.022151 model2 loss : 0.025056
[21:26:01.342] iteration 5493 : model1 loss : 0.026361 model2 loss : 0.026301
[21:26:01.991] iteration 5494 : model1 loss : 0.026863 model2 loss : 0.024827
[21:26:02.661] iteration 5495 : model1 loss : 0.042256 model2 loss : 0.036618
[21:26:03.332] iteration 5496 : model1 loss : 0.028992 model2 loss : 0.024192
[21:26:03.984] iteration 5497 : model1 loss : 0.033923 model2 loss : 0.037258
[21:26:04.636] iteration 5498 : model1 loss : 0.029184 model2 loss : 0.029871
[21:26:05.295] iteration 5499 : model1 loss : 0.025261 model2 loss : 0.025514
[21:26:05.968] iteration 5500 : model1 loss : 0.026356 model2 loss : 0.032274
[21:26:06.678] iteration 5501 : model1 loss : 0.154207 model2 loss : 0.154033
[21:26:07.342] iteration 5502 : model1 loss : 0.024153 model2 loss : 0.025884
[21:26:08.009] iteration 5503 : model1 loss : 0.032717 model2 loss : 0.029198
[21:26:08.671] iteration 5504 : model1 loss : 0.033315 model2 loss : 0.028127
[21:26:09.329] iteration 5505 : model1 loss : 0.025997 model2 loss : 0.025448
[21:26:09.976] iteration 5506 : model1 loss : 0.047149 model2 loss : 0.046183
[21:26:10.631] iteration 5507 : model1 loss : 0.031469 model2 loss : 0.036162
[21:26:11.295] iteration 5508 : model1 loss : 0.026751 model2 loss : 0.026712
[21:26:11.953] iteration 5509 : model1 loss : 0.018044 model2 loss : 0.021234
[21:26:12.624] iteration 5510 : model1 loss : 0.022751 model2 loss : 0.032968
[21:26:13.275] iteration 5511 : model1 loss : 0.132106 model2 loss : 0.148176
[21:26:13.937] iteration 5512 : model1 loss : 0.023997 model2 loss : 0.021073
[21:26:14.612] iteration 5513 : model1 loss : 0.048616 model2 loss : 0.045681
[21:26:15.274] iteration 5514 : model1 loss : 0.043217 model2 loss : 0.035749
[21:26:15.934] iteration 5515 : model1 loss : 0.033093 model2 loss : 0.030655
[21:26:16.590] iteration 5516 : model1 loss : 0.054146 model2 loss : 0.066144
[21:26:17.261] iteration 5517 : model1 loss : 0.034964 model2 loss : 0.034940
[21:26:17.925] iteration 5518 : model1 loss : 0.054606 model2 loss : 0.034935
[21:26:18.603] iteration 5519 : model1 loss : 0.025268 model2 loss : 0.026047
[21:26:19.253] iteration 5520 : model1 loss : 0.035320 model2 loss : 0.033616
[21:26:19.911] iteration 5521 : model1 loss : 0.027098 model2 loss : 0.028283
[21:26:20.579] iteration 5522 : model1 loss : 0.031664 model2 loss : 0.028101
[21:26:21.243] iteration 5523 : model1 loss : 0.033090 model2 loss : 0.027991
[21:26:21.889] iteration 5524 : model1 loss : 0.070807 model2 loss : 0.060851
[21:26:22.553] iteration 5525 : model1 loss : 0.042854 model2 loss : 0.043571
[21:26:23.201] iteration 5526 : model1 loss : 0.028702 model2 loss : 0.033851
[21:26:23.860] iteration 5527 : model1 loss : 0.108037 model2 loss : 0.113713
[21:26:24.524] iteration 5528 : model1 loss : 0.034663 model2 loss : 0.034916
[21:26:25.187] iteration 5529 : model1 loss : 0.022692 model2 loss : 0.023176
[21:26:25.843] iteration 5530 : model1 loss : 0.035539 model2 loss : 0.047158
[21:26:26.505] iteration 5531 : model1 loss : 0.041360 model2 loss : 0.039451
[21:26:27.164] iteration 5532 : model1 loss : 0.035045 model2 loss : 0.031348
[21:26:27.824] iteration 5533 : model1 loss : 0.026451 model2 loss : 0.033099
[21:26:28.492] iteration 5534 : model1 loss : 0.036586 model2 loss : 0.040283
[21:26:29.150] iteration 5535 : model1 loss : 0.034338 model2 loss : 0.025954
[21:26:29.807] iteration 5536 : model1 loss : 0.029168 model2 loss : 0.026742
[21:26:30.472] iteration 5537 : model1 loss : 0.032270 model2 loss : 0.028335
[21:26:31.134] iteration 5538 : model1 loss : 0.042047 model2 loss : 0.042434
[21:26:31.794] iteration 5539 : model1 loss : 0.027875 model2 loss : 0.028577
[21:26:32.456] iteration 5540 : model1 loss : 0.031041 model2 loss : 0.031133
[21:26:33.119] iteration 5541 : model1 loss : 0.092511 model2 loss : 0.113220
[21:26:33.767] iteration 5542 : model1 loss : 0.156665 model2 loss : 0.156421
[21:26:34.431] iteration 5543 : model1 loss : 0.024309 model2 loss : 0.029002
[21:26:35.088] iteration 5544 : model1 loss : 0.051836 model2 loss : 0.034930
[21:26:35.754] iteration 5545 : model1 loss : 0.033370 model2 loss : 0.030867
[21:26:36.436] iteration 5546 : model1 loss : 0.043873 model2 loss : 0.045404
[21:26:37.102] iteration 5547 : model1 loss : 0.043033 model2 loss : 0.037503
[21:26:37.764] iteration 5548 : model1 loss : 0.030641 model2 loss : 0.032257
[21:26:38.416] iteration 5549 : model1 loss : 0.026324 model2 loss : 0.024418
[21:26:39.071] iteration 5550 : model1 loss : 0.027455 model2 loss : 0.028083
[21:26:39.784] iteration 5551 : model1 loss : 0.034263 model2 loss : 0.029833
[21:26:40.463] iteration 5552 : model1 loss : 0.034049 model2 loss : 0.033932
[21:26:41.129] iteration 5553 : model1 loss : 0.023051 model2 loss : 0.021477
[21:26:41.793] iteration 5554 : model1 loss : 0.028204 model2 loss : 0.030531
[21:26:42.445] iteration 5555 : model1 loss : 0.020446 model2 loss : 0.022920
[21:26:43.101] iteration 5556 : model1 loss : 0.045561 model2 loss : 0.030142
[21:26:43.751] iteration 5557 : model1 loss : 0.033582 model2 loss : 0.032034
[21:26:44.403] iteration 5558 : model1 loss : 0.027611 model2 loss : 0.027496
[21:26:45.072] iteration 5559 : model1 loss : 0.099194 model2 loss : 0.062547
[21:26:45.727] iteration 5560 : model1 loss : 0.043595 model2 loss : 0.048200
[21:26:46.384] iteration 5561 : model1 loss : 0.035310 model2 loss : 0.039739
[21:26:47.033] iteration 5562 : model1 loss : 0.027695 model2 loss : 0.027679
[21:26:47.698] iteration 5563 : model1 loss : 0.025463 model2 loss : 0.028840
[21:26:48.364] iteration 5564 : model1 loss : 0.031844 model2 loss : 0.028239
[21:26:49.021] iteration 5565 : model1 loss : 0.034031 model2 loss : 0.036097
[21:26:49.694] iteration 5566 : model1 loss : 0.028965 model2 loss : 0.026816
[21:26:50.364] iteration 5567 : model1 loss : 0.052036 model2 loss : 0.040013
[21:26:51.020] iteration 5568 : model1 loss : 0.029139 model2 loss : 0.021851
[21:26:51.674] iteration 5569 : model1 loss : 0.033736 model2 loss : 0.027588
[21:26:52.332] iteration 5570 : model1 loss : 0.052442 model2 loss : 0.036916
[21:26:53.002] iteration 5571 : model1 loss : 0.055144 model2 loss : 0.068362
[21:26:53.669] iteration 5572 : model1 loss : 0.026711 model2 loss : 0.031731
[21:26:54.322] iteration 5573 : model1 loss : 0.029994 model2 loss : 0.030771
[21:26:54.975] iteration 5574 : model1 loss : 0.048310 model2 loss : 0.041028
[21:26:55.635] iteration 5575 : model1 loss : 0.036373 model2 loss : 0.035103
[21:26:56.316] iteration 5576 : model1 loss : 0.034002 model2 loss : 0.031730
[21:26:56.983] iteration 5577 : model1 loss : 0.058839 model2 loss : 0.076883
[21:26:57.637] iteration 5578 : model1 loss : 0.035719 model2 loss : 0.029473
[21:26:58.303] iteration 5579 : model1 loss : 0.088731 model2 loss : 0.053102
[21:26:58.954] iteration 5580 : model1 loss : 0.027833 model2 loss : 0.024929
[21:26:59.616] iteration 5581 : model1 loss : 0.039554 model2 loss : 0.030198
[21:27:00.266] iteration 5582 : model1 loss : 0.038689 model2 loss : 0.035215
[21:27:00.923] iteration 5583 : model1 loss : 0.029271 model2 loss : 0.034936
[21:27:01.590] iteration 5584 : model1 loss : 0.026469 model2 loss : 0.024036
[21:27:02.253] iteration 5585 : model1 loss : 0.028735 model2 loss : 0.031262
[21:27:02.911] iteration 5586 : model1 loss : 0.032923 model2 loss : 0.036271
[21:27:03.570] iteration 5587 : model1 loss : 0.044850 model2 loss : 0.056854
[21:27:04.223] iteration 5588 : model1 loss : 0.033037 model2 loss : 0.035046
[21:27:04.878] iteration 5589 : model1 loss : 0.025423 model2 loss : 0.025675
[21:27:05.539] iteration 5590 : model1 loss : 0.028306 model2 loss : 0.029925
[21:27:06.197] iteration 5591 : model1 loss : 0.027534 model2 loss : 0.028003
[21:27:06.847] iteration 5592 : model1 loss : 0.039610 model2 loss : 0.037111
[21:27:07.518] iteration 5593 : model1 loss : 0.028952 model2 loss : 0.029085
[21:27:08.170] iteration 5594 : model1 loss : 0.027746 model2 loss : 0.024555
[21:27:08.825] iteration 5595 : model1 loss : 0.036960 model2 loss : 0.031345
[21:27:09.496] iteration 5596 : model1 loss : 0.024635 model2 loss : 0.021668
[21:27:10.158] iteration 5597 : model1 loss : 0.034468 model2 loss : 0.032166
[21:27:10.814] iteration 5598 : model1 loss : 0.026568 model2 loss : 0.028400
[21:27:11.482] iteration 5599 : model1 loss : 0.029627 model2 loss : 0.027256
[21:27:12.134] iteration 5600 : model1 loss : 0.037503 model2 loss : 0.047369
[21:27:29.806] iteration 5600 : model1_mean_dice : 0.833748 model1_mean_hd95 : 9.764612
[21:27:47.704] iteration 5600 : model2_mean_dice : 0.834933 model2_mean_hd95 : 9.062726
[21:27:48.375] iteration 5601 : model1 loss : 0.028240 model2 loss : 0.026555
[21:27:49.021] iteration 5602 : model1 loss : 0.049710 model2 loss : 0.038532
[21:27:49.668] iteration 5603 : model1 loss : 0.044217 model2 loss : 0.049270
[21:27:50.324] iteration 5604 : model1 loss : 0.025352 model2 loss : 0.025766
[21:27:50.992] iteration 5605 : model1 loss : 0.032513 model2 loss : 0.028238
[21:27:51.638] iteration 5606 : model1 loss : 0.030467 model2 loss : 0.026364
[21:27:52.306] iteration 5607 : model1 loss : 0.027788 model2 loss : 0.030923
[21:27:52.959] iteration 5608 : model1 loss : 0.025646 model2 loss : 0.023999
[21:27:53.628] iteration 5609 : model1 loss : 0.022754 model2 loss : 0.024387
[21:27:54.275] iteration 5610 : model1 loss : 0.042869 model2 loss : 0.049602
[21:27:54.927] iteration 5611 : model1 loss : 0.031617 model2 loss : 0.033210
[21:27:55.600] iteration 5612 : model1 loss : 0.022784 model2 loss : 0.022254
[21:27:56.243] iteration 5613 : model1 loss : 0.026487 model2 loss : 0.027387
[21:27:56.899] iteration 5614 : model1 loss : 0.048474 model2 loss : 0.040965
[21:27:57.572] iteration 5615 : model1 loss : 0.028942 model2 loss : 0.028444
[21:27:58.225] iteration 5616 : model1 loss : 0.036625 model2 loss : 0.071270
[21:27:58.883] iteration 5617 : model1 loss : 0.030125 model2 loss : 0.034754
[21:27:59.535] iteration 5618 : model1 loss : 0.030951 model2 loss : 0.030927
[21:28:00.180] iteration 5619 : model1 loss : 0.037811 model2 loss : 0.030050
[21:28:00.831] iteration 5620 : model1 loss : 0.020707 model2 loss : 0.023022
[21:28:01.485] iteration 5621 : model1 loss : 0.056181 model2 loss : 0.058892
[21:28:02.138] iteration 5622 : model1 loss : 0.027294 model2 loss : 0.053496
[21:28:02.787] iteration 5623 : model1 loss : 0.027099 model2 loss : 0.029601
[21:28:03.440] iteration 5624 : model1 loss : 0.033894 model2 loss : 0.031221
[21:28:04.091] iteration 5625 : model1 loss : 0.035998 model2 loss : 0.036746
[21:28:04.746] iteration 5626 : model1 loss : 0.036236 model2 loss : 0.043357
[21:28:05.411] iteration 5627 : model1 loss : 0.029608 model2 loss : 0.025836
[21:28:06.069] iteration 5628 : model1 loss : 0.033831 model2 loss : 0.037701
[21:28:06.723] iteration 5629 : model1 loss : 0.035485 model2 loss : 0.034949
[21:28:07.386] iteration 5630 : model1 loss : 0.029819 model2 loss : 0.021323
[21:28:08.035] iteration 5631 : model1 loss : 0.031227 model2 loss : 0.028377
[21:28:08.691] iteration 5632 : model1 loss : 0.028886 model2 loss : 0.025521
[21:28:09.342] iteration 5633 : model1 loss : 0.025487 model2 loss : 0.023284
[21:28:10.005] iteration 5634 : model1 loss : 0.025855 model2 loss : 0.026159
[21:28:10.664] iteration 5635 : model1 loss : 0.021822 model2 loss : 0.020639
[21:28:11.322] iteration 5636 : model1 loss : 0.035842 model2 loss : 0.036648
[21:28:11.976] iteration 5637 : model1 loss : 0.030749 model2 loss : 0.032417
[21:28:12.648] iteration 5638 : model1 loss : 0.036636 model2 loss : 0.037752
[21:28:13.315] iteration 5639 : model1 loss : 0.041936 model2 loss : 0.057789
[21:28:13.967] iteration 5640 : model1 loss : 0.021664 model2 loss : 0.027069
[21:28:14.631] iteration 5641 : model1 loss : 0.052860 model2 loss : 0.044471
[21:28:15.283] iteration 5642 : model1 loss : 0.041484 model2 loss : 0.037947
[21:28:15.931] iteration 5643 : model1 loss : 0.035923 model2 loss : 0.045468
[21:28:16.575] iteration 5644 : model1 loss : 0.028614 model2 loss : 0.027445
[21:28:17.243] iteration 5645 : model1 loss : 0.029620 model2 loss : 0.029496
[21:28:17.908] iteration 5646 : model1 loss : 0.027747 model2 loss : 0.029290
[21:28:18.578] iteration 5647 : model1 loss : 0.037722 model2 loss : 0.034463
[21:28:19.236] iteration 5648 : model1 loss : 0.076066 model2 loss : 0.096745
[21:28:19.894] iteration 5649 : model1 loss : 0.035681 model2 loss : 0.032784
[21:28:20.557] iteration 5650 : model1 loss : 0.037066 model2 loss : 0.035717
[21:28:21.259] iteration 5651 : model1 loss : 0.028291 model2 loss : 0.029769
[21:28:21.912] iteration 5652 : model1 loss : 0.033543 model2 loss : 0.030443
[21:28:22.584] iteration 5653 : model1 loss : 0.027948 model2 loss : 0.024721
[21:28:23.241] iteration 5654 : model1 loss : 0.027460 model2 loss : 0.027360
[21:28:23.902] iteration 5655 : model1 loss : 0.025890 model2 loss : 0.027696
[21:28:24.554] iteration 5656 : model1 loss : 0.028252 model2 loss : 0.029446
[21:28:25.227] iteration 5657 : model1 loss : 0.040989 model2 loss : 0.033170
[21:28:25.884] iteration 5658 : model1 loss : 0.017767 model2 loss : 0.021232
[21:28:26.540] iteration 5659 : model1 loss : 0.035112 model2 loss : 0.051117
[21:28:27.206] iteration 5660 : model1 loss : 0.032560 model2 loss : 0.049912
[21:28:27.876] iteration 5661 : model1 loss : 0.022069 model2 loss : 0.020776
[21:28:28.536] iteration 5662 : model1 loss : 0.032836 model2 loss : 0.028332
[21:28:29.200] iteration 5663 : model1 loss : 0.024155 model2 loss : 0.022530
[21:28:29.854] iteration 5664 : model1 loss : 0.025772 model2 loss : 0.026801
[21:28:30.527] iteration 5665 : model1 loss : 0.024014 model2 loss : 0.023783
[21:28:31.189] iteration 5666 : model1 loss : 0.019688 model2 loss : 0.019758
[21:28:31.854] iteration 5667 : model1 loss : 0.033431 model2 loss : 0.028679
[21:28:32.518] iteration 5668 : model1 loss : 0.126366 model2 loss : 0.102873
[21:28:33.185] iteration 5669 : model1 loss : 0.024412 model2 loss : 0.026871
[21:28:33.836] iteration 5670 : model1 loss : 0.027556 model2 loss : 0.033606
[21:28:34.488] iteration 5671 : model1 loss : 0.026509 model2 loss : 0.025562
[21:28:35.152] iteration 5672 : model1 loss : 0.025293 model2 loss : 0.023898
[21:28:35.807] iteration 5673 : model1 loss : 0.044557 model2 loss : 0.044066
[21:28:36.467] iteration 5674 : model1 loss : 0.030379 model2 loss : 0.033485
[21:28:37.130] iteration 5675 : model1 loss : 0.034905 model2 loss : 0.041662
[21:28:37.803] iteration 5676 : model1 loss : 0.044537 model2 loss : 0.033476
[21:28:38.464] iteration 5677 : model1 loss : 0.026192 model2 loss : 0.025360
[21:28:39.133] iteration 5678 : model1 loss : 0.027379 model2 loss : 0.026265
[21:28:39.793] iteration 5679 : model1 loss : 0.039580 model2 loss : 0.043983
[21:28:40.453] iteration 5680 : model1 loss : 0.044875 model2 loss : 0.034358
[21:28:41.122] iteration 5681 : model1 loss : 0.024164 model2 loss : 0.024131
[21:28:41.796] iteration 5682 : model1 loss : 0.025812 model2 loss : 0.026620
[21:28:42.447] iteration 5683 : model1 loss : 0.051074 model2 loss : 0.051239
[21:28:43.098] iteration 5684 : model1 loss : 0.026093 model2 loss : 0.026235
[21:28:43.769] iteration 5685 : model1 loss : 0.034298 model2 loss : 0.030847
[21:28:44.428] iteration 5686 : model1 loss : 0.023666 model2 loss : 0.027406
[21:28:45.094] iteration 5687 : model1 loss : 0.068859 model2 loss : 0.054701
[21:28:45.762] iteration 5688 : model1 loss : 0.021834 model2 loss : 0.021058
[21:28:46.418] iteration 5689 : model1 loss : 0.028305 model2 loss : 0.025063
[21:28:47.069] iteration 5690 : model1 loss : 0.023952 model2 loss : 0.026958
[21:28:47.732] iteration 5691 : model1 loss : 0.046993 model2 loss : 0.041280
[21:28:48.398] iteration 5692 : model1 loss : 0.039579 model2 loss : 0.043707
[21:28:49.056] iteration 5693 : model1 loss : 0.026701 model2 loss : 0.029091
[21:28:49.711] iteration 5694 : model1 loss : 0.032925 model2 loss : 0.028155
[21:28:50.371] iteration 5695 : model1 loss : 0.029941 model2 loss : 0.030721
[21:28:51.035] iteration 5696 : model1 loss : 0.059125 model2 loss : 0.026736
[21:28:51.694] iteration 5697 : model1 loss : 0.029553 model2 loss : 0.036791
[21:28:52.365] iteration 5698 : model1 loss : 0.023510 model2 loss : 0.019669
[21:28:53.019] iteration 5699 : model1 loss : 0.025507 model2 loss : 0.024995
[21:28:53.704] iteration 5700 : model1 loss : 0.021620 model2 loss : 0.023594
[21:28:54.407] iteration 5701 : model1 loss : 0.026638 model2 loss : 0.024151
[21:28:55.080] iteration 5702 : model1 loss : 0.025950 model2 loss : 0.026971
[21:28:55.752] iteration 5703 : model1 loss : 0.040148 model2 loss : 0.047400
[21:28:56.433] iteration 5704 : model1 loss : 0.027299 model2 loss : 0.026560
[21:28:57.099] iteration 5705 : model1 loss : 0.021487 model2 loss : 0.019935
[21:28:57.764] iteration 5706 : model1 loss : 0.032494 model2 loss : 0.036007
[21:28:58.424] iteration 5707 : model1 loss : 0.024952 model2 loss : 0.021911
[21:28:59.083] iteration 5708 : model1 loss : 0.028552 model2 loss : 0.028366
[21:28:59.744] iteration 5709 : model1 loss : 0.036622 model2 loss : 0.039183
[21:29:00.397] iteration 5710 : model1 loss : 0.034557 model2 loss : 0.039359
[21:29:01.062] iteration 5711 : model1 loss : 0.021102 model2 loss : 0.021374
[21:29:01.727] iteration 5712 : model1 loss : 0.021962 model2 loss : 0.021795
[21:29:02.392] iteration 5713 : model1 loss : 0.034310 model2 loss : 0.038021
[21:29:03.053] iteration 5714 : model1 loss : 0.032481 model2 loss : 0.032636
[21:29:03.703] iteration 5715 : model1 loss : 0.025446 model2 loss : 0.024505
[21:29:04.384] iteration 5716 : model1 loss : 0.039331 model2 loss : 0.045499
[21:29:05.077] iteration 5717 : model1 loss : 0.027688 model2 loss : 0.024557
[21:29:05.759] iteration 5718 : model1 loss : 0.037106 model2 loss : 0.032514
[21:29:06.465] iteration 5719 : model1 loss : 0.024257 model2 loss : 0.026390
[21:29:07.146] iteration 5720 : model1 loss : 0.022071 model2 loss : 0.025788
[21:29:07.815] iteration 5721 : model1 loss : 0.040663 model2 loss : 0.041037
[21:29:08.487] iteration 5722 : model1 loss : 0.031853 model2 loss : 0.031190
[21:29:09.150] iteration 5723 : model1 loss : 0.032300 model2 loss : 0.027189
[21:29:09.806] iteration 5724 : model1 loss : 0.023196 model2 loss : 0.025108
[21:29:10.472] iteration 5725 : model1 loss : 0.085904 model2 loss : 0.075171
[21:29:11.148] iteration 5726 : model1 loss : 0.039311 model2 loss : 0.029365
[21:29:11.827] iteration 5727 : model1 loss : 0.035916 model2 loss : 0.030480
[21:29:12.512] iteration 5728 : model1 loss : 0.044092 model2 loss : 0.041921
[21:29:13.163] iteration 5729 : model1 loss : 0.020157 model2 loss : 0.023661
[21:29:13.829] iteration 5730 : model1 loss : 0.032466 model2 loss : 0.037592
[21:29:14.487] iteration 5731 : model1 loss : 0.039064 model2 loss : 0.039796
[21:29:15.150] iteration 5732 : model1 loss : 0.026821 model2 loss : 0.027442
[21:29:15.820] iteration 5733 : model1 loss : 0.122099 model2 loss : 0.098400
[21:29:16.508] iteration 5734 : model1 loss : 0.024060 model2 loss : 0.036659
[21:29:17.157] iteration 5735 : model1 loss : 0.091287 model2 loss : 0.051455
[21:29:17.820] iteration 5736 : model1 loss : 0.024069 model2 loss : 0.023104
[21:29:18.508] iteration 5737 : model1 loss : 0.032004 model2 loss : 0.026042
[21:29:19.195] iteration 5738 : model1 loss : 0.024106 model2 loss : 0.026815
[21:29:19.886] iteration 5739 : model1 loss : 0.062418 model2 loss : 0.065163
[21:29:20.557] iteration 5740 : model1 loss : 0.019465 model2 loss : 0.020263
[21:29:21.204] iteration 5741 : model1 loss : 0.020817 model2 loss : 0.023276
[21:29:21.872] iteration 5742 : model1 loss : 0.079663 model2 loss : 0.053445
[21:29:22.542] iteration 5743 : model1 loss : 0.029585 model2 loss : 0.029475
[21:29:23.220] iteration 5744 : model1 loss : 0.032380 model2 loss : 0.031667
[21:29:23.873] iteration 5745 : model1 loss : 0.026645 model2 loss : 0.028037
[21:29:24.533] iteration 5746 : model1 loss : 0.042878 model2 loss : 0.045691
[21:29:25.203] iteration 5747 : model1 loss : 0.031319 model2 loss : 0.035161
[21:29:25.871] iteration 5748 : model1 loss : 0.037518 model2 loss : 0.036317
[21:29:26.543] iteration 5749 : model1 loss : 0.020235 model2 loss : 0.020085
[21:29:27.209] iteration 5750 : model1 loss : 0.030752 model2 loss : 0.035583
[21:29:27.930] iteration 5751 : model1 loss : 0.037884 model2 loss : 0.034544
[21:29:28.599] iteration 5752 : model1 loss : 0.157711 model2 loss : 0.151366
[21:29:29.269] iteration 5753 : model1 loss : 0.028710 model2 loss : 0.027556
[21:29:29.933] iteration 5754 : model1 loss : 0.027396 model2 loss : 0.029249
[21:29:30.593] iteration 5755 : model1 loss : 0.023702 model2 loss : 0.025027
[21:29:31.244] iteration 5756 : model1 loss : 0.034945 model2 loss : 0.023027
[21:29:31.917] iteration 5757 : model1 loss : 0.023896 model2 loss : 0.024518
[21:29:32.582] iteration 5758 : model1 loss : 0.050143 model2 loss : 0.042476
[21:29:33.251] iteration 5759 : model1 loss : 0.030191 model2 loss : 0.030876
[21:29:33.911] iteration 5760 : model1 loss : 0.026342 model2 loss : 0.025469
[21:29:34.559] iteration 5761 : model1 loss : 0.028024 model2 loss : 0.025216
[21:29:35.243] iteration 5762 : model1 loss : 0.025488 model2 loss : 0.025326
[21:29:35.902] iteration 5763 : model1 loss : 0.046228 model2 loss : 0.042756
[21:29:36.585] iteration 5764 : model1 loss : 0.025867 model2 loss : 0.025224
[21:29:37.240] iteration 5765 : model1 loss : 0.023686 model2 loss : 0.024480
[21:29:37.925] iteration 5766 : model1 loss : 0.039717 model2 loss : 0.028468
[21:29:38.607] iteration 5767 : model1 loss : 0.030516 model2 loss : 0.023986
[21:29:39.265] iteration 5768 : model1 loss : 0.023678 model2 loss : 0.024805
[21:29:39.924] iteration 5769 : model1 loss : 0.025566 model2 loss : 0.023309
[21:29:40.584] iteration 5770 : model1 loss : 0.029564 model2 loss : 0.034643
[21:29:41.238] iteration 5771 : model1 loss : 0.031678 model2 loss : 0.031315
[21:29:41.899] iteration 5772 : model1 loss : 0.028106 model2 loss : 0.019016
[21:29:42.565] iteration 5773 : model1 loss : 0.040473 model2 loss : 0.047931
[21:29:43.227] iteration 5774 : model1 loss : 0.022130 model2 loss : 0.023106
[21:29:43.899] iteration 5775 : model1 loss : 0.028858 model2 loss : 0.026260
[21:29:44.551] iteration 5776 : model1 loss : 0.027072 model2 loss : 0.026504
[21:29:45.217] iteration 5777 : model1 loss : 0.027823 model2 loss : 0.025147
[21:29:45.860] iteration 5778 : model1 loss : 0.036322 model2 loss : 0.039356
[21:29:46.522] iteration 5779 : model1 loss : 0.019447 model2 loss : 0.018772
[21:29:47.204] iteration 5780 : model1 loss : 0.036211 model2 loss : 0.038939
[21:29:47.861] iteration 5781 : model1 loss : 0.028772 model2 loss : 0.028667
[21:29:48.541] iteration 5782 : model1 loss : 0.034660 model2 loss : 0.032595
[21:29:49.201] iteration 5783 : model1 loss : 0.050926 model2 loss : 0.052849
[21:29:49.863] iteration 5784 : model1 loss : 0.025061 model2 loss : 0.023024
[21:29:50.528] iteration 5785 : model1 loss : 0.021465 model2 loss : 0.021895
[21:29:51.193] iteration 5786 : model1 loss : 0.026971 model2 loss : 0.022811
[21:29:51.850] iteration 5787 : model1 loss : 0.034529 model2 loss : 0.032223
[21:29:52.501] iteration 5788 : model1 loss : 0.048282 model2 loss : 0.045122
[21:29:53.157] iteration 5789 : model1 loss : 0.034592 model2 loss : 0.032231
[21:29:53.824] iteration 5790 : model1 loss : 0.064972 model2 loss : 0.080404
[21:29:54.479] iteration 5791 : model1 loss : 0.033261 model2 loss : 0.031782
[21:29:55.144] iteration 5792 : model1 loss : 0.022695 model2 loss : 0.019800
[21:29:55.818] iteration 5793 : model1 loss : 0.022768 model2 loss : 0.024997
[21:29:56.478] iteration 5794 : model1 loss : 0.034771 model2 loss : 0.032386
[21:29:57.138] iteration 5795 : model1 loss : 0.036468 model2 loss : 0.039832
[21:29:57.791] iteration 5796 : model1 loss : 0.025424 model2 loss : 0.030270
[21:29:58.459] iteration 5797 : model1 loss : 0.029483 model2 loss : 0.032899
[21:29:59.118] iteration 5798 : model1 loss : 0.065743 model2 loss : 0.053988
[21:29:59.783] iteration 5799 : model1 loss : 0.022924 model2 loss : 0.020031
[21:30:00.456] iteration 5800 : model1 loss : 0.038335 model2 loss : 0.040721
[21:30:18.459] iteration 5800 : model1_mean_dice : 0.849962 model1_mean_hd95 : 6.045328
[21:30:36.187] iteration 5800 : model2_mean_dice : 0.839634 model2_mean_hd95 : 5.877290
[21:30:36.858] iteration 5801 : model1 loss : 0.027394 model2 loss : 0.026311
[21:30:37.515] iteration 5802 : model1 loss : 0.022275 model2 loss : 0.025495
[21:30:38.163] iteration 5803 : model1 loss : 0.031021 model2 loss : 0.032646
[21:30:38.847] iteration 5804 : model1 loss : 0.036577 model2 loss : 0.030498
[21:30:39.504] iteration 5805 : model1 loss : 0.026431 model2 loss : 0.026680
[21:30:40.149] iteration 5806 : model1 loss : 0.026749 model2 loss : 0.031925
[21:30:40.796] iteration 5807 : model1 loss : 0.025258 model2 loss : 0.026776
[21:30:41.460] iteration 5808 : model1 loss : 0.038228 model2 loss : 0.027949
[21:30:42.117] iteration 5809 : model1 loss : 0.025085 model2 loss : 0.027894
[21:30:42.777] iteration 5810 : model1 loss : 0.023872 model2 loss : 0.026158
[21:30:43.426] iteration 5811 : model1 loss : 0.026104 model2 loss : 0.034501
[21:30:44.087] iteration 5812 : model1 loss : 0.029197 model2 loss : 0.031056
[21:30:44.746] iteration 5813 : model1 loss : 0.023804 model2 loss : 0.021138
[21:30:45.397] iteration 5814 : model1 loss : 0.020721 model2 loss : 0.024924
[21:30:46.038] iteration 5815 : model1 loss : 0.031678 model2 loss : 0.028897
[21:30:46.696] iteration 5816 : model1 loss : 0.022436 model2 loss : 0.022931
[21:30:47.369] iteration 5817 : model1 loss : 0.035270 model2 loss : 0.029110
[21:30:48.030] iteration 5818 : model1 loss : 0.022773 model2 loss : 0.024402
[21:30:48.692] iteration 5819 : model1 loss : 0.022139 model2 loss : 0.025615
[21:30:49.370] iteration 5820 : model1 loss : 0.023604 model2 loss : 0.024294
[21:30:50.012] iteration 5821 : model1 loss : 0.043840 model2 loss : 0.028827
[21:30:50.661] iteration 5822 : model1 loss : 0.028821 model2 loss : 0.026155
[21:30:51.330] iteration 5823 : model1 loss : 0.029030 model2 loss : 0.032979
[21:30:51.975] iteration 5824 : model1 loss : 0.024595 model2 loss : 0.047203
[21:30:52.623] iteration 5825 : model1 loss : 0.024705 model2 loss : 0.024874
[21:30:53.295] iteration 5826 : model1 loss : 0.020850 model2 loss : 0.022759
[21:30:53.945] iteration 5827 : model1 loss : 0.022707 model2 loss : 0.027027
[21:30:54.610] iteration 5828 : model1 loss : 0.022561 model2 loss : 0.027021
[21:30:55.269] iteration 5829 : model1 loss : 0.045427 model2 loss : 0.032454
[21:30:55.912] iteration 5830 : model1 loss : 0.019045 model2 loss : 0.022378
[21:30:56.573] iteration 5831 : model1 loss : 0.098369 model2 loss : 0.102629
[21:30:57.232] iteration 5832 : model1 loss : 0.065755 model2 loss : 0.058715
[21:30:57.895] iteration 5833 : model1 loss : 0.022637 model2 loss : 0.024979
[21:30:58.550] iteration 5834 : model1 loss : 0.026855 model2 loss : 0.025235
[21:30:59.218] iteration 5835 : model1 loss : 0.024427 model2 loss : 0.028687
[21:30:59.872] iteration 5836 : model1 loss : 0.068360 model2 loss : 0.044193
[21:31:00.535] iteration 5837 : model1 loss : 0.026192 model2 loss : 0.022834
[21:31:01.188] iteration 5838 : model1 loss : 0.053506 model2 loss : 0.040105
[21:31:01.848] iteration 5839 : model1 loss : 0.026568 model2 loss : 0.025556
[21:31:02.515] iteration 5840 : model1 loss : 0.024288 model2 loss : 0.025960
[21:31:03.163] iteration 5841 : model1 loss : 0.030327 model2 loss : 0.023081
[21:31:03.808] iteration 5842 : model1 loss : 0.025537 model2 loss : 0.024484
[21:31:04.470] iteration 5843 : model1 loss : 0.068074 model2 loss : 0.042178
[21:31:05.123] iteration 5844 : model1 loss : 0.031178 model2 loss : 0.031036
[21:31:05.772] iteration 5845 : model1 loss : 0.029058 model2 loss : 0.031718
[21:31:06.452] iteration 5846 : model1 loss : 0.025023 model2 loss : 0.028446
[21:31:07.133] iteration 5847 : model1 loss : 0.042684 model2 loss : 0.045689
[21:31:07.805] iteration 5848 : model1 loss : 0.018195 model2 loss : 0.019628
[21:31:08.476] iteration 5849 : model1 loss : 0.070811 model2 loss : 0.043579
[21:31:09.152] iteration 5850 : model1 loss : 0.026306 model2 loss : 0.040263
[21:31:09.868] iteration 5851 : model1 loss : 0.105217 model2 loss : 0.098906
[21:31:10.517] iteration 5852 : model1 loss : 0.035804 model2 loss : 0.037947
[21:31:11.193] iteration 5853 : model1 loss : 0.040834 model2 loss : 0.053366
[21:31:11.857] iteration 5854 : model1 loss : 0.029230 model2 loss : 0.029941
[21:31:12.534] iteration 5855 : model1 loss : 0.028620 model2 loss : 0.031299
[21:31:13.191] iteration 5856 : model1 loss : 0.058825 model2 loss : 0.050803
[21:31:13.847] iteration 5857 : model1 loss : 0.024944 model2 loss : 0.024153
[21:31:14.541] iteration 5858 : model1 loss : 0.025972 model2 loss : 0.027015
[21:31:15.204] iteration 5859 : model1 loss : 0.020704 model2 loss : 0.021100
[21:31:15.877] iteration 5860 : model1 loss : 0.029332 model2 loss : 0.027861
[21:31:16.570] iteration 5861 : model1 loss : 0.081564 model2 loss : 0.075817
[21:31:17.236] iteration 5862 : model1 loss : 0.046252 model2 loss : 0.036769
[21:31:17.924] iteration 5863 : model1 loss : 0.040511 model2 loss : 0.045982
[21:31:18.651] iteration 5864 : model1 loss : 0.081342 model2 loss : 0.063311
[21:31:19.360] iteration 5865 : model1 loss : 0.084211 model2 loss : 0.126454
[21:31:20.050] iteration 5866 : model1 loss : 0.028425 model2 loss : 0.026172
[21:31:20.711] iteration 5867 : model1 loss : 0.024477 model2 loss : 0.028000
[21:31:21.367] iteration 5868 : model1 loss : 0.061284 model2 loss : 0.062008
[21:31:22.033] iteration 5869 : model1 loss : 0.027433 model2 loss : 0.029294
[21:31:22.696] iteration 5870 : model1 loss : 0.037424 model2 loss : 0.047146
[21:31:23.369] iteration 5871 : model1 loss : 0.030655 model2 loss : 0.031904
[21:31:24.018] iteration 5872 : model1 loss : 0.036726 model2 loss : 0.041887
[21:31:24.684] iteration 5873 : model1 loss : 0.032159 model2 loss : 0.043688
[21:31:25.336] iteration 5874 : model1 loss : 0.033454 model2 loss : 0.024341
[21:31:25.987] iteration 5875 : model1 loss : 0.052923 model2 loss : 0.042538
[21:31:26.644] iteration 5876 : model1 loss : 0.021892 model2 loss : 0.022649
[21:31:27.299] iteration 5877 : model1 loss : 0.045685 model2 loss : 0.044342
[21:31:27.960] iteration 5878 : model1 loss : 0.149913 model2 loss : 0.156571
[21:31:28.628] iteration 5879 : model1 loss : 0.031051 model2 loss : 0.033517
[21:31:29.285] iteration 5880 : model1 loss : 0.026128 model2 loss : 0.029307
[21:31:29.948] iteration 5881 : model1 loss : 0.028072 model2 loss : 0.051949
[21:31:30.599] iteration 5882 : model1 loss : 0.029622 model2 loss : 0.027304
[21:31:31.254] iteration 5883 : model1 loss : 0.030537 model2 loss : 0.032130
[21:31:31.915] iteration 5884 : model1 loss : 0.043824 model2 loss : 0.040337
[21:31:32.582] iteration 5885 : model1 loss : 0.027683 model2 loss : 0.026884
[21:31:33.247] iteration 5886 : model1 loss : 0.030680 model2 loss : 0.031210
[21:31:33.903] iteration 5887 : model1 loss : 0.028219 model2 loss : 0.025653
[21:31:34.560] iteration 5888 : model1 loss : 0.027124 model2 loss : 0.090421
[21:31:35.210] iteration 5889 : model1 loss : 0.065082 model2 loss : 0.047546
[21:31:35.867] iteration 5890 : model1 loss : 0.026730 model2 loss : 0.028213
[21:31:36.530] iteration 5891 : model1 loss : 0.026695 model2 loss : 0.029344
[21:31:37.199] iteration 5892 : model1 loss : 0.026866 model2 loss : 0.033496
[21:31:37.860] iteration 5893 : model1 loss : 0.022518 model2 loss : 0.025344
[21:31:38.526] iteration 5894 : model1 loss : 0.027276 model2 loss : 0.024062
[21:31:39.208] iteration 5895 : model1 loss : 0.029788 model2 loss : 0.030636
[21:31:39.880] iteration 5896 : model1 loss : 0.022368 model2 loss : 0.022816
[21:31:40.535] iteration 5897 : model1 loss : 0.029686 model2 loss : 0.033860
[21:31:41.196] iteration 5898 : model1 loss : 0.020385 model2 loss : 0.028428
[21:31:41.863] iteration 5899 : model1 loss : 0.032280 model2 loss : 0.032434
[21:31:42.534] iteration 5900 : model1 loss : 0.028366 model2 loss : 0.029857
[21:31:43.229] iteration 5901 : model1 loss : 0.029203 model2 loss : 0.035700
[21:31:43.894] iteration 5902 : model1 loss : 0.032699 model2 loss : 0.034868
[21:31:44.556] iteration 5903 : model1 loss : 0.023587 model2 loss : 0.027376
[21:31:45.230] iteration 5904 : model1 loss : 0.022701 model2 loss : 0.027925
[21:31:45.895] iteration 5905 : model1 loss : 0.025457 model2 loss : 0.023925
[21:31:46.546] iteration 5906 : model1 loss : 0.037801 model2 loss : 0.066298
[21:31:47.210] iteration 5907 : model1 loss : 0.031156 model2 loss : 0.045754
[21:31:47.867] iteration 5908 : model1 loss : 0.043139 model2 loss : 0.119486
[21:31:48.537] iteration 5909 : model1 loss : 0.021789 model2 loss : 0.021601
[21:31:49.193] iteration 5910 : model1 loss : 0.034074 model2 loss : 0.033991
[21:31:49.866] iteration 5911 : model1 loss : 0.036066 model2 loss : 0.030165
[21:31:50.532] iteration 5912 : model1 loss : 0.024805 model2 loss : 0.025356
[21:31:51.198] iteration 5913 : model1 loss : 0.048520 model2 loss : 0.050023
[21:31:51.849] iteration 5914 : model1 loss : 0.025405 model2 loss : 0.027144
[21:31:52.520] iteration 5915 : model1 loss : 0.038829 model2 loss : 0.035602
[21:31:53.176] iteration 5916 : model1 loss : 0.027573 model2 loss : 0.027106
[21:31:53.833] iteration 5917 : model1 loss : 0.101585 model2 loss : 0.128223
[21:31:54.494] iteration 5918 : model1 loss : 0.027498 model2 loss : 0.036202
[21:31:55.156] iteration 5919 : model1 loss : 0.030673 model2 loss : 0.035952
[21:31:55.809] iteration 5920 : model1 loss : 0.026205 model2 loss : 0.032466
[21:31:56.476] iteration 5921 : model1 loss : 0.026856 model2 loss : 0.030937
[21:31:57.133] iteration 5922 : model1 loss : 0.039475 model2 loss : 0.051744
[21:31:57.778] iteration 5923 : model1 loss : 0.028998 model2 loss : 0.031047
[21:31:58.441] iteration 5924 : model1 loss : 0.024954 model2 loss : 0.050434
[21:31:59.094] iteration 5925 : model1 loss : 0.025744 model2 loss : 0.028723
[21:31:59.743] iteration 5926 : model1 loss : 0.027326 model2 loss : 0.033826
[21:32:00.397] iteration 5927 : model1 loss : 0.022144 model2 loss : 0.025433
[21:32:01.055] iteration 5928 : model1 loss : 0.032256 model2 loss : 0.028557
[21:32:01.717] iteration 5929 : model1 loss : 0.025673 model2 loss : 0.028885
[21:32:02.373] iteration 5930 : model1 loss : 0.025985 model2 loss : 0.025976
[21:32:03.040] iteration 5931 : model1 loss : 0.038157 model2 loss : 0.030356
[21:32:03.706] iteration 5932 : model1 loss : 0.027846 model2 loss : 0.025429
[21:32:04.369] iteration 5933 : model1 loss : 0.042528 model2 loss : 0.040798
[21:32:05.035] iteration 5934 : model1 loss : 0.028456 model2 loss : 0.038901
[21:32:05.694] iteration 5935 : model1 loss : 0.155424 model2 loss : 0.172262
[21:32:06.353] iteration 5936 : model1 loss : 0.027686 model2 loss : 0.026655
[21:32:07.015] iteration 5937 : model1 loss : 0.045785 model2 loss : 0.033392
[21:32:07.676] iteration 5938 : model1 loss : 0.039577 model2 loss : 0.057898
[21:32:08.346] iteration 5939 : model1 loss : 0.026439 model2 loss : 0.028074
[21:32:09.009] iteration 5940 : model1 loss : 0.023016 model2 loss : 0.029020
[21:32:09.674] iteration 5941 : model1 loss : 0.056427 model2 loss : 0.043802
[21:32:10.346] iteration 5942 : model1 loss : 0.030650 model2 loss : 0.033920
[21:32:11.015] iteration 5943 : model1 loss : 0.046452 model2 loss : 0.043733
[21:32:11.679] iteration 5944 : model1 loss : 0.036664 model2 loss : 0.033423
[21:32:12.331] iteration 5945 : model1 loss : 0.021636 model2 loss : 0.022880
[21:32:12.983] iteration 5946 : model1 loss : 0.032822 model2 loss : 0.028469
[21:32:13.643] iteration 5947 : model1 loss : 0.030482 model2 loss : 0.035111
[21:32:14.309] iteration 5948 : model1 loss : 0.030604 model2 loss : 0.026696
[21:32:14.974] iteration 5949 : model1 loss : 0.026436 model2 loss : 0.027412
[21:32:15.632] iteration 5950 : model1 loss : 0.021279 model2 loss : 0.020968
[21:32:16.326] iteration 5951 : model1 loss : 0.025561 model2 loss : 0.029170
[21:32:16.982] iteration 5952 : model1 loss : 0.033984 model2 loss : 0.038302
[21:32:17.636] iteration 5953 : model1 loss : 0.022062 model2 loss : 0.027362
[21:32:18.301] iteration 5954 : model1 loss : 0.022499 model2 loss : 0.026064
[21:32:18.965] iteration 5955 : model1 loss : 0.035547 model2 loss : 0.032049
[21:32:19.620] iteration 5956 : model1 loss : 0.041474 model2 loss : 0.065151
[21:32:20.278] iteration 5957 : model1 loss : 0.027729 model2 loss : 0.026474
[21:32:20.938] iteration 5958 : model1 loss : 0.023820 model2 loss : 0.023594
[21:32:21.599] iteration 5959 : model1 loss : 0.024493 model2 loss : 0.024561
[21:32:22.262] iteration 5960 : model1 loss : 0.041405 model2 loss : 0.043035
[21:32:22.932] iteration 5961 : model1 loss : 0.030202 model2 loss : 0.031014
[21:32:23.598] iteration 5962 : model1 loss : 0.021037 model2 loss : 0.025239
[21:32:24.265] iteration 5963 : model1 loss : 0.031730 model2 loss : 0.033126
[21:32:24.927] iteration 5964 : model1 loss : 0.039962 model2 loss : 0.041753
[21:32:25.583] iteration 5965 : model1 loss : 0.035078 model2 loss : 0.031450
[21:32:26.256] iteration 5966 : model1 loss : 0.031099 model2 loss : 0.026679
[21:32:26.924] iteration 5967 : model1 loss : 0.029455 model2 loss : 0.025114
[21:32:27.579] iteration 5968 : model1 loss : 0.053294 model2 loss : 0.042724
[21:32:28.242] iteration 5969 : model1 loss : 0.025823 model2 loss : 0.026196
[21:32:28.900] iteration 5970 : model1 loss : 0.033790 model2 loss : 0.032603
[21:32:29.553] iteration 5971 : model1 loss : 0.022890 model2 loss : 0.025546
[21:32:30.224] iteration 5972 : model1 loss : 0.025942 model2 loss : 0.026659
[21:32:30.884] iteration 5973 : model1 loss : 0.031879 model2 loss : 0.030879
[21:32:31.550] iteration 5974 : model1 loss : 0.027643 model2 loss : 0.029937
[21:32:32.218] iteration 5975 : model1 loss : 0.027123 model2 loss : 0.027778
[21:32:32.867] iteration 5976 : model1 loss : 0.034777 model2 loss : 0.041254
[21:32:33.533] iteration 5977 : model1 loss : 0.058827 model2 loss : 0.052196
[21:32:34.196] iteration 5978 : model1 loss : 0.026745 model2 loss : 0.024707
[21:32:34.858] iteration 5979 : model1 loss : 0.034896 model2 loss : 0.032113
[21:32:35.512] iteration 5980 : model1 loss : 0.041702 model2 loss : 0.034655
[21:32:36.169] iteration 5981 : model1 loss : 0.033681 model2 loss : 0.034984
[21:32:36.820] iteration 5982 : model1 loss : 0.024760 model2 loss : 0.026993
[21:32:37.478] iteration 5983 : model1 loss : 0.086945 model2 loss : 0.049111
[21:32:38.138] iteration 5984 : model1 loss : 0.034968 model2 loss : 0.033928
[21:32:38.795] iteration 5985 : model1 loss : 0.025963 model2 loss : 0.021943
[21:32:39.480] iteration 5986 : model1 loss : 0.027422 model2 loss : 0.037608
[21:32:40.150] iteration 5987 : model1 loss : 0.024091 model2 loss : 0.023255
[21:32:40.812] iteration 5988 : model1 loss : 0.053056 model2 loss : 0.072805
[21:32:41.468] iteration 5989 : model1 loss : 0.042076 model2 loss : 0.031629
[21:32:42.132] iteration 5990 : model1 loss : 0.025058 model2 loss : 0.023878
[21:32:42.800] iteration 5991 : model1 loss : 0.028534 model2 loss : 0.032100
[21:32:43.455] iteration 5992 : model1 loss : 0.045162 model2 loss : 0.039802
[21:32:44.120] iteration 5993 : model1 loss : 0.022656 model2 loss : 0.019666
[21:32:44.781] iteration 5994 : model1 loss : 0.059899 model2 loss : 0.079744
[21:32:45.445] iteration 5995 : model1 loss : 0.030064 model2 loss : 0.029156
[21:32:46.100] iteration 5996 : model1 loss : 0.063492 model2 loss : 0.079971
[21:32:46.764] iteration 5997 : model1 loss : 0.022791 model2 loss : 0.025316
[21:32:47.413] iteration 5998 : model1 loss : 0.035454 model2 loss : 0.028267
[21:32:48.085] iteration 5999 : model1 loss : 0.082222 model2 loss : 0.081083
[21:32:48.755] iteration 6000 : model1 loss : 0.053911 model2 loss : 0.038441
[21:33:06.718] iteration 6000 : model1_mean_dice : 0.813829 model1_mean_hd95 : 8.594141
[21:33:24.440] iteration 6000 : model2_mean_dice : 0.832310 model2_mean_hd95 : 4.449514
[21:33:24.502] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_6000.pth
[21:33:24.559] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_6000.pth
[21:33:25.240] iteration 6001 : model1 loss : 0.044673 model2 loss : 0.034033
[21:33:25.892] iteration 6002 : model1 loss : 0.091750 model2 loss : 0.104255
[21:33:26.553] iteration 6003 : model1 loss : 0.030247 model2 loss : 0.033805
[21:33:27.204] iteration 6004 : model1 loss : 0.027546 model2 loss : 0.028540
[21:33:27.852] iteration 6005 : model1 loss : 0.049611 model2 loss : 0.025727
[21:33:28.500] iteration 6006 : model1 loss : 0.036373 model2 loss : 0.030851
[21:33:29.162] iteration 6007 : model1 loss : 0.033079 model2 loss : 0.036327
[21:33:29.839] iteration 6008 : model1 loss : 0.023039 model2 loss : 0.029016
[21:33:30.497] iteration 6009 : model1 loss : 0.029782 model2 loss : 0.029241
[21:33:31.148] iteration 6010 : model1 loss : 0.028986 model2 loss : 0.032587
[21:33:31.818] iteration 6011 : model1 loss : 0.034913 model2 loss : 0.028968
[21:33:32.473] iteration 6012 : model1 loss : 0.023580 model2 loss : 0.029019
[21:33:33.146] iteration 6013 : model1 loss : 0.027297 model2 loss : 0.031527
[21:33:33.803] iteration 6014 : model1 loss : 0.032620 model2 loss : 0.027403
[21:33:34.447] iteration 6015 : model1 loss : 0.025364 model2 loss : 0.025602
[21:33:35.103] iteration 6016 : model1 loss : 0.021350 model2 loss : 0.024651
[21:33:35.755] iteration 6017 : model1 loss : 0.023498 model2 loss : 0.026100
[21:33:36.409] iteration 6018 : model1 loss : 0.042437 model2 loss : 0.035338
[21:33:37.069] iteration 6019 : model1 loss : 0.021059 model2 loss : 0.023216
[21:33:37.716] iteration 6020 : model1 loss : 0.061241 model2 loss : 0.080472
[21:33:38.390] iteration 6021 : model1 loss : 0.037049 model2 loss : 0.044415
[21:33:39.040] iteration 6022 : model1 loss : 0.053202 model2 loss : 0.038294
[21:33:39.737] iteration 6023 : model1 loss : 0.073995 model2 loss : 0.102219
[21:33:40.414] iteration 6024 : model1 loss : 0.028945 model2 loss : 0.029684
[21:33:41.063] iteration 6025 : model1 loss : 0.022990 model2 loss : 0.028252
[21:33:41.732] iteration 6026 : model1 loss : 0.033492 model2 loss : 0.029424
[21:33:42.418] iteration 6027 : model1 loss : 0.025491 model2 loss : 0.033867
[21:33:43.067] iteration 6028 : model1 loss : 0.041290 model2 loss : 0.037988
[21:33:43.727] iteration 6029 : model1 loss : 0.025892 model2 loss : 0.027061
[21:33:44.394] iteration 6030 : model1 loss : 0.099038 model2 loss : 0.077651
[21:33:45.047] iteration 6031 : model1 loss : 0.024881 model2 loss : 0.029357
[21:33:45.692] iteration 6032 : model1 loss : 0.033146 model2 loss : 0.035620
[21:33:46.354] iteration 6033 : model1 loss : 0.023765 model2 loss : 0.024370
[21:33:47.017] iteration 6034 : model1 loss : 0.039646 model2 loss : 0.037509
[21:33:47.674] iteration 6035 : model1 loss : 0.080537 model2 loss : 0.102123
[21:33:48.332] iteration 6036 : model1 loss : 0.037024 model2 loss : 0.031621
[21:33:48.990] iteration 6037 : model1 loss : 0.022978 model2 loss : 0.024431
[21:33:49.643] iteration 6038 : model1 loss : 0.032180 model2 loss : 0.023930
[21:33:50.301] iteration 6039 : model1 loss : 0.057022 model2 loss : 0.047393
[21:33:50.952] iteration 6040 : model1 loss : 0.018907 model2 loss : 0.020908
[21:33:51.597] iteration 6041 : model1 loss : 0.021731 model2 loss : 0.024319
[21:33:52.261] iteration 6042 : model1 loss : 0.029265 model2 loss : 0.028845
[21:33:52.925] iteration 6043 : model1 loss : 0.053818 model2 loss : 0.057365
[21:33:53.576] iteration 6044 : model1 loss : 0.048420 model2 loss : 0.051722
[21:33:54.227] iteration 6045 : model1 loss : 0.031825 model2 loss : 0.047485
[21:33:54.878] iteration 6046 : model1 loss : 0.066778 model2 loss : 0.100699
[21:33:55.534] iteration 6047 : model1 loss : 0.033026 model2 loss : 0.043596
[21:33:56.188] iteration 6048 : model1 loss : 0.024851 model2 loss : 0.023354
[21:33:56.835] iteration 6049 : model1 loss : 0.056800 model2 loss : 0.046279
[21:33:57.489] iteration 6050 : model1 loss : 0.042173 model2 loss : 0.040984
[21:33:58.191] iteration 6051 : model1 loss : 0.027697 model2 loss : 0.023413
[21:33:58.838] iteration 6052 : model1 loss : 0.034106 model2 loss : 0.037401
[21:33:59.520] iteration 6053 : model1 loss : 0.027458 model2 loss : 0.028956
[21:34:00.175] iteration 6054 : model1 loss : 0.023644 model2 loss : 0.025988
[21:34:00.832] iteration 6055 : model1 loss : 0.035460 model2 loss : 0.032266
[21:34:01.497] iteration 6056 : model1 loss : 0.024462 model2 loss : 0.026069
[21:34:02.152] iteration 6057 : model1 loss : 0.029479 model2 loss : 0.037874
[21:34:02.828] iteration 6058 : model1 loss : 0.030693 model2 loss : 0.031829
[21:34:03.481] iteration 6059 : model1 loss : 0.023065 model2 loss : 0.025318
[21:34:04.128] iteration 6060 : model1 loss : 0.081545 model2 loss : 0.049529
[21:34:04.800] iteration 6061 : model1 loss : 0.028090 model2 loss : 0.031726
[21:34:05.451] iteration 6062 : model1 loss : 0.031126 model2 loss : 0.031386
[21:34:06.115] iteration 6063 : model1 loss : 0.051651 model2 loss : 0.052009
[21:34:06.792] iteration 6064 : model1 loss : 0.026014 model2 loss : 0.028067
[21:34:07.458] iteration 6065 : model1 loss : 0.040362 model2 loss : 0.047047
[21:34:08.131] iteration 6066 : model1 loss : 0.028054 model2 loss : 0.024417
[21:34:08.794] iteration 6067 : model1 loss : 0.027682 model2 loss : 0.028466
[21:34:09.448] iteration 6068 : model1 loss : 0.022858 model2 loss : 0.023031
[21:34:10.107] iteration 6069 : model1 loss : 0.033261 model2 loss : 0.035082
[21:34:10.761] iteration 6070 : model1 loss : 0.032149 model2 loss : 0.028975
[21:34:11.430] iteration 6071 : model1 loss : 0.049484 model2 loss : 0.080491
[21:34:12.084] iteration 6072 : model1 loss : 0.030878 model2 loss : 0.023895
[21:34:12.738] iteration 6073 : model1 loss : 0.036604 model2 loss : 0.035396
[21:34:13.404] iteration 6074 : model1 loss : 0.026422 model2 loss : 0.026837
[21:34:14.071] iteration 6075 : model1 loss : 0.030448 model2 loss : 0.033280
[21:34:14.733] iteration 6076 : model1 loss : 0.038618 model2 loss : 0.036025
[21:34:15.401] iteration 6077 : model1 loss : 0.031069 model2 loss : 0.036317
[21:34:16.060] iteration 6078 : model1 loss : 0.022749 model2 loss : 0.023780
[21:34:16.713] iteration 6079 : model1 loss : 0.026317 model2 loss : 0.026451
[21:34:17.371] iteration 6080 : model1 loss : 0.038865 model2 loss : 0.067297
[21:34:18.029] iteration 6081 : model1 loss : 0.136652 model2 loss : 0.053693
[21:34:18.692] iteration 6082 : model1 loss : 0.024309 model2 loss : 0.024006
[21:34:19.357] iteration 6083 : model1 loss : 0.025529 model2 loss : 0.025732
[21:34:20.018] iteration 6084 : model1 loss : 0.025985 model2 loss : 0.021512
[21:34:20.687] iteration 6085 : model1 loss : 0.027819 model2 loss : 0.028555
[21:34:21.349] iteration 6086 : model1 loss : 0.035310 model2 loss : 0.043205
[21:34:22.004] iteration 6087 : model1 loss : 0.028929 model2 loss : 0.024264
[21:34:22.674] iteration 6088 : model1 loss : 0.037072 model2 loss : 0.029289
[21:34:23.347] iteration 6089 : model1 loss : 0.037041 model2 loss : 0.038777
[21:34:24.002] iteration 6090 : model1 loss : 0.044589 model2 loss : 0.033188
[21:34:24.665] iteration 6091 : model1 loss : 0.028399 model2 loss : 0.041411
[21:34:25.326] iteration 6092 : model1 loss : 0.051322 model2 loss : 0.068586
[21:34:26.003] iteration 6093 : model1 loss : 0.056812 model2 loss : 0.034450
[21:34:26.666] iteration 6094 : model1 loss : 0.024560 model2 loss : 0.024048
[21:34:27.332] iteration 6095 : model1 loss : 0.029334 model2 loss : 0.028536
[21:34:27.989] iteration 6096 : model1 loss : 0.028059 model2 loss : 0.027184
[21:34:28.654] iteration 6097 : model1 loss : 0.038818 model2 loss : 0.046298
[21:34:29.323] iteration 6098 : model1 loss : 0.033128 model2 loss : 0.046560
[21:34:29.972] iteration 6099 : model1 loss : 0.145681 model2 loss : 0.150191
[21:34:30.616] iteration 6100 : model1 loss : 0.149530 model2 loss : 0.119598
[21:34:31.322] iteration 6101 : model1 loss : 0.027800 model2 loss : 0.031139
[21:34:31.986] iteration 6102 : model1 loss : 0.032064 model2 loss : 0.024934
[21:34:32.650] iteration 6103 : model1 loss : 0.022002 model2 loss : 0.023609
[21:34:33.335] iteration 6104 : model1 loss : 0.032022 model2 loss : 0.038131
[21:34:33.995] iteration 6105 : model1 loss : 0.038294 model2 loss : 0.041251
[21:34:34.649] iteration 6106 : model1 loss : 0.033395 model2 loss : 0.026791
[21:34:35.331] iteration 6107 : model1 loss : 0.037041 model2 loss : 0.042209
[21:34:35.997] iteration 6108 : model1 loss : 0.255577 model2 loss : 0.220373
[21:34:36.660] iteration 6109 : model1 loss : 0.040311 model2 loss : 0.044285
[21:34:37.311] iteration 6110 : model1 loss : 0.025761 model2 loss : 0.028109
[21:34:37.978] iteration 6111 : model1 loss : 0.028795 model2 loss : 0.029428
[21:34:38.647] iteration 6112 : model1 loss : 0.024538 model2 loss : 0.046889
[21:34:39.306] iteration 6113 : model1 loss : 0.040305 model2 loss : 0.053443
[21:34:39.975] iteration 6114 : model1 loss : 0.036881 model2 loss : 0.027563
[21:34:40.649] iteration 6115 : model1 loss : 0.026057 model2 loss : 0.027257
[21:34:41.316] iteration 6116 : model1 loss : 0.028519 model2 loss : 0.025073
[21:34:41.972] iteration 6117 : model1 loss : 0.032363 model2 loss : 0.037853
[21:34:42.646] iteration 6118 : model1 loss : 0.023910 model2 loss : 0.024089
[21:34:43.304] iteration 6119 : model1 loss : 0.026081 model2 loss : 0.023099
[21:34:43.963] iteration 6120 : model1 loss : 0.022478 model2 loss : 0.030961
[21:34:44.619] iteration 6121 : model1 loss : 0.025842 model2 loss : 0.027183
[21:34:45.270] iteration 6122 : model1 loss : 0.031328 model2 loss : 0.032390
[21:34:45.927] iteration 6123 : model1 loss : 0.033470 model2 loss : 0.036457
[21:34:46.577] iteration 6124 : model1 loss : 0.052105 model2 loss : 0.069288
[21:34:47.242] iteration 6125 : model1 loss : 0.027382 model2 loss : 0.028254
[21:34:47.909] iteration 6126 : model1 loss : 0.038384 model2 loss : 0.034565
[21:34:48.586] iteration 6127 : model1 loss : 0.042933 model2 loss : 0.032728
[21:34:49.249] iteration 6128 : model1 loss : 0.031392 model2 loss : 0.029695
[21:34:49.919] iteration 6129 : model1 loss : 0.029013 model2 loss : 0.030616
[21:34:50.574] iteration 6130 : model1 loss : 0.049273 model2 loss : 0.027834
[21:34:51.234] iteration 6131 : model1 loss : 0.057229 model2 loss : 0.059313
[21:34:51.896] iteration 6132 : model1 loss : 0.030233 model2 loss : 0.032540
[21:34:52.571] iteration 6133 : model1 loss : 0.024145 model2 loss : 0.023510
[21:34:53.244] iteration 6134 : model1 loss : 0.028547 model2 loss : 0.027084
[21:34:53.905] iteration 6135 : model1 loss : 0.029722 model2 loss : 0.030060
[21:34:54.559] iteration 6136 : model1 loss : 0.026785 model2 loss : 0.027716
[21:34:55.220] iteration 6137 : model1 loss : 0.029060 model2 loss : 0.040160
[21:34:55.866] iteration 6138 : model1 loss : 0.134310 model2 loss : 0.146744
[21:34:56.534] iteration 6139 : model1 loss : 0.047188 model2 loss : 0.047150
[21:34:57.193] iteration 6140 : model1 loss : 0.017934 model2 loss : 0.019189
[21:34:57.862] iteration 6141 : model1 loss : 0.151870 model2 loss : 0.160286
[21:34:58.525] iteration 6142 : model1 loss : 0.029796 model2 loss : 0.025790
[21:34:59.175] iteration 6143 : model1 loss : 0.033109 model2 loss : 0.025722
[21:34:59.843] iteration 6144 : model1 loss : 0.032900 model2 loss : 0.028984
[21:35:00.501] iteration 6145 : model1 loss : 0.065863 model2 loss : 0.059649
[21:35:01.165] iteration 6146 : model1 loss : 0.020580 model2 loss : 0.020467
[21:35:01.831] iteration 6147 : model1 loss : 0.030343 model2 loss : 0.025295
[21:35:02.490] iteration 6148 : model1 loss : 0.029306 model2 loss : 0.026675
[21:35:03.158] iteration 6149 : model1 loss : 0.033005 model2 loss : 0.026416
[21:35:03.810] iteration 6150 : model1 loss : 0.024239 model2 loss : 0.036203
[21:35:04.520] iteration 6151 : model1 loss : 0.029143 model2 loss : 0.029458
[21:35:05.177] iteration 6152 : model1 loss : 0.029548 model2 loss : 0.031694
[21:35:05.839] iteration 6153 : model1 loss : 0.036316 model2 loss : 0.051445
[21:35:06.493] iteration 6154 : model1 loss : 0.034141 model2 loss : 0.036327
[21:35:07.151] iteration 6155 : model1 loss : 0.025613 model2 loss : 0.023413
[21:35:07.808] iteration 6156 : model1 loss : 0.027669 model2 loss : 0.026098
[21:35:08.474] iteration 6157 : model1 loss : 0.021564 model2 loss : 0.025183
[21:35:09.131] iteration 6158 : model1 loss : 0.033423 model2 loss : 0.041181
[21:35:09.790] iteration 6159 : model1 loss : 0.017889 model2 loss : 0.022227
[21:35:10.457] iteration 6160 : model1 loss : 0.141960 model2 loss : 0.142294
[21:35:11.123] iteration 6161 : model1 loss : 0.034347 model2 loss : 0.036059
[21:35:11.785] iteration 6162 : model1 loss : 0.024487 model2 loss : 0.025483
[21:35:12.438] iteration 6163 : model1 loss : 0.021948 model2 loss : 0.023481
[21:35:13.104] iteration 6164 : model1 loss : 0.032760 model2 loss : 0.032276
[21:35:13.768] iteration 6165 : model1 loss : 0.026084 model2 loss : 0.030743
[21:35:14.420] iteration 6166 : model1 loss : 0.030179 model2 loss : 0.036184
[21:35:15.076] iteration 6167 : model1 loss : 0.038776 model2 loss : 0.039907
[21:35:15.742] iteration 6168 : model1 loss : 0.021127 model2 loss : 0.020116
[21:35:16.401] iteration 6169 : model1 loss : 0.039841 model2 loss : 0.034389
[21:35:17.064] iteration 6170 : model1 loss : 0.023414 model2 loss : 0.023960
[21:35:17.714] iteration 6171 : model1 loss : 0.062491 model2 loss : 0.055189
[21:35:18.374] iteration 6172 : model1 loss : 0.025907 model2 loss : 0.023134
[21:35:19.026] iteration 6173 : model1 loss : 0.024408 model2 loss : 0.045215
[21:35:19.681] iteration 6174 : model1 loss : 0.038913 model2 loss : 0.039979
[21:35:20.365] iteration 6175 : model1 loss : 0.032475 model2 loss : 0.028655
[21:35:21.025] iteration 6176 : model1 loss : 0.044506 model2 loss : 0.041844
[21:35:21.690] iteration 6177 : model1 loss : 0.033344 model2 loss : 0.029820
[21:35:22.351] iteration 6178 : model1 loss : 0.027128 model2 loss : 0.027699
[21:35:23.013] iteration 6179 : model1 loss : 0.030161 model2 loss : 0.030302
[21:35:23.686] iteration 6180 : model1 loss : 0.028386 model2 loss : 0.027262
[21:35:24.344] iteration 6181 : model1 loss : 0.024982 model2 loss : 0.024153
[21:35:25.003] iteration 6182 : model1 loss : 0.021989 model2 loss : 0.024188
[21:35:25.675] iteration 6183 : model1 loss : 0.033359 model2 loss : 0.026034
[21:35:26.348] iteration 6184 : model1 loss : 0.029830 model2 loss : 0.028899
[21:35:27.003] iteration 6185 : model1 loss : 0.032849 model2 loss : 0.034277
[21:35:27.664] iteration 6186 : model1 loss : 0.030298 model2 loss : 0.048817
[21:35:28.319] iteration 6187 : model1 loss : 0.022475 model2 loss : 0.021486
[21:35:28.974] iteration 6188 : model1 loss : 0.036576 model2 loss : 0.029055
[21:35:29.635] iteration 6189 : model1 loss : 0.026957 model2 loss : 0.022215
[21:35:30.291] iteration 6190 : model1 loss : 0.031528 model2 loss : 0.026899
[21:35:30.953] iteration 6191 : model1 loss : 0.033965 model2 loss : 0.027880
[21:35:31.626] iteration 6192 : model1 loss : 0.024910 model2 loss : 0.029643
[21:35:32.289] iteration 6193 : model1 loss : 0.025574 model2 loss : 0.027818
[21:35:32.942] iteration 6194 : model1 loss : 0.037605 model2 loss : 0.030151
[21:35:33.597] iteration 6195 : model1 loss : 0.020370 model2 loss : 0.027683
[21:35:34.260] iteration 6196 : model1 loss : 0.052994 model2 loss : 0.045107
[21:35:34.926] iteration 6197 : model1 loss : 0.033276 model2 loss : 0.036627
[21:35:35.587] iteration 6198 : model1 loss : 0.022136 model2 loss : 0.024272
[21:35:36.241] iteration 6199 : model1 loss : 0.040914 model2 loss : 0.044356
[21:35:36.901] iteration 6200 : model1 loss : 0.025991 model2 loss : 0.026648
[21:35:54.862] iteration 6200 : model1_mean_dice : 0.813106 model1_mean_hd95 : 14.893506
[21:36:12.891] iteration 6200 : model2_mean_dice : 0.832400 model2_mean_hd95 : 5.125398
[21:36:13.572] iteration 6201 : model1 loss : 0.036239 model2 loss : 0.037095
[21:36:14.228] iteration 6202 : model1 loss : 0.025051 model2 loss : 0.027130
[21:36:14.870] iteration 6203 : model1 loss : 0.030361 model2 loss : 0.027696
[21:36:15.538] iteration 6204 : model1 loss : 0.025398 model2 loss : 0.022209
[21:36:16.179] iteration 6205 : model1 loss : 0.055145 model2 loss : 0.052609
[21:36:16.839] iteration 6206 : model1 loss : 0.034552 model2 loss : 0.038871
[21:36:17.492] iteration 6207 : model1 loss : 0.056888 model2 loss : 0.053371
[21:36:18.139] iteration 6208 : model1 loss : 0.031660 model2 loss : 0.029281
[21:36:18.816] iteration 6209 : model1 loss : 0.042248 model2 loss : 0.049418
[21:36:19.502] iteration 6210 : model1 loss : 0.033764 model2 loss : 0.042731
[21:36:20.181] iteration 6211 : model1 loss : 0.022108 model2 loss : 0.023545
[21:36:20.871] iteration 6212 : model1 loss : 0.025795 model2 loss : 0.031460
[21:36:21.534] iteration 6213 : model1 loss : 0.022468 model2 loss : 0.023585
[21:36:22.187] iteration 6214 : model1 loss : 0.022828 model2 loss : 0.024792
[21:36:22.885] iteration 6215 : model1 loss : 0.023063 model2 loss : 0.024322
[21:36:23.574] iteration 6216 : model1 loss : 0.029851 model2 loss : 0.035501
[21:36:24.454] iteration 6217 : model1 loss : 0.034443 model2 loss : 0.040068
[21:36:25.161] iteration 6218 : model1 loss : 0.060421 model2 loss : 0.129970
[21:36:25.820] iteration 6219 : model1 loss : 0.088513 model2 loss : 0.116788
[21:36:26.485] iteration 6220 : model1 loss : 0.026461 model2 loss : 0.023416
[21:36:27.142] iteration 6221 : model1 loss : 0.033542 model2 loss : 0.030482
[21:36:27.808] iteration 6222 : model1 loss : 0.031109 model2 loss : 0.032819
[21:36:28.456] iteration 6223 : model1 loss : 0.036269 model2 loss : 0.038470
[21:36:29.112] iteration 6224 : model1 loss : 0.022315 model2 loss : 0.026625
[21:36:29.774] iteration 6225 : model1 loss : 0.025441 model2 loss : 0.027474
[21:36:30.418] iteration 6226 : model1 loss : 0.025640 model2 loss : 0.027459
[21:36:31.074] iteration 6227 : model1 loss : 0.041570 model2 loss : 0.038970
[21:36:31.725] iteration 6228 : model1 loss : 0.027023 model2 loss : 0.022880
[21:36:32.371] iteration 6229 : model1 loss : 0.035189 model2 loss : 0.034025
[21:36:33.037] iteration 6230 : model1 loss : 0.023683 model2 loss : 0.019469
[21:36:33.694] iteration 6231 : model1 loss : 0.031028 model2 loss : 0.031522
[21:36:34.361] iteration 6232 : model1 loss : 0.022807 model2 loss : 0.024505
[21:36:35.015] iteration 6233 : model1 loss : 0.043381 model2 loss : 0.041571
[21:36:35.671] iteration 6234 : model1 loss : 0.024504 model2 loss : 0.024734
[21:36:36.346] iteration 6235 : model1 loss : 0.029190 model2 loss : 0.026987
[21:36:37.003] iteration 6236 : model1 loss : 0.029708 model2 loss : 0.032777
[21:36:37.667] iteration 6237 : model1 loss : 0.033661 model2 loss : 0.034538
[21:36:38.362] iteration 6238 : model1 loss : 0.028055 model2 loss : 0.032220
[21:36:39.022] iteration 6239 : model1 loss : 0.026237 model2 loss : 0.025302
[21:36:39.684] iteration 6240 : model1 loss : 0.023974 model2 loss : 0.025753
[21:36:40.342] iteration 6241 : model1 loss : 0.019608 model2 loss : 0.018601
[21:36:41.035] iteration 6242 : model1 loss : 0.030757 model2 loss : 0.027693
[21:36:41.692] iteration 6243 : model1 loss : 0.026757 model2 loss : 0.024473
[21:36:42.354] iteration 6244 : model1 loss : 0.023944 model2 loss : 0.025091
[21:36:43.015] iteration 6245 : model1 loss : 0.053778 model2 loss : 0.043139
[21:36:43.664] iteration 6246 : model1 loss : 0.154390 model2 loss : 0.158969
[21:36:44.324] iteration 6247 : model1 loss : 0.039137 model2 loss : 0.043058
[21:36:44.989] iteration 6248 : model1 loss : 0.034046 model2 loss : 0.034192
[21:36:45.644] iteration 6249 : model1 loss : 0.056217 model2 loss : 0.049484
[21:36:46.290] iteration 6250 : model1 loss : 0.041027 model2 loss : 0.033157
[21:36:47.005] iteration 6251 : model1 loss : 0.038452 model2 loss : 0.037062
[21:36:47.662] iteration 6252 : model1 loss : 0.021704 model2 loss : 0.021817
[21:36:48.320] iteration 6253 : model1 loss : 0.035354 model2 loss : 0.037831
[21:36:48.980] iteration 6254 : model1 loss : 0.031041 model2 loss : 0.067352
[21:36:49.640] iteration 6255 : model1 loss : 0.025776 model2 loss : 0.029656
[21:36:50.303] iteration 6256 : model1 loss : 0.130091 model2 loss : 0.117482
[21:36:50.964] iteration 6257 : model1 loss : 0.035051 model2 loss : 0.041206
[21:36:51.630] iteration 6258 : model1 loss : 0.024548 model2 loss : 0.026423
[21:36:52.291] iteration 6259 : model1 loss : 0.029232 model2 loss : 0.039609
[21:36:52.945] iteration 6260 : model1 loss : 0.029363 model2 loss : 0.051311
[21:36:53.628] iteration 6261 : model1 loss : 0.059174 model2 loss : 0.057239
[21:36:54.284] iteration 6262 : model1 loss : 0.023376 model2 loss : 0.026072
[21:36:54.943] iteration 6263 : model1 loss : 0.031813 model2 loss : 0.048258
[21:36:55.601] iteration 6264 : model1 loss : 0.026231 model2 loss : 0.029890
[21:36:56.264] iteration 6265 : model1 loss : 0.025039 model2 loss : 0.026278
[21:36:56.926] iteration 6266 : model1 loss : 0.023060 model2 loss : 0.023357
[21:36:57.592] iteration 6267 : model1 loss : 0.031214 model2 loss : 0.034487
[21:36:58.253] iteration 6268 : model1 loss : 0.026451 model2 loss : 0.026854
[21:36:58.906] iteration 6269 : model1 loss : 0.020373 model2 loss : 0.023575
[21:36:59.584] iteration 6270 : model1 loss : 0.021186 model2 loss : 0.024168
[21:37:00.259] iteration 6271 : model1 loss : 0.044726 model2 loss : 0.039465
[21:37:00.935] iteration 6272 : model1 loss : 0.026098 model2 loss : 0.029943
[21:37:01.606] iteration 6273 : model1 loss : 0.030867 model2 loss : 0.033138
[21:37:02.278] iteration 6274 : model1 loss : 0.029809 model2 loss : 0.027919
[21:37:02.976] iteration 6275 : model1 loss : 0.045335 model2 loss : 0.043829
[21:37:03.649] iteration 6276 : model1 loss : 0.025763 model2 loss : 0.024047
[21:37:04.341] iteration 6277 : model1 loss : 0.023868 model2 loss : 0.028829
[21:37:05.012] iteration 6278 : model1 loss : 0.033050 model2 loss : 0.030919
[21:37:05.679] iteration 6279 : model1 loss : 0.029280 model2 loss : 0.031799
[21:37:06.348] iteration 6280 : model1 loss : 0.023091 model2 loss : 0.021040
[21:37:07.018] iteration 6281 : model1 loss : 0.031882 model2 loss : 0.043466
[21:37:07.684] iteration 6282 : model1 loss : 0.021657 model2 loss : 0.021555
[21:37:08.363] iteration 6283 : model1 loss : 0.019302 model2 loss : 0.023156
[21:37:09.025] iteration 6284 : model1 loss : 0.031829 model2 loss : 0.061607
[21:37:09.696] iteration 6285 : model1 loss : 0.035273 model2 loss : 0.033892
[21:37:10.357] iteration 6286 : model1 loss : 0.043718 model2 loss : 0.031344
[21:37:11.037] iteration 6287 : model1 loss : 0.042111 model2 loss : 0.069038
[21:37:11.714] iteration 6288 : model1 loss : 0.032386 model2 loss : 0.029143
[21:37:12.379] iteration 6289 : model1 loss : 0.022324 model2 loss : 0.026167
[21:37:13.054] iteration 6290 : model1 loss : 0.019338 model2 loss : 0.023278
[21:37:13.741] iteration 6291 : model1 loss : 0.023989 model2 loss : 0.027613
[21:37:14.424] iteration 6292 : model1 loss : 0.028008 model2 loss : 0.030074
[21:37:15.101] iteration 6293 : model1 loss : 0.025829 model2 loss : 0.033996
[21:37:15.777] iteration 6294 : model1 loss : 0.031035 model2 loss : 0.039282
[21:37:16.448] iteration 6295 : model1 loss : 0.071600 model2 loss : 0.053528
[21:37:17.124] iteration 6296 : model1 loss : 0.050656 model2 loss : 0.037851
[21:37:17.800] iteration 6297 : model1 loss : 0.035541 model2 loss : 0.041630
[21:37:18.482] iteration 6298 : model1 loss : 0.034404 model2 loss : 0.033414
[21:37:19.169] iteration 6299 : model1 loss : 0.029733 model2 loss : 0.036707
[21:37:19.842] iteration 6300 : model1 loss : 0.029897 model2 loss : 0.028697
[21:37:20.580] iteration 6301 : model1 loss : 0.036593 model2 loss : 0.051314
[21:37:21.267] iteration 6302 : model1 loss : 0.045183 model2 loss : 0.036706
[21:37:21.946] iteration 6303 : model1 loss : 0.039330 model2 loss : 0.043355
[21:37:22.632] iteration 6304 : model1 loss : 0.024661 model2 loss : 0.030772
[21:37:23.305] iteration 6305 : model1 loss : 0.028166 model2 loss : 0.033812
[21:37:23.976] iteration 6306 : model1 loss : 0.033436 model2 loss : 0.040724
[21:37:24.703] iteration 6307 : model1 loss : 0.040409 model2 loss : 0.043207
[21:37:25.369] iteration 6308 : model1 loss : 0.022377 model2 loss : 0.023555
[21:37:26.031] iteration 6309 : model1 loss : 0.020864 model2 loss : 0.022032
[21:37:26.711] iteration 6310 : model1 loss : 0.029251 model2 loss : 0.031734
[21:37:27.385] iteration 6311 : model1 loss : 0.026986 model2 loss : 0.028302
[21:37:28.047] iteration 6312 : model1 loss : 0.025122 model2 loss : 0.043259
[21:37:28.703] iteration 6313 : model1 loss : 0.021438 model2 loss : 0.033788
[21:37:29.371] iteration 6314 : model1 loss : 0.025228 model2 loss : 0.034807
[21:37:30.029] iteration 6315 : model1 loss : 0.023168 model2 loss : 0.029401
[21:37:30.700] iteration 6316 : model1 loss : 0.032374 model2 loss : 0.041532
[21:37:31.364] iteration 6317 : model1 loss : 0.076424 model2 loss : 0.090321
[21:37:32.025] iteration 6318 : model1 loss : 0.032979 model2 loss : 0.079713
[21:37:32.691] iteration 6319 : model1 loss : 0.035007 model2 loss : 0.035760
[21:37:33.346] iteration 6320 : model1 loss : 0.025010 model2 loss : 0.024811
[21:37:34.034] iteration 6321 : model1 loss : 0.024646 model2 loss : 0.043853
[21:37:34.695] iteration 6322 : model1 loss : 0.039952 model2 loss : 0.041675
[21:37:35.350] iteration 6323 : model1 loss : 0.041370 model2 loss : 0.040341
[21:37:36.005] iteration 6324 : model1 loss : 0.032208 model2 loss : 0.036944
[21:37:36.665] iteration 6325 : model1 loss : 0.025738 model2 loss : 0.031354
[21:37:37.349] iteration 6326 : model1 loss : 0.021856 model2 loss : 0.036781
[21:37:38.000] iteration 6327 : model1 loss : 0.028310 model2 loss : 0.037059
[21:37:38.661] iteration 6328 : model1 loss : 0.034168 model2 loss : 0.036082
[21:37:39.324] iteration 6329 : model1 loss : 0.022850 model2 loss : 0.022106
[21:37:39.973] iteration 6330 : model1 loss : 0.026629 model2 loss : 0.033985
[21:37:40.635] iteration 6331 : model1 loss : 0.038030 model2 loss : 0.044125
[21:37:41.303] iteration 6332 : model1 loss : 0.020511 model2 loss : 0.022004
[21:37:41.970] iteration 6333 : model1 loss : 0.021371 model2 loss : 0.021870
[21:37:42.660] iteration 6334 : model1 loss : 0.018302 model2 loss : 0.020499
[21:37:43.314] iteration 6335 : model1 loss : 0.035395 model2 loss : 0.033432
[21:37:43.966] iteration 6336 : model1 loss : 0.025091 model2 loss : 0.023294
[21:37:44.627] iteration 6337 : model1 loss : 0.023957 model2 loss : 0.028297
[21:37:45.285] iteration 6338 : model1 loss : 0.040938 model2 loss : 0.040954
[21:37:45.943] iteration 6339 : model1 loss : 0.027504 model2 loss : 0.031101
[21:37:46.614] iteration 6340 : model1 loss : 0.032882 model2 loss : 0.036378
[21:37:47.272] iteration 6341 : model1 loss : 0.021261 model2 loss : 0.024428
[21:37:47.928] iteration 6342 : model1 loss : 0.019312 model2 loss : 0.019739
[21:37:48.613] iteration 6343 : model1 loss : 0.023000 model2 loss : 0.025356
[21:37:49.285] iteration 6344 : model1 loss : 0.026889 model2 loss : 0.030925
[21:37:49.941] iteration 6345 : model1 loss : 0.051391 model2 loss : 0.054108
[21:37:50.603] iteration 6346 : model1 loss : 0.024555 model2 loss : 0.026161
[21:37:51.265] iteration 6347 : model1 loss : 0.031783 model2 loss : 0.040108
[21:37:51.913] iteration 6348 : model1 loss : 0.026419 model2 loss : 0.023999
[21:37:52.595] iteration 6349 : model1 loss : 0.022324 model2 loss : 0.024276
[21:37:53.258] iteration 6350 : model1 loss : 0.026057 model2 loss : 0.029392
[21:37:53.954] iteration 6351 : model1 loss : 0.022398 model2 loss : 0.023288
[21:37:54.624] iteration 6352 : model1 loss : 0.037679 model2 loss : 0.036409
[21:37:55.283] iteration 6353 : model1 loss : 0.025811 model2 loss : 0.036111
[21:37:55.941] iteration 6354 : model1 loss : 0.029762 model2 loss : 0.026505
[21:37:56.609] iteration 6355 : model1 loss : 0.034052 model2 loss : 0.031262
[21:37:57.271] iteration 6356 : model1 loss : 0.031756 model2 loss : 0.029435
[21:37:57.937] iteration 6357 : model1 loss : 0.020565 model2 loss : 0.023176
[21:37:58.601] iteration 6358 : model1 loss : 0.052555 model2 loss : 0.041975
[21:37:59.268] iteration 6359 : model1 loss : 0.027738 model2 loss : 0.026310
[21:37:59.932] iteration 6360 : model1 loss : 0.030989 model2 loss : 0.037643
[21:38:00.593] iteration 6361 : model1 loss : 0.022471 model2 loss : 0.022940
[21:38:01.266] iteration 6362 : model1 loss : 0.021778 model2 loss : 0.022061
[21:38:01.929] iteration 6363 : model1 loss : 0.053736 model2 loss : 0.041421
[21:38:02.599] iteration 6364 : model1 loss : 0.026063 model2 loss : 0.031101
[21:38:03.261] iteration 6365 : model1 loss : 0.023029 model2 loss : 0.027580
[21:38:03.926] iteration 6366 : model1 loss : 0.031287 model2 loss : 0.039855
[21:38:04.590] iteration 6367 : model1 loss : 0.059580 model2 loss : 0.062983
[21:38:05.253] iteration 6368 : model1 loss : 0.024810 model2 loss : 0.028967
[21:38:05.913] iteration 6369 : model1 loss : 0.054090 model2 loss : 0.053682
[21:38:06.572] iteration 6370 : model1 loss : 0.030005 model2 loss : 0.028362
[21:38:07.232] iteration 6371 : model1 loss : 0.032018 model2 loss : 0.032302
[21:38:07.901] iteration 6372 : model1 loss : 0.023594 model2 loss : 0.019707
[21:38:08.572] iteration 6373 : model1 loss : 0.028647 model2 loss : 0.027286
[21:38:09.235] iteration 6374 : model1 loss : 0.028786 model2 loss : 0.025868
[21:38:09.896] iteration 6375 : model1 loss : 0.026676 model2 loss : 0.031494
[21:38:10.567] iteration 6376 : model1 loss : 0.022834 model2 loss : 0.026643
[21:38:11.230] iteration 6377 : model1 loss : 0.029619 model2 loss : 0.030432
[21:38:11.889] iteration 6378 : model1 loss : 0.035604 model2 loss : 0.035435
[21:38:12.554] iteration 6379 : model1 loss : 0.056291 model2 loss : 0.050476
[21:38:13.209] iteration 6380 : model1 loss : 0.036727 model2 loss : 0.035261
[21:38:13.881] iteration 6381 : model1 loss : 0.047829 model2 loss : 0.030545
[21:38:14.545] iteration 6382 : model1 loss : 0.023315 model2 loss : 0.020662
[21:38:15.203] iteration 6383 : model1 loss : 0.024858 model2 loss : 0.022901
[21:38:15.862] iteration 6384 : model1 loss : 0.023948 model2 loss : 0.024054
[21:38:16.516] iteration 6385 : model1 loss : 0.023957 model2 loss : 0.024671
[21:38:17.178] iteration 6386 : model1 loss : 0.086797 model2 loss : 0.070001
[21:38:17.836] iteration 6387 : model1 loss : 0.031126 model2 loss : 0.031678
[21:38:18.488] iteration 6388 : model1 loss : 0.028072 model2 loss : 0.036211
[21:38:19.146] iteration 6389 : model1 loss : 0.028389 model2 loss : 0.027840
[21:38:19.800] iteration 6390 : model1 loss : 0.037875 model2 loss : 0.033836
[21:38:20.456] iteration 6391 : model1 loss : 0.028038 model2 loss : 0.029742
[21:38:21.111] iteration 6392 : model1 loss : 0.027349 model2 loss : 0.024426
[21:38:21.771] iteration 6393 : model1 loss : 0.033669 model2 loss : 0.030858
[21:38:22.443] iteration 6394 : model1 loss : 0.022617 model2 loss : 0.025589
[21:38:23.113] iteration 6395 : model1 loss : 0.049143 model2 loss : 0.057977
[21:38:23.755] iteration 6396 : model1 loss : 0.021341 model2 loss : 0.023859
[21:38:24.417] iteration 6397 : model1 loss : 0.026937 model2 loss : 0.028702
[21:38:25.077] iteration 6398 : model1 loss : 0.028531 model2 loss : 0.028644
[21:38:25.722] iteration 6399 : model1 loss : 0.032346 model2 loss : 0.026906
[21:38:26.383] iteration 6400 : model1 loss : 0.043195 model2 loss : 0.038499
[21:38:44.453] iteration 6400 : model1_mean_dice : 0.828830 model1_mean_hd95 : 10.133373
[21:39:02.384] iteration 6400 : model2_mean_dice : 0.835916 model2_mean_hd95 : 6.961354
[21:39:03.060] iteration 6401 : model1 loss : 0.026680 model2 loss : 0.023566
[21:39:03.722] iteration 6402 : model1 loss : 0.032749 model2 loss : 0.037392
[21:39:04.381] iteration 6403 : model1 loss : 0.094941 model2 loss : 0.118990
[21:39:05.029] iteration 6404 : model1 loss : 0.033745 model2 loss : 0.029855
[21:39:05.681] iteration 6405 : model1 loss : 0.027454 model2 loss : 0.028704
[21:39:06.347] iteration 6406 : model1 loss : 0.024110 model2 loss : 0.025154
[21:39:07.009] iteration 6407 : model1 loss : 0.046344 model2 loss : 0.043691
[21:39:07.658] iteration 6408 : model1 loss : 0.022283 model2 loss : 0.030007
[21:39:08.311] iteration 6409 : model1 loss : 0.027785 model2 loss : 0.027828
[21:39:08.967] iteration 6410 : model1 loss : 0.022313 model2 loss : 0.026406
[21:39:09.614] iteration 6411 : model1 loss : 0.038743 model2 loss : 0.033778
[21:39:10.280] iteration 6412 : model1 loss : 0.033307 model2 loss : 0.029900
[21:39:10.938] iteration 6413 : model1 loss : 0.030610 model2 loss : 0.025820
[21:39:11.591] iteration 6414 : model1 loss : 0.020702 model2 loss : 0.021458
[21:39:12.249] iteration 6415 : model1 loss : 0.034059 model2 loss : 0.033081
[21:39:12.911] iteration 6416 : model1 loss : 0.046449 model2 loss : 0.047062
[21:39:13.574] iteration 6417 : model1 loss : 0.037249 model2 loss : 0.041235
[21:39:14.237] iteration 6418 : model1 loss : 0.033475 model2 loss : 0.031315
[21:39:14.892] iteration 6419 : model1 loss : 0.026870 model2 loss : 0.031916
[21:39:15.536] iteration 6420 : model1 loss : 0.033528 model2 loss : 0.044634
[21:39:16.191] iteration 6421 : model1 loss : 0.073578 model2 loss : 0.092958
[21:39:16.846] iteration 6422 : model1 loss : 0.051628 model2 loss : 0.055735
[21:39:17.514] iteration 6423 : model1 loss : 0.029189 model2 loss : 0.029790
[21:39:18.167] iteration 6424 : model1 loss : 0.060042 model2 loss : 0.051581
[21:39:18.819] iteration 6425 : model1 loss : 0.032121 model2 loss : 0.027779
[21:39:19.498] iteration 6426 : model1 loss : 0.045131 model2 loss : 0.055913
[21:39:20.140] iteration 6427 : model1 loss : 0.047938 model2 loss : 0.047832
[21:39:20.798] iteration 6428 : model1 loss : 0.045251 model2 loss : 0.052268
[21:39:21.456] iteration 6429 : model1 loss : 0.030709 model2 loss : 0.038823
[21:39:22.112] iteration 6430 : model1 loss : 0.045510 model2 loss : 0.040633
[21:39:22.779] iteration 6431 : model1 loss : 0.074969 model2 loss : 0.054178
[21:39:23.441] iteration 6432 : model1 loss : 0.040630 model2 loss : 0.046289
[21:39:24.117] iteration 6433 : model1 loss : 0.031501 model2 loss : 0.039225
[21:39:24.761] iteration 6434 : model1 loss : 0.024552 model2 loss : 0.028287
[21:39:25.430] iteration 6435 : model1 loss : 0.025751 model2 loss : 0.026619
[21:39:26.087] iteration 6436 : model1 loss : 0.047133 model2 loss : 0.049698
[21:39:26.737] iteration 6437 : model1 loss : 0.023042 model2 loss : 0.023782
[21:39:27.397] iteration 6438 : model1 loss : 0.036595 model2 loss : 0.032160
[21:39:28.051] iteration 6439 : model1 loss : 0.019079 model2 loss : 0.021345
[21:39:28.712] iteration 6440 : model1 loss : 0.027279 model2 loss : 0.031099
[21:39:29.381] iteration 6441 : model1 loss : 0.031111 model2 loss : 0.028225
[21:39:30.034] iteration 6442 : model1 loss : 0.050753 model2 loss : 0.046180
[21:39:30.693] iteration 6443 : model1 loss : 0.022227 model2 loss : 0.025556
[21:39:31.352] iteration 6444 : model1 loss : 0.033743 model2 loss : 0.040146
[21:39:32.010] iteration 6445 : model1 loss : 0.066542 model2 loss : 0.066472
[21:39:32.674] iteration 6446 : model1 loss : 0.028508 model2 loss : 0.028911
[21:39:33.347] iteration 6447 : model1 loss : 0.057810 model2 loss : 0.027863
[21:39:34.018] iteration 6448 : model1 loss : 0.026608 model2 loss : 0.030808
[21:39:34.675] iteration 6449 : model1 loss : 0.022814 model2 loss : 0.021080
[21:39:35.356] iteration 6450 : model1 loss : 0.030007 model2 loss : 0.023955
[21:39:36.061] iteration 6451 : model1 loss : 0.036798 model2 loss : 0.028904
[21:39:36.722] iteration 6452 : model1 loss : 0.024370 model2 loss : 0.028322
[21:39:37.384] iteration 6453 : model1 loss : 0.024866 model2 loss : 0.025242
[21:39:38.042] iteration 6454 : model1 loss : 0.024190 model2 loss : 0.024281
[21:39:38.698] iteration 6455 : model1 loss : 0.027223 model2 loss : 0.027724
[21:39:39.353] iteration 6456 : model1 loss : 0.020026 model2 loss : 0.020713
[21:39:40.023] iteration 6457 : model1 loss : 0.026863 model2 loss : 0.026490
[21:39:40.679] iteration 6458 : model1 loss : 0.051292 model2 loss : 0.043829
[21:39:41.339] iteration 6459 : model1 loss : 0.027972 model2 loss : 0.029839
[21:39:42.011] iteration 6460 : model1 loss : 0.053466 model2 loss : 0.044852
[21:39:42.743] iteration 6461 : model1 loss : 0.025420 model2 loss : 0.024070
[21:39:43.405] iteration 6462 : model1 loss : 0.019455 model2 loss : 0.018924
[21:39:44.061] iteration 6463 : model1 loss : 0.032731 model2 loss : 0.034974
[21:39:44.720] iteration 6464 : model1 loss : 0.023640 model2 loss : 0.022705
[21:39:45.382] iteration 6465 : model1 loss : 0.024080 model2 loss : 0.023244
[21:39:46.033] iteration 6466 : model1 loss : 0.029254 model2 loss : 0.031343
[21:39:46.696] iteration 6467 : model1 loss : 0.021852 model2 loss : 0.021996
[21:39:47.359] iteration 6468 : model1 loss : 0.031109 model2 loss : 0.033368
[21:39:48.031] iteration 6469 : model1 loss : 0.024533 model2 loss : 0.025311
[21:39:48.690] iteration 6470 : model1 loss : 0.026296 model2 loss : 0.026073
[21:39:49.353] iteration 6471 : model1 loss : 0.036749 model2 loss : 0.034807
[21:39:50.004] iteration 6472 : model1 loss : 0.023348 model2 loss : 0.023538
[21:39:50.669] iteration 6473 : model1 loss : 0.022055 model2 loss : 0.021663
[21:39:51.340] iteration 6474 : model1 loss : 0.146008 model2 loss : 0.143131
[21:39:51.998] iteration 6475 : model1 loss : 0.026879 model2 loss : 0.028480
[21:39:52.671] iteration 6476 : model1 loss : 0.028411 model2 loss : 0.030991
[21:39:53.334] iteration 6477 : model1 loss : 0.028305 model2 loss : 0.029515
[21:39:53.995] iteration 6478 : model1 loss : 0.029856 model2 loss : 0.027370
[21:39:54.654] iteration 6479 : model1 loss : 0.024583 model2 loss : 0.022081
[21:39:55.321] iteration 6480 : model1 loss : 0.035219 model2 loss : 0.033174
[21:39:55.979] iteration 6481 : model1 loss : 0.047087 model2 loss : 0.032990
[21:39:56.657] iteration 6482 : model1 loss : 0.034994 model2 loss : 0.032671
[21:39:57.321] iteration 6483 : model1 loss : 0.018137 model2 loss : 0.023698
[21:39:57.980] iteration 6484 : model1 loss : 0.032756 model2 loss : 0.032101
[21:39:58.645] iteration 6485 : model1 loss : 0.033700 model2 loss : 0.034268
[21:39:59.300] iteration 6486 : model1 loss : 0.025634 model2 loss : 0.023807
[21:39:59.953] iteration 6487 : model1 loss : 0.031513 model2 loss : 0.027952
[21:40:00.614] iteration 6488 : model1 loss : 0.045582 model2 loss : 0.079705
[21:40:01.273] iteration 6489 : model1 loss : 0.040470 model2 loss : 0.039186
[21:40:01.923] iteration 6490 : model1 loss : 0.034896 model2 loss : 0.043971
[21:40:02.589] iteration 6491 : model1 loss : 0.037836 model2 loss : 0.038106
[21:40:03.258] iteration 6492 : model1 loss : 0.040315 model2 loss : 0.036767
[21:40:03.919] iteration 6493 : model1 loss : 0.039433 model2 loss : 0.031485
[21:40:04.583] iteration 6494 : model1 loss : 0.023218 model2 loss : 0.022558
[21:40:05.243] iteration 6495 : model1 loss : 0.032266 model2 loss : 0.029658
[21:40:05.898] iteration 6496 : model1 loss : 0.048888 model2 loss : 0.045016
[21:40:06.570] iteration 6497 : model1 loss : 0.020943 model2 loss : 0.022353
[21:40:07.224] iteration 6498 : model1 loss : 0.032885 model2 loss : 0.030033
[21:40:07.881] iteration 6499 : model1 loss : 0.029453 model2 loss : 0.030751
[21:40:08.537] iteration 6500 : model1 loss : 0.022061 model2 loss : 0.023295
[21:40:09.232] iteration 6501 : model1 loss : 0.022486 model2 loss : 0.021778
[21:40:09.907] iteration 6502 : model1 loss : 0.025151 model2 loss : 0.025843
[21:40:10.584] iteration 6503 : model1 loss : 0.025032 model2 loss : 0.026634
[21:40:11.245] iteration 6504 : model1 loss : 0.037995 model2 loss : 0.043726
[21:40:11.905] iteration 6505 : model1 loss : 0.050437 model2 loss : 0.046334
[21:40:12.571] iteration 6506 : model1 loss : 0.045566 model2 loss : 0.033222
[21:40:13.230] iteration 6507 : model1 loss : 0.035212 model2 loss : 0.039340
[21:40:13.886] iteration 6508 : model1 loss : 0.035520 model2 loss : 0.030722
[21:40:14.544] iteration 6509 : model1 loss : 0.055372 model2 loss : 0.037883
[21:40:15.208] iteration 6510 : model1 loss : 0.028273 model2 loss : 0.027173
[21:40:15.871] iteration 6511 : model1 loss : 0.030532 model2 loss : 0.033870
[21:40:16.524] iteration 6512 : model1 loss : 0.029520 model2 loss : 0.026052
[21:40:17.183] iteration 6513 : model1 loss : 0.032611 model2 loss : 0.030315
[21:40:17.844] iteration 6514 : model1 loss : 0.027560 model2 loss : 0.028562
[21:40:18.507] iteration 6515 : model1 loss : 0.022556 model2 loss : 0.032831
[21:40:19.168] iteration 6516 : model1 loss : 0.030075 model2 loss : 0.032509
[21:40:19.829] iteration 6517 : model1 loss : 0.038478 model2 loss : 0.027306
[21:40:20.482] iteration 6518 : model1 loss : 0.036614 model2 loss : 0.048713
[21:40:21.151] iteration 6519 : model1 loss : 0.022901 model2 loss : 0.021208
[21:40:21.819] iteration 6520 : model1 loss : 0.038153 model2 loss : 0.038986
[21:40:22.480] iteration 6521 : model1 loss : 0.025895 model2 loss : 0.038814
[21:40:23.142] iteration 6522 : model1 loss : 0.023910 model2 loss : 0.026135
[21:40:23.809] iteration 6523 : model1 loss : 0.030764 model2 loss : 0.033382
[21:40:24.479] iteration 6524 : model1 loss : 0.022624 model2 loss : 0.024237
[21:40:25.144] iteration 6525 : model1 loss : 0.029630 model2 loss : 0.031695
[21:40:25.802] iteration 6526 : model1 loss : 0.058651 model2 loss : 0.046053
[21:40:26.462] iteration 6527 : model1 loss : 0.019874 model2 loss : 0.021613
[21:40:27.131] iteration 6528 : model1 loss : 0.025392 model2 loss : 0.028405
[21:40:27.784] iteration 6529 : model1 loss : 0.019742 model2 loss : 0.020216
[21:40:28.444] iteration 6530 : model1 loss : 0.024371 model2 loss : 0.022031
[21:40:29.101] iteration 6531 : model1 loss : 0.023769 model2 loss : 0.027186
[21:40:29.774] iteration 6532 : model1 loss : 0.047164 model2 loss : 0.050883
[21:40:30.430] iteration 6533 : model1 loss : 0.023279 model2 loss : 0.028637
[21:40:31.083] iteration 6534 : model1 loss : 0.029567 model2 loss : 0.027502
[21:40:31.749] iteration 6535 : model1 loss : 0.025742 model2 loss : 0.028863
[21:40:32.404] iteration 6536 : model1 loss : 0.027581 model2 loss : 0.023739
[21:40:33.067] iteration 6537 : model1 loss : 0.021048 model2 loss : 0.021103
[21:40:33.730] iteration 6538 : model1 loss : 0.022691 model2 loss : 0.022860
[21:40:34.397] iteration 6539 : model1 loss : 0.036155 model2 loss : 0.027257
[21:40:35.050] iteration 6540 : model1 loss : 0.032197 model2 loss : 0.029849
[21:40:35.712] iteration 6541 : model1 loss : 0.024969 model2 loss : 0.024270
[21:40:36.362] iteration 6542 : model1 loss : 0.044312 model2 loss : 0.049327
[21:40:37.018] iteration 6543 : model1 loss : 0.020174 model2 loss : 0.022370
[21:40:37.672] iteration 6544 : model1 loss : 0.022327 model2 loss : 0.023067
[21:40:38.339] iteration 6545 : model1 loss : 0.025652 model2 loss : 0.032709
[21:40:38.989] iteration 6546 : model1 loss : 0.017553 model2 loss : 0.019137
[21:40:39.658] iteration 6547 : model1 loss : 0.026154 model2 loss : 0.025213
[21:40:40.331] iteration 6548 : model1 loss : 0.037487 model2 loss : 0.030654
[21:40:40.994] iteration 6549 : model1 loss : 0.021477 model2 loss : 0.023020
[21:40:41.655] iteration 6550 : model1 loss : 0.022506 model2 loss : 0.022041
[21:40:42.366] iteration 6551 : model1 loss : 0.028333 model2 loss : 0.024126
[21:40:43.069] iteration 6552 : model1 loss : 0.022152 model2 loss : 0.020467
[21:40:43.740] iteration 6553 : model1 loss : 0.028785 model2 loss : 0.027424
[21:40:44.395] iteration 6554 : model1 loss : 0.049012 model2 loss : 0.052610
[21:40:45.058] iteration 6555 : model1 loss : 0.021311 model2 loss : 0.020639
[21:40:45.718] iteration 6556 : model1 loss : 0.027594 model2 loss : 0.030993
[21:40:46.378] iteration 6557 : model1 loss : 0.025021 model2 loss : 0.032852
[21:40:47.028] iteration 6558 : model1 loss : 0.041662 model2 loss : 0.060153
[21:40:47.692] iteration 6559 : model1 loss : 0.032999 model2 loss : 0.037478
[21:40:48.360] iteration 6560 : model1 loss : 0.027284 model2 loss : 0.027422
[21:40:49.036] iteration 6561 : model1 loss : 0.025394 model2 loss : 0.021971
[21:40:49.693] iteration 6562 : model1 loss : 0.072179 model2 loss : 0.085850
[21:40:50.359] iteration 6563 : model1 loss : 0.025158 model2 loss : 0.023965
[21:40:51.008] iteration 6564 : model1 loss : 0.041565 model2 loss : 0.058522
[21:40:51.668] iteration 6565 : model1 loss : 0.040979 model2 loss : 0.036949
[21:40:52.336] iteration 6566 : model1 loss : 0.105409 model2 loss : 0.115237
[21:40:52.998] iteration 6567 : model1 loss : 0.033179 model2 loss : 0.027244
[21:40:53.656] iteration 6568 : model1 loss : 0.023047 model2 loss : 0.037552
[21:40:54.333] iteration 6569 : model1 loss : 0.021916 model2 loss : 0.023134
[21:40:54.987] iteration 6570 : model1 loss : 0.027081 model2 loss : 0.036291
[21:40:55.644] iteration 6571 : model1 loss : 0.024638 model2 loss : 0.025079
[21:40:56.295] iteration 6572 : model1 loss : 0.029311 model2 loss : 0.032762
[21:40:56.947] iteration 6573 : model1 loss : 0.037849 model2 loss : 0.040518
[21:40:57.600] iteration 6574 : model1 loss : 0.020577 model2 loss : 0.028949
[21:40:58.269] iteration 6575 : model1 loss : 0.028493 model2 loss : 0.032454
[21:40:58.926] iteration 6576 : model1 loss : 0.030131 model2 loss : 0.027871
[21:40:59.588] iteration 6577 : model1 loss : 0.023933 model2 loss : 0.027022
[21:41:00.247] iteration 6578 : model1 loss : 0.026653 model2 loss : 0.022408
[21:41:00.903] iteration 6579 : model1 loss : 0.019771 model2 loss : 0.021671
[21:41:01.573] iteration 6580 : model1 loss : 0.024471 model2 loss : 0.028325
[21:41:02.231] iteration 6581 : model1 loss : 0.032115 model2 loss : 0.040038
[21:41:02.897] iteration 6582 : model1 loss : 0.058862 model2 loss : 0.034401
[21:41:03.548] iteration 6583 : model1 loss : 0.024125 model2 loss : 0.023032
[21:41:04.220] iteration 6584 : model1 loss : 0.036813 model2 loss : 0.038100
[21:41:04.878] iteration 6585 : model1 loss : 0.022124 model2 loss : 0.025674
[21:41:05.543] iteration 6586 : model1 loss : 0.026412 model2 loss : 0.024623
[21:41:06.198] iteration 6587 : model1 loss : 0.025570 model2 loss : 0.027789
[21:41:06.855] iteration 6588 : model1 loss : 0.021280 model2 loss : 0.026066
[21:41:07.523] iteration 6589 : model1 loss : 0.023268 model2 loss : 0.025118
[21:41:08.192] iteration 6590 : model1 loss : 0.025946 model2 loss : 0.026563
[21:41:08.854] iteration 6591 : model1 loss : 0.020455 model2 loss : 0.022712
[21:41:09.508] iteration 6592 : model1 loss : 0.029952 model2 loss : 0.030292
[21:41:10.163] iteration 6593 : model1 loss : 0.084367 model2 loss : 0.071358
[21:41:10.827] iteration 6594 : model1 loss : 0.023959 model2 loss : 0.023580
[21:41:11.498] iteration 6595 : model1 loss : 0.034984 model2 loss : 0.040898
[21:41:12.153] iteration 6596 : model1 loss : 0.025820 model2 loss : 0.028794
[21:41:12.807] iteration 6597 : model1 loss : 0.051097 model2 loss : 0.043717
[21:41:13.468] iteration 6598 : model1 loss : 0.022219 model2 loss : 0.021238
[21:41:14.129] iteration 6599 : model1 loss : 0.028674 model2 loss : 0.025114
[21:41:14.791] iteration 6600 : model1 loss : 0.052147 model2 loss : 0.048830
[21:41:32.872] iteration 6600 : model1_mean_dice : 0.811053 model1_mean_hd95 : 20.781944
[21:41:50.878] iteration 6600 : model2_mean_dice : 0.834448 model2_mean_hd95 : 9.978624
[21:41:51.572] iteration 6601 : model1 loss : 0.040825 model2 loss : 0.028196
[21:41:52.238] iteration 6602 : model1 loss : 0.026626 model2 loss : 0.022740
[21:41:52.891] iteration 6603 : model1 loss : 0.021608 model2 loss : 0.022742
[21:41:53.551] iteration 6604 : model1 loss : 0.024399 model2 loss : 0.022089
[21:41:54.207] iteration 6605 : model1 loss : 0.038688 model2 loss : 0.049722
[21:41:54.863] iteration 6606 : model1 loss : 0.021328 model2 loss : 0.020820
[21:41:55.539] iteration 6607 : model1 loss : 0.019992 model2 loss : 0.020107
[21:41:56.191] iteration 6608 : model1 loss : 0.038519 model2 loss : 0.035731
[21:41:56.845] iteration 6609 : model1 loss : 0.052825 model2 loss : 0.041623
[21:41:57.507] iteration 6610 : model1 loss : 0.026189 model2 loss : 0.023371
[21:41:58.151] iteration 6611 : model1 loss : 0.026120 model2 loss : 0.020975
[21:41:58.814] iteration 6612 : model1 loss : 0.031658 model2 loss : 0.032373
[21:41:59.477] iteration 6613 : model1 loss : 0.039552 model2 loss : 0.037615
[21:42:00.131] iteration 6614 : model1 loss : 0.025001 model2 loss : 0.025813
[21:42:00.781] iteration 6615 : model1 loss : 0.027123 model2 loss : 0.028029
[21:42:01.450] iteration 6616 : model1 loss : 0.030037 model2 loss : 0.048954
[21:42:02.101] iteration 6617 : model1 loss : 0.027883 model2 loss : 0.025614
[21:42:02.770] iteration 6618 : model1 loss : 0.039849 model2 loss : 0.026613
[21:42:03.435] iteration 6619 : model1 loss : 0.028693 model2 loss : 0.027150
[21:42:04.088] iteration 6620 : model1 loss : 0.042456 model2 loss : 0.078049
[21:42:04.747] iteration 6621 : model1 loss : 0.037379 model2 loss : 0.062688
[21:42:05.399] iteration 6622 : model1 loss : 0.024502 model2 loss : 0.032459
[21:42:06.054] iteration 6623 : model1 loss : 0.050628 model2 loss : 0.054545
[21:42:06.708] iteration 6624 : model1 loss : 0.023595 model2 loss : 0.020306
[21:42:07.356] iteration 6625 : model1 loss : 0.028776 model2 loss : 0.049345
[21:42:08.008] iteration 6626 : model1 loss : 0.026971 model2 loss : 0.027975
[21:42:08.670] iteration 6627 : model1 loss : 0.033119 model2 loss : 0.032565
[21:42:09.335] iteration 6628 : model1 loss : 0.053225 model2 loss : 0.090011
[21:42:09.986] iteration 6629 : model1 loss : 0.032508 model2 loss : 0.040535
[21:42:10.646] iteration 6630 : model1 loss : 0.021697 model2 loss : 0.019367
[21:42:11.302] iteration 6631 : model1 loss : 0.025338 model2 loss : 0.027398
[21:42:11.959] iteration 6632 : model1 loss : 0.021176 model2 loss : 0.022207
[21:42:12.618] iteration 6633 : model1 loss : 0.027346 model2 loss : 0.028608
[21:42:13.270] iteration 6634 : model1 loss : 0.024746 model2 loss : 0.029910
[21:42:13.930] iteration 6635 : model1 loss : 0.031298 model2 loss : 0.028626
[21:42:14.597] iteration 6636 : model1 loss : 0.027514 model2 loss : 0.029978
[21:42:15.257] iteration 6637 : model1 loss : 0.027393 model2 loss : 0.030384
[21:42:15.907] iteration 6638 : model1 loss : 0.043769 model2 loss : 0.049462
[21:42:16.565] iteration 6639 : model1 loss : 0.032890 model2 loss : 0.028963
[21:42:17.236] iteration 6640 : model1 loss : 0.021050 model2 loss : 0.023161
[21:42:17.900] iteration 6641 : model1 loss : 0.038180 model2 loss : 0.042370
[21:42:18.575] iteration 6642 : model1 loss : 0.032645 model2 loss : 0.034947
[21:42:19.228] iteration 6643 : model1 loss : 0.094471 model2 loss : 0.115782
[21:42:19.887] iteration 6644 : model1 loss : 0.028764 model2 loss : 0.037431
[21:42:20.547] iteration 6645 : model1 loss : 0.020378 model2 loss : 0.024689
[21:42:21.201] iteration 6646 : model1 loss : 0.031090 model2 loss : 0.030896
[21:42:21.860] iteration 6647 : model1 loss : 0.029333 model2 loss : 0.033391
[21:42:22.520] iteration 6648 : model1 loss : 0.026286 model2 loss : 0.032551
[21:42:23.181] iteration 6649 : model1 loss : 0.038677 model2 loss : 0.040221
[21:42:23.839] iteration 6650 : model1 loss : 0.036181 model2 loss : 0.034862
[21:42:24.540] iteration 6651 : model1 loss : 0.029255 model2 loss : 0.026108
[21:42:25.198] iteration 6652 : model1 loss : 0.025889 model2 loss : 0.030639
[21:42:25.856] iteration 6653 : model1 loss : 0.023776 model2 loss : 0.025136
[21:42:26.508] iteration 6654 : model1 loss : 0.031042 model2 loss : 0.027941
[21:42:27.165] iteration 6655 : model1 loss : 0.061008 model2 loss : 0.049707
[21:42:27.822] iteration 6656 : model1 loss : 0.022521 model2 loss : 0.027869
[21:42:28.490] iteration 6657 : model1 loss : 0.031614 model2 loss : 0.036127
[21:42:29.145] iteration 6658 : model1 loss : 0.019244 model2 loss : 0.020319
[21:42:29.801] iteration 6659 : model1 loss : 0.029005 model2 loss : 0.027113
[21:42:30.461] iteration 6660 : model1 loss : 0.032457 model2 loss : 0.042319
[21:42:31.131] iteration 6661 : model1 loss : 0.025028 model2 loss : 0.026406
[21:42:31.792] iteration 6662 : model1 loss : 0.039325 model2 loss : 0.085210
[21:42:32.450] iteration 6663 : model1 loss : 0.019924 model2 loss : 0.021447
[21:42:33.098] iteration 6664 : model1 loss : 0.049733 model2 loss : 0.054978
[21:42:33.759] iteration 6665 : model1 loss : 0.018172 model2 loss : 0.022185
[21:42:34.414] iteration 6666 : model1 loss : 0.031476 model2 loss : 0.032112
[21:42:35.069] iteration 6667 : model1 loss : 0.019175 model2 loss : 0.018875
[21:42:35.720] iteration 6668 : model1 loss : 0.019516 model2 loss : 0.020374
[21:42:36.386] iteration 6669 : model1 loss : 0.052299 model2 loss : 0.071930
[21:42:37.054] iteration 6670 : model1 loss : 0.023968 model2 loss : 0.028007
[21:42:37.721] iteration 6671 : model1 loss : 0.026758 model2 loss : 0.031616
[21:42:38.379] iteration 6672 : model1 loss : 0.034127 model2 loss : 0.026363
[21:42:39.051] iteration 6673 : model1 loss : 0.038086 model2 loss : 0.036904
[21:42:39.714] iteration 6674 : model1 loss : 0.025115 model2 loss : 0.028676
[21:42:40.378] iteration 6675 : model1 loss : 0.038132 model2 loss : 0.033475
[21:42:41.042] iteration 6676 : model1 loss : 0.029608 model2 loss : 0.029624
[21:42:41.718] iteration 6677 : model1 loss : 0.028388 model2 loss : 0.028212
[21:42:42.374] iteration 6678 : model1 loss : 0.042747 model2 loss : 0.068171
[21:42:43.039] iteration 6679 : model1 loss : 0.030389 model2 loss : 0.027270
[21:42:43.736] iteration 6680 : model1 loss : 0.027303 model2 loss : 0.024267
[21:42:44.412] iteration 6681 : model1 loss : 0.021529 model2 loss : 0.023535
[21:42:45.081] iteration 6682 : model1 loss : 0.021058 model2 loss : 0.023812
[21:42:45.744] iteration 6683 : model1 loss : 0.018690 model2 loss : 0.021921
[21:42:46.392] iteration 6684 : model1 loss : 0.021250 model2 loss : 0.025805
[21:42:47.051] iteration 6685 : model1 loss : 0.036204 model2 loss : 0.042356
[21:42:47.708] iteration 6686 : model1 loss : 0.031572 model2 loss : 0.034603
[21:42:48.369] iteration 6687 : model1 loss : 0.026561 model2 loss : 0.027974
[21:42:49.033] iteration 6688 : model1 loss : 0.038868 model2 loss : 0.038335
[21:42:49.708] iteration 6689 : model1 loss : 0.026988 model2 loss : 0.025290
[21:42:50.371] iteration 6690 : model1 loss : 0.056566 model2 loss : 0.044961
[21:42:51.032] iteration 6691 : model1 loss : 0.035125 model2 loss : 0.075650
[21:42:51.694] iteration 6692 : model1 loss : 0.020144 model2 loss : 0.019766
[21:42:52.359] iteration 6693 : model1 loss : 0.026790 model2 loss : 0.028204
[21:42:53.020] iteration 6694 : model1 loss : 0.028150 model2 loss : 0.037807
[21:42:53.678] iteration 6695 : model1 loss : 0.152361 model2 loss : 0.151239
[21:42:54.332] iteration 6696 : model1 loss : 0.023261 model2 loss : 0.021273
[21:42:54.991] iteration 6697 : model1 loss : 0.025846 model2 loss : 0.026522
[21:42:55.658] iteration 6698 : model1 loss : 0.035078 model2 loss : 0.036869
[21:42:56.315] iteration 6699 : model1 loss : 0.020671 model2 loss : 0.020787
[21:42:56.984] iteration 6700 : model1 loss : 0.026052 model2 loss : 0.029203
[21:42:57.677] iteration 6701 : model1 loss : 0.027225 model2 loss : 0.023442
[21:42:58.340] iteration 6702 : model1 loss : 0.029275 model2 loss : 0.038249
[21:42:59.004] iteration 6703 : model1 loss : 0.041656 model2 loss : 0.049391
[21:42:59.677] iteration 6704 : model1 loss : 0.022969 model2 loss : 0.024227
[21:43:00.356] iteration 6705 : model1 loss : 0.027320 model2 loss : 0.030001
[21:43:01.028] iteration 6706 : model1 loss : 0.029124 model2 loss : 0.027706
[21:43:01.693] iteration 6707 : model1 loss : 0.022484 model2 loss : 0.025882
[21:43:02.350] iteration 6708 : model1 loss : 0.023901 model2 loss : 0.025502
[21:43:03.006] iteration 6709 : model1 loss : 0.023930 model2 loss : 0.031300
[21:43:03.676] iteration 6710 : model1 loss : 0.040639 model2 loss : 0.035624
[21:43:04.348] iteration 6711 : model1 loss : 0.034603 model2 loss : 0.038555
[21:43:05.014] iteration 6712 : model1 loss : 0.024551 model2 loss : 0.021750
[21:43:05.679] iteration 6713 : model1 loss : 0.022411 model2 loss : 0.023715
[21:43:06.345] iteration 6714 : model1 loss : 0.029452 model2 loss : 0.032667
[21:43:07.006] iteration 6715 : model1 loss : 0.030420 model2 loss : 0.031456
[21:43:07.662] iteration 6716 : model1 loss : 0.028610 model2 loss : 0.029604
[21:43:08.323] iteration 6717 : model1 loss : 0.022823 model2 loss : 0.023554
[21:43:08.978] iteration 6718 : model1 loss : 0.033408 model2 loss : 0.032568
[21:43:09.640] iteration 6719 : model1 loss : 0.030382 model2 loss : 0.035757
[21:43:10.293] iteration 6720 : model1 loss : 0.033486 model2 loss : 0.037958
[21:43:10.947] iteration 6721 : model1 loss : 0.023125 model2 loss : 0.021909
[21:43:11.613] iteration 6722 : model1 loss : 0.022315 model2 loss : 0.024883
[21:43:12.264] iteration 6723 : model1 loss : 0.033898 model2 loss : 0.047776
[21:43:12.917] iteration 6724 : model1 loss : 0.021043 model2 loss : 0.025395
[21:43:13.571] iteration 6725 : model1 loss : 0.029773 model2 loss : 0.024740
[21:43:14.241] iteration 6726 : model1 loss : 0.019553 model2 loss : 0.019756
[21:43:14.910] iteration 6727 : model1 loss : 0.067678 model2 loss : 0.072016
[21:43:15.575] iteration 6728 : model1 loss : 0.020205 model2 loss : 0.020670
[21:43:16.224] iteration 6729 : model1 loss : 0.026285 model2 loss : 0.027985
[21:43:16.878] iteration 6730 : model1 loss : 0.028140 model2 loss : 0.028429
[21:43:17.540] iteration 6731 : model1 loss : 0.023690 model2 loss : 0.025091
[21:43:18.197] iteration 6732 : model1 loss : 0.022015 model2 loss : 0.030843
[21:43:18.849] iteration 6733 : model1 loss : 0.035737 model2 loss : 0.035746
[21:43:19.521] iteration 6734 : model1 loss : 0.025647 model2 loss : 0.032543
[21:43:20.177] iteration 6735 : model1 loss : 0.046569 model2 loss : 0.071633
[21:43:20.834] iteration 6736 : model1 loss : 0.090617 model2 loss : 0.053055
[21:43:21.503] iteration 6737 : model1 loss : 0.019291 model2 loss : 0.020956
[21:43:22.171] iteration 6738 : model1 loss : 0.024501 model2 loss : 0.023010
[21:43:22.832] iteration 6739 : model1 loss : 0.021717 model2 loss : 0.023901
[21:43:23.491] iteration 6740 : model1 loss : 0.181953 model2 loss : 0.179131
[21:43:24.147] iteration 6741 : model1 loss : 0.029927 model2 loss : 0.028157
[21:43:24.810] iteration 6742 : model1 loss : 0.041717 model2 loss : 0.030148
[21:43:25.471] iteration 6743 : model1 loss : 0.018430 model2 loss : 0.020169
[21:43:26.140] iteration 6744 : model1 loss : 0.043771 model2 loss : 0.048963
[21:43:26.791] iteration 6745 : model1 loss : 0.031057 model2 loss : 0.028601
[21:43:27.437] iteration 6746 : model1 loss : 0.028041 model2 loss : 0.026067
[21:43:28.098] iteration 6747 : model1 loss : 0.022919 model2 loss : 0.018906
[21:43:28.766] iteration 6748 : model1 loss : 0.020409 model2 loss : 0.022524
[21:43:29.414] iteration 6749 : model1 loss : 0.031324 model2 loss : 0.042613
[21:43:30.077] iteration 6750 : model1 loss : 0.031709 model2 loss : 0.029046
[21:43:30.781] iteration 6751 : model1 loss : 0.034428 model2 loss : 0.027668
[21:43:31.440] iteration 6752 : model1 loss : 0.052795 model2 loss : 0.041765
[21:43:32.086] iteration 6753 : model1 loss : 0.027047 model2 loss : 0.026379
[21:43:32.752] iteration 6754 : model1 loss : 0.043459 model2 loss : 0.050047
[21:43:33.423] iteration 6755 : model1 loss : 0.024470 model2 loss : 0.024362
[21:43:34.079] iteration 6756 : model1 loss : 0.022287 model2 loss : 0.023330
[21:43:34.738] iteration 6757 : model1 loss : 0.026854 model2 loss : 0.024233
[21:43:35.412] iteration 6758 : model1 loss : 0.028754 model2 loss : 0.030313
[21:43:36.067] iteration 6759 : model1 loss : 0.043608 model2 loss : 0.031250
[21:43:36.714] iteration 6760 : model1 loss : 0.031997 model2 loss : 0.028270
[21:43:37.382] iteration 6761 : model1 loss : 0.022959 model2 loss : 0.022220
[21:43:38.033] iteration 6762 : model1 loss : 0.038006 model2 loss : 0.036391
[21:43:38.711] iteration 6763 : model1 loss : 0.032117 model2 loss : 0.030774
[21:43:39.368] iteration 6764 : model1 loss : 0.044978 model2 loss : 0.051324
[21:43:40.020] iteration 6765 : model1 loss : 0.099080 model2 loss : 0.081109
[21:43:40.676] iteration 6766 : model1 loss : 0.039564 model2 loss : 0.097873
[21:43:41.323] iteration 6767 : model1 loss : 0.027159 model2 loss : 0.031059
[21:43:41.983] iteration 6768 : model1 loss : 0.035893 model2 loss : 0.036848
[21:43:42.636] iteration 6769 : model1 loss : 0.022796 model2 loss : 0.017626
[21:43:43.287] iteration 6770 : model1 loss : 0.033681 model2 loss : 0.023586
[21:43:43.961] iteration 6771 : model1 loss : 0.026942 model2 loss : 0.029494
[21:43:44.635] iteration 6772 : model1 loss : 0.031963 model2 loss : 0.028721
[21:43:45.291] iteration 6773 : model1 loss : 0.044572 model2 loss : 0.042221
[21:43:45.959] iteration 6774 : model1 loss : 0.028210 model2 loss : 0.025750
[21:43:46.623] iteration 6775 : model1 loss : 0.031281 model2 loss : 0.031283
[21:43:47.295] iteration 6776 : model1 loss : 0.026558 model2 loss : 0.028521
[21:43:47.955] iteration 6777 : model1 loss : 0.051523 model2 loss : 0.044603
[21:43:48.614] iteration 6778 : model1 loss : 0.026102 model2 loss : 0.024877
[21:43:49.286] iteration 6779 : model1 loss : 0.023279 model2 loss : 0.027838
[21:43:49.935] iteration 6780 : model1 loss : 0.019365 model2 loss : 0.020562
[21:43:50.591] iteration 6781 : model1 loss : 0.029554 model2 loss : 0.028714
[21:43:51.263] iteration 6782 : model1 loss : 0.073802 model2 loss : 0.085974
[21:43:51.932] iteration 6783 : model1 loss : 0.030798 model2 loss : 0.037147
[21:43:52.605] iteration 6784 : model1 loss : 0.024073 model2 loss : 0.024429
[21:43:53.261] iteration 6785 : model1 loss : 0.030695 model2 loss : 0.030519
[21:43:53.927] iteration 6786 : model1 loss : 0.024125 model2 loss : 0.022804
[21:43:54.587] iteration 6787 : model1 loss : 0.030168 model2 loss : 0.028022
[21:43:55.248] iteration 6788 : model1 loss : 0.026596 model2 loss : 0.025248
[21:43:55.920] iteration 6789 : model1 loss : 0.080685 model2 loss : 0.066828
[21:43:56.583] iteration 6790 : model1 loss : 0.030997 model2 loss : 0.026942
[21:43:57.238] iteration 6791 : model1 loss : 0.030516 model2 loss : 0.029263
[21:43:57.899] iteration 6792 : model1 loss : 0.022089 model2 loss : 0.021085
[21:43:58.566] iteration 6793 : model1 loss : 0.047493 model2 loss : 0.034014
[21:43:59.222] iteration 6794 : model1 loss : 0.024789 model2 loss : 0.043358
[21:43:59.886] iteration 6795 : model1 loss : 0.030642 model2 loss : 0.032595
[21:44:00.556] iteration 6796 : model1 loss : 0.034582 model2 loss : 0.029943
[21:44:01.223] iteration 6797 : model1 loss : 0.034329 model2 loss : 0.032215
[21:44:01.876] iteration 6798 : model1 loss : 0.026059 model2 loss : 0.029133
[21:44:02.545] iteration 6799 : model1 loss : 0.031655 model2 loss : 0.032238
[21:44:03.204] iteration 6800 : model1 loss : 0.027847 model2 loss : 0.024358
[21:44:21.212] iteration 6800 : model1_mean_dice : 0.835651 model1_mean_hd95 : 8.058272
[21:44:39.006] iteration 6800 : model2_mean_dice : 0.844200 model2_mean_hd95 : 5.428928
[21:44:39.671] iteration 6801 : model1 loss : 0.032215 model2 loss : 0.029378
[21:44:40.345] iteration 6802 : model1 loss : 0.034843 model2 loss : 0.040807
[21:44:40.996] iteration 6803 : model1 loss : 0.022423 model2 loss : 0.021323
[21:44:41.658] iteration 6804 : model1 loss : 0.021566 model2 loss : 0.022930
[21:44:42.319] iteration 6805 : model1 loss : 0.027959 model2 loss : 0.029951
[21:44:42.965] iteration 6806 : model1 loss : 0.031744 model2 loss : 0.031360
[21:44:43.622] iteration 6807 : model1 loss : 0.025180 model2 loss : 0.027071
[21:44:44.278] iteration 6808 : model1 loss : 0.034252 model2 loss : 0.032439
[21:44:44.961] iteration 6809 : model1 loss : 0.027417 model2 loss : 0.029836
[21:44:45.629] iteration 6810 : model1 loss : 0.025918 model2 loss : 0.027057
[21:44:46.269] iteration 6811 : model1 loss : 0.030681 model2 loss : 0.049971
[21:44:46.928] iteration 6812 : model1 loss : 0.041147 model2 loss : 0.031980
[21:44:47.585] iteration 6813 : model1 loss : 0.031318 model2 loss : 0.027917
[21:44:48.249] iteration 6814 : model1 loss : 0.028664 model2 loss : 0.071815
[21:44:48.912] iteration 6815 : model1 loss : 0.043769 model2 loss : 0.040777
[21:44:49.559] iteration 6816 : model1 loss : 0.032741 model2 loss : 0.030032
[21:44:50.216] iteration 6817 : model1 loss : 0.028410 model2 loss : 0.027642
[21:44:50.865] iteration 6818 : model1 loss : 0.080188 model2 loss : 0.089418
[21:44:51.526] iteration 6819 : model1 loss : 0.034497 model2 loss : 0.032671
[21:44:52.178] iteration 6820 : model1 loss : 0.035963 model2 loss : 0.038949
[21:44:52.835] iteration 6821 : model1 loss : 0.042918 model2 loss : 0.036275
[21:44:53.503] iteration 6822 : model1 loss : 0.033655 model2 loss : 0.034723
[21:44:54.163] iteration 6823 : model1 loss : 0.028369 model2 loss : 0.030048
[21:44:54.812] iteration 6824 : model1 loss : 0.022262 model2 loss : 0.029670
[21:44:55.472] iteration 6825 : model1 loss : 0.033406 model2 loss : 0.028855
[21:44:56.126] iteration 6826 : model1 loss : 0.038766 model2 loss : 0.075708
[21:44:56.787] iteration 6827 : model1 loss : 0.033393 model2 loss : 0.028250
[21:44:57.445] iteration 6828 : model1 loss : 0.033770 model2 loss : 0.026045
[21:44:58.103] iteration 6829 : model1 loss : 0.031166 model2 loss : 0.031763
[21:44:58.765] iteration 6830 : model1 loss : 0.020217 model2 loss : 0.022728
[21:44:59.416] iteration 6831 : model1 loss : 0.020250 model2 loss : 0.023403
[21:45:00.075] iteration 6832 : model1 loss : 0.031752 model2 loss : 0.028364
[21:45:00.732] iteration 6833 : model1 loss : 0.023067 model2 loss : 0.024782
[21:45:01.384] iteration 6834 : model1 loss : 0.030847 model2 loss : 0.036358
[21:45:02.036] iteration 6835 : model1 loss : 0.024155 model2 loss : 0.024859
[21:45:02.694] iteration 6836 : model1 loss : 0.023192 model2 loss : 0.021440
[21:45:03.346] iteration 6837 : model1 loss : 0.020587 model2 loss : 0.023689
[21:45:04.008] iteration 6838 : model1 loss : 0.025665 model2 loss : 0.024376
[21:45:04.655] iteration 6839 : model1 loss : 0.023798 model2 loss : 0.020739
[21:45:05.307] iteration 6840 : model1 loss : 0.043957 model2 loss : 0.060364
[21:45:05.961] iteration 6841 : model1 loss : 0.020411 model2 loss : 0.019715
[21:45:06.614] iteration 6842 : model1 loss : 0.035212 model2 loss : 0.034683
[21:45:07.267] iteration 6843 : model1 loss : 0.034589 model2 loss : 0.029396
[21:45:07.917] iteration 6844 : model1 loss : 0.024083 model2 loss : 0.026412
[21:45:08.575] iteration 6845 : model1 loss : 0.046967 model2 loss : 0.048758
[21:45:09.223] iteration 6846 : model1 loss : 0.029004 model2 loss : 0.025792
[21:45:09.871] iteration 6847 : model1 loss : 0.023500 model2 loss : 0.025959
[21:45:10.535] iteration 6848 : model1 loss : 0.034484 model2 loss : 0.042994
[21:45:11.179] iteration 6849 : model1 loss : 0.024194 model2 loss : 0.024531
[21:45:11.838] iteration 6850 : model1 loss : 0.027764 model2 loss : 0.024065
[21:45:12.541] iteration 6851 : model1 loss : 0.033094 model2 loss : 0.060439
[21:45:13.204] iteration 6852 : model1 loss : 0.028537 model2 loss : 0.031276
[21:45:13.853] iteration 6853 : model1 loss : 0.024552 model2 loss : 0.024942
[21:45:14.499] iteration 6854 : model1 loss : 0.024360 model2 loss : 0.026886
[21:45:15.147] iteration 6855 : model1 loss : 0.014260 model2 loss : 0.017922
[21:45:15.815] iteration 6856 : model1 loss : 0.030799 model2 loss : 0.030452
[21:45:16.488] iteration 6857 : model1 loss : 0.024987 model2 loss : 0.021390
[21:45:17.143] iteration 6858 : model1 loss : 0.027980 model2 loss : 0.031623
[21:45:17.798] iteration 6859 : model1 loss : 0.033774 model2 loss : 0.031458
[21:45:18.464] iteration 6860 : model1 loss : 0.028909 model2 loss : 0.037516
[21:45:19.107] iteration 6861 : model1 loss : 0.027729 model2 loss : 0.029081
[21:45:19.766] iteration 6862 : model1 loss : 0.025553 model2 loss : 0.039459
[21:45:20.427] iteration 6863 : model1 loss : 0.028504 model2 loss : 0.027782
[21:45:21.082] iteration 6864 : model1 loss : 0.028411 model2 loss : 0.040825
[21:45:21.741] iteration 6865 : model1 loss : 0.101201 model2 loss : 0.110434
[21:45:22.396] iteration 6866 : model1 loss : 0.164954 model2 loss : 0.126025
[21:45:23.049] iteration 6867 : model1 loss : 0.035571 model2 loss : 0.040740
[21:45:23.709] iteration 6868 : model1 loss : 0.027560 model2 loss : 0.027881
[21:45:24.370] iteration 6869 : model1 loss : 0.020293 model2 loss : 0.020231
[21:45:25.022] iteration 6870 : model1 loss : 0.024751 model2 loss : 0.024564
[21:45:25.688] iteration 6871 : model1 loss : 0.032087 model2 loss : 0.033282
[21:45:26.363] iteration 6872 : model1 loss : 0.042046 model2 loss : 0.057306
[21:45:27.021] iteration 6873 : model1 loss : 0.035044 model2 loss : 0.039326
[21:45:27.679] iteration 6874 : model1 loss : 0.022992 model2 loss : 0.029242
[21:45:28.350] iteration 6875 : model1 loss : 0.022841 model2 loss : 0.023225
[21:45:29.010] iteration 6876 : model1 loss : 0.024033 model2 loss : 0.027591
[21:45:29.674] iteration 6877 : model1 loss : 0.020491 model2 loss : 0.020576
[21:45:30.329] iteration 6878 : model1 loss : 0.025382 model2 loss : 0.029274
[21:45:30.983] iteration 6879 : model1 loss : 0.040477 model2 loss : 0.057802
[21:45:31.657] iteration 6880 : model1 loss : 0.031707 model2 loss : 0.030045
[21:45:32.305] iteration 6881 : model1 loss : 0.043761 model2 loss : 0.031161
[21:45:32.973] iteration 6882 : model1 loss : 0.027522 model2 loss : 0.031273
[21:45:33.632] iteration 6883 : model1 loss : 0.038204 model2 loss : 0.039354
[21:45:34.285] iteration 6884 : model1 loss : 0.031456 model2 loss : 0.036680
[21:45:34.955] iteration 6885 : model1 loss : 0.030165 model2 loss : 0.042458
[21:45:35.619] iteration 6886 : model1 loss : 0.020034 model2 loss : 0.021306
[21:45:36.287] iteration 6887 : model1 loss : 0.027964 model2 loss : 0.033242
[21:45:36.975] iteration 6888 : model1 loss : 0.031641 model2 loss : 0.030496
[21:45:37.634] iteration 6889 : model1 loss : 0.025030 model2 loss : 0.060265
[21:45:38.298] iteration 6890 : model1 loss : 0.040595 model2 loss : 0.040301
[21:45:38.958] iteration 6891 : model1 loss : 0.030126 model2 loss : 0.028813
[21:45:39.619] iteration 6892 : model1 loss : 0.027164 model2 loss : 0.027893
[21:45:40.297] iteration 6893 : model1 loss : 0.033145 model2 loss : 0.051474
[21:45:40.956] iteration 6894 : model1 loss : 0.024784 model2 loss : 0.028446
[21:45:41.612] iteration 6895 : model1 loss : 0.047387 model2 loss : 0.049227
[21:45:42.271] iteration 6896 : model1 loss : 0.025520 model2 loss : 0.028631
[21:45:42.918] iteration 6897 : model1 loss : 0.028050 model2 loss : 0.028656
[21:45:43.568] iteration 6898 : model1 loss : 0.033354 model2 loss : 0.036760
[21:45:44.221] iteration 6899 : model1 loss : 0.035238 model2 loss : 0.037044
[21:45:44.890] iteration 6900 : model1 loss : 0.028659 model2 loss : 0.032132
[21:45:45.597] iteration 6901 : model1 loss : 0.022084 model2 loss : 0.022835
[21:45:46.258] iteration 6902 : model1 loss : 0.028126 model2 loss : 0.028981
[21:45:46.918] iteration 6903 : model1 loss : 0.032955 model2 loss : 0.037342
[21:45:47.587] iteration 6904 : model1 loss : 0.025452 model2 loss : 0.027674
[21:45:48.247] iteration 6905 : model1 loss : 0.029009 model2 loss : 0.027935
[21:45:48.911] iteration 6906 : model1 loss : 0.023067 model2 loss : 0.044864
[21:45:49.579] iteration 6907 : model1 loss : 0.065346 model2 loss : 0.099651
[21:45:50.237] iteration 6908 : model1 loss : 0.021795 model2 loss : 0.027628
[21:45:50.887] iteration 6909 : model1 loss : 0.077907 model2 loss : 0.087190
[21:45:51.541] iteration 6910 : model1 loss : 0.032753 model2 loss : 0.034976
[21:45:52.192] iteration 6911 : model1 loss : 0.021359 model2 loss : 0.023609
[21:45:52.856] iteration 6912 : model1 loss : 0.026696 model2 loss : 0.025179
[21:45:53.526] iteration 6913 : model1 loss : 0.044752 model2 loss : 0.042418
[21:45:54.174] iteration 6914 : model1 loss : 0.022412 model2 loss : 0.025067
[21:45:54.822] iteration 6915 : model1 loss : 0.022142 model2 loss : 0.026666
[21:45:55.491] iteration 6916 : model1 loss : 0.032122 model2 loss : 0.035492
[21:45:56.157] iteration 6917 : model1 loss : 0.027042 model2 loss : 0.026717
[21:45:56.833] iteration 6918 : model1 loss : 0.025303 model2 loss : 0.030042
[21:45:57.501] iteration 6919 : model1 loss : 0.029683 model2 loss : 0.026303
[21:45:58.162] iteration 6920 : model1 loss : 0.023410 model2 loss : 0.027781
[21:45:58.829] iteration 6921 : model1 loss : 0.026392 model2 loss : 0.031930
[21:45:59.493] iteration 6922 : model1 loss : 0.028303 model2 loss : 0.026217
[21:46:00.148] iteration 6923 : model1 loss : 0.024366 model2 loss : 0.023658
[21:46:00.811] iteration 6924 : model1 loss : 0.048057 model2 loss : 0.069897
[21:46:01.474] iteration 6925 : model1 loss : 0.026524 model2 loss : 0.037486
[21:46:02.126] iteration 6926 : model1 loss : 0.019461 model2 loss : 0.021660
[21:46:02.785] iteration 6927 : model1 loss : 0.025310 model2 loss : 0.024542
[21:46:03.451] iteration 6928 : model1 loss : 0.022798 model2 loss : 0.026116
[21:46:04.126] iteration 6929 : model1 loss : 0.025501 model2 loss : 0.025518
[21:46:04.777] iteration 6930 : model1 loss : 0.038835 model2 loss : 0.040875
[21:46:05.431] iteration 6931 : model1 loss : 0.028109 model2 loss : 0.031361
[21:46:06.091] iteration 6932 : model1 loss : 0.052039 model2 loss : 0.053558
[21:46:06.760] iteration 6933 : model1 loss : 0.024377 model2 loss : 0.025738
[21:46:07.425] iteration 6934 : model1 loss : 0.026832 model2 loss : 0.025783
[21:46:08.090] iteration 6935 : model1 loss : 0.043423 model2 loss : 0.043621
[21:46:08.751] iteration 6936 : model1 loss : 0.085377 model2 loss : 0.133361
[21:46:09.428] iteration 6937 : model1 loss : 0.045689 model2 loss : 0.042648
[21:46:10.084] iteration 6938 : model1 loss : 0.062294 model2 loss : 0.066663
[21:46:10.739] iteration 6939 : model1 loss : 0.023796 model2 loss : 0.024980
[21:46:11.405] iteration 6940 : model1 loss : 0.035232 model2 loss : 0.040407
[21:46:12.060] iteration 6941 : model1 loss : 0.047130 model2 loss : 0.037513
[21:46:12.712] iteration 6942 : model1 loss : 0.026776 model2 loss : 0.024136
[21:46:13.371] iteration 6943 : model1 loss : 0.072083 model2 loss : 0.079196
[21:46:14.032] iteration 6944 : model1 loss : 0.036003 model2 loss : 0.027109
[21:46:14.696] iteration 6945 : model1 loss : 0.026629 model2 loss : 0.029584
[21:46:15.362] iteration 6946 : model1 loss : 0.029083 model2 loss : 0.022614
[21:46:16.037] iteration 6947 : model1 loss : 0.021534 model2 loss : 0.021750
[21:46:16.711] iteration 6948 : model1 loss : 0.024757 model2 loss : 0.026662
[21:46:17.364] iteration 6949 : model1 loss : 0.030602 model2 loss : 0.071807
[21:46:18.028] iteration 6950 : model1 loss : 0.031795 model2 loss : 0.039008
[21:46:18.755] iteration 6951 : model1 loss : 0.037009 model2 loss : 0.030919
[21:46:19.433] iteration 6952 : model1 loss : 0.053476 model2 loss : 0.048950
[21:46:20.106] iteration 6953 : model1 loss : 0.036084 model2 loss : 0.027991
[21:46:20.775] iteration 6954 : model1 loss : 0.027602 model2 loss : 0.031292
[21:46:21.474] iteration 6955 : model1 loss : 0.023235 model2 loss : 0.028073
[21:46:22.131] iteration 6956 : model1 loss : 0.061672 model2 loss : 0.021957
[21:46:22.819] iteration 6957 : model1 loss : 0.023811 model2 loss : 0.025487
[21:46:23.512] iteration 6958 : model1 loss : 0.027585 model2 loss : 0.025318
[21:46:24.198] iteration 6959 : model1 loss : 0.038947 model2 loss : 0.041028
[21:46:24.865] iteration 6960 : model1 loss : 0.021243 model2 loss : 0.023615
[21:46:25.522] iteration 6961 : model1 loss : 0.024468 model2 loss : 0.025875
[21:46:26.179] iteration 6962 : model1 loss : 0.024785 model2 loss : 0.021557
[21:46:26.834] iteration 6963 : model1 loss : 0.026057 model2 loss : 0.021935
[21:46:27.490] iteration 6964 : model1 loss : 0.061079 model2 loss : 0.028181
[21:46:28.148] iteration 6965 : model1 loss : 0.025487 model2 loss : 0.030761
[21:46:28.812] iteration 6966 : model1 loss : 0.026686 model2 loss : 0.024241
[21:46:29.464] iteration 6967 : model1 loss : 0.042213 model2 loss : 0.040057
[21:46:30.129] iteration 6968 : model1 loss : 0.025627 model2 loss : 0.024667
[21:46:30.778] iteration 6969 : model1 loss : 0.038581 model2 loss : 0.025615
[21:46:31.438] iteration 6970 : model1 loss : 0.027983 model2 loss : 0.029418
[21:46:32.112] iteration 6971 : model1 loss : 0.169524 model2 loss : 0.165064
[21:46:32.770] iteration 6972 : model1 loss : 0.039297 model2 loss : 0.035389
[21:46:33.441] iteration 6973 : model1 loss : 0.040699 model2 loss : 0.033749
[21:46:34.108] iteration 6974 : model1 loss : 0.028714 model2 loss : 0.026874
[21:46:34.756] iteration 6975 : model1 loss : 0.029526 model2 loss : 0.026899
[21:46:35.411] iteration 6976 : model1 loss : 0.033753 model2 loss : 0.034322
[21:46:36.069] iteration 6977 : model1 loss : 0.028041 model2 loss : 0.034287
[21:46:36.739] iteration 6978 : model1 loss : 0.044429 model2 loss : 0.044392
[21:46:37.401] iteration 6979 : model1 loss : 0.025610 model2 loss : 0.028855
[21:46:38.048] iteration 6980 : model1 loss : 0.023310 model2 loss : 0.021450
[21:46:38.708] iteration 6981 : model1 loss : 0.030644 model2 loss : 0.032467
[21:46:39.366] iteration 6982 : model1 loss : 0.034000 model2 loss : 0.045763
[21:46:40.017] iteration 6983 : model1 loss : 0.027758 model2 loss : 0.029889
[21:46:40.689] iteration 6984 : model1 loss : 0.034914 model2 loss : 0.035049
[21:46:41.348] iteration 6985 : model1 loss : 0.028686 model2 loss : 0.026197
[21:46:42.000] iteration 6986 : model1 loss : 0.031837 model2 loss : 0.027701
[21:46:42.690] iteration 6987 : model1 loss : 0.030873 model2 loss : 0.026044
[21:46:43.353] iteration 6988 : model1 loss : 0.026281 model2 loss : 0.028191
[21:46:44.003] iteration 6989 : model1 loss : 0.022234 model2 loss : 0.022300
[21:46:44.655] iteration 6990 : model1 loss : 0.034450 model2 loss : 0.032442
[21:46:45.332] iteration 6991 : model1 loss : 0.060055 model2 loss : 0.043056
[21:46:46.005] iteration 6992 : model1 loss : 0.025062 model2 loss : 0.023122
[21:46:46.676] iteration 6993 : model1 loss : 0.027540 model2 loss : 0.021734
[21:46:47.356] iteration 6994 : model1 loss : 0.022403 model2 loss : 0.022089
[21:46:48.018] iteration 6995 : model1 loss : 0.029553 model2 loss : 0.039902
[21:46:48.688] iteration 6996 : model1 loss : 0.022167 model2 loss : 0.021278
[21:46:49.353] iteration 6997 : model1 loss : 0.028250 model2 loss : 0.029434
[21:46:50.012] iteration 6998 : model1 loss : 0.026032 model2 loss : 0.028386
[21:46:50.675] iteration 6999 : model1 loss : 0.024159 model2 loss : 0.024847
[21:46:51.334] iteration 7000 : model1 loss : 0.025517 model2 loss : 0.026926
[21:47:09.441] iteration 7000 : model1_mean_dice : 0.819431 model1_mean_hd95 : 16.567996
[21:47:27.481] iteration 7000 : model2_mean_dice : 0.852149 model2_mean_hd95 : 3.912044
[21:47:28.168] iteration 7001 : model1 loss : 0.045548 model2 loss : 0.038955
[21:47:28.828] iteration 7002 : model1 loss : 0.030597 model2 loss : 0.027777
[21:47:29.490] iteration 7003 : model1 loss : 0.023026 model2 loss : 0.019106
[21:47:30.157] iteration 7004 : model1 loss : 0.039149 model2 loss : 0.029608
[21:47:30.809] iteration 7005 : model1 loss : 0.026810 model2 loss : 0.026439
[21:47:31.467] iteration 7006 : model1 loss : 0.038790 model2 loss : 0.023316
[21:47:32.127] iteration 7007 : model1 loss : 0.034690 model2 loss : 0.036287
[21:47:32.784] iteration 7008 : model1 loss : 0.028208 model2 loss : 0.024394
[21:47:33.442] iteration 7009 : model1 loss : 0.019641 model2 loss : 0.021844
[21:47:34.105] iteration 7010 : model1 loss : 0.030872 model2 loss : 0.027501
[21:47:34.773] iteration 7011 : model1 loss : 0.035107 model2 loss : 0.032110
[21:47:35.422] iteration 7012 : model1 loss : 0.022593 model2 loss : 0.020195
[21:47:36.084] iteration 7013 : model1 loss : 0.026322 model2 loss : 0.023846
[21:47:36.752] iteration 7014 : model1 loss : 0.029922 model2 loss : 0.033773
[21:47:37.408] iteration 7015 : model1 loss : 0.061443 model2 loss : 0.046789
[21:47:38.060] iteration 7016 : model1 loss : 0.019113 model2 loss : 0.019696
[21:47:38.712] iteration 7017 : model1 loss : 0.036792 model2 loss : 0.039971
[21:47:39.375] iteration 7018 : model1 loss : 0.027511 model2 loss : 0.025215
[21:47:40.026] iteration 7019 : model1 loss : 0.036692 model2 loss : 0.024662
[21:47:40.681] iteration 7020 : model1 loss : 0.033687 model2 loss : 0.030949
[21:47:41.339] iteration 7021 : model1 loss : 0.022060 model2 loss : 0.023132
[21:47:42.002] iteration 7022 : model1 loss : 0.035523 model2 loss : 0.032853
[21:47:42.659] iteration 7023 : model1 loss : 0.020419 model2 loss : 0.019812
[21:47:43.331] iteration 7024 : model1 loss : 0.025478 model2 loss : 0.022903
[21:47:44.023] iteration 7025 : model1 loss : 0.040347 model2 loss : 0.032567
[21:47:44.697] iteration 7026 : model1 loss : 0.030345 model2 loss : 0.028214
[21:47:45.356] iteration 7027 : model1 loss : 0.025818 model2 loss : 0.024793
[21:47:46.024] iteration 7028 : model1 loss : 0.066559 model2 loss : 0.040334
[21:47:46.683] iteration 7029 : model1 loss : 0.021813 model2 loss : 0.019931
[21:47:47.343] iteration 7030 : model1 loss : 0.040638 model2 loss : 0.042629
[21:47:47.988] iteration 7031 : model1 loss : 0.024006 model2 loss : 0.025024
[21:47:48.642] iteration 7032 : model1 loss : 0.022668 model2 loss : 0.025923
[21:47:49.306] iteration 7033 : model1 loss : 0.032798 model2 loss : 0.032710
[21:47:49.969] iteration 7034 : model1 loss : 0.026013 model2 loss : 0.026255
[21:47:50.628] iteration 7035 : model1 loss : 0.034357 model2 loss : 0.026517
[21:47:51.290] iteration 7036 : model1 loss : 0.021979 model2 loss : 0.023029
[21:47:51.936] iteration 7037 : model1 loss : 0.040184 model2 loss : 0.043011
[21:47:52.594] iteration 7038 : model1 loss : 0.033930 model2 loss : 0.027206
[21:47:53.253] iteration 7039 : model1 loss : 0.051753 model2 loss : 0.021807
[21:47:53.913] iteration 7040 : model1 loss : 0.040933 model2 loss : 0.034682
[21:47:54.572] iteration 7041 : model1 loss : 0.037938 model2 loss : 0.039513
[21:47:55.223] iteration 7042 : model1 loss : 0.052252 model2 loss : 0.043482
[21:47:55.887] iteration 7043 : model1 loss : 0.054945 model2 loss : 0.025688
[21:47:56.545] iteration 7044 : model1 loss : 0.047024 model2 loss : 0.037547
[21:47:57.208] iteration 7045 : model1 loss : 0.021926 model2 loss : 0.022617
[21:47:57.882] iteration 7046 : model1 loss : 0.028688 model2 loss : 0.032134
[21:47:58.542] iteration 7047 : model1 loss : 0.038931 model2 loss : 0.032543
[21:47:59.191] iteration 7048 : model1 loss : 0.026690 model2 loss : 0.034590
[21:47:59.862] iteration 7049 : model1 loss : 0.030457 model2 loss : 0.027278
[21:48:00.538] iteration 7050 : model1 loss : 0.024091 model2 loss : 0.024543
[21:48:01.261] iteration 7051 : model1 loss : 0.100899 model2 loss : 0.088991
[21:48:01.923] iteration 7052 : model1 loss : 0.027667 model2 loss : 0.030873
[21:48:02.596] iteration 7053 : model1 loss : 0.024077 model2 loss : 0.029146
[21:48:03.262] iteration 7054 : model1 loss : 0.039975 model2 loss : 0.031658
[21:48:03.915] iteration 7055 : model1 loss : 0.031125 model2 loss : 0.036546
[21:48:04.570] iteration 7056 : model1 loss : 0.025608 model2 loss : 0.027566
[21:48:05.239] iteration 7057 : model1 loss : 0.033726 model2 loss : 0.031649
[21:48:05.898] iteration 7058 : model1 loss : 0.035955 model2 loss : 0.035806
[21:48:06.568] iteration 7059 : model1 loss : 0.029868 model2 loss : 0.025372
[21:48:07.216] iteration 7060 : model1 loss : 0.038268 model2 loss : 0.039483
[21:48:07.883] iteration 7061 : model1 loss : 0.026451 model2 loss : 0.023953
[21:48:08.550] iteration 7062 : model1 loss : 0.027940 model2 loss : 0.027009
[21:48:09.203] iteration 7063 : model1 loss : 0.025314 model2 loss : 0.028635
[21:48:09.862] iteration 7064 : model1 loss : 0.028000 model2 loss : 0.023452
[21:48:10.523] iteration 7065 : model1 loss : 0.029756 model2 loss : 0.025093
[21:48:11.175] iteration 7066 : model1 loss : 0.026953 model2 loss : 0.033367
[21:48:11.833] iteration 7067 : model1 loss : 0.024679 model2 loss : 0.023026
[21:48:12.489] iteration 7068 : model1 loss : 0.032457 model2 loss : 0.027197
[21:48:13.148] iteration 7069 : model1 loss : 0.070067 model2 loss : 0.066335
[21:48:13.812] iteration 7070 : model1 loss : 0.028513 model2 loss : 0.035509
[21:48:14.486] iteration 7071 : model1 loss : 0.032182 model2 loss : 0.028689
[21:48:15.146] iteration 7072 : model1 loss : 0.035372 model2 loss : 0.020995
[21:48:15.815] iteration 7073 : model1 loss : 0.047718 model2 loss : 0.056481
[21:48:16.483] iteration 7074 : model1 loss : 0.035480 model2 loss : 0.032708
[21:48:17.146] iteration 7075 : model1 loss : 0.029059 model2 loss : 0.031228
[21:48:17.802] iteration 7076 : model1 loss : 0.024578 model2 loss : 0.032785
[21:48:18.461] iteration 7077 : model1 loss : 0.026562 model2 loss : 0.029077
[21:48:19.119] iteration 7078 : model1 loss : 0.058214 model2 loss : 0.030706
[21:48:19.783] iteration 7079 : model1 loss : 0.029868 model2 loss : 0.033917
[21:48:20.443] iteration 7080 : model1 loss : 0.021213 model2 loss : 0.019771
[21:48:21.102] iteration 7081 : model1 loss : 0.030368 model2 loss : 0.030585
[21:48:21.760] iteration 7082 : model1 loss : 0.023085 model2 loss : 0.025580
[21:48:22.425] iteration 7083 : model1 loss : 0.031707 model2 loss : 0.032477
[21:48:23.089] iteration 7084 : model1 loss : 0.030192 model2 loss : 0.031538
[21:48:23.739] iteration 7085 : model1 loss : 0.022062 model2 loss : 0.023873
[21:48:24.393] iteration 7086 : model1 loss : 0.029177 model2 loss : 0.029959
[21:48:25.055] iteration 7087 : model1 loss : 0.021329 model2 loss : 0.018841
[21:48:25.722] iteration 7088 : model1 loss : 0.026167 model2 loss : 0.030048
[21:48:26.412] iteration 7089 : model1 loss : 0.032466 model2 loss : 0.031679
[21:48:27.067] iteration 7090 : model1 loss : 0.026795 model2 loss : 0.024520
[21:48:27.728] iteration 7091 : model1 loss : 0.061534 model2 loss : 0.054827
[21:48:28.400] iteration 7092 : model1 loss : 0.032882 model2 loss : 0.032364
[21:48:29.053] iteration 7093 : model1 loss : 0.024888 model2 loss : 0.021534
[21:48:29.712] iteration 7094 : model1 loss : 0.037858 model2 loss : 0.039454
[21:48:30.362] iteration 7095 : model1 loss : 0.026931 model2 loss : 0.026209
[21:48:31.012] iteration 7096 : model1 loss : 0.022380 model2 loss : 0.026143
[21:48:31.678] iteration 7097 : model1 loss : 0.025442 model2 loss : 0.021277
[21:48:32.334] iteration 7098 : model1 loss : 0.030535 model2 loss : 0.029351
[21:48:32.988] iteration 7099 : model1 loss : 0.031389 model2 loss : 0.032558
[21:48:33.646] iteration 7100 : model1 loss : 0.029808 model2 loss : 0.047310
[21:48:34.343] iteration 7101 : model1 loss : 0.070726 model2 loss : 0.066449
[21:48:35.007] iteration 7102 : model1 loss : 0.031389 model2 loss : 0.032524
[21:48:35.668] iteration 7103 : model1 loss : 0.027324 model2 loss : 0.031677
[21:48:36.326] iteration 7104 : model1 loss : 0.028809 model2 loss : 0.029890
[21:48:36.994] iteration 7105 : model1 loss : 0.021300 model2 loss : 0.024810
[21:48:37.646] iteration 7106 : model1 loss : 0.025743 model2 loss : 0.031439
[21:48:38.318] iteration 7107 : model1 loss : 0.030182 model2 loss : 0.026036
[21:48:38.973] iteration 7108 : model1 loss : 0.028256 model2 loss : 0.031339
[21:48:39.628] iteration 7109 : model1 loss : 0.027236 model2 loss : 0.031071
[21:48:40.285] iteration 7110 : model1 loss : 0.165184 model2 loss : 0.146984
[21:48:40.931] iteration 7111 : model1 loss : 0.022559 model2 loss : 0.025085
[21:48:41.588] iteration 7112 : model1 loss : 0.025444 model2 loss : 0.022226
[21:48:42.246] iteration 7113 : model1 loss : 0.023846 model2 loss : 0.035276
[21:48:42.902] iteration 7114 : model1 loss : 0.017586 model2 loss : 0.017219
[21:48:43.565] iteration 7115 : model1 loss : 0.031033 model2 loss : 0.025139
[21:48:44.229] iteration 7116 : model1 loss : 0.047898 model2 loss : 0.043918
[21:48:44.892] iteration 7117 : model1 loss : 0.055509 model2 loss : 0.080148
[21:48:45.556] iteration 7118 : model1 loss : 0.148540 model2 loss : 0.161636
[21:48:46.222] iteration 7119 : model1 loss : 0.080385 model2 loss : 0.100601
[21:48:46.888] iteration 7120 : model1 loss : 0.031515 model2 loss : 0.032735
[21:48:47.550] iteration 7121 : model1 loss : 0.026485 model2 loss : 0.031437
[21:48:48.208] iteration 7122 : model1 loss : 0.037844 model2 loss : 0.045442
[21:48:48.866] iteration 7123 : model1 loss : 0.047418 model2 loss : 0.080637
[21:48:49.531] iteration 7124 : model1 loss : 0.026321 model2 loss : 0.033781
[21:48:50.189] iteration 7125 : model1 loss : 0.021750 model2 loss : 0.020044
[21:48:50.839] iteration 7126 : model1 loss : 0.031898 model2 loss : 0.032488
[21:48:51.503] iteration 7127 : model1 loss : 0.043607 model2 loss : 0.046603
[21:48:52.165] iteration 7128 : model1 loss : 0.084914 model2 loss : 0.122062
[21:48:52.822] iteration 7129 : model1 loss : 0.152457 model2 loss : 0.152350
[21:48:53.492] iteration 7130 : model1 loss : 0.030929 model2 loss : 0.036900
[21:48:54.143] iteration 7131 : model1 loss : 0.034809 model2 loss : 0.031226
[21:48:54.811] iteration 7132 : model1 loss : 0.039730 model2 loss : 0.037759
[21:48:55.487] iteration 7133 : model1 loss : 0.024743 model2 loss : 0.027689
[21:48:56.149] iteration 7134 : model1 loss : 0.029829 model2 loss : 0.026643
[21:48:56.802] iteration 7135 : model1 loss : 0.024541 model2 loss : 0.026996
[21:48:57.485] iteration 7136 : model1 loss : 0.040416 model2 loss : 0.035183
[21:48:58.145] iteration 7137 : model1 loss : 0.024710 model2 loss : 0.031051
[21:48:58.815] iteration 7138 : model1 loss : 0.026527 model2 loss : 0.025592
[21:48:59.479] iteration 7139 : model1 loss : 0.022329 model2 loss : 0.022489
[21:49:00.139] iteration 7140 : model1 loss : 0.020129 model2 loss : 0.019972
[21:49:00.799] iteration 7141 : model1 loss : 0.024947 model2 loss : 0.029500
[21:49:01.453] iteration 7142 : model1 loss : 0.025527 model2 loss : 0.025897
[21:49:02.113] iteration 7143 : model1 loss : 0.020296 model2 loss : 0.019276
[21:49:02.765] iteration 7144 : model1 loss : 0.154168 model2 loss : 0.151721
[21:49:03.433] iteration 7145 : model1 loss : 0.042101 model2 loss : 0.052807
[21:49:04.098] iteration 7146 : model1 loss : 0.028018 model2 loss : 0.029866
[21:49:04.754] iteration 7147 : model1 loss : 0.023876 model2 loss : 0.028457
[21:49:05.405] iteration 7148 : model1 loss : 0.031857 model2 loss : 0.036764
[21:49:06.065] iteration 7149 : model1 loss : 0.030427 model2 loss : 0.039365
[21:49:06.724] iteration 7150 : model1 loss : 0.028927 model2 loss : 0.031595
[21:49:07.408] iteration 7151 : model1 loss : 0.026970 model2 loss : 0.025868
[21:49:08.067] iteration 7152 : model1 loss : 0.027293 model2 loss : 0.024480
[21:49:08.730] iteration 7153 : model1 loss : 0.032522 model2 loss : 0.034895
[21:49:09.394] iteration 7154 : model1 loss : 0.023185 model2 loss : 0.030294
[21:49:10.055] iteration 7155 : model1 loss : 0.027199 model2 loss : 0.031261
[21:49:10.709] iteration 7156 : model1 loss : 0.026625 model2 loss : 0.033060
[21:49:11.372] iteration 7157 : model1 loss : 0.033564 model2 loss : 0.036622
[21:49:12.041] iteration 7158 : model1 loss : 0.034357 model2 loss : 0.032519
[21:49:12.723] iteration 7159 : model1 loss : 0.021113 model2 loss : 0.025173
[21:49:13.376] iteration 7160 : model1 loss : 0.039256 model2 loss : 0.035906
[21:49:14.029] iteration 7161 : model1 loss : 0.024990 model2 loss : 0.024237
[21:49:14.688] iteration 7162 : model1 loss : 0.028627 model2 loss : 0.025458
[21:49:15.356] iteration 7163 : model1 loss : 0.034908 model2 loss : 0.039784
[21:49:16.012] iteration 7164 : model1 loss : 0.031160 model2 loss : 0.029834
[21:49:16.685] iteration 7165 : model1 loss : 0.023224 model2 loss : 0.022057
[21:49:17.353] iteration 7166 : model1 loss : 0.037798 model2 loss : 0.037910
[21:49:18.007] iteration 7167 : model1 loss : 0.028313 model2 loss : 0.027781
[21:49:18.675] iteration 7168 : model1 loss : 0.039698 model2 loss : 0.033570
[21:49:19.348] iteration 7169 : model1 loss : 0.027561 model2 loss : 0.032148
[21:49:20.009] iteration 7170 : model1 loss : 0.055502 model2 loss : 0.052646
[21:49:20.680] iteration 7171 : model1 loss : 0.022450 model2 loss : 0.022032
[21:49:21.335] iteration 7172 : model1 loss : 0.045351 model2 loss : 0.051158
[21:49:22.006] iteration 7173 : model1 loss : 0.028835 model2 loss : 0.031636
[21:49:22.693] iteration 7174 : model1 loss : 0.023970 model2 loss : 0.022451
[21:49:23.355] iteration 7175 : model1 loss : 0.054425 model2 loss : 0.061084
[21:49:24.023] iteration 7176 : model1 loss : 0.033839 model2 loss : 0.045602
[21:49:24.679] iteration 7177 : model1 loss : 0.021393 model2 loss : 0.019725
[21:49:25.335] iteration 7178 : model1 loss : 0.038050 model2 loss : 0.032670
[21:49:25.990] iteration 7179 : model1 loss : 0.026687 model2 loss : 0.030621
[21:49:26.647] iteration 7180 : model1 loss : 0.040335 model2 loss : 0.044099
[21:49:27.316] iteration 7181 : model1 loss : 0.034303 model2 loss : 0.040765
[21:49:27.973] iteration 7182 : model1 loss : 0.021957 model2 loss : 0.019633
[21:49:28.651] iteration 7183 : model1 loss : 0.026269 model2 loss : 0.024927
[21:49:29.307] iteration 7184 : model1 loss : 0.026514 model2 loss : 0.024605
[21:49:29.972] iteration 7185 : model1 loss : 0.021804 model2 loss : 0.021813
[21:49:30.624] iteration 7186 : model1 loss : 0.041757 model2 loss : 0.046825
[21:49:31.280] iteration 7187 : model1 loss : 0.042841 model2 loss : 0.059604
[21:49:31.930] iteration 7188 : model1 loss : 0.019312 model2 loss : 0.026749
[21:49:32.593] iteration 7189 : model1 loss : 0.040204 model2 loss : 0.032915
[21:49:33.254] iteration 7190 : model1 loss : 0.023394 model2 loss : 0.024123
[21:49:33.908] iteration 7191 : model1 loss : 0.030699 model2 loss : 0.032815
[21:49:34.576] iteration 7192 : model1 loss : 0.030368 model2 loss : 0.045790
[21:49:35.245] iteration 7193 : model1 loss : 0.024514 model2 loss : 0.020852
[21:49:35.909] iteration 7194 : model1 loss : 0.021637 model2 loss : 0.020100
[21:49:36.564] iteration 7195 : model1 loss : 0.028099 model2 loss : 0.027674
[21:49:37.215] iteration 7196 : model1 loss : 0.029389 model2 loss : 0.022501
[21:49:37.867] iteration 7197 : model1 loss : 0.021169 model2 loss : 0.023013
[21:49:38.550] iteration 7198 : model1 loss : 0.030103 model2 loss : 0.033603
[21:49:39.201] iteration 7199 : model1 loss : 0.026544 model2 loss : 0.025665
[21:49:39.855] iteration 7200 : model1 loss : 0.022342 model2 loss : 0.023229
[21:49:57.918] iteration 7200 : model1_mean_dice : 0.833043 model1_mean_hd95 : 7.195367
[21:50:16.171] iteration 7200 : model2_mean_dice : 0.837779 model2_mean_hd95 : 15.830759
[21:50:16.861] iteration 7201 : model1 loss : 0.026294 model2 loss : 0.028247
[21:50:17.531] iteration 7202 : model1 loss : 0.037339 model2 loss : 0.031008
[21:50:18.183] iteration 7203 : model1 loss : 0.037836 model2 loss : 0.037913
[21:50:18.831] iteration 7204 : model1 loss : 0.026439 model2 loss : 0.027675
[21:50:19.488] iteration 7205 : model1 loss : 0.036012 model2 loss : 0.028866
[21:50:20.132] iteration 7206 : model1 loss : 0.044765 model2 loss : 0.065297
[21:50:20.774] iteration 7207 : model1 loss : 0.030461 model2 loss : 0.034062
[21:50:21.431] iteration 7208 : model1 loss : 0.022897 model2 loss : 0.027568
[21:50:22.081] iteration 7209 : model1 loss : 0.073412 model2 loss : 0.051701
[21:50:22.742] iteration 7210 : model1 loss : 0.019935 model2 loss : 0.026727
[21:50:23.389] iteration 7211 : model1 loss : 0.020804 model2 loss : 0.023595
[21:50:24.034] iteration 7212 : model1 loss : 0.027266 model2 loss : 0.027282
[21:50:24.681] iteration 7213 : model1 loss : 0.018911 model2 loss : 0.022591
[21:50:25.345] iteration 7214 : model1 loss : 0.035845 model2 loss : 0.030158
[21:50:26.003] iteration 7215 : model1 loss : 0.021400 model2 loss : 0.021206
[21:50:26.658] iteration 7216 : model1 loss : 0.022460 model2 loss : 0.023288
[21:50:27.321] iteration 7217 : model1 loss : 0.025553 model2 loss : 0.023810
[21:50:27.975] iteration 7218 : model1 loss : 0.023548 model2 loss : 0.022485
[21:50:28.652] iteration 7219 : model1 loss : 0.030528 model2 loss : 0.038106
[21:50:29.306] iteration 7220 : model1 loss : 0.038182 model2 loss : 0.032064
[21:50:29.959] iteration 7221 : model1 loss : 0.026548 model2 loss : 0.027829
[21:50:30.620] iteration 7222 : model1 loss : 0.020397 model2 loss : 0.019681
[21:50:31.279] iteration 7223 : model1 loss : 0.027632 model2 loss : 0.028545
[21:50:31.940] iteration 7224 : model1 loss : 0.022928 model2 loss : 0.028830
[21:50:32.615] iteration 7225 : model1 loss : 0.024917 model2 loss : 0.024754
[21:50:33.280] iteration 7226 : model1 loss : 0.066765 model2 loss : 0.054096
[21:50:33.933] iteration 7227 : model1 loss : 0.022680 model2 loss : 0.019574
[21:50:34.582] iteration 7228 : model1 loss : 0.028666 model2 loss : 0.030590
[21:50:35.236] iteration 7229 : model1 loss : 0.021641 model2 loss : 0.022157
[21:50:35.893] iteration 7230 : model1 loss : 0.019206 model2 loss : 0.020127
[21:50:36.536] iteration 7231 : model1 loss : 0.038022 model2 loss : 0.036766
[21:50:37.188] iteration 7232 : model1 loss : 0.022900 model2 loss : 0.022088
[21:50:37.844] iteration 7233 : model1 loss : 0.027086 model2 loss : 0.030382
[21:50:38.511] iteration 7234 : model1 loss : 0.030333 model2 loss : 0.039473
[21:50:39.163] iteration 7235 : model1 loss : 0.049234 model2 loss : 0.057083
[21:50:39.833] iteration 7236 : model1 loss : 0.031779 model2 loss : 0.051456
[21:50:40.507] iteration 7237 : model1 loss : 0.081403 model2 loss : 0.058128
[21:50:41.154] iteration 7238 : model1 loss : 0.018038 model2 loss : 0.017689
[21:50:41.818] iteration 7239 : model1 loss : 0.021105 model2 loss : 0.027839
[21:50:42.504] iteration 7240 : model1 loss : 0.028561 model2 loss : 0.033300
[21:50:43.165] iteration 7241 : model1 loss : 0.027561 model2 loss : 0.026637
[21:50:43.836] iteration 7242 : model1 loss : 0.032827 model2 loss : 0.029999
[21:50:44.488] iteration 7243 : model1 loss : 0.033562 model2 loss : 0.026620
[21:50:45.140] iteration 7244 : model1 loss : 0.024205 model2 loss : 0.027550
[21:50:45.790] iteration 7245 : model1 loss : 0.045564 model2 loss : 0.045808
[21:50:46.449] iteration 7246 : model1 loss : 0.020274 model2 loss : 0.024057
[21:50:47.104] iteration 7247 : model1 loss : 0.042190 model2 loss : 0.045862
[21:50:47.772] iteration 7248 : model1 loss : 0.030872 model2 loss : 0.028756
[21:50:48.424] iteration 7249 : model1 loss : 0.026033 model2 loss : 0.023564
[21:50:49.076] iteration 7250 : model1 loss : 0.036065 model2 loss : 0.040886
[21:50:49.786] iteration 7251 : model1 loss : 0.031807 model2 loss : 0.032914
[21:50:50.446] iteration 7252 : model1 loss : 0.033955 model2 loss : 0.033044
[21:50:51.099] iteration 7253 : model1 loss : 0.030789 model2 loss : 0.032567
[21:50:51.758] iteration 7254 : model1 loss : 0.023346 model2 loss : 0.024178
[21:50:52.427] iteration 7255 : model1 loss : 0.017509 model2 loss : 0.019102
[21:50:53.087] iteration 7256 : model1 loss : 0.020893 model2 loss : 0.021228
[21:50:53.740] iteration 7257 : model1 loss : 0.026160 model2 loss : 0.027114
[21:50:54.396] iteration 7258 : model1 loss : 0.031961 model2 loss : 0.037291
[21:50:55.051] iteration 7259 : model1 loss : 0.020983 model2 loss : 0.019759
[21:50:55.704] iteration 7260 : model1 loss : 0.017628 model2 loss : 0.018383
[21:50:56.372] iteration 7261 : model1 loss : 0.024370 model2 loss : 0.024994
[21:50:57.020] iteration 7262 : model1 loss : 0.022098 model2 loss : 0.021515
[21:50:57.678] iteration 7263 : model1 loss : 0.035089 model2 loss : 0.034647
[21:50:58.335] iteration 7264 : model1 loss : 0.021912 model2 loss : 0.022095
[21:50:59.013] iteration 7265 : model1 loss : 0.038229 model2 loss : 0.030204
[21:50:59.663] iteration 7266 : model1 loss : 0.026733 model2 loss : 0.044872
[21:51:00.322] iteration 7267 : model1 loss : 0.024102 model2 loss : 0.022719
[21:51:00.987] iteration 7268 : model1 loss : 0.026185 model2 loss : 0.037537
[21:51:01.638] iteration 7269 : model1 loss : 0.020173 model2 loss : 0.019536
[21:51:02.305] iteration 7270 : model1 loss : 0.046405 model2 loss : 0.046534
[21:51:02.962] iteration 7271 : model1 loss : 0.024753 model2 loss : 0.025132
[21:51:03.617] iteration 7272 : model1 loss : 0.028997 model2 loss : 0.035608
[21:51:04.272] iteration 7273 : model1 loss : 0.031286 model2 loss : 0.027941
[21:51:04.930] iteration 7274 : model1 loss : 0.025340 model2 loss : 0.026304
[21:51:05.598] iteration 7275 : model1 loss : 0.019210 model2 loss : 0.019993
[21:51:06.257] iteration 7276 : model1 loss : 0.021055 model2 loss : 0.020788
[21:51:06.916] iteration 7277 : model1 loss : 0.025271 model2 loss : 0.027414
[21:51:07.575] iteration 7278 : model1 loss : 0.024471 model2 loss : 0.023543
[21:51:08.229] iteration 7279 : model1 loss : 0.023111 model2 loss : 0.027105
[21:51:08.916] iteration 7280 : model1 loss : 0.025051 model2 loss : 0.027482
[21:51:09.562] iteration 7281 : model1 loss : 0.036853 model2 loss : 0.039054
[21:51:10.231] iteration 7282 : model1 loss : 0.025139 model2 loss : 0.023363
[21:51:10.894] iteration 7283 : model1 loss : 0.022391 model2 loss : 0.022737
[21:51:11.560] iteration 7284 : model1 loss : 0.030093 model2 loss : 0.028420
[21:51:12.213] iteration 7285 : model1 loss : 0.020050 model2 loss : 0.023088
[21:51:12.872] iteration 7286 : model1 loss : 0.029163 model2 loss : 0.040975
[21:51:13.521] iteration 7287 : model1 loss : 0.035202 model2 loss : 0.033952
[21:51:14.178] iteration 7288 : model1 loss : 0.020258 model2 loss : 0.018576
[21:51:14.834] iteration 7289 : model1 loss : 0.032959 model2 loss : 0.033317
[21:51:15.492] iteration 7290 : model1 loss : 0.023039 model2 loss : 0.025545
[21:51:16.152] iteration 7291 : model1 loss : 0.027104 model2 loss : 0.030638
[21:51:16.805] iteration 7292 : model1 loss : 0.018650 model2 loss : 0.018736
[21:51:17.466] iteration 7293 : model1 loss : 0.036351 model2 loss : 0.033463
[21:51:18.121] iteration 7294 : model1 loss : 0.032787 model2 loss : 0.042889
[21:51:18.777] iteration 7295 : model1 loss : 0.034851 model2 loss : 0.038293
[21:51:19.464] iteration 7296 : model1 loss : 0.024282 model2 loss : 0.021983
[21:51:20.130] iteration 7297 : model1 loss : 0.058541 model2 loss : 0.096839
[21:51:20.779] iteration 7298 : model1 loss : 0.024492 model2 loss : 0.023854
[21:51:21.442] iteration 7299 : model1 loss : 0.026392 model2 loss : 0.026526
[21:51:22.105] iteration 7300 : model1 loss : 0.028729 model2 loss : 0.025873
[21:51:22.817] iteration 7301 : model1 loss : 0.050705 model2 loss : 0.057739
[21:51:23.799] iteration 7302 : model1 loss : 0.034407 model2 loss : 0.036835
[21:51:24.483] iteration 7303 : model1 loss : 0.042661 model2 loss : 0.051683
[21:51:25.155] iteration 7304 : model1 loss : 0.032288 model2 loss : 0.035017
[21:51:25.826] iteration 7305 : model1 loss : 0.029042 model2 loss : 0.031418
[21:51:26.492] iteration 7306 : model1 loss : 0.036519 model2 loss : 0.040471
[21:51:27.161] iteration 7307 : model1 loss : 0.025873 model2 loss : 0.027923
[21:51:27.814] iteration 7308 : model1 loss : 0.022242 model2 loss : 0.032256
[21:51:28.482] iteration 7309 : model1 loss : 0.052033 model2 loss : 0.049606
[21:51:29.149] iteration 7310 : model1 loss : 0.024327 model2 loss : 0.024380
[21:51:29.812] iteration 7311 : model1 loss : 0.024083 model2 loss : 0.026086
[21:51:30.468] iteration 7312 : model1 loss : 0.034632 model2 loss : 0.038267
[21:51:31.117] iteration 7313 : model1 loss : 0.025313 model2 loss : 0.025929
[21:51:31.772] iteration 7314 : model1 loss : 0.022721 model2 loss : 0.023811
[21:51:32.450] iteration 7315 : model1 loss : 0.019062 model2 loss : 0.021768
[21:51:33.125] iteration 7316 : model1 loss : 0.029385 model2 loss : 0.030137
[21:51:33.791] iteration 7317 : model1 loss : 0.052784 model2 loss : 0.045541
[21:51:34.462] iteration 7318 : model1 loss : 0.030643 model2 loss : 0.031030
[21:51:35.117] iteration 7319 : model1 loss : 0.021858 model2 loss : 0.025261
[21:51:35.772] iteration 7320 : model1 loss : 0.053001 model2 loss : 0.036163
[21:51:36.452] iteration 7321 : model1 loss : 0.023926 model2 loss : 0.022053
[21:51:37.115] iteration 7322 : model1 loss : 0.026809 model2 loss : 0.025796
[21:51:37.772] iteration 7323 : model1 loss : 0.063815 model2 loss : 0.077561
[21:51:38.481] iteration 7324 : model1 loss : 0.036146 model2 loss : 0.029166
[21:51:39.153] iteration 7325 : model1 loss : 0.024592 model2 loss : 0.022475
[21:51:39.809] iteration 7326 : model1 loss : 0.039824 model2 loss : 0.033110
[21:51:40.468] iteration 7327 : model1 loss : 0.028567 model2 loss : 0.024847
[21:51:41.128] iteration 7328 : model1 loss : 0.029614 model2 loss : 0.040163
[21:51:41.784] iteration 7329 : model1 loss : 0.042523 model2 loss : 0.039335
[21:51:42.464] iteration 7330 : model1 loss : 0.028744 model2 loss : 0.030392
[21:51:43.126] iteration 7331 : model1 loss : 0.023378 model2 loss : 0.023964
[21:51:43.789] iteration 7332 : model1 loss : 0.023611 model2 loss : 0.024346
[21:51:44.454] iteration 7333 : model1 loss : 0.029137 model2 loss : 0.029807
[21:51:45.113] iteration 7334 : model1 loss : 0.028094 model2 loss : 0.032386
[21:51:45.771] iteration 7335 : model1 loss : 0.025626 model2 loss : 0.019511
[21:51:46.434] iteration 7336 : model1 loss : 0.028831 model2 loss : 0.026490
[21:51:47.096] iteration 7337 : model1 loss : 0.027993 model2 loss : 0.039553
[21:51:47.770] iteration 7338 : model1 loss : 0.023748 model2 loss : 0.023673
[21:51:48.437] iteration 7339 : model1 loss : 0.035584 model2 loss : 0.026961
[21:51:49.095] iteration 7340 : model1 loss : 0.025449 model2 loss : 0.028448
[21:51:49.761] iteration 7341 : model1 loss : 0.017363 model2 loss : 0.024141
[21:51:50.414] iteration 7342 : model1 loss : 0.025981 model2 loss : 0.026706
[21:51:51.078] iteration 7343 : model1 loss : 0.026997 model2 loss : 0.028876
[21:51:51.737] iteration 7344 : model1 loss : 0.021142 model2 loss : 0.023584
[21:51:52.394] iteration 7345 : model1 loss : 0.023829 model2 loss : 0.022983
[21:51:53.055] iteration 7346 : model1 loss : 0.028524 model2 loss : 0.032386
[21:51:53.721] iteration 7347 : model1 loss : 0.031956 model2 loss : 0.031026
[21:51:54.376] iteration 7348 : model1 loss : 0.035146 model2 loss : 0.037406
[21:51:55.044] iteration 7349 : model1 loss : 0.022635 model2 loss : 0.021427
[21:51:55.706] iteration 7350 : model1 loss : 0.035420 model2 loss : 0.023724
[21:51:56.420] iteration 7351 : model1 loss : 0.019756 model2 loss : 0.018651
[21:51:57.078] iteration 7352 : model1 loss : 0.026832 model2 loss : 0.021617
[21:51:57.727] iteration 7353 : model1 loss : 0.056617 model2 loss : 0.060655
[21:51:58.411] iteration 7354 : model1 loss : 0.025592 model2 loss : 0.027225
[21:51:59.073] iteration 7355 : model1 loss : 0.037759 model2 loss : 0.023072
[21:51:59.738] iteration 7356 : model1 loss : 0.021188 model2 loss : 0.023419
[21:52:00.389] iteration 7357 : model1 loss : 0.026493 model2 loss : 0.026049
[21:52:01.043] iteration 7358 : model1 loss : 0.024941 model2 loss : 0.027880
[21:52:01.701] iteration 7359 : model1 loss : 0.025477 model2 loss : 0.024256
[21:52:02.369] iteration 7360 : model1 loss : 0.042455 model2 loss : 0.039885
[21:52:03.022] iteration 7361 : model1 loss : 0.025060 model2 loss : 0.023503
[21:52:03.677] iteration 7362 : model1 loss : 0.023560 model2 loss : 0.022365
[21:52:04.351] iteration 7363 : model1 loss : 0.020770 model2 loss : 0.022686
[21:52:05.021] iteration 7364 : model1 loss : 0.034239 model2 loss : 0.039633
[21:52:05.682] iteration 7365 : model1 loss : 0.058046 model2 loss : 0.076869
[21:52:06.346] iteration 7366 : model1 loss : 0.025824 model2 loss : 0.031012
[21:52:07.009] iteration 7367 : model1 loss : 0.028403 model2 loss : 0.033571
[21:52:07.666] iteration 7368 : model1 loss : 0.018015 model2 loss : 0.019127
[21:52:08.320] iteration 7369 : model1 loss : 0.028522 model2 loss : 0.037823
[21:52:08.970] iteration 7370 : model1 loss : 0.032479 model2 loss : 0.033752
[21:52:09.627] iteration 7371 : model1 loss : 0.033520 model2 loss : 0.026207
[21:52:10.287] iteration 7372 : model1 loss : 0.044424 model2 loss : 0.028714
[21:52:10.941] iteration 7373 : model1 loss : 0.032719 model2 loss : 0.034426
[21:52:11.607] iteration 7374 : model1 loss : 0.020322 model2 loss : 0.022461
[21:52:12.259] iteration 7375 : model1 loss : 0.025500 model2 loss : 0.030994
[21:52:12.914] iteration 7376 : model1 loss : 0.019473 model2 loss : 0.018611
[21:52:13.570] iteration 7377 : model1 loss : 0.024117 model2 loss : 0.023165
[21:52:14.243] iteration 7378 : model1 loss : 0.021040 model2 loss : 0.021368
[21:52:14.906] iteration 7379 : model1 loss : 0.048020 model2 loss : 0.032381
[21:52:15.561] iteration 7380 : model1 loss : 0.023769 model2 loss : 0.024791
[21:52:16.224] iteration 7381 : model1 loss : 0.030487 model2 loss : 0.038128
[21:52:16.867] iteration 7382 : model1 loss : 0.026640 model2 loss : 0.031996
[21:52:17.536] iteration 7383 : model1 loss : 0.020321 model2 loss : 0.019727
[21:52:18.205] iteration 7384 : model1 loss : 0.027134 model2 loss : 0.033734
[21:52:18.863] iteration 7385 : model1 loss : 0.038208 model2 loss : 0.050116
[21:52:19.517] iteration 7386 : model1 loss : 0.025018 model2 loss : 0.026595
[21:52:20.170] iteration 7387 : model1 loss : 0.027242 model2 loss : 0.029718
[21:52:20.818] iteration 7388 : model1 loss : 0.025107 model2 loss : 0.024026
[21:52:21.477] iteration 7389 : model1 loss : 0.028151 model2 loss : 0.029592
[21:52:22.131] iteration 7390 : model1 loss : 0.024591 model2 loss : 0.035019
[21:52:22.797] iteration 7391 : model1 loss : 0.026123 model2 loss : 0.026401
[21:52:23.462] iteration 7392 : model1 loss : 0.025654 model2 loss : 0.026787
[21:52:24.109] iteration 7393 : model1 loss : 0.022895 model2 loss : 0.024915
[21:52:24.758] iteration 7394 : model1 loss : 0.024099 model2 loss : 0.025580
[21:52:25.427] iteration 7395 : model1 loss : 0.027611 model2 loss : 0.025999
[21:52:26.083] iteration 7396 : model1 loss : 0.024408 model2 loss : 0.023800
[21:52:26.742] iteration 7397 : model1 loss : 0.024154 model2 loss : 0.025113
[21:52:27.410] iteration 7398 : model1 loss : 0.030510 model2 loss : 0.031510
[21:52:28.066] iteration 7399 : model1 loss : 0.024692 model2 loss : 0.032409
[21:52:28.727] iteration 7400 : model1 loss : 0.022547 model2 loss : 0.024297
[21:52:46.882] iteration 7400 : model1_mean_dice : 0.837116 model1_mean_hd95 : 5.153666
[21:53:04.819] iteration 7400 : model2_mean_dice : 0.846782 model2_mean_hd95 : 4.562189
[21:53:05.509] iteration 7401 : model1 loss : 0.026911 model2 loss : 0.025920
[21:53:06.152] iteration 7402 : model1 loss : 0.022709 model2 loss : 0.018420
[21:53:06.805] iteration 7403 : model1 loss : 0.038391 model2 loss : 0.038152
[21:53:07.464] iteration 7404 : model1 loss : 0.028911 model2 loss : 0.028568
[21:53:08.110] iteration 7405 : model1 loss : 0.026099 model2 loss : 0.024121
[21:53:08.761] iteration 7406 : model1 loss : 0.026146 model2 loss : 0.026389
[21:53:09.423] iteration 7407 : model1 loss : 0.030300 model2 loss : 0.038478
[21:53:10.083] iteration 7408 : model1 loss : 0.038472 model2 loss : 0.036523
[21:53:10.750] iteration 7409 : model1 loss : 0.022191 model2 loss : 0.026438
[21:53:11.407] iteration 7410 : model1 loss : 0.026166 model2 loss : 0.025072
[21:53:12.062] iteration 7411 : model1 loss : 0.030558 model2 loss : 0.033894
[21:53:12.723] iteration 7412 : model1 loss : 0.029094 model2 loss : 0.029422
[21:53:13.385] iteration 7413 : model1 loss : 0.021913 model2 loss : 0.020821
[21:53:14.037] iteration 7414 : model1 loss : 0.027362 model2 loss : 0.029415
[21:53:14.693] iteration 7415 : model1 loss : 0.018947 model2 loss : 0.018381
[21:53:15.349] iteration 7416 : model1 loss : 0.025011 model2 loss : 0.024321
[21:53:15.992] iteration 7417 : model1 loss : 0.029794 model2 loss : 0.030487
[21:53:16.649] iteration 7418 : model1 loss : 0.029451 model2 loss : 0.026643
[21:53:17.315] iteration 7419 : model1 loss : 0.039341 model2 loss : 0.040880
[21:53:17.971] iteration 7420 : model1 loss : 0.022709 model2 loss : 0.022201
[21:53:18.625] iteration 7421 : model1 loss : 0.050386 model2 loss : 0.035091
[21:53:19.274] iteration 7422 : model1 loss : 0.026411 model2 loss : 0.024929
[21:53:19.928] iteration 7423 : model1 loss : 0.024371 model2 loss : 0.025428
[21:53:20.603] iteration 7424 : model1 loss : 0.051725 model2 loss : 0.053823
[21:53:21.269] iteration 7425 : model1 loss : 0.021847 model2 loss : 0.020145
[21:53:21.926] iteration 7426 : model1 loss : 0.058308 model2 loss : 0.062276
[21:53:22.601] iteration 7427 : model1 loss : 0.030944 model2 loss : 0.027033
[21:53:23.255] iteration 7428 : model1 loss : 0.023051 model2 loss : 0.023258
[21:53:23.908] iteration 7429 : model1 loss : 0.041689 model2 loss : 0.038991
[21:53:24.566] iteration 7430 : model1 loss : 0.032225 model2 loss : 0.032587
[21:53:25.224] iteration 7431 : model1 loss : 0.032148 model2 loss : 0.036752
[21:53:25.871] iteration 7432 : model1 loss : 0.025596 model2 loss : 0.031091
[21:53:26.523] iteration 7433 : model1 loss : 0.025590 model2 loss : 0.042257
[21:53:27.180] iteration 7434 : model1 loss : 0.030691 model2 loss : 0.027717
[21:53:27.831] iteration 7435 : model1 loss : 0.046276 model2 loss : 0.047723
[21:53:28.504] iteration 7436 : model1 loss : 0.030204 model2 loss : 0.029737
[21:53:29.160] iteration 7437 : model1 loss : 0.027031 model2 loss : 0.033628
[21:53:29.813] iteration 7438 : model1 loss : 0.021439 model2 loss : 0.023056
[21:53:30.472] iteration 7439 : model1 loss : 0.023054 model2 loss : 0.023643
[21:53:31.135] iteration 7440 : model1 loss : 0.036262 model2 loss : 0.028199
[21:53:31.786] iteration 7441 : model1 loss : 0.029544 model2 loss : 0.030030
[21:53:32.440] iteration 7442 : model1 loss : 0.026287 model2 loss : 0.024712
[21:53:33.087] iteration 7443 : model1 loss : 0.033924 model2 loss : 0.027602
[21:53:33.740] iteration 7444 : model1 loss : 0.026175 model2 loss : 0.025621
[21:53:34.399] iteration 7445 : model1 loss : 0.032743 model2 loss : 0.034397
[21:53:35.061] iteration 7446 : model1 loss : 0.028967 model2 loss : 0.025934
[21:53:35.725] iteration 7447 : model1 loss : 0.023272 model2 loss : 0.022456
[21:53:36.380] iteration 7448 : model1 loss : 0.036918 model2 loss : 0.034439
[21:53:37.039] iteration 7449 : model1 loss : 0.025286 model2 loss : 0.024823
[21:53:37.698] iteration 7450 : model1 loss : 0.064694 model2 loss : 0.037848
[21:53:38.403] iteration 7451 : model1 loss : 0.036893 model2 loss : 0.034215
[21:53:39.053] iteration 7452 : model1 loss : 0.023976 model2 loss : 0.027429
[21:53:39.722] iteration 7453 : model1 loss : 0.043190 model2 loss : 0.023422
[21:53:40.387] iteration 7454 : model1 loss : 0.019414 model2 loss : 0.020823
[21:53:41.039] iteration 7455 : model1 loss : 0.043719 model2 loss : 0.043620
[21:53:41.687] iteration 7456 : model1 loss : 0.024183 model2 loss : 0.029791
[21:53:42.338] iteration 7457 : model1 loss : 0.033659 model2 loss : 0.029074
[21:53:42.993] iteration 7458 : model1 loss : 0.024731 model2 loss : 0.025876
[21:53:43.653] iteration 7459 : model1 loss : 0.026041 model2 loss : 0.019775
[21:53:44.308] iteration 7460 : model1 loss : 0.028264 model2 loss : 0.021696
[21:53:44.957] iteration 7461 : model1 loss : 0.023792 model2 loss : 0.029311
[21:53:45.609] iteration 7462 : model1 loss : 0.067161 model2 loss : 0.060750
[21:53:46.275] iteration 7463 : model1 loss : 0.037981 model2 loss : 0.036744
[21:53:46.928] iteration 7464 : model1 loss : 0.028627 model2 loss : 0.026134
[21:53:47.590] iteration 7465 : model1 loss : 0.024876 model2 loss : 0.022182
[21:53:48.255] iteration 7466 : model1 loss : 0.028745 model2 loss : 0.027601
[21:53:48.942] iteration 7467 : model1 loss : 0.046669 model2 loss : 0.033485
[21:53:49.628] iteration 7468 : model1 loss : 0.032066 model2 loss : 0.023746
[21:53:50.284] iteration 7469 : model1 loss : 0.029931 model2 loss : 0.026732
[21:53:50.936] iteration 7470 : model1 loss : 0.025623 model2 loss : 0.025128
[21:53:51.586] iteration 7471 : model1 loss : 0.058308 model2 loss : 0.067880
[21:53:52.250] iteration 7472 : model1 loss : 0.029307 model2 loss : 0.024527
[21:53:52.911] iteration 7473 : model1 loss : 0.029039 model2 loss : 0.024143
[21:53:53.562] iteration 7474 : model1 loss : 0.024034 model2 loss : 0.025833
[21:53:54.222] iteration 7475 : model1 loss : 0.031232 model2 loss : 0.028511
[21:53:54.881] iteration 7476 : model1 loss : 0.022913 model2 loss : 0.024452
[21:53:55.555] iteration 7477 : model1 loss : 0.026470 model2 loss : 0.026540
[21:53:56.226] iteration 7478 : model1 loss : 0.066735 model2 loss : 0.078713
[21:53:56.882] iteration 7479 : model1 loss : 0.030555 model2 loss : 0.030918
[21:53:57.535] iteration 7480 : model1 loss : 0.025322 model2 loss : 0.022680
[21:53:58.189] iteration 7481 : model1 loss : 0.026142 model2 loss : 0.021323
[21:53:58.845] iteration 7482 : model1 loss : 0.018038 model2 loss : 0.016435
[21:53:59.501] iteration 7483 : model1 loss : 0.038884 model2 loss : 0.025271
[21:54:00.158] iteration 7484 : model1 loss : 0.024932 model2 loss : 0.022793
[21:54:00.825] iteration 7485 : model1 loss : 0.028083 model2 loss : 0.030558
[21:54:01.476] iteration 7486 : model1 loss : 0.027167 model2 loss : 0.024144
[21:54:02.144] iteration 7487 : model1 loss : 0.025498 model2 loss : 0.028288
[21:54:02.803] iteration 7488 : model1 loss : 0.023126 model2 loss : 0.022874
[21:54:03.464] iteration 7489 : model1 loss : 0.034179 model2 loss : 0.032420
[21:54:04.123] iteration 7490 : model1 loss : 0.019449 model2 loss : 0.017911
[21:54:04.770] iteration 7491 : model1 loss : 0.023641 model2 loss : 0.024243
[21:54:05.436] iteration 7492 : model1 loss : 0.018669 model2 loss : 0.018778
[21:54:06.116] iteration 7493 : model1 loss : 0.029856 model2 loss : 0.028910
[21:54:06.782] iteration 7494 : model1 loss : 0.040553 model2 loss : 0.041673
[21:54:07.444] iteration 7495 : model1 loss : 0.043306 model2 loss : 0.045496
[21:54:08.098] iteration 7496 : model1 loss : 0.023625 model2 loss : 0.022135
[21:54:08.782] iteration 7497 : model1 loss : 0.027162 model2 loss : 0.027963
[21:54:09.445] iteration 7498 : model1 loss : 0.020783 model2 loss : 0.021781
[21:54:10.105] iteration 7499 : model1 loss : 0.028857 model2 loss : 0.027050
[21:54:10.761] iteration 7500 : model1 loss : 0.026925 model2 loss : 0.030317
[21:54:11.460] iteration 7501 : model1 loss : 0.029247 model2 loss : 0.026696
[21:54:12.123] iteration 7502 : model1 loss : 0.029207 model2 loss : 0.034971
[21:54:12.777] iteration 7503 : model1 loss : 0.027973 model2 loss : 0.029449
[21:54:13.441] iteration 7504 : model1 loss : 0.026609 model2 loss : 0.026010
[21:54:14.093] iteration 7505 : model1 loss : 0.026434 model2 loss : 0.029552
[21:54:14.757] iteration 7506 : model1 loss : 0.037898 model2 loss : 0.038740
[21:54:15.409] iteration 7507 : model1 loss : 0.023904 model2 loss : 0.024135
[21:54:16.068] iteration 7508 : model1 loss : 0.034977 model2 loss : 0.036243
[21:54:16.730] iteration 7509 : model1 loss : 0.029714 model2 loss : 0.035380
[21:54:17.381] iteration 7510 : model1 loss : 0.027827 model2 loss : 0.029226
[21:54:18.050] iteration 7511 : model1 loss : 0.016763 model2 loss : 0.018108
[21:54:18.698] iteration 7512 : model1 loss : 0.020216 model2 loss : 0.018647
[21:54:19.352] iteration 7513 : model1 loss : 0.021105 model2 loss : 0.020307
[21:54:20.003] iteration 7514 : model1 loss : 0.022385 model2 loss : 0.023378
[21:54:20.661] iteration 7515 : model1 loss : 0.031918 model2 loss : 0.033219
[21:54:21.343] iteration 7516 : model1 loss : 0.057770 model2 loss : 0.041832
[21:54:22.005] iteration 7517 : model1 loss : 0.028167 model2 loss : 0.025641
[21:54:22.676] iteration 7518 : model1 loss : 0.032374 model2 loss : 0.033168
[21:54:23.335] iteration 7519 : model1 loss : 0.034021 model2 loss : 0.029174
[21:54:23.997] iteration 7520 : model1 loss : 0.020790 model2 loss : 0.019240
[21:54:24.651] iteration 7521 : model1 loss : 0.030702 model2 loss : 0.027195
[21:54:25.300] iteration 7522 : model1 loss : 0.043637 model2 loss : 0.036511
[21:54:25.963] iteration 7523 : model1 loss : 0.027098 model2 loss : 0.023397
[21:54:26.619] iteration 7524 : model1 loss : 0.034514 model2 loss : 0.035401
[21:54:27.274] iteration 7525 : model1 loss : 0.025258 model2 loss : 0.028596
[21:54:27.940] iteration 7526 : model1 loss : 0.021078 model2 loss : 0.021047
[21:54:28.605] iteration 7527 : model1 loss : 0.030074 model2 loss : 0.030184
[21:54:29.273] iteration 7528 : model1 loss : 0.021388 model2 loss : 0.021630
[21:54:29.930] iteration 7529 : model1 loss : 0.029730 model2 loss : 0.031014
[21:54:30.593] iteration 7530 : model1 loss : 0.021650 model2 loss : 0.026166
[21:54:31.260] iteration 7531 : model1 loss : 0.021401 model2 loss : 0.024782
[21:54:31.915] iteration 7532 : model1 loss : 0.024704 model2 loss : 0.036961
[21:54:32.579] iteration 7533 : model1 loss : 0.024490 model2 loss : 0.023964
[21:54:33.242] iteration 7534 : model1 loss : 0.063802 model2 loss : 0.064438
[21:54:33.910] iteration 7535 : model1 loss : 0.026461 model2 loss : 0.027637
[21:54:34.567] iteration 7536 : model1 loss : 0.028392 model2 loss : 0.038947
[21:54:35.253] iteration 7537 : model1 loss : 0.025742 model2 loss : 0.026219
[21:54:35.910] iteration 7538 : model1 loss : 0.023621 model2 loss : 0.019738
[21:54:36.575] iteration 7539 : model1 loss : 0.055843 model2 loss : 0.039556
[21:54:37.237] iteration 7540 : model1 loss : 0.024172 model2 loss : 0.014176
[21:54:37.901] iteration 7541 : model1 loss : 0.024365 model2 loss : 0.023291
[21:54:38.559] iteration 7542 : model1 loss : 0.028565 model2 loss : 0.029950
[21:54:39.227] iteration 7543 : model1 loss : 0.032693 model2 loss : 0.034463
[21:54:39.877] iteration 7544 : model1 loss : 0.037967 model2 loss : 0.035856
[21:54:40.538] iteration 7545 : model1 loss : 0.029466 model2 loss : 0.033262
[21:54:41.194] iteration 7546 : model1 loss : 0.034224 model2 loss : 0.037953
[21:54:41.845] iteration 7547 : model1 loss : 0.026978 model2 loss : 0.024617
[21:54:42.501] iteration 7548 : model1 loss : 0.023971 model2 loss : 0.024425
[21:54:43.159] iteration 7549 : model1 loss : 0.029000 model2 loss : 0.025150
[21:54:43.825] iteration 7550 : model1 loss : 0.028710 model2 loss : 0.029697
[21:54:44.536] iteration 7551 : model1 loss : 0.027590 model2 loss : 0.027668
[21:54:45.203] iteration 7552 : model1 loss : 0.030527 model2 loss : 0.038257
[21:54:45.853] iteration 7553 : model1 loss : 0.022696 model2 loss : 0.019690
[21:54:46.511] iteration 7554 : model1 loss : 0.035086 model2 loss : 0.036462
[21:54:47.180] iteration 7555 : model1 loss : 0.031378 model2 loss : 0.030405
[21:54:47.829] iteration 7556 : model1 loss : 0.032339 model2 loss : 0.030123
[21:54:48.475] iteration 7557 : model1 loss : 0.031669 model2 loss : 0.034784
[21:54:49.174] iteration 7558 : model1 loss : 0.139054 model2 loss : 0.144526
[21:54:49.835] iteration 7559 : model1 loss : 0.031269 model2 loss : 0.038242
[21:54:50.496] iteration 7560 : model1 loss : 0.032996 model2 loss : 0.028725
[21:54:51.149] iteration 7561 : model1 loss : 0.041755 model2 loss : 0.039345
[21:54:51.796] iteration 7562 : model1 loss : 0.026137 model2 loss : 0.022312
[21:54:52.476] iteration 7563 : model1 loss : 0.032264 model2 loss : 0.032283
[21:54:53.133] iteration 7564 : model1 loss : 0.042507 model2 loss : 0.029242
[21:54:53.790] iteration 7565 : model1 loss : 0.024451 model2 loss : 0.025509
[21:54:54.445] iteration 7566 : model1 loss : 0.034787 model2 loss : 0.036463
[21:54:55.100] iteration 7567 : model1 loss : 0.030757 model2 loss : 0.028121
[21:54:55.770] iteration 7568 : model1 loss : 0.063179 model2 loss : 0.051932
[21:54:56.437] iteration 7569 : model1 loss : 0.025788 model2 loss : 0.026699
[21:54:57.090] iteration 7570 : model1 loss : 0.026772 model2 loss : 0.025830
[21:54:57.746] iteration 7571 : model1 loss : 0.027519 model2 loss : 0.026003
[21:54:58.410] iteration 7572 : model1 loss : 0.022391 model2 loss : 0.022235
[21:54:59.092] iteration 7573 : model1 loss : 0.031202 model2 loss : 0.034339
[21:54:59.754] iteration 7574 : model1 loss : 0.052684 model2 loss : 0.021343
[21:55:00.407] iteration 7575 : model1 loss : 0.026040 model2 loss : 0.023270
[21:55:01.072] iteration 7576 : model1 loss : 0.035122 model2 loss : 0.023070
[21:55:01.739] iteration 7577 : model1 loss : 0.036765 model2 loss : 0.037400
[21:55:02.391] iteration 7578 : model1 loss : 0.025917 model2 loss : 0.028917
[21:55:03.054] iteration 7579 : model1 loss : 0.028332 model2 loss : 0.028830
[21:55:03.714] iteration 7580 : model1 loss : 0.048434 model2 loss : 0.030067
[21:55:04.371] iteration 7581 : model1 loss : 0.055193 model2 loss : 0.054039
[21:55:05.034] iteration 7582 : model1 loss : 0.034610 model2 loss : 0.027077
[21:55:05.694] iteration 7583 : model1 loss : 0.023814 model2 loss : 0.024041
[21:55:06.352] iteration 7584 : model1 loss : 0.029548 model2 loss : 0.029705
[21:55:07.010] iteration 7585 : model1 loss : 0.027352 model2 loss : 0.027420
[21:55:07.671] iteration 7586 : model1 loss : 0.033919 model2 loss : 0.027873
[21:55:08.328] iteration 7587 : model1 loss : 0.045198 model2 loss : 0.032798
[21:55:08.988] iteration 7588 : model1 loss : 0.029686 model2 loss : 0.025442
[21:55:09.659] iteration 7589 : model1 loss : 0.037115 model2 loss : 0.028713
[21:55:10.317] iteration 7590 : model1 loss : 0.056039 model2 loss : 0.045642
[21:55:10.971] iteration 7591 : model1 loss : 0.026692 model2 loss : 0.029967
[21:55:11.641] iteration 7592 : model1 loss : 0.024550 model2 loss : 0.027815
[21:55:12.298] iteration 7593 : model1 loss : 0.019707 model2 loss : 0.019567
[21:55:12.972] iteration 7594 : model1 loss : 0.025743 model2 loss : 0.026079
[21:55:13.624] iteration 7595 : model1 loss : 0.023561 model2 loss : 0.022596
[21:55:14.291] iteration 7596 : model1 loss : 0.031354 model2 loss : 0.028977
[21:55:14.950] iteration 7597 : model1 loss : 0.023143 model2 loss : 0.023129
[21:55:15.619] iteration 7598 : model1 loss : 0.021747 model2 loss : 0.020035
[21:55:16.283] iteration 7599 : model1 loss : 0.023528 model2 loss : 0.020941
[21:55:16.931] iteration 7600 : model1 loss : 0.038749 model2 loss : 0.033125
[21:55:35.035] iteration 7600 : model1_mean_dice : 0.842655 model1_mean_hd95 : 7.733498
[21:55:52.857] iteration 7600 : model2_mean_dice : 0.851360 model2_mean_hd95 : 5.463180
[21:55:53.551] iteration 7601 : model1 loss : 0.020674 model2 loss : 0.020247
[21:55:54.196] iteration 7602 : model1 loss : 0.032191 model2 loss : 0.078348
[21:55:54.853] iteration 7603 : model1 loss : 0.020436 model2 loss : 0.022773
[21:55:55.508] iteration 7604 : model1 loss : 0.030011 model2 loss : 0.031419
[21:55:56.170] iteration 7605 : model1 loss : 0.020072 model2 loss : 0.021540
[21:55:56.830] iteration 7606 : model1 loss : 0.049785 model2 loss : 0.054900
[21:55:57.511] iteration 7607 : model1 loss : 0.024841 model2 loss : 0.020477
[21:55:58.165] iteration 7608 : model1 loss : 0.033943 model2 loss : 0.034456
[21:55:58.816] iteration 7609 : model1 loss : 0.027636 model2 loss : 0.026818
[21:55:59.470] iteration 7610 : model1 loss : 0.028083 model2 loss : 0.026510
[21:56:00.119] iteration 7611 : model1 loss : 0.018962 model2 loss : 0.021464
[21:56:00.762] iteration 7612 : model1 loss : 0.032222 model2 loss : 0.029482
[21:56:01.443] iteration 7613 : model1 loss : 0.030380 model2 loss : 0.029652
[21:56:02.098] iteration 7614 : model1 loss : 0.045510 model2 loss : 0.045895
[21:56:02.762] iteration 7615 : model1 loss : 0.030710 model2 loss : 0.027073
[21:56:03.427] iteration 7616 : model1 loss : 0.038764 model2 loss : 0.045751
[21:56:04.083] iteration 7617 : model1 loss : 0.061018 model2 loss : 0.095069
[21:56:04.730] iteration 7618 : model1 loss : 0.027169 model2 loss : 0.025311
[21:56:05.385] iteration 7619 : model1 loss : 0.024926 model2 loss : 0.028832
[21:56:06.043] iteration 7620 : model1 loss : 0.021295 model2 loss : 0.021031
[21:56:06.695] iteration 7621 : model1 loss : 0.035556 model2 loss : 0.034047
[21:56:07.366] iteration 7622 : model1 loss : 0.021871 model2 loss : 0.020850
[21:56:08.017] iteration 7623 : model1 loss : 0.024937 model2 loss : 0.025688
[21:56:08.670] iteration 7624 : model1 loss : 0.025426 model2 loss : 0.024470
[21:56:09.345] iteration 7625 : model1 loss : 0.022344 model2 loss : 0.022625
[21:56:09.999] iteration 7626 : model1 loss : 0.024944 model2 loss : 0.026275
[21:56:10.660] iteration 7627 : model1 loss : 0.021876 model2 loss : 0.028522
[21:56:11.322] iteration 7628 : model1 loss : 0.021843 model2 loss : 0.020781
[21:56:11.979] iteration 7629 : model1 loss : 0.037875 model2 loss : 0.044793
[21:56:12.635] iteration 7630 : model1 loss : 0.038440 model2 loss : 0.042739
[21:56:13.293] iteration 7631 : model1 loss : 0.026189 model2 loss : 0.026395
[21:56:13.944] iteration 7632 : model1 loss : 0.022818 model2 loss : 0.024046
[21:56:14.589] iteration 7633 : model1 loss : 0.022671 model2 loss : 0.023399
[21:56:15.257] iteration 7634 : model1 loss : 0.063488 model2 loss : 0.056274
[21:56:15.928] iteration 7635 : model1 loss : 0.022936 model2 loss : 0.021101
[21:56:16.586] iteration 7636 : model1 loss : 0.038384 model2 loss : 0.025782
[21:56:17.252] iteration 7637 : model1 loss : 0.021711 model2 loss : 0.021147
[21:56:17.904] iteration 7638 : model1 loss : 0.029011 model2 loss : 0.027522
[21:56:18.580] iteration 7639 : model1 loss : 0.155793 model2 loss : 0.154170
[21:56:19.243] iteration 7640 : model1 loss : 0.028677 model2 loss : 0.034817
[21:56:19.895] iteration 7641 : model1 loss : 0.018457 model2 loss : 0.018977
[21:56:20.542] iteration 7642 : model1 loss : 0.024754 model2 loss : 0.026874
[21:56:21.200] iteration 7643 : model1 loss : 0.032082 model2 loss : 0.027371
[21:56:21.858] iteration 7644 : model1 loss : 0.024396 model2 loss : 0.022809
[21:56:22.535] iteration 7645 : model1 loss : 0.036966 model2 loss : 0.046293
[21:56:23.190] iteration 7646 : model1 loss : 0.030854 model2 loss : 0.033548
[21:56:23.852] iteration 7647 : model1 loss : 0.017528 model2 loss : 0.020992
[21:56:24.501] iteration 7648 : model1 loss : 0.028943 model2 loss : 0.037921
[21:56:25.159] iteration 7649 : model1 loss : 0.023705 model2 loss : 0.021772
[21:56:25.825] iteration 7650 : model1 loss : 0.034208 model2 loss : 0.034579
[21:56:26.539] iteration 7651 : model1 loss : 0.025925 model2 loss : 0.026154
[21:56:27.200] iteration 7652 : model1 loss : 0.027061 model2 loss : 0.024753
[21:56:27.854] iteration 7653 : model1 loss : 0.019085 model2 loss : 0.019290
[21:56:28.512] iteration 7654 : model1 loss : 0.035107 model2 loss : 0.044076
[21:56:29.171] iteration 7655 : model1 loss : 0.025491 model2 loss : 0.030199
[21:56:29.837] iteration 7656 : model1 loss : 0.023131 model2 loss : 0.026182
[21:56:30.504] iteration 7657 : model1 loss : 0.023751 model2 loss : 0.023518
[21:56:31.165] iteration 7658 : model1 loss : 0.027539 model2 loss : 0.023465
[21:56:31.826] iteration 7659 : model1 loss : 0.028072 model2 loss : 0.032414
[21:56:32.510] iteration 7660 : model1 loss : 0.027349 model2 loss : 0.030109
[21:56:33.185] iteration 7661 : model1 loss : 0.032132 model2 loss : 0.035588
[21:56:33.845] iteration 7662 : model1 loss : 0.053861 model2 loss : 0.033207
[21:56:34.507] iteration 7663 : model1 loss : 0.025824 model2 loss : 0.024427
[21:56:35.171] iteration 7664 : model1 loss : 0.022665 model2 loss : 0.025654
[21:56:35.830] iteration 7665 : model1 loss : 0.024948 model2 loss : 0.023682
[21:56:36.487] iteration 7666 : model1 loss : 0.027431 model2 loss : 0.023196
[21:56:37.146] iteration 7667 : model1 loss : 0.024363 model2 loss : 0.020231
[21:56:37.813] iteration 7668 : model1 loss : 0.025770 model2 loss : 0.024841
[21:56:38.476] iteration 7669 : model1 loss : 0.037174 model2 loss : 0.057662
[21:56:39.146] iteration 7670 : model1 loss : 0.022303 model2 loss : 0.020981
[21:56:39.799] iteration 7671 : model1 loss : 0.033365 model2 loss : 0.033641
[21:56:40.473] iteration 7672 : model1 loss : 0.027747 model2 loss : 0.033157
[21:56:41.166] iteration 7673 : model1 loss : 0.020502 model2 loss : 0.021491
[21:56:41.814] iteration 7674 : model1 loss : 0.026836 model2 loss : 0.030007
[21:56:42.522] iteration 7675 : model1 loss : 0.018887 model2 loss : 0.021122
[21:56:43.223] iteration 7676 : model1 loss : 0.028073 model2 loss : 0.032168
[21:56:43.898] iteration 7677 : model1 loss : 0.027132 model2 loss : 0.028789
[21:56:44.559] iteration 7678 : model1 loss : 0.026241 model2 loss : 0.026419
[21:56:45.213] iteration 7679 : model1 loss : 0.025624 model2 loss : 0.021758
[21:56:45.895] iteration 7680 : model1 loss : 0.024333 model2 loss : 0.022804
[21:56:46.581] iteration 7681 : model1 loss : 0.038454 model2 loss : 0.032210
[21:56:47.269] iteration 7682 : model1 loss : 0.021497 model2 loss : 0.020965
[21:56:47.935] iteration 7683 : model1 loss : 0.022001 model2 loss : 0.021302
[21:56:48.597] iteration 7684 : model1 loss : 0.038886 model2 loss : 0.032342
[21:56:49.258] iteration 7685 : model1 loss : 0.032673 model2 loss : 0.036781
[21:56:49.942] iteration 7686 : model1 loss : 0.023702 model2 loss : 0.036592
[21:56:50.605] iteration 7687 : model1 loss : 0.077937 model2 loss : 0.096580
[21:56:51.307] iteration 7688 : model1 loss : 0.084478 model2 loss : 0.082034
[21:56:51.999] iteration 7689 : model1 loss : 0.022399 model2 loss : 0.021425
[21:56:52.676] iteration 7690 : model1 loss : 0.018906 model2 loss : 0.021899
[21:56:53.388] iteration 7691 : model1 loss : 0.033678 model2 loss : 0.025674
[21:56:54.080] iteration 7692 : model1 loss : 0.025768 model2 loss : 0.031840
[21:56:54.771] iteration 7693 : model1 loss : 0.035945 model2 loss : 0.034519
[21:56:55.431] iteration 7694 : model1 loss : 0.061883 model2 loss : 0.054114
[21:56:56.095] iteration 7695 : model1 loss : 0.044237 model2 loss : 0.040939
[21:56:56.752] iteration 7696 : model1 loss : 0.029351 model2 loss : 0.025675
[21:56:57.418] iteration 7697 : model1 loss : 0.022958 model2 loss : 0.022371
[21:56:58.069] iteration 7698 : model1 loss : 0.025688 model2 loss : 0.026684
[21:56:58.742] iteration 7699 : model1 loss : 0.152069 model2 loss : 0.148048
[21:56:59.404] iteration 7700 : model1 loss : 0.023220 model2 loss : 0.026925
[21:57:00.111] iteration 7701 : model1 loss : 0.030087 model2 loss : 0.044174
[21:57:00.774] iteration 7702 : model1 loss : 0.022896 model2 loss : 0.021924
[21:57:01.433] iteration 7703 : model1 loss : 0.042353 model2 loss : 0.048131
[21:57:02.104] iteration 7704 : model1 loss : 0.021864 model2 loss : 0.023375
[21:57:02.776] iteration 7705 : model1 loss : 0.039305 model2 loss : 0.042207
[21:57:03.443] iteration 7706 : model1 loss : 0.058644 model2 loss : 0.066651
[21:57:04.118] iteration 7707 : model1 loss : 0.039906 model2 loss : 0.042715
[21:57:04.785] iteration 7708 : model1 loss : 0.031687 model2 loss : 0.045026
[21:57:05.441] iteration 7709 : model1 loss : 0.024244 model2 loss : 0.069232
[21:57:06.096] iteration 7710 : model1 loss : 0.038349 model2 loss : 0.031143
[21:57:06.756] iteration 7711 : model1 loss : 0.156192 model2 loss : 0.111165
[21:57:07.429] iteration 7712 : model1 loss : 0.039533 model2 loss : 0.042573
[21:57:08.089] iteration 7713 : model1 loss : 0.034878 model2 loss : 0.034739
[21:57:08.759] iteration 7714 : model1 loss : 0.033810 model2 loss : 0.036549
[21:57:09.421] iteration 7715 : model1 loss : 0.060846 model2 loss : 0.066327
[21:57:10.086] iteration 7716 : model1 loss : 0.027912 model2 loss : 0.032933
[21:57:10.753] iteration 7717 : model1 loss : 0.024244 model2 loss : 0.023762
[21:57:11.411] iteration 7718 : model1 loss : 0.027919 model2 loss : 0.037068
[21:57:12.066] iteration 7719 : model1 loss : 0.040276 model2 loss : 0.063104
[21:57:12.731] iteration 7720 : model1 loss : 0.022052 model2 loss : 0.023772
[21:57:13.384] iteration 7721 : model1 loss : 0.024763 model2 loss : 0.034027
[21:57:14.046] iteration 7722 : model1 loss : 0.026036 model2 loss : 0.026189
[21:57:14.701] iteration 7723 : model1 loss : 0.033402 model2 loss : 0.041844
[21:57:15.350] iteration 7724 : model1 loss : 0.032445 model2 loss : 0.033947
[21:57:15.996] iteration 7725 : model1 loss : 0.072775 model2 loss : 0.085569
[21:57:16.655] iteration 7726 : model1 loss : 0.147292 model2 loss : 0.154630
[21:57:17.306] iteration 7727 : model1 loss : 0.024569 model2 loss : 0.025609
[21:57:17.958] iteration 7728 : model1 loss : 0.026283 model2 loss : 0.024765
[21:57:18.621] iteration 7729 : model1 loss : 0.025794 model2 loss : 0.032904
[21:57:19.285] iteration 7730 : model1 loss : 0.027040 model2 loss : 0.032624
[21:57:19.941] iteration 7731 : model1 loss : 0.030108 model2 loss : 0.030059
[21:57:20.602] iteration 7732 : model1 loss : 0.041380 model2 loss : 0.042805
[21:57:21.255] iteration 7733 : model1 loss : 0.064151 model2 loss : 0.075158
[21:57:21.910] iteration 7734 : model1 loss : 0.027205 model2 loss : 0.025813
[21:57:22.580] iteration 7735 : model1 loss : 0.051912 model2 loss : 0.062151
[21:57:23.245] iteration 7736 : model1 loss : 0.028116 model2 loss : 0.027601
[21:57:23.899] iteration 7737 : model1 loss : 0.028509 model2 loss : 0.026559
[21:57:24.570] iteration 7738 : model1 loss : 0.028841 model2 loss : 0.029226
[21:57:25.216] iteration 7739 : model1 loss : 0.024833 model2 loss : 0.026459
[21:57:25.869] iteration 7740 : model1 loss : 0.019686 model2 loss : 0.021343
[21:57:26.528] iteration 7741 : model1 loss : 0.030084 model2 loss : 0.025100
[21:57:27.179] iteration 7742 : model1 loss : 0.024155 model2 loss : 0.027971
[21:57:27.833] iteration 7743 : model1 loss : 0.046645 model2 loss : 0.065905
[21:57:28.494] iteration 7744 : model1 loss : 0.027224 model2 loss : 0.022356
[21:57:29.150] iteration 7745 : model1 loss : 0.019509 model2 loss : 0.021459
[21:57:29.806] iteration 7746 : model1 loss : 0.042605 model2 loss : 0.050752
[21:57:30.465] iteration 7747 : model1 loss : 0.023886 model2 loss : 0.026214
[21:57:31.133] iteration 7748 : model1 loss : 0.046864 model2 loss : 0.032074
[21:57:31.787] iteration 7749 : model1 loss : 0.029156 model2 loss : 0.041015
[21:57:32.470] iteration 7750 : model1 loss : 0.029431 model2 loss : 0.047664
[21:57:33.170] iteration 7751 : model1 loss : 0.020839 model2 loss : 0.020540
[21:57:33.837] iteration 7752 : model1 loss : 0.027537 model2 loss : 0.028291
[21:57:34.494] iteration 7753 : model1 loss : 0.035729 model2 loss : 0.038218
[21:57:35.161] iteration 7754 : model1 loss : 0.021217 model2 loss : 0.022477
[21:57:35.828] iteration 7755 : model1 loss : 0.024050 model2 loss : 0.025931
[21:57:36.474] iteration 7756 : model1 loss : 0.021836 model2 loss : 0.020489
[21:57:37.134] iteration 7757 : model1 loss : 0.026953 model2 loss : 0.047293
[21:57:37.802] iteration 7758 : model1 loss : 0.026629 model2 loss : 0.027354
[21:57:38.465] iteration 7759 : model1 loss : 0.024662 model2 loss : 0.030555
[21:57:39.125] iteration 7760 : model1 loss : 0.040827 model2 loss : 0.046351
[21:57:39.777] iteration 7761 : model1 loss : 0.024996 model2 loss : 0.026686
[21:57:40.444] iteration 7762 : model1 loss : 0.022670 model2 loss : 0.025205
[21:57:41.101] iteration 7763 : model1 loss : 0.026485 model2 loss : 0.042082
[21:57:41.758] iteration 7764 : model1 loss : 0.030351 model2 loss : 0.031968
[21:57:42.438] iteration 7765 : model1 loss : 0.024003 model2 loss : 0.028811
[21:57:43.102] iteration 7766 : model1 loss : 0.020870 model2 loss : 0.020970
[21:57:43.769] iteration 7767 : model1 loss : 0.032238 model2 loss : 0.032630
[21:57:44.438] iteration 7768 : model1 loss : 0.029901 model2 loss : 0.044861
[21:57:45.096] iteration 7769 : model1 loss : 0.024150 model2 loss : 0.026228
[21:57:45.753] iteration 7770 : model1 loss : 0.022429 model2 loss : 0.024015
[21:57:46.433] iteration 7771 : model1 loss : 0.029371 model2 loss : 0.041848
[21:57:47.100] iteration 7772 : model1 loss : 0.024164 model2 loss : 0.029775
[21:57:47.758] iteration 7773 : model1 loss : 0.028133 model2 loss : 0.037111
[21:57:48.403] iteration 7774 : model1 loss : 0.034144 model2 loss : 0.035366
[21:57:49.058] iteration 7775 : model1 loss : 0.031686 model2 loss : 0.029992
[21:57:49.723] iteration 7776 : model1 loss : 0.023756 model2 loss : 0.026639
[21:57:50.412] iteration 7777 : model1 loss : 0.028141 model2 loss : 0.039651
[21:57:51.083] iteration 7778 : model1 loss : 0.025303 model2 loss : 0.038925
[21:57:51.751] iteration 7779 : model1 loss : 0.021557 model2 loss : 0.022847
[21:57:52.431] iteration 7780 : model1 loss : 0.026306 model2 loss : 0.030110
[21:57:53.089] iteration 7781 : model1 loss : 0.024263 model2 loss : 0.029069
[21:57:53.745] iteration 7782 : model1 loss : 0.028434 model2 loss : 0.026475
[21:57:54.413] iteration 7783 : model1 loss : 0.021048 model2 loss : 0.022886
[21:57:55.070] iteration 7784 : model1 loss : 0.018713 model2 loss : 0.022832
[21:57:55.738] iteration 7785 : model1 loss : 0.044899 model2 loss : 0.047508
[21:57:56.399] iteration 7786 : model1 loss : 0.029135 model2 loss : 0.030145
[21:57:57.070] iteration 7787 : model1 loss : 0.026160 model2 loss : 0.028962
[21:57:57.723] iteration 7788 : model1 loss : 0.022664 model2 loss : 0.024828
[21:57:58.376] iteration 7789 : model1 loss : 0.033518 model2 loss : 0.028402
[21:57:59.031] iteration 7790 : model1 loss : 0.049479 model2 loss : 0.060544
[21:57:59.692] iteration 7791 : model1 loss : 0.025385 model2 loss : 0.030336
[21:58:00.351] iteration 7792 : model1 loss : 0.029493 model2 loss : 0.029250
[21:58:01.028] iteration 7793 : model1 loss : 0.020010 model2 loss : 0.020482
[21:58:01.689] iteration 7794 : model1 loss : 0.039931 model2 loss : 0.032865
[21:58:02.357] iteration 7795 : model1 loss : 0.032443 model2 loss : 0.029046
[21:58:03.006] iteration 7796 : model1 loss : 0.023845 model2 loss : 0.023842
[21:58:03.659] iteration 7797 : model1 loss : 0.030188 model2 loss : 0.028958
[21:58:04.317] iteration 7798 : model1 loss : 0.019455 model2 loss : 0.018800
[21:58:04.965] iteration 7799 : model1 loss : 0.025470 model2 loss : 0.023434
[21:58:05.634] iteration 7800 : model1 loss : 0.078593 model2 loss : 0.098880
[21:58:23.609] iteration 7800 : model1_mean_dice : 0.847098 model1_mean_hd95 : 6.898081
[21:58:41.549] iteration 7800 : model2_mean_dice : 0.838943 model2_mean_hd95 : 9.622845
[21:58:42.237] iteration 7801 : model1 loss : 0.047969 model2 loss : 0.036117
[21:58:42.890] iteration 7802 : model1 loss : 0.031548 model2 loss : 0.032926
[21:58:43.539] iteration 7803 : model1 loss : 0.027381 model2 loss : 0.024778
[21:58:44.193] iteration 7804 : model1 loss : 0.018651 model2 loss : 0.018866
[21:58:44.838] iteration 7805 : model1 loss : 0.025055 model2 loss : 0.031731
[21:58:45.491] iteration 7806 : model1 loss : 0.029127 model2 loss : 0.026176
[21:58:46.144] iteration 7807 : model1 loss : 0.027859 model2 loss : 0.028576
[21:58:46.803] iteration 7808 : model1 loss : 0.032262 model2 loss : 0.027497
[21:58:47.454] iteration 7809 : model1 loss : 0.030118 model2 loss : 0.030854
[21:58:48.119] iteration 7810 : model1 loss : 0.024922 model2 loss : 0.029987
[21:58:48.765] iteration 7811 : model1 loss : 0.042849 model2 loss : 0.047841
[21:58:49.421] iteration 7812 : model1 loss : 0.034235 model2 loss : 0.043316
[21:58:50.076] iteration 7813 : model1 loss : 0.027033 model2 loss : 0.029058
[21:58:50.724] iteration 7814 : model1 loss : 0.032611 model2 loss : 0.028104
[21:58:51.402] iteration 7815 : model1 loss : 0.033512 model2 loss : 0.037840
[21:58:52.064] iteration 7816 : model1 loss : 0.054418 model2 loss : 0.037399
[21:58:52.720] iteration 7817 : model1 loss : 0.037496 model2 loss : 0.032573
[21:58:53.380] iteration 7818 : model1 loss : 0.027540 model2 loss : 0.029580
[21:58:54.028] iteration 7819 : model1 loss : 0.037551 model2 loss : 0.031411
[21:58:54.683] iteration 7820 : model1 loss : 0.025597 model2 loss : 0.026180
[21:58:55.343] iteration 7821 : model1 loss : 0.037813 model2 loss : 0.034258
[21:58:56.002] iteration 7822 : model1 loss : 0.025295 model2 loss : 0.028154
[21:58:56.656] iteration 7823 : model1 loss : 0.021517 model2 loss : 0.022666
[21:58:57.310] iteration 7824 : model1 loss : 0.023721 model2 loss : 0.020918
[21:58:57.959] iteration 7825 : model1 loss : 0.042359 model2 loss : 0.048711
[21:58:58.643] iteration 7826 : model1 loss : 0.041288 model2 loss : 0.036085
[21:58:59.301] iteration 7827 : model1 loss : 0.026492 model2 loss : 0.024285
[21:58:59.953] iteration 7828 : model1 loss : 0.035651 model2 loss : 0.044481
[21:59:00.622] iteration 7829 : model1 loss : 0.032951 model2 loss : 0.029300
[21:59:01.285] iteration 7830 : model1 loss : 0.036864 model2 loss : 0.025595
[21:59:01.945] iteration 7831 : model1 loss : 0.025493 model2 loss : 0.024762
[21:59:02.611] iteration 7832 : model1 loss : 0.025049 model2 loss : 0.023570
[21:59:03.268] iteration 7833 : model1 loss : 0.026497 model2 loss : 0.026038
[21:59:03.929] iteration 7834 : model1 loss : 0.030545 model2 loss : 0.025697
[21:59:04.580] iteration 7835 : model1 loss : 0.035699 model2 loss : 0.042695
[21:59:05.243] iteration 7836 : model1 loss : 0.029398 model2 loss : 0.033410
[21:59:05.892] iteration 7837 : model1 loss : 0.019818 model2 loss : 0.019551
[21:59:06.553] iteration 7838 : model1 loss : 0.020781 model2 loss : 0.020122
[21:59:07.207] iteration 7839 : model1 loss : 0.030379 model2 loss : 0.029294
[21:59:07.856] iteration 7840 : model1 loss : 0.025022 model2 loss : 0.025294
[21:59:08.510] iteration 7841 : model1 loss : 0.023987 model2 loss : 0.029304
[21:59:09.170] iteration 7842 : model1 loss : 0.037069 model2 loss : 0.068906
[21:59:09.849] iteration 7843 : model1 loss : 0.019437 model2 loss : 0.017055
[21:59:10.533] iteration 7844 : model1 loss : 0.028504 model2 loss : 0.038454
[21:59:11.192] iteration 7845 : model1 loss : 0.029832 model2 loss : 0.034269
[21:59:11.848] iteration 7846 : model1 loss : 0.051268 model2 loss : 0.067063
[21:59:12.513] iteration 7847 : model1 loss : 0.021885 model2 loss : 0.026456
[21:59:13.179] iteration 7848 : model1 loss : 0.026854 model2 loss : 0.030186
[21:59:13.833] iteration 7849 : model1 loss : 0.032918 model2 loss : 0.030906
[21:59:14.493] iteration 7850 : model1 loss : 0.050794 model2 loss : 0.040927
[21:59:15.199] iteration 7851 : model1 loss : 0.017779 model2 loss : 0.019726
[21:59:15.857] iteration 7852 : model1 loss : 0.019704 model2 loss : 0.023130
[21:59:16.524] iteration 7853 : model1 loss : 0.020927 model2 loss : 0.022880
[21:59:17.194] iteration 7854 : model1 loss : 0.035750 model2 loss : 0.030997
[21:59:17.852] iteration 7855 : model1 loss : 0.027293 model2 loss : 0.024427
[21:59:18.517] iteration 7856 : model1 loss : 0.028017 model2 loss : 0.034976
[21:59:19.173] iteration 7857 : model1 loss : 0.022333 model2 loss : 0.026440
[21:59:19.833] iteration 7858 : model1 loss : 0.026987 model2 loss : 0.026631
[21:59:20.499] iteration 7859 : model1 loss : 0.028043 model2 loss : 0.024574
[21:59:21.169] iteration 7860 : model1 loss : 0.053122 model2 loss : 0.029866
[21:59:21.829] iteration 7861 : model1 loss : 0.029537 model2 loss : 0.025904
[21:59:22.490] iteration 7862 : model1 loss : 0.024019 model2 loss : 0.023488
[21:59:23.151] iteration 7863 : model1 loss : 0.024051 model2 loss : 0.026647
[21:59:23.814] iteration 7864 : model1 loss : 0.037710 model2 loss : 0.035426
[21:59:24.470] iteration 7865 : model1 loss : 0.022861 model2 loss : 0.024577
[21:59:25.140] iteration 7866 : model1 loss : 0.042710 model2 loss : 0.045006
[21:59:25.801] iteration 7867 : model1 loss : 0.039836 model2 loss : 0.032944
[21:59:26.463] iteration 7868 : model1 loss : 0.051045 model2 loss : 0.055213
[21:59:27.132] iteration 7869 : model1 loss : 0.025067 model2 loss : 0.027125
[21:59:27.801] iteration 7870 : model1 loss : 0.029955 model2 loss : 0.067094
[21:59:28.459] iteration 7871 : model1 loss : 0.027136 model2 loss : 0.022706
[21:59:29.122] iteration 7872 : model1 loss : 0.029104 model2 loss : 0.028887
[21:59:29.797] iteration 7873 : model1 loss : 0.021778 model2 loss : 0.023287
[21:59:30.478] iteration 7874 : model1 loss : 0.024170 model2 loss : 0.025920
[21:59:31.139] iteration 7875 : model1 loss : 0.025724 model2 loss : 0.028936
[21:59:31.799] iteration 7876 : model1 loss : 0.038963 model2 loss : 0.036694
[21:59:32.456] iteration 7877 : model1 loss : 0.023148 model2 loss : 0.025148
[21:59:33.113] iteration 7878 : model1 loss : 0.032854 model2 loss : 0.048645
[21:59:33.773] iteration 7879 : model1 loss : 0.023078 model2 loss : 0.020907
[21:59:34.433] iteration 7880 : model1 loss : 0.023167 model2 loss : 0.022455
[21:59:35.113] iteration 7881 : model1 loss : 0.025789 model2 loss : 0.028024
[21:59:35.772] iteration 7882 : model1 loss : 0.023591 model2 loss : 0.024147
[21:59:36.427] iteration 7883 : model1 loss : 0.025362 model2 loss : 0.028054
[21:59:37.086] iteration 7884 : model1 loss : 0.023369 model2 loss : 0.025140
[21:59:37.738] iteration 7885 : model1 loss : 0.020491 model2 loss : 0.022053
[21:59:38.405] iteration 7886 : model1 loss : 0.029961 model2 loss : 0.051497
[21:59:39.065] iteration 7887 : model1 loss : 0.037278 model2 loss : 0.042919
[21:59:39.743] iteration 7888 : model1 loss : 0.025496 model2 loss : 0.027359
[21:59:40.433] iteration 7889 : model1 loss : 0.031108 model2 loss : 0.039005
[21:59:41.109] iteration 7890 : model1 loss : 0.031502 model2 loss : 0.036224
[21:59:41.775] iteration 7891 : model1 loss : 0.020082 model2 loss : 0.019187
[21:59:42.451] iteration 7892 : model1 loss : 0.036204 model2 loss : 0.037018
[21:59:43.123] iteration 7893 : model1 loss : 0.027693 model2 loss : 0.026821
[21:59:43.787] iteration 7894 : model1 loss : 0.017840 model2 loss : 0.018917
[21:59:44.445] iteration 7895 : model1 loss : 0.027316 model2 loss : 0.032790
[21:59:45.102] iteration 7896 : model1 loss : 0.058094 model2 loss : 0.033513
[21:59:45.750] iteration 7897 : model1 loss : 0.023670 model2 loss : 0.023061
[21:59:46.403] iteration 7898 : model1 loss : 0.025387 model2 loss : 0.024920
[21:59:47.063] iteration 7899 : model1 loss : 0.022555 model2 loss : 0.026351
[21:59:47.716] iteration 7900 : model1 loss : 0.025725 model2 loss : 0.027637
[21:59:48.413] iteration 7901 : model1 loss : 0.027339 model2 loss : 0.034181
[21:59:49.067] iteration 7902 : model1 loss : 0.022110 model2 loss : 0.027685
[21:59:49.717] iteration 7903 : model1 loss : 0.026318 model2 loss : 0.027912
[21:59:50.396] iteration 7904 : model1 loss : 0.031851 model2 loss : 0.032921
[21:59:51.064] iteration 7905 : model1 loss : 0.151697 model2 loss : 0.152768
[21:59:51.738] iteration 7906 : model1 loss : 0.020241 model2 loss : 0.018320
[21:59:52.413] iteration 7907 : model1 loss : 0.023475 model2 loss : 0.022800
[21:59:53.072] iteration 7908 : model1 loss : 0.022201 model2 loss : 0.022483
[21:59:53.748] iteration 7909 : model1 loss : 0.112953 model2 loss : 0.092933
[21:59:54.420] iteration 7910 : model1 loss : 0.026538 model2 loss : 0.028738
[21:59:55.086] iteration 7911 : model1 loss : 0.027329 model2 loss : 0.028975
[21:59:55.752] iteration 7912 : model1 loss : 0.019804 model2 loss : 0.019084
[21:59:56.420] iteration 7913 : model1 loss : 0.030023 model2 loss : 0.029798
[21:59:57.089] iteration 7914 : model1 loss : 0.029377 model2 loss : 0.027883
[21:59:57.753] iteration 7915 : model1 loss : 0.026430 model2 loss : 0.023868
[21:59:58.406] iteration 7916 : model1 loss : 0.016500 model2 loss : 0.015845
[21:59:59.067] iteration 7917 : model1 loss : 0.021461 model2 loss : 0.024331
[21:59:59.739] iteration 7918 : model1 loss : 0.022321 model2 loss : 0.019933
[22:00:00.410] iteration 7919 : model1 loss : 0.047922 model2 loss : 0.034429
[22:00:01.060] iteration 7920 : model1 loss : 0.022599 model2 loss : 0.022575
[22:00:01.713] iteration 7921 : model1 loss : 0.024662 model2 loss : 0.026435
[22:00:02.371] iteration 7922 : model1 loss : 0.036393 model2 loss : 0.027708
[22:00:03.036] iteration 7923 : model1 loss : 0.023726 model2 loss : 0.025732
[22:00:03.694] iteration 7924 : model1 loss : 0.020857 model2 loss : 0.021154
[22:00:04.355] iteration 7925 : model1 loss : 0.031206 model2 loss : 0.044840
[22:00:05.011] iteration 7926 : model1 loss : 0.051959 model2 loss : 0.047478
[22:00:05.678] iteration 7927 : model1 loss : 0.034177 model2 loss : 0.035130
[22:00:06.333] iteration 7928 : model1 loss : 0.028089 model2 loss : 0.027472
[22:00:07.014] iteration 7929 : model1 loss : 0.027556 model2 loss : 0.028094
[22:00:07.670] iteration 7930 : model1 loss : 0.061956 model2 loss : 0.062788
[22:00:08.317] iteration 7931 : model1 loss : 0.026318 model2 loss : 0.024645
[22:00:08.976] iteration 7932 : model1 loss : 0.022551 model2 loss : 0.026639
[22:00:09.638] iteration 7933 : model1 loss : 0.026038 model2 loss : 0.030190
[22:00:10.299] iteration 7934 : model1 loss : 0.028589 model2 loss : 0.028939
[22:00:10.965] iteration 7935 : model1 loss : 0.050178 model2 loss : 0.047169
[22:00:11.629] iteration 7936 : model1 loss : 0.021104 model2 loss : 0.020062
[22:00:12.294] iteration 7937 : model1 loss : 0.037272 model2 loss : 0.024917
[22:00:12.947] iteration 7938 : model1 loss : 0.019142 model2 loss : 0.019313
[22:00:13.618] iteration 7939 : model1 loss : 0.022939 model2 loss : 0.021864
[22:00:14.272] iteration 7940 : model1 loss : 0.031298 model2 loss : 0.025012
[22:00:14.926] iteration 7941 : model1 loss : 0.018953 model2 loss : 0.021769
[22:00:15.575] iteration 7942 : model1 loss : 0.033407 model2 loss : 0.039082
[22:00:16.228] iteration 7943 : model1 loss : 0.020850 model2 loss : 0.023171
[22:00:16.922] iteration 7944 : model1 loss : 0.146204 model2 loss : 0.143249
[22:00:17.585] iteration 7945 : model1 loss : 0.021120 model2 loss : 0.020629
[22:00:18.261] iteration 7946 : model1 loss : 0.033310 model2 loss : 0.034110
[22:00:18.909] iteration 7947 : model1 loss : 0.032542 model2 loss : 0.030797
[22:00:19.569] iteration 7948 : model1 loss : 0.020588 model2 loss : 0.020568
[22:00:20.236] iteration 7949 : model1 loss : 0.019598 model2 loss : 0.020926
[22:00:20.896] iteration 7950 : model1 loss : 0.032355 model2 loss : 0.038996
[22:00:21.600] iteration 7951 : model1 loss : 0.030565 model2 loss : 0.028432
[22:00:22.262] iteration 7952 : model1 loss : 0.026418 model2 loss : 0.022982
[22:00:22.932] iteration 7953 : model1 loss : 0.033195 model2 loss : 0.029882
[22:00:23.608] iteration 7954 : model1 loss : 0.022712 model2 loss : 0.028772
[22:00:24.269] iteration 7955 : model1 loss : 0.034143 model2 loss : 0.034313
[22:00:24.925] iteration 7956 : model1 loss : 0.018679 model2 loss : 0.019604
[22:00:25.598] iteration 7957 : model1 loss : 0.024319 model2 loss : 0.023908
[22:00:26.251] iteration 7958 : model1 loss : 0.035624 model2 loss : 0.025667
[22:00:26.914] iteration 7959 : model1 loss : 0.022440 model2 loss : 0.025056
[22:00:27.576] iteration 7960 : model1 loss : 0.032083 model2 loss : 0.025750
[22:00:28.227] iteration 7961 : model1 loss : 0.028574 model2 loss : 0.039330
[22:00:28.894] iteration 7962 : model1 loss : 0.027952 model2 loss : 0.030918
[22:00:29.545] iteration 7963 : model1 loss : 0.022734 model2 loss : 0.023123
[22:00:30.211] iteration 7964 : model1 loss : 0.028908 model2 loss : 0.028899
[22:00:30.875] iteration 7965 : model1 loss : 0.023673 model2 loss : 0.024446
[22:00:31.533] iteration 7966 : model1 loss : 0.042276 model2 loss : 0.037472
[22:00:32.200] iteration 7967 : model1 loss : 0.022458 model2 loss : 0.022269
[22:00:32.863] iteration 7968 : model1 loss : 0.032618 model2 loss : 0.032210
[22:00:33.533] iteration 7969 : model1 loss : 0.022250 model2 loss : 0.025777
[22:00:34.185] iteration 7970 : model1 loss : 0.020533 model2 loss : 0.020180
[22:00:34.840] iteration 7971 : model1 loss : 0.020231 model2 loss : 0.022243
[22:00:35.510] iteration 7972 : model1 loss : 0.026384 model2 loss : 0.028839
[22:00:36.164] iteration 7973 : model1 loss : 0.039697 model2 loss : 0.041366
[22:00:36.816] iteration 7974 : model1 loss : 0.025288 model2 loss : 0.026889
[22:00:37.493] iteration 7975 : model1 loss : 0.027382 model2 loss : 0.023869
[22:00:38.153] iteration 7976 : model1 loss : 0.035141 model2 loss : 0.041454
[22:00:38.817] iteration 7977 : model1 loss : 0.021395 model2 loss : 0.023549
[22:00:39.474] iteration 7978 : model1 loss : 0.040305 model2 loss : 0.036439
[22:00:40.128] iteration 7979 : model1 loss : 0.028041 model2 loss : 0.026216
[22:00:40.794] iteration 7980 : model1 loss : 0.025287 model2 loss : 0.021876
[22:00:41.465] iteration 7981 : model1 loss : 0.022650 model2 loss : 0.029962
[22:00:42.126] iteration 7982 : model1 loss : 0.027112 model2 loss : 0.030741
[22:00:42.779] iteration 7983 : model1 loss : 0.033826 model2 loss : 0.030141
[22:00:43.436] iteration 7984 : model1 loss : 0.026261 model2 loss : 0.025706
[22:00:44.107] iteration 7985 : model1 loss : 0.017901 model2 loss : 0.020822
[22:00:44.760] iteration 7986 : model1 loss : 0.016394 model2 loss : 0.017492
[22:00:45.411] iteration 7987 : model1 loss : 0.023112 model2 loss : 0.024144
[22:00:46.056] iteration 7988 : model1 loss : 0.102799 model2 loss : 0.145738
[22:00:46.716] iteration 7989 : model1 loss : 0.025030 model2 loss : 0.027342
[22:00:47.383] iteration 7990 : model1 loss : 0.023150 model2 loss : 0.024126
[22:00:48.034] iteration 7991 : model1 loss : 0.029293 model2 loss : 0.029249
[22:00:48.709] iteration 7992 : model1 loss : 0.023016 model2 loss : 0.022087
[22:00:49.384] iteration 7993 : model1 loss : 0.021803 model2 loss : 0.022493
[22:00:50.041] iteration 7994 : model1 loss : 0.024689 model2 loss : 0.023663
[22:00:50.694] iteration 7995 : model1 loss : 0.039329 model2 loss : 0.041037
[22:00:51.361] iteration 7996 : model1 loss : 0.027938 model2 loss : 0.027859
[22:00:52.047] iteration 7997 : model1 loss : 0.057819 model2 loss : 0.046789
[22:00:52.708] iteration 7998 : model1 loss : 0.035975 model2 loss : 0.024135
[22:00:53.380] iteration 7999 : model1 loss : 0.036671 model2 loss : 0.033209
[22:00:54.032] iteration 8000 : model1 loss : 0.057990 model2 loss : 0.038726
[22:01:11.948] iteration 8000 : model1_mean_dice : 0.844991 model1_mean_hd95 : 11.764755
[22:01:30.519] iteration 8000 : model2_mean_dice : 0.858288 model2_mean_hd95 : 3.902800
[22:01:31.207] iteration 8001 : model1 loss : 0.020103 model2 loss : 0.020025
[22:01:31.880] iteration 8002 : model1 loss : 0.020740 model2 loss : 0.018910
[22:01:32.538] iteration 8003 : model1 loss : 0.021488 model2 loss : 0.020760
[22:01:33.195] iteration 8004 : model1 loss : 0.026055 model2 loss : 0.022515
[22:01:33.845] iteration 8005 : model1 loss : 0.028629 model2 loss : 0.026410
[22:01:34.501] iteration 8006 : model1 loss : 0.067529 model2 loss : 0.049952
[22:01:35.155] iteration 8007 : model1 loss : 0.023797 model2 loss : 0.022732
[22:01:35.819] iteration 8008 : model1 loss : 0.036464 model2 loss : 0.030015
[22:01:36.476] iteration 8009 : model1 loss : 0.038081 model2 loss : 0.031976
[22:01:37.126] iteration 8010 : model1 loss : 0.058930 model2 loss : 0.067215
[22:01:37.784] iteration 8011 : model1 loss : 0.025722 model2 loss : 0.030289
[22:01:38.444] iteration 8012 : model1 loss : 0.031218 model2 loss : 0.032020
[22:01:39.090] iteration 8013 : model1 loss : 0.104276 model2 loss : 0.071151
[22:01:39.742] iteration 8014 : model1 loss : 0.037481 model2 loss : 0.035869
[22:01:40.393] iteration 8015 : model1 loss : 0.034356 model2 loss : 0.029325
[22:01:41.050] iteration 8016 : model1 loss : 0.024713 model2 loss : 0.021408
[22:01:41.707] iteration 8017 : model1 loss : 0.025975 model2 loss : 0.025905
[22:01:42.363] iteration 8018 : model1 loss : 0.055437 model2 loss : 0.049514
[22:01:43.021] iteration 8019 : model1 loss : 0.021607 model2 loss : 0.020627
[22:01:43.694] iteration 8020 : model1 loss : 0.019124 model2 loss : 0.017151
[22:01:44.353] iteration 8021 : model1 loss : 0.025095 model2 loss : 0.024276
[22:01:45.007] iteration 8022 : model1 loss : 0.033502 model2 loss : 0.024797
[22:01:45.664] iteration 8023 : model1 loss : 0.031811 model2 loss : 0.028475
[22:01:46.330] iteration 8024 : model1 loss : 0.023934 model2 loss : 0.022851
[22:01:46.987] iteration 8025 : model1 loss : 0.029804 model2 loss : 0.023910
[22:01:47.651] iteration 8026 : model1 loss : 0.026980 model2 loss : 0.023282
[22:01:48.308] iteration 8027 : model1 loss : 0.040110 model2 loss : 0.026320
[22:01:48.961] iteration 8028 : model1 loss : 0.028750 model2 loss : 0.032464
[22:01:49.630] iteration 8029 : model1 loss : 0.030245 model2 loss : 0.026645
[22:01:50.282] iteration 8030 : model1 loss : 0.092124 model2 loss : 0.089490
[22:01:50.930] iteration 8031 : model1 loss : 0.022154 model2 loss : 0.027862
[22:01:51.600] iteration 8032 : model1 loss : 0.021772 model2 loss : 0.019283
[22:01:52.273] iteration 8033 : model1 loss : 0.035500 model2 loss : 0.032206
[22:01:52.938] iteration 8034 : model1 loss : 0.030461 model2 loss : 0.031304
[22:01:53.579] iteration 8035 : model1 loss : 0.018881 model2 loss : 0.017880
[22:01:54.226] iteration 8036 : model1 loss : 0.047117 model2 loss : 0.058681
[22:01:54.886] iteration 8037 : model1 loss : 0.030890 model2 loss : 0.028721
[22:01:55.553] iteration 8038 : model1 loss : 0.023688 model2 loss : 0.023600
[22:01:56.216] iteration 8039 : model1 loss : 0.019967 model2 loss : 0.019931
[22:01:56.861] iteration 8040 : model1 loss : 0.036815 model2 loss : 0.036982
[22:01:57.517] iteration 8041 : model1 loss : 0.035460 model2 loss : 0.034425
[22:01:58.173] iteration 8042 : model1 loss : 0.055309 model2 loss : 0.052031
[22:01:58.825] iteration 8043 : model1 loss : 0.021534 model2 loss : 0.019297
[22:01:59.471] iteration 8044 : model1 loss : 0.026306 model2 loss : 0.022643
[22:02:00.120] iteration 8045 : model1 loss : 0.026833 model2 loss : 0.025923
[22:02:00.808] iteration 8046 : model1 loss : 0.091083 model2 loss : 0.048449
[22:02:01.491] iteration 8047 : model1 loss : 0.028617 model2 loss : 0.028314
[22:02:02.149] iteration 8048 : model1 loss : 0.028204 model2 loss : 0.027892
[22:02:02.821] iteration 8049 : model1 loss : 0.029979 model2 loss : 0.039329
[22:02:03.489] iteration 8050 : model1 loss : 0.032436 model2 loss : 0.029987
[22:02:04.174] iteration 8051 : model1 loss : 0.036732 model2 loss : 0.033505
[22:02:04.839] iteration 8052 : model1 loss : 0.027487 model2 loss : 0.026886
[22:02:05.505] iteration 8053 : model1 loss : 0.024418 model2 loss : 0.020110
[22:02:06.170] iteration 8054 : model1 loss : 0.032672 model2 loss : 0.033226
[22:02:06.828] iteration 8055 : model1 loss : 0.036645 model2 loss : 0.038535
[22:02:07.487] iteration 8056 : model1 loss : 0.032328 model2 loss : 0.022073
[22:02:08.145] iteration 8057 : model1 loss : 0.031115 model2 loss : 0.026905
[22:02:08.812] iteration 8058 : model1 loss : 0.030745 model2 loss : 0.031532
[22:02:09.467] iteration 8059 : model1 loss : 0.029620 model2 loss : 0.027293
[22:02:10.122] iteration 8060 : model1 loss : 0.032587 model2 loss : 0.022907
[22:02:10.775] iteration 8061 : model1 loss : 0.027906 model2 loss : 0.022421
[22:02:11.438] iteration 8062 : model1 loss : 0.031634 model2 loss : 0.026172
[22:02:12.094] iteration 8063 : model1 loss : 0.031564 model2 loss : 0.033694
[22:02:12.747] iteration 8064 : model1 loss : 0.024068 model2 loss : 0.023553
[22:02:13.400] iteration 8065 : model1 loss : 0.031315 model2 loss : 0.031085
[22:02:14.061] iteration 8066 : model1 loss : 0.075501 model2 loss : 0.073389
[22:02:14.731] iteration 8067 : model1 loss : 0.024187 model2 loss : 0.027348
[22:02:15.412] iteration 8068 : model1 loss : 0.025613 model2 loss : 0.025383
[22:02:16.071] iteration 8069 : model1 loss : 0.040404 model2 loss : 0.043747
[22:02:16.735] iteration 8070 : model1 loss : 0.022209 model2 loss : 0.022968
[22:02:17.396] iteration 8071 : model1 loss : 0.021304 model2 loss : 0.019675
[22:02:18.062] iteration 8072 : model1 loss : 0.021085 model2 loss : 0.022005
[22:02:18.721] iteration 8073 : model1 loss : 0.032015 model2 loss : 0.033168
[22:02:19.380] iteration 8074 : model1 loss : 0.024723 model2 loss : 0.026046
[22:02:20.048] iteration 8075 : model1 loss : 0.050776 model2 loss : 0.048962
[22:02:20.708] iteration 8076 : model1 loss : 0.018794 model2 loss : 0.017916
[22:02:21.380] iteration 8077 : model1 loss : 0.025200 model2 loss : 0.031314
[22:02:22.038] iteration 8078 : model1 loss : 0.026720 model2 loss : 0.026694
[22:02:22.696] iteration 8079 : model1 loss : 0.028203 model2 loss : 0.028072
[22:02:23.363] iteration 8080 : model1 loss : 0.044899 model2 loss : 0.041280
[22:02:24.019] iteration 8081 : model1 loss : 0.020661 model2 loss : 0.019883
[22:02:24.680] iteration 8082 : model1 loss : 0.025651 model2 loss : 0.029879
[22:02:25.345] iteration 8083 : model1 loss : 0.046790 model2 loss : 0.027486
[22:02:26.009] iteration 8084 : model1 loss : 0.027618 model2 loss : 0.027725
[22:02:26.672] iteration 8085 : model1 loss : 0.033980 model2 loss : 0.030269
[22:02:27.320] iteration 8086 : model1 loss : 0.027299 model2 loss : 0.025309
[22:02:27.989] iteration 8087 : model1 loss : 0.022911 model2 loss : 0.020802
[22:02:28.651] iteration 8088 : model1 loss : 0.040598 model2 loss : 0.036681
[22:02:29.326] iteration 8089 : model1 loss : 0.063686 model2 loss : 0.057025
[22:02:29.985] iteration 8090 : model1 loss : 0.025054 model2 loss : 0.029448
[22:02:30.638] iteration 8091 : model1 loss : 0.025570 model2 loss : 0.025734
[22:02:31.303] iteration 8092 : model1 loss : 0.043338 model2 loss : 0.054666
[22:02:31.978] iteration 8093 : model1 loss : 0.035321 model2 loss : 0.029967
[22:02:32.638] iteration 8094 : model1 loss : 0.026190 model2 loss : 0.024067
[22:02:33.299] iteration 8095 : model1 loss : 0.025922 model2 loss : 0.023125
[22:02:33.967] iteration 8096 : model1 loss : 0.024326 model2 loss : 0.024676
[22:02:34.647] iteration 8097 : model1 loss : 0.030333 model2 loss : 0.029485
[22:02:35.313] iteration 8098 : model1 loss : 0.030230 model2 loss : 0.028198
[22:02:35.968] iteration 8099 : model1 loss : 0.030370 model2 loss : 0.026363
[22:02:36.635] iteration 8100 : model1 loss : 0.023558 model2 loss : 0.024288
[22:02:37.326] iteration 8101 : model1 loss : 0.022067 model2 loss : 0.022505
[22:02:37.991] iteration 8102 : model1 loss : 0.030980 model2 loss : 0.044307
[22:02:38.651] iteration 8103 : model1 loss : 0.025677 model2 loss : 0.026919
[22:02:39.307] iteration 8104 : model1 loss : 0.031005 model2 loss : 0.030817
[22:02:39.989] iteration 8105 : model1 loss : 0.024940 model2 loss : 0.042951
[22:02:40.648] iteration 8106 : model1 loss : 0.024731 model2 loss : 0.027096
[22:02:41.302] iteration 8107 : model1 loss : 0.016703 model2 loss : 0.017960
[22:02:41.959] iteration 8108 : model1 loss : 0.141059 model2 loss : 0.143725
[22:02:42.622] iteration 8109 : model1 loss : 0.015381 model2 loss : 0.017948
[22:02:43.288] iteration 8110 : model1 loss : 0.028828 model2 loss : 0.031238
[22:02:43.935] iteration 8111 : model1 loss : 0.037632 model2 loss : 0.052298
[22:02:44.601] iteration 8112 : model1 loss : 0.023880 model2 loss : 0.022902
[22:02:45.277] iteration 8113 : model1 loss : 0.020014 model2 loss : 0.024304
[22:02:45.939] iteration 8114 : model1 loss : 0.028960 model2 loss : 0.026635
[22:02:46.601] iteration 8115 : model1 loss : 0.030394 model2 loss : 0.032617
[22:02:47.258] iteration 8116 : model1 loss : 0.020653 model2 loss : 0.019539
[22:02:47.919] iteration 8117 : model1 loss : 0.143368 model2 loss : 0.144217
[22:02:48.586] iteration 8118 : model1 loss : 0.028372 model2 loss : 0.031067
[22:02:49.248] iteration 8119 : model1 loss : 0.022597 model2 loss : 0.026547
[22:02:49.901] iteration 8120 : model1 loss : 0.032678 model2 loss : 0.031072
[22:02:50.552] iteration 8121 : model1 loss : 0.023141 model2 loss : 0.026187
[22:02:51.205] iteration 8122 : model1 loss : 0.036365 model2 loss : 0.035902
[22:02:51.855] iteration 8123 : model1 loss : 0.025212 model2 loss : 0.023274
[22:02:52.539] iteration 8124 : model1 loss : 0.024536 model2 loss : 0.022844
[22:02:53.208] iteration 8125 : model1 loss : 0.029087 model2 loss : 0.031286
[22:02:53.876] iteration 8126 : model1 loss : 0.025339 model2 loss : 0.030325
[22:02:54.523] iteration 8127 : model1 loss : 0.032589 model2 loss : 0.040348
[22:02:55.183] iteration 8128 : model1 loss : 0.036162 model2 loss : 0.032869
[22:02:55.836] iteration 8129 : model1 loss : 0.018171 model2 loss : 0.020909
[22:02:56.494] iteration 8130 : model1 loss : 0.022889 model2 loss : 0.020520
[22:02:57.153] iteration 8131 : model1 loss : 0.025571 model2 loss : 0.023613
[22:02:57.808] iteration 8132 : model1 loss : 0.020754 model2 loss : 0.022125
[22:02:58.481] iteration 8133 : model1 loss : 0.024632 model2 loss : 0.022796
[22:02:59.152] iteration 8134 : model1 loss : 0.027367 model2 loss : 0.029386
[22:02:59.815] iteration 8135 : model1 loss : 0.052717 model2 loss : 0.057384
[22:03:00.477] iteration 8136 : model1 loss : 0.022191 model2 loss : 0.029794
[22:03:01.134] iteration 8137 : model1 loss : 0.026870 model2 loss : 0.028876
[22:03:01.788] iteration 8138 : model1 loss : 0.035042 model2 loss : 0.032352
[22:03:02.450] iteration 8139 : model1 loss : 0.024650 model2 loss : 0.023180
[22:03:03.105] iteration 8140 : model1 loss : 0.027378 model2 loss : 0.025691
[22:03:03.764] iteration 8141 : model1 loss : 0.034299 model2 loss : 0.041659
[22:03:04.436] iteration 8142 : model1 loss : 0.026520 model2 loss : 0.023435
[22:03:05.099] iteration 8143 : model1 loss : 0.029037 model2 loss : 0.028932
[22:03:05.766] iteration 8144 : model1 loss : 0.020593 model2 loss : 0.020520
[22:03:06.429] iteration 8145 : model1 loss : 0.031091 model2 loss : 0.029077
[22:03:07.084] iteration 8146 : model1 loss : 0.025350 model2 loss : 0.028066
[22:03:07.758] iteration 8147 : model1 loss : 0.027848 model2 loss : 0.028020
[22:03:08.441] iteration 8148 : model1 loss : 0.023574 model2 loss : 0.023167
[22:03:09.099] iteration 8149 : model1 loss : 0.040848 model2 loss : 0.045974
[22:03:09.751] iteration 8150 : model1 loss : 0.029336 model2 loss : 0.034347
[22:03:10.458] iteration 8151 : model1 loss : 0.026423 model2 loss : 0.028720
[22:03:11.118] iteration 8152 : model1 loss : 0.021205 model2 loss : 0.023330
[22:03:11.784] iteration 8153 : model1 loss : 0.027966 model2 loss : 0.023024
[22:03:12.447] iteration 8154 : model1 loss : 0.023116 model2 loss : 0.024916
[22:03:13.106] iteration 8155 : model1 loss : 0.024912 model2 loss : 0.023644
[22:03:13.760] iteration 8156 : model1 loss : 0.154633 model2 loss : 0.150236
[22:03:14.416] iteration 8157 : model1 loss : 0.025425 model2 loss : 0.023519
[22:03:15.084] iteration 8158 : model1 loss : 0.023903 model2 loss : 0.028168
[22:03:15.746] iteration 8159 : model1 loss : 0.025653 model2 loss : 0.028040
[22:03:16.403] iteration 8160 : model1 loss : 0.027694 model2 loss : 0.030288
[22:03:17.065] iteration 8161 : model1 loss : 0.022003 model2 loss : 0.025401
[22:03:17.726] iteration 8162 : model1 loss : 0.021813 model2 loss : 0.024342
[22:03:18.394] iteration 8163 : model1 loss : 0.024046 model2 loss : 0.030577
[22:03:19.060] iteration 8164 : model1 loss : 0.028248 model2 loss : 0.027264
[22:03:19.716] iteration 8165 : model1 loss : 0.023295 model2 loss : 0.026437
[22:03:20.369] iteration 8166 : model1 loss : 0.017885 model2 loss : 0.017781
[22:03:21.034] iteration 8167 : model1 loss : 0.027022 model2 loss : 0.026941
[22:03:21.686] iteration 8168 : model1 loss : 0.026255 model2 loss : 0.024067
[22:03:22.351] iteration 8169 : model1 loss : 0.032483 model2 loss : 0.037818
[22:03:23.006] iteration 8170 : model1 loss : 0.081315 model2 loss : 0.070083
[22:03:23.662] iteration 8171 : model1 loss : 0.025869 model2 loss : 0.033582
[22:03:24.331] iteration 8172 : model1 loss : 0.023094 model2 loss : 0.024092
[22:03:24.988] iteration 8173 : model1 loss : 0.023595 model2 loss : 0.022904
[22:03:25.650] iteration 8174 : model1 loss : 0.017653 model2 loss : 0.017871
[22:03:26.301] iteration 8175 : model1 loss : 0.035925 model2 loss : 0.033457
[22:03:26.964] iteration 8176 : model1 loss : 0.029246 model2 loss : 0.023410
[22:03:27.624] iteration 8177 : model1 loss : 0.021635 model2 loss : 0.022946
[22:03:28.284] iteration 8178 : model1 loss : 0.015951 model2 loss : 0.015653
[22:03:28.942] iteration 8179 : model1 loss : 0.032190 model2 loss : 0.028279
[22:03:29.592] iteration 8180 : model1 loss : 0.027648 model2 loss : 0.023305
[22:03:30.242] iteration 8181 : model1 loss : 0.025717 model2 loss : 0.025672
[22:03:30.898] iteration 8182 : model1 loss : 0.027700 model2 loss : 0.022549
[22:03:31.562] iteration 8183 : model1 loss : 0.022905 model2 loss : 0.024300
[22:03:32.224] iteration 8184 : model1 loss : 0.031527 model2 loss : 0.027080
[22:03:32.894] iteration 8185 : model1 loss : 0.026365 model2 loss : 0.028970
[22:03:33.560] iteration 8186 : model1 loss : 0.032046 model2 loss : 0.029259
[22:03:34.211] iteration 8187 : model1 loss : 0.022014 model2 loss : 0.024158
[22:03:34.876] iteration 8188 : model1 loss : 0.032900 model2 loss : 0.028970
[22:03:35.528] iteration 8189 : model1 loss : 0.020006 model2 loss : 0.019184
[22:03:36.191] iteration 8190 : model1 loss : 0.027387 model2 loss : 0.023461
[22:03:36.866] iteration 8191 : model1 loss : 0.034440 model2 loss : 0.031600
[22:03:37.525] iteration 8192 : model1 loss : 0.021912 model2 loss : 0.023785
[22:03:38.177] iteration 8193 : model1 loss : 0.022737 model2 loss : 0.019985
[22:03:38.835] iteration 8194 : model1 loss : 0.025945 model2 loss : 0.026895
[22:03:39.499] iteration 8195 : model1 loss : 0.024131 model2 loss : 0.020250
[22:03:40.164] iteration 8196 : model1 loss : 0.027573 model2 loss : 0.023726
[22:03:40.817] iteration 8197 : model1 loss : 0.052809 model2 loss : 0.056093
[22:03:41.489] iteration 8198 : model1 loss : 0.058572 model2 loss : 0.073833
[22:03:42.143] iteration 8199 : model1 loss : 0.034992 model2 loss : 0.031962
[22:03:42.813] iteration 8200 : model1 loss : 0.023247 model2 loss : 0.023206
[22:04:00.772] iteration 8200 : model1_mean_dice : 0.846392 model1_mean_hd95 : 3.284458
[22:04:18.886] iteration 8200 : model2_mean_dice : 0.859596 model2_mean_hd95 : 4.245904
[22:04:19.566] iteration 8201 : model1 loss : 0.023139 model2 loss : 0.023291
[22:04:20.209] iteration 8202 : model1 loss : 0.050299 model2 loss : 0.043146
[22:04:20.866] iteration 8203 : model1 loss : 0.024330 model2 loss : 0.024238
[22:04:21.528] iteration 8204 : model1 loss : 0.024346 model2 loss : 0.024359
[22:04:22.173] iteration 8205 : model1 loss : 0.023582 model2 loss : 0.024188
[22:04:22.828] iteration 8206 : model1 loss : 0.024183 model2 loss : 0.023967
[22:04:23.485] iteration 8207 : model1 loss : 0.025307 model2 loss : 0.023855
[22:04:24.135] iteration 8208 : model1 loss : 0.027306 model2 loss : 0.028084
[22:04:24.789] iteration 8209 : model1 loss : 0.030037 model2 loss : 0.028887
[22:04:25.439] iteration 8210 : model1 loss : 0.022960 model2 loss : 0.023803
[22:04:26.103] iteration 8211 : model1 loss : 0.021151 model2 loss : 0.020712
[22:04:26.761] iteration 8212 : model1 loss : 0.024242 model2 loss : 0.025897
[22:04:27.407] iteration 8213 : model1 loss : 0.061557 model2 loss : 0.047527
[22:04:28.075] iteration 8214 : model1 loss : 0.045392 model2 loss : 0.060614
[22:04:28.752] iteration 8215 : model1 loss : 0.014485 model2 loss : 0.017106
[22:04:29.404] iteration 8216 : model1 loss : 0.034129 model2 loss : 0.034108
[22:04:30.054] iteration 8217 : model1 loss : 0.035089 model2 loss : 0.031864
[22:04:30.712] iteration 8218 : model1 loss : 0.030752 model2 loss : 0.027828
[22:04:31.365] iteration 8219 : model1 loss : 0.074955 model2 loss : 0.043604
[22:04:32.024] iteration 8220 : model1 loss : 0.033411 model2 loss : 0.028692
[22:04:32.674] iteration 8221 : model1 loss : 0.030540 model2 loss : 0.067860
[22:04:33.340] iteration 8222 : model1 loss : 0.047717 model2 loss : 0.052103
[22:04:33.985] iteration 8223 : model1 loss : 0.019190 model2 loss : 0.021198
[22:04:34.643] iteration 8224 : model1 loss : 0.021450 model2 loss : 0.022527
[22:04:35.302] iteration 8225 : model1 loss : 0.024923 model2 loss : 0.027802
[22:04:35.968] iteration 8226 : model1 loss : 0.024159 model2 loss : 0.024617
[22:04:36.629] iteration 8227 : model1 loss : 0.035133 model2 loss : 0.039859
[22:04:37.295] iteration 8228 : model1 loss : 0.018639 model2 loss : 0.019980
[22:04:37.961] iteration 8229 : model1 loss : 0.020833 model2 loss : 0.021201
[22:04:38.619] iteration 8230 : model1 loss : 0.044810 model2 loss : 0.046670
[22:04:39.279] iteration 8231 : model1 loss : 0.024684 model2 loss : 0.027480
[22:04:39.939] iteration 8232 : model1 loss : 0.029317 model2 loss : 0.033351
[22:04:40.599] iteration 8233 : model1 loss : 0.032452 model2 loss : 0.043045
[22:04:41.269] iteration 8234 : model1 loss : 0.018850 model2 loss : 0.016059
[22:04:41.953] iteration 8235 : model1 loss : 0.025649 model2 loss : 0.029558
[22:04:42.625] iteration 8236 : model1 loss : 0.020972 model2 loss : 0.022806
[22:04:43.278] iteration 8237 : model1 loss : 0.148991 model2 loss : 0.146233
[22:04:43.941] iteration 8238 : model1 loss : 0.019886 model2 loss : 0.023469
[22:04:44.603] iteration 8239 : model1 loss : 0.030110 model2 loss : 0.026463
[22:04:45.271] iteration 8240 : model1 loss : 0.026741 model2 loss : 0.023947
[22:04:45.922] iteration 8241 : model1 loss : 0.028027 model2 loss : 0.029794
[22:04:46.582] iteration 8242 : model1 loss : 0.027180 model2 loss : 0.026030
[22:04:47.236] iteration 8243 : model1 loss : 0.022102 model2 loss : 0.022445
[22:04:47.893] iteration 8244 : model1 loss : 0.027100 model2 loss : 0.023052
[22:04:48.551] iteration 8245 : model1 loss : 0.022643 model2 loss : 0.022637
[22:04:49.211] iteration 8246 : model1 loss : 0.152187 model2 loss : 0.159260
[22:04:49.869] iteration 8247 : model1 loss : 0.023432 model2 loss : 0.020825
[22:04:50.518] iteration 8248 : model1 loss : 0.020597 model2 loss : 0.019402
[22:04:51.169] iteration 8249 : model1 loss : 0.022175 model2 loss : 0.023316
[22:04:51.845] iteration 8250 : model1 loss : 0.030914 model2 loss : 0.024871
[22:04:52.552] iteration 8251 : model1 loss : 0.027111 model2 loss : 0.028763
[22:04:53.212] iteration 8252 : model1 loss : 0.037640 model2 loss : 0.036642
[22:04:53.886] iteration 8253 : model1 loss : 0.021342 model2 loss : 0.018818
[22:04:54.548] iteration 8254 : model1 loss : 0.050631 model2 loss : 0.053024
[22:04:55.216] iteration 8255 : model1 loss : 0.032450 model2 loss : 0.029454
[22:04:55.880] iteration 8256 : model1 loss : 0.031096 model2 loss : 0.025134
[22:04:56.551] iteration 8257 : model1 loss : 0.024797 model2 loss : 0.023352
[22:04:57.220] iteration 8258 : model1 loss : 0.030504 model2 loss : 0.034897
[22:04:57.878] iteration 8259 : model1 loss : 0.022279 model2 loss : 0.021947
[22:04:58.556] iteration 8260 : model1 loss : 0.022481 model2 loss : 0.017709
[22:04:59.212] iteration 8261 : model1 loss : 0.023507 model2 loss : 0.024141
[22:04:59.878] iteration 8262 : model1 loss : 0.021741 model2 loss : 0.018894
[22:05:00.554] iteration 8263 : model1 loss : 0.029037 model2 loss : 0.026723
[22:05:01.213] iteration 8264 : model1 loss : 0.021590 model2 loss : 0.020456
[22:05:01.877] iteration 8265 : model1 loss : 0.025215 model2 loss : 0.025680
[22:05:02.544] iteration 8266 : model1 loss : 0.035426 model2 loss : 0.032579
[22:05:03.197] iteration 8267 : model1 loss : 0.022425 model2 loss : 0.022549
[22:05:03.863] iteration 8268 : model1 loss : 0.030199 model2 loss : 0.031336
[22:05:04.508] iteration 8269 : model1 loss : 0.021852 model2 loss : 0.029151
[22:05:05.164] iteration 8270 : model1 loss : 0.036233 model2 loss : 0.042130
[22:05:05.821] iteration 8271 : model1 loss : 0.035775 model2 loss : 0.036917
[22:05:06.484] iteration 8272 : model1 loss : 0.018734 model2 loss : 0.023422
[22:05:07.152] iteration 8273 : model1 loss : 0.027325 model2 loss : 0.029291
[22:05:07.823] iteration 8274 : model1 loss : 0.023455 model2 loss : 0.025886
[22:05:08.490] iteration 8275 : model1 loss : 0.025532 model2 loss : 0.020920
[22:05:09.146] iteration 8276 : model1 loss : 0.037226 model2 loss : 0.041181
[22:05:09.807] iteration 8277 : model1 loss : 0.020143 model2 loss : 0.019367
[22:05:10.476] iteration 8278 : model1 loss : 0.020407 model2 loss : 0.028002
[22:05:11.123] iteration 8279 : model1 loss : 0.023391 model2 loss : 0.023178
[22:05:11.775] iteration 8280 : model1 loss : 0.028458 model2 loss : 0.028338
[22:05:12.434] iteration 8281 : model1 loss : 0.036729 model2 loss : 0.037713
[22:05:13.106] iteration 8282 : model1 loss : 0.028026 model2 loss : 0.030344
[22:05:13.771] iteration 8283 : model1 loss : 0.029770 model2 loss : 0.029003
[22:05:14.426] iteration 8284 : model1 loss : 0.034700 model2 loss : 0.045376
[22:05:15.083] iteration 8285 : model1 loss : 0.022482 model2 loss : 0.022683
[22:05:15.741] iteration 8286 : model1 loss : 0.024412 model2 loss : 0.025895
[22:05:16.406] iteration 8287 : model1 loss : 0.034121 model2 loss : 0.032298
[22:05:17.070] iteration 8288 : model1 loss : 0.022882 model2 loss : 0.024461
[22:05:17.733] iteration 8289 : model1 loss : 0.026620 model2 loss : 0.026032
[22:05:18.416] iteration 8290 : model1 loss : 0.025787 model2 loss : 0.026363
[22:05:19.081] iteration 8291 : model1 loss : 0.031372 model2 loss : 0.034649
[22:05:19.743] iteration 8292 : model1 loss : 0.018431 model2 loss : 0.018965
[22:05:20.418] iteration 8293 : model1 loss : 0.019143 model2 loss : 0.021078
[22:05:21.080] iteration 8294 : model1 loss : 0.029103 model2 loss : 0.025486
[22:05:21.741] iteration 8295 : model1 loss : 0.029460 model2 loss : 0.028763
[22:05:22.400] iteration 8296 : model1 loss : 0.026208 model2 loss : 0.031833
[22:05:23.062] iteration 8297 : model1 loss : 0.016338 model2 loss : 0.017754
[22:05:23.724] iteration 8298 : model1 loss : 0.029757 model2 loss : 0.034131
[22:05:24.389] iteration 8299 : model1 loss : 0.023537 model2 loss : 0.022006
[22:05:25.036] iteration 8300 : model1 loss : 0.021195 model2 loss : 0.021584
[22:05:25.744] iteration 8301 : model1 loss : 0.020358 model2 loss : 0.019916
[22:05:26.405] iteration 8302 : model1 loss : 0.024586 model2 loss : 0.028977
[22:05:27.068] iteration 8303 : model1 loss : 0.036450 model2 loss : 0.037507
[22:05:27.731] iteration 8304 : model1 loss : 0.048925 model2 loss : 0.042822
[22:05:28.403] iteration 8305 : model1 loss : 0.039623 model2 loss : 0.040119
[22:05:29.066] iteration 8306 : model1 loss : 0.026790 model2 loss : 0.023255
[22:05:29.723] iteration 8307 : model1 loss : 0.027769 model2 loss : 0.024882
[22:05:30.391] iteration 8308 : model1 loss : 0.022301 model2 loss : 0.022399
[22:05:31.051] iteration 8309 : model1 loss : 0.018641 model2 loss : 0.022418
[22:05:31.715] iteration 8310 : model1 loss : 0.024023 model2 loss : 0.021164
[22:05:32.375] iteration 8311 : model1 loss : 0.023613 model2 loss : 0.021924
[22:05:33.032] iteration 8312 : model1 loss : 0.023405 model2 loss : 0.026241
[22:05:33.690] iteration 8313 : model1 loss : 0.055942 model2 loss : 0.046560
[22:05:34.350] iteration 8314 : model1 loss : 0.024817 model2 loss : 0.024664
[22:05:35.005] iteration 8315 : model1 loss : 0.023528 model2 loss : 0.025936
[22:05:35.667] iteration 8316 : model1 loss : 0.027890 model2 loss : 0.021883
[22:05:36.327] iteration 8317 : model1 loss : 0.024278 model2 loss : 0.026967
[22:05:36.992] iteration 8318 : model1 loss : 0.036210 model2 loss : 0.044534
[22:05:37.643] iteration 8319 : model1 loss : 0.022179 model2 loss : 0.022518
[22:05:38.299] iteration 8320 : model1 loss : 0.030237 model2 loss : 0.028987
[22:05:38.959] iteration 8321 : model1 loss : 0.024803 model2 loss : 0.025070
[22:05:39.624] iteration 8322 : model1 loss : 0.037200 model2 loss : 0.050361
[22:05:40.290] iteration 8323 : model1 loss : 0.018325 model2 loss : 0.019254
[22:05:40.946] iteration 8324 : model1 loss : 0.019774 model2 loss : 0.021239
[22:05:41.604] iteration 8325 : model1 loss : 0.024788 model2 loss : 0.026267
[22:05:42.258] iteration 8326 : model1 loss : 0.027244 model2 loss : 0.041338
[22:05:42.909] iteration 8327 : model1 loss : 0.074411 model2 loss : 0.030243
[22:05:43.567] iteration 8328 : model1 loss : 0.028029 model2 loss : 0.027526
[22:05:44.219] iteration 8329 : model1 loss : 0.039560 model2 loss : 0.026115
[22:05:44.882] iteration 8330 : model1 loss : 0.027942 model2 loss : 0.039687
[22:05:45.539] iteration 8331 : model1 loss : 0.022568 model2 loss : 0.022154
[22:05:46.198] iteration 8332 : model1 loss : 0.026438 model2 loss : 0.030634
[22:05:46.863] iteration 8333 : model1 loss : 0.106461 model2 loss : 0.073871
[22:05:47.533] iteration 8334 : model1 loss : 0.032931 model2 loss : 0.031119
[22:05:48.181] iteration 8335 : model1 loss : 0.032556 model2 loss : 0.041424
[22:05:48.839] iteration 8336 : model1 loss : 0.059698 model2 loss : 0.032392
[22:05:49.497] iteration 8337 : model1 loss : 0.021355 model2 loss : 0.021337
[22:05:50.154] iteration 8338 : model1 loss : 0.024892 model2 loss : 0.022825
[22:05:50.804] iteration 8339 : model1 loss : 0.033833 model2 loss : 0.026965
[22:05:51.488] iteration 8340 : model1 loss : 0.060779 model2 loss : 0.040646
[22:05:52.147] iteration 8341 : model1 loss : 0.023998 model2 loss : 0.024361
[22:05:52.813] iteration 8342 : model1 loss : 0.024355 model2 loss : 0.024005
[22:05:53.481] iteration 8343 : model1 loss : 0.023316 model2 loss : 0.021955
[22:05:54.163] iteration 8344 : model1 loss : 0.068280 model2 loss : 0.069767
[22:05:54.830] iteration 8345 : model1 loss : 0.028825 model2 loss : 0.018812
[22:05:55.495] iteration 8346 : model1 loss : 0.126540 model2 loss : 0.091096
[22:05:56.149] iteration 8347 : model1 loss : 0.047049 model2 loss : 0.050299
[22:05:56.808] iteration 8348 : model1 loss : 0.025076 model2 loss : 0.021794
[22:05:57.475] iteration 8349 : model1 loss : 0.039452 model2 loss : 0.029168
[22:05:58.133] iteration 8350 : model1 loss : 0.049162 model2 loss : 0.031139
[22:05:58.824] iteration 8351 : model1 loss : 0.034291 model2 loss : 0.027885
[22:05:59.489] iteration 8352 : model1 loss : 0.028036 model2 loss : 0.026548
[22:06:00.149] iteration 8353 : model1 loss : 0.064869 model2 loss : 0.048891
[22:06:00.816] iteration 8354 : model1 loss : 0.026910 model2 loss : 0.026125
[22:06:01.477] iteration 8355 : model1 loss : 0.019530 model2 loss : 0.020862
[22:06:02.146] iteration 8356 : model1 loss : 0.137138 model2 loss : 0.067652
[22:06:02.803] iteration 8357 : model1 loss : 0.078048 model2 loss : 0.054077
[22:06:03.461] iteration 8358 : model1 loss : 0.023024 model2 loss : 0.020172
[22:06:04.130] iteration 8359 : model1 loss : 0.031739 model2 loss : 0.030715
[22:06:04.787] iteration 8360 : model1 loss : 0.027648 model2 loss : 0.024377
[22:06:05.454] iteration 8361 : model1 loss : 0.020648 model2 loss : 0.016604
[22:06:06.113] iteration 8362 : model1 loss : 0.024826 model2 loss : 0.023086
[22:06:06.768] iteration 8363 : model1 loss : 0.026882 model2 loss : 0.027275
[22:06:07.424] iteration 8364 : model1 loss : 0.043797 model2 loss : 0.025860
[22:06:08.092] iteration 8365 : model1 loss : 0.020467 model2 loss : 0.020817
[22:06:08.756] iteration 8366 : model1 loss : 0.029298 model2 loss : 0.033369
[22:06:09.429] iteration 8367 : model1 loss : 0.026443 model2 loss : 0.026911
[22:06:10.087] iteration 8368 : model1 loss : 0.030942 model2 loss : 0.030172
[22:06:10.737] iteration 8369 : model1 loss : 0.035116 model2 loss : 0.028777
[22:06:11.396] iteration 8370 : model1 loss : 0.035723 model2 loss : 0.023197
[22:06:12.057] iteration 8371 : model1 loss : 0.028619 model2 loss : 0.026191
[22:06:12.713] iteration 8372 : model1 loss : 0.036884 model2 loss : 0.029053
[22:06:13.395] iteration 8373 : model1 loss : 0.030906 model2 loss : 0.028962
[22:06:14.067] iteration 8374 : model1 loss : 0.021335 model2 loss : 0.021603
[22:06:14.716] iteration 8375 : model1 loss : 0.027423 model2 loss : 0.024699
[22:06:15.375] iteration 8376 : model1 loss : 0.033321 model2 loss : 0.038265
[22:06:16.024] iteration 8377 : model1 loss : 0.031371 model2 loss : 0.036602
[22:06:16.683] iteration 8378 : model1 loss : 0.029130 model2 loss : 0.026328
[22:06:17.337] iteration 8379 : model1 loss : 0.025481 model2 loss : 0.024889
[22:06:17.989] iteration 8380 : model1 loss : 0.035076 model2 loss : 0.022815
[22:06:18.664] iteration 8381 : model1 loss : 0.042652 model2 loss : 0.031823
[22:06:19.324] iteration 8382 : model1 loss : 0.097929 model2 loss : 0.078791
[22:06:19.986] iteration 8383 : model1 loss : 0.024182 model2 loss : 0.021909
[22:06:20.660] iteration 8384 : model1 loss : 0.045443 model2 loss : 0.039539
[22:06:21.314] iteration 8385 : model1 loss : 0.115299 model2 loss : 0.037570
[22:06:21.974] iteration 8386 : model1 loss : 0.021359 model2 loss : 0.023755
[22:06:22.642] iteration 8387 : model1 loss : 0.055364 model2 loss : 0.052265
[22:06:23.403] iteration 8388 : model1 loss : 0.032238 model2 loss : 0.023630
[22:06:24.193] iteration 8389 : model1 loss : 0.040387 model2 loss : 0.036081
[22:06:24.887] iteration 8390 : model1 loss : 0.035656 model2 loss : 0.030439
[22:06:25.561] iteration 8391 : model1 loss : 0.041244 model2 loss : 0.032749
[22:06:26.225] iteration 8392 : model1 loss : 0.019952 model2 loss : 0.019427
[22:06:26.872] iteration 8393 : model1 loss : 0.027920 model2 loss : 0.025672
[22:06:27.537] iteration 8394 : model1 loss : 0.027539 model2 loss : 0.028272
[22:06:28.196] iteration 8395 : model1 loss : 0.028326 model2 loss : 0.031767
[22:06:28.858] iteration 8396 : model1 loss : 0.025685 model2 loss : 0.020408
[22:06:29.526] iteration 8397 : model1 loss : 0.031476 model2 loss : 0.034590
[22:06:30.183] iteration 8398 : model1 loss : 0.035113 model2 loss : 0.025366
[22:06:30.838] iteration 8399 : model1 loss : 0.032374 model2 loss : 0.029066
[22:06:31.499] iteration 8400 : model1 loss : 0.025791 model2 loss : 0.030102
[22:06:49.709] iteration 8400 : model1_mean_dice : 0.850425 model1_mean_hd95 : 4.132815
[22:07:07.825] iteration 8400 : model2_mean_dice : 0.857691 model2_mean_hd95 : 9.661218
[22:07:08.522] iteration 8401 : model1 loss : 0.026997 model2 loss : 0.024908
[22:07:09.172] iteration 8402 : model1 loss : 0.026264 model2 loss : 0.026468
[22:07:09.820] iteration 8403 : model1 loss : 0.033940 model2 loss : 0.039583
[22:07:10.473] iteration 8404 : model1 loss : 0.022149 model2 loss : 0.025733
[22:07:11.123] iteration 8405 : model1 loss : 0.029077 model2 loss : 0.026350
[22:07:11.790] iteration 8406 : model1 loss : 0.031417 model2 loss : 0.027543
[22:07:12.454] iteration 8407 : model1 loss : 0.023098 model2 loss : 0.020278
[22:07:13.105] iteration 8408 : model1 loss : 0.026665 model2 loss : 0.025121
[22:07:13.774] iteration 8409 : model1 loss : 0.030486 model2 loss : 0.029544
[22:07:14.427] iteration 8410 : model1 loss : 0.022040 model2 loss : 0.026138
[22:07:15.101] iteration 8411 : model1 loss : 0.066320 model2 loss : 0.070555
[22:07:15.762] iteration 8412 : model1 loss : 0.020278 model2 loss : 0.018888
[22:07:16.417] iteration 8413 : model1 loss : 0.026053 model2 loss : 0.028055
[22:07:17.076] iteration 8414 : model1 loss : 0.023523 model2 loss : 0.020356
[22:07:17.733] iteration 8415 : model1 loss : 0.023627 model2 loss : 0.022391
[22:07:18.398] iteration 8416 : model1 loss : 0.024766 model2 loss : 0.024872
[22:07:19.053] iteration 8417 : model1 loss : 0.018660 model2 loss : 0.018088
[22:07:19.697] iteration 8418 : model1 loss : 0.020895 model2 loss : 0.023649
[22:07:20.376] iteration 8419 : model1 loss : 0.028432 model2 loss : 0.025326
[22:07:21.027] iteration 8420 : model1 loss : 0.022818 model2 loss : 0.023611
[22:07:21.679] iteration 8421 : model1 loss : 0.033878 model2 loss : 0.032674
[22:07:22.325] iteration 8422 : model1 loss : 0.023345 model2 loss : 0.022605
[22:07:22.970] iteration 8423 : model1 loss : 0.037381 model2 loss : 0.063932
[22:07:23.635] iteration 8424 : model1 loss : 0.028134 model2 loss : 0.027413
[22:07:24.290] iteration 8425 : model1 loss : 0.022059 model2 loss : 0.022182
[22:07:24.949] iteration 8426 : model1 loss : 0.024386 model2 loss : 0.025588
[22:07:25.618] iteration 8427 : model1 loss : 0.026489 model2 loss : 0.028069
[22:07:26.278] iteration 8428 : model1 loss : 0.023801 model2 loss : 0.022896
[22:07:26.937] iteration 8429 : model1 loss : 0.029665 model2 loss : 0.036998
[22:07:27.603] iteration 8430 : model1 loss : 0.027216 model2 loss : 0.027967
[22:07:28.258] iteration 8431 : model1 loss : 0.022667 model2 loss : 0.023448
[22:07:28.914] iteration 8432 : model1 loss : 0.019131 model2 loss : 0.020835
[22:07:29.569] iteration 8433 : model1 loss : 0.029668 model2 loss : 0.027637
[22:07:30.213] iteration 8434 : model1 loss : 0.037514 model2 loss : 0.032189
[22:07:30.864] iteration 8435 : model1 loss : 0.026374 model2 loss : 0.033086
[22:07:31.534] iteration 8436 : model1 loss : 0.038070 model2 loss : 0.032284
[22:07:32.181] iteration 8437 : model1 loss : 0.022593 model2 loss : 0.025950
[22:07:32.835] iteration 8438 : model1 loss : 0.036356 model2 loss : 0.029840
[22:07:33.492] iteration 8439 : model1 loss : 0.036026 model2 loss : 0.035715
[22:07:34.148] iteration 8440 : model1 loss : 0.025158 model2 loss : 0.034317
[22:07:34.810] iteration 8441 : model1 loss : 0.163727 model2 loss : 0.157439
[22:07:35.461] iteration 8442 : model1 loss : 0.023418 model2 loss : 0.022561
[22:07:36.116] iteration 8443 : model1 loss : 0.029717 model2 loss : 0.027501
[22:07:36.771] iteration 8444 : model1 loss : 0.025036 model2 loss : 0.027789
[22:07:37.439] iteration 8445 : model1 loss : 0.035299 model2 loss : 0.030851
[22:07:38.086] iteration 8446 : model1 loss : 0.023473 model2 loss : 0.025632
[22:07:38.739] iteration 8447 : model1 loss : 0.023713 model2 loss : 0.029375
[22:07:39.386] iteration 8448 : model1 loss : 0.034159 model2 loss : 0.031526
[22:07:40.043] iteration 8449 : model1 loss : 0.022244 model2 loss : 0.034430
[22:07:40.694] iteration 8450 : model1 loss : 0.023685 model2 loss : 0.026683
[22:07:41.404] iteration 8451 : model1 loss : 0.025262 model2 loss : 0.039494
[22:07:42.053] iteration 8452 : model1 loss : 0.020510 model2 loss : 0.020215
[22:07:42.711] iteration 8453 : model1 loss : 0.059272 model2 loss : 0.052007
[22:07:43.363] iteration 8454 : model1 loss : 0.035726 model2 loss : 0.041076
[22:07:44.014] iteration 8455 : model1 loss : 0.034211 model2 loss : 0.028704
[22:07:44.668] iteration 8456 : model1 loss : 0.028277 model2 loss : 0.028641
[22:07:45.331] iteration 8457 : model1 loss : 0.023343 model2 loss : 0.025743
[22:07:45.986] iteration 8458 : model1 loss : 0.021738 model2 loss : 0.022480
[22:07:46.638] iteration 8459 : model1 loss : 0.024444 model2 loss : 0.024294
[22:07:47.289] iteration 8460 : model1 loss : 0.024223 model2 loss : 0.023626
[22:07:47.946] iteration 8461 : model1 loss : 0.047581 model2 loss : 0.049713
[22:07:48.597] iteration 8462 : model1 loss : 0.023789 model2 loss : 0.020724
[22:07:49.246] iteration 8463 : model1 loss : 0.023433 model2 loss : 0.026273
[22:07:49.924] iteration 8464 : model1 loss : 0.021645 model2 loss : 0.021240
[22:07:50.588] iteration 8465 : model1 loss : 0.023767 model2 loss : 0.023303
[22:07:51.252] iteration 8466 : model1 loss : 0.147377 model2 loss : 0.144746
[22:07:51.920] iteration 8467 : model1 loss : 0.047277 model2 loss : 0.047719
[22:07:52.578] iteration 8468 : model1 loss : 0.036441 model2 loss : 0.028605
[22:07:53.236] iteration 8469 : model1 loss : 0.027308 model2 loss : 0.031828
[22:07:53.894] iteration 8470 : model1 loss : 0.031067 model2 loss : 0.036379
[22:07:54.551] iteration 8471 : model1 loss : 0.030402 model2 loss : 0.027291
[22:07:55.231] iteration 8472 : model1 loss : 0.027001 model2 loss : 0.026839
[22:07:55.892] iteration 8473 : model1 loss : 0.029652 model2 loss : 0.029978
[22:07:56.564] iteration 8474 : model1 loss : 0.030336 model2 loss : 0.031717
[22:07:57.216] iteration 8475 : model1 loss : 0.052485 model2 loss : 0.051426
[22:07:57.881] iteration 8476 : model1 loss : 0.026693 model2 loss : 0.024817
[22:07:58.537] iteration 8477 : model1 loss : 0.022938 model2 loss : 0.023703
[22:07:59.198] iteration 8478 : model1 loss : 0.038529 model2 loss : 0.033954
[22:07:59.863] iteration 8479 : model1 loss : 0.058344 model2 loss : 0.053473
[22:08:00.532] iteration 8480 : model1 loss : 0.029861 model2 loss : 0.024110
[22:08:01.185] iteration 8481 : model1 loss : 0.024475 model2 loss : 0.023572
[22:08:01.838] iteration 8482 : model1 loss : 0.037815 model2 loss : 0.032652
[22:08:02.505] iteration 8483 : model1 loss : 0.020196 model2 loss : 0.022888
[22:08:03.163] iteration 8484 : model1 loss : 0.036346 model2 loss : 0.037920
[22:08:03.821] iteration 8485 : model1 loss : 0.019674 model2 loss : 0.022369
[22:08:04.488] iteration 8486 : model1 loss : 0.044096 model2 loss : 0.032900
[22:08:05.158] iteration 8487 : model1 loss : 0.027288 model2 loss : 0.027634
[22:08:05.815] iteration 8488 : model1 loss : 0.019621 model2 loss : 0.021037
[22:08:06.472] iteration 8489 : model1 loss : 0.019608 model2 loss : 0.019005
[22:08:07.129] iteration 8490 : model1 loss : 0.027147 model2 loss : 0.028095
[22:08:07.806] iteration 8491 : model1 loss : 0.022328 model2 loss : 0.032004
[22:08:08.471] iteration 8492 : model1 loss : 0.030574 model2 loss : 0.029831
[22:08:09.132] iteration 8493 : model1 loss : 0.026614 model2 loss : 0.033068
[22:08:09.787] iteration 8494 : model1 loss : 0.021837 model2 loss : 0.022530
[22:08:10.435] iteration 8495 : model1 loss : 0.020959 model2 loss : 0.022882
[22:08:11.095] iteration 8496 : model1 loss : 0.026451 model2 loss : 0.027859
[22:08:11.754] iteration 8497 : model1 loss : 0.016964 model2 loss : 0.024933
[22:08:12.410] iteration 8498 : model1 loss : 0.048586 model2 loss : 0.032381
[22:08:13.072] iteration 8499 : model1 loss : 0.024115 model2 loss : 0.027153
[22:08:13.731] iteration 8500 : model1 loss : 0.027684 model2 loss : 0.025024
[22:08:14.430] iteration 8501 : model1 loss : 0.029461 model2 loss : 0.027355
[22:08:15.096] iteration 8502 : model1 loss : 0.033843 model2 loss : 0.052427
[22:08:15.756] iteration 8503 : model1 loss : 0.027595 model2 loss : 0.028323
[22:08:16.414] iteration 8504 : model1 loss : 0.053716 model2 loss : 0.059484
[22:08:17.083] iteration 8505 : model1 loss : 0.021698 model2 loss : 0.023274
[22:08:17.745] iteration 8506 : model1 loss : 0.018064 model2 loss : 0.020307
[22:08:18.394] iteration 8507 : model1 loss : 0.053175 model2 loss : 0.053814
[22:08:19.048] iteration 8508 : model1 loss : 0.026584 model2 loss : 0.026185
[22:08:19.702] iteration 8509 : model1 loss : 0.025533 model2 loss : 0.024533
[22:08:20.366] iteration 8510 : model1 loss : 0.018845 model2 loss : 0.018804
[22:08:21.019] iteration 8511 : model1 loss : 0.024146 model2 loss : 0.022537
[22:08:21.680] iteration 8512 : model1 loss : 0.016799 model2 loss : 0.018749
[22:08:22.341] iteration 8513 : model1 loss : 0.028277 model2 loss : 0.030185
[22:08:22.995] iteration 8514 : model1 loss : 0.036217 model2 loss : 0.055730
[22:08:23.651] iteration 8515 : model1 loss : 0.023176 model2 loss : 0.025704
[22:08:24.304] iteration 8516 : model1 loss : 0.028052 model2 loss : 0.036551
[22:08:24.960] iteration 8517 : model1 loss : 0.037533 model2 loss : 0.030575
[22:08:25.617] iteration 8518 : model1 loss : 0.027389 model2 loss : 0.030301
[22:08:26.271] iteration 8519 : model1 loss : 0.034259 model2 loss : 0.031412
[22:08:26.929] iteration 8520 : model1 loss : 0.027406 model2 loss : 0.029323
[22:08:27.594] iteration 8521 : model1 loss : 0.033637 model2 loss : 0.031468
[22:08:28.260] iteration 8522 : model1 loss : 0.025376 model2 loss : 0.029588
[22:08:28.925] iteration 8523 : model1 loss : 0.022521 model2 loss : 0.024831
[22:08:29.590] iteration 8524 : model1 loss : 0.017743 model2 loss : 0.018674
[22:08:30.250] iteration 8525 : model1 loss : 0.033450 model2 loss : 0.024866
[22:08:30.912] iteration 8526 : model1 loss : 0.027903 model2 loss : 0.024282
[22:08:31.572] iteration 8527 : model1 loss : 0.038710 model2 loss : 0.040035
[22:08:32.220] iteration 8528 : model1 loss : 0.023034 model2 loss : 0.025128
[22:08:32.881] iteration 8529 : model1 loss : 0.022425 model2 loss : 0.023591
[22:08:33.535] iteration 8530 : model1 loss : 0.020481 model2 loss : 0.023411
[22:08:34.196] iteration 8531 : model1 loss : 0.025785 model2 loss : 0.029234
[22:08:34.873] iteration 8532 : model1 loss : 0.028435 model2 loss : 0.027679
[22:08:35.536] iteration 8533 : model1 loss : 0.033669 model2 loss : 0.036904
[22:08:36.210] iteration 8534 : model1 loss : 0.021667 model2 loss : 0.022855
[22:08:36.873] iteration 8535 : model1 loss : 0.019569 model2 loss : 0.020355
[22:08:37.523] iteration 8536 : model1 loss : 0.027696 model2 loss : 0.026591
[22:08:38.194] iteration 8537 : model1 loss : 0.021287 model2 loss : 0.022171
[22:08:38.864] iteration 8538 : model1 loss : 0.029523 model2 loss : 0.026699
[22:08:39.521] iteration 8539 : model1 loss : 0.021706 model2 loss : 0.019079
[22:08:40.189] iteration 8540 : model1 loss : 0.021701 model2 loss : 0.021617
[22:08:40.855] iteration 8541 : model1 loss : 0.031468 model2 loss : 0.037192
[22:08:41.519] iteration 8542 : model1 loss : 0.031858 model2 loss : 0.038160
[22:08:42.180] iteration 8543 : model1 loss : 0.032428 model2 loss : 0.040550
[22:08:42.835] iteration 8544 : model1 loss : 0.026832 model2 loss : 0.027467
[22:08:43.504] iteration 8545 : model1 loss : 0.020804 model2 loss : 0.023243
[22:08:44.156] iteration 8546 : model1 loss : 0.021178 model2 loss : 0.021366
[22:08:44.805] iteration 8547 : model1 loss : 0.019109 model2 loss : 0.019806
[22:08:45.460] iteration 8548 : model1 loss : 0.035534 model2 loss : 0.036331
[22:08:46.111] iteration 8549 : model1 loss : 0.020425 model2 loss : 0.019985
[22:08:46.774] iteration 8550 : model1 loss : 0.025651 model2 loss : 0.025639
[22:08:47.491] iteration 8551 : model1 loss : 0.020506 model2 loss : 0.019513
[22:08:48.150] iteration 8552 : model1 loss : 0.025462 model2 loss : 0.022808
[22:08:48.817] iteration 8553 : model1 loss : 0.033905 model2 loss : 0.038306
[22:08:49.476] iteration 8554 : model1 loss : 0.031890 model2 loss : 0.032125
[22:08:50.137] iteration 8555 : model1 loss : 0.026882 model2 loss : 0.025380
[22:08:50.795] iteration 8556 : model1 loss : 0.036970 model2 loss : 0.047216
[22:08:51.466] iteration 8557 : model1 loss : 0.024636 model2 loss : 0.024605
[22:08:52.128] iteration 8558 : model1 loss : 0.019699 model2 loss : 0.021646
[22:08:52.778] iteration 8559 : model1 loss : 0.023215 model2 loss : 0.024255
[22:08:53.450] iteration 8560 : model1 loss : 0.038289 model2 loss : 0.036020
[22:08:54.099] iteration 8561 : model1 loss : 0.168600 model2 loss : 0.163708
[22:08:54.756] iteration 8562 : model1 loss : 0.023647 model2 loss : 0.021221
[22:08:55.460] iteration 8563 : model1 loss : 0.024782 model2 loss : 0.023516
[22:08:56.110] iteration 8564 : model1 loss : 0.027167 model2 loss : 0.024719
[22:08:56.779] iteration 8565 : model1 loss : 0.025904 model2 loss : 0.027024
[22:08:57.443] iteration 8566 : model1 loss : 0.026473 model2 loss : 0.025975
[22:08:58.092] iteration 8567 : model1 loss : 0.025312 model2 loss : 0.025971
[22:08:58.756] iteration 8568 : model1 loss : 0.024807 model2 loss : 0.024317
[22:08:59.415] iteration 8569 : model1 loss : 0.049350 model2 loss : 0.054026
[22:09:00.070] iteration 8570 : model1 loss : 0.020658 model2 loss : 0.019959
[22:09:00.726] iteration 8571 : model1 loss : 0.020560 model2 loss : 0.019437
[22:09:01.393] iteration 8572 : model1 loss : 0.085497 model2 loss : 0.058607
[22:09:02.056] iteration 8573 : model1 loss : 0.024073 model2 loss : 0.023988
[22:09:02.720] iteration 8574 : model1 loss : 0.022497 model2 loss : 0.021617
[22:09:03.381] iteration 8575 : model1 loss : 0.024788 model2 loss : 0.025973
[22:09:04.041] iteration 8576 : model1 loss : 0.034028 model2 loss : 0.041961
[22:09:04.691] iteration 8577 : model1 loss : 0.034600 model2 loss : 0.039846
[22:09:05.350] iteration 8578 : model1 loss : 0.020950 model2 loss : 0.018732
[22:09:06.020] iteration 8579 : model1 loss : 0.021187 model2 loss : 0.020366
[22:09:06.690] iteration 8580 : model1 loss : 0.041669 model2 loss : 0.029804
[22:09:07.358] iteration 8581 : model1 loss : 0.022488 model2 loss : 0.020711
[22:09:08.009] iteration 8582 : model1 loss : 0.065905 model2 loss : 0.063028
[22:09:08.674] iteration 8583 : model1 loss : 0.026014 model2 loss : 0.042409
[22:09:09.327] iteration 8584 : model1 loss : 0.041500 model2 loss : 0.028130
[22:09:09.989] iteration 8585 : model1 loss : 0.028549 model2 loss : 0.025665
[22:09:10.647] iteration 8586 : model1 loss : 0.036365 model2 loss : 0.035760
[22:09:11.302] iteration 8587 : model1 loss : 0.041860 model2 loss : 0.034126
[22:09:11.960] iteration 8588 : model1 loss : 0.040793 model2 loss : 0.060361
[22:09:12.624] iteration 8589 : model1 loss : 0.022807 model2 loss : 0.021357
[22:09:13.284] iteration 8590 : model1 loss : 0.026403 model2 loss : 0.026153
[22:09:13.939] iteration 8591 : model1 loss : 0.019038 model2 loss : 0.019502
[22:09:14.609] iteration 8592 : model1 loss : 0.037962 model2 loss : 0.068900
[22:09:15.257] iteration 8593 : model1 loss : 0.028788 model2 loss : 0.027270
[22:09:15.911] iteration 8594 : model1 loss : 0.064566 model2 loss : 0.065358
[22:09:16.575] iteration 8595 : model1 loss : 0.028805 model2 loss : 0.029193
[22:09:17.234] iteration 8596 : model1 loss : 0.023297 model2 loss : 0.033008
[22:09:17.899] iteration 8597 : model1 loss : 0.024041 model2 loss : 0.026166
[22:09:18.566] iteration 8598 : model1 loss : 0.039215 model2 loss : 0.030825
[22:09:19.235] iteration 8599 : model1 loss : 0.020870 model2 loss : 0.025698
[22:09:19.900] iteration 8600 : model1 loss : 0.021843 model2 loss : 0.021689
[22:09:37.785] iteration 8600 : model1_mean_dice : 0.830096 model1_mean_hd95 : 8.673062
[22:09:55.906] iteration 8600 : model2_mean_dice : 0.853597 model2_mean_hd95 : 5.770272
[22:09:56.588] iteration 8601 : model1 loss : 0.028940 model2 loss : 0.035782
[22:09:57.240] iteration 8602 : model1 loss : 0.054532 model2 loss : 0.042919
[22:09:57.883] iteration 8603 : model1 loss : 0.021314 model2 loss : 0.025457
[22:09:58.541] iteration 8604 : model1 loss : 0.028570 model2 loss : 0.040159
[22:09:59.192] iteration 8605 : model1 loss : 0.026638 model2 loss : 0.033170
[22:09:59.845] iteration 8606 : model1 loss : 0.026544 model2 loss : 0.027268
[22:10:00.506] iteration 8607 : model1 loss : 0.035668 model2 loss : 0.040309
[22:10:01.154] iteration 8608 : model1 loss : 0.033079 model2 loss : 0.027364
[22:10:01.813] iteration 8609 : model1 loss : 0.029260 model2 loss : 0.033116
[22:10:02.478] iteration 8610 : model1 loss : 0.023656 model2 loss : 0.025818
[22:10:03.128] iteration 8611 : model1 loss : 0.015486 model2 loss : 0.017109
[22:10:03.782] iteration 8612 : model1 loss : 0.037405 model2 loss : 0.031507
[22:10:04.434] iteration 8613 : model1 loss : 0.032721 model2 loss : 0.040293
[22:10:05.096] iteration 8614 : model1 loss : 0.031184 model2 loss : 0.027295
[22:10:05.750] iteration 8615 : model1 loss : 0.021046 model2 loss : 0.022479
[22:10:06.411] iteration 8616 : model1 loss : 0.033430 model2 loss : 0.029857
[22:10:07.067] iteration 8617 : model1 loss : 0.027771 model2 loss : 0.027085
[22:10:07.728] iteration 8618 : model1 loss : 0.019666 model2 loss : 0.020373
[22:10:08.392] iteration 8619 : model1 loss : 0.022073 model2 loss : 0.023592
[22:10:09.051] iteration 8620 : model1 loss : 0.060904 model2 loss : 0.063978
[22:10:09.702] iteration 8621 : model1 loss : 0.023188 model2 loss : 0.023636
[22:10:10.356] iteration 8622 : model1 loss : 0.023172 model2 loss : 0.024687
[22:10:11.009] iteration 8623 : model1 loss : 0.022075 model2 loss : 0.021217
[22:10:11.661] iteration 8624 : model1 loss : 0.021630 model2 loss : 0.024606
[22:10:12.316] iteration 8625 : model1 loss : 0.027025 model2 loss : 0.023783
[22:10:12.970] iteration 8626 : model1 loss : 0.023493 model2 loss : 0.021559
[22:10:13.641] iteration 8627 : model1 loss : 0.031456 model2 loss : 0.025338
[22:10:14.292] iteration 8628 : model1 loss : 0.024035 model2 loss : 0.021995
[22:10:14.958] iteration 8629 : model1 loss : 0.035711 model2 loss : 0.029156
[22:10:15.609] iteration 8630 : model1 loss : 0.028137 model2 loss : 0.028181
[22:10:16.282] iteration 8631 : model1 loss : 0.059696 model2 loss : 0.046700
[22:10:16.932] iteration 8632 : model1 loss : 0.025054 model2 loss : 0.025635
[22:10:17.593] iteration 8633 : model1 loss : 0.038397 model2 loss : 0.034078
[22:10:18.258] iteration 8634 : model1 loss : 0.029108 model2 loss : 0.030556
[22:10:18.913] iteration 8635 : model1 loss : 0.025109 model2 loss : 0.027466
[22:10:19.565] iteration 8636 : model1 loss : 0.034065 model2 loss : 0.034160
[22:10:20.222] iteration 8637 : model1 loss : 0.023427 model2 loss : 0.022742
[22:10:20.876] iteration 8638 : model1 loss : 0.030161 model2 loss : 0.031705
[22:10:21.549] iteration 8639 : model1 loss : 0.027382 model2 loss : 0.030444
[22:10:22.204] iteration 8640 : model1 loss : 0.023189 model2 loss : 0.023296
[22:10:22.876] iteration 8641 : model1 loss : 0.040261 model2 loss : 0.037178
[22:10:23.533] iteration 8642 : model1 loss : 0.032438 model2 loss : 0.023637
[22:10:24.192] iteration 8643 : model1 loss : 0.023038 model2 loss : 0.022160
[22:10:24.851] iteration 8644 : model1 loss : 0.021896 model2 loss : 0.020173
[22:10:25.526] iteration 8645 : model1 loss : 0.024438 model2 loss : 0.029351
[22:10:26.182] iteration 8646 : model1 loss : 0.029036 model2 loss : 0.025872
[22:10:26.829] iteration 8647 : model1 loss : 0.035172 model2 loss : 0.034640
[22:10:27.484] iteration 8648 : model1 loss : 0.022535 model2 loss : 0.024442
[22:10:28.144] iteration 8649 : model1 loss : 0.071073 model2 loss : 0.114055
[22:10:28.799] iteration 8650 : model1 loss : 0.026581 model2 loss : 0.031389
[22:10:29.506] iteration 8651 : model1 loss : 0.023378 model2 loss : 0.031257
[22:10:30.171] iteration 8652 : model1 loss : 0.029759 model2 loss : 0.024003
[22:10:30.826] iteration 8653 : model1 loss : 0.023472 model2 loss : 0.020467
[22:10:31.480] iteration 8654 : model1 loss : 0.034516 model2 loss : 0.029957
[22:10:32.133] iteration 8655 : model1 loss : 0.040689 model2 loss : 0.036399
[22:10:32.797] iteration 8656 : model1 loss : 0.021948 model2 loss : 0.021835
[22:10:33.453] iteration 8657 : model1 loss : 0.044202 model2 loss : 0.024765
[22:10:34.101] iteration 8658 : model1 loss : 0.024025 model2 loss : 0.026426
[22:10:34.765] iteration 8659 : model1 loss : 0.027605 model2 loss : 0.029335
[22:10:35.439] iteration 8660 : model1 loss : 0.024975 model2 loss : 0.026582
[22:10:36.103] iteration 8661 : model1 loss : 0.031779 model2 loss : 0.032948
[22:10:36.771] iteration 8662 : model1 loss : 0.020197 model2 loss : 0.021003
[22:10:37.425] iteration 8663 : model1 loss : 0.028834 model2 loss : 0.032090
[22:10:38.099] iteration 8664 : model1 loss : 0.031315 model2 loss : 0.028991
[22:10:38.760] iteration 8665 : model1 loss : 0.035851 model2 loss : 0.032350
[22:10:39.428] iteration 8666 : model1 loss : 0.057401 model2 loss : 0.039116
[22:10:40.098] iteration 8667 : model1 loss : 0.027447 model2 loss : 0.026976
[22:10:40.760] iteration 8668 : model1 loss : 0.025168 model2 loss : 0.023040
[22:10:41.418] iteration 8669 : model1 loss : 0.022417 model2 loss : 0.022529
[22:10:42.077] iteration 8670 : model1 loss : 0.024410 model2 loss : 0.026014
[22:10:42.728] iteration 8671 : model1 loss : 0.031371 model2 loss : 0.034057
[22:10:43.393] iteration 8672 : model1 loss : 0.025683 model2 loss : 0.026325
[22:10:44.052] iteration 8673 : model1 loss : 0.025088 model2 loss : 0.024641
[22:10:44.707] iteration 8674 : model1 loss : 0.029261 model2 loss : 0.034321
[22:10:45.368] iteration 8675 : model1 loss : 0.036879 model2 loss : 0.036814
[22:10:46.029] iteration 8676 : model1 loss : 0.026510 model2 loss : 0.022957
[22:10:46.689] iteration 8677 : model1 loss : 0.026490 model2 loss : 0.024362
[22:10:47.353] iteration 8678 : model1 loss : 0.023713 model2 loss : 0.026867
[22:10:48.018] iteration 8679 : model1 loss : 0.128350 model2 loss : 0.073944
[22:10:48.695] iteration 8680 : model1 loss : 0.025298 model2 loss : 0.031128
[22:10:49.352] iteration 8681 : model1 loss : 0.030971 model2 loss : 0.028347
[22:10:50.006] iteration 8682 : model1 loss : 0.021519 model2 loss : 0.021585
[22:10:50.664] iteration 8683 : model1 loss : 0.021293 model2 loss : 0.022519
[22:10:51.333] iteration 8684 : model1 loss : 0.026757 model2 loss : 0.023972
[22:10:51.993] iteration 8685 : model1 loss : 0.036816 model2 loss : 0.039106
[22:10:52.655] iteration 8686 : model1 loss : 0.017277 model2 loss : 0.018313
[22:10:53.319] iteration 8687 : model1 loss : 0.030168 model2 loss : 0.023199
[22:10:53.975] iteration 8688 : model1 loss : 0.069998 model2 loss : 0.051952
[22:10:54.635] iteration 8689 : model1 loss : 0.020989 model2 loss : 0.027469
[22:10:55.303] iteration 8690 : model1 loss : 0.021712 model2 loss : 0.024270
[22:10:55.953] iteration 8691 : model1 loss : 0.025925 model2 loss : 0.026723
[22:10:56.640] iteration 8692 : model1 loss : 0.030612 model2 loss : 0.067262
[22:10:57.300] iteration 8693 : model1 loss : 0.018042 model2 loss : 0.024833
[22:10:57.951] iteration 8694 : model1 loss : 0.054021 model2 loss : 0.052935
[22:10:58.607] iteration 8695 : model1 loss : 0.021793 model2 loss : 0.022250
[22:10:59.272] iteration 8696 : model1 loss : 0.021759 model2 loss : 0.026643
[22:10:59.932] iteration 8697 : model1 loss : 0.035610 model2 loss : 0.033974
[22:11:00.589] iteration 8698 : model1 loss : 0.020602 model2 loss : 0.024415
[22:11:01.242] iteration 8699 : model1 loss : 0.028420 model2 loss : 0.033929
[22:11:01.880] iteration 8700 : model1 loss : 0.027488 model2 loss : 0.024547
[22:11:02.571] iteration 8701 : model1 loss : 0.035039 model2 loss : 0.032842
[22:11:03.228] iteration 8702 : model1 loss : 0.020530 model2 loss : 0.022639
[22:11:03.890] iteration 8703 : model1 loss : 0.024270 model2 loss : 0.022540
[22:11:04.557] iteration 8704 : model1 loss : 0.030897 model2 loss : 0.032430
[22:11:05.222] iteration 8705 : model1 loss : 0.019446 model2 loss : 0.021619
[22:11:05.865] iteration 8706 : model1 loss : 0.025629 model2 loss : 0.050740
[22:11:06.532] iteration 8707 : model1 loss : 0.026369 model2 loss : 0.026774
[22:11:07.178] iteration 8708 : model1 loss : 0.020862 model2 loss : 0.021198
[22:11:07.827] iteration 8709 : model1 loss : 0.059903 model2 loss : 0.044731
[22:11:08.483] iteration 8710 : model1 loss : 0.024332 model2 loss : 0.025338
[22:11:09.153] iteration 8711 : model1 loss : 0.023969 model2 loss : 0.026711
[22:11:09.816] iteration 8712 : model1 loss : 0.029643 model2 loss : 0.040446
[22:11:10.476] iteration 8713 : model1 loss : 0.053290 model2 loss : 0.054542
[22:11:11.134] iteration 8714 : model1 loss : 0.024006 model2 loss : 0.024234
[22:11:11.796] iteration 8715 : model1 loss : 0.026041 model2 loss : 0.027200
[22:11:12.459] iteration 8716 : model1 loss : 0.047972 model2 loss : 0.048694
[22:11:13.115] iteration 8717 : model1 loss : 0.022615 model2 loss : 0.021815
[22:11:13.773] iteration 8718 : model1 loss : 0.031149 model2 loss : 0.032290
[22:11:14.440] iteration 8719 : model1 loss : 0.023595 model2 loss : 0.023757
[22:11:15.097] iteration 8720 : model1 loss : 0.030147 model2 loss : 0.029429
[22:11:15.752] iteration 8721 : model1 loss : 0.036358 model2 loss : 0.040712
[22:11:16.412] iteration 8722 : model1 loss : 0.025343 model2 loss : 0.025000
[22:11:17.073] iteration 8723 : model1 loss : 0.059191 model2 loss : 0.066822
[22:11:17.751] iteration 8724 : model1 loss : 0.032941 model2 loss : 0.027384
[22:11:18.399] iteration 8725 : model1 loss : 0.028078 model2 loss : 0.030853
[22:11:19.059] iteration 8726 : model1 loss : 0.018936 model2 loss : 0.019321
[22:11:19.716] iteration 8727 : model1 loss : 0.029551 model2 loss : 0.027309
[22:11:20.400] iteration 8728 : model1 loss : 0.023670 model2 loss : 0.026846
[22:11:21.050] iteration 8729 : model1 loss : 0.025402 model2 loss : 0.023046
[22:11:21.700] iteration 8730 : model1 loss : 0.038732 model2 loss : 0.028827
[22:11:22.369] iteration 8731 : model1 loss : 0.021656 model2 loss : 0.021809
[22:11:23.027] iteration 8732 : model1 loss : 0.023415 model2 loss : 0.027973
[22:11:23.680] iteration 8733 : model1 loss : 0.026023 model2 loss : 0.034412
[22:11:24.352] iteration 8734 : model1 loss : 0.015346 model2 loss : 0.018749
[22:11:25.025] iteration 8735 : model1 loss : 0.051968 model2 loss : 0.048030
[22:11:25.674] iteration 8736 : model1 loss : 0.023207 model2 loss : 0.021018
[22:11:26.338] iteration 8737 : model1 loss : 0.031462 model2 loss : 0.031646
[22:11:26.999] iteration 8738 : model1 loss : 0.028124 model2 loss : 0.024046
[22:11:27.668] iteration 8739 : model1 loss : 0.033209 model2 loss : 0.030323
[22:11:28.325] iteration 8740 : model1 loss : 0.039388 model2 loss : 0.032896
[22:11:28.987] iteration 8741 : model1 loss : 0.023775 model2 loss : 0.025216
[22:11:29.645] iteration 8742 : model1 loss : 0.026010 model2 loss : 0.024676
[22:11:30.300] iteration 8743 : model1 loss : 0.026283 model2 loss : 0.023791
[22:11:30.967] iteration 8744 : model1 loss : 0.032811 model2 loss : 0.039028
[22:11:31.630] iteration 8745 : model1 loss : 0.024301 model2 loss : 0.021827
[22:11:32.290] iteration 8746 : model1 loss : 0.029237 model2 loss : 0.028729
[22:11:32.946] iteration 8747 : model1 loss : 0.028512 model2 loss : 0.025913
[22:11:33.602] iteration 8748 : model1 loss : 0.034171 model2 loss : 0.031938
[22:11:34.258] iteration 8749 : model1 loss : 0.031146 model2 loss : 0.025318
[22:11:34.912] iteration 8750 : model1 loss : 0.025947 model2 loss : 0.030298
[22:11:35.609] iteration 8751 : model1 loss : 0.043564 model2 loss : 0.028071
[22:11:36.265] iteration 8752 : model1 loss : 0.035598 model2 loss : 0.025702
[22:11:36.927] iteration 8753 : model1 loss : 0.021335 model2 loss : 0.022106
[22:11:37.579] iteration 8754 : model1 loss : 0.022508 model2 loss : 0.019728
[22:11:38.226] iteration 8755 : model1 loss : 0.015690 model2 loss : 0.016595
[22:11:38.889] iteration 8756 : model1 loss : 0.031426 model2 loss : 0.023879
[22:11:39.571] iteration 8757 : model1 loss : 0.029655 model2 loss : 0.026877
[22:11:40.239] iteration 8758 : model1 loss : 0.024593 model2 loss : 0.020996
[22:11:40.893] iteration 8759 : model1 loss : 0.030843 model2 loss : 0.026792
[22:11:41.574] iteration 8760 : model1 loss : 0.036666 model2 loss : 0.038836
[22:11:42.224] iteration 8761 : model1 loss : 0.035119 model2 loss : 0.035563
[22:11:42.882] iteration 8762 : model1 loss : 0.026417 model2 loss : 0.027347
[22:11:43.547] iteration 8763 : model1 loss : 0.023805 model2 loss : 0.023618
[22:11:44.204] iteration 8764 : model1 loss : 0.025012 model2 loss : 0.025210
[22:11:44.866] iteration 8765 : model1 loss : 0.025108 model2 loss : 0.023797
[22:11:45.520] iteration 8766 : model1 loss : 0.036284 model2 loss : 0.033943
[22:11:46.199] iteration 8767 : model1 loss : 0.030202 model2 loss : 0.033403
[22:11:46.858] iteration 8768 : model1 loss : 0.030097 model2 loss : 0.030046
[22:11:47.510] iteration 8769 : model1 loss : 0.018870 model2 loss : 0.020895
[22:11:48.171] iteration 8770 : model1 loss : 0.022329 model2 loss : 0.020869
[22:11:48.830] iteration 8771 : model1 loss : 0.023042 model2 loss : 0.021438
[22:11:49.493] iteration 8772 : model1 loss : 0.027298 model2 loss : 0.022663
[22:11:50.152] iteration 8773 : model1 loss : 0.045964 model2 loss : 0.036711
[22:11:50.815] iteration 8774 : model1 loss : 0.020204 model2 loss : 0.017492
[22:11:51.475] iteration 8775 : model1 loss : 0.028219 model2 loss : 0.025021
[22:11:52.134] iteration 8776 : model1 loss : 0.020607 model2 loss : 0.021520
[22:11:52.807] iteration 8777 : model1 loss : 0.028824 model2 loss : 0.027165
[22:11:53.462] iteration 8778 : model1 loss : 0.019307 model2 loss : 0.020188
[22:11:54.113] iteration 8779 : model1 loss : 0.025148 model2 loss : 0.021617
[22:11:54.779] iteration 8780 : model1 loss : 0.027473 model2 loss : 0.035269
[22:11:55.457] iteration 8781 : model1 loss : 0.025602 model2 loss : 0.023738
[22:11:56.125] iteration 8782 : model1 loss : 0.027507 model2 loss : 0.028769
[22:11:56.810] iteration 8783 : model1 loss : 0.031690 model2 loss : 0.029694
[22:11:57.481] iteration 8784 : model1 loss : 0.039838 model2 loss : 0.039243
[22:11:58.132] iteration 8785 : model1 loss : 0.022355 model2 loss : 0.021449
[22:11:58.792] iteration 8786 : model1 loss : 0.021527 model2 loss : 0.023040
[22:11:59.450] iteration 8787 : model1 loss : 0.025959 model2 loss : 0.026323
[22:12:00.101] iteration 8788 : model1 loss : 0.052015 model2 loss : 0.045227
[22:12:00.782] iteration 8789 : model1 loss : 0.024609 model2 loss : 0.021974
[22:12:01.442] iteration 8790 : model1 loss : 0.030074 model2 loss : 0.029693
[22:12:02.112] iteration 8791 : model1 loss : 0.026866 model2 loss : 0.033187
[22:12:02.776] iteration 8792 : model1 loss : 0.023498 model2 loss : 0.023400
[22:12:03.436] iteration 8793 : model1 loss : 0.028170 model2 loss : 0.033348
[22:12:04.098] iteration 8794 : model1 loss : 0.023515 model2 loss : 0.023639
[22:12:04.764] iteration 8795 : model1 loss : 0.024966 model2 loss : 0.024885
[22:12:05.440] iteration 8796 : model1 loss : 0.027752 model2 loss : 0.030009
[22:12:06.106] iteration 8797 : model1 loss : 0.019270 model2 loss : 0.017865
[22:12:06.763] iteration 8798 : model1 loss : 0.023929 model2 loss : 0.024963
[22:12:07.421] iteration 8799 : model1 loss : 0.024055 model2 loss : 0.024315
[22:12:08.084] iteration 8800 : model1 loss : 0.023395 model2 loss : 0.024150
[22:12:26.076] iteration 8800 : model1_mean_dice : 0.849854 model1_mean_hd95 : 5.391126
[22:12:44.097] iteration 8800 : model2_mean_dice : 0.861707 model2_mean_hd95 : 6.449929
[22:12:44.782] iteration 8801 : model1 loss : 0.024062 model2 loss : 0.023743
[22:12:45.430] iteration 8802 : model1 loss : 0.032834 model2 loss : 0.029349
[22:12:46.081] iteration 8803 : model1 loss : 0.031222 model2 loss : 0.030882
[22:12:46.724] iteration 8804 : model1 loss : 0.020355 model2 loss : 0.021147
[22:12:47.382] iteration 8805 : model1 loss : 0.020682 model2 loss : 0.022411
[22:12:48.039] iteration 8806 : model1 loss : 0.068334 model2 loss : 0.137248
[22:12:48.697] iteration 8807 : model1 loss : 0.024959 model2 loss : 0.026185
[22:12:49.360] iteration 8808 : model1 loss : 0.033171 model2 loss : 0.027672
[22:12:50.021] iteration 8809 : model1 loss : 0.027486 model2 loss : 0.041516
[22:12:50.661] iteration 8810 : model1 loss : 0.042120 model2 loss : 0.036028
[22:12:51.318] iteration 8811 : model1 loss : 0.028912 model2 loss : 0.041728
[22:12:51.975] iteration 8812 : model1 loss : 0.032361 model2 loss : 0.027663
[22:12:52.623] iteration 8813 : model1 loss : 0.030418 model2 loss : 0.028180
[22:12:53.278] iteration 8814 : model1 loss : 0.022176 model2 loss : 0.023865
[22:12:53.925] iteration 8815 : model1 loss : 0.049463 model2 loss : 0.119720
[22:12:54.572] iteration 8816 : model1 loss : 0.027902 model2 loss : 0.025239
[22:12:55.225] iteration 8817 : model1 loss : 0.016786 model2 loss : 0.016475
[22:12:55.868] iteration 8818 : model1 loss : 0.031843 model2 loss : 0.028657
[22:12:56.536] iteration 8819 : model1 loss : 0.049116 model2 loss : 0.040297
[22:12:57.216] iteration 8820 : model1 loss : 0.144508 model2 loss : 0.201397
[22:12:57.882] iteration 8821 : model1 loss : 0.022440 model2 loss : 0.021659
[22:12:58.541] iteration 8822 : model1 loss : 0.030607 model2 loss : 0.022832
[22:12:59.194] iteration 8823 : model1 loss : 0.036133 model2 loss : 0.030860
[22:12:59.843] iteration 8824 : model1 loss : 0.023454 model2 loss : 0.022119
[22:13:00.495] iteration 8825 : model1 loss : 0.046568 model2 loss : 0.040452
[22:13:01.158] iteration 8826 : model1 loss : 0.022815 model2 loss : 0.022791
[22:13:01.799] iteration 8827 : model1 loss : 0.031148 model2 loss : 0.028633
[22:13:02.455] iteration 8828 : model1 loss : 0.031403 model2 loss : 0.045596
[22:13:03.108] iteration 8829 : model1 loss : 0.081720 model2 loss : 0.039861
[22:13:03.782] iteration 8830 : model1 loss : 0.025750 model2 loss : 0.035632
[22:13:04.440] iteration 8831 : model1 loss : 0.026446 model2 loss : 0.022391
[22:13:05.096] iteration 8832 : model1 loss : 0.026319 model2 loss : 0.028250
[22:13:05.756] iteration 8833 : model1 loss : 0.031399 model2 loss : 0.037329
[22:13:06.411] iteration 8834 : model1 loss : 0.031232 model2 loss : 0.031909
[22:13:07.070] iteration 8835 : model1 loss : 0.016509 model2 loss : 0.021175
[22:13:07.724] iteration 8836 : model1 loss : 0.024730 model2 loss : 0.027807
[22:13:08.379] iteration 8837 : model1 loss : 0.039567 model2 loss : 0.031403
[22:13:09.041] iteration 8838 : model1 loss : 0.023704 model2 loss : 0.024878
[22:13:09.711] iteration 8839 : model1 loss : 0.030351 model2 loss : 0.025016
[22:13:10.379] iteration 8840 : model1 loss : 0.025753 model2 loss : 0.029706
[22:13:11.041] iteration 8841 : model1 loss : 0.029600 model2 loss : 0.034249
[22:13:11.697] iteration 8842 : model1 loss : 0.028522 model2 loss : 0.027984
[22:13:12.349] iteration 8843 : model1 loss : 0.054710 model2 loss : 0.071362
[22:13:13.008] iteration 8844 : model1 loss : 0.026387 model2 loss : 0.030562
[22:13:13.657] iteration 8845 : model1 loss : 0.025307 model2 loss : 0.024462
[22:13:14.325] iteration 8846 : model1 loss : 0.023761 model2 loss : 0.028060
[22:13:14.977] iteration 8847 : model1 loss : 0.030634 model2 loss : 0.034767
[22:13:15.635] iteration 8848 : model1 loss : 0.024807 model2 loss : 0.026190
[22:13:16.294] iteration 8849 : model1 loss : 0.026107 model2 loss : 0.024925
[22:13:16.948] iteration 8850 : model1 loss : 0.032163 model2 loss : 0.040160
[22:13:17.651] iteration 8851 : model1 loss : 0.021183 model2 loss : 0.021889
[22:13:18.295] iteration 8852 : model1 loss : 0.030737 model2 loss : 0.029384
[22:13:18.947] iteration 8853 : model1 loss : 0.035644 model2 loss : 0.033488
[22:13:19.621] iteration 8854 : model1 loss : 0.038128 model2 loss : 0.042581
[22:13:20.295] iteration 8855 : model1 loss : 0.025182 model2 loss : 0.038905
[22:13:20.959] iteration 8856 : model1 loss : 0.034043 model2 loss : 0.034685
[22:13:21.617] iteration 8857 : model1 loss : 0.048550 model2 loss : 0.052922
[22:13:22.280] iteration 8858 : model1 loss : 0.033851 model2 loss : 0.039841
[22:13:22.936] iteration 8859 : model1 loss : 0.017619 model2 loss : 0.020852
[22:13:23.587] iteration 8860 : model1 loss : 0.023293 model2 loss : 0.022536
[22:13:24.258] iteration 8861 : model1 loss : 0.023409 model2 loss : 0.026115
[22:13:24.907] iteration 8862 : model1 loss : 0.015783 model2 loss : 0.017875
[22:13:25.566] iteration 8863 : model1 loss : 0.022925 model2 loss : 0.024985
[22:13:26.222] iteration 8864 : model1 loss : 0.026403 model2 loss : 0.034004
[22:13:26.871] iteration 8865 : model1 loss : 0.020032 model2 loss : 0.022736
[22:13:27.536] iteration 8866 : model1 loss : 0.025421 model2 loss : 0.027082
[22:13:28.193] iteration 8867 : model1 loss : 0.020196 model2 loss : 0.022949
[22:13:28.852] iteration 8868 : model1 loss : 0.035976 model2 loss : 0.038418
[22:13:29.508] iteration 8869 : model1 loss : 0.065068 model2 loss : 0.092192
[22:13:30.163] iteration 8870 : model1 loss : 0.027333 model2 loss : 0.023256
[22:13:30.821] iteration 8871 : model1 loss : 0.028441 model2 loss : 0.029608
[22:13:31.490] iteration 8872 : model1 loss : 0.023657 model2 loss : 0.028344
[22:13:32.154] iteration 8873 : model1 loss : 0.076841 model2 loss : 0.051400
[22:13:32.814] iteration 8874 : model1 loss : 0.041669 model2 loss : 0.041653
[22:13:33.466] iteration 8875 : model1 loss : 0.032310 model2 loss : 0.033065
[22:13:34.123] iteration 8876 : model1 loss : 0.164288 model2 loss : 0.184549
[22:13:34.788] iteration 8877 : model1 loss : 0.033818 model2 loss : 0.021621
[22:13:35.446] iteration 8878 : model1 loss : 0.039381 model2 loss : 0.044285
[22:13:36.100] iteration 8879 : model1 loss : 0.022066 model2 loss : 0.026807
[22:13:36.755] iteration 8880 : model1 loss : 0.021540 model2 loss : 0.021713
[22:13:37.417] iteration 8881 : model1 loss : 0.025216 model2 loss : 0.029077
[22:13:38.066] iteration 8882 : model1 loss : 0.028072 model2 loss : 0.029723
[22:13:38.726] iteration 8883 : model1 loss : 0.022429 model2 loss : 0.019552
[22:13:39.401] iteration 8884 : model1 loss : 0.021250 model2 loss : 0.022501
[22:13:40.071] iteration 8885 : model1 loss : 0.022364 model2 loss : 0.022097
[22:13:40.736] iteration 8886 : model1 loss : 0.124093 model2 loss : 0.078256
[22:13:41.407] iteration 8887 : model1 loss : 0.024758 model2 loss : 0.026039
[22:13:42.058] iteration 8888 : model1 loss : 0.019119 model2 loss : 0.020683
[22:13:42.727] iteration 8889 : model1 loss : 0.019355 model2 loss : 0.018467
[22:13:43.397] iteration 8890 : model1 loss : 0.023572 model2 loss : 0.024233
[22:13:44.065] iteration 8891 : model1 loss : 0.045017 model2 loss : 0.026062
[22:13:44.714] iteration 8892 : model1 loss : 0.033533 model2 loss : 0.027871
[22:13:45.375] iteration 8893 : model1 loss : 0.027560 model2 loss : 0.028187
[22:13:46.035] iteration 8894 : model1 loss : 0.030977 model2 loss : 0.024924
[22:13:46.691] iteration 8895 : model1 loss : 0.030858 model2 loss : 0.029576
[22:13:47.358] iteration 8896 : model1 loss : 0.033971 model2 loss : 0.037353
[22:13:48.011] iteration 8897 : model1 loss : 0.021785 model2 loss : 0.021038
[22:13:48.674] iteration 8898 : model1 loss : 0.029834 model2 loss : 0.027455
[22:13:49.342] iteration 8899 : model1 loss : 0.021197 model2 loss : 0.023719
[22:13:49.991] iteration 8900 : model1 loss : 0.033609 model2 loss : 0.032620
[22:13:50.692] iteration 8901 : model1 loss : 0.018176 model2 loss : 0.018019
[22:13:51.386] iteration 8902 : model1 loss : 0.025302 model2 loss : 0.024616
[22:13:52.074] iteration 8903 : model1 loss : 0.031956 model2 loss : 0.028150
[22:13:52.737] iteration 8904 : model1 loss : 0.020654 model2 loss : 0.020948
[22:13:53.396] iteration 8905 : model1 loss : 0.053986 model2 loss : 0.045638
[22:13:54.052] iteration 8906 : model1 loss : 0.051573 model2 loss : 0.047770
[22:13:54.716] iteration 8907 : model1 loss : 0.021316 model2 loss : 0.024265
[22:13:55.391] iteration 8908 : model1 loss : 0.024065 model2 loss : 0.026685
[22:13:56.067] iteration 8909 : model1 loss : 0.096875 model2 loss : 0.118315
[22:13:56.732] iteration 8910 : model1 loss : 0.018895 model2 loss : 0.017855
[22:13:57.408] iteration 8911 : model1 loss : 0.020521 model2 loss : 0.023462
[22:13:58.071] iteration 8912 : model1 loss : 0.029527 model2 loss : 0.029475
[22:13:58.736] iteration 8913 : model1 loss : 0.030672 model2 loss : 0.031987
[22:13:59.412] iteration 8914 : model1 loss : 0.033587 model2 loss : 0.033328
[22:14:00.073] iteration 8915 : model1 loss : 0.033631 model2 loss : 0.042542
[22:14:00.733] iteration 8916 : model1 loss : 0.029124 model2 loss : 0.023667
[22:14:01.384] iteration 8917 : model1 loss : 0.026879 model2 loss : 0.029152
[22:14:02.048] iteration 8918 : model1 loss : 0.020766 model2 loss : 0.019110
[22:14:02.722] iteration 8919 : model1 loss : 0.037864 model2 loss : 0.038930
[22:14:03.397] iteration 8920 : model1 loss : 0.050852 model2 loss : 0.048117
[22:14:04.071] iteration 8921 : model1 loss : 0.028299 model2 loss : 0.031043
[22:14:04.736] iteration 8922 : model1 loss : 0.080594 model2 loss : 0.076077
[22:14:05.392] iteration 8923 : model1 loss : 0.025343 model2 loss : 0.031830
[22:14:06.048] iteration 8924 : model1 loss : 0.020552 model2 loss : 0.021177
[22:14:06.706] iteration 8925 : model1 loss : 0.177968 model2 loss : 0.158265
[22:14:07.363] iteration 8926 : model1 loss : 0.029709 model2 loss : 0.026373
[22:14:08.021] iteration 8927 : model1 loss : 0.027475 model2 loss : 0.034254
[22:14:08.679] iteration 8928 : model1 loss : 0.021673 model2 loss : 0.022415
[22:14:09.339] iteration 8929 : model1 loss : 0.026630 model2 loss : 0.025259
[22:14:10.005] iteration 8930 : model1 loss : 0.020759 model2 loss : 0.024822
[22:14:10.671] iteration 8931 : model1 loss : 0.021407 model2 loss : 0.021062
[22:14:11.352] iteration 8932 : model1 loss : 0.028193 model2 loss : 0.033149
[22:14:12.029] iteration 8933 : model1 loss : 0.040459 model2 loss : 0.048216
[22:14:12.706] iteration 8934 : model1 loss : 0.025128 model2 loss : 0.024059
[22:14:13.373] iteration 8935 : model1 loss : 0.034098 model2 loss : 0.032238
[22:14:14.040] iteration 8936 : model1 loss : 0.021809 model2 loss : 0.020700
[22:14:14.703] iteration 8937 : model1 loss : 0.047981 model2 loss : 0.055278
[22:14:15.364] iteration 8938 : model1 loss : 0.034633 model2 loss : 0.028222
[22:14:16.035] iteration 8939 : model1 loss : 0.031057 model2 loss : 0.029031
[22:14:16.695] iteration 8940 : model1 loss : 0.047974 model2 loss : 0.037959
[22:14:17.354] iteration 8941 : model1 loss : 0.026613 model2 loss : 0.023015
[22:14:18.011] iteration 8942 : model1 loss : 0.025021 model2 loss : 0.022158
[22:14:18.678] iteration 8943 : model1 loss : 0.031317 model2 loss : 0.030222
[22:14:19.337] iteration 8944 : model1 loss : 0.029356 model2 loss : 0.028759
[22:14:20.002] iteration 8945 : model1 loss : 0.030600 model2 loss : 0.037608
[22:14:20.646] iteration 8946 : model1 loss : 0.028776 model2 loss : 0.025596
[22:14:21.315] iteration 8947 : model1 loss : 0.026276 model2 loss : 0.024349
[22:14:21.984] iteration 8948 : model1 loss : 0.034191 model2 loss : 0.025009
[22:14:22.645] iteration 8949 : model1 loss : 0.025456 model2 loss : 0.026360
[22:14:23.302] iteration 8950 : model1 loss : 0.026294 model2 loss : 0.028956
[22:14:24.009] iteration 8951 : model1 loss : 0.022027 model2 loss : 0.022110
[22:14:24.671] iteration 8952 : model1 loss : 0.028484 model2 loss : 0.032649
[22:14:25.332] iteration 8953 : model1 loss : 0.023755 model2 loss : 0.023085
[22:14:25.989] iteration 8954 : model1 loss : 0.021330 model2 loss : 0.019341
[22:14:26.649] iteration 8955 : model1 loss : 0.036392 model2 loss : 0.029086
[22:14:27.326] iteration 8956 : model1 loss : 0.028179 model2 loss : 0.024915
[22:14:27.999] iteration 8957 : model1 loss : 0.020379 model2 loss : 0.019519
[22:14:28.672] iteration 8958 : model1 loss : 0.022920 model2 loss : 0.024124
[22:14:29.330] iteration 8959 : model1 loss : 0.030630 model2 loss : 0.037925
[22:14:29.989] iteration 8960 : model1 loss : 0.028042 model2 loss : 0.027165
[22:14:30.646] iteration 8961 : model1 loss : 0.028144 model2 loss : 0.065209
[22:14:31.312] iteration 8962 : model1 loss : 0.027191 model2 loss : 0.023113
[22:14:31.974] iteration 8963 : model1 loss : 0.029032 model2 loss : 0.033836
[22:14:32.645] iteration 8964 : model1 loss : 0.022255 model2 loss : 0.021434
[22:14:33.302] iteration 8965 : model1 loss : 0.026637 model2 loss : 0.027398
[22:14:33.959] iteration 8966 : model1 loss : 0.024864 model2 loss : 0.030125
[22:14:34.616] iteration 8967 : model1 loss : 0.025857 model2 loss : 0.025461
[22:14:35.287] iteration 8968 : model1 loss : 0.021500 model2 loss : 0.022590
[22:14:35.941] iteration 8969 : model1 loss : 0.041471 model2 loss : 0.038930
[22:14:36.605] iteration 8970 : model1 loss : 0.026683 model2 loss : 0.023263
[22:14:37.269] iteration 8971 : model1 loss : 0.036294 model2 loss : 0.033255
[22:14:37.946] iteration 8972 : model1 loss : 0.023794 model2 loss : 0.023225
[22:14:38.611] iteration 8973 : model1 loss : 0.026684 model2 loss : 0.027219
[22:14:39.268] iteration 8974 : model1 loss : 0.018968 model2 loss : 0.019343
[22:14:39.949] iteration 8975 : model1 loss : 0.024463 model2 loss : 0.024602
[22:14:40.610] iteration 8976 : model1 loss : 0.025196 model2 loss : 0.028731
[22:14:41.281] iteration 8977 : model1 loss : 0.026623 model2 loss : 0.031977
[22:14:41.928] iteration 8978 : model1 loss : 0.041615 model2 loss : 0.043539
[22:14:42.589] iteration 8979 : model1 loss : 0.028501 model2 loss : 0.021384
[22:14:43.255] iteration 8980 : model1 loss : 0.023554 model2 loss : 0.023911
[22:14:43.925] iteration 8981 : model1 loss : 0.026698 model2 loss : 0.025777
[22:14:44.609] iteration 8982 : model1 loss : 0.025892 model2 loss : 0.025456
[22:14:45.265] iteration 8983 : model1 loss : 0.018199 model2 loss : 0.018189
[22:14:45.930] iteration 8984 : model1 loss : 0.019109 model2 loss : 0.021033
[22:14:46.592] iteration 8985 : model1 loss : 0.018058 model2 loss : 0.017029
[22:14:47.246] iteration 8986 : model1 loss : 0.039182 model2 loss : 0.030592
[22:14:47.912] iteration 8987 : model1 loss : 0.019434 model2 loss : 0.021488
[22:14:48.576] iteration 8988 : model1 loss : 0.028161 model2 loss : 0.026645
[22:14:49.249] iteration 8989 : model1 loss : 0.020274 model2 loss : 0.020521
[22:14:49.916] iteration 8990 : model1 loss : 0.020757 model2 loss : 0.023559
[22:14:50.590] iteration 8991 : model1 loss : 0.018007 model2 loss : 0.018307
[22:14:51.247] iteration 8992 : model1 loss : 0.019030 model2 loss : 0.020444
[22:14:51.904] iteration 8993 : model1 loss : 0.021872 model2 loss : 0.026048
[22:14:52.570] iteration 8994 : model1 loss : 0.030300 model2 loss : 0.025628
[22:14:53.239] iteration 8995 : model1 loss : 0.026753 model2 loss : 0.023525
[22:14:53.899] iteration 8996 : model1 loss : 0.032872 model2 loss : 0.030597
[22:14:54.552] iteration 8997 : model1 loss : 0.029065 model2 loss : 0.026900
[22:14:55.210] iteration 8998 : model1 loss : 0.026813 model2 loss : 0.026146
[22:14:55.865] iteration 8999 : model1 loss : 0.029763 model2 loss : 0.023821
[22:14:56.525] iteration 9000 : model1 loss : 0.026230 model2 loss : 0.026660
[22:15:14.699] iteration 9000 : model1_mean_dice : 0.834554 model1_mean_hd95 : 11.000953
[22:15:32.673] iteration 9000 : model2_mean_dice : 0.854727 model2_mean_hd95 : 6.633978
[22:15:32.740] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_9000.pth
[22:15:32.801] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_9000.pth
[22:15:33.508] iteration 9001 : model1 loss : 0.025728 model2 loss : 0.023900
[22:15:34.155] iteration 9002 : model1 loss : 0.022873 model2 loss : 0.023570
[22:15:34.815] iteration 9003 : model1 loss : 0.021485 model2 loss : 0.018885
[22:15:35.465] iteration 9004 : model1 loss : 0.065856 model2 loss : 0.045530
[22:15:36.126] iteration 9005 : model1 loss : 0.027822 model2 loss : 0.032038
[22:15:36.773] iteration 9006 : model1 loss : 0.021104 model2 loss : 0.022681
[22:15:37.437] iteration 9007 : model1 loss : 0.054483 model2 loss : 0.047216
[22:15:38.089] iteration 9008 : model1 loss : 0.021506 model2 loss : 0.022904
[22:15:38.748] iteration 9009 : model1 loss : 0.023515 model2 loss : 0.023971
[22:15:39.400] iteration 9010 : model1 loss : 0.024614 model2 loss : 0.024759
[22:15:40.062] iteration 9011 : model1 loss : 0.027575 model2 loss : 0.027241
[22:15:40.711] iteration 9012 : model1 loss : 0.023873 model2 loss : 0.021947
[22:15:41.365] iteration 9013 : model1 loss : 0.020818 model2 loss : 0.019984
[22:15:42.014] iteration 9014 : model1 loss : 0.021394 model2 loss : 0.021219
[22:15:42.688] iteration 9015 : model1 loss : 0.024036 model2 loss : 0.028529
[22:15:43.349] iteration 9016 : model1 loss : 0.022167 model2 loss : 0.024756
[22:15:44.003] iteration 9017 : model1 loss : 0.024216 model2 loss : 0.027595
[22:15:44.661] iteration 9018 : model1 loss : 0.085679 model2 loss : 0.035139
[22:15:45.318] iteration 9019 : model1 loss : 0.029459 model2 loss : 0.022668
[22:15:45.967] iteration 9020 : model1 loss : 0.028766 model2 loss : 0.026665
[22:15:46.633] iteration 9021 : model1 loss : 0.026842 model2 loss : 0.026148
[22:15:47.295] iteration 9022 : model1 loss : 0.022068 model2 loss : 0.025564
[22:15:47.946] iteration 9023 : model1 loss : 0.020621 model2 loss : 0.022674
[22:15:48.600] iteration 9024 : model1 loss : 0.025756 model2 loss : 0.023902
[22:15:49.263] iteration 9025 : model1 loss : 0.039835 model2 loss : 0.038964
[22:15:49.910] iteration 9026 : model1 loss : 0.048102 model2 loss : 0.025888
[22:15:50.568] iteration 9027 : model1 loss : 0.028605 model2 loss : 0.028364
[22:15:51.226] iteration 9028 : model1 loss : 0.029622 model2 loss : 0.025251
[22:15:51.881] iteration 9029 : model1 loss : 0.026687 model2 loss : 0.021944
[22:15:52.546] iteration 9030 : model1 loss : 0.059155 model2 loss : 0.050192
[22:15:53.203] iteration 9031 : model1 loss : 0.027931 model2 loss : 0.020779
[22:15:53.858] iteration 9032 : model1 loss : 0.049884 model2 loss : 0.034925
[22:15:54.525] iteration 9033 : model1 loss : 0.159710 model2 loss : 0.154234
[22:15:55.187] iteration 9034 : model1 loss : 0.019609 model2 loss : 0.021638
[22:15:55.830] iteration 9035 : model1 loss : 0.029293 model2 loss : 0.031525
[22:15:56.495] iteration 9036 : model1 loss : 0.034740 model2 loss : 0.032905
[22:15:57.147] iteration 9037 : model1 loss : 0.024880 model2 loss : 0.023455
[22:15:57.803] iteration 9038 : model1 loss : 0.035202 model2 loss : 0.028026
[22:15:58.521] iteration 9039 : model1 loss : 0.024941 model2 loss : 0.021885
[22:15:59.175] iteration 9040 : model1 loss : 0.027216 model2 loss : 0.022115
[22:15:59.841] iteration 9041 : model1 loss : 0.022701 model2 loss : 0.022387
[22:16:00.505] iteration 9042 : model1 loss : 0.036274 model2 loss : 0.024164
[22:16:01.164] iteration 9043 : model1 loss : 0.029066 model2 loss : 0.031171
[22:16:01.837] iteration 9044 : model1 loss : 0.023272 model2 loss : 0.021858
[22:16:02.500] iteration 9045 : model1 loss : 0.022485 model2 loss : 0.021830
[22:16:03.155] iteration 9046 : model1 loss : 0.025559 model2 loss : 0.026658
[22:16:03.816] iteration 9047 : model1 loss : 0.029909 model2 loss : 0.024713
[22:16:04.473] iteration 9048 : model1 loss : 0.030173 model2 loss : 0.024566
[22:16:05.131] iteration 9049 : model1 loss : 0.023742 model2 loss : 0.022779
[22:16:05.796] iteration 9050 : model1 loss : 0.026616 model2 loss : 0.027747
[22:16:06.520] iteration 9051 : model1 loss : 0.030693 model2 loss : 0.027387
[22:16:07.175] iteration 9052 : model1 loss : 0.025723 model2 loss : 0.023259
[22:16:07.834] iteration 9053 : model1 loss : 0.023915 model2 loss : 0.024038
[22:16:08.489] iteration 9054 : model1 loss : 0.026504 model2 loss : 0.029736
[22:16:09.146] iteration 9055 : model1 loss : 0.018479 model2 loss : 0.018693
[22:16:09.802] iteration 9056 : model1 loss : 0.030945 model2 loss : 0.029568
[22:16:10.464] iteration 9057 : model1 loss : 0.063954 model2 loss : 0.047607
[22:16:11.120] iteration 9058 : model1 loss : 0.028612 model2 loss : 0.031792
[22:16:11.786] iteration 9059 : model1 loss : 0.020564 model2 loss : 0.020397
[22:16:12.460] iteration 9060 : model1 loss : 0.144998 model2 loss : 0.147441
[22:16:13.120] iteration 9061 : model1 loss : 0.026060 model2 loss : 0.027734
[22:16:13.789] iteration 9062 : model1 loss : 0.030030 model2 loss : 0.027700
[22:16:14.454] iteration 9063 : model1 loss : 0.033226 model2 loss : 0.028117
[22:16:15.112] iteration 9064 : model1 loss : 0.033712 model2 loss : 0.031870
[22:16:15.760] iteration 9065 : model1 loss : 0.027567 model2 loss : 0.025322
[22:16:16.419] iteration 9066 : model1 loss : 0.017638 model2 loss : 0.018726
[22:16:17.071] iteration 9067 : model1 loss : 0.021123 model2 loss : 0.019565
[22:16:17.728] iteration 9068 : model1 loss : 0.039924 model2 loss : 0.027882
[22:16:18.388] iteration 9069 : model1 loss : 0.017839 model2 loss : 0.013835
[22:16:19.051] iteration 9070 : model1 loss : 0.021377 model2 loss : 0.019826
[22:16:19.706] iteration 9071 : model1 loss : 0.021583 model2 loss : 0.026308
[22:16:20.379] iteration 9072 : model1 loss : 0.020939 model2 loss : 0.022420
[22:16:21.033] iteration 9073 : model1 loss : 0.055288 model2 loss : 0.043644
[22:16:21.694] iteration 9074 : model1 loss : 0.025840 model2 loss : 0.027087
[22:16:22.360] iteration 9075 : model1 loss : 0.130879 model2 loss : 0.109206
[22:16:23.026] iteration 9076 : model1 loss : 0.020909 model2 loss : 0.022327
[22:16:23.686] iteration 9077 : model1 loss : 0.031260 model2 loss : 0.028059
[22:16:24.347] iteration 9078 : model1 loss : 0.028047 model2 loss : 0.027823
[22:16:25.008] iteration 9079 : model1 loss : 0.030195 model2 loss : 0.025410
[22:16:25.668] iteration 9080 : model1 loss : 0.029440 model2 loss : 0.028010
[22:16:26.323] iteration 9081 : model1 loss : 0.030276 model2 loss : 0.031947
[22:16:26.988] iteration 9082 : model1 loss : 0.020274 model2 loss : 0.017800
[22:16:27.646] iteration 9083 : model1 loss : 0.027700 model2 loss : 0.020799
[22:16:28.289] iteration 9084 : model1 loss : 0.024774 model2 loss : 0.023609
[22:16:28.948] iteration 9085 : model1 loss : 0.023550 model2 loss : 0.025713
[22:16:29.599] iteration 9086 : model1 loss : 0.029570 model2 loss : 0.028984
[22:16:30.271] iteration 9087 : model1 loss : 0.031511 model2 loss : 0.028560
[22:16:30.931] iteration 9088 : model1 loss : 0.023801 model2 loss : 0.023384
[22:16:31.608] iteration 9089 : model1 loss : 0.021592 model2 loss : 0.020409
[22:16:32.267] iteration 9090 : model1 loss : 0.016825 model2 loss : 0.017863
[22:16:32.986] iteration 9091 : model1 loss : 0.024880 model2 loss : 0.025586
[22:16:33.652] iteration 9092 : model1 loss : 0.067694 model2 loss : 0.066855
[22:16:34.328] iteration 9093 : model1 loss : 0.021249 model2 loss : 0.026919
[22:16:35.026] iteration 9094 : model1 loss : 0.021915 model2 loss : 0.024999
[22:16:35.729] iteration 9095 : model1 loss : 0.067147 model2 loss : 0.031640
[22:16:36.405] iteration 9096 : model1 loss : 0.033871 model2 loss : 0.037472
[22:16:37.069] iteration 9097 : model1 loss : 0.027330 model2 loss : 0.027099
[22:16:37.728] iteration 9098 : model1 loss : 0.019903 model2 loss : 0.019011
[22:16:38.399] iteration 9099 : model1 loss : 0.027398 model2 loss : 0.024783
[22:16:39.051] iteration 9100 : model1 loss : 0.029973 model2 loss : 0.035037
[22:16:39.747] iteration 9101 : model1 loss : 0.025430 model2 loss : 0.025089
[22:16:40.413] iteration 9102 : model1 loss : 0.028187 model2 loss : 0.026839
[22:16:41.075] iteration 9103 : model1 loss : 0.028779 model2 loss : 0.025701
[22:16:41.738] iteration 9104 : model1 loss : 0.022294 model2 loss : 0.022348
[22:16:42.423] iteration 9105 : model1 loss : 0.022186 model2 loss : 0.021636
[22:16:43.086] iteration 9106 : model1 loss : 0.036134 model2 loss : 0.029994
[22:16:43.732] iteration 9107 : model1 loss : 0.019955 model2 loss : 0.020739
[22:16:44.405] iteration 9108 : model1 loss : 0.051186 model2 loss : 0.034923
[22:16:45.083] iteration 9109 : model1 loss : 0.027374 model2 loss : 0.030577
[22:16:45.760] iteration 9110 : model1 loss : 0.021518 model2 loss : 0.022206
[22:16:46.416] iteration 9111 : model1 loss : 0.078781 model2 loss : 0.048338
[22:16:47.078] iteration 9112 : model1 loss : 0.027967 model2 loss : 0.027565
[22:16:47.740] iteration 9113 : model1 loss : 0.033161 model2 loss : 0.043300
[22:16:48.411] iteration 9114 : model1 loss : 0.036568 model2 loss : 0.033101
[22:16:49.076] iteration 9115 : model1 loss : 0.025770 model2 loss : 0.023310
[22:16:49.743] iteration 9116 : model1 loss : 0.021223 model2 loss : 0.026269
[22:16:50.397] iteration 9117 : model1 loss : 0.022492 model2 loss : 0.023542
[22:16:51.055] iteration 9118 : model1 loss : 0.026443 model2 loss : 0.019572
[22:16:51.720] iteration 9119 : model1 loss : 0.017403 model2 loss : 0.017145
[22:16:52.372] iteration 9120 : model1 loss : 0.024432 model2 loss : 0.027820
[22:16:53.035] iteration 9121 : model1 loss : 0.028272 model2 loss : 0.025561
[22:16:53.695] iteration 9122 : model1 loss : 0.022253 model2 loss : 0.020639
[22:16:54.364] iteration 9123 : model1 loss : 0.034643 model2 loss : 0.029538
[22:16:55.016] iteration 9124 : model1 loss : 0.025450 model2 loss : 0.027064
[22:16:55.674] iteration 9125 : model1 loss : 0.022074 model2 loss : 0.018941
[22:16:56.331] iteration 9126 : model1 loss : 0.032593 model2 loss : 0.037547
[22:16:56.986] iteration 9127 : model1 loss : 0.033976 model2 loss : 0.030618
[22:16:57.650] iteration 9128 : model1 loss : 0.060735 model2 loss : 0.052311
[22:16:58.300] iteration 9129 : model1 loss : 0.021012 model2 loss : 0.020271
[22:16:59.001] iteration 9130 : model1 loss : 0.032665 model2 loss : 0.052377
[22:16:59.653] iteration 9131 : model1 loss : 0.030572 model2 loss : 0.028185
[22:17:00.315] iteration 9132 : model1 loss : 0.029238 model2 loss : 0.026445
[22:17:00.979] iteration 9133 : model1 loss : 0.031952 model2 loss : 0.029639
[22:17:01.636] iteration 9134 : model1 loss : 0.040938 model2 loss : 0.035108
[22:17:02.301] iteration 9135 : model1 loss : 0.024092 model2 loss : 0.028017
[22:17:02.943] iteration 9136 : model1 loss : 0.019472 model2 loss : 0.018833
[22:17:03.610] iteration 9137 : model1 loss : 0.028715 model2 loss : 0.026718
[22:17:04.273] iteration 9138 : model1 loss : 0.031083 model2 loss : 0.028126
[22:17:04.930] iteration 9139 : model1 loss : 0.089035 model2 loss : 0.039706
[22:17:05.592] iteration 9140 : model1 loss : 0.021252 model2 loss : 0.019007
[22:17:06.263] iteration 9141 : model1 loss : 0.019854 model2 loss : 0.023081
[22:17:06.925] iteration 9142 : model1 loss : 0.021015 model2 loss : 0.024662
[22:17:07.584] iteration 9143 : model1 loss : 0.019771 model2 loss : 0.022081
[22:17:08.241] iteration 9144 : model1 loss : 0.017549 model2 loss : 0.018390
[22:17:08.898] iteration 9145 : model1 loss : 0.020310 model2 loss : 0.025478
[22:17:09.560] iteration 9146 : model1 loss : 0.020879 model2 loss : 0.020817
[22:17:10.219] iteration 9147 : model1 loss : 0.087479 model2 loss : 0.059549
[22:17:10.883] iteration 9148 : model1 loss : 0.024717 model2 loss : 0.025351
[22:17:11.534] iteration 9149 : model1 loss : 0.019276 model2 loss : 0.020259
[22:17:12.198] iteration 9150 : model1 loss : 0.026213 model2 loss : 0.023533
[22:17:12.906] iteration 9151 : model1 loss : 0.026975 model2 loss : 0.024168
[22:17:13.556] iteration 9152 : model1 loss : 0.028325 model2 loss : 0.031550
[22:17:14.218] iteration 9153 : model1 loss : 0.023583 model2 loss : 0.023178
[22:17:14.866] iteration 9154 : model1 loss : 0.027783 model2 loss : 0.028328
[22:17:15.538] iteration 9155 : model1 loss : 0.018570 model2 loss : 0.018229
[22:17:16.204] iteration 9156 : model1 loss : 0.030272 model2 loss : 0.026652
[22:17:16.858] iteration 9157 : model1 loss : 0.033058 model2 loss : 0.046612
[22:17:17.519] iteration 9158 : model1 loss : 0.027958 model2 loss : 0.024799
[22:17:18.178] iteration 9159 : model1 loss : 0.035939 model2 loss : 0.027435
[22:17:18.845] iteration 9160 : model1 loss : 0.042650 model2 loss : 0.055289
[22:17:19.528] iteration 9161 : model1 loss : 0.022914 model2 loss : 0.022176
[22:17:20.185] iteration 9162 : model1 loss : 0.020130 model2 loss : 0.021651
[22:17:20.839] iteration 9163 : model1 loss : 0.022415 model2 loss : 0.019335
[22:17:21.505] iteration 9164 : model1 loss : 0.026421 model2 loss : 0.028280
[22:17:22.169] iteration 9165 : model1 loss : 0.062185 model2 loss : 0.093717
[22:17:22.838] iteration 9166 : model1 loss : 0.027046 model2 loss : 0.029251
[22:17:23.494] iteration 9167 : model1 loss : 0.025455 model2 loss : 0.025610
[22:17:24.144] iteration 9168 : model1 loss : 0.044484 model2 loss : 0.049661
[22:17:24.808] iteration 9169 : model1 loss : 0.026205 model2 loss : 0.032609
[22:17:25.474] iteration 9170 : model1 loss : 0.040802 model2 loss : 0.028234
[22:17:26.143] iteration 9171 : model1 loss : 0.026573 model2 loss : 0.023685
[22:17:26.807] iteration 9172 : model1 loss : 0.022271 model2 loss : 0.023302
[22:17:27.471] iteration 9173 : model1 loss : 0.030472 model2 loss : 0.030194
[22:17:28.122] iteration 9174 : model1 loss : 0.051474 model2 loss : 0.100260
[22:17:28.777] iteration 9175 : model1 loss : 0.051395 model2 loss : 0.083765
[22:17:29.446] iteration 9176 : model1 loss : 0.032565 model2 loss : 0.037321
[22:17:30.106] iteration 9177 : model1 loss : 0.018092 model2 loss : 0.018409
[22:17:30.763] iteration 9178 : model1 loss : 0.023643 model2 loss : 0.024137
[22:17:31.430] iteration 9179 : model1 loss : 0.025866 model2 loss : 0.021500
[22:17:32.093] iteration 9180 : model1 loss : 0.026960 model2 loss : 0.028709
[22:17:32.773] iteration 9181 : model1 loss : 0.035623 model2 loss : 0.040719
[22:17:33.441] iteration 9182 : model1 loss : 0.026581 model2 loss : 0.024488
[22:17:34.089] iteration 9183 : model1 loss : 0.022812 model2 loss : 0.022573
[22:17:34.744] iteration 9184 : model1 loss : 0.034372 model2 loss : 0.040646
[22:17:35.421] iteration 9185 : model1 loss : 0.030279 model2 loss : 0.031154
[22:17:36.108] iteration 9186 : model1 loss : 0.024195 model2 loss : 0.029502
[22:17:36.771] iteration 9187 : model1 loss : 0.051258 model2 loss : 0.053247
[22:17:37.430] iteration 9188 : model1 loss : 0.027896 model2 loss : 0.029890
[22:17:38.088] iteration 9189 : model1 loss : 0.024134 model2 loss : 0.020037
[22:17:38.759] iteration 9190 : model1 loss : 0.027365 model2 loss : 0.026079
[22:17:39.422] iteration 9191 : model1 loss : 0.022716 model2 loss : 0.020664
[22:17:40.083] iteration 9192 : model1 loss : 0.026840 model2 loss : 0.025482
[22:17:41.047] iteration 9193 : model1 loss : 0.027534 model2 loss : 0.024489
[22:17:41.917] iteration 9194 : model1 loss : 0.025640 model2 loss : 0.026098
[22:17:42.734] iteration 9195 : model1 loss : 0.024907 model2 loss : 0.025309
[22:17:43.487] iteration 9196 : model1 loss : 0.018165 model2 loss : 0.017573
[22:17:44.361] iteration 9197 : model1 loss : 0.026944 model2 loss : 0.027308
[22:17:45.231] iteration 9198 : model1 loss : 0.031140 model2 loss : 0.032016
[22:17:46.271] iteration 9199 : model1 loss : 0.030763 model2 loss : 0.030928
[22:17:46.968] iteration 9200 : model1 loss : 0.022187 model2 loss : 0.019078
[22:18:08.226] iteration 9200 : model1_mean_dice : 0.833587 model1_mean_hd95 : 7.007080
[22:18:27.026] iteration 9200 : model2_mean_dice : 0.847060 model2_mean_hd95 : 6.405262
[22:18:27.715] iteration 9201 : model1 loss : 0.021890 model2 loss : 0.028622
[22:18:28.377] iteration 9202 : model1 loss : 0.043686 model2 loss : 0.036962
[22:18:29.058] iteration 9203 : model1 loss : 0.027102 model2 loss : 0.028319
[22:18:29.734] iteration 9204 : model1 loss : 0.024068 model2 loss : 0.022102
[22:18:30.414] iteration 9205 : model1 loss : 0.020230 model2 loss : 0.020901
[22:18:31.079] iteration 9206 : model1 loss : 0.023369 model2 loss : 0.022546
[22:18:31.733] iteration 9207 : model1 loss : 0.024067 model2 loss : 0.027774
[22:18:32.399] iteration 9208 : model1 loss : 0.030011 model2 loss : 0.027362
[22:18:33.058] iteration 9209 : model1 loss : 0.021553 model2 loss : 0.020432
[22:18:33.726] iteration 9210 : model1 loss : 0.029481 model2 loss : 0.019608
[22:18:34.403] iteration 9211 : model1 loss : 0.022569 model2 loss : 0.028630
[22:18:35.068] iteration 9212 : model1 loss : 0.013148 model2 loss : 0.014315
[22:18:35.752] iteration 9213 : model1 loss : 0.020421 model2 loss : 0.026324
[22:18:36.411] iteration 9214 : model1 loss : 0.029728 model2 loss : 0.031693
[22:18:37.067] iteration 9215 : model1 loss : 0.031456 model2 loss : 0.029930
[22:18:37.736] iteration 9216 : model1 loss : 0.022757 model2 loss : 0.051496
[22:18:38.408] iteration 9217 : model1 loss : 0.023738 model2 loss : 0.025310
[22:18:39.074] iteration 9218 : model1 loss : 0.141670 model2 loss : 0.116488
[22:18:39.758] iteration 9219 : model1 loss : 0.047262 model2 loss : 0.057050
[22:18:40.447] iteration 9220 : model1 loss : 0.032306 model2 loss : 0.021106
[22:18:41.135] iteration 9221 : model1 loss : 0.019466 model2 loss : 0.019514
[22:18:41.845] iteration 9222 : model1 loss : 0.028785 model2 loss : 0.023932
[22:18:42.546] iteration 9223 : model1 loss : 0.054303 model2 loss : 0.052114
[22:18:43.255] iteration 9224 : model1 loss : 0.039136 model2 loss : 0.048358
[22:18:43.950] iteration 9225 : model1 loss : 0.035417 model2 loss : 0.036838
[22:18:44.623] iteration 9226 : model1 loss : 0.144199 model2 loss : 0.147480
[22:18:45.300] iteration 9227 : model1 loss : 0.031038 model2 loss : 0.033219
[22:18:45.972] iteration 9228 : model1 loss : 0.028740 model2 loss : 0.029713
[22:18:46.680] iteration 9229 : model1 loss : 0.023719 model2 loss : 0.039094
[22:18:47.359] iteration 9230 : model1 loss : 0.023310 model2 loss : 0.032130
[22:18:48.027] iteration 9231 : model1 loss : 0.040411 model2 loss : 0.091967
[22:18:48.692] iteration 9232 : model1 loss : 0.023661 model2 loss : 0.030817
[22:18:49.357] iteration 9233 : model1 loss : 0.020190 model2 loss : 0.031052
[22:18:50.023] iteration 9234 : model1 loss : 0.021173 model2 loss : 0.035306
[22:18:50.685] iteration 9235 : model1 loss : 0.025104 model2 loss : 0.033347
[22:18:51.344] iteration 9236 : model1 loss : 0.029162 model2 loss : 0.029869
[22:18:52.002] iteration 9237 : model1 loss : 0.025987 model2 loss : 0.028852
[22:18:52.680] iteration 9238 : model1 loss : 0.024248 model2 loss : 0.040873
[22:18:53.357] iteration 9239 : model1 loss : 0.030243 model2 loss : 0.034280
[22:18:54.018] iteration 9240 : model1 loss : 0.022399 model2 loss : 0.026886
[22:18:54.706] iteration 9241 : model1 loss : 0.023076 model2 loss : 0.030116
[22:18:55.431] iteration 9242 : model1 loss : 0.023762 model2 loss : 0.032139
[22:18:56.102] iteration 9243 : model1 loss : 0.021709 model2 loss : 0.023691
[22:18:56.810] iteration 9244 : model1 loss : 0.021110 model2 loss : 0.020295
[22:18:57.479] iteration 9245 : model1 loss : 0.042301 model2 loss : 0.045001
[22:18:58.162] iteration 9246 : model1 loss : 0.026282 model2 loss : 0.026421
[22:18:58.836] iteration 9247 : model1 loss : 0.025927 model2 loss : 0.026452
[22:18:59.525] iteration 9248 : model1 loss : 0.037564 model2 loss : 0.027931
[22:19:00.257] iteration 9249 : model1 loss : 0.026947 model2 loss : 0.033179
[22:19:00.945] iteration 9250 : model1 loss : 0.022191 model2 loss : 0.023480
[22:19:01.653] iteration 9251 : model1 loss : 0.020124 model2 loss : 0.019943
[22:19:02.318] iteration 9252 : model1 loss : 0.027928 model2 loss : 0.026402
[22:19:02.988] iteration 9253 : model1 loss : 0.026468 model2 loss : 0.029357
[22:19:03.653] iteration 9254 : model1 loss : 0.015118 model2 loss : 0.016941
[22:19:04.319] iteration 9255 : model1 loss : 0.028686 model2 loss : 0.019778
[22:19:04.989] iteration 9256 : model1 loss : 0.045151 model2 loss : 0.032948
[22:19:05.648] iteration 9257 : model1 loss : 0.024889 model2 loss : 0.031255
[22:19:06.336] iteration 9258 : model1 loss : 0.035643 model2 loss : 0.034010
[22:19:07.019] iteration 9259 : model1 loss : 0.030337 model2 loss : 0.034395
[22:19:07.690] iteration 9260 : model1 loss : 0.022103 model2 loss : 0.022177
[22:19:08.431] iteration 9261 : model1 loss : 0.030247 model2 loss : 0.028691
[22:19:09.344] iteration 9262 : model1 loss : 0.022247 model2 loss : 0.023326
[22:19:10.037] iteration 9263 : model1 loss : 0.056080 model2 loss : 0.040539
[22:19:10.720] iteration 9264 : model1 loss : 0.021441 model2 loss : 0.038810
[22:19:11.390] iteration 9265 : model1 loss : 0.024779 model2 loss : 0.025419
[22:19:12.058] iteration 9266 : model1 loss : 0.028774 model2 loss : 0.031686
[22:19:12.714] iteration 9267 : model1 loss : 0.024428 model2 loss : 0.026880
[22:19:13.382] iteration 9268 : model1 loss : 0.025611 model2 loss : 0.037922
[22:19:14.048] iteration 9269 : model1 loss : 0.020507 model2 loss : 0.022420
[22:19:14.723] iteration 9270 : model1 loss : 0.022334 model2 loss : 0.022983
[22:19:15.396] iteration 9271 : model1 loss : 0.036851 model2 loss : 0.046554
[22:19:16.058] iteration 9272 : model1 loss : 0.026289 model2 loss : 0.019187
[22:19:16.720] iteration 9273 : model1 loss : 0.022156 model2 loss : 0.025991
[22:19:17.389] iteration 9274 : model1 loss : 0.037331 model2 loss : 0.024124
[22:19:18.064] iteration 9275 : model1 loss : 0.024846 model2 loss : 0.039625
[22:19:18.753] iteration 9276 : model1 loss : 0.034739 model2 loss : 0.041284
[22:19:19.433] iteration 9277 : model1 loss : 0.026530 model2 loss : 0.026001
[22:19:20.102] iteration 9278 : model1 loss : 0.024581 model2 loss : 0.025451
[22:19:20.770] iteration 9279 : model1 loss : 0.019158 model2 loss : 0.024608
[22:19:21.430] iteration 9280 : model1 loss : 0.025872 model2 loss : 0.026307
[22:19:22.089] iteration 9281 : model1 loss : 0.044432 model2 loss : 0.043958
[22:19:22.763] iteration 9282 : model1 loss : 0.038267 model2 loss : 0.044507
[22:19:23.427] iteration 9283 : model1 loss : 0.030310 model2 loss : 0.029074
[22:19:24.098] iteration 9284 : model1 loss : 0.023369 model2 loss : 0.023368
[22:19:24.762] iteration 9285 : model1 loss : 0.026665 model2 loss : 0.022361
[22:19:25.450] iteration 9286 : model1 loss : 0.023341 model2 loss : 0.021949
[22:19:26.111] iteration 9287 : model1 loss : 0.029280 model2 loss : 0.037937
[22:19:26.782] iteration 9288 : model1 loss : 0.042256 model2 loss : 0.037385
[22:19:27.445] iteration 9289 : model1 loss : 0.027967 model2 loss : 0.030821
[22:19:28.110] iteration 9290 : model1 loss : 0.033324 model2 loss : 0.039226
[22:19:28.775] iteration 9291 : model1 loss : 0.018321 model2 loss : 0.018573
[22:19:29.434] iteration 9292 : model1 loss : 0.022341 model2 loss : 0.021676
[22:19:30.101] iteration 9293 : model1 loss : 0.026254 model2 loss : 0.028329
[22:19:30.784] iteration 9294 : model1 loss : 0.026556 model2 loss : 0.022853
[22:19:31.460] iteration 9295 : model1 loss : 0.022499 model2 loss : 0.024755
[22:19:32.119] iteration 9296 : model1 loss : 0.021088 model2 loss : 0.023545
[22:19:32.786] iteration 9297 : model1 loss : 0.025157 model2 loss : 0.026271
[22:19:33.472] iteration 9298 : model1 loss : 0.027166 model2 loss : 0.026067
[22:19:34.131] iteration 9299 : model1 loss : 0.021620 model2 loss : 0.021765
[22:19:34.789] iteration 9300 : model1 loss : 0.023497 model2 loss : 0.022418
[22:19:35.497] iteration 9301 : model1 loss : 0.028486 model2 loss : 0.027525
[22:19:36.169] iteration 9302 : model1 loss : 0.025146 model2 loss : 0.032674
[22:19:36.838] iteration 9303 : model1 loss : 0.042067 model2 loss : 0.037779
[22:19:37.514] iteration 9304 : model1 loss : 0.021491 model2 loss : 0.022567
[22:19:38.190] iteration 9305 : model1 loss : 0.019643 model2 loss : 0.020937
[22:19:38.866] iteration 9306 : model1 loss : 0.035879 model2 loss : 0.050216
[22:19:39.539] iteration 9307 : model1 loss : 0.036145 model2 loss : 0.040325
[22:19:40.213] iteration 9308 : model1 loss : 0.032692 model2 loss : 0.048670
[22:19:40.892] iteration 9309 : model1 loss : 0.030230 model2 loss : 0.031756
[22:19:41.563] iteration 9310 : model1 loss : 0.027812 model2 loss : 0.028053
[22:19:42.238] iteration 9311 : model1 loss : 0.022949 model2 loss : 0.023686
[22:19:42.925] iteration 9312 : model1 loss : 0.043562 model2 loss : 0.049292
[22:19:43.594] iteration 9313 : model1 loss : 0.029209 model2 loss : 0.031210
[22:19:44.259] iteration 9314 : model1 loss : 0.021486 model2 loss : 0.018869
[22:19:44.955] iteration 9315 : model1 loss : 0.043157 model2 loss : 0.036620
[22:19:45.627] iteration 9316 : model1 loss : 0.026686 model2 loss : 0.025390
[22:19:46.300] iteration 9317 : model1 loss : 0.024284 model2 loss : 0.033878
[22:19:46.974] iteration 9318 : model1 loss : 0.036559 model2 loss : 0.035801
[22:19:47.632] iteration 9319 : model1 loss : 0.025152 model2 loss : 0.023442
[22:19:48.304] iteration 9320 : model1 loss : 0.042588 model2 loss : 0.048968
[22:19:48.978] iteration 9321 : model1 loss : 0.035939 model2 loss : 0.037458
[22:19:49.663] iteration 9322 : model1 loss : 0.026766 model2 loss : 0.051347
[22:19:50.325] iteration 9323 : model1 loss : 0.021202 model2 loss : 0.023080
[22:19:50.992] iteration 9324 : model1 loss : 0.016300 model2 loss : 0.015657
[22:19:51.665] iteration 9325 : model1 loss : 0.022927 model2 loss : 0.021601
[22:19:52.331] iteration 9326 : model1 loss : 0.020508 model2 loss : 0.021068
[22:19:53.004] iteration 9327 : model1 loss : 0.042004 model2 loss : 0.036806
[22:19:53.684] iteration 9328 : model1 loss : 0.027450 model2 loss : 0.034497
[22:19:54.350] iteration 9329 : model1 loss : 0.023539 model2 loss : 0.025291
[22:19:55.025] iteration 9330 : model1 loss : 0.031172 model2 loss : 0.033445
[22:19:55.699] iteration 9331 : model1 loss : 0.024775 model2 loss : 0.039736
[22:19:56.370] iteration 9332 : model1 loss : 0.033779 model2 loss : 0.043676
[22:19:57.050] iteration 9333 : model1 loss : 0.023686 model2 loss : 0.025413
[22:19:57.720] iteration 9334 : model1 loss : 0.017699 model2 loss : 0.016795
[22:19:58.386] iteration 9335 : model1 loss : 0.030828 model2 loss : 0.033412
[22:19:59.039] iteration 9336 : model1 loss : 0.020918 model2 loss : 0.019487
[22:19:59.705] iteration 9337 : model1 loss : 0.028694 model2 loss : 0.028975
[22:20:00.401] iteration 9338 : model1 loss : 0.041779 model2 loss : 0.036228
[22:20:01.078] iteration 9339 : model1 loss : 0.060138 model2 loss : 0.037008
[22:20:01.742] iteration 9340 : model1 loss : 0.021638 model2 loss : 0.032100
[22:20:02.412] iteration 9341 : model1 loss : 0.022590 model2 loss : 0.026311
[22:20:03.087] iteration 9342 : model1 loss : 0.023227 model2 loss : 0.024363
[22:20:03.754] iteration 9343 : model1 loss : 0.017106 model2 loss : 0.017885
[22:20:04.415] iteration 9344 : model1 loss : 0.027739 model2 loss : 0.024303
[22:20:05.075] iteration 9345 : model1 loss : 0.028788 model2 loss : 0.023746
[22:20:05.749] iteration 9346 : model1 loss : 0.027272 model2 loss : 0.025204
[22:20:06.411] iteration 9347 : model1 loss : 0.049040 model2 loss : 0.035892
[22:20:07.083] iteration 9348 : model1 loss : 0.022411 model2 loss : 0.022624
[22:20:07.752] iteration 9349 : model1 loss : 0.023052 model2 loss : 0.022355
[22:20:08.420] iteration 9350 : model1 loss : 0.019219 model2 loss : 0.018554
[22:20:09.130] iteration 9351 : model1 loss : 0.029199 model2 loss : 0.032396
[22:20:09.798] iteration 9352 : model1 loss : 0.029402 model2 loss : 0.029035
[22:20:10.470] iteration 9353 : model1 loss : 0.034838 model2 loss : 0.020107
[22:20:11.149] iteration 9354 : model1 loss : 0.028083 model2 loss : 0.019413
[22:20:11.820] iteration 9355 : model1 loss : 0.029309 model2 loss : 0.029481
[22:20:12.506] iteration 9356 : model1 loss : 0.023410 model2 loss : 0.021869
[22:20:13.177] iteration 9357 : model1 loss : 0.021249 model2 loss : 0.022904
[22:20:13.857] iteration 9358 : model1 loss : 0.029889 model2 loss : 0.028131
[22:20:14.524] iteration 9359 : model1 loss : 0.030128 model2 loss : 0.026650
[22:20:15.205] iteration 9360 : model1 loss : 0.023541 model2 loss : 0.021997
[22:20:15.893] iteration 9361 : model1 loss : 0.028424 model2 loss : 0.026941
[22:20:16.556] iteration 9362 : model1 loss : 0.027805 model2 loss : 0.027687
[22:20:17.224] iteration 9363 : model1 loss : 0.031888 model2 loss : 0.032197
[22:20:17.891] iteration 9364 : model1 loss : 0.031818 model2 loss : 0.036920
[22:20:18.564] iteration 9365 : model1 loss : 0.046557 model2 loss : 0.046728
[22:20:19.238] iteration 9366 : model1 loss : 0.020199 model2 loss : 0.017543
[22:20:19.903] iteration 9367 : model1 loss : 0.022428 model2 loss : 0.023060
[22:20:20.569] iteration 9368 : model1 loss : 0.028662 model2 loss : 0.026707
[22:20:21.255] iteration 9369 : model1 loss : 0.023766 model2 loss : 0.025886
[22:20:21.923] iteration 9370 : model1 loss : 0.022362 model2 loss : 0.022764
[22:20:22.601] iteration 9371 : model1 loss : 0.072286 model2 loss : 0.065998
[22:20:23.275] iteration 9372 : model1 loss : 0.070703 model2 loss : 0.057494
[22:20:23.940] iteration 9373 : model1 loss : 0.024170 model2 loss : 0.025456
[22:20:24.614] iteration 9374 : model1 loss : 0.024638 model2 loss : 0.026747
[22:20:25.279] iteration 9375 : model1 loss : 0.025246 model2 loss : 0.024810
[22:20:25.966] iteration 9376 : model1 loss : 0.025384 model2 loss : 0.026150
[22:20:26.626] iteration 9377 : model1 loss : 0.023164 model2 loss : 0.022686
[22:20:27.294] iteration 9378 : model1 loss : 0.025732 model2 loss : 0.024225
[22:20:27.953] iteration 9379 : model1 loss : 0.051304 model2 loss : 0.052236
[22:20:28.625] iteration 9380 : model1 loss : 0.029064 model2 loss : 0.029995
[22:20:29.313] iteration 9381 : model1 loss : 0.038301 model2 loss : 0.040044
[22:20:29.987] iteration 9382 : model1 loss : 0.032958 model2 loss : 0.042202
[22:20:30.647] iteration 9383 : model1 loss : 0.034184 model2 loss : 0.022801
[22:20:31.315] iteration 9384 : model1 loss : 0.031832 model2 loss : 0.033137
[22:20:31.979] iteration 9385 : model1 loss : 0.020335 model2 loss : 0.019274
[22:20:32.642] iteration 9386 : model1 loss : 0.044424 model2 loss : 0.065061
[22:20:33.322] iteration 9387 : model1 loss : 0.033970 model2 loss : 0.030453
[22:20:33.996] iteration 9388 : model1 loss : 0.028629 model2 loss : 0.028118
[22:20:34.666] iteration 9389 : model1 loss : 0.025744 model2 loss : 0.024524
[22:20:35.336] iteration 9390 : model1 loss : 0.026336 model2 loss : 0.028935
[22:20:36.021] iteration 9391 : model1 loss : 0.153358 model2 loss : 0.157788
[22:20:36.692] iteration 9392 : model1 loss : 0.027203 model2 loss : 0.033693
[22:20:37.391] iteration 9393 : model1 loss : 0.019837 model2 loss : 0.022810
[22:20:38.067] iteration 9394 : model1 loss : 0.020070 model2 loss : 0.022228
[22:20:38.741] iteration 9395 : model1 loss : 0.025139 model2 loss : 0.024307
[22:20:39.412] iteration 9396 : model1 loss : 0.046098 model2 loss : 0.045973
[22:20:40.084] iteration 9397 : model1 loss : 0.019617 model2 loss : 0.019003
[22:20:40.747] iteration 9398 : model1 loss : 0.015539 model2 loss : 0.024387
[22:20:41.428] iteration 9399 : model1 loss : 0.021995 model2 loss : 0.025649
[22:20:42.104] iteration 9400 : model1 loss : 0.019825 model2 loss : 0.020791
[22:21:00.393] iteration 9400 : model1_mean_dice : 0.834157 model1_mean_hd95 : 16.373918
[22:21:18.691] iteration 9400 : model2_mean_dice : 0.821066 model2_mean_hd95 : 21.669629
[22:21:19.386] iteration 9401 : model1 loss : 0.025478 model2 loss : 0.025072
[22:21:20.048] iteration 9402 : model1 loss : 0.022678 model2 loss : 0.022220
[22:21:20.707] iteration 9403 : model1 loss : 0.027827 model2 loss : 0.024380
[22:21:21.373] iteration 9404 : model1 loss : 0.024267 model2 loss : 0.027627
[22:21:22.035] iteration 9405 : model1 loss : 0.027322 model2 loss : 0.028277
[22:21:22.693] iteration 9406 : model1 loss : 0.018582 model2 loss : 0.023223
[22:21:23.630] iteration 9407 : model1 loss : 0.025190 model2 loss : 0.023825
[22:21:24.344] iteration 9408 : model1 loss : 0.027528 model2 loss : 0.026158
[22:21:25.043] iteration 9409 : model1 loss : 0.029728 model2 loss : 0.031342
[22:21:25.697] iteration 9410 : model1 loss : 0.024925 model2 loss : 0.023363
[22:21:26.360] iteration 9411 : model1 loss : 0.029723 model2 loss : 0.035161
[22:21:27.026] iteration 9412 : model1 loss : 0.023349 model2 loss : 0.023195
[22:21:27.697] iteration 9413 : model1 loss : 0.017754 model2 loss : 0.019267
[22:21:28.365] iteration 9414 : model1 loss : 0.021144 model2 loss : 0.023707
[22:21:29.032] iteration 9415 : model1 loss : 0.023770 model2 loss : 0.023096
[22:21:29.690] iteration 9416 : model1 loss : 0.023691 model2 loss : 0.019062
[22:21:30.356] iteration 9417 : model1 loss : 0.031407 model2 loss : 0.023877
[22:21:31.019] iteration 9418 : model1 loss : 0.026799 model2 loss : 0.026503
[22:21:31.689] iteration 9419 : model1 loss : 0.021686 model2 loss : 0.020847
[22:21:32.354] iteration 9420 : model1 loss : 0.027241 model2 loss : 0.026982
[22:21:33.024] iteration 9421 : model1 loss : 0.022466 model2 loss : 0.026348
[22:21:33.689] iteration 9422 : model1 loss : 0.022259 model2 loss : 0.020709
[22:21:34.362] iteration 9423 : model1 loss : 0.028297 model2 loss : 0.026261
[22:21:35.044] iteration 9424 : model1 loss : 0.024673 model2 loss : 0.023809
[22:21:35.712] iteration 9425 : model1 loss : 0.028349 model2 loss : 0.028764
[22:21:36.388] iteration 9426 : model1 loss : 0.027290 model2 loss : 0.031784
[22:21:37.037] iteration 9427 : model1 loss : 0.024850 model2 loss : 0.027089
[22:21:37.700] iteration 9428 : model1 loss : 0.019030 model2 loss : 0.019815
[22:21:38.394] iteration 9429 : model1 loss : 0.024973 model2 loss : 0.020926
[22:21:39.065] iteration 9430 : model1 loss : 0.019123 model2 loss : 0.016505
[22:21:39.736] iteration 9431 : model1 loss : 0.021906 model2 loss : 0.020920
[22:21:40.414] iteration 9432 : model1 loss : 0.095315 model2 loss : 0.115584
[22:21:41.082] iteration 9433 : model1 loss : 0.023269 model2 loss : 0.024386
[22:21:41.742] iteration 9434 : model1 loss : 0.018500 model2 loss : 0.018648
[22:21:42.412] iteration 9435 : model1 loss : 0.043032 model2 loss : 0.038040
[22:21:43.081] iteration 9436 : model1 loss : 0.026463 model2 loss : 0.024116
[22:21:43.746] iteration 9437 : model1 loss : 0.025493 model2 loss : 0.027214
[22:21:44.415] iteration 9438 : model1 loss : 0.038250 model2 loss : 0.038845
[22:21:45.083] iteration 9439 : model1 loss : 0.025025 model2 loss : 0.026021
[22:21:45.747] iteration 9440 : model1 loss : 0.033550 model2 loss : 0.031177
[22:21:46.422] iteration 9441 : model1 loss : 0.020039 model2 loss : 0.021257
[22:21:47.088] iteration 9442 : model1 loss : 0.024443 model2 loss : 0.028202
[22:21:47.750] iteration 9443 : model1 loss : 0.017569 model2 loss : 0.018362
[22:21:48.418] iteration 9444 : model1 loss : 0.022094 model2 loss : 0.025676
[22:21:49.088] iteration 9445 : model1 loss : 0.014438 model2 loss : 0.017366
[22:21:49.746] iteration 9446 : model1 loss : 0.018537 model2 loss : 0.023964
[22:21:50.413] iteration 9447 : model1 loss : 0.020489 model2 loss : 0.019878
[22:21:51.087] iteration 9448 : model1 loss : 0.019073 model2 loss : 0.018215
[22:21:51.772] iteration 9449 : model1 loss : 0.031360 model2 loss : 0.029475
[22:21:52.445] iteration 9450 : model1 loss : 0.020532 model2 loss : 0.021137
[22:21:53.147] iteration 9451 : model1 loss : 0.022769 model2 loss : 0.025896
[22:21:53.812] iteration 9452 : model1 loss : 0.019082 model2 loss : 0.019583
[22:21:54.477] iteration 9453 : model1 loss : 0.020759 model2 loss : 0.022983
[22:21:55.154] iteration 9454 : model1 loss : 0.023822 model2 loss : 0.023621
[22:21:55.827] iteration 9455 : model1 loss : 0.024076 model2 loss : 0.025424
[22:21:56.501] iteration 9456 : model1 loss : 0.018248 model2 loss : 0.021461
[22:21:57.164] iteration 9457 : model1 loss : 0.037297 model2 loss : 0.029457
[22:21:57.818] iteration 9458 : model1 loss : 0.027620 model2 loss : 0.027891
[22:21:58.490] iteration 9459 : model1 loss : 0.158440 model2 loss : 0.179654
[22:21:59.148] iteration 9460 : model1 loss : 0.018260 model2 loss : 0.020371
[22:21:59.817] iteration 9461 : model1 loss : 0.024708 model2 loss : 0.027367
[22:22:00.486] iteration 9462 : model1 loss : 0.018840 model2 loss : 0.022376
[22:22:01.162] iteration 9463 : model1 loss : 0.021430 model2 loss : 0.023614
[22:22:01.870] iteration 9464 : model1 loss : 0.029407 model2 loss : 0.030259
[22:22:02.557] iteration 9465 : model1 loss : 0.028963 model2 loss : 0.078459
[22:22:03.235] iteration 9466 : model1 loss : 0.022353 model2 loss : 0.023252
[22:22:03.903] iteration 9467 : model1 loss : 0.023131 model2 loss : 0.027308
[22:22:04.579] iteration 9468 : model1 loss : 0.016752 model2 loss : 0.018500
[22:22:05.269] iteration 9469 : model1 loss : 0.033600 model2 loss : 0.039620
[22:22:05.943] iteration 9470 : model1 loss : 0.023617 model2 loss : 0.024143
[22:22:06.624] iteration 9471 : model1 loss : 0.031962 model2 loss : 0.035858
[22:22:07.294] iteration 9472 : model1 loss : 0.035735 model2 loss : 0.036256
[22:22:07.945] iteration 9473 : model1 loss : 0.027839 model2 loss : 0.032553
[22:22:08.615] iteration 9474 : model1 loss : 0.022804 model2 loss : 0.025729
[22:22:09.288] iteration 9475 : model1 loss : 0.029829 model2 loss : 0.055434
[22:22:09.955] iteration 9476 : model1 loss : 0.020675 model2 loss : 0.033322
[22:22:10.622] iteration 9477 : model1 loss : 0.051451 model2 loss : 0.046338
[22:22:11.280] iteration 9478 : model1 loss : 0.023705 model2 loss : 0.026557
[22:22:11.937] iteration 9479 : model1 loss : 0.027774 model2 loss : 0.025749
[22:22:12.615] iteration 9480 : model1 loss : 0.020157 model2 loss : 0.022477
[22:22:13.284] iteration 9481 : model1 loss : 0.023446 model2 loss : 0.027687
[22:22:13.947] iteration 9482 : model1 loss : 0.020083 model2 loss : 0.021222
[22:22:14.605] iteration 9483 : model1 loss : 0.015870 model2 loss : 0.017811
[22:22:15.278] iteration 9484 : model1 loss : 0.024302 model2 loss : 0.031145
[22:22:15.959] iteration 9485 : model1 loss : 0.022598 model2 loss : 0.020881
[22:22:16.616] iteration 9486 : model1 loss : 0.023687 model2 loss : 0.019701
[22:22:17.282] iteration 9487 : model1 loss : 0.019008 model2 loss : 0.020275
[22:22:17.944] iteration 9488 : model1 loss : 0.025114 model2 loss : 0.027200
[22:22:18.620] iteration 9489 : model1 loss : 0.026211 model2 loss : 0.035015
[22:22:19.284] iteration 9490 : model1 loss : 0.020064 model2 loss : 0.020955
[22:22:19.958] iteration 9491 : model1 loss : 0.024758 model2 loss : 0.025535
[22:22:20.619] iteration 9492 : model1 loss : 0.022836 model2 loss : 0.023627
[22:22:21.302] iteration 9493 : model1 loss : 0.020118 model2 loss : 0.021813
[22:22:21.960] iteration 9494 : model1 loss : 0.022608 model2 loss : 0.021547
[22:22:22.631] iteration 9495 : model1 loss : 0.017992 model2 loss : 0.020106
[22:22:23.293] iteration 9496 : model1 loss : 0.034708 model2 loss : 0.043168
[22:22:23.955] iteration 9497 : model1 loss : 0.027062 model2 loss : 0.028250
[22:22:24.624] iteration 9498 : model1 loss : 0.020423 model2 loss : 0.029797
[22:22:25.290] iteration 9499 : model1 loss : 0.024442 model2 loss : 0.021511
[22:22:25.958] iteration 9500 : model1 loss : 0.031619 model2 loss : 0.045316
[22:22:26.663] iteration 9501 : model1 loss : 0.033322 model2 loss : 0.028191
[22:22:27.331] iteration 9502 : model1 loss : 0.025016 model2 loss : 0.025949
[22:22:27.989] iteration 9503 : model1 loss : 0.034310 model2 loss : 0.047320
[22:22:28.666] iteration 9504 : model1 loss : 0.024337 model2 loss : 0.020598
[22:22:29.329] iteration 9505 : model1 loss : 0.022887 model2 loss : 0.024990
[22:22:29.995] iteration 9506 : model1 loss : 0.025676 model2 loss : 0.027016
[22:22:30.649] iteration 9507 : model1 loss : 0.023863 model2 loss : 0.023365
[22:22:31.322] iteration 9508 : model1 loss : 0.029797 model2 loss : 0.039733
[22:22:31.973] iteration 9509 : model1 loss : 0.031073 model2 loss : 0.032978
[22:22:32.655] iteration 9510 : model1 loss : 0.027075 model2 loss : 0.026797
[22:22:33.330] iteration 9511 : model1 loss : 0.026129 model2 loss : 0.024081
[22:22:34.012] iteration 9512 : model1 loss : 0.026962 model2 loss : 0.031995
[22:22:34.681] iteration 9513 : model1 loss : 0.028691 model2 loss : 0.030216
[22:22:35.372] iteration 9514 : model1 loss : 0.019804 model2 loss : 0.020358
[22:22:36.038] iteration 9515 : model1 loss : 0.030371 model2 loss : 0.036968
[22:22:36.706] iteration 9516 : model1 loss : 0.017941 model2 loss : 0.016123
[22:22:37.384] iteration 9517 : model1 loss : 0.031669 model2 loss : 0.032396
[22:22:38.055] iteration 9518 : model1 loss : 0.026545 model2 loss : 0.027304
[22:22:38.721] iteration 9519 : model1 loss : 0.030424 model2 loss : 0.033586
[22:22:39.395] iteration 9520 : model1 loss : 0.024644 model2 loss : 0.027765
[22:22:40.059] iteration 9521 : model1 loss : 0.043954 model2 loss : 0.051607
[22:22:40.726] iteration 9522 : model1 loss : 0.025308 model2 loss : 0.026234
[22:22:41.388] iteration 9523 : model1 loss : 0.031195 model2 loss : 0.034304
[22:22:42.057] iteration 9524 : model1 loss : 0.023934 model2 loss : 0.024452
[22:22:42.727] iteration 9525 : model1 loss : 0.026232 model2 loss : 0.025197
[22:22:43.405] iteration 9526 : model1 loss : 0.020392 model2 loss : 0.027186
[22:22:44.063] iteration 9527 : model1 loss : 0.023274 model2 loss : 0.020190
[22:22:44.726] iteration 9528 : model1 loss : 0.023590 model2 loss : 0.025217
[22:22:45.406] iteration 9529 : model1 loss : 0.032565 model2 loss : 0.036673
[22:22:46.070] iteration 9530 : model1 loss : 0.032539 model2 loss : 0.028510
[22:22:46.747] iteration 9531 : model1 loss : 0.041292 model2 loss : 0.041684
[22:22:47.417] iteration 9532 : model1 loss : 0.019339 model2 loss : 0.021113
[22:22:48.087] iteration 9533 : model1 loss : 0.019153 model2 loss : 0.020296
[22:22:48.751] iteration 9534 : model1 loss : 0.020089 model2 loss : 0.021411
[22:22:49.420] iteration 9535 : model1 loss : 0.023151 model2 loss : 0.022915
[22:22:50.070] iteration 9536 : model1 loss : 0.022791 model2 loss : 0.025779
[22:22:50.749] iteration 9537 : model1 loss : 0.019806 model2 loss : 0.020718
[22:22:51.426] iteration 9538 : model1 loss : 0.028472 model2 loss : 0.031239
[22:22:52.113] iteration 9539 : model1 loss : 0.021954 model2 loss : 0.021330
[22:22:52.799] iteration 9540 : model1 loss : 0.033887 model2 loss : 0.029965
[22:22:53.468] iteration 9541 : model1 loss : 0.047218 model2 loss : 0.032282
[22:22:54.146] iteration 9542 : model1 loss : 0.021540 model2 loss : 0.022234
[22:22:54.817] iteration 9543 : model1 loss : 0.019905 model2 loss : 0.018881
[22:22:55.479] iteration 9544 : model1 loss : 0.019153 model2 loss : 0.017702
[22:22:56.148] iteration 9545 : model1 loss : 0.023852 model2 loss : 0.025538
[22:22:56.828] iteration 9546 : model1 loss : 0.019887 model2 loss : 0.020009
[22:22:57.498] iteration 9547 : model1 loss : 0.033531 model2 loss : 0.032355
[22:22:58.161] iteration 9548 : model1 loss : 0.052748 model2 loss : 0.045843
[22:22:58.851] iteration 9549 : model1 loss : 0.020254 model2 loss : 0.021299
[22:22:59.546] iteration 9550 : model1 loss : 0.021433 model2 loss : 0.025024
[22:23:00.297] iteration 9551 : model1 loss : 0.028778 model2 loss : 0.035720
[22:23:01.001] iteration 9552 : model1 loss : 0.022177 model2 loss : 0.023776
[22:23:01.702] iteration 9553 : model1 loss : 0.017156 model2 loss : 0.020558
[22:23:02.388] iteration 9554 : model1 loss : 0.024184 model2 loss : 0.024866
[22:23:03.060] iteration 9555 : model1 loss : 0.024381 model2 loss : 0.037350
[22:23:03.723] iteration 9556 : model1 loss : 0.021954 model2 loss : 0.020679
[22:23:04.414] iteration 9557 : model1 loss : 0.019838 model2 loss : 0.021201
[22:23:05.109] iteration 9558 : model1 loss : 0.037643 model2 loss : 0.040687
[22:23:05.795] iteration 9559 : model1 loss : 0.019560 model2 loss : 0.020432
[22:23:06.487] iteration 9560 : model1 loss : 0.023946 model2 loss : 0.022730
[22:23:07.169] iteration 9561 : model1 loss : 0.023666 model2 loss : 0.022077
[22:23:07.842] iteration 9562 : model1 loss : 0.023777 model2 loss : 0.023318
[22:23:08.522] iteration 9563 : model1 loss : 0.022989 model2 loss : 0.020625
[22:23:09.217] iteration 9564 : model1 loss : 0.021969 model2 loss : 0.021346
[22:23:09.892] iteration 9565 : model1 loss : 0.024155 model2 loss : 0.021576
[22:23:10.562] iteration 9566 : model1 loss : 0.025417 model2 loss : 0.024229
[22:23:11.234] iteration 9567 : model1 loss : 0.029447 model2 loss : 0.029195
[22:23:11.897] iteration 9568 : model1 loss : 0.029943 model2 loss : 0.025034
[22:23:12.574] iteration 9569 : model1 loss : 0.028307 model2 loss : 0.027453
[22:23:13.243] iteration 9570 : model1 loss : 0.026694 model2 loss : 0.028404
[22:23:13.901] iteration 9571 : model1 loss : 0.033928 model2 loss : 0.034001
[22:23:14.586] iteration 9572 : model1 loss : 0.031663 model2 loss : 0.028725
[22:23:15.257] iteration 9573 : model1 loss : 0.022014 model2 loss : 0.022227
[22:23:15.917] iteration 9574 : model1 loss : 0.021388 model2 loss : 0.023909
[22:23:16.586] iteration 9575 : model1 loss : 0.026576 model2 loss : 0.023556
[22:23:17.264] iteration 9576 : model1 loss : 0.021260 model2 loss : 0.021869
[22:23:17.935] iteration 9577 : model1 loss : 0.018317 model2 loss : 0.018670
[22:23:18.614] iteration 9578 : model1 loss : 0.043872 model2 loss : 0.042500
[22:23:19.274] iteration 9579 : model1 loss : 0.040922 model2 loss : 0.027501
[22:23:19.931] iteration 9580 : model1 loss : 0.023493 model2 loss : 0.028702
[22:23:20.614] iteration 9581 : model1 loss : 0.021903 model2 loss : 0.020748
[22:23:21.285] iteration 9582 : model1 loss : 0.021792 model2 loss : 0.022806
[22:23:21.947] iteration 9583 : model1 loss : 0.028665 model2 loss : 0.030935
[22:23:22.619] iteration 9584 : model1 loss : 0.025257 model2 loss : 0.027458
[22:23:23.287] iteration 9585 : model1 loss : 0.026337 model2 loss : 0.031022
[22:23:23.963] iteration 9586 : model1 loss : 0.023780 model2 loss : 0.022285
[22:23:24.630] iteration 9587 : model1 loss : 0.024894 model2 loss : 0.024086
[22:23:25.292] iteration 9588 : model1 loss : 0.028557 model2 loss : 0.029571
[22:23:25.962] iteration 9589 : model1 loss : 0.026016 model2 loss : 0.029325
[22:23:26.642] iteration 9590 : model1 loss : 0.019961 model2 loss : 0.019590
[22:23:27.325] iteration 9591 : model1 loss : 0.049115 model2 loss : 0.043311
[22:23:27.988] iteration 9592 : model1 loss : 0.020276 model2 loss : 0.022373
[22:23:28.654] iteration 9593 : model1 loss : 0.024564 model2 loss : 0.021495
[22:23:29.334] iteration 9594 : model1 loss : 0.019805 model2 loss : 0.024587
[22:23:30.004] iteration 9595 : model1 loss : 0.028263 model2 loss : 0.027821
[22:23:30.670] iteration 9596 : model1 loss : 0.023917 model2 loss : 0.025198
[22:23:31.336] iteration 9597 : model1 loss : 0.030061 model2 loss : 0.037310
[22:23:32.011] iteration 9598 : model1 loss : 0.018105 model2 loss : 0.018305
[22:23:32.680] iteration 9599 : model1 loss : 0.030706 model2 loss : 0.030658
[22:23:33.339] iteration 9600 : model1 loss : 0.022824 model2 loss : 0.025836
[22:23:51.772] iteration 9600 : model1_mean_dice : 0.835905 model1_mean_hd95 : 6.839537
[22:24:10.134] iteration 9600 : model2_mean_dice : 0.854935 model2_mean_hd95 : 4.497544
[22:24:10.824] iteration 9601 : model1 loss : 0.023763 model2 loss : 0.022727
[22:24:11.481] iteration 9602 : model1 loss : 0.023291 model2 loss : 0.024492
[22:24:12.144] iteration 9603 : model1 loss : 0.023672 model2 loss : 0.025951
[22:24:12.803] iteration 9604 : model1 loss : 0.023692 model2 loss : 0.020471
[22:24:13.461] iteration 9605 : model1 loss : 0.035054 model2 loss : 0.038742
[22:24:14.118] iteration 9606 : model1 loss : 0.026732 model2 loss : 0.045412
[22:24:14.788] iteration 9607 : model1 loss : 0.019108 model2 loss : 0.020741
[22:24:15.457] iteration 9608 : model1 loss : 0.020383 model2 loss : 0.021204
[22:24:16.118] iteration 9609 : model1 loss : 0.023019 model2 loss : 0.025350
[22:24:16.770] iteration 9610 : model1 loss : 0.025216 model2 loss : 0.021318
[22:24:17.429] iteration 9611 : model1 loss : 0.027034 model2 loss : 0.029168
[22:24:18.101] iteration 9612 : model1 loss : 0.027572 model2 loss : 0.025522
[22:24:18.768] iteration 9613 : model1 loss : 0.025198 model2 loss : 0.030324
[22:24:19.441] iteration 9614 : model1 loss : 0.027474 model2 loss : 0.025589
[22:24:20.104] iteration 9615 : model1 loss : 0.028300 model2 loss : 0.043909
[22:24:20.773] iteration 9616 : model1 loss : 0.021803 model2 loss : 0.019975
[22:24:21.454] iteration 9617 : model1 loss : 0.021341 model2 loss : 0.021426
[22:24:22.117] iteration 9618 : model1 loss : 0.018734 model2 loss : 0.018095
[22:24:22.779] iteration 9619 : model1 loss : 0.023562 model2 loss : 0.019058
[22:24:23.450] iteration 9620 : model1 loss : 0.025210 model2 loss : 0.035723
[22:24:24.113] iteration 9621 : model1 loss : 0.018195 model2 loss : 0.021929
[22:24:24.785] iteration 9622 : model1 loss : 0.036581 model2 loss : 0.032325
[22:24:25.456] iteration 9623 : model1 loss : 0.023587 model2 loss : 0.023759
[22:24:26.128] iteration 9624 : model1 loss : 0.018009 model2 loss : 0.018669
[22:24:26.790] iteration 9625 : model1 loss : 0.025883 model2 loss : 0.026330
[22:24:27.452] iteration 9626 : model1 loss : 0.024509 model2 loss : 0.027668
[22:24:28.116] iteration 9627 : model1 loss : 0.020658 model2 loss : 0.021562
[22:24:28.771] iteration 9628 : model1 loss : 0.026965 model2 loss : 0.028327
[22:24:29.432] iteration 9629 : model1 loss : 0.019764 model2 loss : 0.025265
[22:24:30.090] iteration 9630 : model1 loss : 0.027561 model2 loss : 0.031659
[22:24:30.751] iteration 9631 : model1 loss : 0.028903 model2 loss : 0.028572
[22:24:31.431] iteration 9632 : model1 loss : 0.024255 model2 loss : 0.022751
[22:24:32.090] iteration 9633 : model1 loss : 0.024623 model2 loss : 0.024692
[22:24:32.753] iteration 9634 : model1 loss : 0.018457 model2 loss : 0.019089
[22:24:33.455] iteration 9635 : model1 loss : 0.029496 model2 loss : 0.034632
[22:24:34.131] iteration 9636 : model1 loss : 0.021718 model2 loss : 0.020992
[22:24:34.790] iteration 9637 : model1 loss : 0.017862 model2 loss : 0.020433
[22:24:35.452] iteration 9638 : model1 loss : 0.026121 model2 loss : 0.029959
[22:24:36.112] iteration 9639 : model1 loss : 0.030178 model2 loss : 0.029808
[22:24:36.789] iteration 9640 : model1 loss : 0.022015 model2 loss : 0.023860
[22:24:37.451] iteration 9641 : model1 loss : 0.148332 model2 loss : 0.147519
[22:24:38.115] iteration 9642 : model1 loss : 0.025780 model2 loss : 0.026178
[22:24:38.786] iteration 9643 : model1 loss : 0.022990 model2 loss : 0.020708
[22:24:39.464] iteration 9644 : model1 loss : 0.020717 model2 loss : 0.023316
[22:24:40.148] iteration 9645 : model1 loss : 0.016693 model2 loss : 0.018562
[22:24:40.804] iteration 9646 : model1 loss : 0.017013 model2 loss : 0.018803
[22:24:41.490] iteration 9647 : model1 loss : 0.047816 model2 loss : 0.043022
[22:24:42.151] iteration 9648 : model1 loss : 0.023133 model2 loss : 0.025075
[22:24:42.813] iteration 9649 : model1 loss : 0.017227 model2 loss : 0.019571
[22:24:43.479] iteration 9650 : model1 loss : 0.034631 model2 loss : 0.033204
[22:24:44.178] iteration 9651 : model1 loss : 0.025161 model2 loss : 0.026296
[22:24:44.836] iteration 9652 : model1 loss : 0.026683 model2 loss : 0.033730
[22:24:45.522] iteration 9653 : model1 loss : 0.063870 model2 loss : 0.034167
[22:24:46.186] iteration 9654 : model1 loss : 0.022588 model2 loss : 0.023098
[22:24:46.859] iteration 9655 : model1 loss : 0.089191 model2 loss : 0.060176
[22:24:47.532] iteration 9656 : model1 loss : 0.048620 model2 loss : 0.055670
[22:24:48.193] iteration 9657 : model1 loss : 0.029528 model2 loss : 0.026473
[22:24:48.873] iteration 9658 : model1 loss : 0.054337 model2 loss : 0.052810
[22:24:49.547] iteration 9659 : model1 loss : 0.027431 model2 loss : 0.026921
[22:24:50.212] iteration 9660 : model1 loss : 0.027245 model2 loss : 0.026011
[22:24:50.873] iteration 9661 : model1 loss : 0.041207 model2 loss : 0.037769
[22:24:51.539] iteration 9662 : model1 loss : 0.030529 model2 loss : 0.029253
[22:24:52.210] iteration 9663 : model1 loss : 0.029973 model2 loss : 0.029982
[22:24:52.874] iteration 9664 : model1 loss : 0.027786 model2 loss : 0.049259
[22:24:53.543] iteration 9665 : model1 loss : 0.036644 model2 loss : 0.030077
[22:24:54.215] iteration 9666 : model1 loss : 0.055212 model2 loss : 0.057641
[22:24:54.895] iteration 9667 : model1 loss : 0.036856 model2 loss : 0.036280
[22:24:55.568] iteration 9668 : model1 loss : 0.038935 model2 loss : 0.038132
[22:24:56.255] iteration 9669 : model1 loss : 0.027686 model2 loss : 0.027565
[22:24:56.918] iteration 9670 : model1 loss : 0.021705 model2 loss : 0.020258
[22:24:57.595] iteration 9671 : model1 loss : 0.032639 model2 loss : 0.029363
[22:24:58.256] iteration 9672 : model1 loss : 0.025081 model2 loss : 0.024136
[22:24:58.920] iteration 9673 : model1 loss : 0.019680 model2 loss : 0.018550
[22:24:59.584] iteration 9674 : model1 loss : 0.026496 model2 loss : 0.024558
[22:25:00.247] iteration 9675 : model1 loss : 0.021345 model2 loss : 0.020896
[22:25:00.932] iteration 9676 : model1 loss : 0.029547 model2 loss : 0.031603
[22:25:01.599] iteration 9677 : model1 loss : 0.020300 model2 loss : 0.029092
[22:25:02.268] iteration 9678 : model1 loss : 0.030909 model2 loss : 0.023239
[22:25:02.984] iteration 9679 : model1 loss : 0.027840 model2 loss : 0.028105
[22:25:03.645] iteration 9680 : model1 loss : 0.024614 model2 loss : 0.026629
[22:25:04.314] iteration 9681 : model1 loss : 0.065991 model2 loss : 0.039755
[22:25:04.976] iteration 9682 : model1 loss : 0.017902 model2 loss : 0.018523
[22:25:05.650] iteration 9683 : model1 loss : 0.027659 model2 loss : 0.023907
[22:25:06.316] iteration 9684 : model1 loss : 0.033142 model2 loss : 0.028921
[22:25:06.976] iteration 9685 : model1 loss : 0.027976 model2 loss : 0.023445
[22:25:07.637] iteration 9686 : model1 loss : 0.027883 model2 loss : 0.031029
[22:25:08.292] iteration 9687 : model1 loss : 0.039693 model2 loss : 0.022811
[22:25:08.978] iteration 9688 : model1 loss : 0.027975 model2 loss : 0.027631
[22:25:09.650] iteration 9689 : model1 loss : 0.022445 model2 loss : 0.021880
[22:25:10.318] iteration 9690 : model1 loss : 0.019163 model2 loss : 0.018422
[22:25:10.981] iteration 9691 : model1 loss : 0.039901 model2 loss : 0.044185
[22:25:11.656] iteration 9692 : model1 loss : 0.021312 model2 loss : 0.023225
[22:25:12.321] iteration 9693 : model1 loss : 0.026204 model2 loss : 0.023536
[22:25:13.007] iteration 9694 : model1 loss : 0.145749 model2 loss : 0.144928
[22:25:13.678] iteration 9695 : model1 loss : 0.027969 model2 loss : 0.023735
[22:25:14.352] iteration 9696 : model1 loss : 0.029244 model2 loss : 0.026365
[22:25:15.019] iteration 9697 : model1 loss : 0.021095 model2 loss : 0.019907
[22:25:15.693] iteration 9698 : model1 loss : 0.025874 model2 loss : 0.027506
[22:25:16.364] iteration 9699 : model1 loss : 0.022679 model2 loss : 0.022537
[22:25:17.035] iteration 9700 : model1 loss : 0.025771 model2 loss : 0.022865
[22:25:17.730] iteration 9701 : model1 loss : 0.026984 model2 loss : 0.024914
[22:25:18.401] iteration 9702 : model1 loss : 0.027229 model2 loss : 0.026475
[22:25:19.076] iteration 9703 : model1 loss : 0.026134 model2 loss : 0.025101
[22:25:19.743] iteration 9704 : model1 loss : 0.151561 model2 loss : 0.145565
[22:25:20.435] iteration 9705 : model1 loss : 0.021355 model2 loss : 0.022927
[22:25:21.112] iteration 9706 : model1 loss : 0.036875 model2 loss : 0.037505
[22:25:21.795] iteration 9707 : model1 loss : 0.018269 model2 loss : 0.020619
[22:25:22.475] iteration 9708 : model1 loss : 0.023051 model2 loss : 0.023900
[22:25:23.164] iteration 9709 : model1 loss : 0.020896 model2 loss : 0.019229
[22:25:23.833] iteration 9710 : model1 loss : 0.021188 model2 loss : 0.021333
[22:25:24.546] iteration 9711 : model1 loss : 0.076211 model2 loss : 0.033976
[22:25:25.250] iteration 9712 : model1 loss : 0.018191 model2 loss : 0.017231
[22:25:25.952] iteration 9713 : model1 loss : 0.034171 model2 loss : 0.028715
[22:25:26.631] iteration 9714 : model1 loss : 0.023340 model2 loss : 0.025697
[22:25:27.292] iteration 9715 : model1 loss : 0.022959 model2 loss : 0.022637
[22:25:27.948] iteration 9716 : model1 loss : 0.022218 model2 loss : 0.020725
[22:25:28.645] iteration 9717 : model1 loss : 0.022084 model2 loss : 0.021599
[22:25:29.327] iteration 9718 : model1 loss : 0.022717 model2 loss : 0.022426
[22:25:30.024] iteration 9719 : model1 loss : 0.021158 model2 loss : 0.022149
[22:25:30.724] iteration 9720 : model1 loss : 0.027901 model2 loss : 0.027658
[22:25:31.400] iteration 9721 : model1 loss : 0.021714 model2 loss : 0.025990
[22:25:32.082] iteration 9722 : model1 loss : 0.023071 model2 loss : 0.022718
[22:25:32.747] iteration 9723 : model1 loss : 0.028859 model2 loss : 0.032269
[22:25:33.427] iteration 9724 : model1 loss : 0.037039 model2 loss : 0.033189
[22:25:34.113] iteration 9725 : model1 loss : 0.021728 model2 loss : 0.019071
[22:25:34.774] iteration 9726 : model1 loss : 0.017195 model2 loss : 0.017616
[22:25:35.464] iteration 9727 : model1 loss : 0.021487 model2 loss : 0.021842
[22:25:36.140] iteration 9728 : model1 loss : 0.022659 model2 loss : 0.022638
[22:25:36.805] iteration 9729 : model1 loss : 0.025477 model2 loss : 0.022965
[22:25:37.477] iteration 9730 : model1 loss : 0.024577 model2 loss : 0.022945
[22:25:38.139] iteration 9731 : model1 loss : 0.022810 model2 loss : 0.026445
[22:25:38.818] iteration 9732 : model1 loss : 0.024878 model2 loss : 0.022889
[22:25:39.495] iteration 9733 : model1 loss : 0.037196 model2 loss : 0.036290
[22:25:40.162] iteration 9734 : model1 loss : 0.021977 model2 loss : 0.018677
[22:25:40.833] iteration 9735 : model1 loss : 0.024599 model2 loss : 0.024486
[22:25:41.501] iteration 9736 : model1 loss : 0.022213 model2 loss : 0.022577
[22:25:42.180] iteration 9737 : model1 loss : 0.030479 model2 loss : 0.034411
[22:25:42.866] iteration 9738 : model1 loss : 0.025381 model2 loss : 0.031464
[22:25:43.529] iteration 9739 : model1 loss : 0.021603 model2 loss : 0.024076
[22:25:44.209] iteration 9740 : model1 loss : 0.033848 model2 loss : 0.030311
[22:25:44.880] iteration 9741 : model1 loss : 0.031988 model2 loss : 0.034234
[22:25:45.568] iteration 9742 : model1 loss : 0.028253 model2 loss : 0.027274
[22:25:46.242] iteration 9743 : model1 loss : 0.020906 model2 loss : 0.021982
[22:25:46.907] iteration 9744 : model1 loss : 0.027751 model2 loss : 0.024718
[22:25:47.580] iteration 9745 : model1 loss : 0.035238 model2 loss : 0.035573
[22:25:48.248] iteration 9746 : model1 loss : 0.032494 model2 loss : 0.032479
[22:25:48.927] iteration 9747 : model1 loss : 0.024951 model2 loss : 0.023641
[22:25:49.590] iteration 9748 : model1 loss : 0.023531 model2 loss : 0.025027
[22:25:50.274] iteration 9749 : model1 loss : 0.026101 model2 loss : 0.021234
[22:25:50.930] iteration 9750 : model1 loss : 0.022570 model2 loss : 0.023090
[22:25:51.645] iteration 9751 : model1 loss : 0.144900 model2 loss : 0.145777
[22:25:52.308] iteration 9752 : model1 loss : 0.024005 model2 loss : 0.065530
[22:25:52.976] iteration 9753 : model1 loss : 0.022583 model2 loss : 0.023813
[22:25:53.638] iteration 9754 : model1 loss : 0.030021 model2 loss : 0.028036
[22:25:54.305] iteration 9755 : model1 loss : 0.015547 model2 loss : 0.018328
[22:25:54.973] iteration 9756 : model1 loss : 0.019671 model2 loss : 0.023617
[22:25:55.641] iteration 9757 : model1 loss : 0.024602 model2 loss : 0.028063
[22:25:56.309] iteration 9758 : model1 loss : 0.024304 model2 loss : 0.027451
[22:25:56.985] iteration 9759 : model1 loss : 0.023191 model2 loss : 0.023924
[22:25:57.658] iteration 9760 : model1 loss : 0.017028 model2 loss : 0.021489
[22:25:58.332] iteration 9761 : model1 loss : 0.030880 model2 loss : 0.031174
[22:25:59.002] iteration 9762 : model1 loss : 0.032884 model2 loss : 0.037419
[22:25:59.666] iteration 9763 : model1 loss : 0.022602 model2 loss : 0.026189
[22:26:00.337] iteration 9764 : model1 loss : 0.017481 model2 loss : 0.016770
[22:26:01.008] iteration 9765 : model1 loss : 0.018313 model2 loss : 0.017352
[22:26:01.675] iteration 9766 : model1 loss : 0.026932 model2 loss : 0.029179
[22:26:02.335] iteration 9767 : model1 loss : 0.027260 model2 loss : 0.019313
[22:26:03.010] iteration 9768 : model1 loss : 0.039559 model2 loss : 0.028629
[22:26:03.693] iteration 9769 : model1 loss : 0.026030 model2 loss : 0.026150
[22:26:04.356] iteration 9770 : model1 loss : 0.024828 model2 loss : 0.026588
[22:26:05.029] iteration 9771 : model1 loss : 0.023373 model2 loss : 0.023932
[22:26:05.704] iteration 9772 : model1 loss : 0.034716 model2 loss : 0.036832
[22:26:06.372] iteration 9773 : model1 loss : 0.025929 model2 loss : 0.025333
[22:26:07.042] iteration 9774 : model1 loss : 0.018948 model2 loss : 0.023907
[22:26:07.705] iteration 9775 : model1 loss : 0.027323 model2 loss : 0.028483
[22:26:08.371] iteration 9776 : model1 loss : 0.021843 model2 loss : 0.019667
[22:26:09.034] iteration 9777 : model1 loss : 0.018917 model2 loss : 0.018170
[22:26:09.692] iteration 9778 : model1 loss : 0.018845 model2 loss : 0.019237
[22:26:10.357] iteration 9779 : model1 loss : 0.027928 model2 loss : 0.023802
[22:26:11.016] iteration 9780 : model1 loss : 0.022013 model2 loss : 0.023787
[22:26:11.674] iteration 9781 : model1 loss : 0.019849 model2 loss : 0.020241
[22:26:12.340] iteration 9782 : model1 loss : 0.024451 model2 loss : 0.025745
[22:26:13.020] iteration 9783 : model1 loss : 0.019895 model2 loss : 0.020641
[22:26:13.691] iteration 9784 : model1 loss : 0.018028 model2 loss : 0.017392
[22:26:14.357] iteration 9785 : model1 loss : 0.020453 model2 loss : 0.021796
[22:26:15.026] iteration 9786 : model1 loss : 0.027206 model2 loss : 0.029441
[22:26:15.704] iteration 9787 : model1 loss : 0.021752 model2 loss : 0.022164
[22:26:16.389] iteration 9788 : model1 loss : 0.026079 model2 loss : 0.022706
[22:26:17.063] iteration 9789 : model1 loss : 0.024154 model2 loss : 0.024478
[22:26:17.725] iteration 9790 : model1 loss : 0.021938 model2 loss : 0.023767
[22:26:18.394] iteration 9791 : model1 loss : 0.034949 model2 loss : 0.040576
[22:26:19.072] iteration 9792 : model1 loss : 0.023464 model2 loss : 0.024178
[22:26:19.745] iteration 9793 : model1 loss : 0.028456 model2 loss : 0.031191
[22:26:20.413] iteration 9794 : model1 loss : 0.052514 model2 loss : 0.036659
[22:26:21.084] iteration 9795 : model1 loss : 0.023165 model2 loss : 0.024877
[22:26:21.753] iteration 9796 : model1 loss : 0.039108 model2 loss : 0.036821
[22:26:22.449] iteration 9797 : model1 loss : 0.026212 model2 loss : 0.027634
[22:26:23.112] iteration 9798 : model1 loss : 0.028608 model2 loss : 0.030614
[22:26:23.777] iteration 9799 : model1 loss : 0.026533 model2 loss : 0.026112
[22:26:24.456] iteration 9800 : model1 loss : 0.042267 model2 loss : 0.039433
[22:26:44.653] iteration 9800 : model1_mean_dice : 0.835535 model1_mean_hd95 : 8.058143
[22:27:07.449] iteration 9800 : model2_mean_dice : 0.848846 model2_mean_hd95 : 4.343352
[22:27:08.184] iteration 9801 : model1 loss : 0.022619 model2 loss : 0.022087
[22:27:08.882] iteration 9802 : model1 loss : 0.022993 model2 loss : 0.023779
[22:27:09.606] iteration 9803 : model1 loss : 0.018281 model2 loss : 0.019471
[22:27:10.311] iteration 9804 : model1 loss : 0.020857 model2 loss : 0.020018
[22:27:11.013] iteration 9805 : model1 loss : 0.025299 model2 loss : 0.026016
[22:27:11.713] iteration 9806 : model1 loss : 0.019807 model2 loss : 0.021830
[22:27:12.443] iteration 9807 : model1 loss : 0.023448 model2 loss : 0.024460
[22:27:13.154] iteration 9808 : model1 loss : 0.024351 model2 loss : 0.027505
[22:27:13.873] iteration 9809 : model1 loss : 0.018098 model2 loss : 0.018229
[22:27:14.566] iteration 9810 : model1 loss : 0.018388 model2 loss : 0.020371
[22:27:15.297] iteration 9811 : model1 loss : 0.025563 model2 loss : 0.023402
[22:27:16.008] iteration 9812 : model1 loss : 0.022626 model2 loss : 0.024314
[22:27:16.715] iteration 9813 : model1 loss : 0.023586 model2 loss : 0.024496
[22:27:17.455] iteration 9814 : model1 loss : 0.026373 model2 loss : 0.027905
[22:27:18.169] iteration 9815 : model1 loss : 0.020272 model2 loss : 0.022588
[22:27:18.874] iteration 9816 : model1 loss : 0.026759 model2 loss : 0.029249
[22:27:19.587] iteration 9817 : model1 loss : 0.017924 model2 loss : 0.017094
[22:27:20.313] iteration 9818 : model1 loss : 0.018187 model2 loss : 0.023299
[22:27:21.019] iteration 9819 : model1 loss : 0.028032 model2 loss : 0.024280
[22:27:21.732] iteration 9820 : model1 loss : 0.026348 model2 loss : 0.028667
[22:27:22.486] iteration 9821 : model1 loss : 0.028950 model2 loss : 0.028664
[22:27:23.197] iteration 9822 : model1 loss : 0.030911 model2 loss : 0.030531
[22:27:23.891] iteration 9823 : model1 loss : 0.017011 model2 loss : 0.019691
[22:27:24.604] iteration 9824 : model1 loss : 0.034897 model2 loss : 0.036481
[22:27:25.335] iteration 9825 : model1 loss : 0.052917 model2 loss : 0.027138
[22:27:26.053] iteration 9826 : model1 loss : 0.019832 model2 loss : 0.018970
[22:27:26.758] iteration 9827 : model1 loss : 0.022011 model2 loss : 0.023670
[22:27:27.499] iteration 9828 : model1 loss : 0.022266 model2 loss : 0.021877
[22:27:28.189] iteration 9829 : model1 loss : 0.026572 model2 loss : 0.025020
[22:27:28.899] iteration 9830 : model1 loss : 0.050146 model2 loss : 0.045099
[22:27:29.610] iteration 9831 : model1 loss : 0.047732 model2 loss : 0.053631
[22:27:30.321] iteration 9832 : model1 loss : 0.039070 model2 loss : 0.025104
[22:27:31.124] iteration 9833 : model1 loss : 0.068064 model2 loss : 0.043098
[22:27:31.881] iteration 9834 : model1 loss : 0.040925 model2 loss : 0.030512
[22:27:32.631] iteration 9835 : model1 loss : 0.035628 model2 loss : 0.028133
[22:27:33.375] iteration 9836 : model1 loss : 0.023394 model2 loss : 0.025805
[22:27:34.100] iteration 9837 : model1 loss : 0.030232 model2 loss : 0.037930
[22:27:34.840] iteration 9838 : model1 loss : 0.026092 model2 loss : 0.026808
[22:27:35.568] iteration 9839 : model1 loss : 0.019127 model2 loss : 0.021445
[22:27:36.272] iteration 9840 : model1 loss : 0.025849 model2 loss : 0.025867
[22:27:36.963] iteration 9841 : model1 loss : 0.033960 model2 loss : 0.068321
[22:27:37.682] iteration 9842 : model1 loss : 0.024994 model2 loss : 0.024424
[22:27:38.388] iteration 9843 : model1 loss : 0.018845 model2 loss : 0.020334
[22:27:39.103] iteration 9844 : model1 loss : 0.029596 model2 loss : 0.025439
[22:27:39.811] iteration 9845 : model1 loss : 0.023785 model2 loss : 0.022933
[22:27:40.507] iteration 9846 : model1 loss : 0.018880 model2 loss : 0.021109
[22:27:41.205] iteration 9847 : model1 loss : 0.041048 model2 loss : 0.037353
[22:27:41.913] iteration 9848 : model1 loss : 0.022761 model2 loss : 0.022328
[22:27:42.646] iteration 9849 : model1 loss : 0.019887 model2 loss : 0.029409
[22:27:43.344] iteration 9850 : model1 loss : 0.023037 model2 loss : 0.023948
[22:27:44.092] iteration 9851 : model1 loss : 0.018087 model2 loss : 0.019725
[22:27:44.802] iteration 9852 : model1 loss : 0.023749 model2 loss : 0.022210
[22:27:45.512] iteration 9853 : model1 loss : 0.031380 model2 loss : 0.027682
[22:27:46.209] iteration 9854 : model1 loss : 0.019871 model2 loss : 0.022201
[22:27:46.906] iteration 9855 : model1 loss : 0.034427 model2 loss : 0.031813
[22:27:47.618] iteration 9856 : model1 loss : 0.019706 model2 loss : 0.019836
[22:27:48.317] iteration 9857 : model1 loss : 0.027052 model2 loss : 0.020240
[22:27:49.021] iteration 9858 : model1 loss : 0.025545 model2 loss : 0.022659
[22:27:49.731] iteration 9859 : model1 loss : 0.030263 model2 loss : 0.030634
[22:27:50.429] iteration 9860 : model1 loss : 0.022689 model2 loss : 0.024320
[22:27:51.135] iteration 9861 : model1 loss : 0.022181 model2 loss : 0.024327
[22:27:51.835] iteration 9862 : model1 loss : 0.026081 model2 loss : 0.033744
[22:27:52.575] iteration 9863 : model1 loss : 0.041826 model2 loss : 0.045495
[22:27:53.287] iteration 9864 : model1 loss : 0.018777 model2 loss : 0.019531
[22:27:54.003] iteration 9865 : model1 loss : 0.027374 model2 loss : 0.032816
[22:27:54.701] iteration 9866 : model1 loss : 0.021276 model2 loss : 0.031214
[22:27:55.428] iteration 9867 : model1 loss : 0.019349 model2 loss : 0.021974
[22:27:56.135] iteration 9868 : model1 loss : 0.018034 model2 loss : 0.020051
[22:27:56.841] iteration 9869 : model1 loss : 0.021255 model2 loss : 0.020128
[22:27:57.582] iteration 9870 : model1 loss : 0.021933 model2 loss : 0.020906
[22:27:58.296] iteration 9871 : model1 loss : 0.027783 model2 loss : 0.022713
[22:27:59.008] iteration 9872 : model1 loss : 0.026298 model2 loss : 0.035423
[22:27:59.713] iteration 9873 : model1 loss : 0.027482 model2 loss : 0.028033
[22:28:00.421] iteration 9874 : model1 loss : 0.020005 model2 loss : 0.023874
[22:28:01.139] iteration 9875 : model1 loss : 0.026512 model2 loss : 0.027734
[22:28:01.902] iteration 9876 : model1 loss : 0.027463 model2 loss : 0.024902
[22:28:02.681] iteration 9877 : model1 loss : 0.023651 model2 loss : 0.020402
[22:28:03.461] iteration 9878 : model1 loss : 0.044485 model2 loss : 0.040571
[22:28:04.284] iteration 9879 : model1 loss : 0.027234 model2 loss : 0.026846
[22:28:05.010] iteration 9880 : model1 loss : 0.020729 model2 loss : 0.022442
[22:28:05.730] iteration 9881 : model1 loss : 0.026498 model2 loss : 0.030239
[22:28:06.446] iteration 9882 : model1 loss : 0.017748 model2 loss : 0.021271
[22:28:07.155] iteration 9883 : model1 loss : 0.021251 model2 loss : 0.020408
[22:28:07.881] iteration 9884 : model1 loss : 0.022385 model2 loss : 0.020779
[22:28:08.608] iteration 9885 : model1 loss : 0.023100 model2 loss : 0.024773
[22:28:09.322] iteration 9886 : model1 loss : 0.023277 model2 loss : 0.027186
[22:28:10.042] iteration 9887 : model1 loss : 0.023490 model2 loss : 0.023769
[22:28:10.746] iteration 9888 : model1 loss : 0.030326 model2 loss : 0.028362
[22:28:11.472] iteration 9889 : model1 loss : 0.024341 model2 loss : 0.025247
[22:28:12.189] iteration 9890 : model1 loss : 0.021058 model2 loss : 0.024700
[22:28:12.896] iteration 9891 : model1 loss : 0.019753 model2 loss : 0.022303
[22:28:13.600] iteration 9892 : model1 loss : 0.024757 model2 loss : 0.025027
[22:28:14.326] iteration 9893 : model1 loss : 0.029753 model2 loss : 0.038851
[22:28:15.039] iteration 9894 : model1 loss : 0.031976 model2 loss : 0.036555
[22:28:15.757] iteration 9895 : model1 loss : 0.017861 model2 loss : 0.018889
[22:28:16.476] iteration 9896 : model1 loss : 0.034322 model2 loss : 0.033550
[22:28:17.199] iteration 9897 : model1 loss : 0.148889 model2 loss : 0.146584
[22:28:17.904] iteration 9898 : model1 loss : 0.031731 model2 loss : 0.033440
[22:28:18.644] iteration 9899 : model1 loss : 0.028119 model2 loss : 0.027828
[22:28:19.408] iteration 9900 : model1 loss : 0.017864 model2 loss : 0.032525
[22:28:20.161] iteration 9901 : model1 loss : 0.022263 model2 loss : 0.020946
[22:28:20.872] iteration 9902 : model1 loss : 0.024480 model2 loss : 0.025077
[22:28:21.587] iteration 9903 : model1 loss : 0.023047 model2 loss : 0.025740
[22:28:22.305] iteration 9904 : model1 loss : 0.020350 model2 loss : 0.019138
[22:28:23.013] iteration 9905 : model1 loss : 0.024830 model2 loss : 0.022168
[22:28:23.723] iteration 9906 : model1 loss : 0.022982 model2 loss : 0.022327
[22:28:24.457] iteration 9907 : model1 loss : 0.024821 model2 loss : 0.022631
[22:28:25.175] iteration 9908 : model1 loss : 0.021592 model2 loss : 0.018820
[22:28:25.880] iteration 9909 : model1 loss : 0.022787 model2 loss : 0.022507
[22:28:26.593] iteration 9910 : model1 loss : 0.046565 model2 loss : 0.102296
[22:28:27.313] iteration 9911 : model1 loss : 0.043949 model2 loss : 0.048972
[22:28:28.030] iteration 9912 : model1 loss : 0.022168 model2 loss : 0.020162
[22:28:28.759] iteration 9913 : model1 loss : 0.021242 model2 loss : 0.021131
[22:28:29.490] iteration 9914 : model1 loss : 0.022240 model2 loss : 0.021437
[22:28:30.190] iteration 9915 : model1 loss : 0.025421 model2 loss : 0.027628
[22:28:30.898] iteration 9916 : model1 loss : 0.024492 model2 loss : 0.025002
[22:28:31.602] iteration 9917 : model1 loss : 0.022206 model2 loss : 0.023455
[22:28:32.321] iteration 9918 : model1 loss : 0.020771 model2 loss : 0.021048
[22:28:33.037] iteration 9919 : model1 loss : 0.023225 model2 loss : 0.023436
[22:28:33.756] iteration 9920 : model1 loss : 0.038664 model2 loss : 0.047959
[22:28:34.461] iteration 9921 : model1 loss : 0.032857 model2 loss : 0.028806
[22:28:35.168] iteration 9922 : model1 loss : 0.026716 model2 loss : 0.025880
[22:28:35.867] iteration 9923 : model1 loss : 0.021418 model2 loss : 0.022735
[22:28:36.569] iteration 9924 : model1 loss : 0.025939 model2 loss : 0.023467
[22:28:37.310] iteration 9925 : model1 loss : 0.018956 model2 loss : 0.019042
[22:28:38.085] iteration 9926 : model1 loss : 0.022291 model2 loss : 0.031533
[22:28:38.838] iteration 9927 : model1 loss : 0.024116 model2 loss : 0.050562
[22:28:39.641] iteration 9928 : model1 loss : 0.026956 model2 loss : 0.038411
[22:28:40.450] iteration 9929 : model1 loss : 0.023169 model2 loss : 0.023574
[22:28:41.167] iteration 9930 : model1 loss : 0.027697 model2 loss : 0.030712
[22:28:41.883] iteration 9931 : model1 loss : 0.018101 model2 loss : 0.021608
[22:28:42.627] iteration 9932 : model1 loss : 0.022743 model2 loss : 0.023401
[22:28:43.345] iteration 9933 : model1 loss : 0.023870 model2 loss : 0.024012
[22:28:44.059] iteration 9934 : model1 loss : 0.025990 model2 loss : 0.029383
[22:28:44.765] iteration 9935 : model1 loss : 0.020357 model2 loss : 0.023565
[22:28:45.491] iteration 9936 : model1 loss : 0.018260 model2 loss : 0.017803
[22:28:46.202] iteration 9937 : model1 loss : 0.040126 model2 loss : 0.044878
[22:28:46.921] iteration 9938 : model1 loss : 0.015577 model2 loss : 0.018637
[22:28:47.620] iteration 9939 : model1 loss : 0.024114 model2 loss : 0.023506
[22:28:48.315] iteration 9940 : model1 loss : 0.025166 model2 loss : 0.025144
[22:28:49.047] iteration 9941 : model1 loss : 0.063340 model2 loss : 0.044916
[22:28:49.763] iteration 9942 : model1 loss : 0.046735 model2 loss : 0.028365
[22:28:50.459] iteration 9943 : model1 loss : 0.025659 model2 loss : 0.025801
[22:28:51.147] iteration 9944 : model1 loss : 0.024483 model2 loss : 0.022938
[22:28:51.825] iteration 9945 : model1 loss : 0.021785 model2 loss : 0.022103
[22:28:52.543] iteration 9946 : model1 loss : 0.024388 model2 loss : 0.024881
[22:28:53.210] iteration 9947 : model1 loss : 0.022856 model2 loss : 0.031928
[22:28:53.893] iteration 9948 : model1 loss : 0.020611 model2 loss : 0.024092
[22:28:54.638] iteration 9949 : model1 loss : 0.019884 model2 loss : 0.017339
[22:28:55.541] iteration 9950 : model1 loss : 0.023648 model2 loss : 0.019314
[22:28:56.437] iteration 9951 : model1 loss : 0.041137 model2 loss : 0.047285
[22:28:57.300] iteration 9952 : model1 loss : 0.025085 model2 loss : 0.026290
[22:28:58.192] iteration 9953 : model1 loss : 0.026423 model2 loss : 0.029005
[22:28:59.084] iteration 9954 : model1 loss : 0.023783 model2 loss : 0.022524
[22:28:59.900] iteration 9955 : model1 loss : 0.026005 model2 loss : 0.028624
[22:29:00.712] iteration 9956 : model1 loss : 0.027942 model2 loss : 0.028275
[22:29:01.501] iteration 9957 : model1 loss : 0.090686 model2 loss : 0.140791
[22:29:02.364] iteration 9958 : model1 loss : 0.028721 model2 loss : 0.028278
[22:29:03.154] iteration 9959 : model1 loss : 0.024838 model2 loss : 0.029990
[22:29:03.954] iteration 9960 : model1 loss : 0.029499 model2 loss : 0.031821
[22:29:04.767] iteration 9961 : model1 loss : 0.036305 model2 loss : 0.041130
[22:29:05.589] iteration 9962 : model1 loss : 0.021759 model2 loss : 0.020560
[22:29:06.426] iteration 9963 : model1 loss : 0.033419 model2 loss : 0.033738
[22:29:07.287] iteration 9964 : model1 loss : 0.029938 model2 loss : 0.027065
[22:29:08.091] iteration 9965 : model1 loss : 0.049883 model2 loss : 0.039647
[22:29:08.947] iteration 9966 : model1 loss : 0.024850 model2 loss : 0.022572
[22:29:09.739] iteration 9967 : model1 loss : 0.040438 model2 loss : 0.081361
[22:29:10.471] iteration 9968 : model1 loss : 0.027225 model2 loss : 0.022222
[22:29:11.232] iteration 9969 : model1 loss : 0.029164 model2 loss : 0.027461
[22:29:11.951] iteration 9970 : model1 loss : 0.025663 model2 loss : 0.025848
[22:29:12.716] iteration 9971 : model1 loss : 0.024551 model2 loss : 0.032540
[22:29:13.443] iteration 9972 : model1 loss : 0.147553 model2 loss : 0.149226
[22:29:14.167] iteration 9973 : model1 loss : 0.018392 model2 loss : 0.019693
[22:29:14.912] iteration 9974 : model1 loss : 0.030462 model2 loss : 0.028044
[22:29:15.649] iteration 9975 : model1 loss : 0.024591 model2 loss : 0.026013
[22:29:16.430] iteration 9976 : model1 loss : 0.019985 model2 loss : 0.018149
[22:29:17.230] iteration 9977 : model1 loss : 0.020908 model2 loss : 0.018748
[22:29:17.963] iteration 9978 : model1 loss : 0.031130 model2 loss : 0.027981
[22:29:18.710] iteration 9979 : model1 loss : 0.023989 model2 loss : 0.021976
[22:29:19.465] iteration 9980 : model1 loss : 0.031259 model2 loss : 0.028985
[22:29:20.217] iteration 9981 : model1 loss : 0.026337 model2 loss : 0.037892
[22:29:21.035] iteration 9982 : model1 loss : 0.021115 model2 loss : 0.021540
[22:29:21.785] iteration 9983 : model1 loss : 0.040345 model2 loss : 0.040232
[22:29:22.584] iteration 9984 : model1 loss : 0.032640 model2 loss : 0.035261
[22:29:23.320] iteration 9985 : model1 loss : 0.019479 model2 loss : 0.018059
[22:29:24.072] iteration 9986 : model1 loss : 0.023995 model2 loss : 0.031433
[22:29:24.970] iteration 9987 : model1 loss : 0.025960 model2 loss : 0.027682
[22:29:25.902] iteration 9988 : model1 loss : 0.025107 model2 loss : 0.023663
[22:29:26.858] iteration 9989 : model1 loss : 0.031684 model2 loss : 0.037931
[22:29:27.775] iteration 9990 : model1 loss : 0.023994 model2 loss : 0.024613
[22:29:28.695] iteration 9991 : model1 loss : 0.029069 model2 loss : 0.033801
[22:29:29.598] iteration 9992 : model1 loss : 0.034212 model2 loss : 0.030773
[22:29:30.508] iteration 9993 : model1 loss : 0.048053 model2 loss : 0.036270
[22:29:31.369] iteration 9994 : model1 loss : 0.038918 model2 loss : 0.035872
[22:29:32.234] iteration 9995 : model1 loss : 0.023416 model2 loss : 0.025864
[22:29:33.169] iteration 9996 : model1 loss : 0.022580 model2 loss : 0.027376
[22:29:33.968] iteration 9997 : model1 loss : 0.023922 model2 loss : 0.030253
[22:29:34.726] iteration 9998 : model1 loss : 0.027502 model2 loss : 0.027015
[22:29:35.451] iteration 9999 : model1 loss : 0.023922 model2 loss : 0.025421
[22:29:36.139] iteration 10000 : model1 loss : 0.030673 model2 loss : 0.034596
[22:29:57.987] iteration 10000 : model1_mean_dice : 0.846547 model1_mean_hd95 : 10.889184
[22:30:20.479] iteration 10000 : model2_mean_dice : 0.864906 model2_mean_hd95 : 5.860405
[22:30:21.185] iteration 10001 : model1 loss : 0.022522 model2 loss : 0.018851
[22:30:21.883] iteration 10002 : model1 loss : 0.022092 model2 loss : 0.022118
[22:30:22.592] iteration 10003 : model1 loss : 0.020729 model2 loss : 0.025023
[22:30:23.280] iteration 10004 : model1 loss : 0.016497 model2 loss : 0.016747
[22:30:23.972] iteration 10005 : model1 loss : 0.019842 model2 loss : 0.022805
[22:30:24.670] iteration 10006 : model1 loss : 0.038583 model2 loss : 0.035359
[22:30:25.382] iteration 10007 : model1 loss : 0.027639 model2 loss : 0.035097
[22:30:26.083] iteration 10008 : model1 loss : 0.026413 model2 loss : 0.023732
[22:30:26.755] iteration 10009 : model1 loss : 0.022642 model2 loss : 0.027433
[22:30:27.452] iteration 10010 : model1 loss : 0.028703 model2 loss : 0.028185
[22:30:28.119] iteration 10011 : model1 loss : 0.030712 model2 loss : 0.034550
[22:30:28.770] iteration 10012 : model1 loss : 0.033334 model2 loss : 0.035951
[22:30:29.447] iteration 10013 : model1 loss : 0.017388 model2 loss : 0.019626
[22:30:30.109] iteration 10014 : model1 loss : 0.020760 model2 loss : 0.017866
[22:30:30.789] iteration 10015 : model1 loss : 0.025934 model2 loss : 0.023898
[22:30:31.491] iteration 10016 : model1 loss : 0.019106 model2 loss : 0.020062
[22:30:32.191] iteration 10017 : model1 loss : 0.044336 model2 loss : 0.032555
[22:30:32.869] iteration 10018 : model1 loss : 0.022765 model2 loss : 0.021588
[22:30:33.539] iteration 10019 : model1 loss : 0.033688 model2 loss : 0.030764
[22:30:34.202] iteration 10020 : model1 loss : 0.019098 model2 loss : 0.024479
[22:30:34.867] iteration 10021 : model1 loss : 0.024065 model2 loss : 0.026037
[22:30:35.532] iteration 10022 : model1 loss : 0.019021 model2 loss : 0.020550
[22:30:36.207] iteration 10023 : model1 loss : 0.027169 model2 loss : 0.023311
[22:30:36.870] iteration 10024 : model1 loss : 0.017936 model2 loss : 0.018592
[22:30:37.548] iteration 10025 : model1 loss : 0.043836 model2 loss : 0.048876
[22:30:38.226] iteration 10026 : model1 loss : 0.022586 model2 loss : 0.024206
[22:30:38.911] iteration 10027 : model1 loss : 0.024218 model2 loss : 0.022330
[22:30:39.596] iteration 10028 : model1 loss : 0.044047 model2 loss : 0.034966
[22:30:40.288] iteration 10029 : model1 loss : 0.024367 model2 loss : 0.026696
[22:30:40.971] iteration 10030 : model1 loss : 0.031773 model2 loss : 0.032607
[22:30:41.647] iteration 10031 : model1 loss : 0.056629 model2 loss : 0.040288
[22:30:42.313] iteration 10032 : model1 loss : 0.024795 model2 loss : 0.027107
[22:30:42.990] iteration 10033 : model1 loss : 0.047154 model2 loss : 0.066750
[22:30:43.662] iteration 10034 : model1 loss : 0.019918 model2 loss : 0.020845
[22:30:44.353] iteration 10035 : model1 loss : 0.027976 model2 loss : 0.024680
[22:30:45.048] iteration 10036 : model1 loss : 0.053187 model2 loss : 0.053292
[22:30:45.715] iteration 10037 : model1 loss : 0.020213 model2 loss : 0.020307
[22:30:46.394] iteration 10038 : model1 loss : 0.027486 model2 loss : 0.025034
[22:30:47.052] iteration 10039 : model1 loss : 0.032360 model2 loss : 0.030057
[22:30:47.706] iteration 10040 : model1 loss : 0.077558 model2 loss : 0.053159
[22:30:48.381] iteration 10041 : model1 loss : 0.020300 model2 loss : 0.020665
[22:30:49.049] iteration 10042 : model1 loss : 0.024900 model2 loss : 0.027998
[22:30:49.716] iteration 10043 : model1 loss : 0.024727 model2 loss : 0.024509
[22:30:50.395] iteration 10044 : model1 loss : 0.022119 model2 loss : 0.023244
[22:30:51.081] iteration 10045 : model1 loss : 0.031149 model2 loss : 0.030240
[22:30:51.772] iteration 10046 : model1 loss : 0.034606 model2 loss : 0.027538
[22:30:52.481] iteration 10047 : model1 loss : 0.017883 model2 loss : 0.022574
[22:30:53.197] iteration 10048 : model1 loss : 0.025082 model2 loss : 0.026103
[22:30:53.911] iteration 10049 : model1 loss : 0.020786 model2 loss : 0.024371
[22:30:54.598] iteration 10050 : model1 loss : 0.027222 model2 loss : 0.027951
[22:30:55.304] iteration 10051 : model1 loss : 0.022416 model2 loss : 0.023105
[22:30:55.992] iteration 10052 : model1 loss : 0.028885 model2 loss : 0.028067
[22:30:56.660] iteration 10053 : model1 loss : 0.032291 model2 loss : 0.045808
[22:30:57.339] iteration 10054 : model1 loss : 0.054458 model2 loss : 0.054517
[22:30:57.998] iteration 10055 : model1 loss : 0.024892 model2 loss : 0.024299
[22:30:58.671] iteration 10056 : model1 loss : 0.023647 model2 loss : 0.022876
[22:30:59.351] iteration 10057 : model1 loss : 0.026739 model2 loss : 0.019446
[22:31:00.024] iteration 10058 : model1 loss : 0.025500 model2 loss : 0.031834
[22:31:00.708] iteration 10059 : model1 loss : 0.031001 model2 loss : 0.032707
[22:31:01.393] iteration 10060 : model1 loss : 0.029381 model2 loss : 0.026612
[22:31:02.064] iteration 10061 : model1 loss : 0.023523 model2 loss : 0.022092
[22:31:02.744] iteration 10062 : model1 loss : 0.023744 model2 loss : 0.023778
[22:31:03.438] iteration 10063 : model1 loss : 0.019592 model2 loss : 0.020731
[22:31:04.120] iteration 10064 : model1 loss : 0.025498 model2 loss : 0.034983
[22:31:04.820] iteration 10065 : model1 loss : 0.025123 model2 loss : 0.024559
[22:31:05.503] iteration 10066 : model1 loss : 0.019782 model2 loss : 0.017730
[22:31:06.226] iteration 10067 : model1 loss : 0.022168 model2 loss : 0.024216
[22:31:06.900] iteration 10068 : model1 loss : 0.021389 model2 loss : 0.019931
[22:31:07.565] iteration 10069 : model1 loss : 0.022957 model2 loss : 0.025293
[22:31:08.244] iteration 10070 : model1 loss : 0.025580 model2 loss : 0.024597
[22:31:08.917] iteration 10071 : model1 loss : 0.028575 model2 loss : 0.026003
[22:31:09.601] iteration 10072 : model1 loss : 0.039758 model2 loss : 0.024884
[22:31:10.284] iteration 10073 : model1 loss : 0.027333 model2 loss : 0.023307
[22:31:10.964] iteration 10074 : model1 loss : 0.035168 model2 loss : 0.031545
[22:31:11.653] iteration 10075 : model1 loss : 0.022074 model2 loss : 0.024349
[22:31:12.341] iteration 10076 : model1 loss : 0.021351 model2 loss : 0.020308
[22:31:13.019] iteration 10077 : model1 loss : 0.028610 model2 loss : 0.029241
[22:31:13.708] iteration 10078 : model1 loss : 0.030028 model2 loss : 0.024306
[22:31:14.405] iteration 10079 : model1 loss : 0.016546 model2 loss : 0.017040
[22:31:15.084] iteration 10080 : model1 loss : 0.028811 model2 loss : 0.026294
[22:31:15.760] iteration 10081 : model1 loss : 0.042242 model2 loss : 0.038609
[22:31:16.456] iteration 10082 : model1 loss : 0.027071 model2 loss : 0.025648
[22:31:17.145] iteration 10083 : model1 loss : 0.031709 model2 loss : 0.032874
[22:31:17.808] iteration 10084 : model1 loss : 0.021491 model2 loss : 0.022589
[22:31:18.489] iteration 10085 : model1 loss : 0.038083 model2 loss : 0.040188
[22:31:19.178] iteration 10086 : model1 loss : 0.032316 model2 loss : 0.033573
[22:31:19.846] iteration 10087 : model1 loss : 0.020778 model2 loss : 0.021889
[22:31:20.526] iteration 10088 : model1 loss : 0.034223 model2 loss : 0.030982
[22:31:21.198] iteration 10089 : model1 loss : 0.023264 model2 loss : 0.021534
[22:31:21.873] iteration 10090 : model1 loss : 0.022829 model2 loss : 0.024104
[22:31:22.558] iteration 10091 : model1 loss : 0.098450 model2 loss : 0.157517
[22:31:23.215] iteration 10092 : model1 loss : 0.027835 model2 loss : 0.025744
[22:31:23.890] iteration 10093 : model1 loss : 0.029952 model2 loss : 0.020280
[22:31:24.581] iteration 10094 : model1 loss : 0.030348 model2 loss : 0.024219
[22:31:25.258] iteration 10095 : model1 loss : 0.033769 model2 loss : 0.036108
[22:31:25.948] iteration 10096 : model1 loss : 0.044748 model2 loss : 0.028361
[22:31:26.650] iteration 10097 : model1 loss : 0.026177 model2 loss : 0.023423
[22:31:27.433] iteration 10098 : model1 loss : 0.025523 model2 loss : 0.020668
[22:31:28.172] iteration 10099 : model1 loss : 0.030391 model2 loss : 0.021625
[22:31:29.028] iteration 10100 : model1 loss : 0.028007 model2 loss : 0.026906
[22:31:29.895] iteration 10101 : model1 loss : 0.021200 model2 loss : 0.019046
[22:31:30.647] iteration 10102 : model1 loss : 0.026909 model2 loss : 0.022773
[22:31:31.435] iteration 10103 : model1 loss : 0.030230 model2 loss : 0.022398
[22:31:32.244] iteration 10104 : model1 loss : 0.053415 model2 loss : 0.026638
[22:31:33.020] iteration 10105 : model1 loss : 0.042132 model2 loss : 0.034303
[22:31:33.760] iteration 10106 : model1 loss : 0.024023 model2 loss : 0.021160
[22:31:34.506] iteration 10107 : model1 loss : 0.024897 model2 loss : 0.019552
[22:31:35.249] iteration 10108 : model1 loss : 0.038032 model2 loss : 0.028173
[22:31:36.078] iteration 10109 : model1 loss : 0.042480 model2 loss : 0.023769
[22:31:36.930] iteration 10110 : model1 loss : 0.020767 model2 loss : 0.019135
[22:31:37.660] iteration 10111 : model1 loss : 0.023154 model2 loss : 0.022018
[22:31:38.383] iteration 10112 : model1 loss : 0.021103 model2 loss : 0.024942
[22:31:39.108] iteration 10113 : model1 loss : 0.023984 model2 loss : 0.024739
[22:31:39.816] iteration 10114 : model1 loss : 0.024433 model2 loss : 0.024361
[22:31:40.564] iteration 10115 : model1 loss : 0.022181 model2 loss : 0.019335
[22:31:41.317] iteration 10116 : model1 loss : 0.022999 model2 loss : 0.021124
[22:31:42.059] iteration 10117 : model1 loss : 0.019269 model2 loss : 0.018142
[22:31:42.784] iteration 10118 : model1 loss : 0.027980 model2 loss : 0.024528
[22:31:43.480] iteration 10119 : model1 loss : 0.027021 model2 loss : 0.023790
[22:31:44.180] iteration 10120 : model1 loss : 0.022076 model2 loss : 0.020655
[22:31:44.901] iteration 10121 : model1 loss : 0.030213 model2 loss : 0.026591
[22:31:45.618] iteration 10122 : model1 loss : 0.017712 model2 loss : 0.016249
[22:31:46.377] iteration 10123 : model1 loss : 0.023164 model2 loss : 0.022531
[22:31:47.108] iteration 10124 : model1 loss : 0.026298 model2 loss : 0.027284
[22:31:47.823] iteration 10125 : model1 loss : 0.023337 model2 loss : 0.022278
[22:31:48.562] iteration 10126 : model1 loss : 0.024652 model2 loss : 0.023575
[22:31:49.272] iteration 10127 : model1 loss : 0.020702 model2 loss : 0.019310
[22:31:49.988] iteration 10128 : model1 loss : 0.030241 model2 loss : 0.030608
[22:31:50.746] iteration 10129 : model1 loss : 0.017771 model2 loss : 0.017078
[22:31:51.486] iteration 10130 : model1 loss : 0.027834 model2 loss : 0.025558
[22:31:52.222] iteration 10131 : model1 loss : 0.055575 model2 loss : 0.040561
[22:31:52.973] iteration 10132 : model1 loss : 0.023457 model2 loss : 0.022397
[22:31:53.694] iteration 10133 : model1 loss : 0.035430 model2 loss : 0.033211
[22:31:54.396] iteration 10134 : model1 loss : 0.020777 model2 loss : 0.019954
[22:31:55.118] iteration 10135 : model1 loss : 0.027133 model2 loss : 0.022782
[22:31:55.852] iteration 10136 : model1 loss : 0.035822 model2 loss : 0.033286
[22:31:56.568] iteration 10137 : model1 loss : 0.022321 model2 loss : 0.024845
[22:31:57.303] iteration 10138 : model1 loss : 0.022896 model2 loss : 0.024683
[22:31:58.008] iteration 10139 : model1 loss : 0.024445 model2 loss : 0.026146
[22:31:58.730] iteration 10140 : model1 loss : 0.021084 model2 loss : 0.019930
[22:31:59.428] iteration 10141 : model1 loss : 0.047004 model2 loss : 0.042230
[22:32:00.149] iteration 10142 : model1 loss : 0.033493 model2 loss : 0.026638
[22:32:00.868] iteration 10143 : model1 loss : 0.024593 model2 loss : 0.024609
[22:32:01.593] iteration 10144 : model1 loss : 0.033567 model2 loss : 0.030794
[22:32:02.337] iteration 10145 : model1 loss : 0.029959 model2 loss : 0.031473
[22:32:03.064] iteration 10146 : model1 loss : 0.031697 model2 loss : 0.021882
[22:32:03.807] iteration 10147 : model1 loss : 0.037350 model2 loss : 0.028678
[22:32:04.515] iteration 10148 : model1 loss : 0.025625 model2 loss : 0.029236
[22:32:05.223] iteration 10149 : model1 loss : 0.023944 model2 loss : 0.023802
[22:32:05.952] iteration 10150 : model1 loss : 0.027026 model2 loss : 0.020641
[22:32:06.764] iteration 10151 : model1 loss : 0.026455 model2 loss : 0.023564
[22:32:07.510] iteration 10152 : model1 loss : 0.020040 model2 loss : 0.019094
[22:32:08.245] iteration 10153 : model1 loss : 0.024197 model2 loss : 0.023096
[22:32:08.982] iteration 10154 : model1 loss : 0.028660 model2 loss : 0.025329
[22:32:09.687] iteration 10155 : model1 loss : 0.026465 model2 loss : 0.025105
[22:32:10.414] iteration 10156 : model1 loss : 0.033410 model2 loss : 0.026762
[22:32:11.144] iteration 10157 : model1 loss : 0.024103 model2 loss : 0.023145
[22:32:11.863] iteration 10158 : model1 loss : 0.015781 model2 loss : 0.017770
[22:32:12.585] iteration 10159 : model1 loss : 0.034555 model2 loss : 0.023487
[22:32:13.287] iteration 10160 : model1 loss : 0.026436 model2 loss : 0.027162
[22:32:13.986] iteration 10161 : model1 loss : 0.023244 model2 loss : 0.020692
[22:32:14.716] iteration 10162 : model1 loss : 0.020317 model2 loss : 0.018011
[22:32:15.430] iteration 10163 : model1 loss : 0.024240 model2 loss : 0.020797
[22:32:16.142] iteration 10164 : model1 loss : 0.018561 model2 loss : 0.018234
[22:32:16.872] iteration 10165 : model1 loss : 0.024431 model2 loss : 0.039440
[22:32:17.599] iteration 10166 : model1 loss : 0.028916 model2 loss : 0.031165
[22:32:18.310] iteration 10167 : model1 loss : 0.026646 model2 loss : 0.023078
[22:32:19.012] iteration 10168 : model1 loss : 0.023312 model2 loss : 0.022317
[22:32:19.721] iteration 10169 : model1 loss : 0.028467 model2 loss : 0.026246
[22:32:20.452] iteration 10170 : model1 loss : 0.049164 model2 loss : 0.042923
[22:32:21.179] iteration 10171 : model1 loss : 0.025413 model2 loss : 0.025601
[22:32:21.911] iteration 10172 : model1 loss : 0.022037 model2 loss : 0.021643
[22:32:22.646] iteration 10173 : model1 loss : 0.042589 model2 loss : 0.034880
[22:32:23.373] iteration 10174 : model1 loss : 0.019041 model2 loss : 0.019152
[22:32:24.097] iteration 10175 : model1 loss : 0.025386 model2 loss : 0.022559
[22:32:24.806] iteration 10176 : model1 loss : 0.022321 model2 loss : 0.024980
[22:32:25.516] iteration 10177 : model1 loss : 0.019103 model2 loss : 0.019235
[22:32:26.223] iteration 10178 : model1 loss : 0.024411 model2 loss : 0.023931
[22:32:26.959] iteration 10179 : model1 loss : 0.025488 model2 loss : 0.028098
[22:32:27.695] iteration 10180 : model1 loss : 0.024695 model2 loss : 0.026369
[22:32:28.412] iteration 10181 : model1 loss : 0.018307 model2 loss : 0.020115
[22:32:29.118] iteration 10182 : model1 loss : 0.025772 model2 loss : 0.025323
[22:32:29.820] iteration 10183 : model1 loss : 0.029837 model2 loss : 0.029466
[22:32:30.521] iteration 10184 : model1 loss : 0.060499 model2 loss : 0.049243
[22:32:31.242] iteration 10185 : model1 loss : 0.017033 model2 loss : 0.017251
[22:32:31.977] iteration 10186 : model1 loss : 0.027739 model2 loss : 0.028360
[22:32:32.707] iteration 10187 : model1 loss : 0.017855 model2 loss : 0.021362
[22:32:33.415] iteration 10188 : model1 loss : 0.025517 model2 loss : 0.024422
[22:32:34.129] iteration 10189 : model1 loss : 0.114406 model2 loss : 0.130527
[22:32:34.844] iteration 10190 : model1 loss : 0.023680 model2 loss : 0.021163
[22:32:35.560] iteration 10191 : model1 loss : 0.027225 model2 loss : 0.028980
[22:32:36.298] iteration 10192 : model1 loss : 0.019411 model2 loss : 0.020610
[22:32:37.066] iteration 10193 : model1 loss : 0.023427 model2 loss : 0.025042
[22:32:37.811] iteration 10194 : model1 loss : 0.029846 model2 loss : 0.029635
[22:32:38.566] iteration 10195 : model1 loss : 0.027363 model2 loss : 0.027954
[22:32:39.285] iteration 10196 : model1 loss : 0.018185 model2 loss : 0.020605
[22:32:40.019] iteration 10197 : model1 loss : 0.021656 model2 loss : 0.021218
[22:32:40.753] iteration 10198 : model1 loss : 0.036232 model2 loss : 0.045491
[22:32:41.472] iteration 10199 : model1 loss : 0.026041 model2 loss : 0.023117
[22:32:42.176] iteration 10200 : model1 loss : 0.025716 model2 loss : 0.024042
[22:33:03.483] iteration 10200 : model1_mean_dice : 0.834627 model1_mean_hd95 : 9.881747
[22:33:25.211] iteration 10200 : model2_mean_dice : 0.859333 model2_mean_hd95 : 5.438411
[22:33:26.065] iteration 10201 : model1 loss : 0.023789 model2 loss : 0.024840
[22:33:26.806] iteration 10202 : model1 loss : 0.018422 model2 loss : 0.016178
[22:33:27.570] iteration 10203 : model1 loss : 0.021580 model2 loss : 0.020276
[22:33:28.324] iteration 10204 : model1 loss : 0.025855 model2 loss : 0.020442
[22:33:29.119] iteration 10205 : model1 loss : 0.017698 model2 loss : 0.018578
[22:33:29.886] iteration 10206 : model1 loss : 0.022091 model2 loss : 0.020411
[22:33:30.660] iteration 10207 : model1 loss : 0.018731 model2 loss : 0.019449
[22:33:31.475] iteration 10208 : model1 loss : 0.020834 model2 loss : 0.022640
[22:33:32.268] iteration 10209 : model1 loss : 0.032382 model2 loss : 0.030417
[22:33:33.038] iteration 10210 : model1 loss : 0.030619 model2 loss : 0.026576
[22:33:33.772] iteration 10211 : model1 loss : 0.055937 model2 loss : 0.040395
[22:33:34.485] iteration 10212 : model1 loss : 0.030491 model2 loss : 0.023564
[22:33:35.185] iteration 10213 : model1 loss : 0.024187 model2 loss : 0.023205
[22:33:35.884] iteration 10214 : model1 loss : 0.028939 model2 loss : 0.029574
[22:33:36.591] iteration 10215 : model1 loss : 0.062210 model2 loss : 0.055812
[22:33:37.329] iteration 10216 : model1 loss : 0.019544 model2 loss : 0.019294
[22:33:38.030] iteration 10217 : model1 loss : 0.029169 model2 loss : 0.032667
[22:33:38.754] iteration 10218 : model1 loss : 0.023792 model2 loss : 0.021772
[22:33:39.471] iteration 10219 : model1 loss : 0.066908 model2 loss : 0.049093
[22:33:40.165] iteration 10220 : model1 loss : 0.022067 model2 loss : 0.022342
[22:33:40.887] iteration 10221 : model1 loss : 0.039283 model2 loss : 0.037705
[22:33:41.638] iteration 10222 : model1 loss : 0.025347 model2 loss : 0.026714
[22:33:42.392] iteration 10223 : model1 loss : 0.028749 model2 loss : 0.025992
[22:33:43.143] iteration 10224 : model1 loss : 0.027939 model2 loss : 0.028894
[22:33:43.937] iteration 10225 : model1 loss : 0.022052 model2 loss : 0.023097
[22:33:44.675] iteration 10226 : model1 loss : 0.031993 model2 loss : 0.031024
[22:33:45.411] iteration 10227 : model1 loss : 0.018391 model2 loss : 0.018730
[22:33:46.150] iteration 10228 : model1 loss : 0.017433 model2 loss : 0.017835
[22:33:46.883] iteration 10229 : model1 loss : 0.022159 model2 loss : 0.021566
[22:33:47.635] iteration 10230 : model1 loss : 0.021878 model2 loss : 0.026137
[22:33:48.360] iteration 10231 : model1 loss : 0.022166 model2 loss : 0.019559
[22:33:49.082] iteration 10232 : model1 loss : 0.030801 model2 loss : 0.024409
[22:33:49.792] iteration 10233 : model1 loss : 0.027004 model2 loss : 0.028274
[22:33:50.500] iteration 10234 : model1 loss : 0.033784 model2 loss : 0.040137
[22:33:51.208] iteration 10235 : model1 loss : 0.029675 model2 loss : 0.031826
[22:33:51.929] iteration 10236 : model1 loss : 0.022189 model2 loss : 0.021062
[22:33:52.692] iteration 10237 : model1 loss : 0.022532 model2 loss : 0.023177
[22:33:53.434] iteration 10238 : model1 loss : 0.021605 model2 loss : 0.022177
[22:33:54.180] iteration 10239 : model1 loss : 0.019074 model2 loss : 0.021819
[22:33:54.884] iteration 10240 : model1 loss : 0.097740 model2 loss : 0.067382
[22:33:55.600] iteration 10241 : model1 loss : 0.022812 model2 loss : 0.023163
[22:33:56.338] iteration 10242 : model1 loss : 0.023551 model2 loss : 0.024075
[22:33:57.042] iteration 10243 : model1 loss : 0.021222 model2 loss : 0.025178
[22:33:57.776] iteration 10244 : model1 loss : 0.020878 model2 loss : 0.019534
[22:33:58.536] iteration 10245 : model1 loss : 0.029774 model2 loss : 0.030581
[22:33:59.266] iteration 10246 : model1 loss : 0.031135 model2 loss : 0.026407
[22:33:59.969] iteration 10247 : model1 loss : 0.021224 model2 loss : 0.020311
[22:34:00.725] iteration 10248 : model1 loss : 0.025518 model2 loss : 0.026320
[22:34:01.440] iteration 10249 : model1 loss : 0.026307 model2 loss : 0.024679
[22:34:02.164] iteration 10250 : model1 loss : 0.017937 model2 loss : 0.016507
[22:34:02.940] iteration 10251 : model1 loss : 0.027678 model2 loss : 0.026827
[22:34:03.638] iteration 10252 : model1 loss : 0.032079 model2 loss : 0.035322
[22:34:04.353] iteration 10253 : model1 loss : 0.021706 model2 loss : 0.022271
[22:34:05.058] iteration 10254 : model1 loss : 0.035580 model2 loss : 0.026831
[22:34:05.761] iteration 10255 : model1 loss : 0.029460 model2 loss : 0.026769
[22:34:06.479] iteration 10256 : model1 loss : 0.031081 model2 loss : 0.028415
[22:34:07.207] iteration 10257 : model1 loss : 0.029139 model2 loss : 0.028912
[22:34:07.954] iteration 10258 : model1 loss : 0.036826 model2 loss : 0.035393
[22:34:08.664] iteration 10259 : model1 loss : 0.020940 model2 loss : 0.019363
[22:34:09.385] iteration 10260 : model1 loss : 0.018479 model2 loss : 0.016535
[22:34:10.091] iteration 10261 : model1 loss : 0.026085 model2 loss : 0.029036
[22:34:10.812] iteration 10262 : model1 loss : 0.029979 model2 loss : 0.025649
[22:34:11.544] iteration 10263 : model1 loss : 0.023847 model2 loss : 0.026035
[22:34:12.257] iteration 10264 : model1 loss : 0.033016 model2 loss : 0.030724
[22:34:12.974] iteration 10265 : model1 loss : 0.041455 model2 loss : 0.032023
[22:34:13.686] iteration 10266 : model1 loss : 0.021412 model2 loss : 0.021852
[22:34:14.432] iteration 10267 : model1 loss : 0.024923 model2 loss : 0.024348
[22:34:15.148] iteration 10268 : model1 loss : 0.039992 model2 loss : 0.032051
[22:34:15.862] iteration 10269 : model1 loss : 0.026575 model2 loss : 0.024270
[22:34:16.572] iteration 10270 : model1 loss : 0.022202 model2 loss : 0.024747
[22:34:17.319] iteration 10271 : model1 loss : 0.025068 model2 loss : 0.025622
[22:34:18.032] iteration 10272 : model1 loss : 0.022342 model2 loss : 0.020559
[22:34:18.754] iteration 10273 : model1 loss : 0.025947 model2 loss : 0.024382
[22:34:19.464] iteration 10274 : model1 loss : 0.027063 model2 loss : 0.022768
[22:34:20.177] iteration 10275 : model1 loss : 0.028082 model2 loss : 0.025168
[22:34:20.885] iteration 10276 : model1 loss : 0.026141 model2 loss : 0.022453
[22:34:21.597] iteration 10277 : model1 loss : 0.031105 model2 loss : 0.040094
[22:34:22.319] iteration 10278 : model1 loss : 0.036321 model2 loss : 0.038534
[22:34:23.049] iteration 10279 : model1 loss : 0.022684 model2 loss : 0.023011
[22:34:23.818] iteration 10280 : model1 loss : 0.041880 model2 loss : 0.035169
[22:34:24.536] iteration 10281 : model1 loss : 0.028260 model2 loss : 0.026636
[22:34:25.261] iteration 10282 : model1 loss : 0.025863 model2 loss : 0.022765
[22:34:25.965] iteration 10283 : model1 loss : 0.025477 model2 loss : 0.029938
[22:34:26.689] iteration 10284 : model1 loss : 0.029577 model2 loss : 0.031568
[22:34:27.414] iteration 10285 : model1 loss : 0.025359 model2 loss : 0.024359
[22:34:28.139] iteration 10286 : model1 loss : 0.026132 model2 loss : 0.026478
[22:34:28.903] iteration 10287 : model1 loss : 0.023567 model2 loss : 0.023055
[22:34:29.630] iteration 10288 : model1 loss : 0.020680 model2 loss : 0.023273
[22:34:30.379] iteration 10289 : model1 loss : 0.030300 model2 loss : 0.026666
[22:34:31.102] iteration 10290 : model1 loss : 0.025607 model2 loss : 0.025670
[22:34:31.855] iteration 10291 : model1 loss : 0.067353 model2 loss : 0.071651
[22:34:32.609] iteration 10292 : model1 loss : 0.020693 model2 loss : 0.023798
[22:34:33.361] iteration 10293 : model1 loss : 0.053290 model2 loss : 0.045980
[22:34:34.152] iteration 10294 : model1 loss : 0.026838 model2 loss : 0.027608
[22:34:34.865] iteration 10295 : model1 loss : 0.021402 model2 loss : 0.020621
[22:34:35.573] iteration 10296 : model1 loss : 0.024995 model2 loss : 0.025574
[22:34:36.315] iteration 10297 : model1 loss : 0.027019 model2 loss : 0.027835
[22:34:37.036] iteration 10298 : model1 loss : 0.029635 model2 loss : 0.028935
[22:34:37.743] iteration 10299 : model1 loss : 0.021501 model2 loss : 0.020420
[22:34:38.452] iteration 10300 : model1 loss : 0.021486 model2 loss : 0.020800
[22:34:39.209] iteration 10301 : model1 loss : 0.028140 model2 loss : 0.023446
[22:34:39.929] iteration 10302 : model1 loss : 0.025651 model2 loss : 0.025997
[22:34:40.637] iteration 10303 : model1 loss : 0.028680 model2 loss : 0.029747
[22:34:41.402] iteration 10304 : model1 loss : 0.020564 model2 loss : 0.018074
[22:34:42.159] iteration 10305 : model1 loss : 0.023357 model2 loss : 0.022079
[22:34:42.919] iteration 10306 : model1 loss : 0.025976 model2 loss : 0.023968
[22:34:43.635] iteration 10307 : model1 loss : 0.026365 model2 loss : 0.032647
[22:34:44.380] iteration 10308 : model1 loss : 0.023908 model2 loss : 0.023251
[22:34:45.154] iteration 10309 : model1 loss : 0.026254 model2 loss : 0.026232
[22:34:45.860] iteration 10310 : model1 loss : 0.022317 model2 loss : 0.023537
[22:34:46.574] iteration 10311 : model1 loss : 0.024155 model2 loss : 0.025558
[22:34:47.348] iteration 10312 : model1 loss : 0.021401 model2 loss : 0.020445
[22:34:48.067] iteration 10313 : model1 loss : 0.021001 model2 loss : 0.023876
[22:34:48.808] iteration 10314 : model1 loss : 0.018324 model2 loss : 0.019015
[22:34:49.560] iteration 10315 : model1 loss : 0.028505 model2 loss : 0.027016
[22:34:50.296] iteration 10316 : model1 loss : 0.029184 model2 loss : 0.031045
[22:34:51.066] iteration 10317 : model1 loss : 0.021892 model2 loss : 0.022659
[22:34:51.815] iteration 10318 : model1 loss : 0.020561 model2 loss : 0.022017
[22:34:52.559] iteration 10319 : model1 loss : 0.027108 model2 loss : 0.028074
[22:34:53.269] iteration 10320 : model1 loss : 0.029488 model2 loss : 0.035529
[22:34:53.978] iteration 10321 : model1 loss : 0.024813 model2 loss : 0.023239
[22:34:54.671] iteration 10322 : model1 loss : 0.021485 model2 loss : 0.023525
[22:34:55.399] iteration 10323 : model1 loss : 0.026773 model2 loss : 0.028777
[22:34:56.115] iteration 10324 : model1 loss : 0.021921 model2 loss : 0.022152
[22:34:56.807] iteration 10325 : model1 loss : 0.020296 model2 loss : 0.020485
[22:34:57.542] iteration 10326 : model1 loss : 0.060201 model2 loss : 0.057638
[22:34:58.260] iteration 10327 : model1 loss : 0.026693 model2 loss : 0.023830
[22:34:59.013] iteration 10328 : model1 loss : 0.028477 model2 loss : 0.025970
[22:34:59.717] iteration 10329 : model1 loss : 0.021616 model2 loss : 0.021087
[22:35:00.428] iteration 10330 : model1 loss : 0.024835 model2 loss : 0.027194
[22:35:01.147] iteration 10331 : model1 loss : 0.014863 model2 loss : 0.015539
[22:35:01.878] iteration 10332 : model1 loss : 0.142647 model2 loss : 0.142338
[22:35:02.613] iteration 10333 : model1 loss : 0.033076 model2 loss : 0.034998
[22:35:03.348] iteration 10334 : model1 loss : 0.025598 model2 loss : 0.024305
[22:35:04.066] iteration 10335 : model1 loss : 0.017056 model2 loss : 0.018527
[22:35:04.789] iteration 10336 : model1 loss : 0.024064 model2 loss : 0.023310
[22:35:05.487] iteration 10337 : model1 loss : 0.023850 model2 loss : 0.027942
[22:35:06.219] iteration 10338 : model1 loss : 0.028560 model2 loss : 0.029142
[22:35:06.932] iteration 10339 : model1 loss : 0.019391 model2 loss : 0.020237
[22:35:07.646] iteration 10340 : model1 loss : 0.025643 model2 loss : 0.024173
[22:35:08.393] iteration 10341 : model1 loss : 0.021236 model2 loss : 0.020609
[22:35:09.104] iteration 10342 : model1 loss : 0.023021 model2 loss : 0.023034
[22:35:09.822] iteration 10343 : model1 loss : 0.029431 model2 loss : 0.028334
[22:35:10.523] iteration 10344 : model1 loss : 0.024169 model2 loss : 0.021932
[22:35:11.237] iteration 10345 : model1 loss : 0.043824 model2 loss : 0.042031
[22:35:11.945] iteration 10346 : model1 loss : 0.021107 model2 loss : 0.024800
[22:35:12.685] iteration 10347 : model1 loss : 0.022342 model2 loss : 0.025029
[22:35:13.391] iteration 10348 : model1 loss : 0.024993 model2 loss : 0.026035
[22:35:14.107] iteration 10349 : model1 loss : 0.028254 model2 loss : 0.026617
[22:35:14.811] iteration 10350 : model1 loss : 0.023709 model2 loss : 0.024161
[22:35:15.551] iteration 10351 : model1 loss : 0.044131 model2 loss : 0.035315
[22:35:16.302] iteration 10352 : model1 loss : 0.018018 model2 loss : 0.017800
[22:35:17.034] iteration 10353 : model1 loss : 0.018309 model2 loss : 0.017620
[22:35:17.757] iteration 10354 : model1 loss : 0.024728 model2 loss : 0.025502
[22:35:18.524] iteration 10355 : model1 loss : 0.070716 model2 loss : 0.042001
[22:35:19.237] iteration 10356 : model1 loss : 0.021205 model2 loss : 0.021973
[22:35:19.963] iteration 10357 : model1 loss : 0.031547 model2 loss : 0.030581
[22:35:20.689] iteration 10358 : model1 loss : 0.020848 model2 loss : 0.024173
[22:35:21.437] iteration 10359 : model1 loss : 0.020627 model2 loss : 0.020638
[22:35:22.168] iteration 10360 : model1 loss : 0.026877 model2 loss : 0.024497
[22:35:22.909] iteration 10361 : model1 loss : 0.031159 model2 loss : 0.025435
[22:35:23.614] iteration 10362 : model1 loss : 0.038411 model2 loss : 0.035757
[22:35:24.325] iteration 10363 : model1 loss : 0.023049 model2 loss : 0.024851
[22:35:25.053] iteration 10364 : model1 loss : 0.091918 model2 loss : 0.046405
[22:35:25.772] iteration 10365 : model1 loss : 0.038163 model2 loss : 0.028940
[22:35:26.530] iteration 10366 : model1 loss : 0.019745 model2 loss : 0.018129
[22:35:27.247] iteration 10367 : model1 loss : 0.024308 model2 loss : 0.028792
[22:35:27.949] iteration 10368 : model1 loss : 0.029535 model2 loss : 0.027131
[22:35:28.693] iteration 10369 : model1 loss : 0.024536 model2 loss : 0.023451
[22:35:29.413] iteration 10370 : model1 loss : 0.034651 model2 loss : 0.038919
[22:35:30.132] iteration 10371 : model1 loss : 0.033218 model2 loss : 0.027270
[22:35:30.848] iteration 10372 : model1 loss : 0.028411 model2 loss : 0.027021
[22:35:31.572] iteration 10373 : model1 loss : 0.025284 model2 loss : 0.020133
[22:35:32.317] iteration 10374 : model1 loss : 0.025696 model2 loss : 0.023303
[22:35:33.037] iteration 10375 : model1 loss : 0.028533 model2 loss : 0.022255
[22:35:33.760] iteration 10376 : model1 loss : 0.016530 model2 loss : 0.015386
[22:35:34.476] iteration 10377 : model1 loss : 0.023687 model2 loss : 0.020844
[22:35:35.191] iteration 10378 : model1 loss : 0.029973 model2 loss : 0.031025
[22:35:35.917] iteration 10379 : model1 loss : 0.032200 model2 loss : 0.014650
[22:35:36.662] iteration 10380 : model1 loss : 0.036300 model2 loss : 0.033129
[22:35:37.376] iteration 10381 : model1 loss : 0.030961 model2 loss : 0.027683
[22:35:38.076] iteration 10382 : model1 loss : 0.024793 model2 loss : 0.024985
[22:35:38.785] iteration 10383 : model1 loss : 0.039392 model2 loss : 0.039808
[22:35:39.489] iteration 10384 : model1 loss : 0.029517 model2 loss : 0.031108
[22:35:40.195] iteration 10385 : model1 loss : 0.027649 model2 loss : 0.028383
[22:35:40.921] iteration 10386 : model1 loss : 0.023616 model2 loss : 0.021282
[22:35:41.647] iteration 10387 : model1 loss : 0.022538 model2 loss : 0.022337
[22:35:42.394] iteration 10388 : model1 loss : 0.035736 model2 loss : 0.034129
[22:35:43.102] iteration 10389 : model1 loss : 0.039372 model2 loss : 0.043137
[22:35:43.802] iteration 10390 : model1 loss : 0.016613 model2 loss : 0.017690
[22:35:44.510] iteration 10391 : model1 loss : 0.034538 model2 loss : 0.030423
[22:35:45.205] iteration 10392 : model1 loss : 0.141694 model2 loss : 0.143594
[22:35:45.902] iteration 10393 : model1 loss : 0.025447 model2 loss : 0.025617
[22:35:46.623] iteration 10394 : model1 loss : 0.027869 model2 loss : 0.026774
[22:35:47.357] iteration 10395 : model1 loss : 0.048892 model2 loss : 0.021461
[22:35:48.071] iteration 10396 : model1 loss : 0.024473 model2 loss : 0.023407
[22:35:48.793] iteration 10397 : model1 loss : 0.020926 model2 loss : 0.022378
[22:35:49.513] iteration 10398 : model1 loss : 0.036549 model2 loss : 0.023076
[22:35:50.224] iteration 10399 : model1 loss : 0.028272 model2 loss : 0.023340
[22:35:50.954] iteration 10400 : model1 loss : 0.025198 model2 loss : 0.022936
[22:36:13.917] iteration 10400 : model1_mean_dice : 0.829874 model1_mean_hd95 : 7.943979
[22:36:34.386] iteration 10400 : model2_mean_dice : 0.852097 model2_mean_hd95 : 4.038128
[22:36:35.094] iteration 10401 : model1 loss : 0.027959 model2 loss : 0.026876
[22:36:35.770] iteration 10402 : model1 loss : 0.023353 model2 loss : 0.022258
[22:36:36.451] iteration 10403 : model1 loss : 0.023806 model2 loss : 0.021059
[22:36:37.119] iteration 10404 : model1 loss : 0.022212 model2 loss : 0.020337
[22:36:37.807] iteration 10405 : model1 loss : 0.021649 model2 loss : 0.019819
[22:36:38.546] iteration 10406 : model1 loss : 0.034397 model2 loss : 0.035151
[22:36:39.246] iteration 10407 : model1 loss : 0.040910 model2 loss : 0.025747
[22:36:39.923] iteration 10408 : model1 loss : 0.017379 model2 loss : 0.035276
[22:36:40.610] iteration 10409 : model1 loss : 0.027971 model2 loss : 0.021410
[22:36:41.290] iteration 10410 : model1 loss : 0.028874 model2 loss : 0.028201
[22:36:42.004] iteration 10411 : model1 loss : 0.022657 model2 loss : 0.024980
[22:36:42.707] iteration 10412 : model1 loss : 0.030925 model2 loss : 0.026684
[22:36:43.384] iteration 10413 : model1 loss : 0.022910 model2 loss : 0.029301
[22:36:44.072] iteration 10414 : model1 loss : 0.024654 model2 loss : 0.026929
[22:36:44.776] iteration 10415 : model1 loss : 0.023215 model2 loss : 0.027125
[22:36:45.450] iteration 10416 : model1 loss : 0.018230 model2 loss : 0.017918
[22:36:46.114] iteration 10417 : model1 loss : 0.029943 model2 loss : 0.026125
[22:36:46.779] iteration 10418 : model1 loss : 0.026187 model2 loss : 0.023131
[22:36:47.445] iteration 10419 : model1 loss : 0.029065 model2 loss : 0.028729
[22:36:48.110] iteration 10420 : model1 loss : 0.019217 model2 loss : 0.018636
[22:36:48.787] iteration 10421 : model1 loss : 0.026706 model2 loss : 0.027306
[22:36:49.492] iteration 10422 : model1 loss : 0.030718 model2 loss : 0.029837
[22:36:50.215] iteration 10423 : model1 loss : 0.029888 model2 loss : 0.025284
[22:36:50.902] iteration 10424 : model1 loss : 0.023513 model2 loss : 0.023287
[22:36:51.572] iteration 10425 : model1 loss : 0.050407 model2 loss : 0.047999
[22:36:52.234] iteration 10426 : model1 loss : 0.023706 model2 loss : 0.025699
[22:36:52.908] iteration 10427 : model1 loss : 0.105418 model2 loss : 0.137878
[22:36:53.582] iteration 10428 : model1 loss : 0.024736 model2 loss : 0.023102
[22:36:54.249] iteration 10429 : model1 loss : 0.031966 model2 loss : 0.029290
[22:36:54.911] iteration 10430 : model1 loss : 0.024721 model2 loss : 0.045198
[22:36:55.603] iteration 10431 : model1 loss : 0.019634 model2 loss : 0.021462
[22:36:56.310] iteration 10432 : model1 loss : 0.023709 model2 loss : 0.022427
[22:36:57.012] iteration 10433 : model1 loss : 0.019089 model2 loss : 0.021198
[22:36:57.719] iteration 10434 : model1 loss : 0.031474 model2 loss : 0.023812
[22:36:58.406] iteration 10435 : model1 loss : 0.030724 model2 loss : 0.030643
[22:36:59.103] iteration 10436 : model1 loss : 0.026645 model2 loss : 0.024851
[22:36:59.774] iteration 10437 : model1 loss : 0.028658 model2 loss : 0.028349
[22:37:00.444] iteration 10438 : model1 loss : 0.021015 model2 loss : 0.019301
[22:37:01.109] iteration 10439 : model1 loss : 0.057371 model2 loss : 0.118761
[22:37:01.793] iteration 10440 : model1 loss : 0.035894 model2 loss : 0.051739
[22:37:02.462] iteration 10441 : model1 loss : 0.023286 model2 loss : 0.022997
[22:37:03.130] iteration 10442 : model1 loss : 0.015897 model2 loss : 0.018937
[22:37:03.802] iteration 10443 : model1 loss : 0.048088 model2 loss : 0.050379
[22:37:04.476] iteration 10444 : model1 loss : 0.034381 model2 loss : 0.037667
[22:37:05.151] iteration 10445 : model1 loss : 0.027502 model2 loss : 0.037867
[22:37:05.811] iteration 10446 : model1 loss : 0.021142 model2 loss : 0.020663
[22:37:06.491] iteration 10447 : model1 loss : 0.020173 model2 loss : 0.020860
[22:37:07.151] iteration 10448 : model1 loss : 0.028590 model2 loss : 0.025053
[22:37:07.805] iteration 10449 : model1 loss : 0.030872 model2 loss : 0.029815
[22:37:08.473] iteration 10450 : model1 loss : 0.022248 model2 loss : 0.046024
[22:37:09.213] iteration 10451 : model1 loss : 0.022229 model2 loss : 0.026935
[22:37:09.878] iteration 10452 : model1 loss : 0.023813 model2 loss : 0.029769
[22:37:10.545] iteration 10453 : model1 loss : 0.022627 model2 loss : 0.023768
[22:37:11.214] iteration 10454 : model1 loss : 0.035355 model2 loss : 0.028960
[22:37:11.881] iteration 10455 : model1 loss : 0.020833 model2 loss : 0.020424
[22:37:12.554] iteration 10456 : model1 loss : 0.032629 model2 loss : 0.030712
[22:37:13.208] iteration 10457 : model1 loss : 0.047134 model2 loss : 0.041286
[22:37:13.871] iteration 10458 : model1 loss : 0.035847 model2 loss : 0.033458
[22:37:14.546] iteration 10459 : model1 loss : 0.018846 model2 loss : 0.022429
[22:37:15.207] iteration 10460 : model1 loss : 0.041882 model2 loss : 0.056396
[22:37:15.864] iteration 10461 : model1 loss : 0.024294 model2 loss : 0.024123
[22:37:16.542] iteration 10462 : model1 loss : 0.034560 model2 loss : 0.036663
[22:37:17.210] iteration 10463 : model1 loss : 0.018832 model2 loss : 0.018829
[22:37:17.882] iteration 10464 : model1 loss : 0.023275 model2 loss : 0.025758
[22:37:18.549] iteration 10465 : model1 loss : 0.025897 model2 loss : 0.023376
[22:37:19.215] iteration 10466 : model1 loss : 0.021372 model2 loss : 0.021798
[22:37:19.888] iteration 10467 : model1 loss : 0.023410 model2 loss : 0.025722
[22:37:20.614] iteration 10468 : model1 loss : 0.031529 model2 loss : 0.034893
[22:37:21.290] iteration 10469 : model1 loss : 0.028476 model2 loss : 0.028248
[22:37:21.973] iteration 10470 : model1 loss : 0.026196 model2 loss : 0.029270
[22:37:22.643] iteration 10471 : model1 loss : 0.051093 model2 loss : 0.044715
[22:37:23.317] iteration 10472 : model1 loss : 0.029071 model2 loss : 0.027085
[22:37:24.027] iteration 10473 : model1 loss : 0.026814 model2 loss : 0.027708
[22:37:24.693] iteration 10474 : model1 loss : 0.037808 model2 loss : 0.043205
[22:37:25.365] iteration 10475 : model1 loss : 0.075743 model2 loss : 0.070642
[22:37:26.040] iteration 10476 : model1 loss : 0.034780 model2 loss : 0.034838
[22:37:26.702] iteration 10477 : model1 loss : 0.018728 model2 loss : 0.021492
[22:37:27.373] iteration 10478 : model1 loss : 0.027396 model2 loss : 0.037284
[22:37:28.050] iteration 10479 : model1 loss : 0.020387 model2 loss : 0.018763
[22:37:28.725] iteration 10480 : model1 loss : 0.020098 model2 loss : 0.022831
[22:37:29.411] iteration 10481 : model1 loss : 0.023842 model2 loss : 0.028067
[22:37:30.081] iteration 10482 : model1 loss : 0.033958 model2 loss : 0.028495
[22:37:30.758] iteration 10483 : model1 loss : 0.020667 model2 loss : 0.028844
[22:37:31.433] iteration 10484 : model1 loss : 0.023265 model2 loss : 0.022324
[22:37:32.097] iteration 10485 : model1 loss : 0.019636 model2 loss : 0.018171
[22:37:32.785] iteration 10486 : model1 loss : 0.052670 model2 loss : 0.025477
[22:37:33.445] iteration 10487 : model1 loss : 0.023349 model2 loss : 0.025087
[22:37:34.128] iteration 10488 : model1 loss : 0.023450 model2 loss : 0.023375
[22:37:34.821] iteration 10489 : model1 loss : 0.046317 model2 loss : 0.042772
[22:37:35.499] iteration 10490 : model1 loss : 0.018103 model2 loss : 0.016529
[22:37:36.177] iteration 10491 : model1 loss : 0.025911 model2 loss : 0.022092
[22:37:36.861] iteration 10492 : model1 loss : 0.017019 model2 loss : 0.018350
[22:37:37.562] iteration 10493 : model1 loss : 0.018406 model2 loss : 0.018615
[22:37:38.226] iteration 10494 : model1 loss : 0.037008 model2 loss : 0.040238
[22:37:38.896] iteration 10495 : model1 loss : 0.022700 model2 loss : 0.020473
[22:37:39.609] iteration 10496 : model1 loss : 0.021383 model2 loss : 0.022668
[22:37:40.339] iteration 10497 : model1 loss : 0.018865 model2 loss : 0.018183
[22:37:41.002] iteration 10498 : model1 loss : 0.024558 model2 loss : 0.024075
[22:37:41.698] iteration 10499 : model1 loss : 0.022521 model2 loss : 0.021749
[22:37:42.456] iteration 10500 : model1 loss : 0.029487 model2 loss : 0.034670
[22:37:43.214] iteration 10501 : model1 loss : 0.023908 model2 loss : 0.023973
[22:37:43.961] iteration 10502 : model1 loss : 0.045661 model2 loss : 0.048546
[22:37:44.680] iteration 10503 : model1 loss : 0.018894 model2 loss : 0.019977
[22:37:45.420] iteration 10504 : model1 loss : 0.026306 model2 loss : 0.028303
[22:37:46.144] iteration 10505 : model1 loss : 0.025560 model2 loss : 0.024109
[22:37:46.932] iteration 10506 : model1 loss : 0.038902 model2 loss : 0.033570
[22:37:47.704] iteration 10507 : model1 loss : 0.022631 model2 loss : 0.019264
[22:37:48.469] iteration 10508 : model1 loss : 0.026312 model2 loss : 0.021775
[22:37:49.265] iteration 10509 : model1 loss : 0.028973 model2 loss : 0.028705
[22:37:50.046] iteration 10510 : model1 loss : 0.029327 model2 loss : 0.026417
[22:37:50.789] iteration 10511 : model1 loss : 0.020869 model2 loss : 0.020575
[22:37:51.490] iteration 10512 : model1 loss : 0.018737 model2 loss : 0.019895
[22:37:52.199] iteration 10513 : model1 loss : 0.021097 model2 loss : 0.019997
[22:37:52.862] iteration 10514 : model1 loss : 0.040857 model2 loss : 0.041922
[22:37:53.556] iteration 10515 : model1 loss : 0.020698 model2 loss : 0.020071
[22:37:54.244] iteration 10516 : model1 loss : 0.018018 model2 loss : 0.018076
[22:37:54.919] iteration 10517 : model1 loss : 0.025365 model2 loss : 0.022535
[22:37:55.622] iteration 10518 : model1 loss : 0.043725 model2 loss : 0.038739
[22:37:56.316] iteration 10519 : model1 loss : 0.020750 model2 loss : 0.020805
[22:37:57.010] iteration 10520 : model1 loss : 0.056308 model2 loss : 0.073067
[22:37:57.688] iteration 10521 : model1 loss : 0.026676 model2 loss : 0.027848
[22:37:58.380] iteration 10522 : model1 loss : 0.054847 model2 loss : 0.060903
[22:37:59.068] iteration 10523 : model1 loss : 0.027709 model2 loss : 0.028890
[22:37:59.767] iteration 10524 : model1 loss : 0.065415 model2 loss : 0.054773
[22:38:00.456] iteration 10525 : model1 loss : 0.034955 model2 loss : 0.032247
[22:38:01.140] iteration 10526 : model1 loss : 0.022894 model2 loss : 0.023807
[22:38:01.834] iteration 10527 : model1 loss : 0.024428 model2 loss : 0.023667
[22:38:02.518] iteration 10528 : model1 loss : 0.023320 model2 loss : 0.024573
[22:38:03.190] iteration 10529 : model1 loss : 0.028294 model2 loss : 0.027806
[22:38:03.852] iteration 10530 : model1 loss : 0.037873 model2 loss : 0.032453
[22:38:04.518] iteration 10531 : model1 loss : 0.026519 model2 loss : 0.027208
[22:38:05.183] iteration 10532 : model1 loss : 0.035963 model2 loss : 0.033190
[22:38:05.853] iteration 10533 : model1 loss : 0.028000 model2 loss : 0.028788
[22:38:06.526] iteration 10534 : model1 loss : 0.059310 model2 loss : 0.026946
[22:38:07.192] iteration 10535 : model1 loss : 0.030773 model2 loss : 0.032488
[22:38:07.859] iteration 10536 : model1 loss : 0.034688 model2 loss : 0.030723
[22:38:08.555] iteration 10537 : model1 loss : 0.019854 model2 loss : 0.024665
[22:38:09.255] iteration 10538 : model1 loss : 0.025227 model2 loss : 0.031480
[22:38:09.955] iteration 10539 : model1 loss : 0.019123 model2 loss : 0.019368
[22:38:10.631] iteration 10540 : model1 loss : 0.021120 model2 loss : 0.023647
[22:38:11.302] iteration 10541 : model1 loss : 0.025147 model2 loss : 0.028759
[22:38:11.974] iteration 10542 : model1 loss : 0.038417 model2 loss : 0.039673
[22:38:12.662] iteration 10543 : model1 loss : 0.023911 model2 loss : 0.023994
[22:38:13.364] iteration 10544 : model1 loss : 0.026363 model2 loss : 0.027054
[22:38:14.055] iteration 10545 : model1 loss : 0.025270 model2 loss : 0.022018
[22:38:14.733] iteration 10546 : model1 loss : 0.020406 model2 loss : 0.020815
[22:38:15.449] iteration 10547 : model1 loss : 0.022771 model2 loss : 0.025502
[22:38:16.128] iteration 10548 : model1 loss : 0.027771 model2 loss : 0.025935
[22:38:16.826] iteration 10549 : model1 loss : 0.023309 model2 loss : 0.031001
[22:38:17.493] iteration 10550 : model1 loss : 0.023902 model2 loss : 0.028530
[22:38:18.252] iteration 10551 : model1 loss : 0.055563 model2 loss : 0.047191
[22:38:18.956] iteration 10552 : model1 loss : 0.037143 model2 loss : 0.031882
[22:38:19.637] iteration 10553 : model1 loss : 0.047310 model2 loss : 0.081144
[22:38:20.304] iteration 10554 : model1 loss : 0.021644 model2 loss : 0.022621
[22:38:20.982] iteration 10555 : model1 loss : 0.031930 model2 loss : 0.038284
[22:38:21.652] iteration 10556 : model1 loss : 0.023859 model2 loss : 0.021658
[22:38:22.314] iteration 10557 : model1 loss : 0.030163 model2 loss : 0.033625
[22:38:22.988] iteration 10558 : model1 loss : 0.027721 model2 loss : 0.032704
[22:38:23.665] iteration 10559 : model1 loss : 0.023323 model2 loss : 0.025368
[22:38:24.369] iteration 10560 : model1 loss : 0.027813 model2 loss : 0.039829
[22:38:25.053] iteration 10561 : model1 loss : 0.023044 model2 loss : 0.020158
[22:38:25.713] iteration 10562 : model1 loss : 0.022758 model2 loss : 0.022085
[22:38:26.388] iteration 10563 : model1 loss : 0.026861 model2 loss : 0.028650
[22:38:27.061] iteration 10564 : model1 loss : 0.030581 model2 loss : 0.026419
[22:38:27.734] iteration 10565 : model1 loss : 0.021435 model2 loss : 0.021206
[22:38:28.431] iteration 10566 : model1 loss : 0.024793 model2 loss : 0.027217
[22:38:29.103] iteration 10567 : model1 loss : 0.021046 model2 loss : 0.022855
[22:38:29.769] iteration 10568 : model1 loss : 0.020738 model2 loss : 0.020628
[22:38:30.448] iteration 10569 : model1 loss : 0.024167 model2 loss : 0.027978
[22:38:31.119] iteration 10570 : model1 loss : 0.022283 model2 loss : 0.021516
[22:38:31.801] iteration 10571 : model1 loss : 0.025564 model2 loss : 0.029208
[22:38:32.475] iteration 10572 : model1 loss : 0.040951 model2 loss : 0.055678
[22:38:33.146] iteration 10573 : model1 loss : 0.021923 model2 loss : 0.023123
[22:38:33.824] iteration 10574 : model1 loss : 0.028552 model2 loss : 0.025011
[22:38:34.509] iteration 10575 : model1 loss : 0.021808 model2 loss : 0.022014
[22:38:35.181] iteration 10576 : model1 loss : 0.018842 model2 loss : 0.021457
[22:38:35.842] iteration 10577 : model1 loss : 0.024231 model2 loss : 0.024546
[22:38:36.519] iteration 10578 : model1 loss : 0.028987 model2 loss : 0.030024
[22:38:37.187] iteration 10579 : model1 loss : 0.017854 model2 loss : 0.017781
[22:38:37.859] iteration 10580 : model1 loss : 0.024305 model2 loss : 0.023104
[22:38:38.568] iteration 10581 : model1 loss : 0.149227 model2 loss : 0.169740
[22:38:39.251] iteration 10582 : model1 loss : 0.025649 model2 loss : 0.025721
[22:38:39.951] iteration 10583 : model1 loss : 0.032769 model2 loss : 0.033959
[22:38:40.638] iteration 10584 : model1 loss : 0.030833 model2 loss : 0.032292
[22:38:41.322] iteration 10585 : model1 loss : 0.027996 model2 loss : 0.029340
[22:38:42.001] iteration 10586 : model1 loss : 0.026933 model2 loss : 0.026512
[22:38:42.677] iteration 10587 : model1 loss : 0.018020 model2 loss : 0.016565
[22:38:43.345] iteration 10588 : model1 loss : 0.052377 model2 loss : 0.045973
[22:38:44.028] iteration 10589 : model1 loss : 0.017623 model2 loss : 0.021016
[22:38:44.703] iteration 10590 : model1 loss : 0.024903 model2 loss : 0.023236
[22:38:45.370] iteration 10591 : model1 loss : 0.019030 model2 loss : 0.018121
[22:38:46.051] iteration 10592 : model1 loss : 0.041807 model2 loss : 0.043437
[22:38:46.739] iteration 10593 : model1 loss : 0.024772 model2 loss : 0.028794
[22:38:47.427] iteration 10594 : model1 loss : 0.021655 model2 loss : 0.020585
[22:38:48.096] iteration 10595 : model1 loss : 0.018793 model2 loss : 0.020604
[22:38:48.781] iteration 10596 : model1 loss : 0.042417 model2 loss : 0.041888
[22:38:49.464] iteration 10597 : model1 loss : 0.021379 model2 loss : 0.020569
[22:38:50.175] iteration 10598 : model1 loss : 0.024232 model2 loss : 0.022393
[22:38:50.992] iteration 10599 : model1 loss : 0.029412 model2 loss : 0.031850
[22:38:51.800] iteration 10600 : model1 loss : 0.019165 model2 loss : 0.019307
[22:39:12.249] iteration 10600 : model1_mean_dice : 0.862810 model1_mean_hd95 : 7.094564
[22:39:31.323] iteration 10600 : model2_mean_dice : 0.858802 model2_mean_hd95 : 4.208951
[22:39:32.033] iteration 10601 : model1 loss : 0.025112 model2 loss : 0.023844
[22:39:32.696] iteration 10602 : model1 loss : 0.033461 model2 loss : 0.033362
[22:39:33.371] iteration 10603 : model1 loss : 0.020286 model2 loss : 0.021584
[22:39:34.058] iteration 10604 : model1 loss : 0.022057 model2 loss : 0.027274
[22:39:34.765] iteration 10605 : model1 loss : 0.017223 model2 loss : 0.018221
[22:39:35.480] iteration 10606 : model1 loss : 0.023952 model2 loss : 0.025816
[22:39:36.206] iteration 10607 : model1 loss : 0.020802 model2 loss : 0.022391
[22:39:36.871] iteration 10608 : model1 loss : 0.024733 model2 loss : 0.022129
[22:39:37.548] iteration 10609 : model1 loss : 0.016200 model2 loss : 0.017640
[22:39:38.200] iteration 10610 : model1 loss : 0.022011 model2 loss : 0.021019
[22:39:38.877] iteration 10611 : model1 loss : 0.030344 model2 loss : 0.025992
[22:39:39.547] iteration 10612 : model1 loss : 0.025187 model2 loss : 0.026432
[22:39:40.221] iteration 10613 : model1 loss : 0.052138 model2 loss : 0.060936
[22:39:40.883] iteration 10614 : model1 loss : 0.031791 model2 loss : 0.029904
[22:39:41.554] iteration 10615 : model1 loss : 0.025604 model2 loss : 0.029415
[22:39:42.223] iteration 10616 : model1 loss : 0.033723 model2 loss : 0.041751
[22:39:42.891] iteration 10617 : model1 loss : 0.018876 model2 loss : 0.018009
[22:39:43.554] iteration 10618 : model1 loss : 0.028500 model2 loss : 0.027451
[22:39:44.255] iteration 10619 : model1 loss : 0.019767 model2 loss : 0.022906
[22:39:44.925] iteration 10620 : model1 loss : 0.039937 model2 loss : 0.031692
[22:39:45.585] iteration 10621 : model1 loss : 0.047013 model2 loss : 0.042253
[22:39:46.246] iteration 10622 : model1 loss : 0.095212 model2 loss : 0.082173
[22:39:46.905] iteration 10623 : model1 loss : 0.019032 model2 loss : 0.018259
[22:39:47.585] iteration 10624 : model1 loss : 0.021623 model2 loss : 0.023764
[22:39:48.253] iteration 10625 : model1 loss : 0.020876 model2 loss : 0.020203
[22:39:48.924] iteration 10626 : model1 loss : 0.021814 model2 loss : 0.029978
[22:39:49.589] iteration 10627 : model1 loss : 0.020846 model2 loss : 0.021515
[22:39:50.258] iteration 10628 : model1 loss : 0.020620 model2 loss : 0.023101
[22:39:50.926] iteration 10629 : model1 loss : 0.021564 model2 loss : 0.020428
[22:39:51.596] iteration 10630 : model1 loss : 0.053159 model2 loss : 0.035950
[22:39:52.267] iteration 10631 : model1 loss : 0.028886 model2 loss : 0.034021
[22:39:52.942] iteration 10632 : model1 loss : 0.022149 model2 loss : 0.023814
[22:39:53.629] iteration 10633 : model1 loss : 0.023155 model2 loss : 0.021288
[22:39:54.331] iteration 10634 : model1 loss : 0.019905 model2 loss : 0.022564
[22:39:55.026] iteration 10635 : model1 loss : 0.022603 model2 loss : 0.020963
[22:39:55.718] iteration 10636 : model1 loss : 0.019503 model2 loss : 0.019431
[22:39:56.439] iteration 10637 : model1 loss : 0.026301 model2 loss : 0.027945
[22:39:57.109] iteration 10638 : model1 loss : 0.028505 model2 loss : 0.026410
[22:39:57.815] iteration 10639 : model1 loss : 0.027143 model2 loss : 0.027433
[22:39:58.496] iteration 10640 : model1 loss : 0.031608 model2 loss : 0.026604
[22:39:59.157] iteration 10641 : model1 loss : 0.018630 model2 loss : 0.018358
[22:39:59.814] iteration 10642 : model1 loss : 0.019734 model2 loss : 0.022727
[22:40:00.486] iteration 10643 : model1 loss : 0.021945 model2 loss : 0.021169
[22:40:01.152] iteration 10644 : model1 loss : 0.036404 model2 loss : 0.034686
[22:40:01.824] iteration 10645 : model1 loss : 0.020695 model2 loss : 0.023148
[22:40:02.500] iteration 10646 : model1 loss : 0.026112 model2 loss : 0.031175
[22:40:03.179] iteration 10647 : model1 loss : 0.020091 model2 loss : 0.019654
[22:40:03.850] iteration 10648 : model1 loss : 0.020858 model2 loss : 0.020627
[22:40:04.530] iteration 10649 : model1 loss : 0.024438 model2 loss : 0.023577
[22:40:05.211] iteration 10650 : model1 loss : 0.022301 model2 loss : 0.021873
[22:40:05.921] iteration 10651 : model1 loss : 0.021407 model2 loss : 0.024012
[22:40:06.589] iteration 10652 : model1 loss : 0.024460 model2 loss : 0.024340
[22:40:07.289] iteration 10653 : model1 loss : 0.026549 model2 loss : 0.027393
[22:40:07.978] iteration 10654 : model1 loss : 0.027681 model2 loss : 0.026040
[22:40:08.663] iteration 10655 : model1 loss : 0.018954 model2 loss : 0.016246
[22:40:09.346] iteration 10656 : model1 loss : 0.024239 model2 loss : 0.024464
[22:40:10.045] iteration 10657 : model1 loss : 0.023820 model2 loss : 0.022142
[22:40:10.791] iteration 10658 : model1 loss : 0.056730 model2 loss : 0.046200
[22:40:11.476] iteration 10659 : model1 loss : 0.030299 model2 loss : 0.030963
[22:40:12.185] iteration 10660 : model1 loss : 0.021569 model2 loss : 0.021455
[22:40:12.863] iteration 10661 : model1 loss : 0.035464 model2 loss : 0.040913
[22:40:13.563] iteration 10662 : model1 loss : 0.020688 model2 loss : 0.022766
[22:40:14.256] iteration 10663 : model1 loss : 0.022562 model2 loss : 0.020537
[22:40:14.959] iteration 10664 : model1 loss : 0.026699 model2 loss : 0.022674
[22:40:15.662] iteration 10665 : model1 loss : 0.024882 model2 loss : 0.022682
[22:40:16.369] iteration 10666 : model1 loss : 0.027541 model2 loss : 0.026025
[22:40:17.053] iteration 10667 : model1 loss : 0.036395 model2 loss : 0.027370
[22:40:17.760] iteration 10668 : model1 loss : 0.032241 model2 loss : 0.030730
[22:40:18.493] iteration 10669 : model1 loss : 0.027079 model2 loss : 0.022814
[22:40:19.175] iteration 10670 : model1 loss : 0.141427 model2 loss : 0.140339
[22:40:19.844] iteration 10671 : model1 loss : 0.019459 model2 loss : 0.021515
[22:40:20.512] iteration 10672 : model1 loss : 0.023273 model2 loss : 0.022247
[22:40:21.227] iteration 10673 : model1 loss : 0.040711 model2 loss : 0.038318
[22:40:22.011] iteration 10674 : model1 loss : 0.017439 model2 loss : 0.018955
[22:40:22.712] iteration 10675 : model1 loss : 0.018960 model2 loss : 0.018716
[22:40:23.412] iteration 10676 : model1 loss : 0.027223 model2 loss : 0.022741
[22:40:24.108] iteration 10677 : model1 loss : 0.026867 model2 loss : 0.027409
[22:40:24.789] iteration 10678 : model1 loss : 0.027518 model2 loss : 0.024052
[22:40:25.477] iteration 10679 : model1 loss : 0.017329 model2 loss : 0.020483
[22:40:26.157] iteration 10680 : model1 loss : 0.024081 model2 loss : 0.024935
[22:40:26.819] iteration 10681 : model1 loss : 0.028423 model2 loss : 0.024952
[22:40:27.488] iteration 10682 : model1 loss : 0.025505 model2 loss : 0.025280
[22:40:28.148] iteration 10683 : model1 loss : 0.026288 model2 loss : 0.026232
[22:40:28.818] iteration 10684 : model1 loss : 0.020452 model2 loss : 0.019949
[22:40:29.492] iteration 10685 : model1 loss : 0.032344 model2 loss : 0.033869
[22:40:30.161] iteration 10686 : model1 loss : 0.031976 model2 loss : 0.028442
[22:40:30.833] iteration 10687 : model1 loss : 0.039786 model2 loss : 0.050283
[22:40:31.513] iteration 10688 : model1 loss : 0.018117 model2 loss : 0.022707
[22:40:32.184] iteration 10689 : model1 loss : 0.079105 model2 loss : 0.060511
[22:40:32.889] iteration 10690 : model1 loss : 0.023148 model2 loss : 0.022693
[22:40:33.596] iteration 10691 : model1 loss : 0.028933 model2 loss : 0.030510
[22:40:34.295] iteration 10692 : model1 loss : 0.022914 model2 loss : 0.022759
[22:40:34.961] iteration 10693 : model1 loss : 0.032979 model2 loss : 0.028797
[22:40:35.678] iteration 10694 : model1 loss : 0.021505 model2 loss : 0.018327
[22:40:36.362] iteration 10695 : model1 loss : 0.024920 model2 loss : 0.024385
[22:40:37.017] iteration 10696 : model1 loss : 0.025171 model2 loss : 0.025443
[22:40:37.683] iteration 10697 : model1 loss : 0.021557 model2 loss : 0.021182
[22:40:38.357] iteration 10698 : model1 loss : 0.020988 model2 loss : 0.021244
[22:40:39.031] iteration 10699 : model1 loss : 0.024057 model2 loss : 0.025195
[22:40:39.706] iteration 10700 : model1 loss : 0.049214 model2 loss : 0.041778
[22:40:40.414] iteration 10701 : model1 loss : 0.023788 model2 loss : 0.023638
[22:40:41.085] iteration 10702 : model1 loss : 0.018715 model2 loss : 0.024359
[22:40:41.751] iteration 10703 : model1 loss : 0.031534 model2 loss : 0.032325
[22:40:42.417] iteration 10704 : model1 loss : 0.021841 model2 loss : 0.020302
[22:40:43.084] iteration 10705 : model1 loss : 0.024547 model2 loss : 0.023721
[22:40:43.748] iteration 10706 : model1 loss : 0.026527 model2 loss : 0.026298
[22:40:44.424] iteration 10707 : model1 loss : 0.024481 model2 loss : 0.026709
[22:40:45.092] iteration 10708 : model1 loss : 0.018370 model2 loss : 0.020759
[22:40:45.767] iteration 10709 : model1 loss : 0.029294 model2 loss : 0.023808
[22:40:46.444] iteration 10710 : model1 loss : 0.042331 model2 loss : 0.031689
[22:40:47.116] iteration 10711 : model1 loss : 0.021737 model2 loss : 0.025493
[22:40:47.781] iteration 10712 : model1 loss : 0.047089 model2 loss : 0.055978
[22:40:48.462] iteration 10713 : model1 loss : 0.032972 model2 loss : 0.021152
[22:40:49.124] iteration 10714 : model1 loss : 0.036368 model2 loss : 0.030373
[22:40:49.777] iteration 10715 : model1 loss : 0.018883 model2 loss : 0.019107
[22:40:50.448] iteration 10716 : model1 loss : 0.031196 model2 loss : 0.030408
[22:40:51.117] iteration 10717 : model1 loss : 0.027697 model2 loss : 0.025250
[22:40:51.802] iteration 10718 : model1 loss : 0.016259 model2 loss : 0.017594
[22:40:52.480] iteration 10719 : model1 loss : 0.023417 model2 loss : 0.025105
[22:40:53.145] iteration 10720 : model1 loss : 0.021637 model2 loss : 0.024154
[22:40:53.810] iteration 10721 : model1 loss : 0.024691 model2 loss : 0.025692
[22:40:54.478] iteration 10722 : model1 loss : 0.020890 model2 loss : 0.021912
[22:40:55.150] iteration 10723 : model1 loss : 0.041509 model2 loss : 0.034901
[22:40:55.821] iteration 10724 : model1 loss : 0.021077 model2 loss : 0.021369
[22:40:56.506] iteration 10725 : model1 loss : 0.041431 model2 loss : 0.037694
[22:40:57.179] iteration 10726 : model1 loss : 0.015472 model2 loss : 0.016853
[22:40:57.848] iteration 10727 : model1 loss : 0.034129 model2 loss : 0.041472
[22:40:58.522] iteration 10728 : model1 loss : 0.017578 model2 loss : 0.017803
[22:40:59.179] iteration 10729 : model1 loss : 0.023770 model2 loss : 0.023367
[22:40:59.839] iteration 10730 : model1 loss : 0.030289 model2 loss : 0.027820
[22:41:00.515] iteration 10731 : model1 loss : 0.021921 model2 loss : 0.021305
[22:41:01.182] iteration 10732 : model1 loss : 0.020238 model2 loss : 0.022838
[22:41:01.851] iteration 10733 : model1 loss : 0.029474 model2 loss : 0.027717
[22:41:02.521] iteration 10734 : model1 loss : 0.023376 model2 loss : 0.023380
[22:41:03.193] iteration 10735 : model1 loss : 0.020354 model2 loss : 0.022613
[22:41:03.861] iteration 10736 : model1 loss : 0.039853 model2 loss : 0.037097
[22:41:04.533] iteration 10737 : model1 loss : 0.024521 model2 loss : 0.023309
[22:41:05.227] iteration 10738 : model1 loss : 0.023576 model2 loss : 0.024551
[22:41:05.908] iteration 10739 : model1 loss : 0.025420 model2 loss : 0.023465
[22:41:06.585] iteration 10740 : model1 loss : 0.025861 model2 loss : 0.025498
[22:41:07.282] iteration 10741 : model1 loss : 0.017695 model2 loss : 0.016287
[22:41:07.952] iteration 10742 : model1 loss : 0.021426 model2 loss : 0.020033
[22:41:08.626] iteration 10743 : model1 loss : 0.027398 model2 loss : 0.029242
[22:41:09.307] iteration 10744 : model1 loss : 0.024995 model2 loss : 0.024081
[22:41:09.975] iteration 10745 : model1 loss : 0.018293 model2 loss : 0.019242
[22:41:10.644] iteration 10746 : model1 loss : 0.018706 model2 loss : 0.017710
[22:41:11.329] iteration 10747 : model1 loss : 0.021728 model2 loss : 0.020092
[22:41:12.008] iteration 10748 : model1 loss : 0.026163 model2 loss : 0.029468
[22:41:12.692] iteration 10749 : model1 loss : 0.029805 model2 loss : 0.024015
[22:41:13.363] iteration 10750 : model1 loss : 0.032680 model2 loss : 0.031989
[22:41:14.073] iteration 10751 : model1 loss : 0.024799 model2 loss : 0.018908
[22:41:14.742] iteration 10752 : model1 loss : 0.034339 model2 loss : 0.032174
[22:41:15.407] iteration 10753 : model1 loss : 0.021471 model2 loss : 0.022260
[22:41:16.098] iteration 10754 : model1 loss : 0.020787 model2 loss : 0.020607
[22:41:16.763] iteration 10755 : model1 loss : 0.026078 model2 loss : 0.029080
[22:41:17.416] iteration 10756 : model1 loss : 0.039974 model2 loss : 0.039610
[22:41:18.088] iteration 10757 : model1 loss : 0.024931 model2 loss : 0.024209
[22:41:18.756] iteration 10758 : model1 loss : 0.021487 model2 loss : 0.022025
[22:41:19.447] iteration 10759 : model1 loss : 0.025618 model2 loss : 0.027903
[22:41:20.116] iteration 10760 : model1 loss : 0.031362 model2 loss : 0.029730
[22:41:20.788] iteration 10761 : model1 loss : 0.026068 model2 loss : 0.023477
[22:41:21.468] iteration 10762 : model1 loss : 0.033175 model2 loss : 0.034123
[22:41:22.126] iteration 10763 : model1 loss : 0.035128 model2 loss : 0.035950
[22:41:22.793] iteration 10764 : model1 loss : 0.026611 model2 loss : 0.022333
[22:41:23.463] iteration 10765 : model1 loss : 0.028466 model2 loss : 0.028356
[22:41:24.121] iteration 10766 : model1 loss : 0.024252 model2 loss : 0.023533
[22:41:24.793] iteration 10767 : model1 loss : 0.024784 model2 loss : 0.029089
[22:41:25.469] iteration 10768 : model1 loss : 0.023573 model2 loss : 0.024450
[22:41:26.132] iteration 10769 : model1 loss : 0.022993 model2 loss : 0.023071
[22:41:26.800] iteration 10770 : model1 loss : 0.021538 model2 loss : 0.021080
[22:41:27.468] iteration 10771 : model1 loss : 0.020780 model2 loss : 0.020216
[22:41:28.140] iteration 10772 : model1 loss : 0.022991 model2 loss : 0.023157
[22:41:28.803] iteration 10773 : model1 loss : 0.020366 model2 loss : 0.020444
[22:41:29.477] iteration 10774 : model1 loss : 0.020595 model2 loss : 0.019539
[22:41:30.148] iteration 10775 : model1 loss : 0.076488 model2 loss : 0.069551
[22:41:30.815] iteration 10776 : model1 loss : 0.030816 model2 loss : 0.031570
[22:41:31.480] iteration 10777 : model1 loss : 0.020487 model2 loss : 0.020559
[22:41:32.148] iteration 10778 : model1 loss : 0.020989 model2 loss : 0.022270
[22:41:32.817] iteration 10779 : model1 loss : 0.024849 model2 loss : 0.039341
[22:41:33.491] iteration 10780 : model1 loss : 0.014859 model2 loss : 0.016407
[22:41:34.165] iteration 10781 : model1 loss : 0.023691 model2 loss : 0.025517
[22:41:34.837] iteration 10782 : model1 loss : 0.024882 model2 loss : 0.021983
[22:41:35.512] iteration 10783 : model1 loss : 0.035348 model2 loss : 0.039187
[22:41:36.178] iteration 10784 : model1 loss : 0.027629 model2 loss : 0.024281
[22:41:36.858] iteration 10785 : model1 loss : 0.019898 model2 loss : 0.021619
[22:41:37.530] iteration 10786 : model1 loss : 0.038316 model2 loss : 0.048530
[22:41:38.201] iteration 10787 : model1 loss : 0.026935 model2 loss : 0.023979
[22:41:38.869] iteration 10788 : model1 loss : 0.025888 model2 loss : 0.022143
[22:41:39.539] iteration 10789 : model1 loss : 0.023759 model2 loss : 0.026121
[22:41:40.206] iteration 10790 : model1 loss : 0.019557 model2 loss : 0.019290
[22:41:40.870] iteration 10791 : model1 loss : 0.024559 model2 loss : 0.022817
[22:41:41.527] iteration 10792 : model1 loss : 0.064084 model2 loss : 0.047083
[22:41:42.175] iteration 10793 : model1 loss : 0.021397 model2 loss : 0.020944
[22:41:42.863] iteration 10794 : model1 loss : 0.026321 model2 loss : 0.027964
[22:41:43.531] iteration 10795 : model1 loss : 0.017838 model2 loss : 0.018294
[22:41:44.193] iteration 10796 : model1 loss : 0.026821 model2 loss : 0.028925
[22:41:44.865] iteration 10797 : model1 loss : 0.025295 model2 loss : 0.033312
[22:41:45.547] iteration 10798 : model1 loss : 0.037108 model2 loss : 0.038726
[22:41:46.223] iteration 10799 : model1 loss : 0.029052 model2 loss : 0.029375
[22:41:46.907] iteration 10800 : model1 loss : 0.025814 model2 loss : 0.026838
[22:42:05.314] iteration 10800 : model1_mean_dice : 0.863451 model1_mean_hd95 : 6.982312
[22:42:24.281] iteration 10800 : model2_mean_dice : 0.869340 model2_mean_hd95 : 6.143720
[22:42:24.969] iteration 10801 : model1 loss : 0.025639 model2 loss : 0.023368
[22:42:25.644] iteration 10802 : model1 loss : 0.018277 model2 loss : 0.019773
[22:42:26.325] iteration 10803 : model1 loss : 0.022992 model2 loss : 0.018557
[22:42:27.010] iteration 10804 : model1 loss : 0.015146 model2 loss : 0.020156
[22:42:27.701] iteration 10805 : model1 loss : 0.021887 model2 loss : 0.021704
[22:42:28.400] iteration 10806 : model1 loss : 0.039503 model2 loss : 0.039524
[22:42:29.104] iteration 10807 : model1 loss : 0.024868 model2 loss : 0.028825
[22:42:29.812] iteration 10808 : model1 loss : 0.037364 model2 loss : 0.030583
[22:42:30.508] iteration 10809 : model1 loss : 0.016619 model2 loss : 0.018292
[22:42:31.198] iteration 10810 : model1 loss : 0.022984 model2 loss : 0.019837
[22:42:31.902] iteration 10811 : model1 loss : 0.024928 model2 loss : 0.024555
[22:42:32.590] iteration 10812 : model1 loss : 0.019970 model2 loss : 0.022944
[22:42:33.256] iteration 10813 : model1 loss : 0.025649 model2 loss : 0.026959
[22:42:33.923] iteration 10814 : model1 loss : 0.023515 model2 loss : 0.024987
[22:42:34.586] iteration 10815 : model1 loss : 0.021587 model2 loss : 0.024352
[22:42:35.249] iteration 10816 : model1 loss : 0.020246 model2 loss : 0.021595
[22:42:35.917] iteration 10817 : model1 loss : 0.022475 model2 loss : 0.019333
[22:42:36.573] iteration 10818 : model1 loss : 0.026857 model2 loss : 0.025285
[22:42:37.242] iteration 10819 : model1 loss : 0.028190 model2 loss : 0.032927
[22:42:37.908] iteration 10820 : model1 loss : 0.024192 model2 loss : 0.024765
[22:42:38.579] iteration 10821 : model1 loss : 0.016940 model2 loss : 0.017189
[22:42:39.239] iteration 10822 : model1 loss : 0.044734 model2 loss : 0.027666
[22:42:39.901] iteration 10823 : model1 loss : 0.021588 model2 loss : 0.028453
[22:42:40.569] iteration 10824 : model1 loss : 0.034663 model2 loss : 0.046549
[22:42:41.243] iteration 10825 : model1 loss : 0.025228 model2 loss : 0.024843
[22:42:41.905] iteration 10826 : model1 loss : 0.021836 model2 loss : 0.019764
[22:42:42.572] iteration 10827 : model1 loss : 0.021721 model2 loss : 0.022510
[22:42:43.243] iteration 10828 : model1 loss : 0.020753 model2 loss : 0.016865
[22:42:43.900] iteration 10829 : model1 loss : 0.026638 model2 loss : 0.033176
[22:42:44.566] iteration 10830 : model1 loss : 0.022964 model2 loss : 0.024339
[22:42:45.230] iteration 10831 : model1 loss : 0.066196 model2 loss : 0.038410
[22:42:45.901] iteration 10832 : model1 loss : 0.027276 model2 loss : 0.026697
[22:42:46.564] iteration 10833 : model1 loss : 0.042382 model2 loss : 0.032593
[22:42:47.228] iteration 10834 : model1 loss : 0.025752 model2 loss : 0.026753
[22:42:47.888] iteration 10835 : model1 loss : 0.022073 model2 loss : 0.024643
[22:42:48.581] iteration 10836 : model1 loss : 0.023065 model2 loss : 0.028391
[22:42:49.260] iteration 10837 : model1 loss : 0.031552 model2 loss : 0.030023
[22:42:49.914] iteration 10838 : model1 loss : 0.063055 model2 loss : 0.052467
[22:42:50.580] iteration 10839 : model1 loss : 0.030092 model2 loss : 0.028829
[22:42:51.257] iteration 10840 : model1 loss : 0.031557 model2 loss : 0.021885
[22:42:51.913] iteration 10841 : model1 loss : 0.033909 model2 loss : 0.026209
[22:42:52.589] iteration 10842 : model1 loss : 0.017235 model2 loss : 0.018252
[22:42:53.276] iteration 10843 : model1 loss : 0.019899 model2 loss : 0.020541
[22:42:53.951] iteration 10844 : model1 loss : 0.033436 model2 loss : 0.034380
[22:42:54.627] iteration 10845 : model1 loss : 0.051175 model2 loss : 0.061170
[22:42:55.302] iteration 10846 : model1 loss : 0.026596 model2 loss : 0.026380
[22:42:55.983] iteration 10847 : model1 loss : 0.017366 model2 loss : 0.018829
[22:42:56.665] iteration 10848 : model1 loss : 0.023402 model2 loss : 0.022533
[22:42:57.347] iteration 10849 : model1 loss : 0.027570 model2 loss : 0.027671
[22:42:58.024] iteration 10850 : model1 loss : 0.024993 model2 loss : 0.023698
[22:42:58.752] iteration 10851 : model1 loss : 0.022029 model2 loss : 0.022408
[22:42:59.428] iteration 10852 : model1 loss : 0.033008 model2 loss : 0.033540
[22:43:00.108] iteration 10853 : model1 loss : 0.022469 model2 loss : 0.022328
[22:43:00.784] iteration 10854 : model1 loss : 0.022362 model2 loss : 0.021236
[22:43:01.459] iteration 10855 : model1 loss : 0.046735 model2 loss : 0.048610
[22:43:02.128] iteration 10856 : model1 loss : 0.025976 model2 loss : 0.031981
[22:43:02.789] iteration 10857 : model1 loss : 0.032419 model2 loss : 0.032176
[22:43:03.458] iteration 10858 : model1 loss : 0.034078 model2 loss : 0.033187
[22:43:04.126] iteration 10859 : model1 loss : 0.019560 model2 loss : 0.020175
[22:43:04.790] iteration 10860 : model1 loss : 0.017185 model2 loss : 0.016980
[22:43:05.463] iteration 10861 : model1 loss : 0.037934 model2 loss : 0.025548
[22:43:06.142] iteration 10862 : model1 loss : 0.022228 model2 loss : 0.022749
[22:43:06.819] iteration 10863 : model1 loss : 0.022597 model2 loss : 0.027899
[22:43:07.486] iteration 10864 : model1 loss : 0.020628 model2 loss : 0.021329
[22:43:08.163] iteration 10865 : model1 loss : 0.023566 model2 loss : 0.025263
[22:43:08.834] iteration 10866 : model1 loss : 0.030217 model2 loss : 0.031536
[22:43:09.505] iteration 10867 : model1 loss : 0.025142 model2 loss : 0.021669
[22:43:10.179] iteration 10868 : model1 loss : 0.023777 model2 loss : 0.027968
[22:43:10.866] iteration 10869 : model1 loss : 0.021596 model2 loss : 0.022992
[22:43:11.543] iteration 10870 : model1 loss : 0.020390 model2 loss : 0.022081
[22:43:12.252] iteration 10871 : model1 loss : 0.018927 model2 loss : 0.019720
[22:43:12.928] iteration 10872 : model1 loss : 0.020094 model2 loss : 0.021334
[22:43:13.594] iteration 10873 : model1 loss : 0.020195 model2 loss : 0.019504
[22:43:14.275] iteration 10874 : model1 loss : 0.033642 model2 loss : 0.039136
[22:43:14.949] iteration 10875 : model1 loss : 0.018476 model2 loss : 0.018953
[22:43:15.624] iteration 10876 : model1 loss : 0.030935 model2 loss : 0.030039
[22:43:16.294] iteration 10877 : model1 loss : 0.025116 model2 loss : 0.023245
[22:43:16.968] iteration 10878 : model1 loss : 0.021398 model2 loss : 0.021522
[22:43:17.636] iteration 10879 : model1 loss : 0.023950 model2 loss : 0.023668
[22:43:18.310] iteration 10880 : model1 loss : 0.020674 model2 loss : 0.021115
[22:43:18.980] iteration 10881 : model1 loss : 0.025504 model2 loss : 0.023030
[22:43:19.649] iteration 10882 : model1 loss : 0.022744 model2 loss : 0.023988
[22:43:20.325] iteration 10883 : model1 loss : 0.039830 model2 loss : 0.036543
[22:43:21.008] iteration 10884 : model1 loss : 0.024760 model2 loss : 0.025595
[22:43:21.675] iteration 10885 : model1 loss : 0.072762 model2 loss : 0.080419
[22:43:22.350] iteration 10886 : model1 loss : 0.021838 model2 loss : 0.019265
[22:43:23.021] iteration 10887 : model1 loss : 0.022081 model2 loss : 0.022438
[22:43:23.690] iteration 10888 : model1 loss : 0.024545 model2 loss : 0.024991
[22:43:24.359] iteration 10889 : model1 loss : 0.022389 model2 loss : 0.021203
[22:43:25.017] iteration 10890 : model1 loss : 0.022779 model2 loss : 0.023920
[22:43:25.677] iteration 10891 : model1 loss : 0.022742 model2 loss : 0.021291
[22:43:26.366] iteration 10892 : model1 loss : 0.036827 model2 loss : 0.038941
[22:43:27.031] iteration 10893 : model1 loss : 0.022313 model2 loss : 0.018302
[22:43:27.699] iteration 10894 : model1 loss : 0.023106 model2 loss : 0.024383
[22:43:28.383] iteration 10895 : model1 loss : 0.018275 model2 loss : 0.018459
[22:43:29.116] iteration 10896 : model1 loss : 0.045607 model2 loss : 0.045211
[22:43:29.890] iteration 10897 : model1 loss : 0.018890 model2 loss : 0.021101
[22:43:30.616] iteration 10898 : model1 loss : 0.022839 model2 loss : 0.018973
[22:43:31.549] iteration 10899 : model1 loss : 0.028878 model2 loss : 0.028966
[22:43:32.285] iteration 10900 : model1 loss : 0.024564 model2 loss : 0.022900
[22:43:33.027] iteration 10901 : model1 loss : 0.033831 model2 loss : 0.035385
[22:43:33.707] iteration 10902 : model1 loss : 0.022229 model2 loss : 0.019896
[22:43:34.414] iteration 10903 : model1 loss : 0.021122 model2 loss : 0.021037
[22:43:35.108] iteration 10904 : model1 loss : 0.023709 model2 loss : 0.024465
[22:43:35.813] iteration 10905 : model1 loss : 0.022912 model2 loss : 0.021792
[22:43:36.502] iteration 10906 : model1 loss : 0.028677 model2 loss : 0.026191
[22:43:37.190] iteration 10907 : model1 loss : 0.041726 model2 loss : 0.053894
[22:43:37.886] iteration 10908 : model1 loss : 0.019674 model2 loss : 0.024058
[22:43:38.578] iteration 10909 : model1 loss : 0.043497 model2 loss : 0.029137
[22:43:39.273] iteration 10910 : model1 loss : 0.020071 model2 loss : 0.019520
[22:43:39.964] iteration 10911 : model1 loss : 0.029487 model2 loss : 0.027113
[22:43:40.665] iteration 10912 : model1 loss : 0.054530 model2 loss : 0.050371
[22:43:41.368] iteration 10913 : model1 loss : 0.024310 model2 loss : 0.024563
[22:43:42.067] iteration 10914 : model1 loss : 0.025107 model2 loss : 0.026986
[22:43:42.752] iteration 10915 : model1 loss : 0.029632 model2 loss : 0.049543
[22:43:43.445] iteration 10916 : model1 loss : 0.015760 model2 loss : 0.015925
[22:43:44.119] iteration 10917 : model1 loss : 0.028598 model2 loss : 0.029399
[22:43:44.811] iteration 10918 : model1 loss : 0.018373 model2 loss : 0.019078
[22:43:45.471] iteration 10919 : model1 loss : 0.021902 model2 loss : 0.023020
[22:43:46.137] iteration 10920 : model1 loss : 0.029121 model2 loss : 0.035679
[22:43:46.809] iteration 10921 : model1 loss : 0.026865 model2 loss : 0.026867
[22:43:47.493] iteration 10922 : model1 loss : 0.023216 model2 loss : 0.021559
[22:43:48.162] iteration 10923 : model1 loss : 0.020307 model2 loss : 0.020391
[22:43:48.837] iteration 10924 : model1 loss : 0.021608 model2 loss : 0.021479
[22:43:49.536] iteration 10925 : model1 loss : 0.017595 model2 loss : 0.019415
[22:43:50.228] iteration 10926 : model1 loss : 0.027265 model2 loss : 0.023758
[22:43:50.901] iteration 10927 : model1 loss : 0.018736 model2 loss : 0.020106
[22:43:51.583] iteration 10928 : model1 loss : 0.017010 model2 loss : 0.017731
[22:43:52.272] iteration 10929 : model1 loss : 0.021789 model2 loss : 0.022572
[22:43:52.968] iteration 10930 : model1 loss : 0.020153 model2 loss : 0.019607
[22:43:53.659] iteration 10931 : model1 loss : 0.072072 model2 loss : 0.079816
[22:43:54.356] iteration 10932 : model1 loss : 0.022914 model2 loss : 0.028238
[22:43:55.056] iteration 10933 : model1 loss : 0.015995 model2 loss : 0.018300
[22:43:55.746] iteration 10934 : model1 loss : 0.019265 model2 loss : 0.019214
[22:43:56.430] iteration 10935 : model1 loss : 0.024454 model2 loss : 0.024765
[22:43:57.139] iteration 10936 : model1 loss : 0.037625 model2 loss : 0.038337
[22:43:57.810] iteration 10937 : model1 loss : 0.020124 model2 loss : 0.022100
[22:43:58.487] iteration 10938 : model1 loss : 0.018252 model2 loss : 0.019545
[22:43:59.148] iteration 10939 : model1 loss : 0.022694 model2 loss : 0.022636
[22:43:59.809] iteration 10940 : model1 loss : 0.020041 model2 loss : 0.018876
[22:44:00.494] iteration 10941 : model1 loss : 0.055681 model2 loss : 0.038971
[22:44:01.166] iteration 10942 : model1 loss : 0.019799 model2 loss : 0.020287
[22:44:01.839] iteration 10943 : model1 loss : 0.023427 model2 loss : 0.020610
[22:44:02.520] iteration 10944 : model1 loss : 0.029819 model2 loss : 0.027505
[22:44:03.187] iteration 10945 : model1 loss : 0.024354 model2 loss : 0.025114
[22:44:03.852] iteration 10946 : model1 loss : 0.020294 model2 loss : 0.020242
[22:44:04.519] iteration 10947 : model1 loss : 0.023398 model2 loss : 0.025432
[22:44:05.187] iteration 10948 : model1 loss : 0.020925 model2 loss : 0.022358
[22:44:05.869] iteration 10949 : model1 loss : 0.146712 model2 loss : 0.148403
[22:44:06.543] iteration 10950 : model1 loss : 0.020602 model2 loss : 0.018125
[22:44:07.256] iteration 10951 : model1 loss : 0.044060 model2 loss : 0.039340
[22:44:07.918] iteration 10952 : model1 loss : 0.022737 model2 loss : 0.021090
[22:44:08.613] iteration 10953 : model1 loss : 0.030772 model2 loss : 0.026946
[22:44:09.276] iteration 10954 : model1 loss : 0.031178 model2 loss : 0.032643
[22:44:09.945] iteration 10955 : model1 loss : 0.029144 model2 loss : 0.025294
[22:44:10.624] iteration 10956 : model1 loss : 0.030684 model2 loss : 0.027683
[22:44:11.301] iteration 10957 : model1 loss : 0.019092 model2 loss : 0.020956
[22:44:11.972] iteration 10958 : model1 loss : 0.027141 model2 loss : 0.027053
[22:44:12.687] iteration 10959 : model1 loss : 0.041804 model2 loss : 0.046767
[22:44:13.363] iteration 10960 : model1 loss : 0.028125 model2 loss : 0.029609
[22:44:14.053] iteration 10961 : model1 loss : 0.025122 model2 loss : 0.026456
[22:44:14.717] iteration 10962 : model1 loss : 0.023646 model2 loss : 0.021687
[22:44:15.377] iteration 10963 : model1 loss : 0.021608 model2 loss : 0.021695
[22:44:16.060] iteration 10964 : model1 loss : 0.022666 model2 loss : 0.021476
[22:44:16.728] iteration 10965 : model1 loss : 0.022302 model2 loss : 0.019416
[22:44:17.396] iteration 10966 : model1 loss : 0.021904 model2 loss : 0.023570
[22:44:18.062] iteration 10967 : model1 loss : 0.021277 model2 loss : 0.023074
[22:44:18.755] iteration 10968 : model1 loss : 0.019161 model2 loss : 0.023007
[22:44:19.430] iteration 10969 : model1 loss : 0.021142 model2 loss : 0.020641
[22:44:20.114] iteration 10970 : model1 loss : 0.025299 model2 loss : 0.026627
[22:44:20.777] iteration 10971 : model1 loss : 0.025907 model2 loss : 0.024736
[22:44:21.448] iteration 10972 : model1 loss : 0.021643 model2 loss : 0.020007
[22:44:22.118] iteration 10973 : model1 loss : 0.059556 model2 loss : 0.055636
[22:44:22.787] iteration 10974 : model1 loss : 0.019623 model2 loss : 0.019141
[22:44:23.450] iteration 10975 : model1 loss : 0.024586 model2 loss : 0.023757
[22:44:24.114] iteration 10976 : model1 loss : 0.023463 model2 loss : 0.021718
[22:44:24.772] iteration 10977 : model1 loss : 0.026569 model2 loss : 0.024717
[22:44:25.441] iteration 10978 : model1 loss : 0.014611 model2 loss : 0.016974
[22:44:26.115] iteration 10979 : model1 loss : 0.025305 model2 loss : 0.022939
[22:44:26.795] iteration 10980 : model1 loss : 0.021036 model2 loss : 0.021165
[22:44:27.457] iteration 10981 : model1 loss : 0.029386 model2 loss : 0.029151
[22:44:28.112] iteration 10982 : model1 loss : 0.019079 model2 loss : 0.020316
[22:44:28.790] iteration 10983 : model1 loss : 0.031578 model2 loss : 0.033866
[22:44:29.492] iteration 10984 : model1 loss : 0.030364 model2 loss : 0.029282
[22:44:30.163] iteration 10985 : model1 loss : 0.025483 model2 loss : 0.025489
[22:44:30.830] iteration 10986 : model1 loss : 0.030556 model2 loss : 0.032087
[22:44:31.504] iteration 10987 : model1 loss : 0.034688 model2 loss : 0.029571
[22:44:32.172] iteration 10988 : model1 loss : 0.027100 model2 loss : 0.025362
[22:44:32.850] iteration 10989 : model1 loss : 0.149623 model2 loss : 0.141882
[22:44:33.523] iteration 10990 : model1 loss : 0.025197 model2 loss : 0.025897
[22:44:34.178] iteration 10991 : model1 loss : 0.020730 model2 loss : 0.024933
[22:44:34.846] iteration 10992 : model1 loss : 0.046461 model2 loss : 0.046149
[22:44:35.535] iteration 10993 : model1 loss : 0.023970 model2 loss : 0.025269
[22:44:36.198] iteration 10994 : model1 loss : 0.025379 model2 loss : 0.027678
[22:44:36.879] iteration 10995 : model1 loss : 0.022264 model2 loss : 0.024019
[22:44:37.562] iteration 10996 : model1 loss : 0.018950 model2 loss : 0.019011
[22:44:38.237] iteration 10997 : model1 loss : 0.021785 model2 loss : 0.033788
[22:44:38.922] iteration 10998 : model1 loss : 0.022665 model2 loss : 0.023045
[22:44:39.591] iteration 10999 : model1 loss : 0.027371 model2 loss : 0.032020
[22:44:40.287] iteration 11000 : model1 loss : 0.024184 model2 loss : 0.021296
[22:44:58.866] iteration 11000 : model1_mean_dice : 0.846665 model1_mean_hd95 : 6.693789
[22:45:17.649] iteration 11000 : model2_mean_dice : 0.856793 model2_mean_hd95 : 4.477530
[22:45:18.340] iteration 11001 : model1 loss : 0.020484 model2 loss : 0.021693
[22:45:19.006] iteration 11002 : model1 loss : 0.022275 model2 loss : 0.021463
[22:45:19.678] iteration 11003 : model1 loss : 0.035600 model2 loss : 0.029169
[22:45:20.356] iteration 11004 : model1 loss : 0.021137 model2 loss : 0.022079
[22:45:21.013] iteration 11005 : model1 loss : 0.028149 model2 loss : 0.027940
[22:45:21.675] iteration 11006 : model1 loss : 0.022452 model2 loss : 0.021331
[22:45:22.347] iteration 11007 : model1 loss : 0.025509 model2 loss : 0.024164
[22:45:23.021] iteration 11008 : model1 loss : 0.028395 model2 loss : 0.026845
[22:45:23.678] iteration 11009 : model1 loss : 0.021025 model2 loss : 0.020410
[22:45:24.350] iteration 11010 : model1 loss : 0.024290 model2 loss : 0.023372
[22:45:25.018] iteration 11011 : model1 loss : 0.104935 model2 loss : 0.087101
[22:45:25.676] iteration 11012 : model1 loss : 0.022509 model2 loss : 0.023051
[22:45:26.346] iteration 11013 : model1 loss : 0.028508 model2 loss : 0.027603
[22:45:27.011] iteration 11014 : model1 loss : 0.026718 model2 loss : 0.023865
[22:45:27.682] iteration 11015 : model1 loss : 0.030471 model2 loss : 0.022500
[22:45:28.351] iteration 11016 : model1 loss : 0.029264 model2 loss : 0.028457
[22:45:29.021] iteration 11017 : model1 loss : 0.020265 model2 loss : 0.020284
[22:45:29.680] iteration 11018 : model1 loss : 0.022239 model2 loss : 0.021380
[22:45:30.360] iteration 11019 : model1 loss : 0.038519 model2 loss : 0.047785
[22:45:31.035] iteration 11020 : model1 loss : 0.030038 model2 loss : 0.018984
[22:45:31.709] iteration 11021 : model1 loss : 0.044794 model2 loss : 0.032892
[22:45:32.388] iteration 11022 : model1 loss : 0.021897 model2 loss : 0.019735
[22:45:33.055] iteration 11023 : model1 loss : 0.033232 model2 loss : 0.019823
[22:45:33.721] iteration 11024 : model1 loss : 0.024569 model2 loss : 0.026895
[22:45:34.397] iteration 11025 : model1 loss : 0.024186 model2 loss : 0.024018
[22:45:35.057] iteration 11026 : model1 loss : 0.023352 model2 loss : 0.021308
[22:45:35.727] iteration 11027 : model1 loss : 0.027966 model2 loss : 0.031408
[22:45:36.400] iteration 11028 : model1 loss : 0.025107 model2 loss : 0.025140
[22:45:37.065] iteration 11029 : model1 loss : 0.031176 model2 loss : 0.040793
[22:45:37.735] iteration 11030 : model1 loss : 0.026975 model2 loss : 0.019721
[22:45:38.413] iteration 11031 : model1 loss : 0.028582 model2 loss : 0.026205
[22:45:39.089] iteration 11032 : model1 loss : 0.024654 model2 loss : 0.023475
[22:45:39.752] iteration 11033 : model1 loss : 0.026595 model2 loss : 0.021674
[22:45:40.432] iteration 11034 : model1 loss : 0.028454 model2 loss : 0.026595
[22:45:41.108] iteration 11035 : model1 loss : 0.023379 model2 loss : 0.024097
[22:45:41.804] iteration 11036 : model1 loss : 0.025195 model2 loss : 0.028626
[22:45:42.528] iteration 11037 : model1 loss : 0.031830 model2 loss : 0.026777
[22:45:43.214] iteration 11038 : model1 loss : 0.020997 model2 loss : 0.019513
[22:45:43.897] iteration 11039 : model1 loss : 0.026229 model2 loss : 0.023303
[22:45:44.570] iteration 11040 : model1 loss : 0.032680 model2 loss : 0.028966
[22:45:45.256] iteration 11041 : model1 loss : 0.023342 model2 loss : 0.021724
[22:45:45.981] iteration 11042 : model1 loss : 0.025250 model2 loss : 0.024671
[22:45:46.638] iteration 11043 : model1 loss : 0.025147 model2 loss : 0.022614
[22:45:47.329] iteration 11044 : model1 loss : 0.048943 model2 loss : 0.052858
[22:45:48.028] iteration 11045 : model1 loss : 0.020365 model2 loss : 0.021874
[22:45:48.714] iteration 11046 : model1 loss : 0.021518 model2 loss : 0.020492
[22:45:49.418] iteration 11047 : model1 loss : 0.045429 model2 loss : 0.036251
[22:45:50.113] iteration 11048 : model1 loss : 0.022931 model2 loss : 0.022791
[22:45:50.798] iteration 11049 : model1 loss : 0.041801 model2 loss : 0.042799
[22:45:51.507] iteration 11050 : model1 loss : 0.018311 model2 loss : 0.017616
[22:45:52.286] iteration 11051 : model1 loss : 0.021708 model2 loss : 0.023720
[22:45:52.987] iteration 11052 : model1 loss : 0.024555 model2 loss : 0.023273
[22:45:53.698] iteration 11053 : model1 loss : 0.023293 model2 loss : 0.019784
[22:45:54.381] iteration 11054 : model1 loss : 0.036135 model2 loss : 0.037692
[22:45:55.080] iteration 11055 : model1 loss : 0.025681 model2 loss : 0.024668
[22:45:55.774] iteration 11056 : model1 loss : 0.028470 model2 loss : 0.027291
[22:45:56.478] iteration 11057 : model1 loss : 0.082003 model2 loss : 0.046125
[22:45:57.200] iteration 11058 : model1 loss : 0.024545 model2 loss : 0.023753
[22:45:57.911] iteration 11059 : model1 loss : 0.028854 model2 loss : 0.030816
[22:45:58.625] iteration 11060 : model1 loss : 0.032490 model2 loss : 0.024530
[22:45:59.322] iteration 11061 : model1 loss : 0.020903 model2 loss : 0.019318
[22:46:00.016] iteration 11062 : model1 loss : 0.032091 model2 loss : 0.031501
[22:46:00.727] iteration 11063 : model1 loss : 0.027310 model2 loss : 0.024641
[22:46:01.445] iteration 11064 : model1 loss : 0.036321 model2 loss : 0.025103
[22:46:02.133] iteration 11065 : model1 loss : 0.025233 model2 loss : 0.022188
[22:46:02.846] iteration 11066 : model1 loss : 0.038144 model2 loss : 0.033545
[22:46:03.547] iteration 11067 : model1 loss : 0.035076 model2 loss : 0.026724
[22:46:04.250] iteration 11068 : model1 loss : 0.021718 model2 loss : 0.021045
[22:46:04.968] iteration 11069 : model1 loss : 0.023547 model2 loss : 0.023134
[22:46:05.657] iteration 11070 : model1 loss : 0.046903 model2 loss : 0.025347
[22:46:06.350] iteration 11071 : model1 loss : 0.026973 model2 loss : 0.028202
[22:46:07.032] iteration 11072 : model1 loss : 0.024557 model2 loss : 0.028336
[22:46:07.728] iteration 11073 : model1 loss : 0.031817 model2 loss : 0.026464
[22:46:08.420] iteration 11074 : model1 loss : 0.028830 model2 loss : 0.029324
[22:46:09.084] iteration 11075 : model1 loss : 0.046148 model2 loss : 0.023170
[22:46:09.755] iteration 11076 : model1 loss : 0.031220 model2 loss : 0.036031
[22:46:10.425] iteration 11077 : model1 loss : 0.026220 model2 loss : 0.028586
[22:46:11.099] iteration 11078 : model1 loss : 0.019522 model2 loss : 0.021466
[22:46:11.770] iteration 11079 : model1 loss : 0.024580 model2 loss : 0.019195
[22:46:12.457] iteration 11080 : model1 loss : 0.027491 model2 loss : 0.027043
[22:46:13.140] iteration 11081 : model1 loss : 0.034813 model2 loss : 0.023284
[22:46:13.832] iteration 11082 : model1 loss : 0.022387 model2 loss : 0.020444
[22:46:14.498] iteration 11083 : model1 loss : 0.019723 model2 loss : 0.021055
[22:46:15.163] iteration 11084 : model1 loss : 0.018020 model2 loss : 0.017617
[22:46:15.825] iteration 11085 : model1 loss : 0.024414 model2 loss : 0.026334
[22:46:16.492] iteration 11086 : model1 loss : 0.024428 model2 loss : 0.019653
[22:46:17.169] iteration 11087 : model1 loss : 0.038856 model2 loss : 0.034430
[22:46:17.835] iteration 11088 : model1 loss : 0.024788 model2 loss : 0.021868
[22:46:18.513] iteration 11089 : model1 loss : 0.027648 model2 loss : 0.027246
[22:46:19.180] iteration 11090 : model1 loss : 0.022018 model2 loss : 0.021749
[22:46:19.867] iteration 11091 : model1 loss : 0.023276 model2 loss : 0.018857
[22:46:20.546] iteration 11092 : model1 loss : 0.036273 model2 loss : 0.035116
[22:46:21.212] iteration 11093 : model1 loss : 0.022295 model2 loss : 0.023401
[22:46:21.871] iteration 11094 : model1 loss : 0.022593 model2 loss : 0.021909
[22:46:22.550] iteration 11095 : model1 loss : 0.029675 model2 loss : 0.029985
[22:46:23.210] iteration 11096 : model1 loss : 0.025823 model2 loss : 0.021866
[22:46:23.879] iteration 11097 : model1 loss : 0.023329 model2 loss : 0.020572
[22:46:24.553] iteration 11098 : model1 loss : 0.045088 model2 loss : 0.039950
[22:46:25.216] iteration 11099 : model1 loss : 0.021361 model2 loss : 0.025380
[22:46:25.898] iteration 11100 : model1 loss : 0.020098 model2 loss : 0.019491
[22:46:26.604] iteration 11101 : model1 loss : 0.029081 model2 loss : 0.026664
[22:46:27.277] iteration 11102 : model1 loss : 0.027532 model2 loss : 0.019987
[22:46:27.943] iteration 11103 : model1 loss : 0.075268 model2 loss : 0.042324
[22:46:28.611] iteration 11104 : model1 loss : 0.040773 model2 loss : 0.033589
[22:46:29.290] iteration 11105 : model1 loss : 0.040029 model2 loss : 0.035692
[22:46:29.964] iteration 11106 : model1 loss : 0.021121 model2 loss : 0.020383
[22:46:30.630] iteration 11107 : model1 loss : 0.020751 model2 loss : 0.020611
[22:46:31.308] iteration 11108 : model1 loss : 0.026948 model2 loss : 0.024739
[22:46:31.994] iteration 11109 : model1 loss : 0.026747 model2 loss : 0.021563
[22:46:32.678] iteration 11110 : model1 loss : 0.031057 model2 loss : 0.025816
[22:46:33.350] iteration 11111 : model1 loss : 0.028827 model2 loss : 0.037647
[22:46:34.018] iteration 11112 : model1 loss : 0.030081 model2 loss : 0.025563
[22:46:34.689] iteration 11113 : model1 loss : 0.045807 model2 loss : 0.042871
[22:46:35.352] iteration 11114 : model1 loss : 0.018264 model2 loss : 0.019236
[22:46:36.020] iteration 11115 : model1 loss : 0.035935 model2 loss : 0.024851
[22:46:36.690] iteration 11116 : model1 loss : 0.044916 model2 loss : 0.033254
[22:46:37.366] iteration 11117 : model1 loss : 0.030974 model2 loss : 0.024540
[22:46:38.047] iteration 11118 : model1 loss : 0.024926 model2 loss : 0.026105
[22:46:38.724] iteration 11119 : model1 loss : 0.026287 model2 loss : 0.024901
[22:46:39.392] iteration 11120 : model1 loss : 0.024177 model2 loss : 0.022769
[22:46:40.053] iteration 11121 : model1 loss : 0.024457 model2 loss : 0.024340
[22:46:40.726] iteration 11122 : model1 loss : 0.026063 model2 loss : 0.029779
[22:46:41.410] iteration 11123 : model1 loss : 0.022923 model2 loss : 0.025338
[22:46:42.078] iteration 11124 : model1 loss : 0.024196 model2 loss : 0.022105
[22:46:42.780] iteration 11125 : model1 loss : 0.033892 model2 loss : 0.036479
[22:46:43.452] iteration 11126 : model1 loss : 0.023374 model2 loss : 0.018216
[22:46:44.115] iteration 11127 : model1 loss : 0.020095 model2 loss : 0.025618
[22:46:44.788] iteration 11128 : model1 loss : 0.025622 model2 loss : 0.023378
[22:46:45.462] iteration 11129 : model1 loss : 0.020194 model2 loss : 0.019048
[22:46:46.140] iteration 11130 : model1 loss : 0.023025 model2 loss : 0.023035
[22:46:46.814] iteration 11131 : model1 loss : 0.024582 model2 loss : 0.023083
[22:46:47.480] iteration 11132 : model1 loss : 0.023323 model2 loss : 0.021487
[22:46:48.151] iteration 11133 : model1 loss : 0.019816 model2 loss : 0.017413
[22:46:48.820] iteration 11134 : model1 loss : 0.030517 model2 loss : 0.024872
[22:46:49.509] iteration 11135 : model1 loss : 0.026544 model2 loss : 0.029630
[22:46:50.180] iteration 11136 : model1 loss : 0.021435 model2 loss : 0.019797
[22:46:50.837] iteration 11137 : model1 loss : 0.024287 model2 loss : 0.024367
[22:46:51.507] iteration 11138 : model1 loss : 0.016916 model2 loss : 0.020282
[22:46:52.195] iteration 11139 : model1 loss : 0.031450 model2 loss : 0.025671
[22:46:52.867] iteration 11140 : model1 loss : 0.021268 model2 loss : 0.021807
[22:46:53.543] iteration 11141 : model1 loss : 0.037026 model2 loss : 0.031676
[22:46:54.217] iteration 11142 : model1 loss : 0.025470 model2 loss : 0.027661
[22:46:54.907] iteration 11143 : model1 loss : 0.026817 model2 loss : 0.026728
[22:46:55.582] iteration 11144 : model1 loss : 0.024650 model2 loss : 0.024397
[22:46:56.262] iteration 11145 : model1 loss : 0.051576 model2 loss : 0.026361
[22:46:56.950] iteration 11146 : model1 loss : 0.028806 model2 loss : 0.031254
[22:46:57.639] iteration 11147 : model1 loss : 0.042760 model2 loss : 0.038091
[22:46:58.324] iteration 11148 : model1 loss : 0.017609 model2 loss : 0.016254
[22:46:59.045] iteration 11149 : model1 loss : 0.022520 model2 loss : 0.021285
[22:46:59.755] iteration 11150 : model1 loss : 0.023523 model2 loss : 0.019464
[22:47:00.489] iteration 11151 : model1 loss : 0.020154 model2 loss : 0.019823
[22:47:01.160] iteration 11152 : model1 loss : 0.142708 model2 loss : 0.144673
[22:47:01.836] iteration 11153 : model1 loss : 0.021090 model2 loss : 0.019834
[22:47:02.512] iteration 11154 : model1 loss : 0.021115 model2 loss : 0.021024
[22:47:03.176] iteration 11155 : model1 loss : 0.026595 model2 loss : 0.025049
[22:47:03.839] iteration 11156 : model1 loss : 0.022415 model2 loss : 0.024645
[22:47:04.511] iteration 11157 : model1 loss : 0.025813 model2 loss : 0.023143
[22:47:05.174] iteration 11158 : model1 loss : 0.021313 model2 loss : 0.021127
[22:47:05.847] iteration 11159 : model1 loss : 0.022286 model2 loss : 0.021561
[22:47:06.511] iteration 11160 : model1 loss : 0.031369 model2 loss : 0.026111
[22:47:07.180] iteration 11161 : model1 loss : 0.071521 model2 loss : 0.064316
[22:47:07.871] iteration 11162 : model1 loss : 0.018869 model2 loss : 0.018134
[22:47:08.555] iteration 11163 : model1 loss : 0.024559 model2 loss : 0.028450
[22:47:09.225] iteration 11164 : model1 loss : 0.024929 model2 loss : 0.021275
[22:47:09.896] iteration 11165 : model1 loss : 0.025161 model2 loss : 0.026580
[22:47:10.570] iteration 11166 : model1 loss : 0.022976 model2 loss : 0.022329
[22:47:11.250] iteration 11167 : model1 loss : 0.026335 model2 loss : 0.023494
[22:47:11.920] iteration 11168 : model1 loss : 0.024981 model2 loss : 0.026503
[22:47:12.598] iteration 11169 : model1 loss : 0.023216 model2 loss : 0.022644
[22:47:13.281] iteration 11170 : model1 loss : 0.034982 model2 loss : 0.026380
[22:47:13.976] iteration 11171 : model1 loss : 0.037001 model2 loss : 0.037470
[22:47:14.646] iteration 11172 : model1 loss : 0.024961 model2 loss : 0.025654
[22:47:15.321] iteration 11173 : model1 loss : 0.021300 model2 loss : 0.021732
[22:47:15.994] iteration 11174 : model1 loss : 0.025086 model2 loss : 0.023828
[22:47:16.674] iteration 11175 : model1 loss : 0.020757 model2 loss : 0.020898
[22:47:17.338] iteration 11176 : model1 loss : 0.018018 model2 loss : 0.017170
[22:47:17.999] iteration 11177 : model1 loss : 0.020048 model2 loss : 0.019779
[22:47:18.680] iteration 11178 : model1 loss : 0.018987 model2 loss : 0.019609
[22:47:19.349] iteration 11179 : model1 loss : 0.032476 model2 loss : 0.023991
[22:47:20.028] iteration 11180 : model1 loss : 0.020612 model2 loss : 0.027019
[22:47:20.705] iteration 11181 : model1 loss : 0.017263 model2 loss : 0.019089
[22:47:21.365] iteration 11182 : model1 loss : 0.026662 model2 loss : 0.024642
[22:47:22.029] iteration 11183 : model1 loss : 0.028493 model2 loss : 0.025473
[22:47:22.707] iteration 11184 : model1 loss : 0.028560 model2 loss : 0.027680
[22:47:23.396] iteration 11185 : model1 loss : 0.024352 model2 loss : 0.022196
[22:47:24.079] iteration 11186 : model1 loss : 0.035129 model2 loss : 0.036521
[22:47:24.749] iteration 11187 : model1 loss : 0.026445 model2 loss : 0.023770
[22:47:25.440] iteration 11188 : model1 loss : 0.060345 model2 loss : 0.053631
[22:47:26.102] iteration 11189 : model1 loss : 0.025237 model2 loss : 0.026070
[22:47:26.769] iteration 11190 : model1 loss : 0.024032 model2 loss : 0.027821
[22:47:27.450] iteration 11191 : model1 loss : 0.023818 model2 loss : 0.019077
[22:47:28.127] iteration 11192 : model1 loss : 0.063265 model2 loss : 0.043703
[22:47:28.813] iteration 11193 : model1 loss : 0.019788 model2 loss : 0.018933
[22:47:29.477] iteration 11194 : model1 loss : 0.026376 model2 loss : 0.020754
[22:47:30.139] iteration 11195 : model1 loss : 0.017154 model2 loss : 0.016932
[22:47:30.799] iteration 11196 : model1 loss : 0.023138 model2 loss : 0.019448
[22:47:31.460] iteration 11197 : model1 loss : 0.029421 model2 loss : 0.024293
[22:47:32.142] iteration 11198 : model1 loss : 0.026086 model2 loss : 0.023702
[22:47:32.816] iteration 11199 : model1 loss : 0.020417 model2 loss : 0.018819
[22:47:33.490] iteration 11200 : model1 loss : 0.035581 model2 loss : 0.032547
[22:47:52.084] iteration 11200 : model1_mean_dice : 0.834360 model1_mean_hd95 : 2.668598
[22:48:10.828] iteration 11200 : model2_mean_dice : 0.860474 model2_mean_hd95 : 4.145399
[22:48:11.546] iteration 11201 : model1 loss : 0.023736 model2 loss : 0.028346
[22:48:12.204] iteration 11202 : model1 loss : 0.023872 model2 loss : 0.020648
[22:48:12.863] iteration 11203 : model1 loss : 0.024749 model2 loss : 0.021777
[22:48:13.530] iteration 11204 : model1 loss : 0.030710 model2 loss : 0.023487
[22:48:14.238] iteration 11205 : model1 loss : 0.024475 model2 loss : 0.026454
[22:48:14.914] iteration 11206 : model1 loss : 0.026452 model2 loss : 0.028400
[22:48:15.592] iteration 11207 : model1 loss : 0.032090 model2 loss : 0.025727
[22:48:16.279] iteration 11208 : model1 loss : 0.024246 model2 loss : 0.022610
[22:48:16.941] iteration 11209 : model1 loss : 0.025081 model2 loss : 0.020774
[22:48:17.607] iteration 11210 : model1 loss : 0.038927 model2 loss : 0.037607
[22:48:18.275] iteration 11211 : model1 loss : 0.030753 model2 loss : 0.027495
[22:48:18.947] iteration 11212 : model1 loss : 0.023499 model2 loss : 0.022271
[22:48:19.642] iteration 11213 : model1 loss : 0.023686 model2 loss : 0.023359
[22:48:20.327] iteration 11214 : model1 loss : 0.022817 model2 loss : 0.021417
[22:48:21.001] iteration 11215 : model1 loss : 0.027211 model2 loss : 0.027160
[22:48:21.664] iteration 11216 : model1 loss : 0.020598 model2 loss : 0.021628
[22:48:22.329] iteration 11217 : model1 loss : 0.023674 model2 loss : 0.022235
[22:48:23.011] iteration 11218 : model1 loss : 0.027421 model2 loss : 0.019581
[22:48:23.667] iteration 11219 : model1 loss : 0.025570 model2 loss : 0.026901
[22:48:24.341] iteration 11220 : model1 loss : 0.032063 model2 loss : 0.030683
[22:48:25.010] iteration 11221 : model1 loss : 0.024013 model2 loss : 0.022262
[22:48:25.675] iteration 11222 : model1 loss : 0.017028 model2 loss : 0.017577
[22:48:26.338] iteration 11223 : model1 loss : 0.029652 model2 loss : 0.026366
[22:48:26.999] iteration 11224 : model1 loss : 0.026226 model2 loss : 0.026005
[22:48:27.671] iteration 11225 : model1 loss : 0.030879 model2 loss : 0.030353
[22:48:28.333] iteration 11226 : model1 loss : 0.016263 model2 loss : 0.017355
[22:48:29.012] iteration 11227 : model1 loss : 0.023384 model2 loss : 0.020187
[22:48:29.679] iteration 11228 : model1 loss : 0.019457 model2 loss : 0.021902
[22:48:30.341] iteration 11229 : model1 loss : 0.019247 model2 loss : 0.018801
[22:48:31.011] iteration 11230 : model1 loss : 0.038088 model2 loss : 0.032842
[22:48:31.665] iteration 11231 : model1 loss : 0.021045 model2 loss : 0.022077
[22:48:32.340] iteration 11232 : model1 loss : 0.023261 model2 loss : 0.022028
[22:48:32.997] iteration 11233 : model1 loss : 0.021910 model2 loss : 0.020610
[22:48:33.662] iteration 11234 : model1 loss : 0.033452 model2 loss : 0.030702
[22:48:34.326] iteration 11235 : model1 loss : 0.021944 model2 loss : 0.020923
[22:48:34.993] iteration 11236 : model1 loss : 0.032236 model2 loss : 0.031952
[22:48:35.658] iteration 11237 : model1 loss : 0.019631 model2 loss : 0.022189
[22:48:36.337] iteration 11238 : model1 loss : 0.023144 model2 loss : 0.023882
[22:48:36.994] iteration 11239 : model1 loss : 0.028168 model2 loss : 0.019521
[22:48:37.649] iteration 11240 : model1 loss : 0.022642 model2 loss : 0.023574
[22:48:38.318] iteration 11241 : model1 loss : 0.017914 model2 loss : 0.020358
[22:48:39.001] iteration 11242 : model1 loss : 0.028966 model2 loss : 0.022277
[22:48:39.682] iteration 11243 : model1 loss : 0.020643 model2 loss : 0.019072
[22:48:40.355] iteration 11244 : model1 loss : 0.037370 model2 loss : 0.037320
[22:48:41.009] iteration 11245 : model1 loss : 0.020502 model2 loss : 0.018627
[22:48:41.684] iteration 11246 : model1 loss : 0.022602 model2 loss : 0.023994
[22:48:42.352] iteration 11247 : model1 loss : 0.023588 model2 loss : 0.023097
[22:48:43.015] iteration 11248 : model1 loss : 0.020949 model2 loss : 0.022182
[22:48:43.698] iteration 11249 : model1 loss : 0.021424 model2 loss : 0.020686
[22:48:44.383] iteration 11250 : model1 loss : 0.024953 model2 loss : 0.022512
[22:48:45.089] iteration 11251 : model1 loss : 0.026941 model2 loss : 0.020738
[22:48:45.755] iteration 11252 : model1 loss : 0.024690 model2 loss : 0.024673
[22:48:46.433] iteration 11253 : model1 loss : 0.014890 model2 loss : 0.019523
[22:48:47.100] iteration 11254 : model1 loss : 0.034476 model2 loss : 0.021326
[22:48:47.767] iteration 11255 : model1 loss : 0.028408 model2 loss : 0.027096
[22:48:48.446] iteration 11256 : model1 loss : 0.032883 model2 loss : 0.025925
[22:48:49.123] iteration 11257 : model1 loss : 0.141377 model2 loss : 0.141434
[22:48:49.794] iteration 11258 : model1 loss : 0.024319 model2 loss : 0.022904
[22:48:50.467] iteration 11259 : model1 loss : 0.030182 model2 loss : 0.027166
[22:48:51.127] iteration 11260 : model1 loss : 0.041907 model2 loss : 0.036836
[22:48:51.800] iteration 11261 : model1 loss : 0.031517 model2 loss : 0.032044
[22:48:52.472] iteration 11262 : model1 loss : 0.018299 model2 loss : 0.019079
[22:48:53.140] iteration 11263 : model1 loss : 0.021461 model2 loss : 0.021305
[22:48:53.817] iteration 11264 : model1 loss : 0.024787 model2 loss : 0.025982
[22:48:54.478] iteration 11265 : model1 loss : 0.022509 model2 loss : 0.021691
[22:48:55.136] iteration 11266 : model1 loss : 0.018750 model2 loss : 0.017183
[22:48:55.808] iteration 11267 : model1 loss : 0.020054 model2 loss : 0.020358
[22:48:56.478] iteration 11268 : model1 loss : 0.030859 model2 loss : 0.029730
[22:48:57.158] iteration 11269 : model1 loss : 0.022413 model2 loss : 0.018961
[22:48:57.815] iteration 11270 : model1 loss : 0.026327 model2 loss : 0.022687
[22:48:58.493] iteration 11271 : model1 loss : 0.021159 model2 loss : 0.020353
[22:48:59.173] iteration 11272 : model1 loss : 0.022862 model2 loss : 0.024227
[22:48:59.836] iteration 11273 : model1 loss : 0.019451 model2 loss : 0.022744
[22:49:00.519] iteration 11274 : model1 loss : 0.021073 model2 loss : 0.020124
[22:49:01.221] iteration 11275 : model1 loss : 0.017146 model2 loss : 0.018708
[22:49:01.908] iteration 11276 : model1 loss : 0.023819 model2 loss : 0.023195
[22:49:02.579] iteration 11277 : model1 loss : 0.026605 model2 loss : 0.024651
[22:49:03.255] iteration 11278 : model1 loss : 0.030939 model2 loss : 0.029643
[22:49:03.927] iteration 11279 : model1 loss : 0.024687 model2 loss : 0.025681
[22:49:04.602] iteration 11280 : model1 loss : 0.021261 model2 loss : 0.018013
[22:49:05.286] iteration 11281 : model1 loss : 0.026601 model2 loss : 0.025968
[22:49:05.964] iteration 11282 : model1 loss : 0.028813 model2 loss : 0.033892
[22:49:06.631] iteration 11283 : model1 loss : 0.110659 model2 loss : 0.065369
[22:49:07.308] iteration 11284 : model1 loss : 0.023991 model2 loss : 0.026365
[22:49:07.980] iteration 11285 : model1 loss : 0.029494 model2 loss : 0.030255
[22:49:08.660] iteration 11286 : model1 loss : 0.017279 model2 loss : 0.016019
[22:49:09.346] iteration 11287 : model1 loss : 0.022913 model2 loss : 0.019780
[22:49:10.011] iteration 11288 : model1 loss : 0.054702 model2 loss : 0.025087
[22:49:10.677] iteration 11289 : model1 loss : 0.021545 model2 loss : 0.017823
[22:49:11.348] iteration 11290 : model1 loss : 0.037401 model2 loss : 0.028663
[22:49:12.013] iteration 11291 : model1 loss : 0.026824 model2 loss : 0.020583
[22:49:12.682] iteration 11292 : model1 loss : 0.023531 model2 loss : 0.026630
[22:49:13.357] iteration 11293 : model1 loss : 0.037216 model2 loss : 0.033678
[22:49:14.025] iteration 11294 : model1 loss : 0.027344 model2 loss : 0.025833
[22:49:14.738] iteration 11295 : model1 loss : 0.027755 model2 loss : 0.024396
[22:49:15.410] iteration 11296 : model1 loss : 0.075581 model2 loss : 0.056191
[22:49:16.086] iteration 11297 : model1 loss : 0.031025 model2 loss : 0.029392
[22:49:16.760] iteration 11298 : model1 loss : 0.034236 model2 loss : 0.025340
[22:49:17.427] iteration 11299 : model1 loss : 0.036939 model2 loss : 0.035985
[22:49:18.107] iteration 11300 : model1 loss : 0.023304 model2 loss : 0.021609
[22:49:18.807] iteration 11301 : model1 loss : 0.018973 model2 loss : 0.018515
[22:49:19.483] iteration 11302 : model1 loss : 0.035230 model2 loss : 0.025570
[22:49:20.150] iteration 11303 : model1 loss : 0.022881 model2 loss : 0.018396
[22:49:20.825] iteration 11304 : model1 loss : 0.029328 model2 loss : 0.025118
[22:49:21.491] iteration 11305 : model1 loss : 0.022806 model2 loss : 0.021776
[22:49:22.161] iteration 11306 : model1 loss : 0.022680 model2 loss : 0.021519
[22:49:22.829] iteration 11307 : model1 loss : 0.022047 model2 loss : 0.023823
[22:49:23.493] iteration 11308 : model1 loss : 0.019983 model2 loss : 0.020656
[22:49:24.161] iteration 11309 : model1 loss : 0.020919 model2 loss : 0.021276
[22:49:24.825] iteration 11310 : model1 loss : 0.028356 model2 loss : 0.026454
[22:49:25.500] iteration 11311 : model1 loss : 0.020763 model2 loss : 0.022050
[22:49:26.160] iteration 11312 : model1 loss : 0.029778 model2 loss : 0.022383
[22:49:26.826] iteration 11313 : model1 loss : 0.025422 model2 loss : 0.021165
[22:49:27.505] iteration 11314 : model1 loss : 0.028945 model2 loss : 0.025815
[22:49:28.179] iteration 11315 : model1 loss : 0.024349 model2 loss : 0.023483
[22:49:28.855] iteration 11316 : model1 loss : 0.017558 model2 loss : 0.019119
[22:49:29.535] iteration 11317 : model1 loss : 0.023556 model2 loss : 0.023401
[22:49:30.203] iteration 11318 : model1 loss : 0.020192 model2 loss : 0.021255
[22:49:30.871] iteration 11319 : model1 loss : 0.022096 model2 loss : 0.021457
[22:49:31.534] iteration 11320 : model1 loss : 0.107012 model2 loss : 0.061316
[22:49:32.202] iteration 11321 : model1 loss : 0.025960 model2 loss : 0.028813
[22:49:32.875] iteration 11322 : model1 loss : 0.028414 model2 loss : 0.024296
[22:49:33.538] iteration 11323 : model1 loss : 0.023457 model2 loss : 0.026150
[22:49:34.230] iteration 11324 : model1 loss : 0.025538 model2 loss : 0.023247
[22:49:34.899] iteration 11325 : model1 loss : 0.030704 model2 loss : 0.028428
[22:49:35.558] iteration 11326 : model1 loss : 0.029119 model2 loss : 0.023640
[22:49:36.222] iteration 11327 : model1 loss : 0.020365 model2 loss : 0.018896
[22:49:36.897] iteration 11328 : model1 loss : 0.033794 model2 loss : 0.027646
[22:49:37.560] iteration 11329 : model1 loss : 0.024800 model2 loss : 0.022056
[22:49:38.237] iteration 11330 : model1 loss : 0.072338 model2 loss : 0.049045
[22:49:38.902] iteration 11331 : model1 loss : 0.023056 model2 loss : 0.023752
[22:49:39.583] iteration 11332 : model1 loss : 0.022542 model2 loss : 0.021095
[22:49:40.282] iteration 11333 : model1 loss : 0.177215 model2 loss : 0.163416
[22:49:40.944] iteration 11334 : model1 loss : 0.050283 model2 loss : 0.045526
[22:49:41.607] iteration 11335 : model1 loss : 0.018802 model2 loss : 0.018230
[22:49:42.283] iteration 11336 : model1 loss : 0.023292 model2 loss : 0.022482
[22:49:42.951] iteration 11337 : model1 loss : 0.019041 model2 loss : 0.020956
[22:49:43.621] iteration 11338 : model1 loss : 0.065874 model2 loss : 0.069187
[22:49:44.294] iteration 11339 : model1 loss : 0.020857 model2 loss : 0.018953
[22:49:44.965] iteration 11340 : model1 loss : 0.017710 model2 loss : 0.018222
[22:49:45.645] iteration 11341 : model1 loss : 0.022987 model2 loss : 0.023411
[22:49:46.315] iteration 11342 : model1 loss : 0.023124 model2 loss : 0.023727
[22:49:46.981] iteration 11343 : model1 loss : 0.019855 model2 loss : 0.020381
[22:49:47.649] iteration 11344 : model1 loss : 0.019460 model2 loss : 0.020852
[22:49:48.319] iteration 11345 : model1 loss : 0.024141 model2 loss : 0.025052
[22:49:48.992] iteration 11346 : model1 loss : 0.033943 model2 loss : 0.028590
[22:49:49.658] iteration 11347 : model1 loss : 0.032584 model2 loss : 0.030123
[22:49:50.325] iteration 11348 : model1 loss : 0.031733 model2 loss : 0.031018
[22:49:50.990] iteration 11349 : model1 loss : 0.055595 model2 loss : 0.024843
[22:49:51.659] iteration 11350 : model1 loss : 0.021418 model2 loss : 0.020844
[22:49:52.389] iteration 11351 : model1 loss : 0.026153 model2 loss : 0.026057
[22:49:53.066] iteration 11352 : model1 loss : 0.029912 model2 loss : 0.030259
[22:49:53.742] iteration 11353 : model1 loss : 0.021535 model2 loss : 0.025144
[22:49:54.403] iteration 11354 : model1 loss : 0.025006 model2 loss : 0.023604
[22:49:55.084] iteration 11355 : model1 loss : 0.021376 model2 loss : 0.021320
[22:49:55.751] iteration 11356 : model1 loss : 0.043727 model2 loss : 0.036028
[22:49:56.431] iteration 11357 : model1 loss : 0.026680 model2 loss : 0.030228
[22:49:57.100] iteration 11358 : model1 loss : 0.021092 model2 loss : 0.021410
[22:49:57.795] iteration 11359 : model1 loss : 0.023663 model2 loss : 0.018842
[22:49:58.471] iteration 11360 : model1 loss : 0.019752 model2 loss : 0.018018
[22:49:59.141] iteration 11361 : model1 loss : 0.022509 model2 loss : 0.020633
[22:49:59.815] iteration 11362 : model1 loss : 0.037740 model2 loss : 0.040225
[22:50:00.491] iteration 11363 : model1 loss : 0.019514 model2 loss : 0.018783
[22:50:01.159] iteration 11364 : model1 loss : 0.023923 model2 loss : 0.022655
[22:50:01.837] iteration 11365 : model1 loss : 0.028678 model2 loss : 0.025414
[22:50:02.512] iteration 11366 : model1 loss : 0.021289 model2 loss : 0.022084
[22:50:03.178] iteration 11367 : model1 loss : 0.026345 model2 loss : 0.024171
[22:50:03.849] iteration 11368 : model1 loss : 0.023228 model2 loss : 0.022100
[22:50:04.522] iteration 11369 : model1 loss : 0.021329 model2 loss : 0.019365
[22:50:05.180] iteration 11370 : model1 loss : 0.018618 model2 loss : 0.020430
[22:50:05.848] iteration 11371 : model1 loss : 0.031114 model2 loss : 0.034412
[22:50:06.544] iteration 11372 : model1 loss : 0.022739 model2 loss : 0.026242
[22:50:07.209] iteration 11373 : model1 loss : 0.025460 model2 loss : 0.023215
[22:50:07.883] iteration 11374 : model1 loss : 0.031902 model2 loss : 0.027879
[22:50:08.563] iteration 11375 : model1 loss : 0.020815 model2 loss : 0.019233
[22:50:09.231] iteration 11376 : model1 loss : 0.037614 model2 loss : 0.037745
[22:50:09.917] iteration 11377 : model1 loss : 0.017713 model2 loss : 0.019658
[22:50:10.590] iteration 11378 : model1 loss : 0.031601 model2 loss : 0.027600
[22:50:11.258] iteration 11379 : model1 loss : 0.017549 model2 loss : 0.017094
[22:50:11.925] iteration 11380 : model1 loss : 0.020613 model2 loss : 0.021929
[22:50:12.600] iteration 11381 : model1 loss : 0.021417 model2 loss : 0.019024
[22:50:13.274] iteration 11382 : model1 loss : 0.017837 model2 loss : 0.016565
[22:50:13.945] iteration 11383 : model1 loss : 0.018474 model2 loss : 0.021290
[22:50:14.622] iteration 11384 : model1 loss : 0.026366 model2 loss : 0.023183
[22:50:15.324] iteration 11385 : model1 loss : 0.024949 model2 loss : 0.023648
[22:50:15.996] iteration 11386 : model1 loss : 0.022045 model2 loss : 0.021071
[22:50:16.681] iteration 11387 : model1 loss : 0.036951 model2 loss : 0.036502
[22:50:17.354] iteration 11388 : model1 loss : 0.023361 model2 loss : 0.023989
[22:50:18.009] iteration 11389 : model1 loss : 0.036011 model2 loss : 0.037060
[22:50:18.690] iteration 11390 : model1 loss : 0.028346 model2 loss : 0.031071
[22:50:19.357] iteration 11391 : model1 loss : 0.038417 model2 loss : 0.032485
[22:50:20.033] iteration 11392 : model1 loss : 0.021108 model2 loss : 0.021481
[22:50:20.687] iteration 11393 : model1 loss : 0.024231 model2 loss : 0.026005
[22:50:21.359] iteration 11394 : model1 loss : 0.022961 model2 loss : 0.024520
[22:50:22.032] iteration 11395 : model1 loss : 0.022901 model2 loss : 0.023448
[22:50:22.710] iteration 11396 : model1 loss : 0.023324 model2 loss : 0.024398
[22:50:23.385] iteration 11397 : model1 loss : 0.019112 model2 loss : 0.019234
[22:50:24.064] iteration 11398 : model1 loss : 0.023696 model2 loss : 0.025406
[22:50:24.726] iteration 11399 : model1 loss : 0.018654 model2 loss : 0.018606
[22:50:25.417] iteration 11400 : model1 loss : 0.021089 model2 loss : 0.026785
[22:50:46.586] iteration 11400 : model1_mean_dice : 0.861896 model1_mean_hd95 : 7.008212
[22:51:07.069] iteration 11400 : model2_mean_dice : 0.859648 model2_mean_hd95 : 5.920590
[22:51:07.836] iteration 11401 : model1 loss : 0.025116 model2 loss : 0.024780
[22:51:08.575] iteration 11402 : model1 loss : 0.024298 model2 loss : 0.023134
[22:51:09.301] iteration 11403 : model1 loss : 0.020303 model2 loss : 0.020191
[22:51:10.010] iteration 11404 : model1 loss : 0.023251 model2 loss : 0.022558
[22:51:10.718] iteration 11405 : model1 loss : 0.038533 model2 loss : 0.027471
[22:51:11.493] iteration 11406 : model1 loss : 0.023812 model2 loss : 0.021593
[22:51:12.245] iteration 11407 : model1 loss : 0.020424 model2 loss : 0.022135
[22:51:12.975] iteration 11408 : model1 loss : 0.022444 model2 loss : 0.023174
[22:51:13.709] iteration 11409 : model1 loss : 0.015764 model2 loss : 0.015436
[22:51:14.412] iteration 11410 : model1 loss : 0.025614 model2 loss : 0.023181
[22:51:15.112] iteration 11411 : model1 loss : 0.027595 model2 loss : 0.028609
[22:51:15.832] iteration 11412 : model1 loss : 0.017915 model2 loss : 0.018214
[22:51:16.571] iteration 11413 : model1 loss : 0.022940 model2 loss : 0.024586
[22:51:17.337] iteration 11414 : model1 loss : 0.059113 model2 loss : 0.050224
[22:51:18.050] iteration 11415 : model1 loss : 0.086445 model2 loss : 0.077945
[22:51:18.750] iteration 11416 : model1 loss : 0.022902 model2 loss : 0.021349
[22:51:19.460] iteration 11417 : model1 loss : 0.022366 model2 loss : 0.025302
[22:51:20.178] iteration 11418 : model1 loss : 0.034715 model2 loss : 0.037066
[22:51:20.891] iteration 11419 : model1 loss : 0.018899 model2 loss : 0.017889
[22:51:21.613] iteration 11420 : model1 loss : 0.021615 model2 loss : 0.019603
[22:51:22.353] iteration 11421 : model1 loss : 0.037849 model2 loss : 0.032253
[22:51:23.073] iteration 11422 : model1 loss : 0.029271 model2 loss : 0.035196
[22:51:24.042] iteration 11423 : model1 loss : 0.020792 model2 loss : 0.021543
[22:51:24.809] iteration 11424 : model1 loss : 0.029932 model2 loss : 0.027861
[22:51:25.514] iteration 11425 : model1 loss : 0.024314 model2 loss : 0.020803
[22:51:26.214] iteration 11426 : model1 loss : 0.026364 model2 loss : 0.029302
[22:51:26.934] iteration 11427 : model1 loss : 0.017513 model2 loss : 0.017897
[22:51:27.665] iteration 11428 : model1 loss : 0.023292 model2 loss : 0.021129
[22:51:28.383] iteration 11429 : model1 loss : 0.020735 model2 loss : 0.022290
[22:51:29.085] iteration 11430 : model1 loss : 0.015674 model2 loss : 0.014889
[22:51:29.787] iteration 11431 : model1 loss : 0.020894 model2 loss : 0.027906
[22:51:30.499] iteration 11432 : model1 loss : 0.018204 model2 loss : 0.018245
[22:51:31.199] iteration 11433 : model1 loss : 0.024649 model2 loss : 0.024511
[22:51:31.901] iteration 11434 : model1 loss : 0.024648 model2 loss : 0.024036
[22:51:32.634] iteration 11435 : model1 loss : 0.018131 model2 loss : 0.020093
[22:51:33.348] iteration 11436 : model1 loss : 0.024419 model2 loss : 0.025627
[22:51:34.058] iteration 11437 : model1 loss : 0.041381 model2 loss : 0.036313
[22:51:34.753] iteration 11438 : model1 loss : 0.043204 model2 loss : 0.036587
[22:51:35.457] iteration 11439 : model1 loss : 0.024404 model2 loss : 0.025160
[22:51:36.149] iteration 11440 : model1 loss : 0.021565 model2 loss : 0.021123
[22:51:36.849] iteration 11441 : model1 loss : 0.024287 model2 loss : 0.021453
[22:51:37.589] iteration 11442 : model1 loss : 0.024395 model2 loss : 0.029387
[22:51:38.321] iteration 11443 : model1 loss : 0.019687 model2 loss : 0.019755
[22:51:39.060] iteration 11444 : model1 loss : 0.022531 model2 loss : 0.023537
[22:51:39.797] iteration 11445 : model1 loss : 0.020864 model2 loss : 0.020939
[22:51:40.571] iteration 11446 : model1 loss : 0.018241 model2 loss : 0.016386
[22:51:41.335] iteration 11447 : model1 loss : 0.029521 model2 loss : 0.032440
[22:51:42.109] iteration 11448 : model1 loss : 0.024636 model2 loss : 0.026262
[22:51:42.871] iteration 11449 : model1 loss : 0.027623 model2 loss : 0.030416
[22:51:43.594] iteration 11450 : model1 loss : 0.035919 model2 loss : 0.036752
[22:51:44.369] iteration 11451 : model1 loss : 0.023076 model2 loss : 0.024180
[22:51:45.135] iteration 11452 : model1 loss : 0.021585 model2 loss : 0.019999
[22:51:45.865] iteration 11453 : model1 loss : 0.058161 model2 loss : 0.060986
[22:51:46.590] iteration 11454 : model1 loss : 0.018972 model2 loss : 0.019430
[22:51:47.395] iteration 11455 : model1 loss : 0.025276 model2 loss : 0.023557
[22:51:48.161] iteration 11456 : model1 loss : 0.023147 model2 loss : 0.021789
[22:51:48.914] iteration 11457 : model1 loss : 0.019898 model2 loss : 0.018315
[22:51:49.613] iteration 11458 : model1 loss : 0.020343 model2 loss : 0.018217
[22:51:50.332] iteration 11459 : model1 loss : 0.025094 model2 loss : 0.024986
[22:51:51.064] iteration 11460 : model1 loss : 0.028313 model2 loss : 0.023472
[22:51:51.784] iteration 11461 : model1 loss : 0.020362 model2 loss : 0.021480
[22:51:52.543] iteration 11462 : model1 loss : 0.020310 model2 loss : 0.019641
[22:51:53.245] iteration 11463 : model1 loss : 0.063178 model2 loss : 0.051588
[22:51:53.953] iteration 11464 : model1 loss : 0.029479 model2 loss : 0.027530
[22:51:54.662] iteration 11465 : model1 loss : 0.022967 model2 loss : 0.024351
[22:51:55.376] iteration 11466 : model1 loss : 0.018451 model2 loss : 0.018808
[22:51:56.090] iteration 11467 : model1 loss : 0.023613 model2 loss : 0.023771
[22:51:56.804] iteration 11468 : model1 loss : 0.026232 model2 loss : 0.035453
[22:51:57.539] iteration 11469 : model1 loss : 0.027851 model2 loss : 0.029559
[22:51:58.252] iteration 11470 : model1 loss : 0.021244 model2 loss : 0.020828
[22:51:58.953] iteration 11471 : model1 loss : 0.039388 model2 loss : 0.030365
[22:51:59.644] iteration 11472 : model1 loss : 0.023832 model2 loss : 0.022406
[22:52:00.357] iteration 11473 : model1 loss : 0.035898 model2 loss : 0.034539
[22:52:01.059] iteration 11474 : model1 loss : 0.023137 model2 loss : 0.023431
[22:52:01.755] iteration 11475 : model1 loss : 0.027819 model2 loss : 0.026464
[22:52:02.494] iteration 11476 : model1 loss : 0.021447 model2 loss : 0.018958
[22:52:03.202] iteration 11477 : model1 loss : 0.021973 model2 loss : 0.022436
[22:52:03.915] iteration 11478 : model1 loss : 0.017109 model2 loss : 0.016532
[22:52:04.621] iteration 11479 : model1 loss : 0.022783 model2 loss : 0.022553
[22:52:05.332] iteration 11480 : model1 loss : 0.033125 model2 loss : 0.035895
[22:52:06.046] iteration 11481 : model1 loss : 0.029826 model2 loss : 0.032585
[22:52:06.754] iteration 11482 : model1 loss : 0.033522 model2 loss : 0.029801
[22:52:07.518] iteration 11483 : model1 loss : 0.029625 model2 loss : 0.031174
[22:52:08.245] iteration 11484 : model1 loss : 0.026537 model2 loss : 0.029428
[22:52:08.963] iteration 11485 : model1 loss : 0.020953 model2 loss : 0.020739
[22:52:09.679] iteration 11486 : model1 loss : 0.022264 model2 loss : 0.024041
[22:52:10.387] iteration 11487 : model1 loss : 0.023285 model2 loss : 0.023754
[22:52:11.101] iteration 11488 : model1 loss : 0.020239 model2 loss : 0.018206
[22:52:11.811] iteration 11489 : model1 loss : 0.022454 model2 loss : 0.024968
[22:52:12.558] iteration 11490 : model1 loss : 0.021048 model2 loss : 0.017313
[22:52:13.268] iteration 11491 : model1 loss : 0.045586 model2 loss : 0.052453
[22:52:13.978] iteration 11492 : model1 loss : 0.025234 model2 loss : 0.025726
[22:52:14.683] iteration 11493 : model1 loss : 0.030984 model2 loss : 0.027018
[22:52:15.386] iteration 11494 : model1 loss : 0.017359 model2 loss : 0.018911
[22:52:16.142] iteration 11495 : model1 loss : 0.036084 model2 loss : 0.033901
[22:52:16.852] iteration 11496 : model1 loss : 0.025853 model2 loss : 0.025860
[22:52:17.590] iteration 11497 : model1 loss : 0.021192 model2 loss : 0.024132
[22:52:18.322] iteration 11498 : model1 loss : 0.052902 model2 loss : 0.072877
[22:52:19.100] iteration 11499 : model1 loss : 0.029391 model2 loss : 0.027713
[22:52:19.817] iteration 11500 : model1 loss : 0.029384 model2 loss : 0.038038
[22:52:20.582] iteration 11501 : model1 loss : 0.019733 model2 loss : 0.019825
[22:52:21.291] iteration 11502 : model1 loss : 0.020921 model2 loss : 0.023508
[22:52:22.013] iteration 11503 : model1 loss : 0.022967 model2 loss : 0.020490
[22:52:22.757] iteration 11504 : model1 loss : 0.030010 model2 loss : 0.035349
[22:52:23.463] iteration 11505 : model1 loss : 0.021966 model2 loss : 0.022598
[22:52:24.171] iteration 11506 : model1 loss : 0.020278 model2 loss : 0.020387
[22:52:24.885] iteration 11507 : model1 loss : 0.021246 model2 loss : 0.021352
[22:52:25.588] iteration 11508 : model1 loss : 0.022968 model2 loss : 0.022833
[22:52:26.300] iteration 11509 : model1 loss : 0.041074 model2 loss : 0.037071
[22:52:27.035] iteration 11510 : model1 loss : 0.038132 model2 loss : 0.037190
[22:52:27.767] iteration 11511 : model1 loss : 0.028190 model2 loss : 0.027791
[22:52:28.479] iteration 11512 : model1 loss : 0.021306 model2 loss : 0.023997
[22:52:29.186] iteration 11513 : model1 loss : 0.022301 model2 loss : 0.017258
[22:52:29.879] iteration 11514 : model1 loss : 0.019832 model2 loss : 0.020555
[22:52:30.602] iteration 11515 : model1 loss : 0.023195 model2 loss : 0.024802
[22:52:31.307] iteration 11516 : model1 loss : 0.027266 model2 loss : 0.019853
[22:52:32.045] iteration 11517 : model1 loss : 0.029607 model2 loss : 0.027052
[22:52:32.779] iteration 11518 : model1 loss : 0.024301 model2 loss : 0.022512
[22:52:33.474] iteration 11519 : model1 loss : 0.036982 model2 loss : 0.042912
[22:52:34.187] iteration 11520 : model1 loss : 0.034460 model2 loss : 0.038634
[22:52:34.895] iteration 11521 : model1 loss : 0.029218 model2 loss : 0.025434
[22:52:35.601] iteration 11522 : model1 loss : 0.022594 model2 loss : 0.023366
[22:52:36.306] iteration 11523 : model1 loss : 0.031901 model2 loss : 0.030766
[22:52:37.018] iteration 11524 : model1 loss : 0.025127 model2 loss : 0.028962
[22:52:37.735] iteration 11525 : model1 loss : 0.017912 model2 loss : 0.018717
[22:52:38.452] iteration 11526 : model1 loss : 0.023756 model2 loss : 0.020696
[22:52:39.151] iteration 11527 : model1 loss : 0.024462 model2 loss : 0.022265
[22:52:39.858] iteration 11528 : model1 loss : 0.022254 model2 loss : 0.022764
[22:52:40.576] iteration 11529 : model1 loss : 0.032266 model2 loss : 0.031656
[22:52:41.281] iteration 11530 : model1 loss : 0.024359 model2 loss : 0.026281
[22:52:42.011] iteration 11531 : model1 loss : 0.020087 model2 loss : 0.021579
[22:52:42.753] iteration 11532 : model1 loss : 0.026154 model2 loss : 0.026186
[22:52:43.484] iteration 11533 : model1 loss : 0.030891 model2 loss : 0.028035
[22:52:44.187] iteration 11534 : model1 loss : 0.022763 model2 loss : 0.024469
[22:52:44.900] iteration 11535 : model1 loss : 0.025223 model2 loss : 0.020676
[22:52:45.607] iteration 11536 : model1 loss : 0.016761 model2 loss : 0.017730
[22:52:46.306] iteration 11537 : model1 loss : 0.024466 model2 loss : 0.020461
[22:52:47.039] iteration 11538 : model1 loss : 0.017909 model2 loss : 0.021042
[22:52:47.759] iteration 11539 : model1 loss : 0.035792 model2 loss : 0.043921
[22:52:48.472] iteration 11540 : model1 loss : 0.018033 model2 loss : 0.019636
[22:52:49.175] iteration 11541 : model1 loss : 0.023215 model2 loss : 0.024124
[22:52:49.894] iteration 11542 : model1 loss : 0.014654 model2 loss : 0.015188
[22:52:50.600] iteration 11543 : model1 loss : 0.018639 model2 loss : 0.018030
[22:52:51.310] iteration 11544 : model1 loss : 0.025341 model2 loss : 0.027239
[22:52:52.027] iteration 11545 : model1 loss : 0.025345 model2 loss : 0.024363
[22:52:52.792] iteration 11546 : model1 loss : 0.020194 model2 loss : 0.019647
[22:52:53.488] iteration 11547 : model1 loss : 0.019294 model2 loss : 0.019646
[22:52:54.189] iteration 11548 : model1 loss : 0.017109 model2 loss : 0.016977
[22:52:54.897] iteration 11549 : model1 loss : 0.037407 model2 loss : 0.030039
[22:52:55.615] iteration 11550 : model1 loss : 0.025019 model2 loss : 0.020769
[22:52:56.377] iteration 11551 : model1 loss : 0.022669 model2 loss : 0.020101
[22:52:57.115] iteration 11552 : model1 loss : 0.022635 model2 loss : 0.026230
[22:52:57.848] iteration 11553 : model1 loss : 0.019133 model2 loss : 0.021404
[22:52:58.572] iteration 11554 : model1 loss : 0.019347 model2 loss : 0.018989
[22:52:59.300] iteration 11555 : model1 loss : 0.018695 model2 loss : 0.022033
[22:53:00.007] iteration 11556 : model1 loss : 0.024899 model2 loss : 0.023331
[22:53:00.712] iteration 11557 : model1 loss : 0.022994 model2 loss : 0.024864
[22:53:01.436] iteration 11558 : model1 loss : 0.021270 model2 loss : 0.020090
[22:53:02.182] iteration 11559 : model1 loss : 0.028593 model2 loss : 0.027896
[22:53:02.912] iteration 11560 : model1 loss : 0.020776 model2 loss : 0.022622
[22:53:03.628] iteration 11561 : model1 loss : 0.026805 model2 loss : 0.028479
[22:53:04.340] iteration 11562 : model1 loss : 0.070011 model2 loss : 0.062078
[22:53:05.076] iteration 11563 : model1 loss : 0.024111 model2 loss : 0.026748
[22:53:05.779] iteration 11564 : model1 loss : 0.026478 model2 loss : 0.033078
[22:53:06.481] iteration 11565 : model1 loss : 0.046054 model2 loss : 0.040323
[22:53:07.228] iteration 11566 : model1 loss : 0.027784 model2 loss : 0.028100
[22:53:07.936] iteration 11567 : model1 loss : 0.025354 model2 loss : 0.027585
[22:53:08.661] iteration 11568 : model1 loss : 0.018127 model2 loss : 0.018757
[22:53:09.380] iteration 11569 : model1 loss : 0.041540 model2 loss : 0.031067
[22:53:10.086] iteration 11570 : model1 loss : 0.021731 model2 loss : 0.026217
[22:53:10.782] iteration 11571 : model1 loss : 0.031003 model2 loss : 0.031039
[22:53:11.506] iteration 11572 : model1 loss : 0.021051 model2 loss : 0.024639
[22:53:12.257] iteration 11573 : model1 loss : 0.025253 model2 loss : 0.024904
[22:53:12.965] iteration 11574 : model1 loss : 0.021353 model2 loss : 0.021672
[22:53:13.686] iteration 11575 : model1 loss : 0.018835 model2 loss : 0.020620
[22:53:14.389] iteration 11576 : model1 loss : 0.033953 model2 loss : 0.033867
[22:53:15.104] iteration 11577 : model1 loss : 0.024232 model2 loss : 0.023390
[22:53:15.807] iteration 11578 : model1 loss : 0.024653 model2 loss : 0.020183
[22:53:16.542] iteration 11579 : model1 loss : 0.019187 model2 loss : 0.018808
[22:53:17.302] iteration 11580 : model1 loss : 0.019381 model2 loss : 0.020729
[22:53:18.011] iteration 11581 : model1 loss : 0.025047 model2 loss : 0.022697
[22:53:18.724] iteration 11582 : model1 loss : 0.021830 model2 loss : 0.018975
[22:53:19.454] iteration 11583 : model1 loss : 0.019712 model2 loss : 0.018631
[22:53:20.171] iteration 11584 : model1 loss : 0.024787 model2 loss : 0.026504
[22:53:20.879] iteration 11585 : model1 loss : 0.027150 model2 loss : 0.024124
[22:53:21.604] iteration 11586 : model1 loss : 0.024297 model2 loss : 0.023210
[22:53:22.351] iteration 11587 : model1 loss : 0.021835 model2 loss : 0.026452
[22:53:23.058] iteration 11588 : model1 loss : 0.022664 model2 loss : 0.021678
[22:53:23.777] iteration 11589 : model1 loss : 0.021180 model2 loss : 0.021883
[22:53:24.484] iteration 11590 : model1 loss : 0.023782 model2 loss : 0.027462
[22:53:25.196] iteration 11591 : model1 loss : 0.024050 model2 loss : 0.023877
[22:53:25.913] iteration 11592 : model1 loss : 0.022997 model2 loss : 0.023401
[22:53:26.608] iteration 11593 : model1 loss : 0.027655 model2 loss : 0.033997
[22:53:27.354] iteration 11594 : model1 loss : 0.020120 model2 loss : 0.019420
[22:53:28.066] iteration 11595 : model1 loss : 0.019191 model2 loss : 0.020032
[22:53:28.777] iteration 11596 : model1 loss : 0.019115 model2 loss : 0.016241
[22:53:29.497] iteration 11597 : model1 loss : 0.023190 model2 loss : 0.023215
[22:53:30.206] iteration 11598 : model1 loss : 0.023564 model2 loss : 0.023715
[22:53:30.904] iteration 11599 : model1 loss : 0.019430 model2 loss : 0.018894
[22:53:31.627] iteration 11600 : model1 loss : 0.024293 model2 loss : 0.023162
[22:53:51.655] iteration 11600 : model1_mean_dice : 0.857101 model1_mean_hd95 : 6.967823
[22:54:11.882] iteration 11600 : model2_mean_dice : 0.861180 model2_mean_hd95 : 7.494425
[22:54:12.596] iteration 11601 : model1 loss : 0.021784 model2 loss : 0.020941
[22:54:13.271] iteration 11602 : model1 loss : 0.022768 model2 loss : 0.030086
[22:54:13.958] iteration 11603 : model1 loss : 0.023907 model2 loss : 0.024211
[22:54:14.627] iteration 11604 : model1 loss : 0.030997 model2 loss : 0.031732
[22:54:15.317] iteration 11605 : model1 loss : 0.023867 model2 loss : 0.024394
[22:54:15.980] iteration 11606 : model1 loss : 0.020161 model2 loss : 0.017672
[22:54:16.675] iteration 11607 : model1 loss : 0.033817 model2 loss : 0.034963
[22:54:17.377] iteration 11608 : model1 loss : 0.023742 model2 loss : 0.025734
[22:54:18.058] iteration 11609 : model1 loss : 0.025569 model2 loss : 0.027375
[22:54:18.738] iteration 11610 : model1 loss : 0.031506 model2 loss : 0.028216
[22:54:19.414] iteration 11611 : model1 loss : 0.029263 model2 loss : 0.027315
[22:54:20.099] iteration 11612 : model1 loss : 0.026308 model2 loss : 0.022792
[22:54:20.771] iteration 11613 : model1 loss : 0.020878 model2 loss : 0.019769
[22:54:21.443] iteration 11614 : model1 loss : 0.023557 model2 loss : 0.025231
[22:54:22.124] iteration 11615 : model1 loss : 0.023313 model2 loss : 0.028490
[22:54:22.805] iteration 11616 : model1 loss : 0.023404 model2 loss : 0.024148
[22:54:23.481] iteration 11617 : model1 loss : 0.031155 model2 loss : 0.027235
[22:54:24.161] iteration 11618 : model1 loss : 0.023670 model2 loss : 0.024129
[22:54:24.833] iteration 11619 : model1 loss : 0.018633 model2 loss : 0.021733
[22:54:25.520] iteration 11620 : model1 loss : 0.026221 model2 loss : 0.026734
[22:54:26.206] iteration 11621 : model1 loss : 0.020556 model2 loss : 0.021147
[22:54:26.876] iteration 11622 : model1 loss : 0.021323 model2 loss : 0.023261
[22:54:27.556] iteration 11623 : model1 loss : 0.034359 model2 loss : 0.027595
[22:54:28.229] iteration 11624 : model1 loss : 0.025403 model2 loss : 0.029698
[22:54:28.902] iteration 11625 : model1 loss : 0.027325 model2 loss : 0.022012
[22:54:29.598] iteration 11626 : model1 loss : 0.019973 model2 loss : 0.020806
[22:54:30.271] iteration 11627 : model1 loss : 0.031911 model2 loss : 0.029622
[22:54:30.957] iteration 11628 : model1 loss : 0.036354 model2 loss : 0.029524
[22:54:31.640] iteration 11629 : model1 loss : 0.022594 model2 loss : 0.021796
[22:54:32.327] iteration 11630 : model1 loss : 0.014673 model2 loss : 0.014261
[22:54:33.018] iteration 11631 : model1 loss : 0.018049 model2 loss : 0.019360
[22:54:33.690] iteration 11632 : model1 loss : 0.025698 model2 loss : 0.025944
[22:54:34.379] iteration 11633 : model1 loss : 0.031060 model2 loss : 0.035079
[22:54:35.059] iteration 11634 : model1 loss : 0.020905 model2 loss : 0.022166
[22:54:35.731] iteration 11635 : model1 loss : 0.027094 model2 loss : 0.029844
[22:54:36.406] iteration 11636 : model1 loss : 0.018013 model2 loss : 0.018521
[22:54:37.093] iteration 11637 : model1 loss : 0.029251 model2 loss : 0.031015
[22:54:37.774] iteration 11638 : model1 loss : 0.047589 model2 loss : 0.042796
[22:54:38.460] iteration 11639 : model1 loss : 0.016155 model2 loss : 0.015861
[22:54:39.150] iteration 11640 : model1 loss : 0.025322 model2 loss : 0.023863
[22:54:39.834] iteration 11641 : model1 loss : 0.017593 model2 loss : 0.019401
[22:54:40.545] iteration 11642 : model1 loss : 0.019980 model2 loss : 0.018965
[22:54:41.256] iteration 11643 : model1 loss : 0.024069 model2 loss : 0.020897
[22:54:41.957] iteration 11644 : model1 loss : 0.020675 model2 loss : 0.019936
[22:54:42.689] iteration 11645 : model1 loss : 0.020004 model2 loss : 0.019161
[22:54:43.375] iteration 11646 : model1 loss : 0.016385 model2 loss : 0.017050
[22:54:44.068] iteration 11647 : model1 loss : 0.018103 model2 loss : 0.020156
[22:54:44.741] iteration 11648 : model1 loss : 0.019312 model2 loss : 0.023660
[22:54:45.426] iteration 11649 : model1 loss : 0.029841 model2 loss : 0.036123
[22:54:46.123] iteration 11650 : model1 loss : 0.025384 model2 loss : 0.026480
[22:54:46.846] iteration 11651 : model1 loss : 0.034841 model2 loss : 0.033580
[22:54:47.534] iteration 11652 : model1 loss : 0.025842 model2 loss : 0.022012
[22:54:48.220] iteration 11653 : model1 loss : 0.023053 model2 loss : 0.023821
[22:54:48.898] iteration 11654 : model1 loss : 0.023342 model2 loss : 0.020660
[22:54:49.589] iteration 11655 : model1 loss : 0.027146 model2 loss : 0.030867
[22:54:50.285] iteration 11656 : model1 loss : 0.022208 model2 loss : 0.023889
[22:54:51.047] iteration 11657 : model1 loss : 0.033889 model2 loss : 0.035864
[22:54:51.777] iteration 11658 : model1 loss : 0.020209 model2 loss : 0.019754
[22:54:52.478] iteration 11659 : model1 loss : 0.016622 model2 loss : 0.016691
[22:54:53.143] iteration 11660 : model1 loss : 0.020712 model2 loss : 0.021195
[22:54:53.825] iteration 11661 : model1 loss : 0.017837 model2 loss : 0.019816
[22:54:54.502] iteration 11662 : model1 loss : 0.024723 model2 loss : 0.025513
[22:54:55.183] iteration 11663 : model1 loss : 0.052913 model2 loss : 0.038562
[22:54:55.853] iteration 11664 : model1 loss : 0.023828 model2 loss : 0.025182
[22:54:56.584] iteration 11665 : model1 loss : 0.025625 model2 loss : 0.024006
[22:54:57.340] iteration 11666 : model1 loss : 0.023670 model2 loss : 0.022442
[22:54:58.087] iteration 11667 : model1 loss : 0.037446 model2 loss : 0.074472
[22:54:58.843] iteration 11668 : model1 loss : 0.027481 model2 loss : 0.029079
[22:54:59.636] iteration 11669 : model1 loss : 0.022002 model2 loss : 0.021220
[22:55:00.354] iteration 11670 : model1 loss : 0.023281 model2 loss : 0.024135
[22:55:01.060] iteration 11671 : model1 loss : 0.020281 model2 loss : 0.018104
[22:55:01.752] iteration 11672 : model1 loss : 0.025314 model2 loss : 0.033197
[22:55:02.470] iteration 11673 : model1 loss : 0.019858 model2 loss : 0.023889
[22:55:03.181] iteration 11674 : model1 loss : 0.023187 model2 loss : 0.026632
[22:55:03.927] iteration 11675 : model1 loss : 0.023578 model2 loss : 0.027318
[22:55:04.625] iteration 11676 : model1 loss : 0.031487 model2 loss : 0.036037
[22:55:05.311] iteration 11677 : model1 loss : 0.027150 model2 loss : 0.028808
[22:55:06.003] iteration 11678 : model1 loss : 0.028961 model2 loss : 0.034983
[22:55:06.699] iteration 11679 : model1 loss : 0.022351 model2 loss : 0.085889
[22:55:07.384] iteration 11680 : model1 loss : 0.048007 model2 loss : 0.047161
[22:55:08.083] iteration 11681 : model1 loss : 0.034241 model2 loss : 0.037007
[22:55:08.787] iteration 11682 : model1 loss : 0.025901 model2 loss : 0.033003
[22:55:09.472] iteration 11683 : model1 loss : 0.050001 model2 loss : 0.031795
[22:55:10.144] iteration 11684 : model1 loss : 0.038071 model2 loss : 0.034018
[22:55:10.854] iteration 11685 : model1 loss : 0.018920 model2 loss : 0.029196
[22:55:11.553] iteration 11686 : model1 loss : 0.023809 model2 loss : 0.025501
[22:55:12.296] iteration 11687 : model1 loss : 0.023357 model2 loss : 0.024215
[22:55:13.064] iteration 11688 : model1 loss : 0.027436 model2 loss : 0.030969
[22:55:13.827] iteration 11689 : model1 loss : 0.021617 model2 loss : 0.021222
[22:55:14.544] iteration 11690 : model1 loss : 0.032513 model2 loss : 0.037684
[22:55:15.279] iteration 11691 : model1 loss : 0.024868 model2 loss : 0.026743
[22:55:15.996] iteration 11692 : model1 loss : 0.021206 model2 loss : 0.025149
[22:55:16.656] iteration 11693 : model1 loss : 0.021228 model2 loss : 0.022365
[22:55:17.372] iteration 11694 : model1 loss : 0.024810 model2 loss : 0.024014
[22:55:18.068] iteration 11695 : model1 loss : 0.018949 model2 loss : 0.020277
[22:55:18.767] iteration 11696 : model1 loss : 0.020435 model2 loss : 0.019231
[22:55:19.509] iteration 11697 : model1 loss : 0.021450 model2 loss : 0.020689
[22:55:20.215] iteration 11698 : model1 loss : 0.031387 model2 loss : 0.029536
[22:55:20.946] iteration 11699 : model1 loss : 0.017783 model2 loss : 0.016238
[22:55:21.634] iteration 11700 : model1 loss : 0.024964 model2 loss : 0.022739
[22:55:22.336] iteration 11701 : model1 loss : 0.031236 model2 loss : 0.031017
[22:55:23.027] iteration 11702 : model1 loss : 0.028746 model2 loss : 0.030167
[22:55:23.760] iteration 11703 : model1 loss : 0.030878 model2 loss : 0.028488
[22:55:24.544] iteration 11704 : model1 loss : 0.039459 model2 loss : 0.053180
[22:55:25.263] iteration 11705 : model1 loss : 0.032105 model2 loss : 0.039215
[22:55:25.954] iteration 11706 : model1 loss : 0.019518 model2 loss : 0.017802
[22:55:26.647] iteration 11707 : model1 loss : 0.019877 model2 loss : 0.020794
[22:55:27.380] iteration 11708 : model1 loss : 0.020169 model2 loss : 0.019560
[22:55:28.152] iteration 11709 : model1 loss : 0.018944 model2 loss : 0.019344
[22:55:29.003] iteration 11710 : model1 loss : 0.022401 model2 loss : 0.023573
[22:55:29.772] iteration 11711 : model1 loss : 0.023295 model2 loss : 0.026769
[22:55:30.593] iteration 11712 : model1 loss : 0.018120 model2 loss : 0.024981
[22:55:31.304] iteration 11713 : model1 loss : 0.024382 model2 loss : 0.023069
[22:55:32.001] iteration 11714 : model1 loss : 0.026770 model2 loss : 0.019401
[22:55:32.759] iteration 11715 : model1 loss : 0.021070 model2 loss : 0.024401
[22:55:33.478] iteration 11716 : model1 loss : 0.031040 model2 loss : 0.040044
[22:55:34.156] iteration 11717 : model1 loss : 0.020446 model2 loss : 0.021793
[22:55:34.851] iteration 11718 : model1 loss : 0.034346 model2 loss : 0.038041
[22:55:35.517] iteration 11719 : model1 loss : 0.026321 model2 loss : 0.023627
[22:55:36.272] iteration 11720 : model1 loss : 0.026566 model2 loss : 0.026269
[22:55:36.961] iteration 11721 : model1 loss : 0.027327 model2 loss : 0.026454
[22:55:37.664] iteration 11722 : model1 loss : 0.019386 model2 loss : 0.019283
[22:55:38.369] iteration 11723 : model1 loss : 0.027479 model2 loss : 0.022315
[22:55:39.072] iteration 11724 : model1 loss : 0.024156 model2 loss : 0.020580
[22:55:39.760] iteration 11725 : model1 loss : 0.019796 model2 loss : 0.019265
[22:55:40.494] iteration 11726 : model1 loss : 0.032851 model2 loss : 0.035349
[22:55:41.220] iteration 11727 : model1 loss : 0.019693 model2 loss : 0.020388
[22:55:41.913] iteration 11728 : model1 loss : 0.029139 model2 loss : 0.029381
[22:55:42.584] iteration 11729 : model1 loss : 0.025894 model2 loss : 0.024674
[22:55:43.262] iteration 11730 : model1 loss : 0.031919 model2 loss : 0.028251
[22:55:43.937] iteration 11731 : model1 loss : 0.022091 model2 loss : 0.024201
[22:55:44.689] iteration 11732 : model1 loss : 0.020187 model2 loss : 0.020458
[22:55:45.374] iteration 11733 : model1 loss : 0.028814 model2 loss : 0.027822
[22:55:46.038] iteration 11734 : model1 loss : 0.028956 model2 loss : 0.024300
[22:55:46.705] iteration 11735 : model1 loss : 0.028658 model2 loss : 0.076824
[22:55:47.452] iteration 11736 : model1 loss : 0.025118 model2 loss : 0.023992
[22:55:48.183] iteration 11737 : model1 loss : 0.016114 model2 loss : 0.015354
[22:55:48.915] iteration 11738 : model1 loss : 0.022567 model2 loss : 0.026508
[22:55:49.631] iteration 11739 : model1 loss : 0.035751 model2 loss : 0.032458
[22:55:50.343] iteration 11740 : model1 loss : 0.017341 model2 loss : 0.021286
[22:55:51.011] iteration 11741 : model1 loss : 0.015804 model2 loss : 0.015777
[22:55:51.700] iteration 11742 : model1 loss : 0.017920 model2 loss : 0.020035
[22:55:52.431] iteration 11743 : model1 loss : 0.048997 model2 loss : 0.050554
[22:55:53.129] iteration 11744 : model1 loss : 0.027725 model2 loss : 0.029672
[22:55:53.795] iteration 11745 : model1 loss : 0.022693 model2 loss : 0.021457
[22:55:54.539] iteration 11746 : model1 loss : 0.020231 model2 loss : 0.024369
[22:55:55.252] iteration 11747 : model1 loss : 0.017277 model2 loss : 0.015622
[22:55:55.953] iteration 11748 : model1 loss : 0.014718 model2 loss : 0.015579
[22:55:56.660] iteration 11749 : model1 loss : 0.023766 model2 loss : 0.023756
[22:55:57.379] iteration 11750 : model1 loss : 0.021405 model2 loss : 0.024077
[22:55:58.103] iteration 11751 : model1 loss : 0.057492 model2 loss : 0.052365
[22:55:58.817] iteration 11752 : model1 loss : 0.018278 model2 loss : 0.020010
[22:55:59.501] iteration 11753 : model1 loss : 0.021601 model2 loss : 0.023165
[22:56:00.197] iteration 11754 : model1 loss : 0.027769 model2 loss : 0.025703
[22:56:00.879] iteration 11755 : model1 loss : 0.026779 model2 loss : 0.025472
[22:56:01.550] iteration 11756 : model1 loss : 0.020273 model2 loss : 0.018748
[22:56:02.214] iteration 11757 : model1 loss : 0.025734 model2 loss : 0.025775
[22:56:02.890] iteration 11758 : model1 loss : 0.039704 model2 loss : 0.032712
[22:56:03.567] iteration 11759 : model1 loss : 0.029644 model2 loss : 0.028462
[22:56:04.239] iteration 11760 : model1 loss : 0.018276 model2 loss : 0.021334
[22:56:04.901] iteration 11761 : model1 loss : 0.043973 model2 loss : 0.043917
[22:56:05.574] iteration 11762 : model1 loss : 0.028800 model2 loss : 0.032396
[22:56:06.243] iteration 11763 : model1 loss : 0.021744 model2 loss : 0.019269
[22:56:06.919] iteration 11764 : model1 loss : 0.031494 model2 loss : 0.025801
[22:56:07.587] iteration 11765 : model1 loss : 0.019744 model2 loss : 0.018676
[22:56:08.251] iteration 11766 : model1 loss : 0.021433 model2 loss : 0.032412
[22:56:08.971] iteration 11767 : model1 loss : 0.059097 model2 loss : 0.057648
[22:56:09.792] iteration 11768 : model1 loss : 0.020163 model2 loss : 0.022452
[22:56:10.477] iteration 11769 : model1 loss : 0.019857 model2 loss : 0.020918
[22:56:11.145] iteration 11770 : model1 loss : 0.021130 model2 loss : 0.018643
[22:56:11.834] iteration 11771 : model1 loss : 0.018939 model2 loss : 0.017864
[22:56:12.503] iteration 11772 : model1 loss : 0.023941 model2 loss : 0.021063
[22:56:13.182] iteration 11773 : model1 loss : 0.042542 model2 loss : 0.040295
[22:56:13.854] iteration 11774 : model1 loss : 0.029350 model2 loss : 0.028823
[22:56:14.520] iteration 11775 : model1 loss : 0.022081 model2 loss : 0.023511
[22:56:15.199] iteration 11776 : model1 loss : 0.047557 model2 loss : 0.036562
[22:56:15.865] iteration 11777 : model1 loss : 0.018337 model2 loss : 0.018025
[22:56:16.551] iteration 11778 : model1 loss : 0.018280 model2 loss : 0.020001
[22:56:17.242] iteration 11779 : model1 loss : 0.022294 model2 loss : 0.020498
[22:56:17.950] iteration 11780 : model1 loss : 0.023444 model2 loss : 0.022954
[22:56:18.633] iteration 11781 : model1 loss : 0.021001 model2 loss : 0.019529
[22:56:19.309] iteration 11782 : model1 loss : 0.075003 model2 loss : 0.042070
[22:56:20.030] iteration 11783 : model1 loss : 0.024532 model2 loss : 0.029913
[22:56:20.817] iteration 11784 : model1 loss : 0.022493 model2 loss : 0.020139
[22:56:21.566] iteration 11785 : model1 loss : 0.024123 model2 loss : 0.029538
[22:56:22.275] iteration 11786 : model1 loss : 0.028409 model2 loss : 0.027720
[22:56:22.977] iteration 11787 : model1 loss : 0.147831 model2 loss : 0.146656
[22:56:23.672] iteration 11788 : model1 loss : 0.028896 model2 loss : 0.032520
[22:56:24.365] iteration 11789 : model1 loss : 0.022474 model2 loss : 0.023343
[22:56:25.094] iteration 11790 : model1 loss : 0.026370 model2 loss : 0.021574
[22:56:25.768] iteration 11791 : model1 loss : 0.024572 model2 loss : 0.024814
[22:56:26.445] iteration 11792 : model1 loss : 0.028827 model2 loss : 0.024156
[22:56:27.116] iteration 11793 : model1 loss : 0.025873 model2 loss : 0.028800
[22:56:27.774] iteration 11794 : model1 loss : 0.022332 model2 loss : 0.022612
[22:56:28.448] iteration 11795 : model1 loss : 0.047473 model2 loss : 0.061323
[22:56:29.119] iteration 11796 : model1 loss : 0.025766 model2 loss : 0.029685
[22:56:29.836] iteration 11797 : model1 loss : 0.022559 model2 loss : 0.018105
[22:56:30.529] iteration 11798 : model1 loss : 0.034468 model2 loss : 0.037094
[22:56:31.216] iteration 11799 : model1 loss : 0.035109 model2 loss : 0.034966
[22:56:31.923] iteration 11800 : model1 loss : 0.024243 model2 loss : 0.026318
[22:56:53.940] iteration 11800 : model1_mean_dice : 0.821640 model1_mean_hd95 : 7.502847
[22:57:13.723] iteration 11800 : model2_mean_dice : 0.849382 model2_mean_hd95 : 9.822541
[22:57:14.426] iteration 11801 : model1 loss : 0.023565 model2 loss : 0.022364
[22:57:15.091] iteration 11802 : model1 loss : 0.020820 model2 loss : 0.021457
[22:57:15.825] iteration 11803 : model1 loss : 0.018865 model2 loss : 0.023827
[22:57:16.523] iteration 11804 : model1 loss : 0.024314 model2 loss : 0.023186
[22:57:17.233] iteration 11805 : model1 loss : 0.017892 model2 loss : 0.017595
[22:57:17.942] iteration 11806 : model1 loss : 0.029245 model2 loss : 0.110727
[22:57:18.621] iteration 11807 : model1 loss : 0.026865 model2 loss : 0.021650
[22:57:19.307] iteration 11808 : model1 loss : 0.029847 model2 loss : 0.027037
[22:57:20.003] iteration 11809 : model1 loss : 0.018551 model2 loss : 0.014162
[22:57:20.677] iteration 11810 : model1 loss : 0.028875 model2 loss : 0.032015
[22:57:21.364] iteration 11811 : model1 loss : 0.019882 model2 loss : 0.018361
[22:57:22.118] iteration 11812 : model1 loss : 0.024168 model2 loss : 0.022910
[22:57:22.822] iteration 11813 : model1 loss : 0.021466 model2 loss : 0.021946
[22:57:23.494] iteration 11814 : model1 loss : 0.031274 model2 loss : 0.028426
[22:57:24.177] iteration 11815 : model1 loss : 0.017274 model2 loss : 0.016478
[22:57:24.911] iteration 11816 : model1 loss : 0.021270 model2 loss : 0.022748
[22:57:25.669] iteration 11817 : model1 loss : 0.034160 model2 loss : 0.052105
[22:57:26.347] iteration 11818 : model1 loss : 0.028156 model2 loss : 0.027526
[22:57:27.017] iteration 11819 : model1 loss : 0.034505 model2 loss : 0.021592
[22:57:27.694] iteration 11820 : model1 loss : 0.031558 model2 loss : 0.030239
[22:57:28.356] iteration 11821 : model1 loss : 0.028977 model2 loss : 0.028494
[22:57:29.017] iteration 11822 : model1 loss : 0.021110 model2 loss : 0.022393
[22:57:29.676] iteration 11823 : model1 loss : 0.022049 model2 loss : 0.021413
[22:57:30.393] iteration 11824 : model1 loss : 0.020467 model2 loss : 0.022822
[22:57:31.136] iteration 11825 : model1 loss : 0.021750 model2 loss : 0.024396
[22:57:31.811] iteration 11826 : model1 loss : 0.016185 model2 loss : 0.018196
[22:57:32.489] iteration 11827 : model1 loss : 0.030269 model2 loss : 0.027305
[22:57:33.189] iteration 11828 : model1 loss : 0.035791 model2 loss : 0.029062
[22:57:33.944] iteration 11829 : model1 loss : 0.027363 model2 loss : 0.025147
[22:57:34.638] iteration 11830 : model1 loss : 0.024075 model2 loss : 0.022235
[22:57:35.329] iteration 11831 : model1 loss : 0.023077 model2 loss : 0.038289
[22:57:36.071] iteration 11832 : model1 loss : 0.018290 model2 loss : 0.017953
[22:57:36.827] iteration 11833 : model1 loss : 0.025714 model2 loss : 0.027841
[22:57:37.521] iteration 11834 : model1 loss : 0.018859 model2 loss : 0.018962
[22:57:38.213] iteration 11835 : model1 loss : 0.032567 model2 loss : 0.028089
[22:57:38.998] iteration 11836 : model1 loss : 0.017809 model2 loss : 0.020553
[22:57:39.694] iteration 11837 : model1 loss : 0.023960 model2 loss : 0.021587
[22:57:40.410] iteration 11838 : model1 loss : 0.023635 model2 loss : 0.025645
[22:57:41.105] iteration 11839 : model1 loss : 0.025873 model2 loss : 0.026214
[22:57:41.815] iteration 11840 : model1 loss : 0.017834 model2 loss : 0.016438
[22:57:42.516] iteration 11841 : model1 loss : 0.033093 model2 loss : 0.030351
[22:57:43.194] iteration 11842 : model1 loss : 0.025604 model2 loss : 0.025162
[22:57:43.885] iteration 11843 : model1 loss : 0.024590 model2 loss : 0.021388
[22:57:44.585] iteration 11844 : model1 loss : 0.024352 model2 loss : 0.022813
[22:57:45.341] iteration 11845 : model1 loss : 0.024416 model2 loss : 0.026667
[22:57:46.038] iteration 11846 : model1 loss : 0.016878 model2 loss : 0.018235
[22:57:46.705] iteration 11847 : model1 loss : 0.020255 model2 loss : 0.018908
[22:57:47.393] iteration 11848 : model1 loss : 0.018054 model2 loss : 0.017945
[22:57:48.081] iteration 11849 : model1 loss : 0.019423 model2 loss : 0.019356
[22:57:48.853] iteration 11850 : model1 loss : 0.022627 model2 loss : 0.028538
[22:57:49.651] iteration 11851 : model1 loss : 0.018741 model2 loss : 0.020104
[22:57:50.350] iteration 11852 : model1 loss : 0.023843 model2 loss : 0.022877
[22:57:51.037] iteration 11853 : model1 loss : 0.029384 model2 loss : 0.026941
[22:57:51.714] iteration 11854 : model1 loss : 0.027770 model2 loss : 0.026145
[22:57:52.460] iteration 11855 : model1 loss : 0.015359 model2 loss : 0.015824
[22:57:53.201] iteration 11856 : model1 loss : 0.020057 model2 loss : 0.021435
[22:57:53.885] iteration 11857 : model1 loss : 0.016871 model2 loss : 0.018900
[22:57:54.611] iteration 11858 : model1 loss : 0.018448 model2 loss : 0.019678
[22:57:55.397] iteration 11859 : model1 loss : 0.021217 model2 loss : 0.021832
[22:57:56.091] iteration 11860 : model1 loss : 0.028705 model2 loss : 0.054489
[22:57:56.788] iteration 11861 : model1 loss : 0.043880 model2 loss : 0.041166
[22:57:57.451] iteration 11862 : model1 loss : 0.018941 model2 loss : 0.021432
[22:57:58.132] iteration 11863 : model1 loss : 0.017769 model2 loss : 0.017373
[22:57:58.904] iteration 11864 : model1 loss : 0.030183 model2 loss : 0.023642
[22:57:59.598] iteration 11865 : model1 loss : 0.025611 model2 loss : 0.028412
[22:58:00.277] iteration 11866 : model1 loss : 0.027389 model2 loss : 0.027726
[22:58:01.023] iteration 11867 : model1 loss : 0.021427 model2 loss : 0.019918
[22:58:01.706] iteration 11868 : model1 loss : 0.015433 model2 loss : 0.017107
[22:58:02.376] iteration 11869 : model1 loss : 0.022258 model2 loss : 0.021886
[22:58:03.066] iteration 11870 : model1 loss : 0.027210 model2 loss : 0.028819
[22:58:03.768] iteration 11871 : model1 loss : 0.019192 model2 loss : 0.019727
[22:58:04.462] iteration 11872 : model1 loss : 0.019227 model2 loss : 0.021389
[22:58:05.141] iteration 11873 : model1 loss : 0.071254 model2 loss : 0.095156
[22:58:05.809] iteration 11874 : model1 loss : 0.026689 model2 loss : 0.026982
[22:58:06.561] iteration 11875 : model1 loss : 0.020875 model2 loss : 0.020448
[22:58:07.250] iteration 11876 : model1 loss : 0.025190 model2 loss : 0.025718
[22:58:07.979] iteration 11877 : model1 loss : 0.019814 model2 loss : 0.020885
[22:58:08.674] iteration 11878 : model1 loss : 0.017554 model2 loss : 0.017194
[22:58:09.359] iteration 11879 : model1 loss : 0.024475 model2 loss : 0.022795
[22:58:10.051] iteration 11880 : model1 loss : 0.021608 model2 loss : 0.023880
[22:58:10.730] iteration 11881 : model1 loss : 0.022582 model2 loss : 0.022021
[22:58:11.467] iteration 11882 : model1 loss : 0.019319 model2 loss : 0.021332
[22:58:12.178] iteration 11883 : model1 loss : 0.025325 model2 loss : 0.024141
[22:58:12.919] iteration 11884 : model1 loss : 0.030877 model2 loss : 0.035213
[22:58:13.662] iteration 11885 : model1 loss : 0.029787 model2 loss : 0.027407
[22:58:14.390] iteration 11886 : model1 loss : 0.024075 model2 loss : 0.023652
[22:58:15.066] iteration 11887 : model1 loss : 0.029008 model2 loss : 0.030592
[22:58:15.743] iteration 11888 : model1 loss : 0.018164 model2 loss : 0.018119
[22:58:16.433] iteration 11889 : model1 loss : 0.023693 model2 loss : 0.030715
[22:58:17.114] iteration 11890 : model1 loss : 0.024713 model2 loss : 0.025448
[22:58:17.791] iteration 11891 : model1 loss : 0.028243 model2 loss : 0.032185
[22:58:18.517] iteration 11892 : model1 loss : 0.026199 model2 loss : 0.019549
[22:58:19.231] iteration 11893 : model1 loss : 0.024836 model2 loss : 0.027883
[22:58:19.947] iteration 11894 : model1 loss : 0.040792 model2 loss : 0.040885
[22:58:20.615] iteration 11895 : model1 loss : 0.019882 model2 loss : 0.019152
[22:58:21.306] iteration 11896 : model1 loss : 0.019687 model2 loss : 0.020743
[22:58:21.964] iteration 11897 : model1 loss : 0.024631 model2 loss : 0.027515
[22:58:22.653] iteration 11898 : model1 loss : 0.037763 model2 loss : 0.034653
[22:58:23.334] iteration 11899 : model1 loss : 0.031423 model2 loss : 0.031682
[22:58:23.994] iteration 11900 : model1 loss : 0.022911 model2 loss : 0.025951
[22:58:24.711] iteration 11901 : model1 loss : 0.018651 model2 loss : 0.019412
[22:58:25.380] iteration 11902 : model1 loss : 0.042649 model2 loss : 0.038265
[22:58:26.055] iteration 11903 : model1 loss : 0.018719 model2 loss : 0.018681
[22:58:26.725] iteration 11904 : model1 loss : 0.028436 model2 loss : 0.032923
[22:58:27.404] iteration 11905 : model1 loss : 0.021430 model2 loss : 0.020240
[22:58:28.086] iteration 11906 : model1 loss : 0.015082 model2 loss : 0.015296
[22:58:28.805] iteration 11907 : model1 loss : 0.024196 model2 loss : 0.022032
[22:58:29.526] iteration 11908 : model1 loss : 0.014364 model2 loss : 0.018672
[22:58:30.288] iteration 11909 : model1 loss : 0.029795 model2 loss : 0.030351
[22:58:31.018] iteration 11910 : model1 loss : 0.023201 model2 loss : 0.027772
[22:58:31.710] iteration 11911 : model1 loss : 0.024326 model2 loss : 0.026127
[22:58:32.385] iteration 11912 : model1 loss : 0.016824 model2 loss : 0.015186
[22:58:33.125] iteration 11913 : model1 loss : 0.022648 model2 loss : 0.023243
[22:58:33.803] iteration 11914 : model1 loss : 0.019613 model2 loss : 0.020396
[22:58:34.509] iteration 11915 : model1 loss : 0.024863 model2 loss : 0.026905
[22:58:35.232] iteration 11916 : model1 loss : 0.020341 model2 loss : 0.020141
[22:58:35.909] iteration 11917 : model1 loss : 0.022209 model2 loss : 0.021626
[22:58:36.577] iteration 11918 : model1 loss : 0.143714 model2 loss : 0.144215
[22:58:37.242] iteration 11919 : model1 loss : 0.024118 model2 loss : 0.025717
[22:58:37.946] iteration 11920 : model1 loss : 0.018481 model2 loss : 0.018409
[22:58:38.704] iteration 11921 : model1 loss : 0.022972 model2 loss : 0.023670
[22:58:39.415] iteration 11922 : model1 loss : 0.020740 model2 loss : 0.019574
[22:58:40.180] iteration 11923 : model1 loss : 0.022871 model2 loss : 0.019921
[22:58:40.947] iteration 11924 : model1 loss : 0.018186 model2 loss : 0.018296
[22:58:41.677] iteration 11925 : model1 loss : 0.028102 model2 loss : 0.024356
[22:58:42.363] iteration 11926 : model1 loss : 0.062069 model2 loss : 0.072729
[22:58:43.037] iteration 11927 : model1 loss : 0.136811 model2 loss : 0.135855
[22:58:43.706] iteration 11928 : model1 loss : 0.058034 model2 loss : 0.056933
[22:58:44.402] iteration 11929 : model1 loss : 0.024942 model2 loss : 0.024572
[22:58:45.097] iteration 11930 : model1 loss : 0.022698 model2 loss : 0.026520
[22:58:45.783] iteration 11931 : model1 loss : 0.023912 model2 loss : 0.021369
[22:58:46.468] iteration 11932 : model1 loss : 0.018931 model2 loss : 0.019373
[22:58:47.201] iteration 11933 : model1 loss : 0.028191 model2 loss : 0.025100
[22:58:47.905] iteration 11934 : model1 loss : 0.038260 model2 loss : 0.024681
[22:58:48.569] iteration 11935 : model1 loss : 0.017836 model2 loss : 0.018274
[22:58:49.230] iteration 11936 : model1 loss : 0.024862 model2 loss : 0.024129
[22:58:49.899] iteration 11937 : model1 loss : 0.045223 model2 loss : 0.039414
[22:58:50.573] iteration 11938 : model1 loss : 0.021417 model2 loss : 0.019339
[22:58:51.252] iteration 11939 : model1 loss : 0.024661 model2 loss : 0.018883
[22:58:51.918] iteration 11940 : model1 loss : 0.028398 model2 loss : 0.024983
[22:58:52.607] iteration 11941 : model1 loss : 0.021961 model2 loss : 0.020490
[22:58:53.349] iteration 11942 : model1 loss : 0.022057 model2 loss : 0.025179
[22:58:54.094] iteration 11943 : model1 loss : 0.027870 model2 loss : 0.029121
[22:58:54.842] iteration 11944 : model1 loss : 0.026827 model2 loss : 0.025839
[22:58:55.558] iteration 11945 : model1 loss : 0.030911 model2 loss : 0.035284
[22:58:56.302] iteration 11946 : model1 loss : 0.022178 model2 loss : 0.024448
[22:58:57.022] iteration 11947 : model1 loss : 0.057531 model2 loss : 0.058627
[22:58:57.784] iteration 11948 : model1 loss : 0.041657 model2 loss : 0.036924
[22:58:58.519] iteration 11949 : model1 loss : 0.019959 model2 loss : 0.021083
[22:58:59.265] iteration 11950 : model1 loss : 0.023251 model2 loss : 0.025620
[22:59:00.093] iteration 11951 : model1 loss : 0.024683 model2 loss : 0.025181
[22:59:00.790] iteration 11952 : model1 loss : 0.021374 model2 loss : 0.023341
[22:59:01.533] iteration 11953 : model1 loss : 0.017279 model2 loss : 0.018389
[22:59:02.350] iteration 11954 : model1 loss : 0.016755 model2 loss : 0.017296
[22:59:03.028] iteration 11955 : model1 loss : 0.019300 model2 loss : 0.018155
[22:59:03.771] iteration 11956 : model1 loss : 0.020814 model2 loss : 0.023397
[22:59:04.458] iteration 11957 : model1 loss : 0.033337 model2 loss : 0.025268
[22:59:05.125] iteration 11958 : model1 loss : 0.019238 model2 loss : 0.019358
[22:59:05.835] iteration 11959 : model1 loss : 0.020128 model2 loss : 0.020547
[22:59:06.506] iteration 11960 : model1 loss : 0.021509 model2 loss : 0.022932
[22:59:07.189] iteration 11961 : model1 loss : 0.028695 model2 loss : 0.022305
[22:59:07.893] iteration 11962 : model1 loss : 0.037543 model2 loss : 0.032601
[22:59:08.578] iteration 11963 : model1 loss : 0.024222 model2 loss : 0.021768
[22:59:09.291] iteration 11964 : model1 loss : 0.149197 model2 loss : 0.149087
[22:59:09.982] iteration 11965 : model1 loss : 0.019925 model2 loss : 0.022515
[22:59:10.689] iteration 11966 : model1 loss : 0.028337 model2 loss : 0.023020
[22:59:11.369] iteration 11967 : model1 loss : 0.027086 model2 loss : 0.025106
[22:59:12.046] iteration 11968 : model1 loss : 0.024045 model2 loss : 0.028128
[22:59:12.706] iteration 11969 : model1 loss : 0.019481 model2 loss : 0.018655
[22:59:13.371] iteration 11970 : model1 loss : 0.019480 model2 loss : 0.017490
[22:59:14.028] iteration 11971 : model1 loss : 0.019142 model2 loss : 0.020002
[22:59:14.698] iteration 11972 : model1 loss : 0.026461 model2 loss : 0.024620
[22:59:15.361] iteration 11973 : model1 loss : 0.032048 model2 loss : 0.030868
[22:59:16.034] iteration 11974 : model1 loss : 0.026377 model2 loss : 0.029502
[22:59:16.718] iteration 11975 : model1 loss : 0.025727 model2 loss : 0.025626
[22:59:17.392] iteration 11976 : model1 loss : 0.032597 model2 loss : 0.030523
[22:59:18.074] iteration 11977 : model1 loss : 0.034261 model2 loss : 0.036814
[22:59:18.750] iteration 11978 : model1 loss : 0.022055 model2 loss : 0.024153
[22:59:19.454] iteration 11979 : model1 loss : 0.026494 model2 loss : 0.026340
[22:59:20.139] iteration 11980 : model1 loss : 0.025837 model2 loss : 0.028114
[22:59:20.819] iteration 11981 : model1 loss : 0.020313 model2 loss : 0.022344
[22:59:21.512] iteration 11982 : model1 loss : 0.023583 model2 loss : 0.024691
[22:59:22.176] iteration 11983 : model1 loss : 0.029696 model2 loss : 0.033913
[22:59:22.867] iteration 11984 : model1 loss : 0.033946 model2 loss : 0.028930
[22:59:23.546] iteration 11985 : model1 loss : 0.023169 model2 loss : 0.021124
[22:59:24.227] iteration 11986 : model1 loss : 0.030308 model2 loss : 0.029577
[22:59:24.892] iteration 11987 : model1 loss : 0.021112 model2 loss : 0.021950
[22:59:25.568] iteration 11988 : model1 loss : 0.019138 model2 loss : 0.021370
[22:59:26.243] iteration 11989 : model1 loss : 0.071739 model2 loss : 0.056964
[22:59:26.945] iteration 11990 : model1 loss : 0.022790 model2 loss : 0.022714
[22:59:27.632] iteration 11991 : model1 loss : 0.023141 model2 loss : 0.021969
[22:59:28.466] iteration 11992 : model1 loss : 0.024675 model2 loss : 0.023524
[22:59:29.289] iteration 11993 : model1 loss : 0.085818 model2 loss : 0.039784
[22:59:30.001] iteration 11994 : model1 loss : 0.030082 model2 loss : 0.025745
[22:59:30.726] iteration 11995 : model1 loss : 0.026827 model2 loss : 0.026532
[22:59:31.425] iteration 11996 : model1 loss : 0.024416 model2 loss : 0.021527
[22:59:32.094] iteration 11997 : model1 loss : 0.032767 model2 loss : 0.030118
[22:59:32.760] iteration 11998 : model1 loss : 0.061158 model2 loss : 0.065781
[22:59:33.457] iteration 11999 : model1 loss : 0.034132 model2 loss : 0.031726
[22:59:34.203] iteration 12000 : model1 loss : 0.032747 model2 loss : 0.028236
[22:59:55.388] iteration 12000 : model1_mean_dice : 0.821746 model1_mean_hd95 : 14.489992
[23:00:13.624] iteration 12000 : model2_mean_dice : 0.858053 model2_mean_hd95 : 7.072604
[23:00:13.687] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_12000.pth
[23:00:13.747] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_12000.pth
[23:00:14.427] iteration 12001 : model1 loss : 0.025154 model2 loss : 0.022963
[23:00:15.101] iteration 12002 : model1 loss : 0.019580 model2 loss : 0.015484
[23:00:15.781] iteration 12003 : model1 loss : 0.035551 model2 loss : 0.028861
[23:00:16.461] iteration 12004 : model1 loss : 0.025494 model2 loss : 0.024683
[23:00:17.133] iteration 12005 : model1 loss : 0.041241 model2 loss : 0.035261
[23:00:17.793] iteration 12006 : model1 loss : 0.035978 model2 loss : 0.027621
[23:00:18.463] iteration 12007 : model1 loss : 0.021357 model2 loss : 0.020875
[23:00:19.116] iteration 12008 : model1 loss : 0.060711 model2 loss : 0.022366
[23:00:19.821] iteration 12009 : model1 loss : 0.030970 model2 loss : 0.025271
[23:00:20.506] iteration 12010 : model1 loss : 0.019420 model2 loss : 0.019109
[23:00:21.161] iteration 12011 : model1 loss : 0.029725 model2 loss : 0.023610
[23:00:21.814] iteration 12012 : model1 loss : 0.022151 model2 loss : 0.021950
[23:00:22.478] iteration 12013 : model1 loss : 0.020399 model2 loss : 0.019035
[23:00:23.132] iteration 12014 : model1 loss : 0.037683 model2 loss : 0.035665
[23:00:23.801] iteration 12015 : model1 loss : 0.036988 model2 loss : 0.031644
[23:00:24.460] iteration 12016 : model1 loss : 0.032496 model2 loss : 0.029462
[23:00:25.133] iteration 12017 : model1 loss : 0.075969 model2 loss : 0.033372
[23:00:25.804] iteration 12018 : model1 loss : 0.025687 model2 loss : 0.023832
[23:00:26.469] iteration 12019 : model1 loss : 0.068049 model2 loss : 0.071237
[23:00:27.146] iteration 12020 : model1 loss : 0.018845 model2 loss : 0.017449
[23:00:27.836] iteration 12021 : model1 loss : 0.025615 model2 loss : 0.024196
[23:00:28.503] iteration 12022 : model1 loss : 0.034008 model2 loss : 0.029791
[23:00:29.174] iteration 12023 : model1 loss : 0.025108 model2 loss : 0.022493
[23:00:29.853] iteration 12024 : model1 loss : 0.015364 model2 loss : 0.015589
[23:00:30.521] iteration 12025 : model1 loss : 0.021497 model2 loss : 0.033463
[23:00:31.198] iteration 12026 : model1 loss : 0.023711 model2 loss : 0.023472
[23:00:31.866] iteration 12027 : model1 loss : 0.023377 model2 loss : 0.024131
[23:00:32.534] iteration 12028 : model1 loss : 0.050030 model2 loss : 0.045152
[23:00:33.211] iteration 12029 : model1 loss : 0.023849 model2 loss : 0.028155
[23:00:33.925] iteration 12030 : model1 loss : 0.025114 model2 loss : 0.020726
[23:00:34.647] iteration 12031 : model1 loss : 0.020893 model2 loss : 0.024261
[23:00:35.377] iteration 12032 : model1 loss : 0.036543 model2 loss : 0.034117
[23:00:36.093] iteration 12033 : model1 loss : 0.049213 model2 loss : 0.027461
[23:00:36.807] iteration 12034 : model1 loss : 0.027595 model2 loss : 0.027308
[23:00:37.476] iteration 12035 : model1 loss : 0.044305 model2 loss : 0.068390
[23:00:38.168] iteration 12036 : model1 loss : 0.020778 model2 loss : 0.020200
[23:00:38.843] iteration 12037 : model1 loss : 0.024628 model2 loss : 0.018373
[23:00:39.543] iteration 12038 : model1 loss : 0.024212 model2 loss : 0.025989
[23:00:40.229] iteration 12039 : model1 loss : 0.023460 model2 loss : 0.025861
[23:00:40.898] iteration 12040 : model1 loss : 0.020573 model2 loss : 0.018581
[23:00:41.707] iteration 12041 : model1 loss : 0.021961 model2 loss : 0.019362
[23:00:42.409] iteration 12042 : model1 loss : 0.019538 model2 loss : 0.017821
[23:00:43.115] iteration 12043 : model1 loss : 0.024173 model2 loss : 0.022465
[23:00:43.789] iteration 12044 : model1 loss : 0.028687 model2 loss : 0.028317
[23:00:44.459] iteration 12045 : model1 loss : 0.022124 model2 loss : 0.024536
[23:00:45.135] iteration 12046 : model1 loss : 0.027847 model2 loss : 0.030469
[23:00:45.806] iteration 12047 : model1 loss : 0.025772 model2 loss : 0.021503
[23:00:46.490] iteration 12048 : model1 loss : 0.024891 model2 loss : 0.025294
[23:00:47.200] iteration 12049 : model1 loss : 0.023551 model2 loss : 0.027252
[23:00:47.970] iteration 12050 : model1 loss : 0.021296 model2 loss : 0.020068
[23:00:48.702] iteration 12051 : model1 loss : 0.029589 model2 loss : 0.022570
[23:00:49.459] iteration 12052 : model1 loss : 0.018913 model2 loss : 0.018415
[23:00:50.170] iteration 12053 : model1 loss : 0.021079 model2 loss : 0.019195
[23:00:50.937] iteration 12054 : model1 loss : 0.020332 model2 loss : 0.021659
[23:00:51.642] iteration 12055 : model1 loss : 0.031292 model2 loss : 0.027154
[23:00:52.309] iteration 12056 : model1 loss : 0.020909 model2 loss : 0.016475
[23:00:53.001] iteration 12057 : model1 loss : 0.022313 model2 loss : 0.020511
[23:00:53.698] iteration 12058 : model1 loss : 0.043466 model2 loss : 0.033880
[23:00:54.377] iteration 12059 : model1 loss : 0.021962 model2 loss : 0.019184
[23:00:55.072] iteration 12060 : model1 loss : 0.030182 model2 loss : 0.030807
[23:00:55.797] iteration 12061 : model1 loss : 0.030856 model2 loss : 0.033953
[23:00:56.501] iteration 12062 : model1 loss : 0.026928 model2 loss : 0.024650
[23:00:57.208] iteration 12063 : model1 loss : 0.024300 model2 loss : 0.019869
[23:00:57.890] iteration 12064 : model1 loss : 0.035683 model2 loss : 0.027371
[23:00:58.571] iteration 12065 : model1 loss : 0.021651 model2 loss : 0.020449
[23:00:59.239] iteration 12066 : model1 loss : 0.020666 model2 loss : 0.017857
[23:00:59.909] iteration 12067 : model1 loss : 0.051679 model2 loss : 0.036406
[23:01:00.585] iteration 12068 : model1 loss : 0.040772 model2 loss : 0.025501
[23:01:01.244] iteration 12069 : model1 loss : 0.049787 model2 loss : 0.044288
[23:01:01.921] iteration 12070 : model1 loss : 0.024037 model2 loss : 0.023634
[23:01:02.607] iteration 12071 : model1 loss : 0.032557 model2 loss : 0.034697
[23:01:03.279] iteration 12072 : model1 loss : 0.023257 model2 loss : 0.025140
[23:01:03.948] iteration 12073 : model1 loss : 0.030907 model2 loss : 0.030158
[23:01:04.620] iteration 12074 : model1 loss : 0.023239 model2 loss : 0.022297
[23:01:05.290] iteration 12075 : model1 loss : 0.030312 model2 loss : 0.031283
[23:01:05.974] iteration 12076 : model1 loss : 0.025377 model2 loss : 0.024121
[23:01:06.645] iteration 12077 : model1 loss : 0.019783 model2 loss : 0.017080
[23:01:07.316] iteration 12078 : model1 loss : 0.025801 model2 loss : 0.024038
[23:01:07.992] iteration 12079 : model1 loss : 0.019296 model2 loss : 0.018927
[23:01:08.667] iteration 12080 : model1 loss : 0.022914 model2 loss : 0.019791
[23:01:09.337] iteration 12081 : model1 loss : 0.041730 model2 loss : 0.053707
[23:01:10.014] iteration 12082 : model1 loss : 0.017530 model2 loss : 0.017081
[23:01:10.694] iteration 12083 : model1 loss : 0.022242 model2 loss : 0.021561
[23:01:11.431] iteration 12084 : model1 loss : 0.024456 model2 loss : 0.022209
[23:01:12.115] iteration 12085 : model1 loss : 0.034528 model2 loss : 0.024906
[23:01:12.801] iteration 12086 : model1 loss : 0.024644 model2 loss : 0.023353
[23:01:13.495] iteration 12087 : model1 loss : 0.019936 model2 loss : 0.018845
[23:01:14.222] iteration 12088 : model1 loss : 0.071956 model2 loss : 0.057790
[23:01:14.950] iteration 12089 : model1 loss : 0.028029 model2 loss : 0.029369
[23:01:15.633] iteration 12090 : model1 loss : 0.018960 model2 loss : 0.018550
[23:01:16.311] iteration 12091 : model1 loss : 0.027061 model2 loss : 0.027705
[23:01:16.992] iteration 12092 : model1 loss : 0.030592 model2 loss : 0.023935
[23:01:17.668] iteration 12093 : model1 loss : 0.031305 model2 loss : 0.027925
[23:01:18.347] iteration 12094 : model1 loss : 0.059737 model2 loss : 0.065353
[23:01:19.043] iteration 12095 : model1 loss : 0.028954 model2 loss : 0.025133
[23:01:19.796] iteration 12096 : model1 loss : 0.023439 model2 loss : 0.022036
[23:01:20.507] iteration 12097 : model1 loss : 0.036126 model2 loss : 0.043059
[23:01:21.230] iteration 12098 : model1 loss : 0.026211 model2 loss : 0.029710
[23:01:21.950] iteration 12099 : model1 loss : 0.037196 model2 loss : 0.041699
[23:01:22.723] iteration 12100 : model1 loss : 0.018333 model2 loss : 0.018032
[23:01:23.491] iteration 12101 : model1 loss : 0.022135 model2 loss : 0.020047
[23:01:24.175] iteration 12102 : model1 loss : 0.049043 model2 loss : 0.023493
[23:01:24.848] iteration 12103 : model1 loss : 0.021229 model2 loss : 0.020304
[23:01:25.536] iteration 12104 : model1 loss : 0.042049 model2 loss : 0.042806
[23:01:26.226] iteration 12105 : model1 loss : 0.025795 model2 loss : 0.026073
[23:01:26.910] iteration 12106 : model1 loss : 0.038693 model2 loss : 0.033418
[23:01:27.580] iteration 12107 : model1 loss : 0.026935 model2 loss : 0.025226
[23:01:28.260] iteration 12108 : model1 loss : 0.021648 model2 loss : 0.022969
[23:01:28.946] iteration 12109 : model1 loss : 0.062131 model2 loss : 0.033345
[23:01:29.621] iteration 12110 : model1 loss : 0.021493 model2 loss : 0.020894
[23:01:30.336] iteration 12111 : model1 loss : 0.024167 model2 loss : 0.024827
[23:01:31.002] iteration 12112 : model1 loss : 0.024656 model2 loss : 0.024762
[23:01:31.676] iteration 12113 : model1 loss : 0.029805 model2 loss : 0.023727
[23:01:32.350] iteration 12114 : model1 loss : 0.037246 model2 loss : 0.046119
[23:01:33.048] iteration 12115 : model1 loss : 0.028711 model2 loss : 0.023846
[23:01:33.781] iteration 12116 : model1 loss : 0.022980 model2 loss : 0.020558
[23:01:34.498] iteration 12117 : model1 loss : 0.025807 model2 loss : 0.024141
[23:01:35.179] iteration 12118 : model1 loss : 0.034859 model2 loss : 0.030287
[23:01:35.855] iteration 12119 : model1 loss : 0.027523 model2 loss : 0.028908
[23:01:36.534] iteration 12120 : model1 loss : 0.023892 model2 loss : 0.021258
[23:01:37.215] iteration 12121 : model1 loss : 0.024709 model2 loss : 0.022984
[23:01:37.882] iteration 12122 : model1 loss : 0.014916 model2 loss : 0.014925
[23:01:38.560] iteration 12123 : model1 loss : 0.023003 model2 loss : 0.018580
[23:01:39.227] iteration 12124 : model1 loss : 0.022013 model2 loss : 0.022331
[23:01:39.892] iteration 12125 : model1 loss : 0.022057 model2 loss : 0.021871
[23:01:40.595] iteration 12126 : model1 loss : 0.023526 model2 loss : 0.026850
[23:01:41.289] iteration 12127 : model1 loss : 0.024264 model2 loss : 0.028627
[23:01:41.966] iteration 12128 : model1 loss : 0.024112 model2 loss : 0.023777
[23:01:42.662] iteration 12129 : model1 loss : 0.021106 model2 loss : 0.022604
[23:01:43.336] iteration 12130 : model1 loss : 0.027017 model2 loss : 0.025517
[23:01:44.005] iteration 12131 : model1 loss : 0.030157 model2 loss : 0.023412
[23:01:44.689] iteration 12132 : model1 loss : 0.024626 model2 loss : 0.022994
[23:01:45.367] iteration 12133 : model1 loss : 0.151374 model2 loss : 0.145711
[23:01:46.048] iteration 12134 : model1 loss : 0.024048 model2 loss : 0.020458
[23:01:46.738] iteration 12135 : model1 loss : 0.018132 model2 loss : 0.019513
[23:01:47.412] iteration 12136 : model1 loss : 0.018841 model2 loss : 0.018661
[23:01:48.134] iteration 12137 : model1 loss : 0.028899 model2 loss : 0.022982
[23:01:48.874] iteration 12138 : model1 loss : 0.020421 model2 loss : 0.020307
[23:01:49.683] iteration 12139 : model1 loss : 0.021526 model2 loss : 0.020606
[23:01:50.396] iteration 12140 : model1 loss : 0.023973 model2 loss : 0.024709
[23:01:51.083] iteration 12141 : model1 loss : 0.026506 model2 loss : 0.019054
[23:01:51.788] iteration 12142 : model1 loss : 0.016630 model2 loss : 0.016416
[23:01:52.474] iteration 12143 : model1 loss : 0.036151 model2 loss : 0.031292
[23:01:53.205] iteration 12144 : model1 loss : 0.023311 model2 loss : 0.020416
[23:01:53.913] iteration 12145 : model1 loss : 0.018498 model2 loss : 0.018269
[23:01:54.616] iteration 12146 : model1 loss : 0.026099 model2 loss : 0.025767
[23:01:55.340] iteration 12147 : model1 loss : 0.041844 model2 loss : 0.045711
[23:01:56.055] iteration 12148 : model1 loss : 0.037571 model2 loss : 0.026719
[23:01:56.758] iteration 12149 : model1 loss : 0.023672 model2 loss : 0.028285
[23:01:57.452] iteration 12150 : model1 loss : 0.026693 model2 loss : 0.023490
[23:01:58.201] iteration 12151 : model1 loss : 0.021820 model2 loss : 0.023724
[23:01:58.871] iteration 12152 : model1 loss : 0.025610 model2 loss : 0.021735
[23:01:59.542] iteration 12153 : model1 loss : 0.022473 model2 loss : 0.021090
[23:02:00.268] iteration 12154 : model1 loss : 0.030947 model2 loss : 0.025869
[23:02:00.940] iteration 12155 : model1 loss : 0.025328 model2 loss : 0.023845
[23:02:01.658] iteration 12156 : model1 loss : 0.019934 model2 loss : 0.019931
[23:02:02.344] iteration 12157 : model1 loss : 0.030053 model2 loss : 0.031368
[23:02:03.036] iteration 12158 : model1 loss : 0.035992 model2 loss : 0.033994
[23:02:03.810] iteration 12159 : model1 loss : 0.019298 model2 loss : 0.021631
[23:02:04.494] iteration 12160 : model1 loss : 0.027187 model2 loss : 0.026086
[23:02:05.203] iteration 12161 : model1 loss : 0.020957 model2 loss : 0.021512
[23:02:06.064] iteration 12162 : model1 loss : 0.020989 model2 loss : 0.024245
[23:02:06.896] iteration 12163 : model1 loss : 0.025389 model2 loss : 0.027120
[23:02:07.599] iteration 12164 : model1 loss : 0.027764 model2 loss : 0.027146
[23:02:08.286] iteration 12165 : model1 loss : 0.023732 model2 loss : 0.021203
[23:02:08.994] iteration 12166 : model1 loss : 0.025313 model2 loss : 0.027135
[23:02:09.709] iteration 12167 : model1 loss : 0.024371 model2 loss : 0.024170
[23:02:10.398] iteration 12168 : model1 loss : 0.018971 model2 loss : 0.018268
[23:02:11.066] iteration 12169 : model1 loss : 0.019189 model2 loss : 0.017451
[23:02:11.754] iteration 12170 : model1 loss : 0.034710 model2 loss : 0.019047
[23:02:12.428] iteration 12171 : model1 loss : 0.025733 model2 loss : 0.022380
[23:02:13.090] iteration 12172 : model1 loss : 0.041118 model2 loss : 0.046148
[23:02:13.791] iteration 12173 : model1 loss : 0.022086 model2 loss : 0.021940
[23:02:14.502] iteration 12174 : model1 loss : 0.027371 model2 loss : 0.024003
[23:02:15.173] iteration 12175 : model1 loss : 0.023518 model2 loss : 0.025175
[23:02:15.849] iteration 12176 : model1 loss : 0.032891 model2 loss : 0.033875
[23:02:16.523] iteration 12177 : model1 loss : 0.027653 model2 loss : 0.024686
[23:02:17.209] iteration 12178 : model1 loss : 0.032195 model2 loss : 0.031781
[23:02:17.869] iteration 12179 : model1 loss : 0.016056 model2 loss : 0.018558
[23:02:18.549] iteration 12180 : model1 loss : 0.022210 model2 loss : 0.021683
[23:02:19.219] iteration 12181 : model1 loss : 0.025314 model2 loss : 0.024350
[23:02:19.889] iteration 12182 : model1 loss : 0.031813 model2 loss : 0.036300
[23:02:20.604] iteration 12183 : model1 loss : 0.021124 model2 loss : 0.023742
[23:02:21.288] iteration 12184 : model1 loss : 0.021984 model2 loss : 0.023300
[23:02:21.961] iteration 12185 : model1 loss : 0.031481 model2 loss : 0.028025
[23:02:22.656] iteration 12186 : model1 loss : 0.043116 model2 loss : 0.040193
[23:02:23.332] iteration 12187 : model1 loss : 0.020475 model2 loss : 0.020077
[23:02:23.992] iteration 12188 : model1 loss : 0.018996 model2 loss : 0.017650
[23:02:24.650] iteration 12189 : model1 loss : 0.034170 model2 loss : 0.041060
[23:02:25.325] iteration 12190 : model1 loss : 0.018379 model2 loss : 0.019719
[23:02:25.990] iteration 12191 : model1 loss : 0.025187 model2 loss : 0.021090
[23:02:26.668] iteration 12192 : model1 loss : 0.025757 model2 loss : 0.021619
[23:02:27.350] iteration 12193 : model1 loss : 0.029905 model2 loss : 0.029205
[23:02:28.031] iteration 12194 : model1 loss : 0.032352 model2 loss : 0.031606
[23:02:28.702] iteration 12195 : model1 loss : 0.025345 model2 loss : 0.025540
[23:02:29.427] iteration 12196 : model1 loss : 0.021186 model2 loss : 0.020520
[23:02:30.094] iteration 12197 : model1 loss : 0.022349 model2 loss : 0.022322
[23:02:30.769] iteration 12198 : model1 loss : 0.018058 model2 loss : 0.022341
[23:02:31.466] iteration 12199 : model1 loss : 0.016915 model2 loss : 0.017446
[23:02:32.229] iteration 12200 : model1 loss : 0.024396 model2 loss : 0.024679
[23:02:53.585] iteration 12200 : model1_mean_dice : 0.846035 model1_mean_hd95 : 8.129745
[23:03:13.177] iteration 12200 : model2_mean_dice : 0.861023 model2_mean_hd95 : 8.884768
[23:03:13.869] iteration 12201 : model1 loss : 0.022016 model2 loss : 0.024325
[23:03:14.528] iteration 12202 : model1 loss : 0.023009 model2 loss : 0.024380
[23:03:15.190] iteration 12203 : model1 loss : 0.030006 model2 loss : 0.029603
[23:03:15.849] iteration 12204 : model1 loss : 0.018970 model2 loss : 0.020138
[23:03:16.506] iteration 12205 : model1 loss : 0.022954 model2 loss : 0.026323
[23:03:17.168] iteration 12206 : model1 loss : 0.026233 model2 loss : 0.038355
[23:03:17.837] iteration 12207 : model1 loss : 0.140618 model2 loss : 0.139311
[23:03:18.489] iteration 12208 : model1 loss : 0.021839 model2 loss : 0.021459
[23:03:19.143] iteration 12209 : model1 loss : 0.026334 model2 loss : 0.026545
[23:03:19.807] iteration 12210 : model1 loss : 0.029485 model2 loss : 0.027252
[23:03:20.493] iteration 12211 : model1 loss : 0.039688 model2 loss : 0.033487
[23:03:21.183] iteration 12212 : model1 loss : 0.027256 model2 loss : 0.025020
[23:03:21.862] iteration 12213 : model1 loss : 0.015342 model2 loss : 0.016667
[23:03:22.533] iteration 12214 : model1 loss : 0.050110 model2 loss : 0.056568
[23:03:23.220] iteration 12215 : model1 loss : 0.028494 model2 loss : 0.033301
[23:03:23.879] iteration 12216 : model1 loss : 0.029873 model2 loss : 0.022354
[23:03:24.530] iteration 12217 : model1 loss : 0.030026 model2 loss : 0.031644
[23:03:25.185] iteration 12218 : model1 loss : 0.020003 model2 loss : 0.020001
[23:03:25.864] iteration 12219 : model1 loss : 0.024268 model2 loss : 0.023173
[23:03:26.548] iteration 12220 : model1 loss : 0.040608 model2 loss : 0.038533
[23:03:27.212] iteration 12221 : model1 loss : 0.024441 model2 loss : 0.025402
[23:03:27.871] iteration 12222 : model1 loss : 0.022675 model2 loss : 0.024054
[23:03:28.545] iteration 12223 : model1 loss : 0.021527 model2 loss : 0.018886
[23:03:29.276] iteration 12224 : model1 loss : 0.027491 model2 loss : 0.024075
[23:03:29.996] iteration 12225 : model1 loss : 0.021841 model2 loss : 0.022780
[23:03:30.670] iteration 12226 : model1 loss : 0.026403 model2 loss : 0.018820
[23:03:31.454] iteration 12227 : model1 loss : 0.023898 model2 loss : 0.028839
[23:03:32.275] iteration 12228 : model1 loss : 0.031649 model2 loss : 0.024705
[23:03:32.975] iteration 12229 : model1 loss : 0.049178 model2 loss : 0.020278
[23:03:33.684] iteration 12230 : model1 loss : 0.018149 model2 loss : 0.018119
[23:03:34.386] iteration 12231 : model1 loss : 0.018561 model2 loss : 0.017553
[23:03:35.088] iteration 12232 : model1 loss : 0.017918 model2 loss : 0.018384
[23:03:35.814] iteration 12233 : model1 loss : 0.022577 model2 loss : 0.024610
[23:03:36.563] iteration 12234 : model1 loss : 0.021305 model2 loss : 0.020417
[23:03:37.288] iteration 12235 : model1 loss : 0.018037 model2 loss : 0.017919
[23:03:37.955] iteration 12236 : model1 loss : 0.030054 model2 loss : 0.026713
[23:03:38.628] iteration 12237 : model1 loss : 0.027009 model2 loss : 0.027571
[23:03:39.340] iteration 12238 : model1 loss : 0.022213 model2 loss : 0.021568
[23:03:40.102] iteration 12239 : model1 loss : 0.024240 model2 loss : 0.026447
[23:03:40.874] iteration 12240 : model1 loss : 0.021943 model2 loss : 0.019349
[23:03:41.636] iteration 12241 : model1 loss : 0.025360 model2 loss : 0.021391
[23:03:42.355] iteration 12242 : model1 loss : 0.028022 model2 loss : 0.021939
[23:03:43.024] iteration 12243 : model1 loss : 0.027977 model2 loss : 0.026193
[23:03:43.741] iteration 12244 : model1 loss : 0.023911 model2 loss : 0.021285
[23:03:44.428] iteration 12245 : model1 loss : 0.030643 model2 loss : 0.028962
[23:03:45.086] iteration 12246 : model1 loss : 0.022175 model2 loss : 0.021097
[23:03:45.766] iteration 12247 : model1 loss : 0.028633 model2 loss : 0.024979
[23:03:46.435] iteration 12248 : model1 loss : 0.022835 model2 loss : 0.028050
[23:03:47.092] iteration 12249 : model1 loss : 0.019003 model2 loss : 0.018093
[23:03:47.771] iteration 12250 : model1 loss : 0.018315 model2 loss : 0.017894
[23:03:48.494] iteration 12251 : model1 loss : 0.020647 model2 loss : 0.022238
[23:03:49.155] iteration 12252 : model1 loss : 0.026006 model2 loss : 0.042451
[23:03:49.841] iteration 12253 : model1 loss : 0.019295 model2 loss : 0.018924
[23:03:50.527] iteration 12254 : model1 loss : 0.023729 model2 loss : 0.021725
[23:03:51.304] iteration 12255 : model1 loss : 0.022141 model2 loss : 0.025602
[23:03:52.052] iteration 12256 : model1 loss : 0.036848 model2 loss : 0.032932
[23:03:52.808] iteration 12257 : model1 loss : 0.023276 model2 loss : 0.021673
[23:03:53.644] iteration 12258 : model1 loss : 0.023160 model2 loss : 0.022663
[23:03:54.399] iteration 12259 : model1 loss : 0.023129 model2 loss : 0.021093
[23:03:55.081] iteration 12260 : model1 loss : 0.021492 model2 loss : 0.021793
[23:03:55.854] iteration 12261 : model1 loss : 0.019797 model2 loss : 0.020283
[23:03:56.561] iteration 12262 : model1 loss : 0.019384 model2 loss : 0.021414
[23:03:57.312] iteration 12263 : model1 loss : 0.025266 model2 loss : 0.027876
[23:03:58.047] iteration 12264 : model1 loss : 0.031740 model2 loss : 0.031876
[23:03:58.787] iteration 12265 : model1 loss : 0.142668 model2 loss : 0.147158
[23:03:59.589] iteration 12266 : model1 loss : 0.033332 model2 loss : 0.039924
[23:04:00.380] iteration 12267 : model1 loss : 0.038565 model2 loss : 0.037388
[23:04:01.088] iteration 12268 : model1 loss : 0.016722 model2 loss : 0.016236
[23:04:01.756] iteration 12269 : model1 loss : 0.037738 model2 loss : 0.029345
[23:04:02.440] iteration 12270 : model1 loss : 0.017280 model2 loss : 0.017317
[23:04:03.102] iteration 12271 : model1 loss : 0.029158 model2 loss : 0.027414
[23:04:03.806] iteration 12272 : model1 loss : 0.019053 model2 loss : 0.022025
[23:04:04.509] iteration 12273 : model1 loss : 0.033319 model2 loss : 0.029609
[23:04:05.223] iteration 12274 : model1 loss : 0.058047 model2 loss : 0.050501
[23:04:05.917] iteration 12275 : model1 loss : 0.034552 model2 loss : 0.054602
[23:04:06.569] iteration 12276 : model1 loss : 0.046596 model2 loss : 0.045360
[23:04:07.334] iteration 12277 : model1 loss : 0.020874 model2 loss : 0.019388
[23:04:08.041] iteration 12278 : model1 loss : 0.026210 model2 loss : 0.028356
[23:04:08.775] iteration 12279 : model1 loss : 0.020910 model2 loss : 0.021579
[23:04:09.488] iteration 12280 : model1 loss : 0.031153 model2 loss : 0.029505
[23:04:10.219] iteration 12281 : model1 loss : 0.054819 model2 loss : 0.048109
[23:04:10.899] iteration 12282 : model1 loss : 0.029405 model2 loss : 0.031423
[23:04:11.578] iteration 12283 : model1 loss : 0.019689 model2 loss : 0.020888
[23:04:12.309] iteration 12284 : model1 loss : 0.023939 model2 loss : 0.031877
[23:04:13.090] iteration 12285 : model1 loss : 0.023314 model2 loss : 0.024179
[23:04:13.827] iteration 12286 : model1 loss : 0.024212 model2 loss : 0.024449
[23:04:14.598] iteration 12287 : model1 loss : 0.029663 model2 loss : 0.029078
[23:04:15.321] iteration 12288 : model1 loss : 0.027598 model2 loss : 0.026356
[23:04:16.004] iteration 12289 : model1 loss : 0.027892 model2 loss : 0.027024
[23:04:16.668] iteration 12290 : model1 loss : 0.018802 model2 loss : 0.018547
[23:04:17.338] iteration 12291 : model1 loss : 0.017907 model2 loss : 0.018326
[23:04:18.026] iteration 12292 : model1 loss : 0.018323 model2 loss : 0.020143
[23:04:18.689] iteration 12293 : model1 loss : 0.027275 model2 loss : 0.028976
[23:04:19.350] iteration 12294 : model1 loss : 0.028542 model2 loss : 0.029569
[23:04:20.022] iteration 12295 : model1 loss : 0.027043 model2 loss : 0.025482
[23:04:20.682] iteration 12296 : model1 loss : 0.020753 model2 loss : 0.020446
[23:04:21.362] iteration 12297 : model1 loss : 0.022404 model2 loss : 0.024993
[23:04:22.037] iteration 12298 : model1 loss : 0.051529 model2 loss : 0.034921
[23:04:22.715] iteration 12299 : model1 loss : 0.017706 model2 loss : 0.020082
[23:04:23.375] iteration 12300 : model1 loss : 0.018790 model2 loss : 0.018722
[23:04:24.083] iteration 12301 : model1 loss : 0.026043 model2 loss : 0.028760
[23:04:24.751] iteration 12302 : model1 loss : 0.018140 model2 loss : 0.020161
[23:04:25.421] iteration 12303 : model1 loss : 0.027706 model2 loss : 0.024984
[23:04:26.086] iteration 12304 : model1 loss : 0.020817 model2 loss : 0.032280
[23:04:26.758] iteration 12305 : model1 loss : 0.022506 model2 loss : 0.022671
[23:04:27.428] iteration 12306 : model1 loss : 0.021007 model2 loss : 0.022001
[23:04:28.102] iteration 12307 : model1 loss : 0.022373 model2 loss : 0.030685
[23:04:28.768] iteration 12308 : model1 loss : 0.027677 model2 loss : 0.030382
[23:04:29.430] iteration 12309 : model1 loss : 0.018180 model2 loss : 0.019669
[23:04:30.118] iteration 12310 : model1 loss : 0.021213 model2 loss : 0.020750
[23:04:30.779] iteration 12311 : model1 loss : 0.030334 model2 loss : 0.043928
[23:04:31.452] iteration 12312 : model1 loss : 0.021851 model2 loss : 0.020626
[23:04:32.113] iteration 12313 : model1 loss : 0.029698 model2 loss : 0.028510
[23:04:32.787] iteration 12314 : model1 loss : 0.025750 model2 loss : 0.022114
[23:04:33.452] iteration 12315 : model1 loss : 0.019728 model2 loss : 0.022112
[23:04:34.097] iteration 12316 : model1 loss : 0.021300 model2 loss : 0.021043
[23:04:34.759] iteration 12317 : model1 loss : 0.026891 model2 loss : 0.024192
[23:04:35.433] iteration 12318 : model1 loss : 0.022541 model2 loss : 0.025330
[23:04:36.099] iteration 12319 : model1 loss : 0.024973 model2 loss : 0.025406
[23:04:36.773] iteration 12320 : model1 loss : 0.015590 model2 loss : 0.018562
[23:04:37.455] iteration 12321 : model1 loss : 0.017833 model2 loss : 0.018531
[23:04:38.119] iteration 12322 : model1 loss : 0.016268 model2 loss : 0.020792
[23:04:38.774] iteration 12323 : model1 loss : 0.020681 model2 loss : 0.018708
[23:04:39.446] iteration 12324 : model1 loss : 0.022606 model2 loss : 0.023937
[23:04:40.109] iteration 12325 : model1 loss : 0.019714 model2 loss : 0.021061
[23:04:40.788] iteration 12326 : model1 loss : 0.023219 model2 loss : 0.020980
[23:04:41.462] iteration 12327 : model1 loss : 0.021354 model2 loss : 0.020990
[23:04:42.115] iteration 12328 : model1 loss : 0.036747 model2 loss : 0.043345
[23:04:42.774] iteration 12329 : model1 loss : 0.025090 model2 loss : 0.023366
[23:04:43.442] iteration 12330 : model1 loss : 0.017744 model2 loss : 0.017158
[23:04:44.116] iteration 12331 : model1 loss : 0.024151 model2 loss : 0.023932
[23:04:44.786] iteration 12332 : model1 loss : 0.023388 model2 loss : 0.025592
[23:04:45.459] iteration 12333 : model1 loss : 0.022546 model2 loss : 0.019533
[23:04:46.114] iteration 12334 : model1 loss : 0.021953 model2 loss : 0.023106
[23:04:46.786] iteration 12335 : model1 loss : 0.029909 model2 loss : 0.023975
[23:04:47.456] iteration 12336 : model1 loss : 0.018039 model2 loss : 0.019631
[23:04:48.117] iteration 12337 : model1 loss : 0.018560 model2 loss : 0.022539
[23:04:48.791] iteration 12338 : model1 loss : 0.022484 model2 loss : 0.023557
[23:04:49.452] iteration 12339 : model1 loss : 0.030346 model2 loss : 0.030311
[23:04:50.130] iteration 12340 : model1 loss : 0.026337 model2 loss : 0.020913
[23:04:50.791] iteration 12341 : model1 loss : 0.035794 model2 loss : 0.035947
[23:04:51.448] iteration 12342 : model1 loss : 0.022083 model2 loss : 0.020989
[23:04:52.104] iteration 12343 : model1 loss : 0.020324 model2 loss : 0.020447
[23:04:52.776] iteration 12344 : model1 loss : 0.054226 model2 loss : 0.058051
[23:04:53.440] iteration 12345 : model1 loss : 0.038068 model2 loss : 0.032289
[23:04:54.099] iteration 12346 : model1 loss : 0.025348 model2 loss : 0.023398
[23:04:54.765] iteration 12347 : model1 loss : 0.029667 model2 loss : 0.028007
[23:04:55.436] iteration 12348 : model1 loss : 0.021701 model2 loss : 0.021487
[23:04:56.105] iteration 12349 : model1 loss : 0.020214 model2 loss : 0.021480
[23:04:56.781] iteration 12350 : model1 loss : 0.029812 model2 loss : 0.029904
[23:04:57.500] iteration 12351 : model1 loss : 0.026360 model2 loss : 0.023447
[23:04:58.167] iteration 12352 : model1 loss : 0.028264 model2 loss : 0.025485
[23:04:58.834] iteration 12353 : model1 loss : 0.028831 model2 loss : 0.025324
[23:04:59.509] iteration 12354 : model1 loss : 0.016802 model2 loss : 0.016812
[23:05:00.175] iteration 12355 : model1 loss : 0.039538 model2 loss : 0.045359
[23:05:00.836] iteration 12356 : model1 loss : 0.026083 model2 loss : 0.024983
[23:05:01.504] iteration 12357 : model1 loss : 0.018377 model2 loss : 0.020609
[23:05:02.188] iteration 12358 : model1 loss : 0.061047 model2 loss : 0.049156
[23:05:02.848] iteration 12359 : model1 loss : 0.017708 model2 loss : 0.020497
[23:05:03.520] iteration 12360 : model1 loss : 0.022103 model2 loss : 0.024569
[23:05:04.178] iteration 12361 : model1 loss : 0.015879 model2 loss : 0.016285
[23:05:04.835] iteration 12362 : model1 loss : 0.027928 model2 loss : 0.026461
[23:05:05.513] iteration 12363 : model1 loss : 0.030506 model2 loss : 0.040665
[23:05:06.172] iteration 12364 : model1 loss : 0.028925 model2 loss : 0.030497
[23:05:06.839] iteration 12365 : model1 loss : 0.020339 model2 loss : 0.019095
[23:05:07.502] iteration 12366 : model1 loss : 0.021773 model2 loss : 0.021308
[23:05:08.184] iteration 12367 : model1 loss : 0.042090 model2 loss : 0.034018
[23:05:08.852] iteration 12368 : model1 loss : 0.026647 model2 loss : 0.029908
[23:05:09.515] iteration 12369 : model1 loss : 0.017758 model2 loss : 0.018622
[23:05:10.180] iteration 12370 : model1 loss : 0.023417 model2 loss : 0.021710
[23:05:10.847] iteration 12371 : model1 loss : 0.025061 model2 loss : 0.026139
[23:05:11.510] iteration 12372 : model1 loss : 0.036310 model2 loss : 0.029542
[23:05:12.168] iteration 12373 : model1 loss : 0.021811 model2 loss : 0.024235
[23:05:12.833] iteration 12374 : model1 loss : 0.022444 model2 loss : 0.025526
[23:05:13.494] iteration 12375 : model1 loss : 0.018568 model2 loss : 0.020855
[23:05:14.160] iteration 12376 : model1 loss : 0.033519 model2 loss : 0.035223
[23:05:14.812] iteration 12377 : model1 loss : 0.026473 model2 loss : 0.025410
[23:05:15.480] iteration 12378 : model1 loss : 0.026981 model2 loss : 0.023142
[23:05:16.145] iteration 12379 : model1 loss : 0.022084 model2 loss : 0.022245
[23:05:16.801] iteration 12380 : model1 loss : 0.033964 model2 loss : 0.061411
[23:05:17.479] iteration 12381 : model1 loss : 0.025798 model2 loss : 0.029546
[23:05:18.145] iteration 12382 : model1 loss : 0.022701 model2 loss : 0.022692
[23:05:18.825] iteration 12383 : model1 loss : 0.028059 model2 loss : 0.027091
[23:05:19.490] iteration 12384 : model1 loss : 0.021621 model2 loss : 0.021812
[23:05:20.138] iteration 12385 : model1 loss : 0.022763 model2 loss : 0.020028
[23:05:20.823] iteration 12386 : model1 loss : 0.023468 model2 loss : 0.022844
[23:05:21.518] iteration 12387 : model1 loss : 0.022897 model2 loss : 0.020196
[23:05:22.216] iteration 12388 : model1 loss : 0.022951 model2 loss : 0.022604
[23:05:22.874] iteration 12389 : model1 loss : 0.026451 model2 loss : 0.026629
[23:05:23.539] iteration 12390 : model1 loss : 0.015452 model2 loss : 0.015342
[23:05:24.201] iteration 12391 : model1 loss : 0.019255 model2 loss : 0.019080
[23:05:24.870] iteration 12392 : model1 loss : 0.020990 model2 loss : 0.017059
[23:05:25.544] iteration 12393 : model1 loss : 0.021411 model2 loss : 0.020635
[23:05:26.204] iteration 12394 : model1 loss : 0.021999 model2 loss : 0.021623
[23:05:26.856] iteration 12395 : model1 loss : 0.016443 model2 loss : 0.016557
[23:05:27.539] iteration 12396 : model1 loss : 0.027101 model2 loss : 0.021360
[23:05:28.197] iteration 12397 : model1 loss : 0.021216 model2 loss : 0.019190
[23:05:28.878] iteration 12398 : model1 loss : 0.023782 model2 loss : 0.027642
[23:05:29.567] iteration 12399 : model1 loss : 0.035889 model2 loss : 0.019362
[23:05:30.238] iteration 12400 : model1 loss : 0.021432 model2 loss : 0.021645
[23:05:51.831] iteration 12400 : model1_mean_dice : 0.853049 model1_mean_hd95 : 4.059686
[23:06:13.640] iteration 12400 : model2_mean_dice : 0.864962 model2_mean_hd95 : 4.522757
[23:06:14.373] iteration 12401 : model1 loss : 0.023276 model2 loss : 0.023042
[23:06:15.060] iteration 12402 : model1 loss : 0.016607 model2 loss : 0.017579
[23:06:15.773] iteration 12403 : model1 loss : 0.022752 model2 loss : 0.023789
[23:06:16.487] iteration 12404 : model1 loss : 0.026238 model2 loss : 0.023219
[23:06:17.203] iteration 12405 : model1 loss : 0.018832 model2 loss : 0.020460
[23:06:17.904] iteration 12406 : model1 loss : 0.017801 model2 loss : 0.017890
[23:06:18.608] iteration 12407 : model1 loss : 0.067977 model2 loss : 0.063700
[23:06:19.329] iteration 12408 : model1 loss : 0.020297 model2 loss : 0.020669
[23:06:20.048] iteration 12409 : model1 loss : 0.024760 model2 loss : 0.027078
[23:06:20.779] iteration 12410 : model1 loss : 0.023224 model2 loss : 0.019776
[23:06:21.552] iteration 12411 : model1 loss : 0.017725 model2 loss : 0.018956
[23:06:22.297] iteration 12412 : model1 loss : 0.039995 model2 loss : 0.031384
[23:06:23.250] iteration 12413 : model1 loss : 0.020361 model2 loss : 0.019693
[23:06:23.984] iteration 12414 : model1 loss : 0.023017 model2 loss : 0.026602
[23:06:24.767] iteration 12415 : model1 loss : 0.025529 model2 loss : 0.024684
[23:06:25.514] iteration 12416 : model1 loss : 0.067777 model2 loss : 0.078338
[23:06:26.190] iteration 12417 : model1 loss : 0.033438 model2 loss : 0.032403
[23:06:26.885] iteration 12418 : model1 loss : 0.017816 model2 loss : 0.016351
[23:06:27.581] iteration 12419 : model1 loss : 0.026056 model2 loss : 0.023501
[23:06:28.261] iteration 12420 : model1 loss : 0.085262 model2 loss : 0.065433
[23:06:28.953] iteration 12421 : model1 loss : 0.030721 model2 loss : 0.026725
[23:06:29.659] iteration 12422 : model1 loss : 0.044209 model2 loss : 0.048517
[23:06:30.346] iteration 12423 : model1 loss : 0.027505 model2 loss : 0.026667
[23:06:31.034] iteration 12424 : model1 loss : 0.020178 model2 loss : 0.021324
[23:06:31.710] iteration 12425 : model1 loss : 0.022739 model2 loss : 0.023335
[23:06:32.435] iteration 12426 : model1 loss : 0.024889 model2 loss : 0.026166
[23:06:33.141] iteration 12427 : model1 loss : 0.035663 model2 loss : 0.036384
[23:06:33.833] iteration 12428 : model1 loss : 0.021092 model2 loss : 0.020567
[23:06:34.542] iteration 12429 : model1 loss : 0.024624 model2 loss : 0.023560
[23:06:35.228] iteration 12430 : model1 loss : 0.027720 model2 loss : 0.024659
[23:06:35.915] iteration 12431 : model1 loss : 0.021964 model2 loss : 0.020101
[23:06:36.617] iteration 12432 : model1 loss : 0.022249 model2 loss : 0.022181
[23:06:37.326] iteration 12433 : model1 loss : 0.019717 model2 loss : 0.021430
[23:06:38.027] iteration 12434 : model1 loss : 0.021875 model2 loss : 0.028467
[23:06:38.762] iteration 12435 : model1 loss : 0.018191 model2 loss : 0.019910
[23:06:39.474] iteration 12436 : model1 loss : 0.016157 model2 loss : 0.015804
[23:06:40.191] iteration 12437 : model1 loss : 0.024462 model2 loss : 0.033624
[23:06:40.886] iteration 12438 : model1 loss : 0.024408 model2 loss : 0.024029
[23:06:41.587] iteration 12439 : model1 loss : 0.022271 model2 loss : 0.020440
[23:06:42.318] iteration 12440 : model1 loss : 0.020188 model2 loss : 0.020139
[23:06:43.005] iteration 12441 : model1 loss : 0.028211 model2 loss : 0.028351
[23:06:43.694] iteration 12442 : model1 loss : 0.023179 model2 loss : 0.026016
[23:06:44.397] iteration 12443 : model1 loss : 0.021927 model2 loss : 0.025379
[23:06:45.085] iteration 12444 : model1 loss : 0.021713 model2 loss : 0.021381
[23:06:45.773] iteration 12445 : model1 loss : 0.021625 model2 loss : 0.020635
[23:06:46.464] iteration 12446 : model1 loss : 0.028618 model2 loss : 0.025606
[23:06:47.188] iteration 12447 : model1 loss : 0.022744 model2 loss : 0.023820
[23:06:47.893] iteration 12448 : model1 loss : 0.024949 model2 loss : 0.023808
[23:06:48.598] iteration 12449 : model1 loss : 0.020759 model2 loss : 0.019351
[23:06:49.311] iteration 12450 : model1 loss : 0.031772 model2 loss : 0.029869
[23:06:50.032] iteration 12451 : model1 loss : 0.022810 model2 loss : 0.021454
[23:06:50.714] iteration 12452 : model1 loss : 0.025764 model2 loss : 0.024974
[23:06:51.416] iteration 12453 : model1 loss : 0.041631 model2 loss : 0.042239
[23:06:52.126] iteration 12454 : model1 loss : 0.019441 model2 loss : 0.021204
[23:06:52.821] iteration 12455 : model1 loss : 0.023023 model2 loss : 0.023633
[23:06:53.520] iteration 12456 : model1 loss : 0.020905 model2 loss : 0.021679
[23:06:54.221] iteration 12457 : model1 loss : 0.037935 model2 loss : 0.032926
[23:06:54.908] iteration 12458 : model1 loss : 0.019691 model2 loss : 0.024854
[23:06:55.594] iteration 12459 : model1 loss : 0.027830 model2 loss : 0.032814
[23:06:56.289] iteration 12460 : model1 loss : 0.025955 model2 loss : 0.018719
[23:06:57.007] iteration 12461 : model1 loss : 0.021688 model2 loss : 0.022994
[23:06:57.729] iteration 12462 : model1 loss : 0.016119 model2 loss : 0.015842
[23:06:58.415] iteration 12463 : model1 loss : 0.016020 model2 loss : 0.015934
[23:06:59.110] iteration 12464 : model1 loss : 0.020308 model2 loss : 0.021020
[23:06:59.811] iteration 12465 : model1 loss : 0.021943 model2 loss : 0.021113
[23:07:00.505] iteration 12466 : model1 loss : 0.028753 model2 loss : 0.025011
[23:07:01.188] iteration 12467 : model1 loss : 0.019812 model2 loss : 0.018706
[23:07:01.883] iteration 12468 : model1 loss : 0.023248 model2 loss : 0.029762
[23:07:02.600] iteration 12469 : model1 loss : 0.025383 model2 loss : 0.024800
[23:07:03.303] iteration 12470 : model1 loss : 0.022715 model2 loss : 0.023250
[23:07:04.003] iteration 12471 : model1 loss : 0.024676 model2 loss : 0.026427
[23:07:04.699] iteration 12472 : model1 loss : 0.020030 model2 loss : 0.020033
[23:07:05.385] iteration 12473 : model1 loss : 0.030758 model2 loss : 0.032034
[23:07:06.079] iteration 12474 : model1 loss : 0.022566 model2 loss : 0.023035
[23:07:06.771] iteration 12475 : model1 loss : 0.089935 model2 loss : 0.091332
[23:07:07.512] iteration 12476 : model1 loss : 0.024107 model2 loss : 0.023574
[23:07:08.254] iteration 12477 : model1 loss : 0.020565 model2 loss : 0.020160
[23:07:08.991] iteration 12478 : model1 loss : 0.018818 model2 loss : 0.022576
[23:07:09.699] iteration 12479 : model1 loss : 0.019143 model2 loss : 0.022367
[23:07:10.407] iteration 12480 : model1 loss : 0.016298 model2 loss : 0.017013
[23:07:11.115] iteration 12481 : model1 loss : 0.035580 model2 loss : 0.030938
[23:07:11.846] iteration 12482 : model1 loss : 0.035241 model2 loss : 0.032336
[23:07:12.574] iteration 12483 : model1 loss : 0.033813 model2 loss : 0.030674
[23:07:13.287] iteration 12484 : model1 loss : 0.018771 model2 loss : 0.019330
[23:07:13.989] iteration 12485 : model1 loss : 0.030295 model2 loss : 0.033887
[23:07:14.695] iteration 12486 : model1 loss : 0.021529 model2 loss : 0.023382
[23:07:15.411] iteration 12487 : model1 loss : 0.028551 model2 loss : 0.028602
[23:07:16.110] iteration 12488 : model1 loss : 0.022560 model2 loss : 0.026582
[23:07:16.836] iteration 12489 : model1 loss : 0.018421 model2 loss : 0.018879
[23:07:17.558] iteration 12490 : model1 loss : 0.037810 model2 loss : 0.048509
[23:07:18.258] iteration 12491 : model1 loss : 0.018402 model2 loss : 0.017306
[23:07:18.961] iteration 12492 : model1 loss : 0.026811 model2 loss : 0.025373
[23:07:19.680] iteration 12493 : model1 loss : 0.019550 model2 loss : 0.019622
[23:07:20.392] iteration 12494 : model1 loss : 0.054506 model2 loss : 0.078783
[23:07:21.094] iteration 12495 : model1 loss : 0.023275 model2 loss : 0.024290
[23:07:21.812] iteration 12496 : model1 loss : 0.025374 model2 loss : 0.023167
[23:07:22.546] iteration 12497 : model1 loss : 0.027460 model2 loss : 0.032228
[23:07:23.290] iteration 12498 : model1 loss : 0.017765 model2 loss : 0.020780
[23:07:24.006] iteration 12499 : model1 loss : 0.017883 model2 loss : 0.016669
[23:07:24.712] iteration 12500 : model1 loss : 0.021602 model2 loss : 0.026020
[23:07:25.467] iteration 12501 : model1 loss : 0.020879 model2 loss : 0.020072
[23:07:26.172] iteration 12502 : model1 loss : 0.018667 model2 loss : 0.018792
[23:07:26.907] iteration 12503 : model1 loss : 0.024457 model2 loss : 0.023759
[23:07:27.626] iteration 12504 : model1 loss : 0.035594 model2 loss : 0.038649
[23:07:28.332] iteration 12505 : model1 loss : 0.024509 model2 loss : 0.025149
[23:07:29.040] iteration 12506 : model1 loss : 0.026252 model2 loss : 0.025954
[23:07:29.763] iteration 12507 : model1 loss : 0.019315 model2 loss : 0.023257
[23:07:30.495] iteration 12508 : model1 loss : 0.026854 model2 loss : 0.024106
[23:07:31.211] iteration 12509 : model1 loss : 0.021758 model2 loss : 0.022785
[23:07:31.940] iteration 12510 : model1 loss : 0.026513 model2 loss : 0.026042
[23:07:32.669] iteration 12511 : model1 loss : 0.024408 model2 loss : 0.023310
[23:07:33.378] iteration 12512 : model1 loss : 0.023321 model2 loss : 0.023684
[23:07:34.096] iteration 12513 : model1 loss : 0.029174 model2 loss : 0.024475
[23:07:34.799] iteration 12514 : model1 loss : 0.018687 model2 loss : 0.020685
[23:07:35.518] iteration 12515 : model1 loss : 0.021733 model2 loss : 0.023278
[23:07:36.232] iteration 12516 : model1 loss : 0.037496 model2 loss : 0.030577
[23:07:36.951] iteration 12517 : model1 loss : 0.025022 model2 loss : 0.020321
[23:07:37.676] iteration 12518 : model1 loss : 0.041906 model2 loss : 0.029635
[23:07:38.382] iteration 12519 : model1 loss : 0.032268 model2 loss : 0.030598
[23:07:39.103] iteration 12520 : model1 loss : 0.025836 model2 loss : 0.024669
[23:07:39.796] iteration 12521 : model1 loss : 0.024825 model2 loss : 0.024908
[23:07:40.511] iteration 12522 : model1 loss : 0.018331 model2 loss : 0.019138
[23:07:41.226] iteration 12523 : model1 loss : 0.022338 model2 loss : 0.020915
[23:07:41.939] iteration 12524 : model1 loss : 0.023807 model2 loss : 0.017333
[23:07:42.677] iteration 12525 : model1 loss : 0.021268 model2 loss : 0.027114
[23:07:43.392] iteration 12526 : model1 loss : 0.022599 model2 loss : 0.021075
[23:07:44.089] iteration 12527 : model1 loss : 0.026290 model2 loss : 0.026116
[23:07:44.807] iteration 12528 : model1 loss : 0.033126 model2 loss : 0.032418
[23:07:45.536] iteration 12529 : model1 loss : 0.023286 model2 loss : 0.024680
[23:07:46.243] iteration 12530 : model1 loss : 0.027290 model2 loss : 0.032872
[23:07:46.958] iteration 12531 : model1 loss : 0.021749 model2 loss : 0.021062
[23:07:47.673] iteration 12532 : model1 loss : 0.045222 model2 loss : 0.049066
[23:07:48.378] iteration 12533 : model1 loss : 0.027179 model2 loss : 0.025264
[23:07:49.082] iteration 12534 : model1 loss : 0.018338 model2 loss : 0.020439
[23:07:49.790] iteration 12535 : model1 loss : 0.019301 model2 loss : 0.019090
[23:07:50.508] iteration 12536 : model1 loss : 0.020457 model2 loss : 0.019479
[23:07:51.210] iteration 12537 : model1 loss : 0.026590 model2 loss : 0.023761
[23:07:51.935] iteration 12538 : model1 loss : 0.023172 model2 loss : 0.024274
[23:07:52.701] iteration 12539 : model1 loss : 0.021066 model2 loss : 0.019691
[23:07:53.431] iteration 12540 : model1 loss : 0.026373 model2 loss : 0.030426
[23:07:54.134] iteration 12541 : model1 loss : 0.052629 model2 loss : 0.050299
[23:07:54.836] iteration 12542 : model1 loss : 0.026244 model2 loss : 0.036414
[23:07:55.538] iteration 12543 : model1 loss : 0.043486 model2 loss : 0.037420
[23:07:56.241] iteration 12544 : model1 loss : 0.017582 model2 loss : 0.017907
[23:07:56.958] iteration 12545 : model1 loss : 0.020342 model2 loss : 0.021753
[23:07:57.678] iteration 12546 : model1 loss : 0.018866 model2 loss : 0.022350
[23:07:58.405] iteration 12547 : model1 loss : 0.025272 model2 loss : 0.021519
[23:07:59.132] iteration 12548 : model1 loss : 0.025050 model2 loss : 0.022609
[23:07:59.838] iteration 12549 : model1 loss : 0.018912 model2 loss : 0.019024
[23:08:00.556] iteration 12550 : model1 loss : 0.025972 model2 loss : 0.025910
[23:08:01.311] iteration 12551 : model1 loss : 0.021029 model2 loss : 0.021209
[23:08:02.039] iteration 12552 : model1 loss : 0.030342 model2 loss : 0.027954
[23:08:02.772] iteration 12553 : model1 loss : 0.025521 model2 loss : 0.027026
[23:08:03.493] iteration 12554 : model1 loss : 0.021890 model2 loss : 0.021773
[23:08:04.207] iteration 12555 : model1 loss : 0.022742 model2 loss : 0.022103
[23:08:04.914] iteration 12556 : model1 loss : 0.023284 model2 loss : 0.024451
[23:08:05.615] iteration 12557 : model1 loss : 0.026119 model2 loss : 0.028748
[23:08:06.324] iteration 12558 : model1 loss : 0.032512 model2 loss : 0.028855
[23:08:07.050] iteration 12559 : model1 loss : 0.027559 model2 loss : 0.023462
[23:08:07.771] iteration 12560 : model1 loss : 0.023790 model2 loss : 0.023139
[23:08:08.488] iteration 12561 : model1 loss : 0.032421 model2 loss : 0.032835
[23:08:09.208] iteration 12562 : model1 loss : 0.021441 model2 loss : 0.021150
[23:08:09.911] iteration 12563 : model1 loss : 0.019291 model2 loss : 0.018703
[23:08:10.646] iteration 12564 : model1 loss : 0.029413 model2 loss : 0.029852
[23:08:11.371] iteration 12565 : model1 loss : 0.043657 model2 loss : 0.032693
[23:08:12.094] iteration 12566 : model1 loss : 0.040100 model2 loss : 0.033167
[23:08:12.812] iteration 12567 : model1 loss : 0.149322 model2 loss : 0.144901
[23:08:13.526] iteration 12568 : model1 loss : 0.020473 model2 loss : 0.022053
[23:08:14.240] iteration 12569 : model1 loss : 0.019516 model2 loss : 0.017875
[23:08:14.958] iteration 12570 : model1 loss : 0.031894 model2 loss : 0.026834
[23:08:15.673] iteration 12571 : model1 loss : 0.031114 model2 loss : 0.029712
[23:08:16.396] iteration 12572 : model1 loss : 0.033441 model2 loss : 0.032912
[23:08:17.120] iteration 12573 : model1 loss : 0.032091 model2 loss : 0.028447
[23:08:17.839] iteration 12574 : model1 loss : 0.020644 model2 loss : 0.020712
[23:08:18.539] iteration 12575 : model1 loss : 0.022858 model2 loss : 0.020282
[23:08:19.264] iteration 12576 : model1 loss : 0.023127 model2 loss : 0.022904
[23:08:19.963] iteration 12577 : model1 loss : 0.018781 model2 loss : 0.020053
[23:08:20.677] iteration 12578 : model1 loss : 0.018935 model2 loss : 0.020115
[23:08:21.410] iteration 12579 : model1 loss : 0.019749 model2 loss : 0.018581
[23:08:22.118] iteration 12580 : model1 loss : 0.022749 model2 loss : 0.022064
[23:08:22.844] iteration 12581 : model1 loss : 0.097993 model2 loss : 0.071543
[23:08:23.629] iteration 12582 : model1 loss : 0.024750 model2 loss : 0.021706
[23:08:24.360] iteration 12583 : model1 loss : 0.029714 model2 loss : 0.032098
[23:08:25.065] iteration 12584 : model1 loss : 0.026959 model2 loss : 0.024519
[23:08:25.779] iteration 12585 : model1 loss : 0.026296 model2 loss : 0.024248
[23:08:26.483] iteration 12586 : model1 loss : 0.025742 model2 loss : 0.027178
[23:08:27.210] iteration 12587 : model1 loss : 0.028154 model2 loss : 0.024558
[23:08:27.924] iteration 12588 : model1 loss : 0.028065 model2 loss : 0.027759
[23:08:28.643] iteration 12589 : model1 loss : 0.024183 model2 loss : 0.023335
[23:08:29.365] iteration 12590 : model1 loss : 0.024610 model2 loss : 0.025116
[23:08:30.064] iteration 12591 : model1 loss : 0.023630 model2 loss : 0.021379
[23:08:30.766] iteration 12592 : model1 loss : 0.019019 model2 loss : 0.019289
[23:08:31.476] iteration 12593 : model1 loss : 0.020904 model2 loss : 0.018455
[23:08:32.201] iteration 12594 : model1 loss : 0.030681 model2 loss : 0.034769
[23:08:32.921] iteration 12595 : model1 loss : 0.033462 model2 loss : 0.035263
[23:08:33.625] iteration 12596 : model1 loss : 0.026409 model2 loss : 0.020512
[23:08:34.333] iteration 12597 : model1 loss : 0.032382 model2 loss : 0.029795
[23:08:35.038] iteration 12598 : model1 loss : 0.035052 model2 loss : 0.028113
[23:08:35.753] iteration 12599 : model1 loss : 0.025302 model2 loss : 0.023284
[23:08:36.468] iteration 12600 : model1 loss : 0.025908 model2 loss : 0.022626
[23:08:57.504] iteration 12600 : model1_mean_dice : 0.846850 model1_mean_hd95 : 8.198095
[23:09:18.347] iteration 12600 : model2_mean_dice : 0.856416 model2_mean_hd95 : 5.256648
[23:09:19.085] iteration 12601 : model1 loss : 0.020677 model2 loss : 0.021879
[23:09:19.783] iteration 12602 : model1 loss : 0.019123 model2 loss : 0.017949
[23:09:20.484] iteration 12603 : model1 loss : 0.018297 model2 loss : 0.019120
[23:09:21.213] iteration 12604 : model1 loss : 0.021496 model2 loss : 0.020483
[23:09:21.928] iteration 12605 : model1 loss : 0.022778 model2 loss : 0.027231
[23:09:22.663] iteration 12606 : model1 loss : 0.022664 model2 loss : 0.020590
[23:09:23.383] iteration 12607 : model1 loss : 0.017530 model2 loss : 0.017012
[23:09:24.132] iteration 12608 : model1 loss : 0.035838 model2 loss : 0.031869
[23:09:24.844] iteration 12609 : model1 loss : 0.018601 model2 loss : 0.018415
[23:09:25.573] iteration 12610 : model1 loss : 0.035024 model2 loss : 0.045354
[23:09:26.280] iteration 12611 : model1 loss : 0.019667 model2 loss : 0.020444
[23:09:27.012] iteration 12612 : model1 loss : 0.018285 model2 loss : 0.017504
[23:09:27.712] iteration 12613 : model1 loss : 0.025470 model2 loss : 0.022180
[23:09:28.415] iteration 12614 : model1 loss : 0.020989 model2 loss : 0.023055
[23:09:29.131] iteration 12615 : model1 loss : 0.023539 model2 loss : 0.021526
[23:09:29.828] iteration 12616 : model1 loss : 0.014390 model2 loss : 0.014987
[23:09:30.517] iteration 12617 : model1 loss : 0.019747 model2 loss : 0.020193
[23:09:31.246] iteration 12618 : model1 loss : 0.020552 model2 loss : 0.021060
[23:09:31.970] iteration 12619 : model1 loss : 0.056686 model2 loss : 0.049481
[23:09:32.708] iteration 12620 : model1 loss : 0.018739 model2 loss : 0.019457
[23:09:33.418] iteration 12621 : model1 loss : 0.017968 model2 loss : 0.018033
[23:09:34.125] iteration 12622 : model1 loss : 0.028388 model2 loss : 0.027185
[23:09:34.835] iteration 12623 : model1 loss : 0.063261 model2 loss : 0.066434
[23:09:35.552] iteration 12624 : model1 loss : 0.022879 model2 loss : 0.023530
[23:09:36.249] iteration 12625 : model1 loss : 0.018319 model2 loss : 0.035731
[23:09:36.962] iteration 12626 : model1 loss : 0.034659 model2 loss : 0.032398
[23:09:37.721] iteration 12627 : model1 loss : 0.016794 model2 loss : 0.017626
[23:09:38.468] iteration 12628 : model1 loss : 0.021756 model2 loss : 0.023035
[23:09:39.194] iteration 12629 : model1 loss : 0.021001 model2 loss : 0.021000
[23:09:39.919] iteration 12630 : model1 loss : 0.021955 model2 loss : 0.021128
[23:09:40.626] iteration 12631 : model1 loss : 0.142715 model2 loss : 0.145342
[23:09:41.352] iteration 12632 : model1 loss : 0.019903 model2 loss : 0.018493
[23:09:42.070] iteration 12633 : model1 loss : 0.027324 model2 loss : 0.027853
[23:09:42.775] iteration 12634 : model1 loss : 0.018689 model2 loss : 0.019246
[23:09:43.504] iteration 12635 : model1 loss : 0.024866 model2 loss : 0.020781
[23:09:44.203] iteration 12636 : model1 loss : 0.019601 model2 loss : 0.020665
[23:09:44.905] iteration 12637 : model1 loss : 0.022221 model2 loss : 0.019369
[23:09:45.604] iteration 12638 : model1 loss : 0.019666 model2 loss : 0.021913
[23:09:46.306] iteration 12639 : model1 loss : 0.019451 model2 loss : 0.019127
[23:09:47.044] iteration 12640 : model1 loss : 0.038699 model2 loss : 0.033321
[23:09:47.757] iteration 12641 : model1 loss : 0.152300 model2 loss : 0.146796
[23:09:48.468] iteration 12642 : model1 loss : 0.022178 model2 loss : 0.021300
[23:09:49.187] iteration 12643 : model1 loss : 0.035844 model2 loss : 0.037159
[23:09:49.900] iteration 12644 : model1 loss : 0.024305 model2 loss : 0.025196
[23:09:50.620] iteration 12645 : model1 loss : 0.020784 model2 loss : 0.018802
[23:09:51.327] iteration 12646 : model1 loss : 0.028827 model2 loss : 0.029069
[23:09:52.043] iteration 12647 : model1 loss : 0.018789 model2 loss : 0.019216
[23:09:52.784] iteration 12648 : model1 loss : 0.023236 model2 loss : 0.024505
[23:09:53.489] iteration 12649 : model1 loss : 0.025256 model2 loss : 0.026923
[23:09:54.201] iteration 12650 : model1 loss : 0.021471 model2 loss : 0.021820
[23:09:54.961] iteration 12651 : model1 loss : 0.022735 model2 loss : 0.024512
[23:09:55.666] iteration 12652 : model1 loss : 0.020359 model2 loss : 0.019668
[23:09:56.386] iteration 12653 : model1 loss : 0.023083 model2 loss : 0.025310
[23:09:57.120] iteration 12654 : model1 loss : 0.028414 model2 loss : 0.028017
[23:09:57.824] iteration 12655 : model1 loss : 0.022229 model2 loss : 0.021133
[23:09:58.541] iteration 12656 : model1 loss : 0.032307 model2 loss : 0.028721
[23:09:59.247] iteration 12657 : model1 loss : 0.108514 model2 loss : 0.058206
[23:09:59.948] iteration 12658 : model1 loss : 0.021551 model2 loss : 0.021546
[23:10:00.677] iteration 12659 : model1 loss : 0.034960 model2 loss : 0.039926
[23:10:01.394] iteration 12660 : model1 loss : 0.031088 model2 loss : 0.028739
[23:10:02.123] iteration 12661 : model1 loss : 0.020747 model2 loss : 0.020674
[23:10:02.846] iteration 12662 : model1 loss : 0.026370 model2 loss : 0.021793
[23:10:03.552] iteration 12663 : model1 loss : 0.020815 model2 loss : 0.021488
[23:10:04.253] iteration 12664 : model1 loss : 0.023070 model2 loss : 0.025824
[23:10:04.975] iteration 12665 : model1 loss : 0.022226 model2 loss : 0.022497
[23:10:05.679] iteration 12666 : model1 loss : 0.019957 model2 loss : 0.019445
[23:10:06.401] iteration 12667 : model1 loss : 0.143583 model2 loss : 0.143208
[23:10:07.128] iteration 12668 : model1 loss : 0.018652 model2 loss : 0.018637
[23:10:07.849] iteration 12669 : model1 loss : 0.029527 model2 loss : 0.024623
[23:10:08.581] iteration 12670 : model1 loss : 0.031037 model2 loss : 0.030192
[23:10:09.294] iteration 12671 : model1 loss : 0.019525 model2 loss : 0.020447
[23:10:09.998] iteration 12672 : model1 loss : 0.024040 model2 loss : 0.024727
[23:10:10.720] iteration 12673 : model1 loss : 0.017403 model2 loss : 0.018184
[23:10:11.442] iteration 12674 : model1 loss : 0.027917 model2 loss : 0.026756
[23:10:12.187] iteration 12675 : model1 loss : 0.027864 model2 loss : 0.030320
[23:10:12.911] iteration 12676 : model1 loss : 0.022848 model2 loss : 0.020160
[23:10:13.613] iteration 12677 : model1 loss : 0.016626 model2 loss : 0.017207
[23:10:14.325] iteration 12678 : model1 loss : 0.017692 model2 loss : 0.018305
[23:10:15.043] iteration 12679 : model1 loss : 0.028686 model2 loss : 0.026366
[23:10:15.750] iteration 12680 : model1 loss : 0.020944 model2 loss : 0.021699
[23:10:16.453] iteration 12681 : model1 loss : 0.031837 model2 loss : 0.030766
[23:10:17.188] iteration 12682 : model1 loss : 0.017576 model2 loss : 0.016509
[23:10:17.898] iteration 12683 : model1 loss : 0.024043 model2 loss : 0.022108
[23:10:18.626] iteration 12684 : model1 loss : 0.020797 model2 loss : 0.025537
[23:10:19.332] iteration 12685 : model1 loss : 0.033962 model2 loss : 0.031170
[23:10:20.030] iteration 12686 : model1 loss : 0.017968 model2 loss : 0.016748
[23:10:20.733] iteration 12687 : model1 loss : 0.020909 model2 loss : 0.023663
[23:10:21.454] iteration 12688 : model1 loss : 0.019493 model2 loss : 0.019049
[23:10:22.174] iteration 12689 : model1 loss : 0.021456 model2 loss : 0.023501
[23:10:22.920] iteration 12690 : model1 loss : 0.027575 model2 loss : 0.027126
[23:10:23.673] iteration 12691 : model1 loss : 0.042745 model2 loss : 0.036376
[23:10:24.466] iteration 12692 : model1 loss : 0.017239 model2 loss : 0.016926
[23:10:25.187] iteration 12693 : model1 loss : 0.022013 model2 loss : 0.020978
[23:10:25.904] iteration 12694 : model1 loss : 0.025433 model2 loss : 0.024121
[23:10:26.594] iteration 12695 : model1 loss : 0.018278 model2 loss : 0.018038
[23:10:27.332] iteration 12696 : model1 loss : 0.021565 model2 loss : 0.019742
[23:10:28.018] iteration 12697 : model1 loss : 0.027350 model2 loss : 0.024776
[23:10:28.737] iteration 12698 : model1 loss : 0.025855 model2 loss : 0.023289
[23:10:29.463] iteration 12699 : model1 loss : 0.018677 model2 loss : 0.019978
[23:10:30.189] iteration 12700 : model1 loss : 0.023812 model2 loss : 0.021645
[23:10:30.977] iteration 12701 : model1 loss : 0.037588 model2 loss : 0.030361
[23:10:31.673] iteration 12702 : model1 loss : 0.028245 model2 loss : 0.026536
[23:10:32.396] iteration 12703 : model1 loss : 0.023408 model2 loss : 0.023493
[23:10:33.074] iteration 12704 : model1 loss : 0.028448 model2 loss : 0.031503
[23:10:33.764] iteration 12705 : model1 loss : 0.018986 model2 loss : 0.017956
[23:10:34.469] iteration 12706 : model1 loss : 0.015302 model2 loss : 0.014723
[23:10:35.153] iteration 12707 : model1 loss : 0.021770 model2 loss : 0.025134
[23:10:35.840] iteration 12708 : model1 loss : 0.021983 model2 loss : 0.022841
[23:10:36.531] iteration 12709 : model1 loss : 0.026632 model2 loss : 0.028301
[23:10:37.255] iteration 12710 : model1 loss : 0.023661 model2 loss : 0.023441
[23:10:38.003] iteration 12711 : model1 loss : 0.026365 model2 loss : 0.021089
[23:10:38.709] iteration 12712 : model1 loss : 0.024040 model2 loss : 0.023573
[23:10:39.429] iteration 12713 : model1 loss : 0.022610 model2 loss : 0.019910
[23:10:40.143] iteration 12714 : model1 loss : 0.022343 model2 loss : 0.020908
[23:10:40.851] iteration 12715 : model1 loss : 0.022046 model2 loss : 0.019018
[23:10:41.585] iteration 12716 : model1 loss : 0.140669 model2 loss : 0.148411
[23:10:42.323] iteration 12717 : model1 loss : 0.025905 model2 loss : 0.025692
[23:10:43.017] iteration 12718 : model1 loss : 0.036232 model2 loss : 0.039638
[23:10:43.734] iteration 12719 : model1 loss : 0.023967 model2 loss : 0.022912
[23:10:44.464] iteration 12720 : model1 loss : 0.026899 model2 loss : 0.027410
[23:10:45.199] iteration 12721 : model1 loss : 0.023269 model2 loss : 0.021731
[23:10:45.911] iteration 12722 : model1 loss : 0.025403 model2 loss : 0.022624
[23:10:46.633] iteration 12723 : model1 loss : 0.034429 model2 loss : 0.036339
[23:10:47.358] iteration 12724 : model1 loss : 0.024589 model2 loss : 0.024247
[23:10:48.065] iteration 12725 : model1 loss : 0.016721 model2 loss : 0.015399
[23:10:48.778] iteration 12726 : model1 loss : 0.034481 model2 loss : 0.039399
[23:10:49.491] iteration 12727 : model1 loss : 0.019222 model2 loss : 0.020030
[23:10:50.193] iteration 12728 : model1 loss : 0.020040 model2 loss : 0.019156
[23:10:50.923] iteration 12729 : model1 loss : 0.016202 model2 loss : 0.017376
[23:10:51.649] iteration 12730 : model1 loss : 0.019934 model2 loss : 0.020232
[23:10:52.388] iteration 12731 : model1 loss : 0.035969 model2 loss : 0.038412
[23:10:53.096] iteration 12732 : model1 loss : 0.022227 model2 loss : 0.022809
[23:10:53.805] iteration 12733 : model1 loss : 0.022062 model2 loss : 0.023812
[23:10:54.502] iteration 12734 : model1 loss : 0.037118 model2 loss : 0.043132
[23:10:55.218] iteration 12735 : model1 loss : 0.052319 model2 loss : 0.049743
[23:10:55.921] iteration 12736 : model1 loss : 0.018846 model2 loss : 0.017867
[23:10:56.633] iteration 12737 : model1 loss : 0.020592 model2 loss : 0.018658
[23:10:57.385] iteration 12738 : model1 loss : 0.022537 model2 loss : 0.022966
[23:10:58.093] iteration 12739 : model1 loss : 0.020006 model2 loss : 0.019916
[23:10:58.804] iteration 12740 : model1 loss : 0.021837 model2 loss : 0.022855
[23:10:59.528] iteration 12741 : model1 loss : 0.020798 model2 loss : 0.016567
[23:11:00.233] iteration 12742 : model1 loss : 0.025921 model2 loss : 0.025012
[23:11:00.931] iteration 12743 : model1 loss : 0.017877 model2 loss : 0.017571
[23:11:01.674] iteration 12744 : model1 loss : 0.026178 model2 loss : 0.024707
[23:11:02.431] iteration 12745 : model1 loss : 0.024983 model2 loss : 0.024856
[23:11:03.170] iteration 12746 : model1 loss : 0.023281 model2 loss : 0.029274
[23:11:03.868] iteration 12747 : model1 loss : 0.033809 model2 loss : 0.030403
[23:11:04.541] iteration 12748 : model1 loss : 0.044848 model2 loss : 0.031794
[23:11:05.238] iteration 12749 : model1 loss : 0.026560 model2 loss : 0.024374
[23:11:05.932] iteration 12750 : model1 loss : 0.018401 model2 loss : 0.018080
[23:11:06.660] iteration 12751 : model1 loss : 0.023994 model2 loss : 0.021779
[23:11:07.379] iteration 12752 : model1 loss : 0.020908 model2 loss : 0.020524
[23:11:08.058] iteration 12753 : model1 loss : 0.019615 model2 loss : 0.018145
[23:11:08.737] iteration 12754 : model1 loss : 0.023776 model2 loss : 0.024688
[23:11:09.431] iteration 12755 : model1 loss : 0.027320 model2 loss : 0.029584
[23:11:10.118] iteration 12756 : model1 loss : 0.041328 model2 loss : 0.037657
[23:11:10.818] iteration 12757 : model1 loss : 0.016520 model2 loss : 0.017239
[23:11:11.507] iteration 12758 : model1 loss : 0.022960 model2 loss : 0.021539
[23:11:12.225] iteration 12759 : model1 loss : 0.040144 model2 loss : 0.051240
[23:11:12.930] iteration 12760 : model1 loss : 0.020467 model2 loss : 0.020408
[23:11:13.636] iteration 12761 : model1 loss : 0.025797 model2 loss : 0.024405
[23:11:14.346] iteration 12762 : model1 loss : 0.029436 model2 loss : 0.029814
[23:11:15.043] iteration 12763 : model1 loss : 0.024651 model2 loss : 0.022054
[23:11:15.741] iteration 12764 : model1 loss : 0.023752 model2 loss : 0.021333
[23:11:16.427] iteration 12765 : model1 loss : 0.036345 model2 loss : 0.053685
[23:11:17.160] iteration 12766 : model1 loss : 0.036766 model2 loss : 0.037405
[23:11:17.845] iteration 12767 : model1 loss : 0.020072 model2 loss : 0.020181
[23:11:18.548] iteration 12768 : model1 loss : 0.022243 model2 loss : 0.024986
[23:11:19.231] iteration 12769 : model1 loss : 0.022066 model2 loss : 0.022727
[23:11:19.926] iteration 12770 : model1 loss : 0.021155 model2 loss : 0.021982
[23:11:20.626] iteration 12771 : model1 loss : 0.039748 model2 loss : 0.043714
[23:11:21.313] iteration 12772 : model1 loss : 0.026177 model2 loss : 0.023753
[23:11:22.022] iteration 12773 : model1 loss : 0.017443 model2 loss : 0.017730
[23:11:22.739] iteration 12774 : model1 loss : 0.020288 model2 loss : 0.019931
[23:11:23.425] iteration 12775 : model1 loss : 0.027559 model2 loss : 0.029018
[23:11:24.116] iteration 12776 : model1 loss : 0.029181 model2 loss : 0.026030
[23:11:24.825] iteration 12777 : model1 loss : 0.024656 model2 loss : 0.026116
[23:11:25.534] iteration 12778 : model1 loss : 0.014482 model2 loss : 0.015054
[23:11:26.226] iteration 12779 : model1 loss : 0.019221 model2 loss : 0.019595
[23:11:26.919] iteration 12780 : model1 loss : 0.024888 model2 loss : 0.029368
[23:11:27.626] iteration 12781 : model1 loss : 0.029299 model2 loss : 0.033776
[23:11:28.325] iteration 12782 : model1 loss : 0.031863 model2 loss : 0.032954
[23:11:29.031] iteration 12783 : model1 loss : 0.023330 model2 loss : 0.021031
[23:11:29.728] iteration 12784 : model1 loss : 0.022212 model2 loss : 0.022790
[23:11:30.432] iteration 12785 : model1 loss : 0.020250 model2 loss : 0.022163
[23:11:31.125] iteration 12786 : model1 loss : 0.026344 model2 loss : 0.027198
[23:11:31.827] iteration 12787 : model1 loss : 0.020838 model2 loss : 0.022571
[23:11:32.553] iteration 12788 : model1 loss : 0.021983 model2 loss : 0.022496
[23:11:33.237] iteration 12789 : model1 loss : 0.020224 model2 loss : 0.022043
[23:11:33.928] iteration 12790 : model1 loss : 0.023912 model2 loss : 0.027814
[23:11:34.617] iteration 12791 : model1 loss : 0.020790 model2 loss : 0.021314
[23:11:35.313] iteration 12792 : model1 loss : 0.021924 model2 loss : 0.022420
[23:11:35.994] iteration 12793 : model1 loss : 0.020085 model2 loss : 0.022163
[23:11:36.684] iteration 12794 : model1 loss : 0.025927 model2 loss : 0.031217
[23:11:37.398] iteration 12795 : model1 loss : 0.017440 model2 loss : 0.019353
[23:11:38.094] iteration 12796 : model1 loss : 0.023265 model2 loss : 0.025259
[23:11:38.780] iteration 12797 : model1 loss : 0.021899 model2 loss : 0.023148
[23:11:39.463] iteration 12798 : model1 loss : 0.015947 model2 loss : 0.017715
[23:11:40.147] iteration 12799 : model1 loss : 0.016924 model2 loss : 0.018652
[23:11:40.839] iteration 12800 : model1 loss : 0.031445 model2 loss : 0.028455
[23:12:00.758] iteration 12800 : model1_mean_dice : 0.858402 model1_mean_hd95 : 5.717999
[23:12:21.226] iteration 12800 : model2_mean_dice : 0.854222 model2_mean_hd95 : 5.880593
[23:12:21.973] iteration 12801 : model1 loss : 0.020427 model2 loss : 0.019666
[23:12:22.717] iteration 12802 : model1 loss : 0.017468 model2 loss : 0.018400
[23:12:23.426] iteration 12803 : model1 loss : 0.036546 model2 loss : 0.050623
[23:12:24.139] iteration 12804 : model1 loss : 0.020656 model2 loss : 0.020155
[23:12:24.837] iteration 12805 : model1 loss : 0.023260 model2 loss : 0.023104
[23:12:25.584] iteration 12806 : model1 loss : 0.020633 model2 loss : 0.022289
[23:12:26.293] iteration 12807 : model1 loss : 0.019702 model2 loss : 0.018951
[23:12:26.998] iteration 12808 : model1 loss : 0.020034 model2 loss : 0.020598
[23:12:27.699] iteration 12809 : model1 loss : 0.025707 model2 loss : 0.022002
[23:12:28.383] iteration 12810 : model1 loss : 0.018338 model2 loss : 0.019744
[23:12:29.090] iteration 12811 : model1 loss : 0.024250 model2 loss : 0.024887
[23:12:29.783] iteration 12812 : model1 loss : 0.033775 model2 loss : 0.029600
[23:12:30.497] iteration 12813 : model1 loss : 0.027217 model2 loss : 0.041772
[23:12:31.201] iteration 12814 : model1 loss : 0.017262 model2 loss : 0.018559
[23:12:31.904] iteration 12815 : model1 loss : 0.017936 model2 loss : 0.018644
[23:12:32.639] iteration 12816 : model1 loss : 0.024960 model2 loss : 0.023423
[23:12:33.383] iteration 12817 : model1 loss : 0.018726 model2 loss : 0.018545
[23:12:34.089] iteration 12818 : model1 loss : 0.027505 model2 loss : 0.028754
[23:12:34.833] iteration 12819 : model1 loss : 0.021278 model2 loss : 0.023309
[23:12:35.567] iteration 12820 : model1 loss : 0.017493 model2 loss : 0.020939
[23:12:36.274] iteration 12821 : model1 loss : 0.085978 model2 loss : 0.104026
[23:12:36.979] iteration 12822 : model1 loss : 0.021483 model2 loss : 0.022088
[23:12:37.727] iteration 12823 : model1 loss : 0.036463 model2 loss : 0.033302
[23:12:38.432] iteration 12824 : model1 loss : 0.022687 model2 loss : 0.024873
[23:12:39.155] iteration 12825 : model1 loss : 0.025182 model2 loss : 0.024134
[23:12:39.875] iteration 12826 : model1 loss : 0.027729 model2 loss : 0.030260
[23:12:40.588] iteration 12827 : model1 loss : 0.020237 model2 loss : 0.021752
[23:12:41.311] iteration 12828 : model1 loss : 0.019806 model2 loss : 0.023165
[23:12:42.032] iteration 12829 : model1 loss : 0.025102 model2 loss : 0.028988
[23:12:42.770] iteration 12830 : model1 loss : 0.020538 model2 loss : 0.022028
[23:12:43.486] iteration 12831 : model1 loss : 0.023433 model2 loss : 0.024699
[23:12:44.190] iteration 12832 : model1 loss : 0.021107 model2 loss : 0.020459
[23:12:44.903] iteration 12833 : model1 loss : 0.025025 model2 loss : 0.031808
[23:12:45.605] iteration 12834 : model1 loss : 0.032142 model2 loss : 0.048443
[23:12:46.311] iteration 12835 : model1 loss : 0.040697 model2 loss : 0.068169
[23:12:47.058] iteration 12836 : model1 loss : 0.019374 model2 loss : 0.018057
[23:12:47.847] iteration 12837 : model1 loss : 0.023571 model2 loss : 0.026428
[23:12:48.608] iteration 12838 : model1 loss : 0.025269 model2 loss : 0.025334
[23:12:49.537] iteration 12839 : model1 loss : 0.022695 model2 loss : 0.024953
[23:12:50.336] iteration 12840 : model1 loss : 0.027899 model2 loss : 0.025977
[23:12:51.077] iteration 12841 : model1 loss : 0.026984 model2 loss : 0.025746
[23:12:51.922] iteration 12842 : model1 loss : 0.027987 model2 loss : 0.024631
[23:12:52.760] iteration 12843 : model1 loss : 0.023404 model2 loss : 0.026086
[23:12:53.512] iteration 12844 : model1 loss : 0.021445 model2 loss : 0.020887
[23:12:54.243] iteration 12845 : model1 loss : 0.019101 model2 loss : 0.019363
[23:12:54.978] iteration 12846 : model1 loss : 0.021196 model2 loss : 0.021940
[23:12:55.650] iteration 12847 : model1 loss : 0.029851 model2 loss : 0.048418
[23:12:56.336] iteration 12848 : model1 loss : 0.021695 model2 loss : 0.025624
[23:12:57.052] iteration 12849 : model1 loss : 0.017699 model2 loss : 0.019238
[23:12:57.733] iteration 12850 : model1 loss : 0.023406 model2 loss : 0.026789
[23:12:58.472] iteration 12851 : model1 loss : 0.058434 model2 loss : 0.063668
[23:12:59.182] iteration 12852 : model1 loss : 0.029567 model2 loss : 0.029954
[23:12:59.873] iteration 12853 : model1 loss : 0.019467 model2 loss : 0.023027
[23:13:00.572] iteration 12854 : model1 loss : 0.019491 model2 loss : 0.020064
[23:13:01.250] iteration 12855 : model1 loss : 0.033213 model2 loss : 0.030629
[23:13:01.927] iteration 12856 : model1 loss : 0.019976 model2 loss : 0.021232
[23:13:02.634] iteration 12857 : model1 loss : 0.022246 model2 loss : 0.023740
[23:13:03.332] iteration 12858 : model1 loss : 0.038215 model2 loss : 0.027715
[23:13:04.034] iteration 12859 : model1 loss : 0.028969 model2 loss : 0.028652
[23:13:04.768] iteration 12860 : model1 loss : 0.030144 model2 loss : 0.033322
[23:13:05.531] iteration 12861 : model1 loss : 0.034406 model2 loss : 0.039208
[23:13:06.313] iteration 12862 : model1 loss : 0.024136 model2 loss : 0.028112
[23:13:07.046] iteration 12863 : model1 loss : 0.028859 model2 loss : 0.033005
[23:13:08.043] iteration 12864 : model1 loss : 0.015899 model2 loss : 0.017762
[23:13:08.749] iteration 12865 : model1 loss : 0.022223 model2 loss : 0.022769
[23:13:09.520] iteration 12866 : model1 loss : 0.023293 model2 loss : 0.023020
[23:13:10.228] iteration 12867 : model1 loss : 0.028039 model2 loss : 0.036747
[23:13:10.912] iteration 12868 : model1 loss : 0.020830 model2 loss : 0.024126
[23:13:11.600] iteration 12869 : model1 loss : 0.017400 model2 loss : 0.019829
[23:13:12.287] iteration 12870 : model1 loss : 0.023246 model2 loss : 0.022436
[23:13:12.983] iteration 12871 : model1 loss : 0.020340 model2 loss : 0.021654
[23:13:13.747] iteration 12872 : model1 loss : 0.023235 model2 loss : 0.024415
[23:13:14.496] iteration 12873 : model1 loss : 0.020740 model2 loss : 0.018785
[23:13:15.198] iteration 12874 : model1 loss : 0.022169 model2 loss : 0.033017
[23:13:15.877] iteration 12875 : model1 loss : 0.023631 model2 loss : 0.023772
[23:13:16.557] iteration 12876 : model1 loss : 0.021393 model2 loss : 0.023845
[23:13:17.227] iteration 12877 : model1 loss : 0.023664 model2 loss : 0.024464
[23:13:17.885] iteration 12878 : model1 loss : 0.016787 model2 loss : 0.017799
[23:13:18.573] iteration 12879 : model1 loss : 0.021938 model2 loss : 0.024565
[23:13:19.238] iteration 12880 : model1 loss : 0.019230 model2 loss : 0.020155
[23:13:19.915] iteration 12881 : model1 loss : 0.016204 model2 loss : 0.017057
[23:13:20.599] iteration 12882 : model1 loss : 0.026776 model2 loss : 0.027207
[23:13:21.270] iteration 12883 : model1 loss : 0.020937 model2 loss : 0.021198
[23:13:21.949] iteration 12884 : model1 loss : 0.040664 model2 loss : 0.039881
[23:13:22.636] iteration 12885 : model1 loss : 0.029942 model2 loss : 0.028039
[23:13:23.335] iteration 12886 : model1 loss : 0.018092 model2 loss : 0.020266
[23:13:24.016] iteration 12887 : model1 loss : 0.024182 model2 loss : 0.026653
[23:13:24.723] iteration 12888 : model1 loss : 0.022931 model2 loss : 0.019273
[23:13:25.393] iteration 12889 : model1 loss : 0.023976 model2 loss : 0.021034
[23:13:26.116] iteration 12890 : model1 loss : 0.019617 model2 loss : 0.017771
[23:13:26.807] iteration 12891 : model1 loss : 0.142077 model2 loss : 0.148727
[23:13:27.501] iteration 12892 : model1 loss : 0.019774 model2 loss : 0.023209
[23:13:28.224] iteration 12893 : model1 loss : 0.023357 model2 loss : 0.028111
[23:13:29.194] iteration 12894 : model1 loss : 0.021092 model2 loss : 0.022767
[23:13:29.987] iteration 12895 : model1 loss : 0.047580 model2 loss : 0.044962
[23:13:30.753] iteration 12896 : model1 loss : 0.022998 model2 loss : 0.022013
[23:13:31.455] iteration 12897 : model1 loss : 0.033918 model2 loss : 0.032243
[23:13:32.185] iteration 12898 : model1 loss : 0.022074 model2 loss : 0.021116
[23:13:32.904] iteration 12899 : model1 loss : 0.020858 model2 loss : 0.022564
[23:13:33.610] iteration 12900 : model1 loss : 0.026615 model2 loss : 0.031653
[23:13:34.372] iteration 12901 : model1 loss : 0.041431 model2 loss : 0.110909
[23:13:35.104] iteration 12902 : model1 loss : 0.022614 model2 loss : 0.022712
[23:13:35.808] iteration 12903 : model1 loss : 0.035915 model2 loss : 0.037944
[23:13:36.524] iteration 12904 : model1 loss : 0.020792 model2 loss : 0.019877
[23:13:37.241] iteration 12905 : model1 loss : 0.020459 model2 loss : 0.021342
[23:13:37.947] iteration 12906 : model1 loss : 0.028287 model2 loss : 0.032016
[23:13:38.683] iteration 12907 : model1 loss : 0.026691 model2 loss : 0.023426
[23:13:39.393] iteration 12908 : model1 loss : 0.020786 model2 loss : 0.019284
[23:13:40.106] iteration 12909 : model1 loss : 0.028128 model2 loss : 0.020104
[23:13:40.803] iteration 12910 : model1 loss : 0.043194 model2 loss : 0.036433
[23:13:41.505] iteration 12911 : model1 loss : 0.062051 model2 loss : 0.029673
[23:13:42.231] iteration 12912 : model1 loss : 0.022456 model2 loss : 0.024875
[23:13:42.933] iteration 12913 : model1 loss : 0.034885 model2 loss : 0.028045
[23:13:43.657] iteration 12914 : model1 loss : 0.021178 model2 loss : 0.022197
[23:13:44.375] iteration 12915 : model1 loss : 0.017485 model2 loss : 0.017355
[23:13:45.083] iteration 12916 : model1 loss : 0.019863 model2 loss : 0.020041
[23:13:45.785] iteration 12917 : model1 loss : 0.017794 model2 loss : 0.020599
[23:13:46.485] iteration 12918 : model1 loss : 0.022533 model2 loss : 0.021879
[23:13:47.209] iteration 12919 : model1 loss : 0.022434 model2 loss : 0.023028
[23:13:47.923] iteration 12920 : model1 loss : 0.024926 model2 loss : 0.023099
[23:13:48.648] iteration 12921 : model1 loss : 0.020098 model2 loss : 0.020823
[23:13:49.366] iteration 12922 : model1 loss : 0.021614 model2 loss : 0.022701
[23:13:50.074] iteration 12923 : model1 loss : 0.018082 model2 loss : 0.018103
[23:13:50.771] iteration 12924 : model1 loss : 0.025183 model2 loss : 0.025450
[23:13:51.476] iteration 12925 : model1 loss : 0.026241 model2 loss : 0.031322
[23:13:52.200] iteration 12926 : model1 loss : 0.016480 model2 loss : 0.017024
[23:13:52.902] iteration 12927 : model1 loss : 0.021237 model2 loss : 0.021011
[23:13:53.618] iteration 12928 : model1 loss : 0.021984 model2 loss : 0.023589
[23:13:54.328] iteration 12929 : model1 loss : 0.023036 model2 loss : 0.024410
[23:13:55.037] iteration 12930 : model1 loss : 0.022452 model2 loss : 0.024006
[23:13:55.761] iteration 12931 : model1 loss : 0.026499 model2 loss : 0.026537
[23:13:56.463] iteration 12932 : model1 loss : 0.143976 model2 loss : 0.142534
[23:13:57.169] iteration 12933 : model1 loss : 0.021834 model2 loss : 0.021043
[23:13:57.882] iteration 12934 : model1 loss : 0.021903 model2 loss : 0.018902
[23:13:58.593] iteration 12935 : model1 loss : 0.029048 model2 loss : 0.018422
[23:13:59.297] iteration 12936 : model1 loss : 0.038172 model2 loss : 0.030872
[23:14:00.057] iteration 12937 : model1 loss : 0.028345 model2 loss : 0.024061
[23:14:00.785] iteration 12938 : model1 loss : 0.024777 model2 loss : 0.029936
[23:14:01.478] iteration 12939 : model1 loss : 0.016147 model2 loss : 0.017037
[23:14:02.191] iteration 12940 : model1 loss : 0.020267 model2 loss : 0.022506
[23:14:02.898] iteration 12941 : model1 loss : 0.019915 model2 loss : 0.019414
[23:14:03.599] iteration 12942 : model1 loss : 0.036263 model2 loss : 0.020466
[23:14:04.303] iteration 12943 : model1 loss : 0.045134 model2 loss : 0.042409
[23:14:04.991] iteration 12944 : model1 loss : 0.028532 model2 loss : 0.026790
[23:14:05.687] iteration 12945 : model1 loss : 0.019739 model2 loss : 0.019204
[23:14:06.389] iteration 12946 : model1 loss : 0.019500 model2 loss : 0.019264
[23:14:07.094] iteration 12947 : model1 loss : 0.018812 model2 loss : 0.017229
[23:14:07.802] iteration 12948 : model1 loss : 0.019690 model2 loss : 0.019417
[23:14:08.489] iteration 12949 : model1 loss : 0.037279 model2 loss : 0.042662
[23:14:09.197] iteration 12950 : model1 loss : 0.045083 model2 loss : 0.049146
[23:14:09.917] iteration 12951 : model1 loss : 0.147318 model2 loss : 0.146603
[23:14:10.615] iteration 12952 : model1 loss : 0.017547 model2 loss : 0.020165
[23:14:11.341] iteration 12953 : model1 loss : 0.028387 model2 loss : 0.025619
[23:14:12.047] iteration 12954 : model1 loss : 0.021915 model2 loss : 0.022405
[23:14:12.765] iteration 12955 : model1 loss : 0.037999 model2 loss : 0.040265
[23:14:13.490] iteration 12956 : model1 loss : 0.018734 model2 loss : 0.017390
[23:14:14.193] iteration 12957 : model1 loss : 0.022139 model2 loss : 0.028967
[23:14:14.899] iteration 12958 : model1 loss : 0.023074 model2 loss : 0.022449
[23:14:15.607] iteration 12959 : model1 loss : 0.021545 model2 loss : 0.022584
[23:14:16.302] iteration 12960 : model1 loss : 0.019120 model2 loss : 0.018984
[23:14:17.034] iteration 12961 : model1 loss : 0.026036 model2 loss : 0.021533
[23:14:17.756] iteration 12962 : model1 loss : 0.021366 model2 loss : 0.019951
[23:14:18.451] iteration 12963 : model1 loss : 0.021036 model2 loss : 0.020746
[23:14:19.164] iteration 12964 : model1 loss : 0.018239 model2 loss : 0.019639
[23:14:19.886] iteration 12965 : model1 loss : 0.020512 model2 loss : 0.020027
[23:14:20.608] iteration 12966 : model1 loss : 0.024406 model2 loss : 0.023683
[23:14:21.326] iteration 12967 : model1 loss : 0.026719 model2 loss : 0.026126
[23:14:22.034] iteration 12968 : model1 loss : 0.028099 model2 loss : 0.026265
[23:14:22.760] iteration 12969 : model1 loss : 0.030789 model2 loss : 0.032612
[23:14:23.481] iteration 12970 : model1 loss : 0.021062 model2 loss : 0.022061
[23:14:24.205] iteration 12971 : model1 loss : 0.018352 model2 loss : 0.018706
[23:14:24.912] iteration 12972 : model1 loss : 0.027000 model2 loss : 0.029441
[23:14:25.619] iteration 12973 : model1 loss : 0.022456 model2 loss : 0.022697
[23:14:26.352] iteration 12974 : model1 loss : 0.021033 model2 loss : 0.021736
[23:14:27.079] iteration 12975 : model1 loss : 0.021583 model2 loss : 0.019063
[23:14:27.787] iteration 12976 : model1 loss : 0.023182 model2 loss : 0.022033
[23:14:28.511] iteration 12977 : model1 loss : 0.048232 model2 loss : 0.038979
[23:14:29.234] iteration 12978 : model1 loss : 0.020992 model2 loss : 0.020862
[23:14:29.945] iteration 12979 : model1 loss : 0.024972 model2 loss : 0.024615
[23:14:30.657] iteration 12980 : model1 loss : 0.025893 model2 loss : 0.022504
[23:14:31.379] iteration 12981 : model1 loss : 0.025483 model2 loss : 0.022414
[23:14:32.095] iteration 12982 : model1 loss : 0.016339 model2 loss : 0.017168
[23:14:32.818] iteration 12983 : model1 loss : 0.022327 model2 loss : 0.021156
[23:14:33.527] iteration 12984 : model1 loss : 0.019692 model2 loss : 0.019482
[23:14:34.230] iteration 12985 : model1 loss : 0.023518 model2 loss : 0.022437
[23:14:34.953] iteration 12986 : model1 loss : 0.025377 model2 loss : 0.025430
[23:14:35.671] iteration 12987 : model1 loss : 0.022757 model2 loss : 0.022507
[23:14:36.389] iteration 12988 : model1 loss : 0.024380 model2 loss : 0.025256
[23:14:37.102] iteration 12989 : model1 loss : 0.025635 model2 loss : 0.023635
[23:14:37.805] iteration 12990 : model1 loss : 0.025545 model2 loss : 0.021090
[23:14:38.509] iteration 12991 : model1 loss : 0.023547 model2 loss : 0.026415
[23:14:39.251] iteration 12992 : model1 loss : 0.031340 model2 loss : 0.031474
[23:14:39.975] iteration 12993 : model1 loss : 0.027689 model2 loss : 0.022882
[23:14:40.682] iteration 12994 : model1 loss : 0.038518 model2 loss : 0.032876
[23:14:41.401] iteration 12995 : model1 loss : 0.024889 model2 loss : 0.023813
[23:14:42.116] iteration 12996 : model1 loss : 0.017990 model2 loss : 0.019189
[23:14:42.849] iteration 12997 : model1 loss : 0.026924 model2 loss : 0.027858
[23:14:43.553] iteration 12998 : model1 loss : 0.021070 model2 loss : 0.023319
[23:14:44.273] iteration 12999 : model1 loss : 0.021152 model2 loss : 0.028686
[23:14:44.981] iteration 13000 : model1 loss : 0.018716 model2 loss : 0.019086
[23:15:05.913] iteration 13000 : model1_mean_dice : 0.856852 model1_mean_hd95 : 6.299369
[23:15:25.821] iteration 13000 : model2_mean_dice : 0.859983 model2_mean_hd95 : 4.364880
[23:15:26.541] iteration 13001 : model1 loss : 0.019080 model2 loss : 0.017743
[23:15:27.261] iteration 13002 : model1 loss : 0.022096 model2 loss : 0.019120
[23:15:27.947] iteration 13003 : model1 loss : 0.025540 model2 loss : 0.027868
[23:15:28.633] iteration 13004 : model1 loss : 0.039400 model2 loss : 0.038257
[23:15:29.324] iteration 13005 : model1 loss : 0.027688 model2 loss : 0.025035
[23:15:30.024] iteration 13006 : model1 loss : 0.019270 model2 loss : 0.022713
[23:15:30.724] iteration 13007 : model1 loss : 0.024882 model2 loss : 0.025723
[23:15:31.438] iteration 13008 : model1 loss : 0.026201 model2 loss : 0.024122
[23:15:32.155] iteration 13009 : model1 loss : 0.040715 model2 loss : 0.039324
[23:15:32.849] iteration 13010 : model1 loss : 0.022565 model2 loss : 0.018457
[23:15:33.539] iteration 13011 : model1 loss : 0.026231 model2 loss : 0.026228
[23:15:34.223] iteration 13012 : model1 loss : 0.021565 model2 loss : 0.021338
[23:15:34.910] iteration 13013 : model1 loss : 0.114916 model2 loss : 0.106565
[23:15:35.613] iteration 13014 : model1 loss : 0.026370 model2 loss : 0.027175
[23:15:36.317] iteration 13015 : model1 loss : 0.022159 model2 loss : 0.022657
[23:15:37.002] iteration 13016 : model1 loss : 0.047518 model2 loss : 0.037889
[23:15:37.704] iteration 13017 : model1 loss : 0.018365 model2 loss : 0.020302
[23:15:38.380] iteration 13018 : model1 loss : 0.026254 model2 loss : 0.028410
[23:15:39.073] iteration 13019 : model1 loss : 0.035157 model2 loss : 0.030954
[23:15:39.755] iteration 13020 : model1 loss : 0.021270 model2 loss : 0.020479
[23:15:40.454] iteration 13021 : model1 loss : 0.017473 model2 loss : 0.019200
[23:15:41.153] iteration 13022 : model1 loss : 0.020762 model2 loss : 0.024015
[23:15:41.836] iteration 13023 : model1 loss : 0.030473 model2 loss : 0.025892
[23:15:42.553] iteration 13024 : model1 loss : 0.023021 model2 loss : 0.025876
[23:15:43.253] iteration 13025 : model1 loss : 0.018521 model2 loss : 0.018253
[23:15:43.933] iteration 13026 : model1 loss : 0.030933 model2 loss : 0.032853
[23:15:44.631] iteration 13027 : model1 loss : 0.022356 model2 loss : 0.022584
[23:15:45.328] iteration 13028 : model1 loss : 0.023848 model2 loss : 0.023617
[23:15:46.007] iteration 13029 : model1 loss : 0.020954 model2 loss : 0.024141
[23:15:46.719] iteration 13030 : model1 loss : 0.021242 model2 loss : 0.021103
[23:15:47.449] iteration 13031 : model1 loss : 0.033472 model2 loss : 0.036233
[23:15:48.137] iteration 13032 : model1 loss : 0.023425 model2 loss : 0.023511
[23:15:48.848] iteration 13033 : model1 loss : 0.027255 model2 loss : 0.024926
[23:15:49.546] iteration 13034 : model1 loss : 0.018232 model2 loss : 0.019114
[23:15:50.230] iteration 13035 : model1 loss : 0.025751 model2 loss : 0.027430
[23:15:50.918] iteration 13036 : model1 loss : 0.016335 model2 loss : 0.016476
[23:15:51.596] iteration 13037 : model1 loss : 0.020640 model2 loss : 0.024633
[23:15:52.297] iteration 13038 : model1 loss : 0.023264 model2 loss : 0.023606
[23:15:52.986] iteration 13039 : model1 loss : 0.018347 model2 loss : 0.018747
[23:15:53.681] iteration 13040 : model1 loss : 0.021409 model2 loss : 0.021407
[23:15:54.376] iteration 13041 : model1 loss : 0.022553 model2 loss : 0.024821
[23:15:55.075] iteration 13042 : model1 loss : 0.018007 model2 loss : 0.017331
[23:15:55.788] iteration 13043 : model1 loss : 0.027555 model2 loss : 0.023719
[23:15:56.463] iteration 13044 : model1 loss : 0.035888 model2 loss : 0.041869
[23:15:57.160] iteration 13045 : model1 loss : 0.018772 model2 loss : 0.019667
[23:15:57.849] iteration 13046 : model1 loss : 0.032061 model2 loss : 0.029117
[23:15:58.538] iteration 13047 : model1 loss : 0.023400 model2 loss : 0.023886
[23:15:59.219] iteration 13048 : model1 loss : 0.015432 model2 loss : 0.014474
[23:15:59.897] iteration 13049 : model1 loss : 0.021665 model2 loss : 0.021132
[23:16:00.598] iteration 13050 : model1 loss : 0.019418 model2 loss : 0.018927
[23:16:01.332] iteration 13051 : model1 loss : 0.024529 model2 loss : 0.021758
[23:16:02.047] iteration 13052 : model1 loss : 0.028253 model2 loss : 0.028834
[23:16:02.750] iteration 13053 : model1 loss : 0.019447 model2 loss : 0.018730
[23:16:03.461] iteration 13054 : model1 loss : 0.025395 model2 loss : 0.036009
[23:16:04.142] iteration 13055 : model1 loss : 0.020138 model2 loss : 0.022316
[23:16:04.833] iteration 13056 : model1 loss : 0.026389 model2 loss : 0.029778
[23:16:05.530] iteration 13057 : model1 loss : 0.023078 model2 loss : 0.022858
[23:16:06.215] iteration 13058 : model1 loss : 0.022257 model2 loss : 0.023077
[23:16:06.914] iteration 13059 : model1 loss : 0.033056 model2 loss : 0.029381
[23:16:07.608] iteration 13060 : model1 loss : 0.020678 model2 loss : 0.019132
[23:16:08.294] iteration 13061 : model1 loss : 0.033363 model2 loss : 0.031591
[23:16:09.005] iteration 13062 : model1 loss : 0.028662 model2 loss : 0.025391
[23:16:09.680] iteration 13063 : model1 loss : 0.021754 model2 loss : 0.025596
[23:16:10.365] iteration 13064 : model1 loss : 0.024089 model2 loss : 0.021412
[23:16:11.053] iteration 13065 : model1 loss : 0.017538 model2 loss : 0.020217
[23:16:11.742] iteration 13066 : model1 loss : 0.022714 model2 loss : 0.021260
[23:16:12.462] iteration 13067 : model1 loss : 0.025178 model2 loss : 0.034842
[23:16:13.149] iteration 13068 : model1 loss : 0.017050 model2 loss : 0.016347
[23:16:13.837] iteration 13069 : model1 loss : 0.020651 model2 loss : 0.020830
[23:16:14.539] iteration 13070 : model1 loss : 0.026570 model2 loss : 0.028512
[23:16:15.222] iteration 13071 : model1 loss : 0.023635 model2 loss : 0.026154
[23:16:15.917] iteration 13072 : model1 loss : 0.017981 model2 loss : 0.019352
[23:16:16.615] iteration 13073 : model1 loss : 0.019298 model2 loss : 0.022884
[23:16:17.332] iteration 13074 : model1 loss : 0.034762 model2 loss : 0.041451
[23:16:18.019] iteration 13075 : model1 loss : 0.026341 model2 loss : 0.030738
[23:16:18.707] iteration 13076 : model1 loss : 0.022683 model2 loss : 0.023260
[23:16:19.397] iteration 13077 : model1 loss : 0.027431 model2 loss : 0.025376
[23:16:20.091] iteration 13078 : model1 loss : 0.026072 model2 loss : 0.026540
[23:16:20.784] iteration 13079 : model1 loss : 0.024220 model2 loss : 0.026476
[23:16:21.488] iteration 13080 : model1 loss : 0.022722 model2 loss : 0.026188
[23:16:22.228] iteration 13081 : model1 loss : 0.027845 model2 loss : 0.025386
[23:16:22.924] iteration 13082 : model1 loss : 0.033094 model2 loss : 0.035818
[23:16:23.611] iteration 13083 : model1 loss : 0.016594 model2 loss : 0.018038
[23:16:24.302] iteration 13084 : model1 loss : 0.021529 model2 loss : 0.021618
[23:16:24.991] iteration 13085 : model1 loss : 0.016865 model2 loss : 0.019147
[23:16:25.694] iteration 13086 : model1 loss : 0.021281 model2 loss : 0.021902
[23:16:26.381] iteration 13087 : model1 loss : 0.027016 model2 loss : 0.028339
[23:16:27.087] iteration 13088 : model1 loss : 0.044783 model2 loss : 0.036138
[23:16:27.814] iteration 13089 : model1 loss : 0.018853 model2 loss : 0.017933
[23:16:28.501] iteration 13090 : model1 loss : 0.020760 model2 loss : 0.021883
[23:16:29.200] iteration 13091 : model1 loss : 0.025261 model2 loss : 0.024156
[23:16:29.899] iteration 13092 : model1 loss : 0.020598 model2 loss : 0.021777
[23:16:30.594] iteration 13093 : model1 loss : 0.018905 model2 loss : 0.019196
[23:16:31.291] iteration 13094 : model1 loss : 0.019273 model2 loss : 0.020414
[23:16:31.983] iteration 13095 : model1 loss : 0.025947 model2 loss : 0.027018
[23:16:32.688] iteration 13096 : model1 loss : 0.026049 model2 loss : 0.027252
[23:16:33.375] iteration 13097 : model1 loss : 0.020081 model2 loss : 0.018995
[23:16:34.064] iteration 13098 : model1 loss : 0.032657 model2 loss : 0.032172
[23:16:34.756] iteration 13099 : model1 loss : 0.050972 model2 loss : 0.048750
[23:16:35.454] iteration 13100 : model1 loss : 0.021547 model2 loss : 0.023220
[23:16:36.191] iteration 13101 : model1 loss : 0.018456 model2 loss : 0.018880
[23:16:36.883] iteration 13102 : model1 loss : 0.147642 model2 loss : 0.149294
[23:16:37.586] iteration 13103 : model1 loss : 0.023086 model2 loss : 0.020945
[23:16:38.269] iteration 13104 : model1 loss : 0.016333 model2 loss : 0.017617
[23:16:38.963] iteration 13105 : model1 loss : 0.017851 model2 loss : 0.014463
[23:16:39.649] iteration 13106 : model1 loss : 0.028283 model2 loss : 0.025667
[23:16:40.338] iteration 13107 : model1 loss : 0.016426 model2 loss : 0.017486
[23:16:41.031] iteration 13108 : model1 loss : 0.024516 model2 loss : 0.032865
[23:16:41.728] iteration 13109 : model1 loss : 0.025152 model2 loss : 0.020692
[23:16:42.437] iteration 13110 : model1 loss : 0.018162 model2 loss : 0.018617
[23:16:43.169] iteration 13111 : model1 loss : 0.042806 model2 loss : 0.037319
[23:16:43.854] iteration 13112 : model1 loss : 0.020450 model2 loss : 0.023039
[23:16:44.545] iteration 13113 : model1 loss : 0.025577 model2 loss : 0.024352
[23:16:45.247] iteration 13114 : model1 loss : 0.025004 model2 loss : 0.026463
[23:16:45.941] iteration 13115 : model1 loss : 0.020650 model2 loss : 0.021881
[23:16:46.631] iteration 13116 : model1 loss : 0.031187 model2 loss : 0.029649
[23:16:47.337] iteration 13117 : model1 loss : 0.017626 model2 loss : 0.016671
[23:16:48.026] iteration 13118 : model1 loss : 0.020913 model2 loss : 0.020715
[23:16:48.724] iteration 13119 : model1 loss : 0.020991 model2 loss : 0.021469
[23:16:49.426] iteration 13120 : model1 loss : 0.022328 model2 loss : 0.020294
[23:16:50.120] iteration 13121 : model1 loss : 0.021858 model2 loss : 0.020811
[23:16:50.812] iteration 13122 : model1 loss : 0.027734 model2 loss : 0.023847
[23:16:51.505] iteration 13123 : model1 loss : 0.027850 model2 loss : 0.029730
[23:16:52.239] iteration 13124 : model1 loss : 0.018940 model2 loss : 0.019663
[23:16:52.930] iteration 13125 : model1 loss : 0.042397 model2 loss : 0.042399
[23:16:53.623] iteration 13126 : model1 loss : 0.024260 model2 loss : 0.021328
[23:16:54.311] iteration 13127 : model1 loss : 0.023555 model2 loss : 0.022256
[23:16:55.003] iteration 13128 : model1 loss : 0.022053 model2 loss : 0.025426
[23:16:55.713] iteration 13129 : model1 loss : 0.021122 model2 loss : 0.022814
[23:16:56.401] iteration 13130 : model1 loss : 0.017509 model2 loss : 0.018374
[23:16:57.085] iteration 13131 : model1 loss : 0.019191 model2 loss : 0.020258
[23:16:57.790] iteration 13132 : model1 loss : 0.018481 model2 loss : 0.018519
[23:16:58.474] iteration 13133 : model1 loss : 0.014778 model2 loss : 0.016031
[23:16:59.155] iteration 13134 : model1 loss : 0.032100 model2 loss : 0.026497
[23:16:59.837] iteration 13135 : model1 loss : 0.020324 model2 loss : 0.023153
[23:17:00.537] iteration 13136 : model1 loss : 0.020933 model2 loss : 0.021116
[23:17:01.233] iteration 13137 : model1 loss : 0.028127 model2 loss : 0.024704
[23:17:01.924] iteration 13138 : model1 loss : 0.025761 model2 loss : 0.022593
[23:17:02.645] iteration 13139 : model1 loss : 0.026300 model2 loss : 0.023662
[23:17:03.340] iteration 13140 : model1 loss : 0.020391 model2 loss : 0.021191
[23:17:04.026] iteration 13141 : model1 loss : 0.017208 model2 loss : 0.016030
[23:17:04.708] iteration 13142 : model1 loss : 0.018243 model2 loss : 0.018433
[23:17:05.400] iteration 13143 : model1 loss : 0.017116 model2 loss : 0.018307
[23:17:06.099] iteration 13144 : model1 loss : 0.037314 model2 loss : 0.033244
[23:17:06.792] iteration 13145 : model1 loss : 0.020636 model2 loss : 0.022002
[23:17:07.511] iteration 13146 : model1 loss : 0.046956 model2 loss : 0.039784
[23:17:08.236] iteration 13147 : model1 loss : 0.025216 model2 loss : 0.025492
[23:17:08.933] iteration 13148 : model1 loss : 0.022928 model2 loss : 0.021708
[23:17:09.623] iteration 13149 : model1 loss : 0.018693 model2 loss : 0.017520
[23:17:10.336] iteration 13150 : model1 loss : 0.038778 model2 loss : 0.046883
[23:17:11.087] iteration 13151 : model1 loss : 0.025072 model2 loss : 0.027381
[23:17:11.794] iteration 13152 : model1 loss : 0.022569 model2 loss : 0.020295
[23:17:12.543] iteration 13153 : model1 loss : 0.020093 model2 loss : 0.018969
[23:17:13.291] iteration 13154 : model1 loss : 0.023065 model2 loss : 0.021644
[23:17:14.012] iteration 13155 : model1 loss : 0.023343 model2 loss : 0.023596
[23:17:14.724] iteration 13156 : model1 loss : 0.022378 model2 loss : 0.020999
[23:17:15.426] iteration 13157 : model1 loss : 0.015490 model2 loss : 0.015334
[23:17:16.105] iteration 13158 : model1 loss : 0.087257 model2 loss : 0.096877
[23:17:16.800] iteration 13159 : model1 loss : 0.019564 model2 loss : 0.026299
[23:17:17.513] iteration 13160 : model1 loss : 0.020454 model2 loss : 0.020492
[23:17:18.191] iteration 13161 : model1 loss : 0.021229 model2 loss : 0.021718
[23:17:18.881] iteration 13162 : model1 loss : 0.019157 model2 loss : 0.020612
[23:17:19.576] iteration 13163 : model1 loss : 0.024832 model2 loss : 0.026527
[23:17:20.270] iteration 13164 : model1 loss : 0.019293 model2 loss : 0.021104
[23:17:20.990] iteration 13165 : model1 loss : 0.022696 model2 loss : 0.021082
[23:17:21.691] iteration 13166 : model1 loss : 0.025409 model2 loss : 0.023172
[23:17:22.408] iteration 13167 : model1 loss : 0.032228 model2 loss : 0.033065
[23:17:23.106] iteration 13168 : model1 loss : 0.020388 model2 loss : 0.021906
[23:17:23.792] iteration 13169 : model1 loss : 0.022055 model2 loss : 0.024217
[23:17:24.489] iteration 13170 : model1 loss : 0.025297 model2 loss : 0.024612
[23:17:25.178] iteration 13171 : model1 loss : 0.023317 model2 loss : 0.020875
[23:17:25.869] iteration 13172 : model1 loss : 0.027989 model2 loss : 0.027752
[23:17:26.558] iteration 13173 : model1 loss : 0.021170 model2 loss : 0.021064
[23:17:27.259] iteration 13174 : model1 loss : 0.021913 model2 loss : 0.023102
[23:17:28.001] iteration 13175 : model1 loss : 0.026368 model2 loss : 0.025343
[23:17:28.706] iteration 13176 : model1 loss : 0.016615 model2 loss : 0.018642
[23:17:29.396] iteration 13177 : model1 loss : 0.020093 model2 loss : 0.022432
[23:17:30.102] iteration 13178 : model1 loss : 0.025034 model2 loss : 0.025326
[23:17:30.794] iteration 13179 : model1 loss : 0.023098 model2 loss : 0.021863
[23:17:31.509] iteration 13180 : model1 loss : 0.026843 model2 loss : 0.027553
[23:17:32.237] iteration 13181 : model1 loss : 0.020096 model2 loss : 0.020765
[23:17:32.947] iteration 13182 : model1 loss : 0.032615 model2 loss : 0.044134
[23:17:33.648] iteration 13183 : model1 loss : 0.027799 model2 loss : 0.029035
[23:17:34.333] iteration 13184 : model1 loss : 0.021013 model2 loss : 0.023206
[23:17:35.024] iteration 13185 : model1 loss : 0.020907 model2 loss : 0.025664
[23:17:35.709] iteration 13186 : model1 loss : 0.017775 model2 loss : 0.016944
[23:17:36.402] iteration 13187 : model1 loss : 0.017964 model2 loss : 0.018671
[23:17:37.103] iteration 13188 : model1 loss : 0.026585 model2 loss : 0.022355
[23:17:37.806] iteration 13189 : model1 loss : 0.031471 model2 loss : 0.026011
[23:17:38.495] iteration 13190 : model1 loss : 0.024241 model2 loss : 0.024289
[23:17:39.179] iteration 13191 : model1 loss : 0.021926 model2 loss : 0.022093
[23:17:39.860] iteration 13192 : model1 loss : 0.031004 model2 loss : 0.031087
[23:17:40.557] iteration 13193 : model1 loss : 0.019760 model2 loss : 0.021720
[23:17:41.260] iteration 13194 : model1 loss : 0.017928 model2 loss : 0.019679
[23:17:41.962] iteration 13195 : model1 loss : 0.021211 model2 loss : 0.018926
[23:17:42.663] iteration 13196 : model1 loss : 0.022036 model2 loss : 0.023816
[23:17:43.365] iteration 13197 : model1 loss : 0.017534 model2 loss : 0.017131
[23:17:44.046] iteration 13198 : model1 loss : 0.030369 model2 loss : 0.029115
[23:17:44.737] iteration 13199 : model1 loss : 0.025198 model2 loss : 0.025462
[23:17:45.427] iteration 13200 : model1 loss : 0.019101 model2 loss : 0.021391
[23:18:05.198] iteration 13200 : model1_mean_dice : 0.861526 model1_mean_hd95 : 3.923165
[23:18:24.767] iteration 13200 : model2_mean_dice : 0.866729 model2_mean_hd95 : 4.026476
[23:18:25.463] iteration 13201 : model1 loss : 0.017708 model2 loss : 0.017275
[23:18:26.146] iteration 13202 : model1 loss : 0.022735 model2 loss : 0.024556
[23:18:26.839] iteration 13203 : model1 loss : 0.025567 model2 loss : 0.027316
[23:18:27.537] iteration 13204 : model1 loss : 0.015521 model2 loss : 0.017516
[23:18:28.254] iteration 13205 : model1 loss : 0.024101 model2 loss : 0.024043
[23:18:28.936] iteration 13206 : model1 loss : 0.046852 model2 loss : 0.046195
[23:18:29.626] iteration 13207 : model1 loss : 0.025430 model2 loss : 0.026395
[23:18:30.303] iteration 13208 : model1 loss : 0.024132 model2 loss : 0.023653
[23:18:30.977] iteration 13209 : model1 loss : 0.024280 model2 loss : 0.023703
[23:18:31.658] iteration 13210 : model1 loss : 0.025743 model2 loss : 0.024962
[23:18:32.366] iteration 13211 : model1 loss : 0.027436 model2 loss : 0.026312
[23:18:33.052] iteration 13212 : model1 loss : 0.017821 model2 loss : 0.017354
[23:18:33.736] iteration 13213 : model1 loss : 0.017431 model2 loss : 0.018804
[23:18:34.412] iteration 13214 : model1 loss : 0.024984 model2 loss : 0.036491
[23:18:35.110] iteration 13215 : model1 loss : 0.025864 model2 loss : 0.025930
[23:18:35.800] iteration 13216 : model1 loss : 0.022806 model2 loss : 0.023077
[23:18:36.494] iteration 13217 : model1 loss : 0.020505 model2 loss : 0.019851
[23:18:37.199] iteration 13218 : model1 loss : 0.016727 model2 loss : 0.020064
[23:18:37.904] iteration 13219 : model1 loss : 0.019063 model2 loss : 0.020167
[23:18:38.599] iteration 13220 : model1 loss : 0.029892 model2 loss : 0.027332
[23:18:39.283] iteration 13221 : model1 loss : 0.023682 model2 loss : 0.031736
[23:18:39.978] iteration 13222 : model1 loss : 0.017160 model2 loss : 0.019761
[23:18:40.678] iteration 13223 : model1 loss : 0.022703 model2 loss : 0.023264
[23:18:41.370] iteration 13224 : model1 loss : 0.020240 model2 loss : 0.017912
[23:18:42.054] iteration 13225 : model1 loss : 0.019430 model2 loss : 0.022207
[23:18:42.747] iteration 13226 : model1 loss : 0.027457 model2 loss : 0.026129
[23:18:43.432] iteration 13227 : model1 loss : 0.019225 model2 loss : 0.019307
[23:18:44.119] iteration 13228 : model1 loss : 0.031562 model2 loss : 0.031503
[23:18:44.805] iteration 13229 : model1 loss : 0.025895 model2 loss : 0.027292
[23:18:45.482] iteration 13230 : model1 loss : 0.028145 model2 loss : 0.037511
[23:18:46.166] iteration 13231 : model1 loss : 0.035320 model2 loss : 0.038177
[23:18:46.884] iteration 13232 : model1 loss : 0.027500 model2 loss : 0.030449
[23:18:47.584] iteration 13233 : model1 loss : 0.023329 model2 loss : 0.024655
[23:18:48.281] iteration 13234 : model1 loss : 0.142053 model2 loss : 0.143105
[23:18:48.976] iteration 13235 : model1 loss : 0.026671 model2 loss : 0.025637
[23:18:49.659] iteration 13236 : model1 loss : 0.023280 model2 loss : 0.028262
[23:18:50.342] iteration 13237 : model1 loss : 0.049855 model2 loss : 0.040766
[23:18:51.028] iteration 13238 : model1 loss : 0.027169 model2 loss : 0.026421
[23:18:51.713] iteration 13239 : model1 loss : 0.029662 model2 loss : 0.030149
[23:18:52.428] iteration 13240 : model1 loss : 0.018640 model2 loss : 0.020553
[23:18:53.132] iteration 13241 : model1 loss : 0.025066 model2 loss : 0.027861
[23:18:53.817] iteration 13242 : model1 loss : 0.015548 model2 loss : 0.015292
[23:18:54.498] iteration 13243 : model1 loss : 0.023126 model2 loss : 0.021317
[23:18:55.194] iteration 13244 : model1 loss : 0.018935 model2 loss : 0.018323
[23:18:55.874] iteration 13245 : model1 loss : 0.024461 model2 loss : 0.020967
[23:18:56.564] iteration 13246 : model1 loss : 0.029878 model2 loss : 0.028005
[23:18:57.269] iteration 13247 : model1 loss : 0.037695 model2 loss : 0.046028
[23:18:57.958] iteration 13248 : model1 loss : 0.026332 model2 loss : 0.022124
[23:18:58.657] iteration 13249 : model1 loss : 0.029045 model2 loss : 0.033296
[23:18:59.358] iteration 13250 : model1 loss : 0.020067 model2 loss : 0.021046
[23:19:00.070] iteration 13251 : model1 loss : 0.046470 model2 loss : 0.062994
[23:19:00.820] iteration 13252 : model1 loss : 0.023855 model2 loss : 0.022310
[23:19:01.552] iteration 13253 : model1 loss : 0.024511 model2 loss : 0.026457
[23:19:02.270] iteration 13254 : model1 loss : 0.020129 model2 loss : 0.020410
[23:19:02.955] iteration 13255 : model1 loss : 0.020834 model2 loss : 0.020062
[23:19:03.642] iteration 13256 : model1 loss : 0.024157 model2 loss : 0.023524
[23:19:04.333] iteration 13257 : model1 loss : 0.029269 model2 loss : 0.030335
[23:19:05.039] iteration 13258 : model1 loss : 0.022712 model2 loss : 0.023416
[23:19:05.725] iteration 13259 : model1 loss : 0.016980 model2 loss : 0.016694
[23:19:06.415] iteration 13260 : model1 loss : 0.019240 model2 loss : 0.020028
[23:19:07.118] iteration 13261 : model1 loss : 0.030998 model2 loss : 0.031671
[23:19:07.810] iteration 13262 : model1 loss : 0.025321 model2 loss : 0.023932
[23:19:08.505] iteration 13263 : model1 loss : 0.028225 model2 loss : 0.022655
[23:19:09.196] iteration 13264 : model1 loss : 0.029552 model2 loss : 0.026493
[23:19:09.882] iteration 13265 : model1 loss : 0.022887 model2 loss : 0.022130
[23:19:10.577] iteration 13266 : model1 loss : 0.017984 model2 loss : 0.019057
[23:19:11.277] iteration 13267 : model1 loss : 0.018462 model2 loss : 0.018894
[23:19:11.966] iteration 13268 : model1 loss : 0.023215 model2 loss : 0.025024
[23:19:12.709] iteration 13269 : model1 loss : 0.023332 model2 loss : 0.020415
[23:19:13.399] iteration 13270 : model1 loss : 0.023099 model2 loss : 0.022881
[23:19:14.093] iteration 13271 : model1 loss : 0.022475 model2 loss : 0.022942
[23:19:14.774] iteration 13272 : model1 loss : 0.017735 model2 loss : 0.018104
[23:19:15.476] iteration 13273 : model1 loss : 0.030483 model2 loss : 0.027405
[23:19:16.152] iteration 13274 : model1 loss : 0.022679 model2 loss : 0.026534
[23:19:16.862] iteration 13275 : model1 loss : 0.144465 model2 loss : 0.142871
[23:19:17.576] iteration 13276 : model1 loss : 0.070037 model2 loss : 0.095259
[23:19:18.259] iteration 13277 : model1 loss : 0.021679 model2 loss : 0.022027
[23:19:18.951] iteration 13278 : model1 loss : 0.028869 model2 loss : 0.027247
[23:19:19.650] iteration 13279 : model1 loss : 0.020189 model2 loss : 0.019257
[23:19:20.351] iteration 13280 : model1 loss : 0.025032 model2 loss : 0.024405
[23:19:21.053] iteration 13281 : model1 loss : 0.031757 model2 loss : 0.031459
[23:19:21.753] iteration 13282 : model1 loss : 0.020439 model2 loss : 0.028047
[23:19:22.471] iteration 13283 : model1 loss : 0.143512 model2 loss : 0.149086
[23:19:23.157] iteration 13284 : model1 loss : 0.017787 model2 loss : 0.020002
[23:19:23.845] iteration 13285 : model1 loss : 0.021464 model2 loss : 0.021063
[23:19:24.533] iteration 13286 : model1 loss : 0.023276 model2 loss : 0.022853
[23:19:25.223] iteration 13287 : model1 loss : 0.018231 model2 loss : 0.018027
[23:19:25.932] iteration 13288 : model1 loss : 0.018665 model2 loss : 0.017780
[23:19:26.638] iteration 13289 : model1 loss : 0.030360 model2 loss : 0.028268
[23:19:27.366] iteration 13290 : model1 loss : 0.022040 model2 loss : 0.024205
[23:19:28.054] iteration 13291 : model1 loss : 0.020046 model2 loss : 0.021135
[23:19:28.789] iteration 13292 : model1 loss : 0.025229 model2 loss : 0.023407
[23:19:29.499] iteration 13293 : model1 loss : 0.030779 model2 loss : 0.029846
[23:19:30.205] iteration 13294 : model1 loss : 0.017465 model2 loss : 0.019308
[23:19:30.905] iteration 13295 : model1 loss : 0.021284 model2 loss : 0.022476
[23:19:31.600] iteration 13296 : model1 loss : 0.023312 model2 loss : 0.021849
[23:19:32.320] iteration 13297 : model1 loss : 0.030944 model2 loss : 0.070889
[23:19:33.032] iteration 13298 : model1 loss : 0.021793 model2 loss : 0.017464
[23:19:33.714] iteration 13299 : model1 loss : 0.018507 model2 loss : 0.019384
[23:19:34.401] iteration 13300 : model1 loss : 0.020433 model2 loss : 0.021452
[23:19:35.152] iteration 13301 : model1 loss : 0.021333 model2 loss : 0.023349
[23:19:35.843] iteration 13302 : model1 loss : 0.026000 model2 loss : 0.024592
[23:19:36.531] iteration 13303 : model1 loss : 0.023284 model2 loss : 0.022145
[23:19:37.273] iteration 13304 : model1 loss : 0.017805 model2 loss : 0.019115
[23:19:37.960] iteration 13305 : model1 loss : 0.020749 model2 loss : 0.021485
[23:19:38.682] iteration 13306 : model1 loss : 0.018059 model2 loss : 0.019206
[23:19:39.381] iteration 13307 : model1 loss : 0.026113 model2 loss : 0.021650
[23:19:40.064] iteration 13308 : model1 loss : 0.023281 model2 loss : 0.028054
[23:19:40.787] iteration 13309 : model1 loss : 0.015891 model2 loss : 0.016725
[23:19:41.512] iteration 13310 : model1 loss : 0.023969 model2 loss : 0.037482
[23:19:42.227] iteration 13311 : model1 loss : 0.019873 model2 loss : 0.022568
[23:19:42.921] iteration 13312 : model1 loss : 0.037515 model2 loss : 0.037263
[23:19:43.619] iteration 13313 : model1 loss : 0.022132 model2 loss : 0.022745
[23:19:44.302] iteration 13314 : model1 loss : 0.020034 model2 loss : 0.023913
[23:19:44.998] iteration 13315 : model1 loss : 0.021540 model2 loss : 0.021629
[23:19:45.684] iteration 13316 : model1 loss : 0.022843 model2 loss : 0.024139
[23:19:46.380] iteration 13317 : model1 loss : 0.019861 model2 loss : 0.019571
[23:19:47.094] iteration 13318 : model1 loss : 0.023581 model2 loss : 0.022788
[23:19:47.785] iteration 13319 : model1 loss : 0.019124 model2 loss : 0.020128
[23:19:48.487] iteration 13320 : model1 loss : 0.031673 model2 loss : 0.031810
[23:19:49.181] iteration 13321 : model1 loss : 0.149967 model2 loss : 0.145212
[23:19:49.857] iteration 13322 : model1 loss : 0.022245 model2 loss : 0.020865
[23:19:50.544] iteration 13323 : model1 loss : 0.017796 model2 loss : 0.016305
[23:19:51.238] iteration 13324 : model1 loss : 0.021231 model2 loss : 0.021301
[23:19:51.950] iteration 13325 : model1 loss : 0.015777 model2 loss : 0.014977
[23:19:52.654] iteration 13326 : model1 loss : 0.084902 model2 loss : 0.080416
[23:19:53.348] iteration 13327 : model1 loss : 0.024696 model2 loss : 0.024117
[23:19:54.038] iteration 13328 : model1 loss : 0.029597 model2 loss : 0.029709
[23:19:54.720] iteration 13329 : model1 loss : 0.017515 model2 loss : 0.017337
[23:19:55.401] iteration 13330 : model1 loss : 0.024186 model2 loss : 0.026147
[23:19:56.095] iteration 13331 : model1 loss : 0.023318 model2 loss : 0.023180
[23:19:56.780] iteration 13332 : model1 loss : 0.071804 model2 loss : 0.061723
[23:19:57.505] iteration 13333 : model1 loss : 0.034648 model2 loss : 0.035418
[23:19:58.190] iteration 13334 : model1 loss : 0.025855 model2 loss : 0.027517
[23:19:58.876] iteration 13335 : model1 loss : 0.015820 model2 loss : 0.016773
[23:19:59.565] iteration 13336 : model1 loss : 0.016952 model2 loss : 0.017208
[23:20:00.244] iteration 13337 : model1 loss : 0.019444 model2 loss : 0.019212
[23:20:00.922] iteration 13338 : model1 loss : 0.035191 model2 loss : 0.034622
[23:20:01.624] iteration 13339 : model1 loss : 0.025783 model2 loss : 0.024138
[23:20:02.343] iteration 13340 : model1 loss : 0.031879 model2 loss : 0.033878
[23:20:03.038] iteration 13341 : model1 loss : 0.029297 model2 loss : 0.030300
[23:20:03.731] iteration 13342 : model1 loss : 0.024228 model2 loss : 0.023539
[23:20:04.450] iteration 13343 : model1 loss : 0.022259 model2 loss : 0.021460
[23:20:05.149] iteration 13344 : model1 loss : 0.026691 model2 loss : 0.028141
[23:20:05.835] iteration 13345 : model1 loss : 0.020706 model2 loss : 0.019865
[23:20:06.522] iteration 13346 : model1 loss : 0.020791 model2 loss : 0.023165
[23:20:07.232] iteration 13347 : model1 loss : 0.025338 model2 loss : 0.025578
[23:20:07.919] iteration 13348 : model1 loss : 0.033859 model2 loss : 0.032094
[23:20:08.616] iteration 13349 : model1 loss : 0.015336 model2 loss : 0.016033
[23:20:09.315] iteration 13350 : model1 loss : 0.027153 model2 loss : 0.031464
[23:20:10.043] iteration 13351 : model1 loss : 0.021585 model2 loss : 0.018608
[23:20:10.724] iteration 13352 : model1 loss : 0.022288 model2 loss : 0.021037
[23:20:11.433] iteration 13353 : model1 loss : 0.020969 model2 loss : 0.019747
[23:20:12.142] iteration 13354 : model1 loss : 0.020836 model2 loss : 0.020430
[23:20:12.843] iteration 13355 : model1 loss : 0.015729 model2 loss : 0.017091
[23:20:13.533] iteration 13356 : model1 loss : 0.020152 model2 loss : 0.020139
[23:20:14.232] iteration 13357 : model1 loss : 0.026152 model2 loss : 0.031545
[23:20:14.919] iteration 13358 : model1 loss : 0.033109 model2 loss : 0.026707
[23:20:15.608] iteration 13359 : model1 loss : 0.042311 model2 loss : 0.025355
[23:20:16.305] iteration 13360 : model1 loss : 0.018997 model2 loss : 0.018999
[23:20:16.996] iteration 13361 : model1 loss : 0.019189 model2 loss : 0.019225
[23:20:17.700] iteration 13362 : model1 loss : 0.020029 model2 loss : 0.020149
[23:20:18.406] iteration 13363 : model1 loss : 0.028180 model2 loss : 0.026561
[23:20:19.098] iteration 13364 : model1 loss : 0.021444 model2 loss : 0.021770
[23:20:19.788] iteration 13365 : model1 loss : 0.018631 model2 loss : 0.018466
[23:20:20.478] iteration 13366 : model1 loss : 0.015097 model2 loss : 0.016482
[23:20:21.164] iteration 13367 : model1 loss : 0.019000 model2 loss : 0.022662
[23:20:21.860] iteration 13368 : model1 loss : 0.020160 model2 loss : 0.018349
[23:20:22.569] iteration 13369 : model1 loss : 0.018547 model2 loss : 0.020158
[23:20:23.260] iteration 13370 : model1 loss : 0.030928 model2 loss : 0.022911
[23:20:23.962] iteration 13371 : model1 loss : 0.017297 model2 loss : 0.018459
[23:20:24.642] iteration 13372 : model1 loss : 0.026052 model2 loss : 0.027913
[23:20:25.341] iteration 13373 : model1 loss : 0.020988 model2 loss : 0.020963
[23:20:26.032] iteration 13374 : model1 loss : 0.016822 model2 loss : 0.016722
[23:20:26.718] iteration 13375 : model1 loss : 0.018796 model2 loss : 0.019326
[23:20:27.434] iteration 13376 : model1 loss : 0.019598 model2 loss : 0.019025
[23:20:28.121] iteration 13377 : model1 loss : 0.023815 model2 loss : 0.021606
[23:20:28.812] iteration 13378 : model1 loss : 0.024899 model2 loss : 0.022560
[23:20:29.529] iteration 13379 : model1 loss : 0.016795 model2 loss : 0.017515
[23:20:30.222] iteration 13380 : model1 loss : 0.024521 model2 loss : 0.023050
[23:20:30.906] iteration 13381 : model1 loss : 0.025216 model2 loss : 0.028439
[23:20:31.625] iteration 13382 : model1 loss : 0.019787 model2 loss : 0.018139
[23:20:32.334] iteration 13383 : model1 loss : 0.027796 model2 loss : 0.026961
[23:20:33.030] iteration 13384 : model1 loss : 0.027761 model2 loss : 0.025621
[23:20:33.728] iteration 13385 : model1 loss : 0.021496 model2 loss : 0.020573
[23:20:34.407] iteration 13386 : model1 loss : 0.021064 model2 loss : 0.020210
[23:20:35.105] iteration 13387 : model1 loss : 0.019394 model2 loss : 0.021063
[23:20:35.789] iteration 13388 : model1 loss : 0.020203 model2 loss : 0.020446
[23:20:36.489] iteration 13389 : model1 loss : 0.021194 model2 loss : 0.020055
[23:20:37.205] iteration 13390 : model1 loss : 0.023012 model2 loss : 0.024061
[23:20:37.960] iteration 13391 : model1 loss : 0.019751 model2 loss : 0.020099
[23:20:38.653] iteration 13392 : model1 loss : 0.037395 model2 loss : 0.033336
[23:20:39.365] iteration 13393 : model1 loss : 0.022087 model2 loss : 0.019349
[23:20:40.060] iteration 13394 : model1 loss : 0.041712 model2 loss : 0.035397
[23:20:40.757] iteration 13395 : model1 loss : 0.019100 model2 loss : 0.017819
[23:20:41.458] iteration 13396 : model1 loss : 0.072387 model2 loss : 0.080952
[23:20:42.167] iteration 13397 : model1 loss : 0.033127 model2 loss : 0.030015
[23:20:42.864] iteration 13398 : model1 loss : 0.020653 model2 loss : 0.020330
[23:20:43.555] iteration 13399 : model1 loss : 0.019942 model2 loss : 0.022782
[23:20:44.249] iteration 13400 : model1 loss : 0.023828 model2 loss : 0.028073
[23:21:03.973] iteration 13400 : model1_mean_dice : 0.843881 model1_mean_hd95 : 5.671890
[23:21:24.021] iteration 13400 : model2_mean_dice : 0.861033 model2_mean_hd95 : 4.877135
[23:21:24.778] iteration 13401 : model1 loss : 0.023336 model2 loss : 0.023311
[23:21:25.500] iteration 13402 : model1 loss : 0.019053 model2 loss : 0.022435
[23:21:26.173] iteration 13403 : model1 loss : 0.025442 model2 loss : 0.023806
[23:21:26.852] iteration 13404 : model1 loss : 0.021420 model2 loss : 0.022268
[23:21:27.557] iteration 13405 : model1 loss : 0.025768 model2 loss : 0.028504
[23:21:28.253] iteration 13406 : model1 loss : 0.020517 model2 loss : 0.022455
[23:21:28.952] iteration 13407 : model1 loss : 0.021832 model2 loss : 0.022359
[23:21:29.652] iteration 13408 : model1 loss : 0.040865 model2 loss : 0.038573
[23:21:30.358] iteration 13409 : model1 loss : 0.025401 model2 loss : 0.028616
[23:21:31.049] iteration 13410 : model1 loss : 0.018584 model2 loss : 0.018482
[23:21:31.724] iteration 13411 : model1 loss : 0.019143 model2 loss : 0.022369
[23:21:32.446] iteration 13412 : model1 loss : 0.024984 model2 loss : 0.022902
[23:21:33.138] iteration 13413 : model1 loss : 0.016057 model2 loss : 0.017477
[23:21:33.849] iteration 13414 : model1 loss : 0.025880 model2 loss : 0.023671
[23:21:34.540] iteration 13415 : model1 loss : 0.019290 model2 loss : 0.018664
[23:21:35.222] iteration 13416 : model1 loss : 0.027159 model2 loss : 0.030396
[23:21:35.902] iteration 13417 : model1 loss : 0.017752 model2 loss : 0.017856
[23:21:36.583] iteration 13418 : model1 loss : 0.019868 model2 loss : 0.022597
[23:21:37.293] iteration 13419 : model1 loss : 0.026033 model2 loss : 0.022812
[23:21:37.990] iteration 13420 : model1 loss : 0.034142 model2 loss : 0.032577
[23:21:38.739] iteration 13421 : model1 loss : 0.024868 model2 loss : 0.022459
[23:21:39.435] iteration 13422 : model1 loss : 0.023535 model2 loss : 0.022877
[23:21:40.120] iteration 13423 : model1 loss : 0.020924 model2 loss : 0.025518
[23:21:40.796] iteration 13424 : model1 loss : 0.028588 model2 loss : 0.028539
[23:21:41.493] iteration 13425 : model1 loss : 0.022680 model2 loss : 0.022942
[23:21:42.193] iteration 13426 : model1 loss : 0.019280 model2 loss : 0.023227
[23:21:42.887] iteration 13427 : model1 loss : 0.029844 model2 loss : 0.046628
[23:21:43.575] iteration 13428 : model1 loss : 0.022372 model2 loss : 0.022457
[23:21:44.269] iteration 13429 : model1 loss : 0.040926 model2 loss : 0.039346
[23:21:44.957] iteration 13430 : model1 loss : 0.023708 model2 loss : 0.026092
[23:21:45.651] iteration 13431 : model1 loss : 0.031909 model2 loss : 0.030596
[23:21:46.340] iteration 13432 : model1 loss : 0.018048 model2 loss : 0.019768
[23:21:47.043] iteration 13433 : model1 loss : 0.078757 model2 loss : 0.059854
[23:21:47.763] iteration 13434 : model1 loss : 0.020340 model2 loss : 0.021015
[23:21:48.458] iteration 13435 : model1 loss : 0.025301 model2 loss : 0.022669
[23:21:49.140] iteration 13436 : model1 loss : 0.023321 model2 loss : 0.021336
[23:21:49.822] iteration 13437 : model1 loss : 0.033043 model2 loss : 0.029370
[23:21:50.518] iteration 13438 : model1 loss : 0.021518 model2 loss : 0.021178
[23:21:51.226] iteration 13439 : model1 loss : 0.025063 model2 loss : 0.023991
[23:21:51.924] iteration 13440 : model1 loss : 0.027121 model2 loss : 0.027436
[23:21:52.648] iteration 13441 : model1 loss : 0.020500 model2 loss : 0.020826
[23:21:53.350] iteration 13442 : model1 loss : 0.014449 model2 loss : 0.014421
[23:21:54.018] iteration 13443 : model1 loss : 0.026389 model2 loss : 0.025868
[23:21:54.696] iteration 13444 : model1 loss : 0.021631 model2 loss : 0.021222
[23:21:55.393] iteration 13445 : model1 loss : 0.026798 model2 loss : 0.023252
[23:21:56.071] iteration 13446 : model1 loss : 0.023429 model2 loss : 0.021954
[23:21:56.766] iteration 13447 : model1 loss : 0.045145 model2 loss : 0.029814
[23:21:57.479] iteration 13448 : model1 loss : 0.021016 model2 loss : 0.018492
[23:21:58.157] iteration 13449 : model1 loss : 0.073168 model2 loss : 0.064487
[23:21:58.845] iteration 13450 : model1 loss : 0.022901 model2 loss : 0.020933
[23:21:59.580] iteration 13451 : model1 loss : 0.027678 model2 loss : 0.028866
[23:22:00.277] iteration 13452 : model1 loss : 0.039335 model2 loss : 0.031545
[23:22:00.959] iteration 13453 : model1 loss : 0.020825 model2 loss : 0.020722
[23:22:01.656] iteration 13454 : model1 loss : 0.034155 model2 loss : 0.042496
[23:22:02.371] iteration 13455 : model1 loss : 0.019615 model2 loss : 0.018318
[23:22:03.065] iteration 13456 : model1 loss : 0.017318 model2 loss : 0.018782
[23:22:03.752] iteration 13457 : model1 loss : 0.021180 model2 loss : 0.019509
[23:22:04.454] iteration 13458 : model1 loss : 0.023501 model2 loss : 0.020789
[23:22:05.132] iteration 13459 : model1 loss : 0.050526 model2 loss : 0.033825
[23:22:05.807] iteration 13460 : model1 loss : 0.026665 model2 loss : 0.033193
[23:22:06.495] iteration 13461 : model1 loss : 0.030097 model2 loss : 0.029991
[23:22:07.190] iteration 13462 : model1 loss : 0.028883 model2 loss : 0.024970
[23:22:07.889] iteration 13463 : model1 loss : 0.028222 model2 loss : 0.028415
[23:22:08.594] iteration 13464 : model1 loss : 0.020934 model2 loss : 0.025115
[23:22:09.282] iteration 13465 : model1 loss : 0.023211 model2 loss : 0.023698
[23:22:09.975] iteration 13466 : model1 loss : 0.022746 model2 loss : 0.020765
[23:22:10.657] iteration 13467 : model1 loss : 0.026484 model2 loss : 0.022900
[23:22:11.356] iteration 13468 : model1 loss : 0.026419 model2 loss : 0.019873
[23:22:12.071] iteration 13469 : model1 loss : 0.025632 model2 loss : 0.026200
[23:22:12.777] iteration 13470 : model1 loss : 0.021520 model2 loss : 0.020150
[23:22:13.464] iteration 13471 : model1 loss : 0.022146 model2 loss : 0.022980
[23:22:14.140] iteration 13472 : model1 loss : 0.019597 model2 loss : 0.021367
[23:22:14.824] iteration 13473 : model1 loss : 0.017658 model2 loss : 0.018234
[23:22:15.511] iteration 13474 : model1 loss : 0.018683 model2 loss : 0.017594
[23:22:16.197] iteration 13475 : model1 loss : 0.028939 model2 loss : 0.028294
[23:22:16.890] iteration 13476 : model1 loss : 0.020124 model2 loss : 0.020364
[23:22:17.603] iteration 13477 : model1 loss : 0.049117 model2 loss : 0.049033
[23:22:18.281] iteration 13478 : model1 loss : 0.032194 model2 loss : 0.036230
[23:22:18.976] iteration 13479 : model1 loss : 0.028017 model2 loss : 0.028920
[23:22:19.654] iteration 13480 : model1 loss : 0.022728 model2 loss : 0.027809
[23:22:20.340] iteration 13481 : model1 loss : 0.020287 model2 loss : 0.021028
[23:22:21.027] iteration 13482 : model1 loss : 0.021414 model2 loss : 0.020366
[23:22:21.723] iteration 13483 : model1 loss : 0.020560 model2 loss : 0.021599
[23:22:22.445] iteration 13484 : model1 loss : 0.033397 model2 loss : 0.032390
[23:22:23.134] iteration 13485 : model1 loss : 0.026562 model2 loss : 0.025289
[23:22:23.832] iteration 13486 : model1 loss : 0.019675 model2 loss : 0.020176
[23:22:24.526] iteration 13487 : model1 loss : 0.021519 model2 loss : 0.025125
[23:22:25.211] iteration 13488 : model1 loss : 0.024113 model2 loss : 0.031473
[23:22:25.899] iteration 13489 : model1 loss : 0.029307 model2 loss : 0.028271
[23:22:26.591] iteration 13490 : model1 loss : 0.026497 model2 loss : 0.025522
[23:22:27.308] iteration 13491 : model1 loss : 0.023517 model2 loss : 0.022890
[23:22:27.986] iteration 13492 : model1 loss : 0.036807 model2 loss : 0.034627
[23:22:28.702] iteration 13493 : model1 loss : 0.027962 model2 loss : 0.025014
[23:22:29.388] iteration 13494 : model1 loss : 0.025602 model2 loss : 0.023552
[23:22:30.101] iteration 13495 : model1 loss : 0.029467 model2 loss : 0.028233
[23:22:30.787] iteration 13496 : model1 loss : 0.021713 model2 loss : 0.022184
[23:22:31.484] iteration 13497 : model1 loss : 0.019687 model2 loss : 0.020064
[23:22:32.188] iteration 13498 : model1 loss : 0.016966 model2 loss : 0.017244
[23:22:32.877] iteration 13499 : model1 loss : 0.018873 model2 loss : 0.019270
[23:22:33.570] iteration 13500 : model1 loss : 0.016235 model2 loss : 0.017498
[23:22:34.304] iteration 13501 : model1 loss : 0.027523 model2 loss : 0.031827
[23:22:34.990] iteration 13502 : model1 loss : 0.033213 model2 loss : 0.028675
[23:22:35.675] iteration 13503 : model1 loss : 0.024783 model2 loss : 0.025222
[23:22:36.369] iteration 13504 : model1 loss : 0.021116 model2 loss : 0.019928
[23:22:37.064] iteration 13505 : model1 loss : 0.019149 model2 loss : 0.020273
[23:22:37.774] iteration 13506 : model1 loss : 0.019131 model2 loss : 0.020670
[23:22:38.468] iteration 13507 : model1 loss : 0.020345 model2 loss : 0.018834
[23:22:39.157] iteration 13508 : model1 loss : 0.018113 model2 loss : 0.015338
[23:22:39.853] iteration 13509 : model1 loss : 0.037985 model2 loss : 0.038529
[23:22:40.560] iteration 13510 : model1 loss : 0.017428 model2 loss : 0.017937
[23:22:41.265] iteration 13511 : model1 loss : 0.031979 model2 loss : 0.070396
[23:22:41.969] iteration 13512 : model1 loss : 0.019949 model2 loss : 0.021396
[23:22:42.692] iteration 13513 : model1 loss : 0.024166 model2 loss : 0.023326
[23:22:43.373] iteration 13514 : model1 loss : 0.042239 model2 loss : 0.034031
[23:22:44.065] iteration 13515 : model1 loss : 0.019821 model2 loss : 0.023782
[23:22:44.741] iteration 13516 : model1 loss : 0.024125 model2 loss : 0.023011
[23:22:45.428] iteration 13517 : model1 loss : 0.019127 model2 loss : 0.017521
[23:22:46.115] iteration 13518 : model1 loss : 0.028856 model2 loss : 0.028936
[23:22:46.809] iteration 13519 : model1 loss : 0.025986 model2 loss : 0.024255
[23:22:47.525] iteration 13520 : model1 loss : 0.024047 model2 loss : 0.027529
[23:22:48.203] iteration 13521 : model1 loss : 0.019043 model2 loss : 0.021173
[23:22:48.908] iteration 13522 : model1 loss : 0.021993 model2 loss : 0.024252
[23:22:49.597] iteration 13523 : model1 loss : 0.017000 model2 loss : 0.016368
[23:22:50.286] iteration 13524 : model1 loss : 0.020576 model2 loss : 0.031043
[23:22:50.976] iteration 13525 : model1 loss : 0.021293 model2 loss : 0.020646
[23:22:51.662] iteration 13526 : model1 loss : 0.030113 model2 loss : 0.029921
[23:22:52.382] iteration 13527 : model1 loss : 0.022859 model2 loss : 0.023158
[23:22:53.063] iteration 13528 : model1 loss : 0.030526 model2 loss : 0.033568
[23:22:53.753] iteration 13529 : model1 loss : 0.029371 model2 loss : 0.031587
[23:22:54.472] iteration 13530 : model1 loss : 0.024628 model2 loss : 0.033750
[23:22:55.156] iteration 13531 : model1 loss : 0.019832 model2 loss : 0.022556
[23:22:55.842] iteration 13532 : model1 loss : 0.022785 model2 loss : 0.023718
[23:22:56.562] iteration 13533 : model1 loss : 0.056439 model2 loss : 0.060343
[23:22:57.285] iteration 13534 : model1 loss : 0.020187 model2 loss : 0.020467
[23:22:57.981] iteration 13535 : model1 loss : 0.017134 model2 loss : 0.018306
[23:22:58.678] iteration 13536 : model1 loss : 0.027188 model2 loss : 0.027097
[23:22:59.369] iteration 13537 : model1 loss : 0.018091 model2 loss : 0.021288
[23:23:00.060] iteration 13538 : model1 loss : 0.019732 model2 loss : 0.018558
[23:23:00.752] iteration 13539 : model1 loss : 0.020503 model2 loss : 0.021073
[23:23:01.440] iteration 13540 : model1 loss : 0.032560 model2 loss : 0.041225
[23:23:02.140] iteration 13541 : model1 loss : 0.017595 model2 loss : 0.017993
[23:23:02.854] iteration 13542 : model1 loss : 0.026536 model2 loss : 0.026736
[23:23:03.547] iteration 13543 : model1 loss : 0.020835 model2 loss : 0.023211
[23:23:04.243] iteration 13544 : model1 loss : 0.143422 model2 loss : 0.153320
[23:23:04.933] iteration 13545 : model1 loss : 0.040788 model2 loss : 0.045263
[23:23:05.621] iteration 13546 : model1 loss : 0.036429 model2 loss : 0.031784
[23:23:06.312] iteration 13547 : model1 loss : 0.023344 model2 loss : 0.025736
[23:23:07.024] iteration 13548 : model1 loss : 0.019527 model2 loss : 0.019868
[23:23:07.727] iteration 13549 : model1 loss : 0.019911 model2 loss : 0.021423
[23:23:08.422] iteration 13550 : model1 loss : 0.021699 model2 loss : 0.027696
[23:23:09.169] iteration 13551 : model1 loss : 0.033498 model2 loss : 0.034567
[23:23:09.862] iteration 13552 : model1 loss : 0.021242 model2 loss : 0.019553
[23:23:10.554] iteration 13553 : model1 loss : 0.023248 model2 loss : 0.025958
[23:23:11.247] iteration 13554 : model1 loss : 0.018830 model2 loss : 0.019536
[23:23:11.952] iteration 13555 : model1 loss : 0.019050 model2 loss : 0.019935
[23:23:12.663] iteration 13556 : model1 loss : 0.018061 model2 loss : 0.018812
[23:23:13.372] iteration 13557 : model1 loss : 0.020915 model2 loss : 0.022505
[23:23:14.082] iteration 13558 : model1 loss : 0.021618 model2 loss : 0.019691
[23:23:14.772] iteration 13559 : model1 loss : 0.031769 model2 loss : 0.030948
[23:23:15.458] iteration 13560 : model1 loss : 0.019089 model2 loss : 0.021750
[23:23:16.157] iteration 13561 : model1 loss : 0.040907 model2 loss : 0.043109
[23:23:16.854] iteration 13562 : model1 loss : 0.019309 model2 loss : 0.020842
[23:23:17.572] iteration 13563 : model1 loss : 0.023778 model2 loss : 0.021843
[23:23:18.267] iteration 13564 : model1 loss : 0.018685 model2 loss : 0.018635
[23:23:18.956] iteration 13565 : model1 loss : 0.032294 model2 loss : 0.039437
[23:23:19.642] iteration 13566 : model1 loss : 0.021671 model2 loss : 0.024741
[23:23:20.331] iteration 13567 : model1 loss : 0.029130 model2 loss : 0.029140
[23:23:21.020] iteration 13568 : model1 loss : 0.025294 model2 loss : 0.033933
[23:23:21.704] iteration 13569 : model1 loss : 0.023033 model2 loss : 0.024980
[23:23:22.423] iteration 13570 : model1 loss : 0.019986 model2 loss : 0.020697
[23:23:23.116] iteration 13571 : model1 loss : 0.023673 model2 loss : 0.023216
[23:23:23.806] iteration 13572 : model1 loss : 0.023333 model2 loss : 0.023620
[23:23:24.489] iteration 13573 : model1 loss : 0.033911 model2 loss : 0.036292
[23:23:25.172] iteration 13574 : model1 loss : 0.021113 model2 loss : 0.018722
[23:23:25.856] iteration 13575 : model1 loss : 0.021365 model2 loss : 0.021709
[23:23:26.557] iteration 13576 : model1 loss : 0.018078 model2 loss : 0.019157
[23:23:27.253] iteration 13577 : model1 loss : 0.017243 model2 loss : 0.059742
[23:23:27.942] iteration 13578 : model1 loss : 0.021795 model2 loss : 0.023132
[23:23:28.627] iteration 13579 : model1 loss : 0.027448 model2 loss : 0.027518
[23:23:29.356] iteration 13580 : model1 loss : 0.021214 model2 loss : 0.025448
[23:23:30.056] iteration 13581 : model1 loss : 0.017627 model2 loss : 0.017155
[23:23:30.773] iteration 13582 : model1 loss : 0.055683 model2 loss : 0.037054
[23:23:31.467] iteration 13583 : model1 loss : 0.023711 model2 loss : 0.027809
[23:23:32.178] iteration 13584 : model1 loss : 0.026593 model2 loss : 0.024512
[23:23:32.873] iteration 13585 : model1 loss : 0.023171 model2 loss : 0.022278
[23:23:33.570] iteration 13586 : model1 loss : 0.022112 model2 loss : 0.023221
[23:23:34.281] iteration 13587 : model1 loss : 0.025814 model2 loss : 0.028935
[23:23:34.970] iteration 13588 : model1 loss : 0.022970 model2 loss : 0.024309
[23:23:35.674] iteration 13589 : model1 loss : 0.021139 model2 loss : 0.021239
[23:23:36.373] iteration 13590 : model1 loss : 0.015249 model2 loss : 0.016026
[23:23:37.067] iteration 13591 : model1 loss : 0.026295 model2 loss : 0.026802
[23:23:37.775] iteration 13592 : model1 loss : 0.021778 model2 loss : 0.024378
[23:23:38.468] iteration 13593 : model1 loss : 0.036350 model2 loss : 0.033343
[23:23:39.159] iteration 13594 : model1 loss : 0.026311 model2 loss : 0.038869
[23:23:39.865] iteration 13595 : model1 loss : 0.023850 model2 loss : 0.026029
[23:23:40.539] iteration 13596 : model1 loss : 0.030394 model2 loss : 0.027253
[23:23:41.227] iteration 13597 : model1 loss : 0.028224 model2 loss : 0.023720
[23:23:41.911] iteration 13598 : model1 loss : 0.018832 model2 loss : 0.019607
[23:23:42.634] iteration 13599 : model1 loss : 0.029780 model2 loss : 0.027199
[23:23:43.318] iteration 13600 : model1 loss : 0.027132 model2 loss : 0.030353
[23:24:03.225] iteration 13600 : model1_mean_dice : 0.857524 model1_mean_hd95 : 6.009444
[23:24:23.016] iteration 13600 : model2_mean_dice : 0.868202 model2_mean_hd95 : 4.035159
[23:24:23.738] iteration 13601 : model1 loss : 0.030381 model2 loss : 0.031110
[23:24:24.414] iteration 13602 : model1 loss : 0.024505 model2 loss : 0.023338
[23:24:25.094] iteration 13603 : model1 loss : 0.023241 model2 loss : 0.022714
[23:24:25.783] iteration 13604 : model1 loss : 0.018981 model2 loss : 0.018136
[23:24:26.456] iteration 13605 : model1 loss : 0.019908 model2 loss : 0.018736
[23:24:27.151] iteration 13606 : model1 loss : 0.069205 model2 loss : 0.045067
[23:24:27.844] iteration 13607 : model1 loss : 0.020515 model2 loss : 0.022852
[23:24:28.537] iteration 13608 : model1 loss : 0.027642 model2 loss : 0.025098
[23:24:29.218] iteration 13609 : model1 loss : 0.022297 model2 loss : 0.022782
[23:24:29.898] iteration 13610 : model1 loss : 0.027147 model2 loss : 0.029333
[23:24:30.590] iteration 13611 : model1 loss : 0.022126 model2 loss : 0.021498
[23:24:31.315] iteration 13612 : model1 loss : 0.016701 model2 loss : 0.016285
[23:24:32.009] iteration 13613 : model1 loss : 0.032367 model2 loss : 0.035707
[23:24:32.718] iteration 13614 : model1 loss : 0.022338 model2 loss : 0.025869
[23:24:33.411] iteration 13615 : model1 loss : 0.019230 model2 loss : 0.017961
[23:24:34.092] iteration 13616 : model1 loss : 0.027954 model2 loss : 0.019606
[23:24:34.780] iteration 13617 : model1 loss : 0.153115 model2 loss : 0.157543
[23:24:35.480] iteration 13618 : model1 loss : 0.018907 model2 loss : 0.020139
[23:24:36.169] iteration 13619 : model1 loss : 0.031258 model2 loss : 0.027783
[23:24:36.864] iteration 13620 : model1 loss : 0.021512 model2 loss : 0.019767
[23:24:37.573] iteration 13621 : model1 loss : 0.020559 model2 loss : 0.024180
[23:24:38.260] iteration 13622 : model1 loss : 0.042644 model2 loss : 0.027004
[23:24:38.949] iteration 13623 : model1 loss : 0.020225 model2 loss : 0.020525
[23:24:39.636] iteration 13624 : model1 loss : 0.024794 model2 loss : 0.020514
[23:24:40.325] iteration 13625 : model1 loss : 0.019473 model2 loss : 0.019100
[23:24:41.015] iteration 13626 : model1 loss : 0.030663 model2 loss : 0.025844
[23:24:41.730] iteration 13627 : model1 loss : 0.025411 model2 loss : 0.026523
[23:24:42.467] iteration 13628 : model1 loss : 0.026799 model2 loss : 0.030319
[23:24:43.149] iteration 13629 : model1 loss : 0.021930 model2 loss : 0.021047
[23:24:43.840] iteration 13630 : model1 loss : 0.024872 model2 loss : 0.024035
[23:24:44.535] iteration 13631 : model1 loss : 0.020420 model2 loss : 0.022888
[23:24:45.235] iteration 13632 : model1 loss : 0.022804 model2 loss : 0.027027
[23:24:45.923] iteration 13633 : model1 loss : 0.018481 model2 loss : 0.019838
[23:24:46.614] iteration 13634 : model1 loss : 0.024916 model2 loss : 0.024039
[23:24:47.323] iteration 13635 : model1 loss : 0.020521 model2 loss : 0.022701
[23:24:48.010] iteration 13636 : model1 loss : 0.019672 model2 loss : 0.017717
[23:24:48.693] iteration 13637 : model1 loss : 0.027829 model2 loss : 0.025074
[23:24:49.375] iteration 13638 : model1 loss : 0.019063 model2 loss : 0.020972
[23:24:50.074] iteration 13639 : model1 loss : 0.022414 model2 loss : 0.025753
[23:24:50.759] iteration 13640 : model1 loss : 0.026902 model2 loss : 0.026650
[23:24:51.450] iteration 13641 : model1 loss : 0.021546 model2 loss : 0.022509
[23:24:52.149] iteration 13642 : model1 loss : 0.022419 model2 loss : 0.018701
[23:24:52.848] iteration 13643 : model1 loss : 0.026494 model2 loss : 0.025471
[23:24:53.556] iteration 13644 : model1 loss : 0.021364 model2 loss : 0.024630
[23:24:54.241] iteration 13645 : model1 loss : 0.019651 model2 loss : 0.018472
[23:24:54.925] iteration 13646 : model1 loss : 0.022676 model2 loss : 0.021873
[23:24:55.614] iteration 13647 : model1 loss : 0.030990 model2 loss : 0.024832
[23:24:56.293] iteration 13648 : model1 loss : 0.022355 model2 loss : 0.024492
[23:24:57.000] iteration 13649 : model1 loss : 0.030832 model2 loss : 0.032019
[23:24:57.706] iteration 13650 : model1 loss : 0.020490 model2 loss : 0.018930
[23:24:58.428] iteration 13651 : model1 loss : 0.023619 model2 loss : 0.022497
[23:24:59.127] iteration 13652 : model1 loss : 0.027148 model2 loss : 0.024780
[23:24:59.827] iteration 13653 : model1 loss : 0.025791 model2 loss : 0.024859
[23:25:00.537] iteration 13654 : model1 loss : 0.020566 model2 loss : 0.022468
[23:25:01.227] iteration 13655 : model1 loss : 0.019726 model2 loss : 0.020851
[23:25:01.915] iteration 13656 : model1 loss : 0.021205 model2 loss : 0.020099
[23:25:02.618] iteration 13657 : model1 loss : 0.023602 model2 loss : 0.021591
[23:25:03.309] iteration 13658 : model1 loss : 0.025976 model2 loss : 0.025891
[23:25:04.003] iteration 13659 : model1 loss : 0.013579 model2 loss : 0.013031
[23:25:04.693] iteration 13660 : model1 loss : 0.026352 model2 loss : 0.028042
[23:25:05.384] iteration 13661 : model1 loss : 0.029999 model2 loss : 0.025608
[23:25:06.079] iteration 13662 : model1 loss : 0.026157 model2 loss : 0.027754
[23:25:06.769] iteration 13663 : model1 loss : 0.031692 model2 loss : 0.022228
[23:25:07.481] iteration 13664 : model1 loss : 0.023379 model2 loss : 0.019625
[23:25:08.182] iteration 13665 : model1 loss : 0.032200 model2 loss : 0.033307
[23:25:08.882] iteration 13666 : model1 loss : 0.026043 model2 loss : 0.025092
[23:25:09.574] iteration 13667 : model1 loss : 0.018923 model2 loss : 0.018247
[23:25:10.269] iteration 13668 : model1 loss : 0.024173 model2 loss : 0.025252
[23:25:10.956] iteration 13669 : model1 loss : 0.016251 model2 loss : 0.016257
[23:25:11.645] iteration 13670 : model1 loss : 0.025805 model2 loss : 0.025033
[23:25:12.374] iteration 13671 : model1 loss : 0.019486 model2 loss : 0.018368
[23:25:13.053] iteration 13672 : model1 loss : 0.024187 model2 loss : 0.025558
[23:25:13.745] iteration 13673 : model1 loss : 0.113876 model2 loss : 0.103394
[23:25:14.439] iteration 13674 : model1 loss : 0.022587 model2 loss : 0.026428
[23:25:15.124] iteration 13675 : model1 loss : 0.019152 model2 loss : 0.020952
[23:25:15.804] iteration 13676 : model1 loss : 0.027706 model2 loss : 0.025105
[23:25:16.504] iteration 13677 : model1 loss : 0.018976 model2 loss : 0.021216
[23:25:17.209] iteration 13678 : model1 loss : 0.041606 model2 loss : 0.033190
[23:25:17.920] iteration 13679 : model1 loss : 0.018480 model2 loss : 0.020640
[23:25:18.635] iteration 13680 : model1 loss : 0.021939 model2 loss : 0.023203
[23:25:19.325] iteration 13681 : model1 loss : 0.025426 model2 loss : 0.025162
[23:25:20.036] iteration 13682 : model1 loss : 0.024799 model2 loss : 0.024689
[23:25:20.731] iteration 13683 : model1 loss : 0.025272 model2 loss : 0.022800
[23:25:21.440] iteration 13684 : model1 loss : 0.021244 model2 loss : 0.021663
[23:25:22.152] iteration 13685 : model1 loss : 0.018479 model2 loss : 0.017143
[23:25:22.846] iteration 13686 : model1 loss : 0.018901 model2 loss : 0.020190
[23:25:23.559] iteration 13687 : model1 loss : 0.027373 model2 loss : 0.023266
[23:25:24.249] iteration 13688 : model1 loss : 0.026198 model2 loss : 0.023646
[23:25:24.934] iteration 13689 : model1 loss : 0.027120 model2 loss : 0.030992
[23:25:25.628] iteration 13690 : model1 loss : 0.016592 model2 loss : 0.017830
[23:25:26.317] iteration 13691 : model1 loss : 0.026257 model2 loss : 0.021040
[23:25:27.018] iteration 13692 : model1 loss : 0.021769 model2 loss : 0.023039
[23:25:27.721] iteration 13693 : model1 loss : 0.035739 model2 loss : 0.038582
[23:25:28.407] iteration 13694 : model1 loss : 0.041138 model2 loss : 0.053964
[23:25:29.098] iteration 13695 : model1 loss : 0.018182 model2 loss : 0.018235
[23:25:29.778] iteration 13696 : model1 loss : 0.024591 model2 loss : 0.028112
[23:25:30.463] iteration 13697 : model1 loss : 0.019854 model2 loss : 0.020397
[23:25:31.164] iteration 13698 : model1 loss : 0.018908 model2 loss : 0.022305
[23:25:31.870] iteration 13699 : model1 loss : 0.026476 model2 loss : 0.027638
[23:25:32.609] iteration 13700 : model1 loss : 0.023885 model2 loss : 0.026066
[23:25:33.345] iteration 13701 : model1 loss : 0.021979 model2 loss : 0.020742
[23:25:34.040] iteration 13702 : model1 loss : 0.021021 model2 loss : 0.019349
[23:25:34.743] iteration 13703 : model1 loss : 0.018534 model2 loss : 0.019666
[23:25:35.435] iteration 13704 : model1 loss : 0.026531 model2 loss : 0.022359
[23:25:36.120] iteration 13705 : model1 loss : 0.023524 model2 loss : 0.022562
[23:25:36.820] iteration 13706 : model1 loss : 0.022604 model2 loss : 0.019594
[23:25:37.524] iteration 13707 : model1 loss : 0.021350 model2 loss : 0.021803
[23:25:38.210] iteration 13708 : model1 loss : 0.018679 model2 loss : 0.021130
[23:25:38.911] iteration 13709 : model1 loss : 0.019713 model2 loss : 0.019914
[23:25:39.605] iteration 13710 : model1 loss : 0.043147 model2 loss : 0.032040
[23:25:40.306] iteration 13711 : model1 loss : 0.028700 model2 loss : 0.029164
[23:25:40.988] iteration 13712 : model1 loss : 0.027270 model2 loss : 0.026612
[23:25:41.668] iteration 13713 : model1 loss : 0.018324 model2 loss : 0.017126
[23:25:42.389] iteration 13714 : model1 loss : 0.023337 model2 loss : 0.025359
[23:25:43.075] iteration 13715 : model1 loss : 0.017889 model2 loss : 0.015814
[23:25:43.768] iteration 13716 : model1 loss : 0.024956 model2 loss : 0.022942
[23:25:44.462] iteration 13717 : model1 loss : 0.029358 model2 loss : 0.026130
[23:25:45.159] iteration 13718 : model1 loss : 0.031964 model2 loss : 0.024884
[23:25:45.849] iteration 13719 : model1 loss : 0.028254 model2 loss : 0.028994
[23:25:46.557] iteration 13720 : model1 loss : 0.016135 model2 loss : 0.017130
[23:25:47.257] iteration 13721 : model1 loss : 0.017492 model2 loss : 0.016583
[23:25:47.958] iteration 13722 : model1 loss : 0.021618 model2 loss : 0.021659
[23:25:48.650] iteration 13723 : model1 loss : 0.018843 model2 loss : 0.018104
[23:25:49.335] iteration 13724 : model1 loss : 0.021531 model2 loss : 0.022238
[23:25:50.028] iteration 13725 : model1 loss : 0.047354 model2 loss : 0.045904
[23:25:50.728] iteration 13726 : model1 loss : 0.032327 model2 loss : 0.034775
[23:25:51.418] iteration 13727 : model1 loss : 0.024180 model2 loss : 0.021338
[23:25:52.127] iteration 13728 : model1 loss : 0.019801 model2 loss : 0.024040
[23:25:52.830] iteration 13729 : model1 loss : 0.024291 model2 loss : 0.027189
[23:25:53.511] iteration 13730 : model1 loss : 0.032358 model2 loss : 0.030632
[23:25:54.207] iteration 13731 : model1 loss : 0.025729 model2 loss : 0.023968
[23:25:54.895] iteration 13732 : model1 loss : 0.049389 model2 loss : 0.068009
[23:25:55.582] iteration 13733 : model1 loss : 0.021083 model2 loss : 0.018755
[23:25:56.259] iteration 13734 : model1 loss : 0.020236 model2 loss : 0.022246
[23:25:56.960] iteration 13735 : model1 loss : 0.026807 model2 loss : 0.027692
[23:25:57.683] iteration 13736 : model1 loss : 0.022508 model2 loss : 0.022389
[23:25:58.379] iteration 13737 : model1 loss : 0.022992 model2 loss : 0.024955
[23:25:59.067] iteration 13738 : model1 loss : 0.024618 model2 loss : 0.035674
[23:25:59.745] iteration 13739 : model1 loss : 0.027214 model2 loss : 0.038879
[23:26:00.439] iteration 13740 : model1 loss : 0.019385 model2 loss : 0.019450
[23:26:01.146] iteration 13741 : model1 loss : 0.023304 model2 loss : 0.021239
[23:26:01.828] iteration 13742 : model1 loss : 0.022220 model2 loss : 0.021700
[23:26:02.539] iteration 13743 : model1 loss : 0.019879 model2 loss : 0.019079
[23:26:03.244] iteration 13744 : model1 loss : 0.025873 model2 loss : 0.022595
[23:26:03.926] iteration 13745 : model1 loss : 0.023923 model2 loss : 0.026516
[23:26:04.619] iteration 13746 : model1 loss : 0.018005 model2 loss : 0.019716
[23:26:05.303] iteration 13747 : model1 loss : 0.022730 model2 loss : 0.021599
[23:26:06.004] iteration 13748 : model1 loss : 0.036662 model2 loss : 0.041551
[23:26:06.712] iteration 13749 : model1 loss : 0.024311 model2 loss : 0.023476
[23:26:07.427] iteration 13750 : model1 loss : 0.027014 model2 loss : 0.030379
[23:26:08.155] iteration 13751 : model1 loss : 0.023792 model2 loss : 0.023135
[23:26:08.852] iteration 13752 : model1 loss : 0.074903 model2 loss : 0.059100
[23:26:09.545] iteration 13753 : model1 loss : 0.022977 model2 loss : 0.026780
[23:26:10.235] iteration 13754 : model1 loss : 0.034969 model2 loss : 0.029890
[23:26:10.943] iteration 13755 : model1 loss : 0.021443 model2 loss : 0.021128
[23:26:11.633] iteration 13756 : model1 loss : 0.026425 model2 loss : 0.023359
[23:26:12.362] iteration 13757 : model1 loss : 0.022895 model2 loss : 0.023310
[23:26:13.070] iteration 13758 : model1 loss : 0.020495 model2 loss : 0.020522
[23:26:13.754] iteration 13759 : model1 loss : 0.019386 model2 loss : 0.020218
[23:26:14.455] iteration 13760 : model1 loss : 0.025511 model2 loss : 0.026702
[23:26:15.149] iteration 13761 : model1 loss : 0.021591 model2 loss : 0.022859
[23:26:15.837] iteration 13762 : model1 loss : 0.018198 model2 loss : 0.017076
[23:26:16.533] iteration 13763 : model1 loss : 0.026086 model2 loss : 0.022093
[23:26:17.232] iteration 13764 : model1 loss : 0.024161 model2 loss : 0.022572
[23:26:17.927] iteration 13765 : model1 loss : 0.026839 model2 loss : 0.025538
[23:26:18.629] iteration 13766 : model1 loss : 0.026948 model2 loss : 0.026065
[23:26:19.320] iteration 13767 : model1 loss : 0.019578 model2 loss : 0.021723
[23:26:20.007] iteration 13768 : model1 loss : 0.022776 model2 loss : 0.020974
[23:26:20.701] iteration 13769 : model1 loss : 0.019128 model2 loss : 0.022699
[23:26:21.395] iteration 13770 : model1 loss : 0.018691 model2 loss : 0.017488
[23:26:22.105] iteration 13771 : model1 loss : 0.022146 model2 loss : 0.021615
[23:26:22.816] iteration 13772 : model1 loss : 0.040966 model2 loss : 0.034081
[23:26:23.511] iteration 13773 : model1 loss : 0.019157 model2 loss : 0.022469
[23:26:24.201] iteration 13774 : model1 loss : 0.027378 model2 loss : 0.028110
[23:26:24.892] iteration 13775 : model1 loss : 0.020608 model2 loss : 0.018962
[23:26:25.586] iteration 13776 : model1 loss : 0.020569 model2 loss : 0.023307
[23:26:26.273] iteration 13777 : model1 loss : 0.028778 model2 loss : 0.029284
[23:26:26.972] iteration 13778 : model1 loss : 0.028014 model2 loss : 0.024142
[23:26:27.683] iteration 13779 : model1 loss : 0.020867 model2 loss : 0.022167
[23:26:28.377] iteration 13780 : model1 loss : 0.023435 model2 loss : 0.022060
[23:26:29.068] iteration 13781 : model1 loss : 0.035537 model2 loss : 0.036912
[23:26:29.757] iteration 13782 : model1 loss : 0.048783 model2 loss : 0.049413
[23:26:30.448] iteration 13783 : model1 loss : 0.048253 model2 loss : 0.027236
[23:26:31.154] iteration 13784 : model1 loss : 0.018950 model2 loss : 0.017402
[23:26:31.858] iteration 13785 : model1 loss : 0.020197 model2 loss : 0.020684
[23:26:32.609] iteration 13786 : model1 loss : 0.023247 model2 loss : 0.023573
[23:26:33.305] iteration 13787 : model1 loss : 0.018231 model2 loss : 0.019041
[23:26:33.986] iteration 13788 : model1 loss : 0.038230 model2 loss : 0.037800
[23:26:34.678] iteration 13789 : model1 loss : 0.017452 model2 loss : 0.017640
[23:26:35.367] iteration 13790 : model1 loss : 0.019726 model2 loss : 0.020608
[23:26:36.068] iteration 13791 : model1 loss : 0.017508 model2 loss : 0.015760
[23:26:36.765] iteration 13792 : model1 loss : 0.025212 model2 loss : 0.026894
[23:26:37.478] iteration 13793 : model1 loss : 0.022142 model2 loss : 0.019605
[23:26:38.168] iteration 13794 : model1 loss : 0.020437 model2 loss : 0.025150
[23:26:38.852] iteration 13795 : model1 loss : 0.026370 model2 loss : 0.026869
[23:26:39.549] iteration 13796 : model1 loss : 0.016032 model2 loss : 0.017451
[23:26:40.228] iteration 13797 : model1 loss : 0.051634 model2 loss : 0.058437
[23:26:40.926] iteration 13798 : model1 loss : 0.021605 model2 loss : 0.019321
[23:26:41.609] iteration 13799 : model1 loss : 0.026015 model2 loss : 0.023104
[23:26:42.317] iteration 13800 : model1 loss : 0.019198 model2 loss : 0.020779
[23:27:03.295] iteration 13800 : model1_mean_dice : 0.854414 model1_mean_hd95 : 7.196690
[23:27:24.653] iteration 13800 : model2_mean_dice : 0.866712 model2_mean_hd95 : 4.445016
[23:27:25.375] iteration 13801 : model1 loss : 0.021471 model2 loss : 0.019170
[23:27:26.060] iteration 13802 : model1 loss : 0.020750 model2 loss : 0.021711
[23:27:26.746] iteration 13803 : model1 loss : 0.032776 model2 loss : 0.028871
[23:27:27.437] iteration 13804 : model1 loss : 0.021899 model2 loss : 0.022775
[23:27:28.117] iteration 13805 : model1 loss : 0.014629 model2 loss : 0.016087
[23:27:28.802] iteration 13806 : model1 loss : 0.022095 model2 loss : 0.022044
[23:27:29.487] iteration 13807 : model1 loss : 0.030217 model2 loss : 0.027927
[23:27:30.190] iteration 13808 : model1 loss : 0.038410 model2 loss : 0.032764
[23:27:30.894] iteration 13809 : model1 loss : 0.026510 model2 loss : 0.027034
[23:27:31.592] iteration 13810 : model1 loss : 0.036376 model2 loss : 0.036792
[23:27:32.296] iteration 13811 : model1 loss : 0.029717 model2 loss : 0.029015
[23:27:33.032] iteration 13812 : model1 loss : 0.026477 model2 loss : 0.021215
[23:27:33.724] iteration 13813 : model1 loss : 0.027987 model2 loss : 0.028357
[23:27:34.416] iteration 13814 : model1 loss : 0.139325 model2 loss : 0.141652
[23:27:35.117] iteration 13815 : model1 loss : 0.062617 model2 loss : 0.051612
[23:27:35.828] iteration 13816 : model1 loss : 0.029506 model2 loss : 0.025515
[23:27:36.522] iteration 13817 : model1 loss : 0.020649 model2 loss : 0.021204
[23:27:37.206] iteration 13818 : model1 loss : 0.027193 model2 loss : 0.027598
[23:27:37.895] iteration 13819 : model1 loss : 0.022056 model2 loss : 0.019758
[23:27:38.589] iteration 13820 : model1 loss : 0.019536 model2 loss : 0.018875
[23:27:39.281] iteration 13821 : model1 loss : 0.021953 model2 loss : 0.022300
[23:27:39.961] iteration 13822 : model1 loss : 0.027406 model2 loss : 0.026630
[23:27:40.684] iteration 13823 : model1 loss : 0.026473 model2 loss : 0.026468
[23:27:41.403] iteration 13824 : model1 loss : 0.019829 model2 loss : 0.021941
[23:27:42.121] iteration 13825 : model1 loss : 0.020458 model2 loss : 0.019260
[23:27:42.835] iteration 13826 : model1 loss : 0.014964 model2 loss : 0.014771
[23:27:43.524] iteration 13827 : model1 loss : 0.024280 model2 loss : 0.021590
[23:27:44.209] iteration 13828 : model1 loss : 0.019816 model2 loss : 0.019567
[23:27:44.883] iteration 13829 : model1 loss : 0.021543 model2 loss : 0.021317
[23:27:45.586] iteration 13830 : model1 loss : 0.020798 model2 loss : 0.019421
[23:27:46.268] iteration 13831 : model1 loss : 0.022948 model2 loss : 0.024769
[23:27:46.958] iteration 13832 : model1 loss : 0.028016 model2 loss : 0.030590
[23:27:47.683] iteration 13833 : model1 loss : 0.024799 model2 loss : 0.024699
[23:27:48.407] iteration 13834 : model1 loss : 0.016450 model2 loss : 0.017652
[23:27:49.101] iteration 13835 : model1 loss : 0.022542 model2 loss : 0.025108
[23:27:49.795] iteration 13836 : model1 loss : 0.018763 model2 loss : 0.018993
[23:27:50.499] iteration 13837 : model1 loss : 0.021051 model2 loss : 0.020624
[23:27:51.193] iteration 13838 : model1 loss : 0.024658 model2 loss : 0.024858
[23:27:51.869] iteration 13839 : model1 loss : 0.023097 model2 loss : 0.023299
[23:27:52.572] iteration 13840 : model1 loss : 0.020512 model2 loss : 0.021965
[23:27:53.276] iteration 13841 : model1 loss : 0.028934 model2 loss : 0.029424
[23:27:53.970] iteration 13842 : model1 loss : 0.020493 model2 loss : 0.020553
[23:27:54.649] iteration 13843 : model1 loss : 0.023965 model2 loss : 0.024528
[23:27:55.339] iteration 13844 : model1 loss : 0.021869 model2 loss : 0.021733
[23:27:56.027] iteration 13845 : model1 loss : 0.028936 model2 loss : 0.029830
[23:27:56.698] iteration 13846 : model1 loss : 0.025116 model2 loss : 0.024547
[23:27:57.382] iteration 13847 : model1 loss : 0.020813 model2 loss : 0.020360
[23:27:58.065] iteration 13848 : model1 loss : 0.042372 model2 loss : 0.040141
[23:27:58.739] iteration 13849 : model1 loss : 0.023262 model2 loss : 0.023137
[23:27:59.441] iteration 13850 : model1 loss : 0.020373 model2 loss : 0.021844
[23:28:00.202] iteration 13851 : model1 loss : 0.028116 model2 loss : 0.030603
[23:28:00.889] iteration 13852 : model1 loss : 0.026024 model2 loss : 0.024329
[23:28:01.567] iteration 13853 : model1 loss : 0.018545 model2 loss : 0.017944
[23:28:02.233] iteration 13854 : model1 loss : 0.024978 model2 loss : 0.027257
[23:28:02.900] iteration 13855 : model1 loss : 0.020694 model2 loss : 0.018011
[23:28:03.600] iteration 13856 : model1 loss : 0.024007 model2 loss : 0.022174
[23:28:04.343] iteration 13857 : model1 loss : 0.030864 model2 loss : 0.033473
[23:28:05.087] iteration 13858 : model1 loss : 0.024971 model2 loss : 0.025636
[23:28:05.762] iteration 13859 : model1 loss : 0.030346 model2 loss : 0.028138
[23:28:06.425] iteration 13860 : model1 loss : 0.023318 model2 loss : 0.023968
[23:28:07.086] iteration 13861 : model1 loss : 0.036390 model2 loss : 0.039050
[23:28:07.732] iteration 13862 : model1 loss : 0.020100 model2 loss : 0.016979
[23:28:08.425] iteration 13863 : model1 loss : 0.030294 model2 loss : 0.023983
[23:28:09.105] iteration 13864 : model1 loss : 0.017122 model2 loss : 0.017945
[23:28:09.786] iteration 13865 : model1 loss : 0.027056 model2 loss : 0.028395
[23:28:10.482] iteration 13866 : model1 loss : 0.019858 model2 loss : 0.019363
[23:28:11.165] iteration 13867 : model1 loss : 0.171072 model2 loss : 0.159590
[23:28:11.846] iteration 13868 : model1 loss : 0.023409 model2 loss : 0.024970
[23:28:12.555] iteration 13869 : model1 loss : 0.019640 model2 loss : 0.019774
[23:28:13.249] iteration 13870 : model1 loss : 0.022578 model2 loss : 0.023478
[23:28:13.946] iteration 13871 : model1 loss : 0.019756 model2 loss : 0.020998
[23:28:14.667] iteration 13872 : model1 loss : 0.021872 model2 loss : 0.019437
[23:28:15.388] iteration 13873 : model1 loss : 0.037784 model2 loss : 0.025262
[23:28:16.160] iteration 13874 : model1 loss : 0.019239 model2 loss : 0.021012
[23:28:16.825] iteration 13875 : model1 loss : 0.026112 model2 loss : 0.025594
[23:28:17.495] iteration 13876 : model1 loss : 0.025446 model2 loss : 0.026970
[23:28:18.166] iteration 13877 : model1 loss : 0.030850 model2 loss : 0.026636
[23:28:18.830] iteration 13878 : model1 loss : 0.019892 model2 loss : 0.018005
[23:28:19.517] iteration 13879 : model1 loss : 0.020811 model2 loss : 0.020468
[23:28:20.204] iteration 13880 : model1 loss : 0.018252 model2 loss : 0.019873
[23:28:20.909] iteration 13881 : model1 loss : 0.023908 model2 loss : 0.022108
[23:28:21.599] iteration 13882 : model1 loss : 0.027531 model2 loss : 0.031111
[23:28:22.317] iteration 13883 : model1 loss : 0.027649 model2 loss : 0.027120
[23:28:23.023] iteration 13884 : model1 loss : 0.024331 model2 loss : 0.026581
[23:28:23.735] iteration 13885 : model1 loss : 0.033577 model2 loss : 0.029945
[23:28:24.419] iteration 13886 : model1 loss : 0.021599 model2 loss : 0.021472
[23:28:25.120] iteration 13887 : model1 loss : 0.025822 model2 loss : 0.026244
[23:28:25.837] iteration 13888 : model1 loss : 0.021481 model2 loss : 0.024686
[23:28:26.553] iteration 13889 : model1 loss : 0.025029 model2 loss : 0.023033
[23:28:27.280] iteration 13890 : model1 loss : 0.026529 model2 loss : 0.026496
[23:28:27.987] iteration 13891 : model1 loss : 0.022467 model2 loss : 0.023292
[23:28:28.703] iteration 13892 : model1 loss : 0.025330 model2 loss : 0.023925
[23:28:29.459] iteration 13893 : model1 loss : 0.023476 model2 loss : 0.023218
[23:28:30.182] iteration 13894 : model1 loss : 0.019097 model2 loss : 0.017979
[23:28:30.900] iteration 13895 : model1 loss : 0.023588 model2 loss : 0.020222
[23:28:31.621] iteration 13896 : model1 loss : 0.017429 model2 loss : 0.017944
[23:28:32.330] iteration 13897 : model1 loss : 0.021975 model2 loss : 0.022257
[23:28:33.045] iteration 13898 : model1 loss : 0.018359 model2 loss : 0.018040
[23:28:33.770] iteration 13899 : model1 loss : 0.021535 model2 loss : 0.020207
[23:28:34.496] iteration 13900 : model1 loss : 0.015007 model2 loss : 0.014915
[23:28:35.244] iteration 13901 : model1 loss : 0.023746 model2 loss : 0.026073
[23:28:35.922] iteration 13902 : model1 loss : 0.021792 model2 loss : 0.021740
[23:28:36.588] iteration 13903 : model1 loss : 0.020341 model2 loss : 0.020838
[23:28:37.288] iteration 13904 : model1 loss : 0.019601 model2 loss : 0.018946
[23:28:37.971] iteration 13905 : model1 loss : 0.024239 model2 loss : 0.021685
[23:28:38.642] iteration 13906 : model1 loss : 0.022826 model2 loss : 0.025479
[23:28:39.335] iteration 13907 : model1 loss : 0.019628 model2 loss : 0.017532
[23:28:40.006] iteration 13908 : model1 loss : 0.026297 model2 loss : 0.025234
[23:28:40.668] iteration 13909 : model1 loss : 0.027991 model2 loss : 0.028672
[23:28:41.340] iteration 13910 : model1 loss : 0.017224 model2 loss : 0.017488
[23:28:42.058] iteration 13911 : model1 loss : 0.022886 model2 loss : 0.021883
[23:28:42.784] iteration 13912 : model1 loss : 0.028369 model2 loss : 0.040746
[23:28:43.487] iteration 13913 : model1 loss : 0.022470 model2 loss : 0.021412
[23:28:44.177] iteration 13914 : model1 loss : 0.024676 model2 loss : 0.022993
[23:28:44.877] iteration 13915 : model1 loss : 0.016800 model2 loss : 0.016770
[23:28:45.645] iteration 13916 : model1 loss : 0.025206 model2 loss : 0.022415
[23:28:46.336] iteration 13917 : model1 loss : 0.022345 model2 loss : 0.022635
[23:28:47.002] iteration 13918 : model1 loss : 0.021964 model2 loss : 0.024302
[23:28:47.679] iteration 13919 : model1 loss : 0.023211 model2 loss : 0.023864
[23:28:48.415] iteration 13920 : model1 loss : 0.020918 model2 loss : 0.021768
[23:28:49.154] iteration 13921 : model1 loss : 0.026511 model2 loss : 0.024057
[23:28:49.895] iteration 13922 : model1 loss : 0.026896 model2 loss : 0.027498
[23:28:50.588] iteration 13923 : model1 loss : 0.021805 model2 loss : 0.022152
[23:28:51.304] iteration 13924 : model1 loss : 0.018851 model2 loss : 0.019833
[23:28:51.965] iteration 13925 : model1 loss : 0.018018 model2 loss : 0.017846
[23:28:52.695] iteration 13926 : model1 loss : 0.022850 model2 loss : 0.024395
[23:28:53.423] iteration 13927 : model1 loss : 0.042867 model2 loss : 0.039805
[23:28:54.098] iteration 13928 : model1 loss : 0.018653 model2 loss : 0.018823
[23:28:54.781] iteration 13929 : model1 loss : 0.018322 model2 loss : 0.018470
[23:28:55.459] iteration 13930 : model1 loss : 0.018978 model2 loss : 0.017935
[23:28:56.183] iteration 13931 : model1 loss : 0.019368 model2 loss : 0.018595
[23:28:56.870] iteration 13932 : model1 loss : 0.015659 model2 loss : 0.015940
[23:28:57.545] iteration 13933 : model1 loss : 0.019162 model2 loss : 0.017884
[23:28:58.213] iteration 13934 : model1 loss : 0.027234 model2 loss : 0.034218
[23:28:58.891] iteration 13935 : model1 loss : 0.018337 model2 loss : 0.019299
[23:28:59.606] iteration 13936 : model1 loss : 0.030235 model2 loss : 0.027787
[23:29:00.310] iteration 13937 : model1 loss : 0.043972 model2 loss : 0.036428
[23:29:00.976] iteration 13938 : model1 loss : 0.020459 model2 loss : 0.018341
[23:29:01.642] iteration 13939 : model1 loss : 0.024976 model2 loss : 0.018415
[23:29:02.326] iteration 13940 : model1 loss : 0.013892 model2 loss : 0.014190
[23:29:03.009] iteration 13941 : model1 loss : 0.021151 model2 loss : 0.022940
[23:29:03.732] iteration 13942 : model1 loss : 0.047241 model2 loss : 0.042869
[23:29:04.448] iteration 13943 : model1 loss : 0.019878 model2 loss : 0.024578
[23:29:05.174] iteration 13944 : model1 loss : 0.019071 model2 loss : 0.020073
[23:29:05.883] iteration 13945 : model1 loss : 0.015727 model2 loss : 0.014441
[23:29:06.549] iteration 13946 : model1 loss : 0.017990 model2 loss : 0.018764
[23:29:07.225] iteration 13947 : model1 loss : 0.032896 model2 loss : 0.033028
[23:29:07.984] iteration 13948 : model1 loss : 0.025811 model2 loss : 0.024247
[23:29:08.725] iteration 13949 : model1 loss : 0.023306 model2 loss : 0.020960
[23:29:09.449] iteration 13950 : model1 loss : 0.028022 model2 loss : 0.027375
[23:29:10.195] iteration 13951 : model1 loss : 0.028438 model2 loss : 0.028391
[23:29:10.880] iteration 13952 : model1 loss : 0.026896 model2 loss : 0.026564
[23:29:11.565] iteration 13953 : model1 loss : 0.018852 model2 loss : 0.018432
[23:29:12.228] iteration 13954 : model1 loss : 0.017124 model2 loss : 0.016826
[23:29:12.910] iteration 13955 : model1 loss : 0.019807 model2 loss : 0.023560
[23:29:13.567] iteration 13956 : model1 loss : 0.023140 model2 loss : 0.021475
[23:29:14.231] iteration 13957 : model1 loss : 0.025742 model2 loss : 0.051177
[23:29:14.915] iteration 13958 : model1 loss : 0.022085 model2 loss : 0.021129
[23:29:15.580] iteration 13959 : model1 loss : 0.024713 model2 loss : 0.025596
[23:29:16.359] iteration 13960 : model1 loss : 0.029594 model2 loss : 0.044558
[23:29:17.047] iteration 13961 : model1 loss : 0.022222 model2 loss : 0.021073
[23:29:17.750] iteration 13962 : model1 loss : 0.032092 model2 loss : 0.028923
[23:29:18.440] iteration 13963 : model1 loss : 0.026443 model2 loss : 0.026583
[23:29:19.128] iteration 13964 : model1 loss : 0.019201 model2 loss : 0.017572
[23:29:19.796] iteration 13965 : model1 loss : 0.019919 model2 loss : 0.022954
[23:29:20.468] iteration 13966 : model1 loss : 0.027643 model2 loss : 0.027563
[23:29:21.133] iteration 13967 : model1 loss : 0.028310 model2 loss : 0.027558
[23:29:21.799] iteration 13968 : model1 loss : 0.025349 model2 loss : 0.024425
[23:29:22.465] iteration 13969 : model1 loss : 0.031156 model2 loss : 0.028654
[23:29:23.124] iteration 13970 : model1 loss : 0.025856 model2 loss : 0.025434
[23:29:23.790] iteration 13971 : model1 loss : 0.017657 model2 loss : 0.016957
[23:29:24.468] iteration 13972 : model1 loss : 0.022773 model2 loss : 0.021128
[23:29:25.156] iteration 13973 : model1 loss : 0.019160 model2 loss : 0.018774
[23:29:25.818] iteration 13974 : model1 loss : 0.024091 model2 loss : 0.023734
[23:29:26.485] iteration 13975 : model1 loss : 0.017675 model2 loss : 0.018134
[23:29:27.160] iteration 13976 : model1 loss : 0.030618 model2 loss : 0.036269
[23:29:27.831] iteration 13977 : model1 loss : 0.021649 model2 loss : 0.022051
[23:29:28.531] iteration 13978 : model1 loss : 0.023739 model2 loss : 0.031025
[23:29:29.203] iteration 13979 : model1 loss : 0.023385 model2 loss : 0.023207
[23:29:29.910] iteration 13980 : model1 loss : 0.026445 model2 loss : 0.025127
[23:29:30.600] iteration 13981 : model1 loss : 0.017699 model2 loss : 0.017543
[23:29:31.265] iteration 13982 : model1 loss : 0.022186 model2 loss : 0.026418
[23:29:31.931] iteration 13983 : model1 loss : 0.025292 model2 loss : 0.025968
[23:29:32.619] iteration 13984 : model1 loss : 0.047284 model2 loss : 0.047790
[23:29:33.317] iteration 13985 : model1 loss : 0.025488 model2 loss : 0.023897
[23:29:34.070] iteration 13986 : model1 loss : 0.030498 model2 loss : 0.031894
[23:29:34.826] iteration 13987 : model1 loss : 0.018529 model2 loss : 0.018357
[23:29:35.552] iteration 13988 : model1 loss : 0.018783 model2 loss : 0.023588
[23:29:36.243] iteration 13989 : model1 loss : 0.022980 model2 loss : 0.021753
[23:29:36.957] iteration 13990 : model1 loss : 0.019063 model2 loss : 0.021389
[23:29:37.639] iteration 13991 : model1 loss : 0.021778 model2 loss : 0.023030
[23:29:38.331] iteration 13992 : model1 loss : 0.020429 model2 loss : 0.020909
[23:29:38.998] iteration 13993 : model1 loss : 0.021500 model2 loss : 0.021229
[23:29:39.651] iteration 13994 : model1 loss : 0.020853 model2 loss : 0.023777
[23:29:40.306] iteration 13995 : model1 loss : 0.026175 model2 loss : 0.024153
[23:29:40.985] iteration 13996 : model1 loss : 0.028783 model2 loss : 0.030880
[23:29:41.758] iteration 13997 : model1 loss : 0.017380 model2 loss : 0.018718
[23:29:42.468] iteration 13998 : model1 loss : 0.022899 model2 loss : 0.022018
[23:29:43.238] iteration 13999 : model1 loss : 0.017656 model2 loss : 0.017405
[23:29:43.906] iteration 14000 : model1 loss : 0.020125 model2 loss : 0.019541
[23:30:05.351] iteration 14000 : model1_mean_dice : 0.861028 model1_mean_hd95 : 7.579114
[23:30:25.758] iteration 14000 : model2_mean_dice : 0.875500 model2_mean_hd95 : 4.845735
[23:30:26.461] iteration 14001 : model1 loss : 0.017790 model2 loss : 0.019217
[23:30:27.163] iteration 14002 : model1 loss : 0.022838 model2 loss : 0.024258
[23:30:27.836] iteration 14003 : model1 loss : 0.021644 model2 loss : 0.022836
[23:30:28.530] iteration 14004 : model1 loss : 0.024825 model2 loss : 0.027124
[23:30:29.217] iteration 14005 : model1 loss : 0.019791 model2 loss : 0.019610
[23:30:29.914] iteration 14006 : model1 loss : 0.022908 model2 loss : 0.023117
[23:30:30.638] iteration 14007 : model1 loss : 0.021331 model2 loss : 0.023817
[23:30:31.381] iteration 14008 : model1 loss : 0.018158 model2 loss : 0.017991
[23:30:32.074] iteration 14009 : model1 loss : 0.016462 model2 loss : 0.016276
[23:30:32.757] iteration 14010 : model1 loss : 0.018566 model2 loss : 0.020762
[23:30:33.428] iteration 14011 : model1 loss : 0.014886 model2 loss : 0.017342
[23:30:34.141] iteration 14012 : model1 loss : 0.022373 model2 loss : 0.024190
[23:30:34.821] iteration 14013 : model1 loss : 0.018582 model2 loss : 0.018956
[23:30:35.510] iteration 14014 : model1 loss : 0.018790 model2 loss : 0.022306
[23:30:36.216] iteration 14015 : model1 loss : 0.021375 model2 loss : 0.021258
[23:30:36.949] iteration 14016 : model1 loss : 0.019706 model2 loss : 0.020926
[23:30:37.635] iteration 14017 : model1 loss : 0.023088 model2 loss : 0.021223
[23:30:38.295] iteration 14018 : model1 loss : 0.014448 model2 loss : 0.016011
[23:30:38.944] iteration 14019 : model1 loss : 0.024605 model2 loss : 0.023097
[23:30:39.605] iteration 14020 : model1 loss : 0.018824 model2 loss : 0.021816
[23:30:40.266] iteration 14021 : model1 loss : 0.023612 model2 loss : 0.024101
[23:30:40.922] iteration 14022 : model1 loss : 0.025993 model2 loss : 0.026744
[23:30:41.587] iteration 14023 : model1 loss : 0.016874 model2 loss : 0.019184
[23:30:42.244] iteration 14024 : model1 loss : 0.021924 model2 loss : 0.022434
[23:30:42.914] iteration 14025 : model1 loss : 0.023224 model2 loss : 0.023183
[23:30:43.578] iteration 14026 : model1 loss : 0.023222 model2 loss : 0.028126
[23:30:44.252] iteration 14027 : model1 loss : 0.032928 model2 loss : 0.031650
[23:30:44.931] iteration 14028 : model1 loss : 0.018619 model2 loss : 0.018928
[23:30:45.642] iteration 14029 : model1 loss : 0.023451 model2 loss : 0.022641
[23:30:46.413] iteration 14030 : model1 loss : 0.018101 model2 loss : 0.018151
[23:30:47.138] iteration 14031 : model1 loss : 0.024675 model2 loss : 0.025156
[23:30:47.884] iteration 14032 : model1 loss : 0.022195 model2 loss : 0.022723
[23:30:48.558] iteration 14033 : model1 loss : 0.018110 model2 loss : 0.017856
[23:30:49.327] iteration 14034 : model1 loss : 0.022088 model2 loss : 0.026117
[23:30:50.113] iteration 14035 : model1 loss : 0.022583 model2 loss : 0.024547
[23:30:50.775] iteration 14036 : model1 loss : 0.019184 model2 loss : 0.025128
[23:30:51.439] iteration 14037 : model1 loss : 0.022316 model2 loss : 0.020850
[23:30:52.097] iteration 14038 : model1 loss : 0.025909 model2 loss : 0.027136
[23:30:52.765] iteration 14039 : model1 loss : 0.026125 model2 loss : 0.021732
[23:30:53.474] iteration 14040 : model1 loss : 0.024993 model2 loss : 0.024590
[23:30:54.178] iteration 14041 : model1 loss : 0.028432 model2 loss : 0.024728
[23:30:54.849] iteration 14042 : model1 loss : 0.027731 model2 loss : 0.024812
[23:30:55.522] iteration 14043 : model1 loss : 0.020765 model2 loss : 0.020617
[23:30:56.200] iteration 14044 : model1 loss : 0.018786 model2 loss : 0.017230
[23:30:56.889] iteration 14045 : model1 loss : 0.045148 model2 loss : 0.048631
[23:30:57.603] iteration 14046 : model1 loss : 0.020019 model2 loss : 0.018929
[23:30:58.384] iteration 14047 : model1 loss : 0.018627 model2 loss : 0.017547
[23:30:59.189] iteration 14048 : model1 loss : 0.020252 model2 loss : 0.021744
[23:30:59.867] iteration 14049 : model1 loss : 0.020364 model2 loss : 0.019955
[23:31:00.541] iteration 14050 : model1 loss : 0.017710 model2 loss : 0.018588
[23:31:01.228] iteration 14051 : model1 loss : 0.029285 model2 loss : 0.030735
[23:31:01.897] iteration 14052 : model1 loss : 0.025499 model2 loss : 0.027966
[23:31:02.564] iteration 14053 : model1 loss : 0.020712 model2 loss : 0.021164
[23:31:03.215] iteration 14054 : model1 loss : 0.021887 model2 loss : 0.022742
[23:31:03.886] iteration 14055 : model1 loss : 0.019009 model2 loss : 0.020097
[23:31:04.586] iteration 14056 : model1 loss : 0.023808 model2 loss : 0.023895
[23:31:05.300] iteration 14057 : model1 loss : 0.020950 model2 loss : 0.020647
[23:31:06.015] iteration 14058 : model1 loss : 0.018518 model2 loss : 0.020311
[23:31:06.690] iteration 14059 : model1 loss : 0.019668 model2 loss : 0.019783
[23:31:07.376] iteration 14060 : model1 loss : 0.023307 model2 loss : 0.023281
[23:31:08.079] iteration 14061 : model1 loss : 0.017840 model2 loss : 0.018402
[23:31:08.758] iteration 14062 : model1 loss : 0.018173 model2 loss : 0.017597
[23:31:09.449] iteration 14063 : model1 loss : 0.020383 model2 loss : 0.019389
[23:31:10.154] iteration 14064 : model1 loss : 0.021644 model2 loss : 0.019850
[23:31:10.878] iteration 14065 : model1 loss : 0.039975 model2 loss : 0.022810
[23:31:11.567] iteration 14066 : model1 loss : 0.018333 model2 loss : 0.017898
[23:31:12.248] iteration 14067 : model1 loss : 0.021957 model2 loss : 0.022965
[23:31:12.949] iteration 14068 : model1 loss : 0.027119 model2 loss : 0.027851
[23:31:13.706] iteration 14069 : model1 loss : 0.024783 model2 loss : 0.022862
[23:31:14.421] iteration 14070 : model1 loss : 0.026574 model2 loss : 0.027168
[23:31:15.148] iteration 14071 : model1 loss : 0.021960 model2 loss : 0.022048
[23:31:15.915] iteration 14072 : model1 loss : 0.033653 model2 loss : 0.028545
[23:31:16.647] iteration 14073 : model1 loss : 0.019281 model2 loss : 0.021051
[23:31:17.323] iteration 14074 : model1 loss : 0.029001 model2 loss : 0.030551
[23:31:18.008] iteration 14075 : model1 loss : 0.019045 model2 loss : 0.017315
[23:31:18.670] iteration 14076 : model1 loss : 0.021334 model2 loss : 0.022167
[23:31:19.338] iteration 14077 : model1 loss : 0.023372 model2 loss : 0.023109
[23:31:19.996] iteration 14078 : model1 loss : 0.019762 model2 loss : 0.019630
[23:31:20.676] iteration 14079 : model1 loss : 0.023538 model2 loss : 0.027363
[23:31:21.332] iteration 14080 : model1 loss : 0.019793 model2 loss : 0.020589
[23:31:21.975] iteration 14081 : model1 loss : 0.025212 model2 loss : 0.028585
[23:31:22.645] iteration 14082 : model1 loss : 0.021061 model2 loss : 0.019737
[23:31:23.318] iteration 14083 : model1 loss : 0.024807 model2 loss : 0.020426
[23:31:23.990] iteration 14084 : model1 loss : 0.026626 model2 loss : 0.029434
[23:31:24.651] iteration 14085 : model1 loss : 0.018221 model2 loss : 0.019894
[23:31:25.308] iteration 14086 : model1 loss : 0.024556 model2 loss : 0.026037
[23:31:25.984] iteration 14087 : model1 loss : 0.029768 model2 loss : 0.032527
[23:31:26.648] iteration 14088 : model1 loss : 0.028316 model2 loss : 0.028908
[23:31:27.307] iteration 14089 : model1 loss : 0.019779 model2 loss : 0.019045
[23:31:27.964] iteration 14090 : model1 loss : 0.035805 model2 loss : 0.038325
[23:31:28.629] iteration 14091 : model1 loss : 0.044438 model2 loss : 0.054098
[23:31:29.301] iteration 14092 : model1 loss : 0.045920 model2 loss : 0.052305
[23:31:29.962] iteration 14093 : model1 loss : 0.015510 model2 loss : 0.016060
[23:31:30.631] iteration 14094 : model1 loss : 0.023227 model2 loss : 0.026965
[23:31:31.293] iteration 14095 : model1 loss : 0.043761 model2 loss : 0.043554
[23:31:31.964] iteration 14096 : model1 loss : 0.024847 model2 loss : 0.026148
[23:31:32.635] iteration 14097 : model1 loss : 0.020437 model2 loss : 0.022450
[23:31:33.291] iteration 14098 : model1 loss : 0.024218 model2 loss : 0.030837
[23:31:33.961] iteration 14099 : model1 loss : 0.025759 model2 loss : 0.027743
[23:31:34.680] iteration 14100 : model1 loss : 0.020625 model2 loss : 0.020504
[23:31:35.368] iteration 14101 : model1 loss : 0.017298 model2 loss : 0.018616
[23:31:36.038] iteration 14102 : model1 loss : 0.189091 model2 loss : 0.158424
[23:31:36.710] iteration 14103 : model1 loss : 0.021561 model2 loss : 0.022986
[23:31:37.379] iteration 14104 : model1 loss : 0.021597 model2 loss : 0.018222
[23:31:38.040] iteration 14105 : model1 loss : 0.034427 model2 loss : 0.034928
[23:31:38.725] iteration 14106 : model1 loss : 0.025841 model2 loss : 0.021439
[23:31:39.401] iteration 14107 : model1 loss : 0.026541 model2 loss : 0.021806
[23:31:40.076] iteration 14108 : model1 loss : 0.017272 model2 loss : 0.015198
[23:31:40.816] iteration 14109 : model1 loss : 0.067784 model2 loss : 0.057969
[23:31:41.512] iteration 14110 : model1 loss : 0.024506 model2 loss : 0.022057
[23:31:42.223] iteration 14111 : model1 loss : 0.024501 model2 loss : 0.031949
[23:31:42.937] iteration 14112 : model1 loss : 0.036819 model2 loss : 0.034380
[23:31:43.633] iteration 14113 : model1 loss : 0.143358 model2 loss : 0.142467
[23:31:44.413] iteration 14114 : model1 loss : 0.031266 model2 loss : 0.030775
[23:31:45.143] iteration 14115 : model1 loss : 0.028063 model2 loss : 0.024211
[23:31:45.817] iteration 14116 : model1 loss : 0.021462 model2 loss : 0.021788
[23:31:46.488] iteration 14117 : model1 loss : 0.031397 model2 loss : 0.024316
[23:31:47.188] iteration 14118 : model1 loss : 0.052509 model2 loss : 0.022467
[23:31:47.851] iteration 14119 : model1 loss : 0.019792 model2 loss : 0.020308
[23:31:48.515] iteration 14120 : model1 loss : 0.035195 model2 loss : 0.022934
[23:31:49.181] iteration 14121 : model1 loss : 0.026851 model2 loss : 0.021202
[23:31:49.847] iteration 14122 : model1 loss : 0.028177 model2 loss : 0.030492
[23:31:50.511] iteration 14123 : model1 loss : 0.026355 model2 loss : 0.026717
[23:31:51.170] iteration 14124 : model1 loss : 0.027852 model2 loss : 0.022776
[23:31:51.825] iteration 14125 : model1 loss : 0.030067 model2 loss : 0.022300
[23:31:52.483] iteration 14126 : model1 loss : 0.024792 model2 loss : 0.023794
[23:31:53.141] iteration 14127 : model1 loss : 0.021430 model2 loss : 0.021172
[23:31:53.797] iteration 14128 : model1 loss : 0.018814 model2 loss : 0.018588
[23:31:54.459] iteration 14129 : model1 loss : 0.072417 model2 loss : 0.061678
[23:31:55.114] iteration 14130 : model1 loss : 0.027394 model2 loss : 0.025134
[23:31:55.776] iteration 14131 : model1 loss : 0.026547 model2 loss : 0.022609
[23:31:56.453] iteration 14132 : model1 loss : 0.028701 model2 loss : 0.026572
[23:31:57.114] iteration 14133 : model1 loss : 0.026577 model2 loss : 0.029893
[23:31:57.783] iteration 14134 : model1 loss : 0.027232 model2 loss : 0.021632
[23:31:58.462] iteration 14135 : model1 loss : 0.021526 model2 loss : 0.022683
[23:31:59.128] iteration 14136 : model1 loss : 0.021945 model2 loss : 0.026490
[23:31:59.791] iteration 14137 : model1 loss : 0.027835 model2 loss : 0.025212
[23:32:00.482] iteration 14138 : model1 loss : 0.026351 model2 loss : 0.019719
[23:32:01.161] iteration 14139 : model1 loss : 0.069522 model2 loss : 0.082815
[23:32:01.852] iteration 14140 : model1 loss : 0.023598 model2 loss : 0.024669
[23:32:02.534] iteration 14141 : model1 loss : 0.028447 model2 loss : 0.025645
[23:32:03.191] iteration 14142 : model1 loss : 0.026351 model2 loss : 0.022442
[23:32:03.867] iteration 14143 : model1 loss : 0.040637 model2 loss : 0.030386
[23:32:04.550] iteration 14144 : model1 loss : 0.021838 model2 loss : 0.018121
[23:32:05.221] iteration 14145 : model1 loss : 0.032493 model2 loss : 0.028355
[23:32:05.885] iteration 14146 : model1 loss : 0.019331 model2 loss : 0.018297
[23:32:06.581] iteration 14147 : model1 loss : 0.034190 model2 loss : 0.044972
[23:32:07.290] iteration 14148 : model1 loss : 0.018697 model2 loss : 0.017508
[23:32:08.006] iteration 14149 : model1 loss : 0.029888 model2 loss : 0.038931
[23:32:08.686] iteration 14150 : model1 loss : 0.048277 model2 loss : 0.041497
[23:32:09.516] iteration 14151 : model1 loss : 0.028045 model2 loss : 0.026417
[23:32:10.241] iteration 14152 : model1 loss : 0.021571 model2 loss : 0.022293
[23:32:10.907] iteration 14153 : model1 loss : 0.026816 model2 loss : 0.025899
[23:32:11.579] iteration 14154 : model1 loss : 0.020880 model2 loss : 0.022748
[23:32:12.266] iteration 14155 : model1 loss : 0.029206 model2 loss : 0.022097
[23:32:12.953] iteration 14156 : model1 loss : 0.067040 model2 loss : 0.036893
[23:32:13.624] iteration 14157 : model1 loss : 0.029475 model2 loss : 0.033610
[23:32:14.291] iteration 14158 : model1 loss : 0.018101 model2 loss : 0.018724
[23:32:14.947] iteration 14159 : model1 loss : 0.026607 model2 loss : 0.025045
[23:32:15.607] iteration 14160 : model1 loss : 0.035250 model2 loss : 0.027874
[23:32:16.271] iteration 14161 : model1 loss : 0.017455 model2 loss : 0.019253
[23:32:16.932] iteration 14162 : model1 loss : 0.018969 model2 loss : 0.016422
[23:32:17.598] iteration 14163 : model1 loss : 0.017169 model2 loss : 0.016581
[23:32:18.275] iteration 14164 : model1 loss : 0.026062 model2 loss : 0.025702
[23:32:18.935] iteration 14165 : model1 loss : 0.018255 model2 loss : 0.018101
[23:32:19.594] iteration 14166 : model1 loss : 0.019084 model2 loss : 0.019692
[23:32:20.270] iteration 14167 : model1 loss : 0.027519 model2 loss : 0.019930
[23:32:20.932] iteration 14168 : model1 loss : 0.032809 model2 loss : 0.031552
[23:32:21.587] iteration 14169 : model1 loss : 0.033889 model2 loss : 0.028690
[23:32:22.255] iteration 14170 : model1 loss : 0.019783 model2 loss : 0.019247
[23:32:22.926] iteration 14171 : model1 loss : 0.021698 model2 loss : 0.023204
[23:32:23.592] iteration 14172 : model1 loss : 0.030682 model2 loss : 0.026445
[23:32:24.253] iteration 14173 : model1 loss : 0.014362 model2 loss : 0.014337
[23:32:24.912] iteration 14174 : model1 loss : 0.030639 model2 loss : 0.039965
[23:32:25.571] iteration 14175 : model1 loss : 0.030451 model2 loss : 0.027027
[23:32:26.226] iteration 14176 : model1 loss : 0.079856 model2 loss : 0.079767
[23:32:26.910] iteration 14177 : model1 loss : 0.021350 model2 loss : 0.020326
[23:32:27.570] iteration 14178 : model1 loss : 0.021376 model2 loss : 0.022794
[23:32:28.229] iteration 14179 : model1 loss : 0.019590 model2 loss : 0.017884
[23:32:28.892] iteration 14180 : model1 loss : 0.040151 model2 loss : 0.035276
[23:32:29.559] iteration 14181 : model1 loss : 0.033272 model2 loss : 0.027756
[23:32:30.216] iteration 14182 : model1 loss : 0.057482 model2 loss : 0.030906
[23:32:30.874] iteration 14183 : model1 loss : 0.017323 model2 loss : 0.019503
[23:32:31.536] iteration 14184 : model1 loss : 0.021283 model2 loss : 0.023687
[23:32:32.185] iteration 14185 : model1 loss : 0.020703 model2 loss : 0.019851
[23:32:32.844] iteration 14186 : model1 loss : 0.020974 model2 loss : 0.016488
[23:32:33.512] iteration 14187 : model1 loss : 0.020342 model2 loss : 0.020206
[23:32:34.206] iteration 14188 : model1 loss : 0.030417 model2 loss : 0.030129
[23:32:34.885] iteration 14189 : model1 loss : 0.029260 model2 loss : 0.029054
[23:32:35.538] iteration 14190 : model1 loss : 0.018202 model2 loss : 0.016852
[23:32:36.193] iteration 14191 : model1 loss : 0.017876 model2 loss : 0.018360
[23:32:36.854] iteration 14192 : model1 loss : 0.019666 model2 loss : 0.020368
[23:32:37.508] iteration 14193 : model1 loss : 0.025167 model2 loss : 0.021408
[23:32:38.167] iteration 14194 : model1 loss : 0.045715 model2 loss : 0.026774
[23:32:38.843] iteration 14195 : model1 loss : 0.018114 model2 loss : 0.020160
[23:32:39.502] iteration 14196 : model1 loss : 0.022016 model2 loss : 0.022853
[23:32:40.177] iteration 14197 : model1 loss : 0.034085 model2 loss : 0.024970
[23:32:40.836] iteration 14198 : model1 loss : 0.025137 model2 loss : 0.025227
[23:32:41.492] iteration 14199 : model1 loss : 0.023061 model2 loss : 0.021376
[23:32:42.150] iteration 14200 : model1 loss : 0.019035 model2 loss : 0.018786
[23:33:00.007] iteration 14200 : model1_mean_dice : 0.860514 model1_mean_hd95 : 2.199035
[23:33:17.877] iteration 14200 : model2_mean_dice : 0.877519 model2_mean_hd95 : 5.553159
[23:33:18.568] iteration 14201 : model1 loss : 0.022808 model2 loss : 0.021225
[23:33:19.222] iteration 14202 : model1 loss : 0.027081 model2 loss : 0.025858
[23:33:19.883] iteration 14203 : model1 loss : 0.020595 model2 loss : 0.019312
[23:33:20.541] iteration 14204 : model1 loss : 0.025242 model2 loss : 0.023468
[23:33:21.207] iteration 14205 : model1 loss : 0.032541 model2 loss : 0.029039
[23:33:21.862] iteration 14206 : model1 loss : 0.037036 model2 loss : 0.025579
[23:33:22.533] iteration 14207 : model1 loss : 0.020087 model2 loss : 0.018027
[23:33:23.188] iteration 14208 : model1 loss : 0.022975 model2 loss : 0.021548
[23:33:23.841] iteration 14209 : model1 loss : 0.045722 model2 loss : 0.038447
[23:33:24.506] iteration 14210 : model1 loss : 0.023868 model2 loss : 0.027380
[23:33:25.165] iteration 14211 : model1 loss : 0.019089 model2 loss : 0.018779
[23:33:25.823] iteration 14212 : model1 loss : 0.019213 model2 loss : 0.020681
[23:33:26.475] iteration 14213 : model1 loss : 0.026554 model2 loss : 0.020582
[23:33:27.131] iteration 14214 : model1 loss : 0.020421 model2 loss : 0.020999
[23:33:27.797] iteration 14215 : model1 loss : 0.022459 model2 loss : 0.022244
[23:33:28.453] iteration 14216 : model1 loss : 0.019528 model2 loss : 0.018892
[23:33:29.120] iteration 14217 : model1 loss : 0.140500 model2 loss : 0.142370
[23:33:29.782] iteration 14218 : model1 loss : 0.030706 model2 loss : 0.031365
[23:33:30.443] iteration 14219 : model1 loss : 0.021765 model2 loss : 0.017387
[23:33:31.098] iteration 14220 : model1 loss : 0.024283 model2 loss : 0.021561
[23:33:31.745] iteration 14221 : model1 loss : 0.018253 model2 loss : 0.021663
[23:33:32.407] iteration 14222 : model1 loss : 0.025186 model2 loss : 0.027420
[23:33:33.087] iteration 14223 : model1 loss : 0.021323 model2 loss : 0.021493
[23:33:33.850] iteration 14224 : model1 loss : 0.019657 model2 loss : 0.019015
[23:33:34.550] iteration 14225 : model1 loss : 0.019462 model2 loss : 0.025184
[23:33:35.271] iteration 14226 : model1 loss : 0.017856 model2 loss : 0.019425
[23:33:35.969] iteration 14227 : model1 loss : 0.026366 model2 loss : 0.022650
[23:33:36.714] iteration 14228 : model1 loss : 0.023949 model2 loss : 0.023601
[23:33:37.438] iteration 14229 : model1 loss : 0.024395 model2 loss : 0.019280
[23:33:38.143] iteration 14230 : model1 loss : 0.016520 model2 loss : 0.018820
[23:33:38.819] iteration 14231 : model1 loss : 0.019104 model2 loss : 0.018890
[23:33:39.519] iteration 14232 : model1 loss : 0.037213 model2 loss : 0.031749
[23:33:40.241] iteration 14233 : model1 loss : 0.020589 model2 loss : 0.019911
[23:33:40.903] iteration 14234 : model1 loss : 0.035388 model2 loss : 0.034715
[23:33:41.571] iteration 14235 : model1 loss : 0.023911 model2 loss : 0.027736
[23:33:42.228] iteration 14236 : model1 loss : 0.028594 model2 loss : 0.025702
[23:33:42.891] iteration 14237 : model1 loss : 0.021139 model2 loss : 0.022480
[23:33:43.558] iteration 14238 : model1 loss : 0.027004 model2 loss : 0.024825
[23:33:44.213] iteration 14239 : model1 loss : 0.022643 model2 loss : 0.020469
[23:33:44.877] iteration 14240 : model1 loss : 0.023127 model2 loss : 0.021995
[23:33:45.552] iteration 14241 : model1 loss : 0.024058 model2 loss : 0.025353
[23:33:46.222] iteration 14242 : model1 loss : 0.020904 model2 loss : 0.019913
[23:33:46.887] iteration 14243 : model1 loss : 0.020969 model2 loss : 0.020089
[23:33:47.538] iteration 14244 : model1 loss : 0.026757 model2 loss : 0.028023
[23:33:48.203] iteration 14245 : model1 loss : 0.032856 model2 loss : 0.030662
[23:33:48.868] iteration 14246 : model1 loss : 0.020778 model2 loss : 0.023283
[23:33:49.534] iteration 14247 : model1 loss : 0.092156 model2 loss : 0.067443
[23:33:50.183] iteration 14248 : model1 loss : 0.020023 model2 loss : 0.020068
[23:33:50.845] iteration 14249 : model1 loss : 0.017023 model2 loss : 0.017343
[23:33:51.509] iteration 14250 : model1 loss : 0.019815 model2 loss : 0.019933
[23:33:52.210] iteration 14251 : model1 loss : 0.024737 model2 loss : 0.045611
[23:33:52.876] iteration 14252 : model1 loss : 0.019746 model2 loss : 0.019194
[23:33:53.547] iteration 14253 : model1 loss : 0.023883 model2 loss : 0.023748
[23:33:54.207] iteration 14254 : model1 loss : 0.020541 model2 loss : 0.020606
[23:33:54.864] iteration 14255 : model1 loss : 0.019195 model2 loss : 0.019527
[23:33:55.527] iteration 14256 : model1 loss : 0.021531 model2 loss : 0.021675
[23:33:56.199] iteration 14257 : model1 loss : 0.023857 model2 loss : 0.023653
[23:33:56.865] iteration 14258 : model1 loss : 0.018522 model2 loss : 0.017120
[23:33:57.520] iteration 14259 : model1 loss : 0.021916 model2 loss : 0.020436
[23:33:58.179] iteration 14260 : model1 loss : 0.025102 model2 loss : 0.022822
[23:33:58.845] iteration 14261 : model1 loss : 0.029040 model2 loss : 0.033379
[23:33:59.505] iteration 14262 : model1 loss : 0.023021 model2 loss : 0.021922
[23:34:00.189] iteration 14263 : model1 loss : 0.014226 model2 loss : 0.014575
[23:34:00.864] iteration 14264 : model1 loss : 0.033004 model2 loss : 0.026315
[23:34:01.535] iteration 14265 : model1 loss : 0.016308 model2 loss : 0.016313
[23:34:02.206] iteration 14266 : model1 loss : 0.021796 model2 loss : 0.022659
[23:34:02.875] iteration 14267 : model1 loss : 0.022080 model2 loss : 0.019350
[23:34:03.539] iteration 14268 : model1 loss : 0.034818 model2 loss : 0.028264
[23:34:04.189] iteration 14269 : model1 loss : 0.045315 model2 loss : 0.045589
[23:34:04.839] iteration 14270 : model1 loss : 0.023598 model2 loss : 0.022522
[23:34:05.517] iteration 14271 : model1 loss : 0.026894 model2 loss : 0.024923
[23:34:06.177] iteration 14272 : model1 loss : 0.020298 model2 loss : 0.020947
[23:34:06.846] iteration 14273 : model1 loss : 0.020694 model2 loss : 0.021510
[23:34:07.513] iteration 14274 : model1 loss : 0.018448 model2 loss : 0.019708
[23:34:08.161] iteration 14275 : model1 loss : 0.021639 model2 loss : 0.022056
[23:34:08.832] iteration 14276 : model1 loss : 0.024053 model2 loss : 0.024550
[23:34:09.496] iteration 14277 : model1 loss : 0.022573 model2 loss : 0.022943
[23:34:10.164] iteration 14278 : model1 loss : 0.022385 model2 loss : 0.021543
[23:34:10.834] iteration 14279 : model1 loss : 0.016897 model2 loss : 0.015731
[23:34:11.619] iteration 14280 : model1 loss : 0.018536 model2 loss : 0.019633
[23:34:12.307] iteration 14281 : model1 loss : 0.017910 model2 loss : 0.020062
[23:34:12.975] iteration 14282 : model1 loss : 0.036736 model2 loss : 0.030478
[23:34:13.647] iteration 14283 : model1 loss : 0.027457 model2 loss : 0.029082
[23:34:14.346] iteration 14284 : model1 loss : 0.018988 model2 loss : 0.018592
[23:34:15.080] iteration 14285 : model1 loss : 0.024993 model2 loss : 0.022177
[23:34:15.785] iteration 14286 : model1 loss : 0.027431 model2 loss : 0.026677
[23:34:16.545] iteration 14287 : model1 loss : 0.020544 model2 loss : 0.022380
[23:34:17.281] iteration 14288 : model1 loss : 0.020161 model2 loss : 0.022041
[23:34:17.977] iteration 14289 : model1 loss : 0.023026 model2 loss : 0.025793
[23:34:18.658] iteration 14290 : model1 loss : 0.020525 model2 loss : 0.018065
[23:34:19.332] iteration 14291 : model1 loss : 0.023340 model2 loss : 0.024073
[23:34:20.000] iteration 14292 : model1 loss : 0.018772 model2 loss : 0.021046
[23:34:20.649] iteration 14293 : model1 loss : 0.019863 model2 loss : 0.021744
[23:34:21.307] iteration 14294 : model1 loss : 0.017970 model2 loss : 0.018291
[23:34:21.965] iteration 14295 : model1 loss : 0.019821 model2 loss : 0.019178
[23:34:22.631] iteration 14296 : model1 loss : 0.030912 model2 loss : 0.029085
[23:34:23.299] iteration 14297 : model1 loss : 0.022260 model2 loss : 0.024250
[23:34:23.962] iteration 14298 : model1 loss : 0.026240 model2 loss : 0.023246
[23:34:24.633] iteration 14299 : model1 loss : 0.020134 model2 loss : 0.020230
[23:34:25.300] iteration 14300 : model1 loss : 0.034642 model2 loss : 0.031781
[23:34:25.999] iteration 14301 : model1 loss : 0.019801 model2 loss : 0.016924
[23:34:26.671] iteration 14302 : model1 loss : 0.018944 model2 loss : 0.017453
[23:34:27.356] iteration 14303 : model1 loss : 0.037250 model2 loss : 0.040377
[23:34:28.064] iteration 14304 : model1 loss : 0.025677 model2 loss : 0.025380
[23:34:28.760] iteration 14305 : model1 loss : 0.015418 model2 loss : 0.017975
[23:34:29.476] iteration 14306 : model1 loss : 0.032156 model2 loss : 0.027017
[23:34:30.187] iteration 14307 : model1 loss : 0.026593 model2 loss : 0.020592
[23:34:30.909] iteration 14308 : model1 loss : 0.021738 model2 loss : 0.021704
[23:34:31.675] iteration 14309 : model1 loss : 0.022752 model2 loss : 0.025837
[23:34:32.377] iteration 14310 : model1 loss : 0.020075 model2 loss : 0.022735
[23:34:33.058] iteration 14311 : model1 loss : 0.023000 model2 loss : 0.023525
[23:34:33.789] iteration 14312 : model1 loss : 0.021739 model2 loss : 0.022966
[23:34:34.546] iteration 14313 : model1 loss : 0.021262 model2 loss : 0.024358
[23:34:35.253] iteration 14314 : model1 loss : 0.033506 model2 loss : 0.032762
[23:34:36.064] iteration 14315 : model1 loss : 0.021785 model2 loss : 0.023232
[23:34:36.827] iteration 14316 : model1 loss : 0.018329 model2 loss : 0.019639
[23:34:37.527] iteration 14317 : model1 loss : 0.022679 model2 loss : 0.023958
[23:34:38.251] iteration 14318 : model1 loss : 0.021949 model2 loss : 0.024594
[23:34:38.948] iteration 14319 : model1 loss : 0.024012 model2 loss : 0.023452
[23:34:39.643] iteration 14320 : model1 loss : 0.021987 model2 loss : 0.019050
[23:34:40.318] iteration 14321 : model1 loss : 0.038381 model2 loss : 0.035228
[23:34:41.006] iteration 14322 : model1 loss : 0.019318 model2 loss : 0.022553
[23:34:41.694] iteration 14323 : model1 loss : 0.021781 model2 loss : 0.019267
[23:34:42.393] iteration 14324 : model1 loss : 0.027244 model2 loss : 0.024761
[23:34:43.079] iteration 14325 : model1 loss : 0.020850 model2 loss : 0.019405
[23:34:43.786] iteration 14326 : model1 loss : 0.021183 model2 loss : 0.020334
[23:34:44.492] iteration 14327 : model1 loss : 0.019165 model2 loss : 0.017587
[23:34:45.178] iteration 14328 : model1 loss : 0.026091 model2 loss : 0.021715
[23:34:45.879] iteration 14329 : model1 loss : 0.020595 model2 loss : 0.019937
[23:34:46.577] iteration 14330 : model1 loss : 0.018860 model2 loss : 0.020411
[23:34:47.259] iteration 14331 : model1 loss : 0.031881 model2 loss : 0.031029
[23:34:47.977] iteration 14332 : model1 loss : 0.013922 model2 loss : 0.013477
[23:34:48.659] iteration 14333 : model1 loss : 0.023097 model2 loss : 0.023107
[23:34:49.351] iteration 14334 : model1 loss : 0.021206 model2 loss : 0.020868
[23:34:50.029] iteration 14335 : model1 loss : 0.035554 model2 loss : 0.019721
[23:34:50.714] iteration 14336 : model1 loss : 0.031028 model2 loss : 0.036571
[23:34:51.405] iteration 14337 : model1 loss : 0.030012 model2 loss : 0.025263
[23:34:52.092] iteration 14338 : model1 loss : 0.026172 model2 loss : 0.027146
[23:34:52.778] iteration 14339 : model1 loss : 0.018156 model2 loss : 0.019246
[23:34:53.469] iteration 14340 : model1 loss : 0.033763 model2 loss : 0.034933
[23:34:54.168] iteration 14341 : model1 loss : 0.023389 model2 loss : 0.022593
[23:34:54.858] iteration 14342 : model1 loss : 0.025204 model2 loss : 0.022554
[23:34:55.573] iteration 14343 : model1 loss : 0.019084 model2 loss : 0.018387
[23:34:56.295] iteration 14344 : model1 loss : 0.018960 model2 loss : 0.017746
[23:34:56.975] iteration 14345 : model1 loss : 0.025186 model2 loss : 0.024393
[23:34:57.668] iteration 14346 : model1 loss : 0.023855 model2 loss : 0.022155
[23:34:58.349] iteration 14347 : model1 loss : 0.023230 model2 loss : 0.025307
[23:34:59.046] iteration 14348 : model1 loss : 0.019772 model2 loss : 0.020167
[23:34:59.739] iteration 14349 : model1 loss : 0.028195 model2 loss : 0.029585
[23:35:00.456] iteration 14350 : model1 loss : 0.017825 model2 loss : 0.017636
[23:35:01.209] iteration 14351 : model1 loss : 0.022439 model2 loss : 0.021856
[23:35:01.911] iteration 14352 : model1 loss : 0.021064 model2 loss : 0.019584
[23:35:02.625] iteration 14353 : model1 loss : 0.019995 model2 loss : 0.018407
[23:35:03.414] iteration 14354 : model1 loss : 0.020548 model2 loss : 0.019828
[23:35:04.173] iteration 14355 : model1 loss : 0.028604 model2 loss : 0.028156
[23:35:04.870] iteration 14356 : model1 loss : 0.018743 model2 loss : 0.018733
[23:35:05.580] iteration 14357 : model1 loss : 0.018787 model2 loss : 0.017414
[23:35:06.266] iteration 14358 : model1 loss : 0.027095 model2 loss : 0.027315
[23:35:06.958] iteration 14359 : model1 loss : 0.019261 model2 loss : 0.020976
[23:35:07.634] iteration 14360 : model1 loss : 0.048825 model2 loss : 0.048646
[23:35:08.310] iteration 14361 : model1 loss : 0.028241 model2 loss : 0.029803
[23:35:08.996] iteration 14362 : model1 loss : 0.020482 model2 loss : 0.020773
[23:35:09.680] iteration 14363 : model1 loss : 0.025207 model2 loss : 0.023640
[23:35:10.365] iteration 14364 : model1 loss : 0.023027 model2 loss : 0.025629
[23:35:11.057] iteration 14365 : model1 loss : 0.024443 model2 loss : 0.026663
[23:35:11.750] iteration 14366 : model1 loss : 0.019622 model2 loss : 0.020184
[23:35:12.445] iteration 14367 : model1 loss : 0.026616 model2 loss : 0.028595
[23:35:13.142] iteration 14368 : model1 loss : 0.019521 model2 loss : 0.024135
[23:35:13.833] iteration 14369 : model1 loss : 0.038919 model2 loss : 0.036223
[23:35:14.518] iteration 14370 : model1 loss : 0.019875 model2 loss : 0.022142
[23:35:15.202] iteration 14371 : model1 loss : 0.026375 model2 loss : 0.021847
[23:35:15.885] iteration 14372 : model1 loss : 0.019367 model2 loss : 0.019189
[23:35:16.572] iteration 14373 : model1 loss : 0.021476 model2 loss : 0.018271
[23:35:17.258] iteration 14374 : model1 loss : 0.021863 model2 loss : 0.021903
[23:35:17.943] iteration 14375 : model1 loss : 0.015181 model2 loss : 0.015524
[23:35:18.633] iteration 14376 : model1 loss : 0.024050 model2 loss : 0.021817
[23:35:19.317] iteration 14377 : model1 loss : 0.019920 model2 loss : 0.020207
[23:35:19.989] iteration 14378 : model1 loss : 0.019098 model2 loss : 0.018206
[23:35:20.680] iteration 14379 : model1 loss : 0.021185 model2 loss : 0.020349
[23:35:21.370] iteration 14380 : model1 loss : 0.016741 model2 loss : 0.014791
[23:35:22.057] iteration 14381 : model1 loss : 0.020689 model2 loss : 0.019998
[23:35:22.758] iteration 14382 : model1 loss : 0.021541 model2 loss : 0.022025
[23:35:23.443] iteration 14383 : model1 loss : 0.022788 model2 loss : 0.020309
[23:35:24.131] iteration 14384 : model1 loss : 0.022452 model2 loss : 0.021999
[23:35:24.811] iteration 14385 : model1 loss : 0.019951 model2 loss : 0.019419
[23:35:25.503] iteration 14386 : model1 loss : 0.022928 model2 loss : 0.022640
[23:35:26.213] iteration 14387 : model1 loss : 0.052260 model2 loss : 0.043203
[23:35:26.884] iteration 14388 : model1 loss : 0.030170 model2 loss : 0.025553
[23:35:27.577] iteration 14389 : model1 loss : 0.029272 model2 loss : 0.030797
[23:35:28.260] iteration 14390 : model1 loss : 0.021776 model2 loss : 0.019632
[23:35:28.947] iteration 14391 : model1 loss : 0.026097 model2 loss : 0.044311
[23:35:29.631] iteration 14392 : model1 loss : 0.020543 model2 loss : 0.019927
[23:35:30.319] iteration 14393 : model1 loss : 0.067579 model2 loss : 0.061256
[23:35:31.005] iteration 14394 : model1 loss : 0.021669 model2 loss : 0.021737
[23:35:31.685] iteration 14395 : model1 loss : 0.053517 model2 loss : 0.054685
[23:35:32.386] iteration 14396 : model1 loss : 0.028221 model2 loss : 0.041753
[23:35:33.076] iteration 14397 : model1 loss : 0.044907 model2 loss : 0.075428
[23:35:33.776] iteration 14398 : model1 loss : 0.025972 model2 loss : 0.024199
[23:35:34.487] iteration 14399 : model1 loss : 0.019482 model2 loss : 0.021774
[23:35:35.172] iteration 14400 : model1 loss : 0.022981 model2 loss : 0.028803
[23:35:54.940] iteration 14400 : model1_mean_dice : 0.863375 model1_mean_hd95 : 6.815586
[23:36:13.755] iteration 14400 : model2_mean_dice : 0.860565 model2_mean_hd95 : 3.931495
[23:36:14.473] iteration 14401 : model1 loss : 0.028789 model2 loss : 0.029440
[23:36:15.141] iteration 14402 : model1 loss : 0.025556 model2 loss : 0.024426
[23:36:15.842] iteration 14403 : model1 loss : 0.018690 model2 loss : 0.019466
[23:36:16.570] iteration 14404 : model1 loss : 0.018906 model2 loss : 0.018592
[23:36:17.338] iteration 14405 : model1 loss : 0.034710 model2 loss : 0.036209
[23:36:18.049] iteration 14406 : model1 loss : 0.017176 model2 loss : 0.018501
[23:36:18.717] iteration 14407 : model1 loss : 0.022844 model2 loss : 0.023735
[23:36:19.368] iteration 14408 : model1 loss : 0.018402 model2 loss : 0.019034
[23:36:20.018] iteration 14409 : model1 loss : 0.020780 model2 loss : 0.021553
[23:36:20.686] iteration 14410 : model1 loss : 0.023452 model2 loss : 0.031831
[23:36:21.350] iteration 14411 : model1 loss : 0.015639 model2 loss : 0.019558
[23:36:22.027] iteration 14412 : model1 loss : 0.018352 model2 loss : 0.020630
[23:36:22.704] iteration 14413 : model1 loss : 0.024693 model2 loss : 0.026443
[23:36:23.490] iteration 14414 : model1 loss : 0.019246 model2 loss : 0.023176
[23:36:24.194] iteration 14415 : model1 loss : 0.025635 model2 loss : 0.023709
[23:36:24.920] iteration 14416 : model1 loss : 0.026725 model2 loss : 0.026419
[23:36:25.638] iteration 14417 : model1 loss : 0.026840 model2 loss : 0.026873
[23:36:26.334] iteration 14418 : model1 loss : 0.018032 model2 loss : 0.017080
[23:36:27.063] iteration 14419 : model1 loss : 0.017014 model2 loss : 0.019834
[23:36:27.771] iteration 14420 : model1 loss : 0.021089 model2 loss : 0.021298
[23:36:28.478] iteration 14421 : model1 loss : 0.022845 model2 loss : 0.020878
[23:36:29.193] iteration 14422 : model1 loss : 0.066479 model2 loss : 0.073349
[23:36:29.917] iteration 14423 : model1 loss : 0.038535 model2 loss : 0.045437
[23:36:30.625] iteration 14424 : model1 loss : 0.018260 model2 loss : 0.017525
[23:36:31.367] iteration 14425 : model1 loss : 0.024478 model2 loss : 0.022476
[23:36:32.102] iteration 14426 : model1 loss : 0.020885 model2 loss : 0.021390
[23:36:32.847] iteration 14427 : model1 loss : 0.026349 model2 loss : 0.024362
[23:36:33.561] iteration 14428 : model1 loss : 0.023822 model2 loss : 0.027321
[23:36:34.280] iteration 14429 : model1 loss : 0.023876 model2 loss : 0.026156
[23:36:34.997] iteration 14430 : model1 loss : 0.023870 model2 loss : 0.022391
[23:36:35.782] iteration 14431 : model1 loss : 0.021880 model2 loss : 0.022573
[23:36:36.577] iteration 14432 : model1 loss : 0.026833 model2 loss : 0.026842
[23:36:37.295] iteration 14433 : model1 loss : 0.023357 model2 loss : 0.021264
[23:36:37.974] iteration 14434 : model1 loss : 0.021173 model2 loss : 0.020302
[23:36:38.703] iteration 14435 : model1 loss : 0.019130 model2 loss : 0.018070
[23:36:39.451] iteration 14436 : model1 loss : 0.022164 model2 loss : 0.025882
[23:36:40.133] iteration 14437 : model1 loss : 0.025805 model2 loss : 0.030929
[23:36:40.853] iteration 14438 : model1 loss : 0.031900 model2 loss : 0.028203
[23:36:41.693] iteration 14439 : model1 loss : 0.019592 model2 loss : 0.018147
[23:36:42.637] iteration 14440 : model1 loss : 0.025475 model2 loss : 0.026933
[23:36:43.658] iteration 14441 : model1 loss : 0.021903 model2 loss : 0.024404
[23:36:44.596] iteration 14442 : model1 loss : 0.022270 model2 loss : 0.021190
[23:36:45.435] iteration 14443 : model1 loss : 0.019931 model2 loss : 0.018977
[23:36:46.245] iteration 14444 : model1 loss : 0.023433 model2 loss : 0.023045
[23:36:46.929] iteration 14445 : model1 loss : 0.028077 model2 loss : 0.023466
[23:36:47.601] iteration 14446 : model1 loss : 0.025568 model2 loss : 0.024589
[23:36:48.288] iteration 14447 : model1 loss : 0.031179 model2 loss : 0.032152
[23:36:48.952] iteration 14448 : model1 loss : 0.019761 model2 loss : 0.021364
[23:36:49.632] iteration 14449 : model1 loss : 0.017769 model2 loss : 0.018897
[23:36:50.314] iteration 14450 : model1 loss : 0.033555 model2 loss : 0.024426
[23:36:51.091] iteration 14451 : model1 loss : 0.021365 model2 loss : 0.022094
[23:36:51.868] iteration 14452 : model1 loss : 0.028072 model2 loss : 0.026423
[23:36:52.629] iteration 14453 : model1 loss : 0.039283 model2 loss : 0.032250
[23:36:53.393] iteration 14454 : model1 loss : 0.023125 model2 loss : 0.023003
[23:36:54.163] iteration 14455 : model1 loss : 0.031985 model2 loss : 0.031353
[23:36:54.924] iteration 14456 : model1 loss : 0.032829 model2 loss : 0.028852
[23:36:55.682] iteration 14457 : model1 loss : 0.019595 model2 loss : 0.019085
[23:36:56.449] iteration 14458 : model1 loss : 0.029093 model2 loss : 0.028838
[23:36:57.144] iteration 14459 : model1 loss : 0.019953 model2 loss : 0.021482
[23:36:57.820] iteration 14460 : model1 loss : 0.023477 model2 loss : 0.024139
[23:36:58.491] iteration 14461 : model1 loss : 0.021273 model2 loss : 0.021861
[23:36:59.156] iteration 14462 : model1 loss : 0.024829 model2 loss : 0.022712
[23:36:59.837] iteration 14463 : model1 loss : 0.026723 model2 loss : 0.024591
[23:37:00.523] iteration 14464 : model1 loss : 0.020010 model2 loss : 0.020468
[23:37:01.194] iteration 14465 : model1 loss : 0.019532 model2 loss : 0.017859
[23:37:01.859] iteration 14466 : model1 loss : 0.035795 model2 loss : 0.030116
[23:37:02.530] iteration 14467 : model1 loss : 0.046997 model2 loss : 0.036493
[23:37:03.201] iteration 14468 : model1 loss : 0.019920 model2 loss : 0.020255
[23:37:03.876] iteration 14469 : model1 loss : 0.022374 model2 loss : 0.020546
[23:37:04.555] iteration 14470 : model1 loss : 0.021203 model2 loss : 0.021078
[23:37:05.229] iteration 14471 : model1 loss : 0.071256 model2 loss : 0.060277
[23:37:05.899] iteration 14472 : model1 loss : 0.022218 model2 loss : 0.019322
[23:37:06.556] iteration 14473 : model1 loss : 0.146945 model2 loss : 0.149393
[23:37:07.224] iteration 14474 : model1 loss : 0.017811 model2 loss : 0.019597
[23:37:07.899] iteration 14475 : model1 loss : 0.029817 model2 loss : 0.031254
[23:37:08.576] iteration 14476 : model1 loss : 0.027723 model2 loss : 0.027560
[23:37:09.244] iteration 14477 : model1 loss : 0.028770 model2 loss : 0.029709
[23:37:09.913] iteration 14478 : model1 loss : 0.021867 model2 loss : 0.020818
[23:37:10.584] iteration 14479 : model1 loss : 0.159555 model2 loss : 0.158532
[23:37:11.251] iteration 14480 : model1 loss : 0.021743 model2 loss : 0.022564
[23:37:11.917] iteration 14481 : model1 loss : 0.032011 model2 loss : 0.029936
[23:37:12.584] iteration 14482 : model1 loss : 0.022911 model2 loss : 0.020816
[23:37:13.250] iteration 14483 : model1 loss : 0.019440 model2 loss : 0.020517
[23:37:13.916] iteration 14484 : model1 loss : 0.026214 model2 loss : 0.024221
[23:37:14.586] iteration 14485 : model1 loss : 0.019215 model2 loss : 0.019040
[23:37:15.264] iteration 14486 : model1 loss : 0.025928 model2 loss : 0.026023
[23:37:15.949] iteration 14487 : model1 loss : 0.028899 model2 loss : 0.022904
[23:37:16.621] iteration 14488 : model1 loss : 0.028253 model2 loss : 0.025513
[23:37:17.306] iteration 14489 : model1 loss : 0.020065 model2 loss : 0.017285
[23:37:17.976] iteration 14490 : model1 loss : 0.023491 model2 loss : 0.022300
[23:37:18.649] iteration 14491 : model1 loss : 0.148951 model2 loss : 0.147945
[23:37:19.327] iteration 14492 : model1 loss : 0.024285 model2 loss : 0.022437
[23:37:19.994] iteration 14493 : model1 loss : 0.025640 model2 loss : 0.027527
[23:37:20.665] iteration 14494 : model1 loss : 0.026391 model2 loss : 0.024312
[23:37:21.342] iteration 14495 : model1 loss : 0.015308 model2 loss : 0.016519
[23:37:22.004] iteration 14496 : model1 loss : 0.024775 model2 loss : 0.022219
[23:37:22.677] iteration 14497 : model1 loss : 0.019827 model2 loss : 0.018648
[23:37:23.353] iteration 14498 : model1 loss : 0.027169 model2 loss : 0.028160
[23:37:24.020] iteration 14499 : model1 loss : 0.022302 model2 loss : 0.023638
[23:37:24.684] iteration 14500 : model1 loss : 0.027284 model2 loss : 0.023489
[23:37:25.399] iteration 14501 : model1 loss : 0.019982 model2 loss : 0.018194
[23:37:26.079] iteration 14502 : model1 loss : 0.021126 model2 loss : 0.020696
[23:37:26.751] iteration 14503 : model1 loss : 0.017487 model2 loss : 0.016483
[23:37:27.426] iteration 14504 : model1 loss : 0.027428 model2 loss : 0.030275
[23:37:28.091] iteration 14505 : model1 loss : 0.022407 model2 loss : 0.022853
[23:37:28.760] iteration 14506 : model1 loss : 0.030985 model2 loss : 0.029639
[23:37:29.429] iteration 14507 : model1 loss : 0.019023 model2 loss : 0.018034
[23:37:30.090] iteration 14508 : model1 loss : 0.017505 model2 loss : 0.018675
[23:37:30.762] iteration 14509 : model1 loss : 0.039603 model2 loss : 0.041983
[23:37:31.430] iteration 14510 : model1 loss : 0.030431 model2 loss : 0.035398
[23:37:32.091] iteration 14511 : model1 loss : 0.019603 model2 loss : 0.018839
[23:37:32.748] iteration 14512 : model1 loss : 0.021804 model2 loss : 0.022192
[23:37:33.422] iteration 14513 : model1 loss : 0.019047 model2 loss : 0.019520
[23:37:34.086] iteration 14514 : model1 loss : 0.020283 model2 loss : 0.019827
[23:37:34.757] iteration 14515 : model1 loss : 0.023500 model2 loss : 0.022555
[23:37:35.434] iteration 14516 : model1 loss : 0.018845 model2 loss : 0.019461
[23:37:36.134] iteration 14517 : model1 loss : 0.023264 model2 loss : 0.024888
[23:37:36.806] iteration 14518 : model1 loss : 0.020972 model2 loss : 0.022128
[23:37:37.506] iteration 14519 : model1 loss : 0.019740 model2 loss : 0.019645
[23:37:38.197] iteration 14520 : model1 loss : 0.021799 model2 loss : 0.020225
[23:37:38.870] iteration 14521 : model1 loss : 0.019970 model2 loss : 0.019147
[23:37:39.536] iteration 14522 : model1 loss : 0.037876 model2 loss : 0.034165
[23:37:40.209] iteration 14523 : model1 loss : 0.015404 model2 loss : 0.018683
[23:37:40.885] iteration 14524 : model1 loss : 0.021575 model2 loss : 0.024854
[23:37:41.554] iteration 14525 : model1 loss : 0.023372 model2 loss : 0.024379
[23:37:42.224] iteration 14526 : model1 loss : 0.018735 model2 loss : 0.017121
[23:37:42.884] iteration 14527 : model1 loss : 0.046649 model2 loss : 0.039782
[23:37:43.559] iteration 14528 : model1 loss : 0.018126 model2 loss : 0.019444
[23:37:44.229] iteration 14529 : model1 loss : 0.026066 model2 loss : 0.028270
[23:37:44.890] iteration 14530 : model1 loss : 0.017706 model2 loss : 0.017262
[23:37:45.572] iteration 14531 : model1 loss : 0.030874 model2 loss : 0.028061
[23:37:46.252] iteration 14532 : model1 loss : 0.022884 model2 loss : 0.024600
[23:37:46.932] iteration 14533 : model1 loss : 0.021205 model2 loss : 0.022016
[23:37:47.601] iteration 14534 : model1 loss : 0.025488 model2 loss : 0.028039
[23:37:48.270] iteration 14535 : model1 loss : 0.017237 model2 loss : 0.017080
[23:37:48.946] iteration 14536 : model1 loss : 0.022932 model2 loss : 0.022680
[23:37:49.618] iteration 14537 : model1 loss : 0.026864 model2 loss : 0.024058
[23:37:50.282] iteration 14538 : model1 loss : 0.024094 model2 loss : 0.023052
[23:37:50.944] iteration 14539 : model1 loss : 0.020467 model2 loss : 0.019789
[23:37:51.621] iteration 14540 : model1 loss : 0.020735 model2 loss : 0.020866
[23:37:52.300] iteration 14541 : model1 loss : 0.017905 model2 loss : 0.017320
[23:37:52.964] iteration 14542 : model1 loss : 0.024168 model2 loss : 0.024217
[23:37:53.630] iteration 14543 : model1 loss : 0.017293 model2 loss : 0.018731
[23:37:54.297] iteration 14544 : model1 loss : 0.020893 model2 loss : 0.019949
[23:37:54.983] iteration 14545 : model1 loss : 0.039521 model2 loss : 0.033711
[23:37:55.672] iteration 14546 : model1 loss : 0.023560 model2 loss : 0.022724
[23:37:56.345] iteration 14547 : model1 loss : 0.018327 model2 loss : 0.018435
[23:37:57.009] iteration 14548 : model1 loss : 0.019907 model2 loss : 0.019695
[23:37:57.672] iteration 14549 : model1 loss : 0.014603 model2 loss : 0.013989
[23:37:58.344] iteration 14550 : model1 loss : 0.022746 model2 loss : 0.021472
[23:37:59.056] iteration 14551 : model1 loss : 0.019620 model2 loss : 0.018671
[23:37:59.717] iteration 14552 : model1 loss : 0.017041 model2 loss : 0.016417
[23:38:00.387] iteration 14553 : model1 loss : 0.019393 model2 loss : 0.019725
[23:38:01.069] iteration 14554 : model1 loss : 0.027331 model2 loss : 0.026171
[23:38:01.736] iteration 14555 : model1 loss : 0.017380 model2 loss : 0.017679
[23:38:02.417] iteration 14556 : model1 loss : 0.024823 model2 loss : 0.023129
[23:38:03.091] iteration 14557 : model1 loss : 0.035396 model2 loss : 0.032735
[23:38:03.772] iteration 14558 : model1 loss : 0.030137 model2 loss : 0.029753
[23:38:04.442] iteration 14559 : model1 loss : 0.016679 model2 loss : 0.016569
[23:38:05.126] iteration 14560 : model1 loss : 0.021123 model2 loss : 0.021714
[23:38:05.789] iteration 14561 : model1 loss : 0.025554 model2 loss : 0.024806
[23:38:06.450] iteration 14562 : model1 loss : 0.030954 model2 loss : 0.032906
[23:38:07.109] iteration 14563 : model1 loss : 0.022368 model2 loss : 0.022306
[23:38:07.787] iteration 14564 : model1 loss : 0.031080 model2 loss : 0.032979
[23:38:08.447] iteration 14565 : model1 loss : 0.018386 model2 loss : 0.017546
[23:38:09.128] iteration 14566 : model1 loss : 0.025180 model2 loss : 0.021437
[23:38:09.785] iteration 14567 : model1 loss : 0.020801 model2 loss : 0.020600
[23:38:10.463] iteration 14568 : model1 loss : 0.025937 model2 loss : 0.027273
[23:38:11.140] iteration 14569 : model1 loss : 0.038319 model2 loss : 0.031952
[23:38:11.801] iteration 14570 : model1 loss : 0.151930 model2 loss : 0.149131
[23:38:12.474] iteration 14571 : model1 loss : 0.019376 model2 loss : 0.020389
[23:38:13.144] iteration 14572 : model1 loss : 0.022372 model2 loss : 0.020033
[23:38:13.820] iteration 14573 : model1 loss : 0.018429 model2 loss : 0.016944
[23:38:14.510] iteration 14574 : model1 loss : 0.016687 model2 loss : 0.017882
[23:38:15.168] iteration 14575 : model1 loss : 0.042351 model2 loss : 0.041238
[23:38:15.826] iteration 14576 : model1 loss : 0.021156 model2 loss : 0.023345
[23:38:16.496] iteration 14577 : model1 loss : 0.028485 model2 loss : 0.029775
[23:38:17.159] iteration 14578 : model1 loss : 0.030739 model2 loss : 0.027392
[23:38:17.831] iteration 14579 : model1 loss : 0.022779 model2 loss : 0.024049
[23:38:18.492] iteration 14580 : model1 loss : 0.020219 model2 loss : 0.022024
[23:38:19.159] iteration 14581 : model1 loss : 0.015264 model2 loss : 0.016527
[23:38:19.834] iteration 14582 : model1 loss : 0.019900 model2 loss : 0.021597
[23:38:20.510] iteration 14583 : model1 loss : 0.019184 model2 loss : 0.021713
[23:38:21.186] iteration 14584 : model1 loss : 0.030428 model2 loss : 0.030363
[23:38:21.865] iteration 14585 : model1 loss : 0.025874 model2 loss : 0.021955
[23:38:22.525] iteration 14586 : model1 loss : 0.017765 model2 loss : 0.018882
[23:38:23.193] iteration 14587 : model1 loss : 0.021806 model2 loss : 0.019969
[23:38:23.856] iteration 14588 : model1 loss : 0.026851 model2 loss : 0.023943
[23:38:24.520] iteration 14589 : model1 loss : 0.027889 model2 loss : 0.028490
[23:38:25.193] iteration 14590 : model1 loss : 0.026837 model2 loss : 0.033985
[23:38:25.860] iteration 14591 : model1 loss : 0.021251 model2 loss : 0.019704
[23:38:26.523] iteration 14592 : model1 loss : 0.017888 model2 loss : 0.016497
[23:38:27.179] iteration 14593 : model1 loss : 0.039135 model2 loss : 0.042416
[23:38:27.857] iteration 14594 : model1 loss : 0.023149 model2 loss : 0.024763
[23:38:28.528] iteration 14595 : model1 loss : 0.018924 model2 loss : 0.021294
[23:38:29.210] iteration 14596 : model1 loss : 0.024979 model2 loss : 0.024283
[23:38:29.884] iteration 14597 : model1 loss : 0.023421 model2 loss : 0.022864
[23:38:30.557] iteration 14598 : model1 loss : 0.063103 model2 loss : 0.030983
[23:38:31.237] iteration 14599 : model1 loss : 0.021328 model2 loss : 0.023440
[23:38:31.899] iteration 14600 : model1 loss : 0.022027 model2 loss : 0.023478
[23:38:50.310] iteration 14600 : model1_mean_dice : 0.866728 model1_mean_hd95 : 7.503601
[23:39:08.572] iteration 14600 : model2_mean_dice : 0.865812 model2_mean_hd95 : 4.745108
[23:39:09.271] iteration 14601 : model1 loss : 0.022345 model2 loss : 0.031264
[23:39:09.942] iteration 14602 : model1 loss : 0.021500 model2 loss : 0.019700
[23:39:10.604] iteration 14603 : model1 loss : 0.016422 model2 loss : 0.014902
[23:39:11.274] iteration 14604 : model1 loss : 0.018487 model2 loss : 0.016932
[23:39:11.938] iteration 14605 : model1 loss : 0.019984 model2 loss : 0.021250
[23:39:12.603] iteration 14606 : model1 loss : 0.023979 model2 loss : 0.024989
[23:39:13.275] iteration 14607 : model1 loss : 0.018927 model2 loss : 0.019603
[23:39:13.942] iteration 14608 : model1 loss : 0.027290 model2 loss : 0.027254
[23:39:14.626] iteration 14609 : model1 loss : 0.021311 model2 loss : 0.021242
[23:39:15.303] iteration 14610 : model1 loss : 0.018866 model2 loss : 0.018641
[23:39:15.965] iteration 14611 : model1 loss : 0.024291 model2 loss : 0.022806
[23:39:16.637] iteration 14612 : model1 loss : 0.027188 model2 loss : 0.027472
[23:39:17.302] iteration 14613 : model1 loss : 0.028653 model2 loss : 0.020515
[23:39:17.974] iteration 14614 : model1 loss : 0.022946 model2 loss : 0.022759
[23:39:18.645] iteration 14615 : model1 loss : 0.022737 model2 loss : 0.022070
[23:39:19.309] iteration 14616 : model1 loss : 0.027689 model2 loss : 0.025424
[23:39:19.982] iteration 14617 : model1 loss : 0.027158 model2 loss : 0.023976
[23:39:20.647] iteration 14618 : model1 loss : 0.031928 model2 loss : 0.030902
[23:39:21.316] iteration 14619 : model1 loss : 0.023221 model2 loss : 0.019492
[23:39:21.973] iteration 14620 : model1 loss : 0.021217 model2 loss : 0.021097
[23:39:22.646] iteration 14621 : model1 loss : 0.019863 model2 loss : 0.019162
[23:39:23.314] iteration 14622 : model1 loss : 0.024316 model2 loss : 0.024875
[23:39:23.977] iteration 14623 : model1 loss : 0.028796 model2 loss : 0.027062
[23:39:24.644] iteration 14624 : model1 loss : 0.023538 model2 loss : 0.023937
[23:39:25.308] iteration 14625 : model1 loss : 0.021739 model2 loss : 0.020820
[23:39:25.983] iteration 14626 : model1 loss : 0.019061 model2 loss : 0.017485
[23:39:26.644] iteration 14627 : model1 loss : 0.014419 model2 loss : 0.013627
[23:39:27.310] iteration 14628 : model1 loss : 0.024019 model2 loss : 0.024791
[23:39:27.975] iteration 14629 : model1 loss : 0.020142 model2 loss : 0.022048
[23:39:28.660] iteration 14630 : model1 loss : 0.141236 model2 loss : 0.103156
[23:39:29.326] iteration 14631 : model1 loss : 0.014575 model2 loss : 0.016662
[23:39:29.992] iteration 14632 : model1 loss : 0.018917 model2 loss : 0.019857
[23:39:30.663] iteration 14633 : model1 loss : 0.020943 model2 loss : 0.019308
[23:39:31.328] iteration 14634 : model1 loss : 0.088470 model2 loss : 0.098351
[23:39:32.000] iteration 14635 : model1 loss : 0.024203 model2 loss : 0.023702
[23:39:32.663] iteration 14636 : model1 loss : 0.020835 model2 loss : 0.024928
[23:39:33.347] iteration 14637 : model1 loss : 0.022056 model2 loss : 0.021429
[23:39:34.013] iteration 14638 : model1 loss : 0.022888 model2 loss : 0.023478
[23:39:34.679] iteration 14639 : model1 loss : 0.026376 model2 loss : 0.023643
[23:39:35.373] iteration 14640 : model1 loss : 0.023208 model2 loss : 0.026190
[23:39:36.043] iteration 14641 : model1 loss : 0.022392 model2 loss : 0.032622
[23:39:36.710] iteration 14642 : model1 loss : 0.023147 model2 loss : 0.028743
[23:39:37.383] iteration 14643 : model1 loss : 0.020868 model2 loss : 0.020692
[23:39:38.073] iteration 14644 : model1 loss : 0.021981 model2 loss : 0.029016
[23:39:38.775] iteration 14645 : model1 loss : 0.019952 model2 loss : 0.021619
[23:39:39.453] iteration 14646 : model1 loss : 0.020460 model2 loss : 0.023410
[23:39:40.120] iteration 14647 : model1 loss : 0.015539 model2 loss : 0.017700
[23:39:40.817] iteration 14648 : model1 loss : 0.023017 model2 loss : 0.027040
[23:39:41.481] iteration 14649 : model1 loss : 0.026691 model2 loss : 0.028183
[23:39:42.153] iteration 14650 : model1 loss : 0.026155 model2 loss : 0.023677
[23:39:42.856] iteration 14651 : model1 loss : 0.020975 model2 loss : 0.021930
[23:39:43.516] iteration 14652 : model1 loss : 0.019101 model2 loss : 0.025064
[23:39:44.191] iteration 14653 : model1 loss : 0.024334 model2 loss : 0.027218
[23:39:44.857] iteration 14654 : model1 loss : 0.026158 model2 loss : 0.030575
[23:39:45.517] iteration 14655 : model1 loss : 0.018763 model2 loss : 0.021556
[23:39:46.197] iteration 14656 : model1 loss : 0.024809 model2 loss : 0.026540
[23:39:46.876] iteration 14657 : model1 loss : 0.029854 model2 loss : 0.040853
[23:39:47.567] iteration 14658 : model1 loss : 0.021331 model2 loss : 0.017751
[23:39:48.237] iteration 14659 : model1 loss : 0.048315 model2 loss : 0.069952
[23:39:48.897] iteration 14660 : model1 loss : 0.022272 model2 loss : 0.023366
[23:39:49.567] iteration 14661 : model1 loss : 0.019703 model2 loss : 0.024675
[23:39:50.241] iteration 14662 : model1 loss : 0.021899 model2 loss : 0.028281
[23:39:50.912] iteration 14663 : model1 loss : 0.023808 model2 loss : 0.025137
[23:39:51.588] iteration 14664 : model1 loss : 0.018414 model2 loss : 0.020521
[23:39:52.255] iteration 14665 : model1 loss : 0.021238 model2 loss : 0.021781
[23:39:52.921] iteration 14666 : model1 loss : 0.021095 model2 loss : 0.024550
[23:39:53.599] iteration 14667 : model1 loss : 0.020401 model2 loss : 0.021193
[23:39:54.274] iteration 14668 : model1 loss : 0.030677 model2 loss : 0.028305
[23:39:54.934] iteration 14669 : model1 loss : 0.016973 model2 loss : 0.022788
[23:39:55.603] iteration 14670 : model1 loss : 0.016385 model2 loss : 0.016077
[23:39:56.273] iteration 14671 : model1 loss : 0.021399 model2 loss : 0.023160
[23:39:56.943] iteration 14672 : model1 loss : 0.029233 model2 loss : 0.023175
[23:39:57.622] iteration 14673 : model1 loss : 0.018049 model2 loss : 0.019613
[23:39:58.290] iteration 14674 : model1 loss : 0.020863 model2 loss : 0.023780
[23:39:58.966] iteration 14675 : model1 loss : 0.024597 model2 loss : 0.023015
[23:39:59.634] iteration 14676 : model1 loss : 0.020913 model2 loss : 0.020951
[23:40:00.301] iteration 14677 : model1 loss : 0.033176 model2 loss : 0.027953
[23:40:00.983] iteration 14678 : model1 loss : 0.020080 model2 loss : 0.021725
[23:40:01.665] iteration 14679 : model1 loss : 0.021994 model2 loss : 0.031129
[23:40:02.342] iteration 14680 : model1 loss : 0.019664 model2 loss : 0.019347
[23:40:03.011] iteration 14681 : model1 loss : 0.019611 model2 loss : 0.020003
[23:40:03.679] iteration 14682 : model1 loss : 0.021768 model2 loss : 0.025182
[23:40:04.346] iteration 14683 : model1 loss : 0.027099 model2 loss : 0.027584
[23:40:05.009] iteration 14684 : model1 loss : 0.037534 model2 loss : 0.035303
[23:40:05.677] iteration 14685 : model1 loss : 0.021267 model2 loss : 0.023226
[23:40:06.356] iteration 14686 : model1 loss : 0.027258 model2 loss : 0.042072
[23:40:07.035] iteration 14687 : model1 loss : 0.026695 model2 loss : 0.023947
[23:40:07.699] iteration 14688 : model1 loss : 0.025828 model2 loss : 0.025533
[23:40:08.354] iteration 14689 : model1 loss : 0.033341 model2 loss : 0.031378
[23:40:09.018] iteration 14690 : model1 loss : 0.028259 model2 loss : 0.038361
[23:40:09.708] iteration 14691 : model1 loss : 0.026014 model2 loss : 0.021399
[23:40:10.381] iteration 14692 : model1 loss : 0.025961 model2 loss : 0.029321
[23:40:11.048] iteration 14693 : model1 loss : 0.026952 model2 loss : 0.029753
[23:40:11.724] iteration 14694 : model1 loss : 0.023199 model2 loss : 0.022580
[23:40:12.395] iteration 14695 : model1 loss : 0.022400 model2 loss : 0.022999
[23:40:13.054] iteration 14696 : model1 loss : 0.046254 model2 loss : 0.045481
[23:40:13.736] iteration 14697 : model1 loss : 0.017918 model2 loss : 0.017736
[23:40:14.401] iteration 14698 : model1 loss : 0.020112 model2 loss : 0.019029
[23:40:15.073] iteration 14699 : model1 loss : 0.020696 model2 loss : 0.021558
[23:40:15.735] iteration 14700 : model1 loss : 0.018458 model2 loss : 0.019154
[23:40:16.442] iteration 14701 : model1 loss : 0.018594 model2 loss : 0.019380
[23:40:17.114] iteration 14702 : model1 loss : 0.020558 model2 loss : 0.020277
[23:40:17.770] iteration 14703 : model1 loss : 0.068862 model2 loss : 0.135396
[23:40:18.441] iteration 14704 : model1 loss : 0.022967 model2 loss : 0.024769
[23:40:19.116] iteration 14705 : model1 loss : 0.021841 model2 loss : 0.021573
[23:40:19.798] iteration 14706 : model1 loss : 0.024442 model2 loss : 0.025983
[23:40:20.469] iteration 14707 : model1 loss : 0.019964 model2 loss : 0.018298
[23:40:21.143] iteration 14708 : model1 loss : 0.019647 model2 loss : 0.019156
[23:40:21.823] iteration 14709 : model1 loss : 0.028862 model2 loss : 0.031324
[23:40:22.492] iteration 14710 : model1 loss : 0.021528 model2 loss : 0.028762
[23:40:23.194] iteration 14711 : model1 loss : 0.021770 model2 loss : 0.020182
[23:40:23.853] iteration 14712 : model1 loss : 0.021520 model2 loss : 0.023810
[23:40:24.511] iteration 14713 : model1 loss : 0.021639 model2 loss : 0.023268
[23:40:25.175] iteration 14714 : model1 loss : 0.033129 model2 loss : 0.040679
[23:40:25.838] iteration 14715 : model1 loss : 0.023249 model2 loss : 0.021764
[23:40:26.515] iteration 14716 : model1 loss : 0.035491 model2 loss : 0.028725
[23:40:27.192] iteration 14717 : model1 loss : 0.017950 model2 loss : 0.017959
[23:40:27.864] iteration 14718 : model1 loss : 0.024604 model2 loss : 0.027112
[23:40:28.537] iteration 14719 : model1 loss : 0.021767 model2 loss : 0.020984
[23:40:29.214] iteration 14720 : model1 loss : 0.027080 model2 loss : 0.027375
[23:40:29.881] iteration 14721 : model1 loss : 0.019382 model2 loss : 0.022476
[23:40:30.543] iteration 14722 : model1 loss : 0.025397 model2 loss : 0.028728
[23:40:31.218] iteration 14723 : model1 loss : 0.019669 model2 loss : 0.019117
[23:40:31.876] iteration 14724 : model1 loss : 0.026935 model2 loss : 0.027772
[23:40:32.558] iteration 14725 : model1 loss : 0.037506 model2 loss : 0.043785
[23:40:33.219] iteration 14726 : model1 loss : 0.021026 model2 loss : 0.022037
[23:40:33.883] iteration 14727 : model1 loss : 0.024773 model2 loss : 0.024329
[23:40:34.545] iteration 14728 : model1 loss : 0.047614 model2 loss : 0.048842
[23:40:35.297] iteration 14729 : model1 loss : 0.028917 model2 loss : 0.027664
[23:40:36.012] iteration 14730 : model1 loss : 0.064938 model2 loss : 0.034911
[23:40:36.688] iteration 14731 : model1 loss : 0.018203 model2 loss : 0.021554
[23:40:37.370] iteration 14732 : model1 loss : 0.021221 model2 loss : 0.023271
[23:40:38.036] iteration 14733 : model1 loss : 0.018511 model2 loss : 0.017651
[23:40:38.717] iteration 14734 : model1 loss : 0.017439 model2 loss : 0.020274
[23:40:39.411] iteration 14735 : model1 loss : 0.024229 model2 loss : 0.023571
[23:40:40.104] iteration 14736 : model1 loss : 0.021971 model2 loss : 0.026070
[23:40:40.762] iteration 14737 : model1 loss : 0.018024 model2 loss : 0.018956
[23:40:41.430] iteration 14738 : model1 loss : 0.018851 model2 loss : 0.017308
[23:40:42.106] iteration 14739 : model1 loss : 0.029677 model2 loss : 0.035149
[23:40:42.776] iteration 14740 : model1 loss : 0.141081 model2 loss : 0.144986
[23:40:43.459] iteration 14741 : model1 loss : 0.023223 model2 loss : 0.022997
[23:40:44.141] iteration 14742 : model1 loss : 0.026380 model2 loss : 0.020713
[23:40:44.818] iteration 14743 : model1 loss : 0.024663 model2 loss : 0.024719
[23:40:45.480] iteration 14744 : model1 loss : 0.019002 model2 loss : 0.018638
[23:40:46.137] iteration 14745 : model1 loss : 0.015188 model2 loss : 0.016414
[23:40:46.814] iteration 14746 : model1 loss : 0.019378 model2 loss : 0.017424
[23:40:47.487] iteration 14747 : model1 loss : 0.016959 model2 loss : 0.016370
[23:40:48.159] iteration 14748 : model1 loss : 0.014370 model2 loss : 0.015530
[23:40:48.827] iteration 14749 : model1 loss : 0.023227 model2 loss : 0.023002
[23:40:49.494] iteration 14750 : model1 loss : 0.025452 model2 loss : 0.027248
[23:40:50.209] iteration 14751 : model1 loss : 0.025680 model2 loss : 0.028133
[23:40:50.875] iteration 14752 : model1 loss : 0.029051 model2 loss : 0.028681
[23:40:51.538] iteration 14753 : model1 loss : 0.018999 model2 loss : 0.021070
[23:40:52.213] iteration 14754 : model1 loss : 0.024919 model2 loss : 0.017942
[23:40:52.877] iteration 14755 : model1 loss : 0.029029 model2 loss : 0.022054
[23:40:53.551] iteration 14756 : model1 loss : 0.067467 model2 loss : 0.055483
[23:40:54.221] iteration 14757 : model1 loss : 0.029260 model2 loss : 0.028751
[23:40:54.888] iteration 14758 : model1 loss : 0.029960 model2 loss : 0.026270
[23:40:55.559] iteration 14759 : model1 loss : 0.022467 model2 loss : 0.019420
[23:40:56.221] iteration 14760 : model1 loss : 0.021767 model2 loss : 0.023115
[23:40:56.889] iteration 14761 : model1 loss : 0.024230 model2 loss : 0.023403
[23:40:57.554] iteration 14762 : model1 loss : 0.024127 model2 loss : 0.019445
[23:40:58.230] iteration 14763 : model1 loss : 0.024821 model2 loss : 0.022806
[23:40:58.904] iteration 14764 : model1 loss : 0.021818 model2 loss : 0.025417
[23:40:59.569] iteration 14765 : model1 loss : 0.015405 model2 loss : 0.018331
[23:41:00.240] iteration 14766 : model1 loss : 0.019281 model2 loss : 0.026240
[23:41:00.914] iteration 14767 : model1 loss : 0.025924 model2 loss : 0.028162
[23:41:01.582] iteration 14768 : model1 loss : 0.017256 model2 loss : 0.017112
[23:41:02.246] iteration 14769 : model1 loss : 0.019985 model2 loss : 0.018690
[23:41:02.910] iteration 14770 : model1 loss : 0.022245 model2 loss : 0.021438
[23:41:03.576] iteration 14771 : model1 loss : 0.020111 model2 loss : 0.018331
[23:41:04.249] iteration 14772 : model1 loss : 0.023307 model2 loss : 0.042323
[23:41:04.913] iteration 14773 : model1 loss : 0.024514 model2 loss : 0.022687
[23:41:05.580] iteration 14774 : model1 loss : 0.023279 model2 loss : 0.021631
[23:41:06.249] iteration 14775 : model1 loss : 0.022062 model2 loss : 0.024757
[23:41:06.925] iteration 14776 : model1 loss : 0.021854 model2 loss : 0.022487
[23:41:07.597] iteration 14777 : model1 loss : 0.017633 model2 loss : 0.016759
[23:41:08.261] iteration 14778 : model1 loss : 0.025055 model2 loss : 0.020899
[23:41:08.931] iteration 14779 : model1 loss : 0.028401 model2 loss : 0.022520
[23:41:09.613] iteration 14780 : model1 loss : 0.018068 model2 loss : 0.018687
[23:41:10.284] iteration 14781 : model1 loss : 0.019820 model2 loss : 0.020189
[23:41:10.942] iteration 14782 : model1 loss : 0.021375 model2 loss : 0.019805
[23:41:11.611] iteration 14783 : model1 loss : 0.023010 model2 loss : 0.021218
[23:41:12.288] iteration 14784 : model1 loss : 0.028537 model2 loss : 0.028173
[23:41:12.946] iteration 14785 : model1 loss : 0.027917 model2 loss : 0.027508
[23:41:13.695] iteration 14786 : model1 loss : 0.023309 model2 loss : 0.025383
[23:41:14.392] iteration 14787 : model1 loss : 0.026064 model2 loss : 0.027908
[23:41:15.087] iteration 14788 : model1 loss : 0.017248 model2 loss : 0.016624
[23:41:15.760] iteration 14789 : model1 loss : 0.039156 model2 loss : 0.048220
[23:41:16.430] iteration 14790 : model1 loss : 0.020368 model2 loss : 0.021311
[23:41:17.094] iteration 14791 : model1 loss : 0.031457 model2 loss : 0.025645
[23:41:17.778] iteration 14792 : model1 loss : 0.026137 model2 loss : 0.022061
[23:41:18.450] iteration 14793 : model1 loss : 0.016954 model2 loss : 0.017322
[23:41:19.119] iteration 14794 : model1 loss : 0.021215 model2 loss : 0.020891
[23:41:19.789] iteration 14795 : model1 loss : 0.035943 model2 loss : 0.038849
[23:41:20.462] iteration 14796 : model1 loss : 0.030072 model2 loss : 0.044496
[23:41:21.130] iteration 14797 : model1 loss : 0.024564 model2 loss : 0.023032
[23:41:21.795] iteration 14798 : model1 loss : 0.022625 model2 loss : 0.024556
[23:41:22.480] iteration 14799 : model1 loss : 0.014305 model2 loss : 0.016856
[23:41:23.149] iteration 14800 : model1 loss : 0.021722 model2 loss : 0.021506
[23:41:41.657] iteration 14800 : model1_mean_dice : 0.861445 model1_mean_hd95 : 8.412128
[23:42:00.214] iteration 14800 : model2_mean_dice : 0.857191 model2_mean_hd95 : 16.651292
[23:42:00.917] iteration 14801 : model1 loss : 0.026293 model2 loss : 0.028195
[23:42:01.578] iteration 14802 : model1 loss : 0.020083 model2 loss : 0.020528
[23:42:02.233] iteration 14803 : model1 loss : 0.023957 model2 loss : 0.025430
[23:42:02.898] iteration 14804 : model1 loss : 0.018899 model2 loss : 0.020622
[23:42:03.555] iteration 14805 : model1 loss : 0.020504 model2 loss : 0.020894
[23:42:04.211] iteration 14806 : model1 loss : 0.027161 model2 loss : 0.037661
[23:42:04.861] iteration 14807 : model1 loss : 0.024861 model2 loss : 0.026724
[23:42:05.530] iteration 14808 : model1 loss : 0.042359 model2 loss : 0.046380
[23:42:06.182] iteration 14809 : model1 loss : 0.020080 model2 loss : 0.017917
[23:42:06.845] iteration 14810 : model1 loss : 0.023852 model2 loss : 0.025825
[23:42:07.527] iteration 14811 : model1 loss : 0.018943 model2 loss : 0.025375
[23:42:08.187] iteration 14812 : model1 loss : 0.016843 model2 loss : 0.017231
[23:42:08.863] iteration 14813 : model1 loss : 0.015421 model2 loss : 0.018450
[23:42:09.532] iteration 14814 : model1 loss : 0.021117 model2 loss : 0.021944
[23:42:10.206] iteration 14815 : model1 loss : 0.017154 model2 loss : 0.018893
[23:42:10.872] iteration 14816 : model1 loss : 0.019012 model2 loss : 0.020451
[23:42:11.536] iteration 14817 : model1 loss : 0.024002 model2 loss : 0.023128
[23:42:12.199] iteration 14818 : model1 loss : 0.021439 model2 loss : 0.021125
[23:42:12.867] iteration 14819 : model1 loss : 0.024860 model2 loss : 0.025455
[23:42:13.531] iteration 14820 : model1 loss : 0.026257 model2 loss : 0.027357
[23:42:14.191] iteration 14821 : model1 loss : 0.026837 model2 loss : 0.028823
[23:42:14.869] iteration 14822 : model1 loss : 0.024720 model2 loss : 0.025110
[23:42:15.569] iteration 14823 : model1 loss : 0.031402 model2 loss : 0.032676
[23:42:16.233] iteration 14824 : model1 loss : 0.024807 model2 loss : 0.031964
[23:42:16.905] iteration 14825 : model1 loss : 0.019477 model2 loss : 0.021406
[23:42:17.567] iteration 14826 : model1 loss : 0.032458 model2 loss : 0.034502
[23:42:18.273] iteration 14827 : model1 loss : 0.025995 model2 loss : 0.025620
[23:42:18.947] iteration 14828 : model1 loss : 0.021023 model2 loss : 0.021798
[23:42:19.629] iteration 14829 : model1 loss : 0.022642 model2 loss : 0.020035
[23:42:20.325] iteration 14830 : model1 loss : 0.018190 model2 loss : 0.018429
[23:42:21.040] iteration 14831 : model1 loss : 0.019981 model2 loss : 0.026747
[23:42:21.708] iteration 14832 : model1 loss : 0.023645 model2 loss : 0.024637
[23:42:22.389] iteration 14833 : model1 loss : 0.025270 model2 loss : 0.021258
[23:42:23.080] iteration 14834 : model1 loss : 0.027023 model2 loss : 0.025323
[23:42:23.754] iteration 14835 : model1 loss : 0.018910 model2 loss : 0.021582
[23:42:24.434] iteration 14836 : model1 loss : 0.036291 model2 loss : 0.040497
[23:42:25.099] iteration 14837 : model1 loss : 0.025782 model2 loss : 0.025478
[23:42:25.769] iteration 14838 : model1 loss : 0.019173 model2 loss : 0.020387
[23:42:26.431] iteration 14839 : model1 loss : 0.023611 model2 loss : 0.023139
[23:42:27.084] iteration 14840 : model1 loss : 0.023379 model2 loss : 0.023982
[23:42:27.760] iteration 14841 : model1 loss : 0.023707 model2 loss : 0.025337
[23:42:28.428] iteration 14842 : model1 loss : 0.016157 model2 loss : 0.016769
[23:42:29.096] iteration 14843 : model1 loss : 0.028797 model2 loss : 0.029830
[23:42:29.762] iteration 14844 : model1 loss : 0.025589 model2 loss : 0.028022
[23:42:30.441] iteration 14845 : model1 loss : 0.017830 model2 loss : 0.020122
[23:42:31.112] iteration 14846 : model1 loss : 0.030876 model2 loss : 0.032396
[23:42:31.776] iteration 14847 : model1 loss : 0.013925 model2 loss : 0.014244
[23:42:32.463] iteration 14848 : model1 loss : 0.021479 model2 loss : 0.025473
[23:42:33.126] iteration 14849 : model1 loss : 0.020760 model2 loss : 0.019337
[23:42:33.793] iteration 14850 : model1 loss : 0.024246 model2 loss : 0.024058
[23:42:34.504] iteration 14851 : model1 loss : 0.022410 model2 loss : 0.028549
[23:42:35.169] iteration 14852 : model1 loss : 0.025482 model2 loss : 0.027482
[23:42:35.844] iteration 14853 : model1 loss : 0.020074 model2 loss : 0.020145
[23:42:36.510] iteration 14854 : model1 loss : 0.021482 model2 loss : 0.022182
[23:42:37.194] iteration 14855 : model1 loss : 0.031493 model2 loss : 0.033378
[23:42:37.874] iteration 14856 : model1 loss : 0.024987 model2 loss : 0.021702
[23:42:38.542] iteration 14857 : model1 loss : 0.017084 model2 loss : 0.018376
[23:42:39.216] iteration 14858 : model1 loss : 0.020510 model2 loss : 0.019932
[23:42:39.900] iteration 14859 : model1 loss : 0.024820 model2 loss : 0.037913
[23:42:40.576] iteration 14860 : model1 loss : 0.046129 model2 loss : 0.046979
[23:42:41.245] iteration 14861 : model1 loss : 0.033584 model2 loss : 0.025721
[23:42:41.915] iteration 14862 : model1 loss : 0.017915 model2 loss : 0.020342
[23:42:42.587] iteration 14863 : model1 loss : 0.029798 model2 loss : 0.027840
[23:42:43.264] iteration 14864 : model1 loss : 0.018812 model2 loss : 0.019386
[23:42:43.931] iteration 14865 : model1 loss : 0.022489 model2 loss : 0.024311
[23:42:44.599] iteration 14866 : model1 loss : 0.021655 model2 loss : 0.021234
[23:42:45.271] iteration 14867 : model1 loss : 0.030587 model2 loss : 0.025072
[23:42:45.933] iteration 14868 : model1 loss : 0.019316 model2 loss : 0.020068
[23:42:46.600] iteration 14869 : model1 loss : 0.021817 model2 loss : 0.022403
[23:42:47.273] iteration 14870 : model1 loss : 0.021171 model2 loss : 0.020453
[23:42:47.958] iteration 14871 : model1 loss : 0.024037 model2 loss : 0.024181
[23:42:48.630] iteration 14872 : model1 loss : 0.026200 model2 loss : 0.025614
[23:42:49.303] iteration 14873 : model1 loss : 0.018932 model2 loss : 0.020618
[23:42:49.979] iteration 14874 : model1 loss : 0.019927 model2 loss : 0.020954
[23:42:50.650] iteration 14875 : model1 loss : 0.018901 model2 loss : 0.020245
[23:42:51.334] iteration 14876 : model1 loss : 0.021007 model2 loss : 0.021697
[23:42:52.001] iteration 14877 : model1 loss : 0.085169 model2 loss : 0.066885
[23:42:52.676] iteration 14878 : model1 loss : 0.018510 model2 loss : 0.020467
[23:42:53.354] iteration 14879 : model1 loss : 0.018699 model2 loss : 0.020224
[23:42:54.019] iteration 14880 : model1 loss : 0.019457 model2 loss : 0.022907
[23:42:54.691] iteration 14881 : model1 loss : 0.023312 model2 loss : 0.024191
[23:42:55.370] iteration 14882 : model1 loss : 0.038224 model2 loss : 0.038142
[23:42:56.039] iteration 14883 : model1 loss : 0.020509 model2 loss : 0.022130
[23:42:56.708] iteration 14884 : model1 loss : 0.018389 model2 loss : 0.019573
[23:42:57.365] iteration 14885 : model1 loss : 0.021932 model2 loss : 0.028431
[23:42:58.023] iteration 14886 : model1 loss : 0.059374 model2 loss : 0.062053
[23:42:58.693] iteration 14887 : model1 loss : 0.023239 model2 loss : 0.024411
[23:42:59.364] iteration 14888 : model1 loss : 0.019384 model2 loss : 0.019541
[23:43:00.033] iteration 14889 : model1 loss : 0.023036 model2 loss : 0.020427
[23:43:00.694] iteration 14890 : model1 loss : 0.024355 model2 loss : 0.023991
[23:43:01.359] iteration 14891 : model1 loss : 0.022360 model2 loss : 0.019654
[23:43:02.022] iteration 14892 : model1 loss : 0.024492 model2 loss : 0.024866
[23:43:02.690] iteration 14893 : model1 loss : 0.019887 model2 loss : 0.019589
[23:43:03.368] iteration 14894 : model1 loss : 0.024048 model2 loss : 0.024485
[23:43:04.027] iteration 14895 : model1 loss : 0.026416 model2 loss : 0.026891
[23:43:04.694] iteration 14896 : model1 loss : 0.020417 model2 loss : 0.018288
[23:43:05.370] iteration 14897 : model1 loss : 0.017623 model2 loss : 0.019429
[23:43:06.030] iteration 14898 : model1 loss : 0.020315 model2 loss : 0.024559
[23:43:06.694] iteration 14899 : model1 loss : 0.016568 model2 loss : 0.018746
[23:43:07.381] iteration 14900 : model1 loss : 0.026390 model2 loss : 0.023027
[23:43:08.089] iteration 14901 : model1 loss : 0.030000 model2 loss : 0.030554
[23:43:08.762] iteration 14902 : model1 loss : 0.022833 model2 loss : 0.027788
[23:43:09.435] iteration 14903 : model1 loss : 0.028287 model2 loss : 0.037257
[23:43:10.087] iteration 14904 : model1 loss : 0.020086 model2 loss : 0.022485
[23:43:10.762] iteration 14905 : model1 loss : 0.025902 model2 loss : 0.024191
[23:43:11.434] iteration 14906 : model1 loss : 0.023469 model2 loss : 0.023561
[23:43:12.106] iteration 14907 : model1 loss : 0.022201 model2 loss : 0.024111
[23:43:12.769] iteration 14908 : model1 loss : 0.023395 model2 loss : 0.020935
[23:43:13.442] iteration 14909 : model1 loss : 0.019284 model2 loss : 0.019201
[23:43:14.104] iteration 14910 : model1 loss : 0.026721 model2 loss : 0.023007
[23:43:14.773] iteration 14911 : model1 loss : 0.027411 model2 loss : 0.028008
[23:43:15.455] iteration 14912 : model1 loss : 0.024831 model2 loss : 0.027218
[23:43:16.120] iteration 14913 : model1 loss : 0.020429 model2 loss : 0.021756
[23:43:16.794] iteration 14914 : model1 loss : 0.020631 model2 loss : 0.023197
[23:43:17.463] iteration 14915 : model1 loss : 0.026527 model2 loss : 0.027115
[23:43:18.119] iteration 14916 : model1 loss : 0.024634 model2 loss : 0.025844
[23:43:18.793] iteration 14917 : model1 loss : 0.022160 model2 loss : 0.021210
[23:43:19.461] iteration 14918 : model1 loss : 0.044782 model2 loss : 0.039345
[23:43:20.120] iteration 14919 : model1 loss : 0.023843 model2 loss : 0.024696
[23:43:20.788] iteration 14920 : model1 loss : 0.018529 model2 loss : 0.019566
[23:43:21.456] iteration 14921 : model1 loss : 0.022254 model2 loss : 0.020801
[23:43:22.124] iteration 14922 : model1 loss : 0.014539 model2 loss : 0.015730
[23:43:22.799] iteration 14923 : model1 loss : 0.017576 model2 loss : 0.017911
[23:43:23.467] iteration 14924 : model1 loss : 0.019820 model2 loss : 0.022642
[23:43:24.139] iteration 14925 : model1 loss : 0.018639 model2 loss : 0.019886
[23:43:24.802] iteration 14926 : model1 loss : 0.033883 model2 loss : 0.033481
[23:43:25.461] iteration 14927 : model1 loss : 0.018795 model2 loss : 0.019185
[23:43:26.130] iteration 14928 : model1 loss : 0.029962 model2 loss : 0.026723
[23:43:26.802] iteration 14929 : model1 loss : 0.022565 model2 loss : 0.020828
[23:43:27.466] iteration 14930 : model1 loss : 0.019943 model2 loss : 0.018702
[23:43:28.133] iteration 14931 : model1 loss : 0.021831 model2 loss : 0.016023
[23:43:28.802] iteration 14932 : model1 loss : 0.020004 model2 loss : 0.019427
[23:43:29.476] iteration 14933 : model1 loss : 0.020371 model2 loss : 0.021951
[23:43:30.142] iteration 14934 : model1 loss : 0.024063 model2 loss : 0.023689
[23:43:30.826] iteration 14935 : model1 loss : 0.025187 model2 loss : 0.025206
[23:43:31.495] iteration 14936 : model1 loss : 0.020248 model2 loss : 0.019549
[23:43:32.165] iteration 14937 : model1 loss : 0.020634 model2 loss : 0.020911
[23:43:32.838] iteration 14938 : model1 loss : 0.020457 model2 loss : 0.025629
[23:43:33.508] iteration 14939 : model1 loss : 0.019205 model2 loss : 0.018747
[23:43:34.178] iteration 14940 : model1 loss : 0.022444 model2 loss : 0.025722
[23:43:34.841] iteration 14941 : model1 loss : 0.019458 model2 loss : 0.019688
[23:43:35.503] iteration 14942 : model1 loss : 0.025178 model2 loss : 0.024387
[23:43:36.174] iteration 14943 : model1 loss : 0.016410 model2 loss : 0.018801
[23:43:36.851] iteration 14944 : model1 loss : 0.024600 model2 loss : 0.024939
[23:43:37.526] iteration 14945 : model1 loss : 0.018819 model2 loss : 0.018555
[23:43:38.191] iteration 14946 : model1 loss : 0.025400 model2 loss : 0.024528
[23:43:38.864] iteration 14947 : model1 loss : 0.022953 model2 loss : 0.023575
[23:43:39.531] iteration 14948 : model1 loss : 0.026816 model2 loss : 0.023496
[23:43:40.200] iteration 14949 : model1 loss : 0.050655 model2 loss : 0.022146
[23:43:40.897] iteration 14950 : model1 loss : 0.020958 model2 loss : 0.023634
[23:43:41.614] iteration 14951 : model1 loss : 0.020628 model2 loss : 0.021023
[23:43:42.286] iteration 14952 : model1 loss : 0.021855 model2 loss : 0.020701
[23:43:42.954] iteration 14953 : model1 loss : 0.025294 model2 loss : 0.027138
[23:43:43.616] iteration 14954 : model1 loss : 0.030192 model2 loss : 0.032490
[23:43:44.286] iteration 14955 : model1 loss : 0.023577 model2 loss : 0.023513
[23:43:44.955] iteration 14956 : model1 loss : 0.019496 model2 loss : 0.021130
[23:43:45.634] iteration 14957 : model1 loss : 0.023467 model2 loss : 0.022906
[23:43:46.299] iteration 14958 : model1 loss : 0.024085 model2 loss : 0.018331
[23:43:46.982] iteration 14959 : model1 loss : 0.021834 model2 loss : 0.022840
[23:43:47.664] iteration 14960 : model1 loss : 0.020606 model2 loss : 0.019094
[23:43:48.336] iteration 14961 : model1 loss : 0.019578 model2 loss : 0.022469
[23:43:49.000] iteration 14962 : model1 loss : 0.026702 model2 loss : 0.026615
[23:43:49.678] iteration 14963 : model1 loss : 0.016348 model2 loss : 0.019003
[23:43:50.347] iteration 14964 : model1 loss : 0.028670 model2 loss : 0.029621
[23:43:51.009] iteration 14965 : model1 loss : 0.022678 model2 loss : 0.023173
[23:43:51.677] iteration 14966 : model1 loss : 0.024236 model2 loss : 0.025351
[23:43:52.348] iteration 14967 : model1 loss : 0.023105 model2 loss : 0.022259
[23:43:53.024] iteration 14968 : model1 loss : 0.027970 model2 loss : 0.021725
[23:43:53.682] iteration 14969 : model1 loss : 0.020619 model2 loss : 0.024140
[23:43:54.363] iteration 14970 : model1 loss : 0.016456 model2 loss : 0.018209
[23:43:55.041] iteration 14971 : model1 loss : 0.033213 model2 loss : 0.028211
[23:43:55.720] iteration 14972 : model1 loss : 0.027861 model2 loss : 0.025673
[23:43:56.394] iteration 14973 : model1 loss : 0.017906 model2 loss : 0.017966
[23:43:57.067] iteration 14974 : model1 loss : 0.017284 model2 loss : 0.017313
[23:43:57.735] iteration 14975 : model1 loss : 0.017100 model2 loss : 0.017559
[23:43:58.399] iteration 14976 : model1 loss : 0.016220 model2 loss : 0.018719
[23:43:59.065] iteration 14977 : model1 loss : 0.022640 model2 loss : 0.024787
[23:43:59.731] iteration 14978 : model1 loss : 0.017735 model2 loss : 0.017244
[23:44:00.404] iteration 14979 : model1 loss : 0.031155 model2 loss : 0.030358
[23:44:01.066] iteration 14980 : model1 loss : 0.023693 model2 loss : 0.021165
[23:44:01.737] iteration 14981 : model1 loss : 0.023085 model2 loss : 0.024775
[23:44:02.404] iteration 14982 : model1 loss : 0.019506 model2 loss : 0.017891
[23:44:03.069] iteration 14983 : model1 loss : 0.025123 model2 loss : 0.024687
[23:44:03.742] iteration 14984 : model1 loss : 0.030731 model2 loss : 0.031300
[23:44:04.410] iteration 14985 : model1 loss : 0.034590 model2 loss : 0.040937
[23:44:05.080] iteration 14986 : model1 loss : 0.020509 model2 loss : 0.019648
[23:44:05.745] iteration 14987 : model1 loss : 0.022509 model2 loss : 0.021666
[23:44:06.418] iteration 14988 : model1 loss : 0.021005 model2 loss : 0.021313
[23:44:07.088] iteration 14989 : model1 loss : 0.017604 model2 loss : 0.017785
[23:44:07.754] iteration 14990 : model1 loss : 0.024502 model2 loss : 0.025029
[23:44:08.429] iteration 14991 : model1 loss : 0.016691 model2 loss : 0.017762
[23:44:09.098] iteration 14992 : model1 loss : 0.018483 model2 loss : 0.018410
[23:44:09.758] iteration 14993 : model1 loss : 0.020171 model2 loss : 0.022585
[23:44:10.437] iteration 14994 : model1 loss : 0.025432 model2 loss : 0.029087
[23:44:11.101] iteration 14995 : model1 loss : 0.012013 model2 loss : 0.013200
[23:44:11.760] iteration 14996 : model1 loss : 0.025684 model2 loss : 0.026035
[23:44:12.429] iteration 14997 : model1 loss : 0.019694 model2 loss : 0.021524
[23:44:13.106] iteration 14998 : model1 loss : 0.021535 model2 loss : 0.022497
[23:44:13.782] iteration 14999 : model1 loss : 0.034015 model2 loss : 0.031323
[23:44:14.449] iteration 15000 : model1 loss : 0.020598 model2 loss : 0.021737
[23:44:32.882] iteration 15000 : model1_mean_dice : 0.871537 model1_mean_hd95 : 6.276119
[23:44:51.464] iteration 15000 : model2_mean_dice : 0.869981 model2_mean_hd95 : 4.677011
[23:44:51.525] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_15000.pth
[23:44:51.587] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_15000.pth
[23:44:52.287] iteration 15001 : model1 loss : 0.059102 model2 loss : 0.059778
[23:44:52.951] iteration 15002 : model1 loss : 0.026252 model2 loss : 0.029330
[23:44:53.623] iteration 15003 : model1 loss : 0.022745 model2 loss : 0.020901
[23:44:54.271] iteration 15004 : model1 loss : 0.020210 model2 loss : 0.020762
[23:44:54.939] iteration 15005 : model1 loss : 0.025081 model2 loss : 0.024630
[23:44:55.592] iteration 15006 : model1 loss : 0.019187 model2 loss : 0.018480
[23:44:56.257] iteration 15007 : model1 loss : 0.019568 model2 loss : 0.020086
[23:44:56.928] iteration 15008 : model1 loss : 0.025275 model2 loss : 0.027647
[23:44:57.596] iteration 15009 : model1 loss : 0.023992 model2 loss : 0.024131
[23:44:58.272] iteration 15010 : model1 loss : 0.025227 model2 loss : 0.025916
[23:44:58.930] iteration 15011 : model1 loss : 0.017964 model2 loss : 0.017985
[23:44:59.595] iteration 15012 : model1 loss : 0.022596 model2 loss : 0.022111
[23:45:00.248] iteration 15013 : model1 loss : 0.030184 model2 loss : 0.023890
[23:45:00.914] iteration 15014 : model1 loss : 0.024695 model2 loss : 0.024277
[23:45:01.581] iteration 15015 : model1 loss : 0.032541 model2 loss : 0.035438
[23:45:02.245] iteration 15016 : model1 loss : 0.018289 model2 loss : 0.019213
[23:45:02.911] iteration 15017 : model1 loss : 0.018973 model2 loss : 0.018125
[23:45:03.575] iteration 15018 : model1 loss : 0.022789 model2 loss : 0.021283
[23:45:04.238] iteration 15019 : model1 loss : 0.023867 model2 loss : 0.022758
[23:45:04.908] iteration 15020 : model1 loss : 0.021122 model2 loss : 0.017941
[23:45:05.570] iteration 15021 : model1 loss : 0.139612 model2 loss : 0.138720
[23:45:06.227] iteration 15022 : model1 loss : 0.021042 model2 loss : 0.020841
[23:45:06.894] iteration 15023 : model1 loss : 0.015162 model2 loss : 0.015985
[23:45:07.561] iteration 15024 : model1 loss : 0.021851 model2 loss : 0.017155
[23:45:08.226] iteration 15025 : model1 loss : 0.021466 model2 loss : 0.019403
[23:45:08.894] iteration 15026 : model1 loss : 0.026414 model2 loss : 0.023867
[23:45:09.543] iteration 15027 : model1 loss : 0.022923 model2 loss : 0.022654
[23:45:10.217] iteration 15028 : model1 loss : 0.031063 model2 loss : 0.031997
[23:45:10.885] iteration 15029 : model1 loss : 0.021039 model2 loss : 0.021636
[23:45:11.556] iteration 15030 : model1 loss : 0.014557 model2 loss : 0.015928
[23:45:12.224] iteration 15031 : model1 loss : 0.021298 model2 loss : 0.021804
[23:45:12.899] iteration 15032 : model1 loss : 0.031005 model2 loss : 0.029998
[23:45:13.562] iteration 15033 : model1 loss : 0.028823 model2 loss : 0.031689
[23:45:14.228] iteration 15034 : model1 loss : 0.029508 model2 loss : 0.034064
[23:45:14.901] iteration 15035 : model1 loss : 0.023811 model2 loss : 0.021176
[23:45:15.615] iteration 15036 : model1 loss : 0.020144 model2 loss : 0.021416
[23:45:16.294] iteration 15037 : model1 loss : 0.029057 model2 loss : 0.029327
[23:45:16.952] iteration 15038 : model1 loss : 0.020778 model2 loss : 0.023736
[23:45:17.612] iteration 15039 : model1 loss : 0.017600 model2 loss : 0.019626
[23:45:18.287] iteration 15040 : model1 loss : 0.019078 model2 loss : 0.018598
[23:45:18.958] iteration 15041 : model1 loss : 0.019618 model2 loss : 0.016633
[23:45:19.631] iteration 15042 : model1 loss : 0.024047 model2 loss : 0.021840
[23:45:20.304] iteration 15043 : model1 loss : 0.047869 model2 loss : 0.051099
[23:45:20.973] iteration 15044 : model1 loss : 0.020253 model2 loss : 0.019830
[23:45:21.649] iteration 15045 : model1 loss : 0.021771 model2 loss : 0.022616
[23:45:22.319] iteration 15046 : model1 loss : 0.020083 model2 loss : 0.019638
[23:45:22.980] iteration 15047 : model1 loss : 0.023975 model2 loss : 0.024520
[23:45:23.659] iteration 15048 : model1 loss : 0.023833 model2 loss : 0.019017
[23:45:24.328] iteration 15049 : model1 loss : 0.015865 model2 loss : 0.016878
[23:45:25.002] iteration 15050 : model1 loss : 0.019016 model2 loss : 0.019213
[23:45:25.705] iteration 15051 : model1 loss : 0.018522 model2 loss : 0.019388
[23:45:26.368] iteration 15052 : model1 loss : 0.026610 model2 loss : 0.022875
[23:45:27.036] iteration 15053 : model1 loss : 0.070012 model2 loss : 0.087600
[23:45:27.693] iteration 15054 : model1 loss : 0.020461 model2 loss : 0.019936
[23:45:28.355] iteration 15055 : model1 loss : 0.023526 model2 loss : 0.019401
[23:45:29.014] iteration 15056 : model1 loss : 0.018416 model2 loss : 0.018560
[23:45:29.679] iteration 15057 : model1 loss : 0.013687 model2 loss : 0.014708
[23:45:30.373] iteration 15058 : model1 loss : 0.026438 model2 loss : 0.025207
[23:45:31.068] iteration 15059 : model1 loss : 0.021244 model2 loss : 0.019441
[23:45:31.742] iteration 15060 : model1 loss : 0.024647 model2 loss : 0.023993
[23:45:32.416] iteration 15061 : model1 loss : 0.029476 model2 loss : 0.034822
[23:45:33.081] iteration 15062 : model1 loss : 0.035869 model2 loss : 0.036763
[23:45:33.747] iteration 15063 : model1 loss : 0.020426 model2 loss : 0.021070
[23:45:34.412] iteration 15064 : model1 loss : 0.018766 model2 loss : 0.020258
[23:45:35.083] iteration 15065 : model1 loss : 0.026273 model2 loss : 0.025737
[23:45:35.752] iteration 15066 : model1 loss : 0.025145 model2 loss : 0.026457
[23:45:36.441] iteration 15067 : model1 loss : 0.019610 model2 loss : 0.020100
[23:45:37.109] iteration 15068 : model1 loss : 0.023280 model2 loss : 0.022200
[23:45:37.800] iteration 15069 : model1 loss : 0.022646 model2 loss : 0.024663
[23:45:38.475] iteration 15070 : model1 loss : 0.020789 model2 loss : 0.021980
[23:45:39.140] iteration 15071 : model1 loss : 0.023283 model2 loss : 0.021241
[23:45:39.799] iteration 15072 : model1 loss : 0.021571 model2 loss : 0.021742
[23:45:40.469] iteration 15073 : model1 loss : 0.024856 model2 loss : 0.025854
[23:45:41.143] iteration 15074 : model1 loss : 0.031548 model2 loss : 0.034763
[23:45:41.835] iteration 15075 : model1 loss : 0.026803 model2 loss : 0.027035
[23:45:42.524] iteration 15076 : model1 loss : 0.025656 model2 loss : 0.024809
[23:45:43.196] iteration 15077 : model1 loss : 0.021970 model2 loss : 0.020023
[23:45:43.859] iteration 15078 : model1 loss : 0.026229 model2 loss : 0.029580
[23:45:44.535] iteration 15079 : model1 loss : 0.020446 model2 loss : 0.020160
[23:45:45.203] iteration 15080 : model1 loss : 0.023036 model2 loss : 0.020501
[23:45:45.868] iteration 15081 : model1 loss : 0.020458 model2 loss : 0.022700
[23:45:46.543] iteration 15082 : model1 loss : 0.019380 model2 loss : 0.020198
[23:45:47.206] iteration 15083 : model1 loss : 0.032169 model2 loss : 0.034102
[23:45:47.870] iteration 15084 : model1 loss : 0.021322 model2 loss : 0.020518
[23:45:48.538] iteration 15085 : model1 loss : 0.019078 model2 loss : 0.021410
[23:45:49.212] iteration 15086 : model1 loss : 0.017892 model2 loss : 0.018499
[23:45:49.882] iteration 15087 : model1 loss : 0.024801 model2 loss : 0.023668
[23:45:50.554] iteration 15088 : model1 loss : 0.019834 model2 loss : 0.020332
[23:45:51.222] iteration 15089 : model1 loss : 0.025453 model2 loss : 0.029653
[23:45:51.889] iteration 15090 : model1 loss : 0.021639 model2 loss : 0.022174
[23:45:52.567] iteration 15091 : model1 loss : 0.020036 model2 loss : 0.017502
[23:45:53.234] iteration 15092 : model1 loss : 0.026412 model2 loss : 0.027520
[23:45:53.898] iteration 15093 : model1 loss : 0.022191 model2 loss : 0.021172
[23:45:54.566] iteration 15094 : model1 loss : 0.027268 model2 loss : 0.031080
[23:45:55.235] iteration 15095 : model1 loss : 0.018301 model2 loss : 0.019453
[23:45:55.914] iteration 15096 : model1 loss : 0.018566 model2 loss : 0.018476
[23:45:56.580] iteration 15097 : model1 loss : 0.020769 model2 loss : 0.027636
[23:45:57.255] iteration 15098 : model1 loss : 0.021766 model2 loss : 0.021457
[23:45:57.915] iteration 15099 : model1 loss : 0.020083 model2 loss : 0.021403
[23:45:58.582] iteration 15100 : model1 loss : 0.017310 model2 loss : 0.019027
[23:45:59.302] iteration 15101 : model1 loss : 0.024578 model2 loss : 0.022982
[23:45:59.973] iteration 15102 : model1 loss : 0.037658 model2 loss : 0.037462
[23:46:00.635] iteration 15103 : model1 loss : 0.029418 model2 loss : 0.032973
[23:46:01.320] iteration 15104 : model1 loss : 0.022796 model2 loss : 0.020414
[23:46:01.996] iteration 15105 : model1 loss : 0.017233 model2 loss : 0.019333
[23:46:02.669] iteration 15106 : model1 loss : 0.141151 model2 loss : 0.141535
[23:46:03.358] iteration 15107 : model1 loss : 0.027810 model2 loss : 0.026172
[23:46:04.022] iteration 15108 : model1 loss : 0.022778 model2 loss : 0.028492
[23:46:04.696] iteration 15109 : model1 loss : 0.033387 model2 loss : 0.019851
[23:46:05.374] iteration 15110 : model1 loss : 0.020791 model2 loss : 0.020919
[23:46:06.040] iteration 15111 : model1 loss : 0.032484 model2 loss : 0.031893
[23:46:06.703] iteration 15112 : model1 loss : 0.021775 model2 loss : 0.021465
[23:46:07.364] iteration 15113 : model1 loss : 0.022132 model2 loss : 0.022475
[23:46:08.046] iteration 15114 : model1 loss : 0.019392 model2 loss : 0.020712
[23:46:08.710] iteration 15115 : model1 loss : 0.020288 model2 loss : 0.020439
[23:46:09.371] iteration 15116 : model1 loss : 0.024615 model2 loss : 0.029949
[23:46:10.036] iteration 15117 : model1 loss : 0.028160 model2 loss : 0.024136
[23:46:10.709] iteration 15118 : model1 loss : 0.016951 model2 loss : 0.017824
[23:46:11.382] iteration 15119 : model1 loss : 0.026694 model2 loss : 0.028243
[23:46:12.046] iteration 15120 : model1 loss : 0.026698 model2 loss : 0.026751
[23:46:12.707] iteration 15121 : model1 loss : 0.028605 model2 loss : 0.026130
[23:46:13.379] iteration 15122 : model1 loss : 0.024438 model2 loss : 0.021789
[23:46:14.040] iteration 15123 : model1 loss : 0.019691 model2 loss : 0.017865
[23:46:14.699] iteration 15124 : model1 loss : 0.022430 model2 loss : 0.022048
[23:46:15.367] iteration 15125 : model1 loss : 0.019422 model2 loss : 0.019028
[23:46:16.031] iteration 15126 : model1 loss : 0.029491 model2 loss : 0.026323
[23:46:16.696] iteration 15127 : model1 loss : 0.020458 model2 loss : 0.018398
[23:46:17.359] iteration 15128 : model1 loss : 0.022532 model2 loss : 0.021135
[23:46:18.024] iteration 15129 : model1 loss : 0.019838 model2 loss : 0.021833
[23:46:18.700] iteration 15130 : model1 loss : 0.028962 model2 loss : 0.021250
[23:46:19.398] iteration 15131 : model1 loss : 0.016897 model2 loss : 0.017604
[23:46:20.077] iteration 15132 : model1 loss : 0.018681 model2 loss : 0.018087
[23:46:20.747] iteration 15133 : model1 loss : 0.025528 model2 loss : 0.025479
[23:46:21.419] iteration 15134 : model1 loss : 0.021747 model2 loss : 0.020554
[23:46:22.091] iteration 15135 : model1 loss : 0.030727 model2 loss : 0.036325
[23:46:22.769] iteration 15136 : model1 loss : 0.017911 model2 loss : 0.018614
[23:46:23.428] iteration 15137 : model1 loss : 0.016389 model2 loss : 0.015988
[23:46:24.096] iteration 15138 : model1 loss : 0.016746 model2 loss : 0.017919
[23:46:24.759] iteration 15139 : model1 loss : 0.018297 model2 loss : 0.019621
[23:46:25.430] iteration 15140 : model1 loss : 0.020236 model2 loss : 0.021358
[23:46:26.098] iteration 15141 : model1 loss : 0.019755 model2 loss : 0.018281
[23:46:26.769] iteration 15142 : model1 loss : 0.022094 model2 loss : 0.021024
[23:46:27.433] iteration 15143 : model1 loss : 0.023250 model2 loss : 0.018712
[23:46:28.093] iteration 15144 : model1 loss : 0.029607 model2 loss : 0.026548
[23:46:28.764] iteration 15145 : model1 loss : 0.027580 model2 loss : 0.027716
[23:46:29.454] iteration 15146 : model1 loss : 0.018954 model2 loss : 0.019533
[23:46:30.134] iteration 15147 : model1 loss : 0.023729 model2 loss : 0.024305
[23:46:30.799] iteration 15148 : model1 loss : 0.025951 model2 loss : 0.023253
[23:46:31.470] iteration 15149 : model1 loss : 0.022615 model2 loss : 0.020604
[23:46:32.147] iteration 15150 : model1 loss : 0.023228 model2 loss : 0.023248
[23:46:32.858] iteration 15151 : model1 loss : 0.027376 model2 loss : 0.024524
[23:46:33.523] iteration 15152 : model1 loss : 0.023505 model2 loss : 0.024373
[23:46:34.189] iteration 15153 : model1 loss : 0.018240 model2 loss : 0.019157
[23:46:34.845] iteration 15154 : model1 loss : 0.024987 model2 loss : 0.025382
[23:46:35.521] iteration 15155 : model1 loss : 0.015390 model2 loss : 0.017586
[23:46:36.189] iteration 15156 : model1 loss : 0.026985 model2 loss : 0.028939
[23:46:36.863] iteration 15157 : model1 loss : 0.027850 model2 loss : 0.026654
[23:46:37.520] iteration 15158 : model1 loss : 0.019021 model2 loss : 0.019023
[23:46:38.193] iteration 15159 : model1 loss : 0.023626 model2 loss : 0.023464
[23:46:38.855] iteration 15160 : model1 loss : 0.054921 model2 loss : 0.029363
[23:46:39.525] iteration 15161 : model1 loss : 0.031169 model2 loss : 0.026067
[23:46:40.189] iteration 15162 : model1 loss : 0.026762 model2 loss : 0.023723
[23:46:40.856] iteration 15163 : model1 loss : 0.023852 model2 loss : 0.023963
[23:46:41.517] iteration 15164 : model1 loss : 0.034560 model2 loss : 0.029934
[23:46:42.214] iteration 15165 : model1 loss : 0.018138 model2 loss : 0.019512
[23:46:42.902] iteration 15166 : model1 loss : 0.022323 model2 loss : 0.024551
[23:46:43.566] iteration 15167 : model1 loss : 0.019906 model2 loss : 0.018152
[23:46:44.233] iteration 15168 : model1 loss : 0.038378 model2 loss : 0.035718
[23:46:44.886] iteration 15169 : model1 loss : 0.029757 model2 loss : 0.030669
[23:46:45.555] iteration 15170 : model1 loss : 0.021153 model2 loss : 0.022341
[23:46:46.221] iteration 15171 : model1 loss : 0.021835 model2 loss : 0.023137
[23:46:46.892] iteration 15172 : model1 loss : 0.022549 model2 loss : 0.021869
[23:46:47.562] iteration 15173 : model1 loss : 0.035035 model2 loss : 0.030358
[23:46:48.239] iteration 15174 : model1 loss : 0.026502 model2 loss : 0.022069
[23:46:48.911] iteration 15175 : model1 loss : 0.031016 model2 loss : 0.025655
[23:46:49.572] iteration 15176 : model1 loss : 0.021011 model2 loss : 0.023996
[23:46:50.229] iteration 15177 : model1 loss : 0.030139 model2 loss : 0.026820
[23:46:50.904] iteration 15178 : model1 loss : 0.030087 model2 loss : 0.027689
[23:46:51.584] iteration 15179 : model1 loss : 0.020192 model2 loss : 0.021355
[23:46:52.261] iteration 15180 : model1 loss : 0.035741 model2 loss : 0.033421
[23:46:52.942] iteration 15181 : model1 loss : 0.022208 model2 loss : 0.024519
[23:46:53.603] iteration 15182 : model1 loss : 0.019500 model2 loss : 0.019043
[23:46:54.286] iteration 15183 : model1 loss : 0.027849 model2 loss : 0.022237
[23:46:54.960] iteration 15184 : model1 loss : 0.017671 model2 loss : 0.020227
[23:46:55.625] iteration 15185 : model1 loss : 0.021969 model2 loss : 0.020460
[23:46:56.291] iteration 15186 : model1 loss : 0.023072 model2 loss : 0.023698
[23:46:56.960] iteration 15187 : model1 loss : 0.018835 model2 loss : 0.019497
[23:46:57.649] iteration 15188 : model1 loss : 0.014809 model2 loss : 0.015710
[23:46:58.320] iteration 15189 : model1 loss : 0.022276 model2 loss : 0.023090
[23:46:58.989] iteration 15190 : model1 loss : 0.022327 model2 loss : 0.024501
[23:46:59.658] iteration 15191 : model1 loss : 0.023158 model2 loss : 0.022283
[23:47:00.328] iteration 15192 : model1 loss : 0.020957 model2 loss : 0.020744
[23:47:01.011] iteration 15193 : model1 loss : 0.021385 model2 loss : 0.022567
[23:47:01.679] iteration 15194 : model1 loss : 0.019704 model2 loss : 0.016162
[23:47:02.347] iteration 15195 : model1 loss : 0.032871 model2 loss : 0.028195
[23:47:03.012] iteration 15196 : model1 loss : 0.018089 model2 loss : 0.018566
[23:47:03.676] iteration 15197 : model1 loss : 0.018758 model2 loss : 0.017132
[23:47:04.356] iteration 15198 : model1 loss : 0.023721 model2 loss : 0.020812
[23:47:05.009] iteration 15199 : model1 loss : 0.137499 model2 loss : 0.137543
[23:47:05.676] iteration 15200 : model1 loss : 0.022696 model2 loss : 0.024672
[23:47:23.926] iteration 15200 : model1_mean_dice : 0.868334 model1_mean_hd95 : 6.128111
[23:47:42.048] iteration 15200 : model2_mean_dice : 0.875349 model2_mean_hd95 : 6.196737
[23:47:42.786] iteration 15201 : model1 loss : 0.028665 model2 loss : 0.035358
[23:47:43.444] iteration 15202 : model1 loss : 0.023828 model2 loss : 0.025506
[23:47:44.101] iteration 15203 : model1 loss : 0.019739 model2 loss : 0.020935
[23:47:44.757] iteration 15204 : model1 loss : 0.010963 model2 loss : 0.013149
[23:47:45.431] iteration 15205 : model1 loss : 0.025373 model2 loss : 0.023564
[23:47:46.103] iteration 15206 : model1 loss : 0.017226 model2 loss : 0.015915
[23:47:46.769] iteration 15207 : model1 loss : 0.050696 model2 loss : 0.049394
[23:47:47.432] iteration 15208 : model1 loss : 0.030993 model2 loss : 0.034994
[23:47:48.110] iteration 15209 : model1 loss : 0.031763 model2 loss : 0.037708
[23:47:48.770] iteration 15210 : model1 loss : 0.029104 model2 loss : 0.046163
[23:47:49.431] iteration 15211 : model1 loss : 0.024289 model2 loss : 0.026702
[23:47:50.087] iteration 15212 : model1 loss : 0.018677 model2 loss : 0.019435
[23:47:50.749] iteration 15213 : model1 loss : 0.019686 model2 loss : 0.017838
[23:47:51.413] iteration 15214 : model1 loss : 0.023739 model2 loss : 0.025264
[23:47:52.070] iteration 15215 : model1 loss : 0.015787 model2 loss : 0.015894
[23:47:52.742] iteration 15216 : model1 loss : 0.028165 model2 loss : 0.026688
[23:47:53.416] iteration 15217 : model1 loss : 0.022751 model2 loss : 0.024823
[23:47:54.071] iteration 15218 : model1 loss : 0.020061 model2 loss : 0.019634
[23:47:54.735] iteration 15219 : model1 loss : 0.032490 model2 loss : 0.046515
[23:47:55.396] iteration 15220 : model1 loss : 0.020203 model2 loss : 0.021242
[23:47:56.054] iteration 15221 : model1 loss : 0.022048 model2 loss : 0.021699
[23:47:56.725] iteration 15222 : model1 loss : 0.027457 model2 loss : 0.034207
[23:47:57.402] iteration 15223 : model1 loss : 0.023997 model2 loss : 0.024513
[23:47:58.054] iteration 15224 : model1 loss : 0.019028 model2 loss : 0.021866
[23:47:58.717] iteration 15225 : model1 loss : 0.021189 model2 loss : 0.025495
[23:47:59.378] iteration 15226 : model1 loss : 0.022425 model2 loss : 0.026356
[23:48:00.031] iteration 15227 : model1 loss : 0.022868 model2 loss : 0.021144
[23:48:00.687] iteration 15228 : model1 loss : 0.020657 model2 loss : 0.020571
[23:48:01.364] iteration 15229 : model1 loss : 0.023592 model2 loss : 0.022944
[23:48:02.019] iteration 15230 : model1 loss : 0.017951 model2 loss : 0.019434
[23:48:02.699] iteration 15231 : model1 loss : 0.021842 model2 loss : 0.023837
[23:48:03.354] iteration 15232 : model1 loss : 0.015042 model2 loss : 0.016934
[23:48:04.019] iteration 15233 : model1 loss : 0.016463 model2 loss : 0.016644
[23:48:04.677] iteration 15234 : model1 loss : 0.021109 model2 loss : 0.021574
[23:48:05.352] iteration 15235 : model1 loss : 0.023322 model2 loss : 0.030094
[23:48:06.010] iteration 15236 : model1 loss : 0.022264 model2 loss : 0.023355
[23:48:06.678] iteration 15237 : model1 loss : 0.025382 model2 loss : 0.026056
[23:48:07.362] iteration 15238 : model1 loss : 0.025605 model2 loss : 0.025177
[23:48:08.008] iteration 15239 : model1 loss : 0.026086 model2 loss : 0.026424
[23:48:08.672] iteration 15240 : model1 loss : 0.022706 model2 loss : 0.018424
[23:48:09.343] iteration 15241 : model1 loss : 0.021571 model2 loss : 0.022427
[23:48:10.011] iteration 15242 : model1 loss : 0.021777 model2 loss : 0.026464
[23:48:10.678] iteration 15243 : model1 loss : 0.026409 model2 loss : 0.027465
[23:48:11.356] iteration 15244 : model1 loss : 0.022119 model2 loss : 0.021850
[23:48:12.020] iteration 15245 : model1 loss : 0.024364 model2 loss : 0.035425
[23:48:12.676] iteration 15246 : model1 loss : 0.033513 model2 loss : 0.032440
[23:48:13.351] iteration 15247 : model1 loss : 0.024628 model2 loss : 0.026109
[23:48:14.031] iteration 15248 : model1 loss : 0.022268 model2 loss : 0.023649
[23:48:14.695] iteration 15249 : model1 loss : 0.016290 model2 loss : 0.016892
[23:48:15.366] iteration 15250 : model1 loss : 0.021765 model2 loss : 0.023994
[23:48:16.086] iteration 15251 : model1 loss : 0.019157 model2 loss : 0.019478
[23:48:16.754] iteration 15252 : model1 loss : 0.024074 model2 loss : 0.022750
[23:48:17.429] iteration 15253 : model1 loss : 0.023678 model2 loss : 0.026763
[23:48:18.097] iteration 15254 : model1 loss : 0.021583 model2 loss : 0.021049
[23:48:18.771] iteration 15255 : model1 loss : 0.018848 model2 loss : 0.019000
[23:48:19.450] iteration 15256 : model1 loss : 0.019057 model2 loss : 0.021072
[23:48:20.107] iteration 15257 : model1 loss : 0.020736 model2 loss : 0.021630
[23:48:20.772] iteration 15258 : model1 loss : 0.019550 model2 loss : 0.022255
[23:48:21.440] iteration 15259 : model1 loss : 0.022296 model2 loss : 0.022959
[23:48:22.104] iteration 15260 : model1 loss : 0.017093 model2 loss : 0.017448
[23:48:22.786] iteration 15261 : model1 loss : 0.022632 model2 loss : 0.025137
[23:48:23.453] iteration 15262 : model1 loss : 0.019647 model2 loss : 0.020298
[23:48:24.117] iteration 15263 : model1 loss : 0.016169 model2 loss : 0.019860
[23:48:24.795] iteration 15264 : model1 loss : 0.022276 model2 loss : 0.021506
[23:48:25.465] iteration 15265 : model1 loss : 0.020535 model2 loss : 0.027153
[23:48:26.121] iteration 15266 : model1 loss : 0.024023 model2 loss : 0.026671
[23:48:26.782] iteration 15267 : model1 loss : 0.018673 model2 loss : 0.018639
[23:48:27.436] iteration 15268 : model1 loss : 0.020439 model2 loss : 0.019720
[23:48:28.098] iteration 15269 : model1 loss : 0.022399 model2 loss : 0.023071
[23:48:28.785] iteration 15270 : model1 loss : 0.020439 model2 loss : 0.019159
[23:48:29.458] iteration 15271 : model1 loss : 0.017823 model2 loss : 0.016092
[23:48:30.114] iteration 15272 : model1 loss : 0.020417 model2 loss : 0.020417
[23:48:30.788] iteration 15273 : model1 loss : 0.024456 model2 loss : 0.033933
[23:48:31.456] iteration 15274 : model1 loss : 0.019643 model2 loss : 0.019531
[23:48:32.117] iteration 15275 : model1 loss : 0.020377 model2 loss : 0.019176
[23:48:32.785] iteration 15276 : model1 loss : 0.024232 model2 loss : 0.029459
[23:48:33.459] iteration 15277 : model1 loss : 0.020106 model2 loss : 0.021316
[23:48:34.123] iteration 15278 : model1 loss : 0.024142 model2 loss : 0.023596
[23:48:34.792] iteration 15279 : model1 loss : 0.021642 model2 loss : 0.022728
[23:48:35.460] iteration 15280 : model1 loss : 0.030373 model2 loss : 0.037605
[23:48:36.138] iteration 15281 : model1 loss : 0.019847 model2 loss : 0.018703
[23:48:36.799] iteration 15282 : model1 loss : 0.032091 model2 loss : 0.029126
[23:48:37.452] iteration 15283 : model1 loss : 0.017121 model2 loss : 0.016859
[23:48:38.118] iteration 15284 : model1 loss : 0.029232 model2 loss : 0.027485
[23:48:38.789] iteration 15285 : model1 loss : 0.038518 model2 loss : 0.042728
[23:48:39.463] iteration 15286 : model1 loss : 0.021354 model2 loss : 0.021466
[23:48:40.135] iteration 15287 : model1 loss : 0.023981 model2 loss : 0.022878
[23:48:40.801] iteration 15288 : model1 loss : 0.020517 model2 loss : 0.023446
[23:48:41.490] iteration 15289 : model1 loss : 0.020532 model2 loss : 0.020898
[23:48:42.156] iteration 15290 : model1 loss : 0.017243 model2 loss : 0.015958
[23:48:42.865] iteration 15291 : model1 loss : 0.030608 model2 loss : 0.029006
[23:48:43.543] iteration 15292 : model1 loss : 0.019538 model2 loss : 0.019701
[23:48:44.202] iteration 15293 : model1 loss : 0.058034 model2 loss : 0.061914
[23:48:44.869] iteration 15294 : model1 loss : 0.021612 model2 loss : 0.020301
[23:48:45.540] iteration 15295 : model1 loss : 0.019809 model2 loss : 0.022624
[23:48:46.229] iteration 15296 : model1 loss : 0.023465 model2 loss : 0.021909
[23:48:46.917] iteration 15297 : model1 loss : 0.031900 model2 loss : 0.032381
[23:48:47.578] iteration 15298 : model1 loss : 0.029630 model2 loss : 0.024687
[23:48:48.252] iteration 15299 : model1 loss : 0.023573 model2 loss : 0.024258
[23:48:48.913] iteration 15300 : model1 loss : 0.024318 model2 loss : 0.022792
[23:48:49.616] iteration 15301 : model1 loss : 0.017997 model2 loss : 0.017916
[23:48:50.290] iteration 15302 : model1 loss : 0.023544 model2 loss : 0.023187
[23:48:50.954] iteration 15303 : model1 loss : 0.019426 model2 loss : 0.020136
[23:48:51.620] iteration 15304 : model1 loss : 0.021658 model2 loss : 0.028686
[23:48:52.298] iteration 15305 : model1 loss : 0.034102 model2 loss : 0.030349
[23:48:52.957] iteration 15306 : model1 loss : 0.016078 model2 loss : 0.016290
[23:48:53.635] iteration 15307 : model1 loss : 0.020149 model2 loss : 0.020072
[23:48:54.292] iteration 15308 : model1 loss : 0.032343 model2 loss : 0.023496
[23:48:54.958] iteration 15309 : model1 loss : 0.022824 model2 loss : 0.021246
[23:48:55.627] iteration 15310 : model1 loss : 0.036003 model2 loss : 0.024125
[23:48:56.300] iteration 15311 : model1 loss : 0.021371 model2 loss : 0.020608
[23:48:56.961] iteration 15312 : model1 loss : 0.023865 model2 loss : 0.020748
[23:48:57.626] iteration 15313 : model1 loss : 0.024758 model2 loss : 0.025566
[23:48:58.302] iteration 15314 : model1 loss : 0.020211 model2 loss : 0.020999
[23:48:58.964] iteration 15315 : model1 loss : 0.022065 model2 loss : 0.025324
[23:48:59.637] iteration 15316 : model1 loss : 0.034503 model2 loss : 0.031195
[23:49:00.309] iteration 15317 : model1 loss : 0.062263 model2 loss : 0.066779
[23:49:00.978] iteration 15318 : model1 loss : 0.019324 model2 loss : 0.021913
[23:49:01.637] iteration 15319 : model1 loss : 0.022540 model2 loss : 0.024317
[23:49:02.314] iteration 15320 : model1 loss : 0.021668 model2 loss : 0.020954
[23:49:02.977] iteration 15321 : model1 loss : 0.025455 model2 loss : 0.025764
[23:49:03.659] iteration 15322 : model1 loss : 0.018915 model2 loss : 0.021476
[23:49:04.331] iteration 15323 : model1 loss : 0.023016 model2 loss : 0.024498
[23:49:04.994] iteration 15324 : model1 loss : 0.021795 model2 loss : 0.020542
[23:49:05.683] iteration 15325 : model1 loss : 0.018694 model2 loss : 0.020861
[23:49:06.375] iteration 15326 : model1 loss : 0.014693 model2 loss : 0.016036
[23:49:07.036] iteration 15327 : model1 loss : 0.019512 model2 loss : 0.017402
[23:49:07.709] iteration 15328 : model1 loss : 0.035233 model2 loss : 0.041546
[23:49:08.412] iteration 15329 : model1 loss : 0.030509 model2 loss : 0.033814
[23:49:09.082] iteration 15330 : model1 loss : 0.019615 model2 loss : 0.020234
[23:49:09.748] iteration 15331 : model1 loss : 0.023155 model2 loss : 0.024109
[23:49:10.425] iteration 15332 : model1 loss : 0.019108 model2 loss : 0.021207
[23:49:11.106] iteration 15333 : model1 loss : 0.025256 model2 loss : 0.026605
[23:49:11.772] iteration 15334 : model1 loss : 0.024526 model2 loss : 0.023629
[23:49:12.447] iteration 15335 : model1 loss : 0.032588 model2 loss : 0.034591
[23:49:13.107] iteration 15336 : model1 loss : 0.015432 model2 loss : 0.016076
[23:49:13.774] iteration 15337 : model1 loss : 0.024107 model2 loss : 0.025383
[23:49:14.456] iteration 15338 : model1 loss : 0.019318 model2 loss : 0.018598
[23:49:15.126] iteration 15339 : model1 loss : 0.028007 model2 loss : 0.024792
[23:49:15.787] iteration 15340 : model1 loss : 0.022037 model2 loss : 0.020504
[23:49:16.450] iteration 15341 : model1 loss : 0.019443 model2 loss : 0.018672
[23:49:17.114] iteration 15342 : model1 loss : 0.020870 model2 loss : 0.019224
[23:49:17.776] iteration 15343 : model1 loss : 0.018100 model2 loss : 0.018526
[23:49:18.445] iteration 15344 : model1 loss : 0.017405 model2 loss : 0.018349
[23:49:19.115] iteration 15345 : model1 loss : 0.021824 model2 loss : 0.023897
[23:49:19.785] iteration 15346 : model1 loss : 0.017892 model2 loss : 0.018700
[23:49:20.458] iteration 15347 : model1 loss : 0.018191 model2 loss : 0.020241
[23:49:21.122] iteration 15348 : model1 loss : 0.024319 model2 loss : 0.022900
[23:49:21.782] iteration 15349 : model1 loss : 0.021602 model2 loss : 0.021414
[23:49:22.458] iteration 15350 : model1 loss : 0.022259 model2 loss : 0.023310
[23:49:23.161] iteration 15351 : model1 loss : 0.023271 model2 loss : 0.022316
[23:49:23.829] iteration 15352 : model1 loss : 0.068368 model2 loss : 0.087117
[23:49:24.501] iteration 15353 : model1 loss : 0.016321 model2 loss : 0.018059
[23:49:25.156] iteration 15354 : model1 loss : 0.021546 model2 loss : 0.019651
[23:49:25.825] iteration 15355 : model1 loss : 0.016281 model2 loss : 0.019917
[23:49:26.490] iteration 15356 : model1 loss : 0.032370 model2 loss : 0.035477
[23:49:27.154] iteration 15357 : model1 loss : 0.016786 model2 loss : 0.017636
[23:49:27.819] iteration 15358 : model1 loss : 0.016908 model2 loss : 0.017175
[23:49:28.480] iteration 15359 : model1 loss : 0.022908 model2 loss : 0.022948
[23:49:29.142] iteration 15360 : model1 loss : 0.018445 model2 loss : 0.017994
[23:49:29.793] iteration 15361 : model1 loss : 0.018502 model2 loss : 0.020725
[23:49:30.477] iteration 15362 : model1 loss : 0.069221 model2 loss : 0.051687
[23:49:31.146] iteration 15363 : model1 loss : 0.019216 model2 loss : 0.017607
[23:49:31.806] iteration 15364 : model1 loss : 0.017929 model2 loss : 0.016739
[23:49:32.491] iteration 15365 : model1 loss : 0.021276 model2 loss : 0.021578
[23:49:33.170] iteration 15366 : model1 loss : 0.055258 model2 loss : 0.056000
[23:49:33.837] iteration 15367 : model1 loss : 0.024317 model2 loss : 0.027526
[23:49:34.507] iteration 15368 : model1 loss : 0.028834 model2 loss : 0.028837
[23:49:35.193] iteration 15369 : model1 loss : 0.021714 model2 loss : 0.021116
[23:49:35.870] iteration 15370 : model1 loss : 0.046674 model2 loss : 0.041927
[23:49:36.546] iteration 15371 : model1 loss : 0.143746 model2 loss : 0.143504
[23:49:37.211] iteration 15372 : model1 loss : 0.017195 model2 loss : 0.017964
[23:49:37.876] iteration 15373 : model1 loss : 0.031534 model2 loss : 0.029830
[23:49:38.558] iteration 15374 : model1 loss : 0.024963 model2 loss : 0.024498
[23:49:39.223] iteration 15375 : model1 loss : 0.020283 model2 loss : 0.020296
[23:49:39.891] iteration 15376 : model1 loss : 0.018569 model2 loss : 0.020755
[23:49:40.552] iteration 15377 : model1 loss : 0.024285 model2 loss : 0.023559
[23:49:41.219] iteration 15378 : model1 loss : 0.024411 model2 loss : 0.022274
[23:49:41.885] iteration 15379 : model1 loss : 0.025656 model2 loss : 0.024898
[23:49:42.556] iteration 15380 : model1 loss : 0.015917 model2 loss : 0.017481
[23:49:43.229] iteration 15381 : model1 loss : 0.024068 model2 loss : 0.022636
[23:49:43.916] iteration 15382 : model1 loss : 0.026081 model2 loss : 0.016547
[23:49:44.574] iteration 15383 : model1 loss : 0.016911 model2 loss : 0.016134
[23:49:45.255] iteration 15384 : model1 loss : 0.031825 model2 loss : 0.034043
[23:49:45.926] iteration 15385 : model1 loss : 0.021971 model2 loss : 0.022467
[23:49:46.599] iteration 15386 : model1 loss : 0.032126 model2 loss : 0.030341
[23:49:47.277] iteration 15387 : model1 loss : 0.020167 model2 loss : 0.029632
[23:49:47.936] iteration 15388 : model1 loss : 0.021131 model2 loss : 0.024663
[23:49:48.611] iteration 15389 : model1 loss : 0.022329 model2 loss : 0.021009
[23:49:49.280] iteration 15390 : model1 loss : 0.015340 model2 loss : 0.015143
[23:49:49.941] iteration 15391 : model1 loss : 0.023705 model2 loss : 0.024067
[23:49:50.607] iteration 15392 : model1 loss : 0.017743 model2 loss : 0.016861
[23:49:51.282] iteration 15393 : model1 loss : 0.019514 model2 loss : 0.021566
[23:49:51.947] iteration 15394 : model1 loss : 0.013154 model2 loss : 0.013994
[23:49:52.622] iteration 15395 : model1 loss : 0.026611 model2 loss : 0.021943
[23:49:53.286] iteration 15396 : model1 loss : 0.019567 model2 loss : 0.019465
[23:49:53.969] iteration 15397 : model1 loss : 0.019623 model2 loss : 0.045129
[23:49:54.652] iteration 15398 : model1 loss : 0.022581 model2 loss : 0.025118
[23:49:55.318] iteration 15399 : model1 loss : 0.026009 model2 loss : 0.032859
[23:49:55.983] iteration 15400 : model1 loss : 0.024752 model2 loss : 0.028270
[23:50:14.162] iteration 15400 : model1_mean_dice : 0.870339 model1_mean_hd95 : 6.381827
[23:50:32.212] iteration 15400 : model2_mean_dice : 0.871335 model2_mean_hd95 : 6.385731
[23:50:32.912] iteration 15401 : model1 loss : 0.032929 model2 loss : 0.029815
[23:50:33.577] iteration 15402 : model1 loss : 0.021293 model2 loss : 0.022234
[23:50:34.238] iteration 15403 : model1 loss : 0.019394 model2 loss : 0.019179
[23:50:34.898] iteration 15404 : model1 loss : 0.021001 model2 loss : 0.023002
[23:50:35.549] iteration 15405 : model1 loss : 0.014751 model2 loss : 0.016007
[23:50:36.207] iteration 15406 : model1 loss : 0.019054 model2 loss : 0.023404
[23:50:36.864] iteration 15407 : model1 loss : 0.027956 model2 loss : 0.021462
[23:50:37.554] iteration 15408 : model1 loss : 0.024577 model2 loss : 0.026385
[23:50:38.217] iteration 15409 : model1 loss : 0.023778 model2 loss : 0.021214
[23:50:38.913] iteration 15410 : model1 loss : 0.017347 model2 loss : 0.018093
[23:50:39.603] iteration 15411 : model1 loss : 0.018800 model2 loss : 0.019685
[23:50:40.289] iteration 15412 : model1 loss : 0.025544 model2 loss : 0.020955
[23:50:40.951] iteration 15413 : model1 loss : 0.052915 model2 loss : 0.054350
[23:50:41.619] iteration 15414 : model1 loss : 0.023167 model2 loss : 0.023665
[23:50:42.269] iteration 15415 : model1 loss : 0.028593 model2 loss : 0.028028
[23:50:42.930] iteration 15416 : model1 loss : 0.014770 model2 loss : 0.016044
[23:50:43.598] iteration 15417 : model1 loss : 0.020693 model2 loss : 0.021625
[23:50:44.278] iteration 15418 : model1 loss : 0.023718 model2 loss : 0.022098
[23:50:44.944] iteration 15419 : model1 loss : 0.017427 model2 loss : 0.017322
[23:50:45.604] iteration 15420 : model1 loss : 0.016224 model2 loss : 0.017159
[23:50:46.269] iteration 15421 : model1 loss : 0.021307 model2 loss : 0.020786
[23:50:46.932] iteration 15422 : model1 loss : 0.024268 model2 loss : 0.022341
[23:50:47.593] iteration 15423 : model1 loss : 0.033220 model2 loss : 0.035089
[23:50:48.271] iteration 15424 : model1 loss : 0.017882 model2 loss : 0.021959
[23:50:48.929] iteration 15425 : model1 loss : 0.019171 model2 loss : 0.021633
[23:50:49.596] iteration 15426 : model1 loss : 0.027070 model2 loss : 0.025938
[23:50:50.245] iteration 15427 : model1 loss : 0.025951 model2 loss : 0.026063
[23:50:50.898] iteration 15428 : model1 loss : 0.017935 model2 loss : 0.017201
[23:50:51.559] iteration 15429 : model1 loss : 0.019153 model2 loss : 0.020139
[23:50:52.232] iteration 15430 : model1 loss : 0.016672 model2 loss : 0.017071
[23:50:52.906] iteration 15431 : model1 loss : 0.023501 model2 loss : 0.025495
[23:50:53.560] iteration 15432 : model1 loss : 0.019261 model2 loss : 0.019971
[23:50:54.230] iteration 15433 : model1 loss : 0.021346 model2 loss : 0.020634
[23:50:54.893] iteration 15434 : model1 loss : 0.028913 model2 loss : 0.032062
[23:50:55.564] iteration 15435 : model1 loss : 0.018690 model2 loss : 0.020010
[23:50:56.223] iteration 15436 : model1 loss : 0.024444 model2 loss : 0.027331
[23:50:56.881] iteration 15437 : model1 loss : 0.028108 model2 loss : 0.025164
[23:50:57.555] iteration 15438 : model1 loss : 0.020891 model2 loss : 0.019729
[23:50:58.237] iteration 15439 : model1 loss : 0.056330 model2 loss : 0.044015
[23:50:58.909] iteration 15440 : model1 loss : 0.025161 model2 loss : 0.026245
[23:50:59.567] iteration 15441 : model1 loss : 0.019865 model2 loss : 0.022638
[23:51:00.228] iteration 15442 : model1 loss : 0.018323 model2 loss : 0.018999
[23:51:00.896] iteration 15443 : model1 loss : 0.027047 model2 loss : 0.025057
[23:51:01.584] iteration 15444 : model1 loss : 0.037900 model2 loss : 0.040807
[23:51:02.251] iteration 15445 : model1 loss : 0.019167 model2 loss : 0.020350
[23:51:02.916] iteration 15446 : model1 loss : 0.023905 model2 loss : 0.022958
[23:51:03.582] iteration 15447 : model1 loss : 0.016562 model2 loss : 0.015785
[23:51:04.258] iteration 15448 : model1 loss : 0.017600 model2 loss : 0.017954
[23:51:04.917] iteration 15449 : model1 loss : 0.019954 model2 loss : 0.017104
[23:51:05.582] iteration 15450 : model1 loss : 0.017344 model2 loss : 0.016082
[23:51:06.283] iteration 15451 : model1 loss : 0.024073 model2 loss : 0.025218
[23:51:06.965] iteration 15452 : model1 loss : 0.022352 model2 loss : 0.023956
[23:51:07.626] iteration 15453 : model1 loss : 0.033447 model2 loss : 0.034813
[23:51:08.309] iteration 15454 : model1 loss : 0.020379 model2 loss : 0.022737
[23:51:08.976] iteration 15455 : model1 loss : 0.075360 model2 loss : 0.071528
[23:51:09.653] iteration 15456 : model1 loss : 0.028663 model2 loss : 0.025211
[23:51:10.323] iteration 15457 : model1 loss : 0.025813 model2 loss : 0.026117
[23:51:10.997] iteration 15458 : model1 loss : 0.026155 model2 loss : 0.025840
[23:51:11.673] iteration 15459 : model1 loss : 0.017149 model2 loss : 0.020631
[23:51:12.336] iteration 15460 : model1 loss : 0.021069 model2 loss : 0.021133
[23:51:12.995] iteration 15461 : model1 loss : 0.028333 model2 loss : 0.034993
[23:51:13.691] iteration 15462 : model1 loss : 0.019966 model2 loss : 0.018992
[23:51:14.401] iteration 15463 : model1 loss : 0.024489 model2 loss : 0.025935
[23:51:15.086] iteration 15464 : model1 loss : 0.021339 model2 loss : 0.021102
[23:51:15.752] iteration 15465 : model1 loss : 0.027044 model2 loss : 0.024664
[23:51:16.413] iteration 15466 : model1 loss : 0.029023 model2 loss : 0.030981
[23:51:17.084] iteration 15467 : model1 loss : 0.024693 model2 loss : 0.024416
[23:51:17.750] iteration 15468 : model1 loss : 0.020013 model2 loss : 0.022599
[23:51:18.425] iteration 15469 : model1 loss : 0.142014 model2 loss : 0.143248
[23:51:19.096] iteration 15470 : model1 loss : 0.025573 model2 loss : 0.033882
[23:51:19.789] iteration 15471 : model1 loss : 0.016900 model2 loss : 0.017903
[23:51:20.479] iteration 15472 : model1 loss : 0.016519 model2 loss : 0.016043
[23:51:21.167] iteration 15473 : model1 loss : 0.028355 model2 loss : 0.028466
[23:51:21.846] iteration 15474 : model1 loss : 0.019556 model2 loss : 0.017117
[23:51:22.540] iteration 15475 : model1 loss : 0.016324 model2 loss : 0.016413
[23:51:23.268] iteration 15476 : model1 loss : 0.022732 model2 loss : 0.020588
[23:51:24.103] iteration 15477 : model1 loss : 0.026359 model2 loss : 0.025787
[23:51:24.840] iteration 15478 : model1 loss : 0.026582 model2 loss : 0.033082
[23:51:25.509] iteration 15479 : model1 loss : 0.031567 model2 loss : 0.030847
[23:51:26.175] iteration 15480 : model1 loss : 0.056609 model2 loss : 0.055530
[23:51:26.851] iteration 15481 : model1 loss : 0.025848 model2 loss : 0.026362
[23:51:27.521] iteration 15482 : model1 loss : 0.017897 model2 loss : 0.018825
[23:51:28.192] iteration 15483 : model1 loss : 0.026248 model2 loss : 0.024232
[23:51:28.858] iteration 15484 : model1 loss : 0.021692 model2 loss : 0.018637
[23:51:29.535] iteration 15485 : model1 loss : 0.020335 model2 loss : 0.021913
[23:51:30.208] iteration 15486 : model1 loss : 0.017943 model2 loss : 0.020654
[23:51:30.889] iteration 15487 : model1 loss : 0.021412 model2 loss : 0.023012
[23:51:31.598] iteration 15488 : model1 loss : 0.023452 model2 loss : 0.022195
[23:51:32.333] iteration 15489 : model1 loss : 0.026015 model2 loss : 0.025994
[23:51:33.083] iteration 15490 : model1 loss : 0.033074 model2 loss : 0.035713
[23:51:33.769] iteration 15491 : model1 loss : 0.050289 model2 loss : 0.051368
[23:51:34.536] iteration 15492 : model1 loss : 0.023626 model2 loss : 0.025659
[23:51:35.279] iteration 15493 : model1 loss : 0.018241 model2 loss : 0.018738
[23:51:36.026] iteration 15494 : model1 loss : 0.026700 model2 loss : 0.027985
[23:51:36.770] iteration 15495 : model1 loss : 0.021639 model2 loss : 0.020265
[23:51:37.536] iteration 15496 : model1 loss : 0.018427 model2 loss : 0.018794
[23:51:38.296] iteration 15497 : model1 loss : 0.022602 model2 loss : 0.021738
[23:51:39.064] iteration 15498 : model1 loss : 0.029454 model2 loss : 0.033444
[23:51:39.819] iteration 15499 : model1 loss : 0.020286 model2 loss : 0.020994
[23:51:40.550] iteration 15500 : model1 loss : 0.020031 model2 loss : 0.020321
[23:51:41.375] iteration 15501 : model1 loss : 0.016950 model2 loss : 0.015986
[23:51:42.104] iteration 15502 : model1 loss : 0.043446 model2 loss : 0.064557
[23:51:42.823] iteration 15503 : model1 loss : 0.021267 model2 loss : 0.018791
[23:51:43.536] iteration 15504 : model1 loss : 0.021960 model2 loss : 0.019867
[23:51:44.244] iteration 15505 : model1 loss : 0.024135 model2 loss : 0.026080
[23:51:44.975] iteration 15506 : model1 loss : 0.025533 model2 loss : 0.025414
[23:51:45.683] iteration 15507 : model1 loss : 0.025545 model2 loss : 0.026719
[23:51:46.383] iteration 15508 : model1 loss : 0.017707 model2 loss : 0.018843
[23:51:47.102] iteration 15509 : model1 loss : 0.016699 model2 loss : 0.022098
[23:51:47.814] iteration 15510 : model1 loss : 0.019458 model2 loss : 0.025034
[23:51:48.507] iteration 15511 : model1 loss : 0.021890 model2 loss : 0.019649
[23:51:49.216] iteration 15512 : model1 loss : 0.018948 model2 loss : 0.018858
[23:51:49.903] iteration 15513 : model1 loss : 0.022142 model2 loss : 0.026080
[23:51:50.606] iteration 15514 : model1 loss : 0.033013 model2 loss : 0.034235
[23:51:51.300] iteration 15515 : model1 loss : 0.026792 model2 loss : 0.030606
[23:51:52.002] iteration 15516 : model1 loss : 0.026768 model2 loss : 0.025649
[23:51:52.725] iteration 15517 : model1 loss : 0.024586 model2 loss : 0.024687
[23:51:53.428] iteration 15518 : model1 loss : 0.018625 model2 loss : 0.019232
[23:51:54.122] iteration 15519 : model1 loss : 0.023857 model2 loss : 0.024280
[23:51:54.841] iteration 15520 : model1 loss : 0.031049 model2 loss : 0.035503
[23:51:55.539] iteration 15521 : model1 loss : 0.016638 model2 loss : 0.022560
[23:51:56.245] iteration 15522 : model1 loss : 0.026509 model2 loss : 0.026990
[23:51:56.945] iteration 15523 : model1 loss : 0.016629 model2 loss : 0.018806
[23:51:57.658] iteration 15524 : model1 loss : 0.018051 model2 loss : 0.033449
[23:51:58.368] iteration 15525 : model1 loss : 0.033893 model2 loss : 0.029367
[23:51:59.070] iteration 15526 : model1 loss : 0.019936 model2 loss : 0.022893
[23:51:59.772] iteration 15527 : model1 loss : 0.043517 model2 loss : 0.042679
[23:52:00.484] iteration 15528 : model1 loss : 0.034529 model2 loss : 0.047218
[23:52:01.177] iteration 15529 : model1 loss : 0.023954 model2 loss : 0.026080
[23:52:01.875] iteration 15530 : model1 loss : 0.022788 model2 loss : 0.025079
[23:52:02.612] iteration 15531 : model1 loss : 0.018185 model2 loss : 0.019759
[23:52:03.317] iteration 15532 : model1 loss : 0.023978 model2 loss : 0.027170
[23:52:04.031] iteration 15533 : model1 loss : 0.023085 model2 loss : 0.024386
[23:52:04.733] iteration 15534 : model1 loss : 0.032987 model2 loss : 0.037391
[23:52:05.440] iteration 15535 : model1 loss : 0.017917 model2 loss : 0.020211
[23:52:06.147] iteration 15536 : model1 loss : 0.016610 model2 loss : 0.018060
[23:52:06.843] iteration 15537 : model1 loss : 0.026887 model2 loss : 0.025393
[23:52:07.558] iteration 15538 : model1 loss : 0.019996 model2 loss : 0.021167
[23:52:08.268] iteration 15539 : model1 loss : 0.024089 model2 loss : 0.030080
[23:52:08.970] iteration 15540 : model1 loss : 0.039167 model2 loss : 0.031371
[23:52:09.671] iteration 15541 : model1 loss : 0.021256 model2 loss : 0.021264
[23:52:10.413] iteration 15542 : model1 loss : 0.020867 model2 loss : 0.021492
[23:52:11.120] iteration 15543 : model1 loss : 0.019226 model2 loss : 0.021740
[23:52:11.809] iteration 15544 : model1 loss : 0.019319 model2 loss : 0.022398
[23:52:12.525] iteration 15545 : model1 loss : 0.144555 model2 loss : 0.143722
[23:52:13.219] iteration 15546 : model1 loss : 0.029497 model2 loss : 0.030304
[23:52:13.922] iteration 15547 : model1 loss : 0.021536 model2 loss : 0.019389
[23:52:14.621] iteration 15548 : model1 loss : 0.022485 model2 loss : 0.021451
[23:52:15.333] iteration 15549 : model1 loss : 0.025239 model2 loss : 0.029927
[23:52:16.053] iteration 15550 : model1 loss : 0.018663 model2 loss : 0.018775
[23:52:16.802] iteration 15551 : model1 loss : 0.018593 model2 loss : 0.018858
[23:52:17.521] iteration 15552 : model1 loss : 0.021805 model2 loss : 0.022935
[23:52:18.238] iteration 15553 : model1 loss : 0.027347 model2 loss : 0.031997
[23:52:18.940] iteration 15554 : model1 loss : 0.020795 model2 loss : 0.022701
[23:52:19.638] iteration 15555 : model1 loss : 0.025018 model2 loss : 0.027482
[23:52:20.330] iteration 15556 : model1 loss : 0.014379 model2 loss : 0.015948
[23:52:21.033] iteration 15557 : model1 loss : 0.032017 model2 loss : 0.032342
[23:52:21.733] iteration 15558 : model1 loss : 0.057977 model2 loss : 0.063314
[23:52:22.439] iteration 15559 : model1 loss : 0.025332 model2 loss : 0.020596
[23:52:23.147] iteration 15560 : model1 loss : 0.025801 model2 loss : 0.030810
[23:52:23.851] iteration 15561 : model1 loss : 0.022817 model2 loss : 0.019412
[23:52:24.549] iteration 15562 : model1 loss : 0.028023 model2 loss : 0.030337
[23:52:25.255] iteration 15563 : model1 loss : 0.020091 model2 loss : 0.021125
[23:52:25.956] iteration 15564 : model1 loss : 0.015998 model2 loss : 0.016346
[23:52:26.656] iteration 15565 : model1 loss : 0.024820 model2 loss : 0.023870
[23:52:27.373] iteration 15566 : model1 loss : 0.029493 model2 loss : 0.030572
[23:52:28.060] iteration 15567 : model1 loss : 0.018240 model2 loss : 0.019498
[23:52:28.759] iteration 15568 : model1 loss : 0.024195 model2 loss : 0.026061
[23:52:29.474] iteration 15569 : model1 loss : 0.026552 model2 loss : 0.023761
[23:52:30.195] iteration 15570 : model1 loss : 0.022037 model2 loss : 0.020849
[23:52:30.908] iteration 15571 : model1 loss : 0.023016 model2 loss : 0.023039
[23:52:31.616] iteration 15572 : model1 loss : 0.022148 model2 loss : 0.019878
[23:52:32.337] iteration 15573 : model1 loss : 0.020777 model2 loss : 0.019284
[23:52:33.047] iteration 15574 : model1 loss : 0.019307 model2 loss : 0.020238
[23:52:33.755] iteration 15575 : model1 loss : 0.021547 model2 loss : 0.026038
[23:52:34.460] iteration 15576 : model1 loss : 0.027215 model2 loss : 0.028175
[23:52:35.166] iteration 15577 : model1 loss : 0.031826 model2 loss : 0.033137
[23:52:35.857] iteration 15578 : model1 loss : 0.029768 model2 loss : 0.029208
[23:52:36.562] iteration 15579 : model1 loss : 0.018846 model2 loss : 0.019117
[23:52:37.283] iteration 15580 : model1 loss : 0.136638 model2 loss : 0.140104
[23:52:37.988] iteration 15581 : model1 loss : 0.037066 model2 loss : 0.027940
[23:52:38.699] iteration 15582 : model1 loss : 0.041493 model2 loss : 0.037894
[23:52:39.404] iteration 15583 : model1 loss : 0.026425 model2 loss : 0.045059
[23:52:40.111] iteration 15584 : model1 loss : 0.026303 model2 loss : 0.026732
[23:52:40.824] iteration 15585 : model1 loss : 0.024220 model2 loss : 0.025440
[23:52:41.539] iteration 15586 : model1 loss : 0.024546 model2 loss : 0.025057
[23:52:42.253] iteration 15587 : model1 loss : 0.030558 model2 loss : 0.026011
[23:52:42.966] iteration 15588 : model1 loss : 0.026449 model2 loss : 0.026923
[23:52:43.665] iteration 15589 : model1 loss : 0.023427 model2 loss : 0.023306
[23:52:44.379] iteration 15590 : model1 loss : 0.027420 model2 loss : 0.025490
[23:52:45.147] iteration 15591 : model1 loss : 0.021745 model2 loss : 0.019200
[23:52:45.836] iteration 15592 : model1 loss : 0.020476 model2 loss : 0.021419
[23:52:46.545] iteration 15593 : model1 loss : 0.021593 model2 loss : 0.024253
[23:52:47.273] iteration 15594 : model1 loss : 0.020372 model2 loss : 0.027182
[23:52:47.982] iteration 15595 : model1 loss : 0.024606 model2 loss : 0.028300
[23:52:48.710] iteration 15596 : model1 loss : 0.018283 model2 loss : 0.020606
[23:52:49.447] iteration 15597 : model1 loss : 0.019119 model2 loss : 0.021259
[23:52:50.151] iteration 15598 : model1 loss : 0.021718 model2 loss : 0.021540
[23:52:50.872] iteration 15599 : model1 loss : 0.022362 model2 loss : 0.021570
[23:52:51.571] iteration 15600 : model1 loss : 0.038844 model2 loss : 0.041318
[23:53:12.299] iteration 15600 : model1_mean_dice : 0.869230 model1_mean_hd95 : 5.522381
[23:53:31.690] iteration 15600 : model2_mean_dice : 0.866624 model2_mean_hd95 : 4.751313
[23:53:32.410] iteration 15601 : model1 loss : 0.026961 model2 loss : 0.026179
[23:53:33.084] iteration 15602 : model1 loss : 0.144063 model2 loss : 0.146962
[23:53:33.769] iteration 15603 : model1 loss : 0.018858 model2 loss : 0.018084
[23:53:34.456] iteration 15604 : model1 loss : 0.022530 model2 loss : 0.024027
[23:53:35.139] iteration 15605 : model1 loss : 0.024907 model2 loss : 0.023438
[23:53:35.838] iteration 15606 : model1 loss : 0.018559 model2 loss : 0.019202
[23:53:36.531] iteration 15607 : model1 loss : 0.019287 model2 loss : 0.020704
[23:53:37.239] iteration 15608 : model1 loss : 0.018124 model2 loss : 0.017818
[23:53:37.931] iteration 15609 : model1 loss : 0.023771 model2 loss : 0.022876
[23:53:38.628] iteration 15610 : model1 loss : 0.018781 model2 loss : 0.018765
[23:53:39.315] iteration 15611 : model1 loss : 0.019227 model2 loss : 0.022821
[23:53:39.990] iteration 15612 : model1 loss : 0.018717 model2 loss : 0.019230
[23:53:40.678] iteration 15613 : model1 loss : 0.016716 model2 loss : 0.015803
[23:53:41.355] iteration 15614 : model1 loss : 0.025695 model2 loss : 0.032922
[23:53:42.043] iteration 15615 : model1 loss : 0.021847 model2 loss : 0.021737
[23:53:42.740] iteration 15616 : model1 loss : 0.019486 model2 loss : 0.020349
[23:53:43.430] iteration 15617 : model1 loss : 0.026283 model2 loss : 0.025867
[23:53:44.104] iteration 15618 : model1 loss : 0.017156 model2 loss : 0.017499
[23:53:44.787] iteration 15619 : model1 loss : 0.022367 model2 loss : 0.027917
[23:53:45.507] iteration 15620 : model1 loss : 0.019001 model2 loss : 0.020550
[23:53:46.204] iteration 15621 : model1 loss : 0.022055 model2 loss : 0.023423
[23:53:46.888] iteration 15622 : model1 loss : 0.024499 model2 loss : 0.025031
[23:53:47.619] iteration 15623 : model1 loss : 0.021312 model2 loss : 0.022002
[23:53:48.304] iteration 15624 : model1 loss : 0.018083 model2 loss : 0.018936
[23:53:49.025] iteration 15625 : model1 loss : 0.023558 model2 loss : 0.026510
[23:53:49.701] iteration 15626 : model1 loss : 0.021500 model2 loss : 0.021582
[23:53:50.372] iteration 15627 : model1 loss : 0.048656 model2 loss : 0.052471
[23:53:51.061] iteration 15628 : model1 loss : 0.020959 model2 loss : 0.021008
[23:53:51.744] iteration 15629 : model1 loss : 0.025882 model2 loss : 0.025787
[23:53:52.452] iteration 15630 : model1 loss : 0.020771 model2 loss : 0.021034
[23:53:53.128] iteration 15631 : model1 loss : 0.021067 model2 loss : 0.022106
[23:53:53.809] iteration 15632 : model1 loss : 0.017225 model2 loss : 0.018537
[23:53:54.506] iteration 15633 : model1 loss : 0.016945 model2 loss : 0.018066
[23:53:55.183] iteration 15634 : model1 loss : 0.022861 model2 loss : 0.024142
[23:53:55.881] iteration 15635 : model1 loss : 0.069506 model2 loss : 0.069653
[23:53:56.580] iteration 15636 : model1 loss : 0.026242 model2 loss : 0.023220
[23:53:57.293] iteration 15637 : model1 loss : 0.023597 model2 loss : 0.023184
[23:53:57.976] iteration 15638 : model1 loss : 0.017985 model2 loss : 0.017646
[23:53:58.673] iteration 15639 : model1 loss : 0.016456 model2 loss : 0.017437
[23:53:59.358] iteration 15640 : model1 loss : 0.019653 model2 loss : 0.021098
[23:54:00.055] iteration 15641 : model1 loss : 0.020999 model2 loss : 0.022121
[23:54:00.737] iteration 15642 : model1 loss : 0.034821 model2 loss : 0.019688
[23:54:01.412] iteration 15643 : model1 loss : 0.022698 model2 loss : 0.023346
[23:54:02.117] iteration 15644 : model1 loss : 0.027298 model2 loss : 0.032732
[23:54:02.816] iteration 15645 : model1 loss : 0.028888 model2 loss : 0.031921
[23:54:03.499] iteration 15646 : model1 loss : 0.020438 model2 loss : 0.022735
[23:54:04.182] iteration 15647 : model1 loss : 0.020138 model2 loss : 0.021063
[23:54:04.884] iteration 15648 : model1 loss : 0.021318 model2 loss : 0.023584
[23:54:05.574] iteration 15649 : model1 loss : 0.023207 model2 loss : 0.024835
[23:54:06.261] iteration 15650 : model1 loss : 0.022108 model2 loss : 0.027813
[23:54:06.992] iteration 15651 : model1 loss : 0.027281 model2 loss : 0.026889
[23:54:07.708] iteration 15652 : model1 loss : 0.019140 model2 loss : 0.022203
[23:54:08.387] iteration 15653 : model1 loss : 0.025175 model2 loss : 0.028301
[23:54:09.070] iteration 15654 : model1 loss : 0.027361 model2 loss : 0.027852
[23:54:09.747] iteration 15655 : model1 loss : 0.016617 model2 loss : 0.016718
[23:54:10.442] iteration 15656 : model1 loss : 0.022781 model2 loss : 0.024618
[23:54:11.132] iteration 15657 : model1 loss : 0.018003 model2 loss : 0.017287
[23:54:11.819] iteration 15658 : model1 loss : 0.022608 model2 loss : 0.022576
[23:54:12.542] iteration 15659 : model1 loss : 0.020013 model2 loss : 0.019513
[23:54:13.234] iteration 15660 : model1 loss : 0.015668 model2 loss : 0.018071
[23:54:13.929] iteration 15661 : model1 loss : 0.026783 model2 loss : 0.025009
[23:54:14.615] iteration 15662 : model1 loss : 0.020514 model2 loss : 0.019490
[23:54:15.298] iteration 15663 : model1 loss : 0.017587 model2 loss : 0.019676
[23:54:15.987] iteration 15664 : model1 loss : 0.022745 model2 loss : 0.022922
[23:54:16.675] iteration 15665 : model1 loss : 0.027176 model2 loss : 0.029505
[23:54:17.392] iteration 15666 : model1 loss : 0.018269 model2 loss : 0.019740
[23:54:18.089] iteration 15667 : model1 loss : 0.019008 model2 loss : 0.020975
[23:54:18.791] iteration 15668 : model1 loss : 0.021310 model2 loss : 0.022765
[23:54:19.471] iteration 15669 : model1 loss : 0.019644 model2 loss : 0.019218
[23:54:20.162] iteration 15670 : model1 loss : 0.021707 model2 loss : 0.019191
[23:54:20.832] iteration 15671 : model1 loss : 0.021250 model2 loss : 0.023396
[23:54:21.521] iteration 15672 : model1 loss : 0.020354 model2 loss : 0.020417
[23:54:22.232] iteration 15673 : model1 loss : 0.022264 model2 loss : 0.024082
[23:54:22.930] iteration 15674 : model1 loss : 0.029649 model2 loss : 0.029845
[23:54:23.613] iteration 15675 : model1 loss : 0.019502 model2 loss : 0.020327
[23:54:24.310] iteration 15676 : model1 loss : 0.029286 model2 loss : 0.028172
[23:54:24.992] iteration 15677 : model1 loss : 0.020817 model2 loss : 0.022120
[23:54:25.744] iteration 15678 : model1 loss : 0.028457 model2 loss : 0.030962
[23:54:26.431] iteration 15679 : model1 loss : 0.033639 model2 loss : 0.035544
[23:54:27.146] iteration 15680 : model1 loss : 0.021601 model2 loss : 0.023891
[23:54:27.840] iteration 15681 : model1 loss : 0.026124 model2 loss : 0.023015
[23:54:28.529] iteration 15682 : model1 loss : 0.017579 model2 loss : 0.019136
[23:54:29.215] iteration 15683 : model1 loss : 0.025605 model2 loss : 0.026430
[23:54:29.916] iteration 15684 : model1 loss : 0.023717 model2 loss : 0.027478
[23:54:30.595] iteration 15685 : model1 loss : 0.022510 model2 loss : 0.021483
[23:54:31.282] iteration 15686 : model1 loss : 0.053083 model2 loss : 0.032630
[23:54:31.963] iteration 15687 : model1 loss : 0.019652 model2 loss : 0.019781
[23:54:32.674] iteration 15688 : model1 loss : 0.024333 model2 loss : 0.023007
[23:54:33.364] iteration 15689 : model1 loss : 0.020146 model2 loss : 0.022774
[23:54:34.038] iteration 15690 : model1 loss : 0.017130 model2 loss : 0.021135
[23:54:34.717] iteration 15691 : model1 loss : 0.017950 model2 loss : 0.019533
[23:54:35.413] iteration 15692 : model1 loss : 0.019646 model2 loss : 0.020814
[23:54:36.102] iteration 15693 : model1 loss : 0.017257 model2 loss : 0.019151
[23:54:36.791] iteration 15694 : model1 loss : 0.018293 model2 loss : 0.020679
[23:54:37.532] iteration 15695 : model1 loss : 0.022642 model2 loss : 0.022964
[23:54:38.230] iteration 15696 : model1 loss : 0.022650 model2 loss : 0.022327
[23:54:38.917] iteration 15697 : model1 loss : 0.027547 model2 loss : 0.026252
[23:54:39.588] iteration 15698 : model1 loss : 0.054280 model2 loss : 0.051818
[23:54:40.289] iteration 15699 : model1 loss : 0.017528 model2 loss : 0.016322
[23:54:40.984] iteration 15700 : model1 loss : 0.021078 model2 loss : 0.021728
[23:54:41.711] iteration 15701 : model1 loss : 0.027197 model2 loss : 0.022910
[23:54:42.416] iteration 15702 : model1 loss : 0.024283 model2 loss : 0.025525
[23:54:43.121] iteration 15703 : model1 loss : 0.026629 model2 loss : 0.030462
[23:54:43.810] iteration 15704 : model1 loss : 0.023568 model2 loss : 0.022342
[23:54:44.507] iteration 15705 : model1 loss : 0.019177 model2 loss : 0.021751
[23:54:45.178] iteration 15706 : model1 loss : 0.022897 model2 loss : 0.020817
[23:54:45.882] iteration 15707 : model1 loss : 0.019764 model2 loss : 0.020423
[23:54:46.616] iteration 15708 : model1 loss : 0.019601 model2 loss : 0.020206
[23:54:47.368] iteration 15709 : model1 loss : 0.031925 model2 loss : 0.028354
[23:54:48.076] iteration 15710 : model1 loss : 0.018521 model2 loss : 0.018613
[23:54:48.779] iteration 15711 : model1 loss : 0.022270 model2 loss : 0.023480
[23:54:49.476] iteration 15712 : model1 loss : 0.021985 model2 loss : 0.021643
[23:54:50.192] iteration 15713 : model1 loss : 0.020855 model2 loss : 0.021318
[23:54:50.887] iteration 15714 : model1 loss : 0.018404 model2 loss : 0.022169
[23:54:51.588] iteration 15715 : model1 loss : 0.020318 model2 loss : 0.024014
[23:54:52.305] iteration 15716 : model1 loss : 0.021720 model2 loss : 0.023436
[23:54:52.999] iteration 15717 : model1 loss : 0.022768 model2 loss : 0.022699
[23:54:53.715] iteration 15718 : model1 loss : 0.018221 model2 loss : 0.019382
[23:54:54.417] iteration 15719 : model1 loss : 0.029206 model2 loss : 0.031066
[23:54:55.136] iteration 15720 : model1 loss : 0.034353 model2 loss : 0.029192
[23:54:55.839] iteration 15721 : model1 loss : 0.028756 model2 loss : 0.032040
[23:54:56.535] iteration 15722 : model1 loss : 0.019268 model2 loss : 0.022234
[23:54:57.258] iteration 15723 : model1 loss : 0.017892 model2 loss : 0.017596
[23:54:57.959] iteration 15724 : model1 loss : 0.019017 model2 loss : 0.017336
[23:54:58.662] iteration 15725 : model1 loss : 0.020879 model2 loss : 0.021996
[23:54:59.366] iteration 15726 : model1 loss : 0.027780 model2 loss : 0.025787
[23:55:00.081] iteration 15727 : model1 loss : 0.029238 model2 loss : 0.021876
[23:55:00.777] iteration 15728 : model1 loss : 0.020768 model2 loss : 0.028158
[23:55:01.489] iteration 15729 : model1 loss : 0.017213 model2 loss : 0.018573
[23:55:02.197] iteration 15730 : model1 loss : 0.020445 model2 loss : 0.017226
[23:55:02.902] iteration 15731 : model1 loss : 0.032884 model2 loss : 0.043727
[23:55:03.598] iteration 15732 : model1 loss : 0.032617 model2 loss : 0.045896
[23:55:04.305] iteration 15733 : model1 loss : 0.018687 model2 loss : 0.018087
[23:55:05.013] iteration 15734 : model1 loss : 0.019944 model2 loss : 0.021972
[23:55:05.719] iteration 15735 : model1 loss : 0.020286 model2 loss : 0.022046
[23:55:06.413] iteration 15736 : model1 loss : 0.023940 model2 loss : 0.021936
[23:55:07.144] iteration 15737 : model1 loss : 0.019324 model2 loss : 0.021323
[23:55:07.859] iteration 15738 : model1 loss : 0.048935 model2 loss : 0.043701
[23:55:08.574] iteration 15739 : model1 loss : 0.019791 model2 loss : 0.020207
[23:55:09.277] iteration 15740 : model1 loss : 0.019878 model2 loss : 0.021345
[23:55:09.983] iteration 15741 : model1 loss : 0.021570 model2 loss : 0.020004
[23:55:10.686] iteration 15742 : model1 loss : 0.016240 model2 loss : 0.020604
[23:55:11.388] iteration 15743 : model1 loss : 0.027054 model2 loss : 0.027255
[23:55:12.086] iteration 15744 : model1 loss : 0.018819 model2 loss : 0.017219
[23:55:12.824] iteration 15745 : model1 loss : 0.025186 model2 loss : 0.024120
[23:55:13.520] iteration 15746 : model1 loss : 0.017131 model2 loss : 0.016116
[23:55:14.234] iteration 15747 : model1 loss : 0.028790 model2 loss : 0.028228
[23:55:14.944] iteration 15748 : model1 loss : 0.025269 model2 loss : 0.031192
[23:55:15.651] iteration 15749 : model1 loss : 0.020230 model2 loss : 0.020646
[23:55:16.353] iteration 15750 : model1 loss : 0.021568 model2 loss : 0.022652
[23:55:17.109] iteration 15751 : model1 loss : 0.017895 model2 loss : 0.019480
[23:55:17.822] iteration 15752 : model1 loss : 0.031224 model2 loss : 0.030857
[23:55:18.540] iteration 15753 : model1 loss : 0.019286 model2 loss : 0.023464
[23:55:19.237] iteration 15754 : model1 loss : 0.031375 model2 loss : 0.035946
[23:55:19.947] iteration 15755 : model1 loss : 0.030333 model2 loss : 0.037042
[23:55:20.662] iteration 15756 : model1 loss : 0.021066 model2 loss : 0.021562
[23:55:21.362] iteration 15757 : model1 loss : 0.019780 model2 loss : 0.022730
[23:55:22.073] iteration 15758 : model1 loss : 0.018151 model2 loss : 0.025666
[23:55:22.821] iteration 15759 : model1 loss : 0.020587 model2 loss : 0.018871
[23:55:23.531] iteration 15760 : model1 loss : 0.020738 model2 loss : 0.024252
[23:55:24.210] iteration 15761 : model1 loss : 0.028007 model2 loss : 0.027357
[23:55:24.889] iteration 15762 : model1 loss : 0.029416 model2 loss : 0.025926
[23:55:25.591] iteration 15763 : model1 loss : 0.050899 model2 loss : 0.056259
[23:55:26.279] iteration 15764 : model1 loss : 0.026012 model2 loss : 0.026018
[23:55:26.972] iteration 15765 : model1 loss : 0.017200 model2 loss : 0.019822
[23:55:27.676] iteration 15766 : model1 loss : 0.018600 model2 loss : 0.020851
[23:55:28.357] iteration 15767 : model1 loss : 0.035715 model2 loss : 0.035150
[23:55:29.047] iteration 15768 : model1 loss : 0.039722 model2 loss : 0.046382
[23:55:29.719] iteration 15769 : model1 loss : 0.027109 model2 loss : 0.032713
[23:55:30.404] iteration 15770 : model1 loss : 0.022573 model2 loss : 0.023758
[23:55:31.089] iteration 15771 : model1 loss : 0.018554 model2 loss : 0.017720
[23:55:31.805] iteration 15772 : model1 loss : 0.023138 model2 loss : 0.028299
[23:55:32.522] iteration 15773 : model1 loss : 0.022703 model2 loss : 0.025731
[23:55:33.220] iteration 15774 : model1 loss : 0.025671 model2 loss : 0.023211
[23:55:33.897] iteration 15775 : model1 loss : 0.021030 model2 loss : 0.023204
[23:55:34.602] iteration 15776 : model1 loss : 0.031972 model2 loss : 0.034605
[23:55:35.287] iteration 15777 : model1 loss : 0.020429 model2 loss : 0.017223
[23:55:35.966] iteration 15778 : model1 loss : 0.021483 model2 loss : 0.026397
[23:55:36.651] iteration 15779 : model1 loss : 0.036779 model2 loss : 0.055458
[23:55:37.376] iteration 15780 : model1 loss : 0.061310 model2 loss : 0.042706
[23:55:38.058] iteration 15781 : model1 loss : 0.024799 model2 loss : 0.025499
[23:55:38.770] iteration 15782 : model1 loss : 0.019954 model2 loss : 0.019182
[23:55:39.461] iteration 15783 : model1 loss : 0.020453 model2 loss : 0.021066
[23:55:40.159] iteration 15784 : model1 loss : 0.031328 model2 loss : 0.043097
[23:55:40.837] iteration 15785 : model1 loss : 0.017446 model2 loss : 0.020243
[23:55:41.559] iteration 15786 : model1 loss : 0.026327 model2 loss : 0.024608
[23:55:42.308] iteration 15787 : model1 loss : 0.039347 model2 loss : 0.049161
[23:55:42.984] iteration 15788 : model1 loss : 0.020026 model2 loss : 0.019470
[23:55:43.671] iteration 15789 : model1 loss : 0.024929 model2 loss : 0.023804
[23:55:44.371] iteration 15790 : model1 loss : 0.036286 model2 loss : 0.037937
[23:55:45.056] iteration 15791 : model1 loss : 0.050461 model2 loss : 0.051930
[23:55:45.737] iteration 15792 : model1 loss : 0.022965 model2 loss : 0.023520
[23:55:46.477] iteration 15793 : model1 loss : 0.015969 model2 loss : 0.018160
[23:55:47.207] iteration 15794 : model1 loss : 0.034970 model2 loss : 0.035216
[23:55:47.900] iteration 15795 : model1 loss : 0.022127 model2 loss : 0.021781
[23:55:48.590] iteration 15796 : model1 loss : 0.022817 model2 loss : 0.023339
[23:55:49.273] iteration 15797 : model1 loss : 0.016588 model2 loss : 0.017393
[23:55:49.965] iteration 15798 : model1 loss : 0.017268 model2 loss : 0.019319
[23:55:50.647] iteration 15799 : model1 loss : 0.021523 model2 loss : 0.023768
[23:55:51.343] iteration 15800 : model1 loss : 0.033760 model2 loss : 0.035625
[23:56:10.591] iteration 15800 : model1_mean_dice : 0.858729 model1_mean_hd95 : 2.926206
[23:56:31.281] iteration 15800 : model2_mean_dice : 0.825389 model2_mean_hd95 : 5.120109
[23:56:31.998] iteration 15801 : model1 loss : 0.019320 model2 loss : 0.020286
[23:56:32.707] iteration 15802 : model1 loss : 0.023883 model2 loss : 0.022791
[23:56:33.406] iteration 15803 : model1 loss : 0.019994 model2 loss : 0.023518
[23:56:34.096] iteration 15804 : model1 loss : 0.020748 model2 loss : 0.019433
[23:56:34.798] iteration 15805 : model1 loss : 0.018865 model2 loss : 0.023118
[23:56:35.505] iteration 15806 : model1 loss : 0.021654 model2 loss : 0.022939
[23:56:36.203] iteration 15807 : model1 loss : 0.055880 model2 loss : 0.101016
[23:56:36.901] iteration 15808 : model1 loss : 0.022823 model2 loss : 0.023981
[23:56:37.620] iteration 15809 : model1 loss : 0.021065 model2 loss : 0.022953
[23:56:38.319] iteration 15810 : model1 loss : 0.013651 model2 loss : 0.014694
[23:56:39.008] iteration 15811 : model1 loss : 0.024839 model2 loss : 0.032547
[23:56:39.703] iteration 15812 : model1 loss : 0.022747 model2 loss : 0.024684
[23:56:40.400] iteration 15813 : model1 loss : 0.017540 model2 loss : 0.020536
[23:56:41.118] iteration 15814 : model1 loss : 0.020784 model2 loss : 0.021617
[23:56:41.825] iteration 15815 : model1 loss : 0.021395 model2 loss : 0.024290
[23:56:42.553] iteration 15816 : model1 loss : 0.026013 model2 loss : 0.032502
[23:56:43.308] iteration 15817 : model1 loss : 0.017711 model2 loss : 0.022501
[23:56:44.032] iteration 15818 : model1 loss : 0.016426 model2 loss : 0.016810
[23:56:44.763] iteration 15819 : model1 loss : 0.037557 model2 loss : 0.039569
[23:56:45.462] iteration 15820 : model1 loss : 0.022462 model2 loss : 0.019679
[23:56:46.152] iteration 15821 : model1 loss : 0.025822 model2 loss : 0.023132
[23:56:46.899] iteration 15822 : model1 loss : 0.018209 model2 loss : 0.018364
[23:56:47.642] iteration 15823 : model1 loss : 0.129553 model2 loss : 0.091791
[23:56:48.375] iteration 15824 : model1 loss : 0.022047 model2 loss : 0.024744
[23:56:49.085] iteration 15825 : model1 loss : 0.019764 model2 loss : 0.020735
[23:56:49.788] iteration 15826 : model1 loss : 0.020536 model2 loss : 0.017525
[23:56:50.495] iteration 15827 : model1 loss : 0.017454 model2 loss : 0.016688
[23:56:51.234] iteration 15828 : model1 loss : 0.023818 model2 loss : 0.024404
[23:56:51.959] iteration 15829 : model1 loss : 0.031295 model2 loss : 0.039609
[23:56:52.719] iteration 15830 : model1 loss : 0.017714 model2 loss : 0.022442
[23:56:53.459] iteration 15831 : model1 loss : 0.020820 model2 loss : 0.029438
[23:56:54.161] iteration 15832 : model1 loss : 0.019931 model2 loss : 0.022252
[23:56:54.863] iteration 15833 : model1 loss : 0.036964 model2 loss : 0.062502
[23:56:55.564] iteration 15834 : model1 loss : 0.017194 model2 loss : 0.018986
[23:56:56.276] iteration 15835 : model1 loss : 0.021264 model2 loss : 0.022171
[23:56:56.971] iteration 15836 : model1 loss : 0.023094 model2 loss : 0.025608
[23:56:57.693] iteration 15837 : model1 loss : 0.030157 model2 loss : 0.031899
[23:56:58.399] iteration 15838 : model1 loss : 0.027317 model2 loss : 0.033502
[23:56:59.114] iteration 15839 : model1 loss : 0.020388 model2 loss : 0.019971
[23:56:59.804] iteration 15840 : model1 loss : 0.018432 model2 loss : 0.023944
[23:57:00.515] iteration 15841 : model1 loss : 0.030044 model2 loss : 0.026838
[23:57:01.210] iteration 15842 : model1 loss : 0.027765 model2 loss : 0.024165
[23:57:01.905] iteration 15843 : model1 loss : 0.019336 model2 loss : 0.020217
[23:57:02.632] iteration 15844 : model1 loss : 0.018248 model2 loss : 0.021943
[23:57:03.324] iteration 15845 : model1 loss : 0.023254 model2 loss : 0.022722
[23:57:04.026] iteration 15846 : model1 loss : 0.023401 model2 loss : 0.026921
[23:57:04.731] iteration 15847 : model1 loss : 0.021965 model2 loss : 0.020013
[23:57:05.434] iteration 15848 : model1 loss : 0.023273 model2 loss : 0.024337
[23:57:06.139] iteration 15849 : model1 loss : 0.023284 model2 loss : 0.020766
[23:57:06.849] iteration 15850 : model1 loss : 0.027417 model2 loss : 0.023671
[23:57:07.618] iteration 15851 : model1 loss : 0.024178 model2 loss : 0.025593
[23:57:08.333] iteration 15852 : model1 loss : 0.020142 model2 loss : 0.020102
[23:57:09.056] iteration 15853 : model1 loss : 0.023427 model2 loss : 0.022689
[23:57:09.771] iteration 15854 : model1 loss : 0.017119 model2 loss : 0.021430
[23:57:10.475] iteration 15855 : model1 loss : 0.033527 model2 loss : 0.059368
[23:57:11.174] iteration 15856 : model1 loss : 0.016354 model2 loss : 0.017635
[23:57:11.896] iteration 15857 : model1 loss : 0.043328 model2 loss : 0.065110
[23:57:12.630] iteration 15858 : model1 loss : 0.040805 model2 loss : 0.043877
[23:57:13.322] iteration 15859 : model1 loss : 0.017532 model2 loss : 0.017341
[23:57:14.020] iteration 15860 : model1 loss : 0.022302 model2 loss : 0.022870
[23:57:14.721] iteration 15861 : model1 loss : 0.017539 model2 loss : 0.021656
[23:57:15.418] iteration 15862 : model1 loss : 0.020248 model2 loss : 0.019763
[23:57:16.119] iteration 15863 : model1 loss : 0.021772 model2 loss : 0.022873
[23:57:16.823] iteration 15864 : model1 loss : 0.028903 model2 loss : 0.029417
[23:57:17.546] iteration 15865 : model1 loss : 0.025256 model2 loss : 0.028261
[23:57:18.254] iteration 15866 : model1 loss : 0.020898 model2 loss : 0.027314
[23:57:18.997] iteration 15867 : model1 loss : 0.015706 model2 loss : 0.019225
[23:57:19.744] iteration 15868 : model1 loss : 0.023672 model2 loss : 0.029910
[23:57:20.501] iteration 15869 : model1 loss : 0.025111 model2 loss : 0.025778
[23:57:21.217] iteration 15870 : model1 loss : 0.025319 model2 loss : 0.024170
[23:57:21.929] iteration 15871 : model1 loss : 0.030339 model2 loss : 0.034825
[23:57:22.658] iteration 15872 : model1 loss : 0.022051 model2 loss : 0.023514
[23:57:23.397] iteration 15873 : model1 loss : 0.023941 model2 loss : 0.025164
[23:57:24.107] iteration 15874 : model1 loss : 0.024573 model2 loss : 0.024896
[23:57:24.813] iteration 15875 : model1 loss : 0.022214 model2 loss : 0.024864
[23:57:25.502] iteration 15876 : model1 loss : 0.023560 model2 loss : 0.026799
[23:57:26.194] iteration 15877 : model1 loss : 0.033912 model2 loss : 0.038247
[23:57:26.943] iteration 15878 : model1 loss : 0.020980 model2 loss : 0.021931
[23:57:27.647] iteration 15879 : model1 loss : 0.019983 model2 loss : 0.021945
[23:57:28.365] iteration 15880 : model1 loss : 0.021627 model2 loss : 0.021080
[23:57:29.100] iteration 15881 : model1 loss : 0.021375 model2 loss : 0.021163
[23:57:29.856] iteration 15882 : model1 loss : 0.025123 model2 loss : 0.024846
[23:57:30.557] iteration 15883 : model1 loss : 0.015339 model2 loss : 0.016803
[23:57:31.299] iteration 15884 : model1 loss : 0.019653 model2 loss : 0.017929
[23:57:32.043] iteration 15885 : model1 loss : 0.025290 model2 loss : 0.022605
[23:57:32.774] iteration 15886 : model1 loss : 0.027614 model2 loss : 0.023975
[23:57:33.464] iteration 15887 : model1 loss : 0.021458 model2 loss : 0.022530
[23:57:34.145] iteration 15888 : model1 loss : 0.024852 model2 loss : 0.027177
[23:57:34.851] iteration 15889 : model1 loss : 0.027709 model2 loss : 0.025015
[23:57:35.562] iteration 15890 : model1 loss : 0.020413 model2 loss : 0.021437
[23:57:36.249] iteration 15891 : model1 loss : 0.020249 model2 loss : 0.020227
[23:57:36.936] iteration 15892 : model1 loss : 0.019799 model2 loss : 0.026402
[23:57:37.668] iteration 15893 : model1 loss : 0.018039 model2 loss : 0.019704
[23:57:38.386] iteration 15894 : model1 loss : 0.025749 model2 loss : 0.027263
[23:57:39.134] iteration 15895 : model1 loss : 0.020498 model2 loss : 0.019663
[23:57:39.888] iteration 15896 : model1 loss : 0.019988 model2 loss : 0.021043
[23:57:40.633] iteration 15897 : model1 loss : 0.020537 model2 loss : 0.024355
[23:57:41.366] iteration 15898 : model1 loss : 0.033626 model2 loss : 0.032543
[23:57:42.097] iteration 15899 : model1 loss : 0.017629 model2 loss : 0.021965
[23:57:42.841] iteration 15900 : model1 loss : 0.027141 model2 loss : 0.020419
[23:57:43.617] iteration 15901 : model1 loss : 0.022123 model2 loss : 0.022575
[23:57:44.335] iteration 15902 : model1 loss : 0.027986 model2 loss : 0.030016
[23:57:45.056] iteration 15903 : model1 loss : 0.025303 model2 loss : 0.022845
[23:57:45.755] iteration 15904 : model1 loss : 0.026279 model2 loss : 0.026337
[23:57:46.451] iteration 15905 : model1 loss : 0.021701 model2 loss : 0.022420
[23:57:47.204] iteration 15906 : model1 loss : 0.014935 model2 loss : 0.014942
[23:57:47.966] iteration 15907 : model1 loss : 0.019910 model2 loss : 0.019018
[23:57:48.645] iteration 15908 : model1 loss : 0.017527 model2 loss : 0.020485
[23:57:49.384] iteration 15909 : model1 loss : 0.024724 model2 loss : 0.024572
[23:57:50.127] iteration 15910 : model1 loss : 0.023667 model2 loss : 0.025410
[23:57:50.859] iteration 15911 : model1 loss : 0.028765 model2 loss : 0.027236
[23:57:51.589] iteration 15912 : model1 loss : 0.017671 model2 loss : 0.017820
[23:57:52.320] iteration 15913 : model1 loss : 0.023731 model2 loss : 0.023207
[23:57:53.042] iteration 15914 : model1 loss : 0.018795 model2 loss : 0.019591
[23:57:53.748] iteration 15915 : model1 loss : 0.015676 model2 loss : 0.015907
[23:57:54.467] iteration 15916 : model1 loss : 0.021922 model2 loss : 0.021660
[23:57:55.191] iteration 15917 : model1 loss : 0.021713 model2 loss : 0.017982
[23:57:55.889] iteration 15918 : model1 loss : 0.022122 model2 loss : 0.022487
[23:57:56.578] iteration 15919 : model1 loss : 0.018609 model2 loss : 0.020900
[23:57:57.287] iteration 15920 : model1 loss : 0.025433 model2 loss : 0.021923
[23:57:57.974] iteration 15921 : model1 loss : 0.019460 model2 loss : 0.021169
[23:57:58.680] iteration 15922 : model1 loss : 0.049748 model2 loss : 0.070001
[23:57:59.365] iteration 15923 : model1 loss : 0.031249 model2 loss : 0.030976
[23:58:00.044] iteration 15924 : model1 loss : 0.017110 model2 loss : 0.019427
[23:58:00.742] iteration 15925 : model1 loss : 0.021158 model2 loss : 0.025767
[23:58:01.441] iteration 15926 : model1 loss : 0.014523 model2 loss : 0.015696
[23:58:02.164] iteration 15927 : model1 loss : 0.027926 model2 loss : 0.026968
[23:58:02.897] iteration 15928 : model1 loss : 0.019860 model2 loss : 0.018766
[23:58:03.623] iteration 15929 : model1 loss : 0.021758 model2 loss : 0.018230
[23:58:04.324] iteration 15930 : model1 loss : 0.038577 model2 loss : 0.040123
[23:58:05.027] iteration 15931 : model1 loss : 0.024589 model2 loss : 0.025172
[23:58:05.758] iteration 15932 : model1 loss : 0.022453 model2 loss : 0.033439
[23:58:06.488] iteration 15933 : model1 loss : 0.028688 model2 loss : 0.028007
[23:58:07.227] iteration 15934 : model1 loss : 0.020084 model2 loss : 0.019109
[23:58:07.938] iteration 15935 : model1 loss : 0.031518 model2 loss : 0.021474
[23:58:08.677] iteration 15936 : model1 loss : 0.019111 model2 loss : 0.020385
[23:58:09.383] iteration 15937 : model1 loss : 0.017725 model2 loss : 0.021070
[23:58:10.070] iteration 15938 : model1 loss : 0.020346 model2 loss : 0.021481
[23:58:10.782] iteration 15939 : model1 loss : 0.018621 model2 loss : 0.019562
[23:58:11.534] iteration 15940 : model1 loss : 0.033088 model2 loss : 0.036659
[23:58:12.264] iteration 15941 : model1 loss : 0.020293 model2 loss : 0.023669
[23:58:12.972] iteration 15942 : model1 loss : 0.019488 model2 loss : 0.018647
[23:58:13.695] iteration 15943 : model1 loss : 0.020101 model2 loss : 0.021522
[23:58:14.504] iteration 15944 : model1 loss : 0.030393 model2 loss : 0.028697
[23:58:15.279] iteration 15945 : model1 loss : 0.025111 model2 loss : 0.026854
[23:58:16.002] iteration 15946 : model1 loss : 0.019570 model2 loss : 0.020291
[23:58:16.783] iteration 15947 : model1 loss : 0.020540 model2 loss : 0.018669
[23:58:17.830] iteration 15948 : model1 loss : 0.025232 model2 loss : 0.026672
[23:58:18.630] iteration 15949 : model1 loss : 0.017791 model2 loss : 0.017842
[23:58:19.311] iteration 15950 : model1 loss : 0.041791 model2 loss : 0.042063
[23:58:20.033] iteration 15951 : model1 loss : 0.039903 model2 loss : 0.042775
[23:58:20.702] iteration 15952 : model1 loss : 0.026358 model2 loss : 0.026316
[23:58:21.401] iteration 15953 : model1 loss : 0.018877 model2 loss : 0.016997
[23:58:22.085] iteration 15954 : model1 loss : 0.031083 model2 loss : 0.032342
[23:58:22.757] iteration 15955 : model1 loss : 0.018848 model2 loss : 0.022224
[23:58:23.424] iteration 15956 : model1 loss : 0.033285 model2 loss : 0.029767
[23:58:24.099] iteration 15957 : model1 loss : 0.018282 model2 loss : 0.018306
[23:58:24.759] iteration 15958 : model1 loss : 0.026200 model2 loss : 0.023816
[23:58:25.448] iteration 15959 : model1 loss : 0.024265 model2 loss : 0.023781
[23:58:26.146] iteration 15960 : model1 loss : 0.017470 model2 loss : 0.016141
[23:58:26.888] iteration 15961 : model1 loss : 0.015999 model2 loss : 0.016500
[23:58:27.854] iteration 15962 : model1 loss : 0.021908 model2 loss : 0.020634
[23:58:28.567] iteration 15963 : model1 loss : 0.022640 model2 loss : 0.022588
[23:58:29.283] iteration 15964 : model1 loss : 0.021693 model2 loss : 0.022360
[23:58:30.015] iteration 15965 : model1 loss : 0.016341 model2 loss : 0.017373
[23:58:30.713] iteration 15966 : model1 loss : 0.018628 model2 loss : 0.019582
[23:58:31.411] iteration 15967 : model1 loss : 0.024138 model2 loss : 0.022139
[23:58:32.089] iteration 15968 : model1 loss : 0.019234 model2 loss : 0.019825
[23:58:32.757] iteration 15969 : model1 loss : 0.025465 model2 loss : 0.026191
[23:58:33.432] iteration 15970 : model1 loss : 0.020037 model2 loss : 0.019267
[23:58:34.142] iteration 15971 : model1 loss : 0.019062 model2 loss : 0.019805
[23:58:34.838] iteration 15972 : model1 loss : 0.020335 model2 loss : 0.022790
[23:58:35.769] iteration 15973 : model1 loss : 0.023925 model2 loss : 0.026196
[23:58:36.452] iteration 15974 : model1 loss : 0.023521 model2 loss : 0.027699
[23:58:37.125] iteration 15975 : model1 loss : 0.034574 model2 loss : 0.032351
[23:58:37.787] iteration 15976 : model1 loss : 0.037199 model2 loss : 0.028404
[23:58:38.456] iteration 15977 : model1 loss : 0.020085 model2 loss : 0.024906
[23:58:39.129] iteration 15978 : model1 loss : 0.020257 model2 loss : 0.017879
[23:58:39.797] iteration 15979 : model1 loss : 0.037270 model2 loss : 0.036926
[23:58:40.464] iteration 15980 : model1 loss : 0.020661 model2 loss : 0.020109
[23:58:41.132] iteration 15981 : model1 loss : 0.015840 model2 loss : 0.017974
[23:58:41.796] iteration 15982 : model1 loss : 0.016909 model2 loss : 0.019458
[23:58:42.469] iteration 15983 : model1 loss : 0.026230 model2 loss : 0.029457
[23:58:43.140] iteration 15984 : model1 loss : 0.027820 model2 loss : 0.030242
[23:58:43.803] iteration 15985 : model1 loss : 0.025023 model2 loss : 0.025431
[23:58:44.482] iteration 15986 : model1 loss : 0.017473 model2 loss : 0.018330
[23:58:45.150] iteration 15987 : model1 loss : 0.017423 model2 loss : 0.019030
[23:58:45.814] iteration 15988 : model1 loss : 0.017560 model2 loss : 0.017372
[23:58:46.492] iteration 15989 : model1 loss : 0.020088 model2 loss : 0.020550
[23:58:47.166] iteration 15990 : model1 loss : 0.019491 model2 loss : 0.019808
[23:58:47.868] iteration 15991 : model1 loss : 0.025194 model2 loss : 0.026343
[23:58:48.568] iteration 15992 : model1 loss : 0.026606 model2 loss : 0.029095
[23:58:49.252] iteration 15993 : model1 loss : 0.018721 model2 loss : 0.017853
[23:58:49.935] iteration 15994 : model1 loss : 0.018619 model2 loss : 0.019538
[23:58:50.607] iteration 15995 : model1 loss : 0.046713 model2 loss : 0.049991
[23:58:51.286] iteration 15996 : model1 loss : 0.018530 model2 loss : 0.018734
[23:58:51.959] iteration 15997 : model1 loss : 0.015663 model2 loss : 0.017271
[23:58:52.628] iteration 15998 : model1 loss : 0.056008 model2 loss : 0.055472
[23:58:53.295] iteration 15999 : model1 loss : 0.018685 model2 loss : 0.018774
[23:58:53.959] iteration 16000 : model1 loss : 0.026868 model2 loss : 0.030854
[23:59:12.128] iteration 16000 : model1_mean_dice : 0.872349 model1_mean_hd95 : 6.744001
[23:59:30.164] iteration 16000 : model2_mean_dice : 0.874595 model2_mean_hd95 : 5.376653
[23:59:30.862] iteration 16001 : model1 loss : 0.021433 model2 loss : 0.021558
[23:59:31.527] iteration 16002 : model1 loss : 0.017229 model2 loss : 0.017941
[23:59:32.198] iteration 16003 : model1 loss : 0.020735 model2 loss : 0.021791
[23:59:32.869] iteration 16004 : model1 loss : 0.019038 model2 loss : 0.018799
[23:59:33.540] iteration 16005 : model1 loss : 0.018254 model2 loss : 0.018706
[23:59:34.207] iteration 16006 : model1 loss : 0.030811 model2 loss : 0.024005
[23:59:34.866] iteration 16007 : model1 loss : 0.023088 model2 loss : 0.022744
[23:59:35.546] iteration 16008 : model1 loss : 0.017087 model2 loss : 0.019584
[23:59:36.201] iteration 16009 : model1 loss : 0.053314 model2 loss : 0.028265
[23:59:36.859] iteration 16010 : model1 loss : 0.018889 model2 loss : 0.020923
[23:59:37.526] iteration 16011 : model1 loss : 0.021243 model2 loss : 0.021946
[23:59:38.190] iteration 16012 : model1 loss : 0.026574 model2 loss : 0.025563
[23:59:38.852] iteration 16013 : model1 loss : 0.018691 model2 loss : 0.018466
[23:59:39.527] iteration 16014 : model1 loss : 0.022730 model2 loss : 0.020965
[23:59:40.199] iteration 16015 : model1 loss : 0.024247 model2 loss : 0.024570
[23:59:40.886] iteration 16016 : model1 loss : 0.029610 model2 loss : 0.037280
[23:59:41.576] iteration 16017 : model1 loss : 0.019849 model2 loss : 0.023026
[23:59:42.245] iteration 16018 : model1 loss : 0.016073 model2 loss : 0.016335
[23:59:42.904] iteration 16019 : model1 loss : 0.026800 model2 loss : 0.028516
[23:59:43.570] iteration 16020 : model1 loss : 0.018853 model2 loss : 0.018859
[23:59:44.239] iteration 16021 : model1 loss : 0.021400 model2 loss : 0.020230
[23:59:44.913] iteration 16022 : model1 loss : 0.027348 model2 loss : 0.020622
[23:59:45.574] iteration 16023 : model1 loss : 0.019850 model2 loss : 0.019846
[23:59:46.238] iteration 16024 : model1 loss : 0.021016 model2 loss : 0.019886
[23:59:46.898] iteration 16025 : model1 loss : 0.019016 model2 loss : 0.018481
[23:59:47.555] iteration 16026 : model1 loss : 0.026016 model2 loss : 0.024585
[23:59:48.226] iteration 16027 : model1 loss : 0.022836 model2 loss : 0.023736
[23:59:48.906] iteration 16028 : model1 loss : 0.022275 model2 loss : 0.029588
[23:59:49.573] iteration 16029 : model1 loss : 0.029881 model2 loss : 0.026678
[23:59:50.245] iteration 16030 : model1 loss : 0.024482 model2 loss : 0.023814
[23:59:50.911] iteration 16031 : model1 loss : 0.026144 model2 loss : 0.025940
[23:59:51.573] iteration 16032 : model1 loss : 0.017972 model2 loss : 0.017487
[23:59:52.227] iteration 16033 : model1 loss : 0.019896 model2 loss : 0.020388
[23:59:52.900] iteration 16034 : model1 loss : 0.033190 model2 loss : 0.033876
[23:59:53.560] iteration 16035 : model1 loss : 0.024761 model2 loss : 0.024053
[23:59:54.224] iteration 16036 : model1 loss : 0.019531 model2 loss : 0.018497
[23:59:54.885] iteration 16037 : model1 loss : 0.037713 model2 loss : 0.026625
[23:59:55.559] iteration 16038 : model1 loss : 0.029708 model2 loss : 0.024382
[23:59:56.214] iteration 16039 : model1 loss : 0.023014 model2 loss : 0.024229
[23:59:56.882] iteration 16040 : model1 loss : 0.027340 model2 loss : 0.031118
[23:59:57.554] iteration 16041 : model1 loss : 0.017867 model2 loss : 0.021807
[23:59:58.223] iteration 16042 : model1 loss : 0.021160 model2 loss : 0.019465
[23:59:58.900] iteration 16043 : model1 loss : 0.027745 model2 loss : 0.028821
[23:59:59.569] iteration 16044 : model1 loss : 0.023646 model2 loss : 0.026192
[00:00:00.239] iteration 16045 : model1 loss : 0.019213 model2 loss : 0.017634
[00:00:00.910] iteration 16046 : model1 loss : 0.015819 model2 loss : 0.016733
[00:00:01.573] iteration 16047 : model1 loss : 0.021585 model2 loss : 0.020369
[00:00:02.239] iteration 16048 : model1 loss : 0.022976 model2 loss : 0.030405
[00:00:02.906] iteration 16049 : model1 loss : 0.023731 model2 loss : 0.020993
[00:00:03.572] iteration 16050 : model1 loss : 0.030477 model2 loss : 0.032063
[00:00:04.277] iteration 16051 : model1 loss : 0.029753 model2 loss : 0.026106
[00:00:04.946] iteration 16052 : model1 loss : 0.024180 model2 loss : 0.023523
[00:00:05.618] iteration 16053 : model1 loss : 0.018862 model2 loss : 0.018165
[00:00:06.287] iteration 16054 : model1 loss : 0.017845 model2 loss : 0.018757
[00:00:06.957] iteration 16055 : model1 loss : 0.022211 model2 loss : 0.021163
[00:00:07.635] iteration 16056 : model1 loss : 0.025851 model2 loss : 0.025023
[00:00:08.289] iteration 16057 : model1 loss : 0.023468 model2 loss : 0.027093
[00:00:08.957] iteration 16058 : model1 loss : 0.020454 model2 loss : 0.018819
[00:00:09.624] iteration 16059 : model1 loss : 0.024019 model2 loss : 0.023709
[00:00:10.289] iteration 16060 : model1 loss : 0.017995 model2 loss : 0.019076
[00:00:10.960] iteration 16061 : model1 loss : 0.064162 model2 loss : 0.089753
[00:00:11.616] iteration 16062 : model1 loss : 0.035815 model2 loss : 0.033071
[00:00:12.285] iteration 16063 : model1 loss : 0.025141 model2 loss : 0.024706
[00:00:12.950] iteration 16064 : model1 loss : 0.019756 model2 loss : 0.021351
[00:00:13.611] iteration 16065 : model1 loss : 0.019102 model2 loss : 0.019168
[00:00:14.275] iteration 16066 : model1 loss : 0.030255 model2 loss : 0.033701
[00:00:14.933] iteration 16067 : model1 loss : 0.024513 model2 loss : 0.025885
[00:00:15.602] iteration 16068 : model1 loss : 0.023023 model2 loss : 0.025415
[00:00:16.282] iteration 16069 : model1 loss : 0.023637 model2 loss : 0.025736
[00:00:16.948] iteration 16070 : model1 loss : 0.020224 model2 loss : 0.019825
[00:00:17.617] iteration 16071 : model1 loss : 0.024856 model2 loss : 0.020741
[00:00:18.279] iteration 16072 : model1 loss : 0.048182 model2 loss : 0.048154
[00:00:18.950] iteration 16073 : model1 loss : 0.028432 model2 loss : 0.027916
[00:00:19.620] iteration 16074 : model1 loss : 0.025161 model2 loss : 0.022263
[00:00:20.285] iteration 16075 : model1 loss : 0.028169 model2 loss : 0.024074
[00:00:20.950] iteration 16076 : model1 loss : 0.020941 model2 loss : 0.023160
[00:00:21.621] iteration 16077 : model1 loss : 0.020939 model2 loss : 0.018524
[00:00:22.298] iteration 16078 : model1 loss : 0.027925 model2 loss : 0.026428
[00:00:22.961] iteration 16079 : model1 loss : 0.020118 model2 loss : 0.021006
[00:00:23.625] iteration 16080 : model1 loss : 0.037366 model2 loss : 0.047644
[00:00:24.300] iteration 16081 : model1 loss : 0.017730 model2 loss : 0.016886
[00:00:24.980] iteration 16082 : model1 loss : 0.026207 model2 loss : 0.025708
[00:00:25.642] iteration 16083 : model1 loss : 0.069102 model2 loss : 0.044588
[00:00:26.344] iteration 16084 : model1 loss : 0.021089 model2 loss : 0.020015
[00:00:27.005] iteration 16085 : model1 loss : 0.020531 model2 loss : 0.022161
[00:00:27.666] iteration 16086 : model1 loss : 0.018085 model2 loss : 0.019598
[00:00:28.330] iteration 16087 : model1 loss : 0.018953 model2 loss : 0.018495
[00:00:28.994] iteration 16088 : model1 loss : 0.019791 model2 loss : 0.019563
[00:00:29.679] iteration 16089 : model1 loss : 0.021714 model2 loss : 0.023257
[00:00:30.351] iteration 16090 : model1 loss : 0.030404 model2 loss : 0.031224
[00:00:31.012] iteration 16091 : model1 loss : 0.022423 model2 loss : 0.024055
[00:00:31.683] iteration 16092 : model1 loss : 0.022482 model2 loss : 0.021334
[00:00:32.352] iteration 16093 : model1 loss : 0.029563 model2 loss : 0.031178
[00:00:33.029] iteration 16094 : model1 loss : 0.021550 model2 loss : 0.024124
[00:00:33.690] iteration 16095 : model1 loss : 0.037190 model2 loss : 0.041672
[00:00:34.361] iteration 16096 : model1 loss : 0.023114 model2 loss : 0.018622
[00:00:35.011] iteration 16097 : model1 loss : 0.018901 model2 loss : 0.022411
[00:00:35.678] iteration 16098 : model1 loss : 0.045630 model2 loss : 0.038764
[00:00:36.353] iteration 16099 : model1 loss : 0.024998 model2 loss : 0.019045
[00:00:37.013] iteration 16100 : model1 loss : 0.017265 model2 loss : 0.016196
[00:00:37.713] iteration 16101 : model1 loss : 0.022658 model2 loss : 0.022395
[00:00:38.385] iteration 16102 : model1 loss : 0.095253 model2 loss : 0.079900
[00:00:39.053] iteration 16103 : model1 loss : 0.018412 model2 loss : 0.018995
[00:00:39.730] iteration 16104 : model1 loss : 0.024631 model2 loss : 0.024598
[00:00:40.397] iteration 16105 : model1 loss : 0.023226 model2 loss : 0.020448
[00:00:41.067] iteration 16106 : model1 loss : 0.016722 model2 loss : 0.017237
[00:00:41.743] iteration 16107 : model1 loss : 0.024929 model2 loss : 0.023230
[00:00:42.409] iteration 16108 : model1 loss : 0.038997 model2 loss : 0.043458
[00:00:43.073] iteration 16109 : model1 loss : 0.022799 model2 loss : 0.020510
[00:00:43.728] iteration 16110 : model1 loss : 0.025422 model2 loss : 0.023711
[00:00:44.394] iteration 16111 : model1 loss : 0.021309 model2 loss : 0.019926
[00:00:45.066] iteration 16112 : model1 loss : 0.024085 model2 loss : 0.024078
[00:00:45.727] iteration 16113 : model1 loss : 0.029441 model2 loss : 0.031649
[00:00:46.398] iteration 16114 : model1 loss : 0.027263 model2 loss : 0.024270
[00:00:47.064] iteration 16115 : model1 loss : 0.030624 model2 loss : 0.025353
[00:00:47.731] iteration 16116 : model1 loss : 0.030856 model2 loss : 0.032630
[00:00:48.413] iteration 16117 : model1 loss : 0.014854 model2 loss : 0.017180
[00:00:49.084] iteration 16118 : model1 loss : 0.021297 model2 loss : 0.021993
[00:00:49.755] iteration 16119 : model1 loss : 0.016138 model2 loss : 0.014766
[00:00:50.432] iteration 16120 : model1 loss : 0.025017 model2 loss : 0.023375
[00:00:51.087] iteration 16121 : model1 loss : 0.015131 model2 loss : 0.013453
[00:00:51.759] iteration 16122 : model1 loss : 0.022989 model2 loss : 0.024702
[00:00:52.416] iteration 16123 : model1 loss : 0.020275 model2 loss : 0.019797
[00:00:53.079] iteration 16124 : model1 loss : 0.020959 model2 loss : 0.019586
[00:00:53.747] iteration 16125 : model1 loss : 0.018648 model2 loss : 0.020419
[00:00:54.427] iteration 16126 : model1 loss : 0.032129 model2 loss : 0.037957
[00:00:55.097] iteration 16127 : model1 loss : 0.024664 model2 loss : 0.024004
[00:00:55.765] iteration 16128 : model1 loss : 0.022041 model2 loss : 0.021454
[00:00:56.441] iteration 16129 : model1 loss : 0.024507 model2 loss : 0.024340
[00:00:57.115] iteration 16130 : model1 loss : 0.018219 model2 loss : 0.016940
[00:00:57.774] iteration 16131 : model1 loss : 0.024172 model2 loss : 0.022220
[00:00:58.438] iteration 16132 : model1 loss : 0.017728 model2 loss : 0.021204
[00:00:59.089] iteration 16133 : model1 loss : 0.020889 model2 loss : 0.021366
[00:00:59.763] iteration 16134 : model1 loss : 0.019408 model2 loss : 0.019619
[00:01:00.441] iteration 16135 : model1 loss : 0.023723 model2 loss : 0.024290
[00:01:01.102] iteration 16136 : model1 loss : 0.024342 model2 loss : 0.024746
[00:01:01.759] iteration 16137 : model1 loss : 0.018797 model2 loss : 0.017823
[00:01:02.430] iteration 16138 : model1 loss : 0.023563 model2 loss : 0.023879
[00:01:03.106] iteration 16139 : model1 loss : 0.020740 model2 loss : 0.019457
[00:01:03.777] iteration 16140 : model1 loss : 0.017519 model2 loss : 0.018001
[00:01:04.452] iteration 16141 : model1 loss : 0.022112 model2 loss : 0.020367
[00:01:05.119] iteration 16142 : model1 loss : 0.030587 model2 loss : 0.027953
[00:01:05.773] iteration 16143 : model1 loss : 0.021296 model2 loss : 0.021319
[00:01:06.459] iteration 16144 : model1 loss : 0.019095 model2 loss : 0.018779
[00:01:07.131] iteration 16145 : model1 loss : 0.020136 model2 loss : 0.019284
[00:01:07.808] iteration 16146 : model1 loss : 0.026405 model2 loss : 0.029920
[00:01:08.471] iteration 16147 : model1 loss : 0.014688 model2 loss : 0.015227
[00:01:09.141] iteration 16148 : model1 loss : 0.022271 model2 loss : 0.023905
[00:01:09.832] iteration 16149 : model1 loss : 0.023836 model2 loss : 0.020137
[00:01:10.501] iteration 16150 : model1 loss : 0.022012 model2 loss : 0.022495
[00:01:11.206] iteration 16151 : model1 loss : 0.023847 model2 loss : 0.025953
[00:01:11.880] iteration 16152 : model1 loss : 0.019067 model2 loss : 0.020103
[00:01:12.560] iteration 16153 : model1 loss : 0.028211 model2 loss : 0.030492
[00:01:13.236] iteration 16154 : model1 loss : 0.036792 model2 loss : 0.037322
[00:01:13.916] iteration 16155 : model1 loss : 0.017252 model2 loss : 0.018324
[00:01:14.574] iteration 16156 : model1 loss : 0.026356 model2 loss : 0.025732
[00:01:15.238] iteration 16157 : model1 loss : 0.021096 model2 loss : 0.021752
[00:01:15.915] iteration 16158 : model1 loss : 0.030506 model2 loss : 0.032660
[00:01:16.580] iteration 16159 : model1 loss : 0.020084 model2 loss : 0.020827
[00:01:17.253] iteration 16160 : model1 loss : 0.024701 model2 loss : 0.025555
[00:01:17.927] iteration 16161 : model1 loss : 0.038093 model2 loss : 0.019408
[00:01:18.590] iteration 16162 : model1 loss : 0.029164 model2 loss : 0.026678
[00:01:19.257] iteration 16163 : model1 loss : 0.019075 model2 loss : 0.021013
[00:01:19.916] iteration 16164 : model1 loss : 0.018426 model2 loss : 0.018187
[00:01:20.582] iteration 16165 : model1 loss : 0.020619 model2 loss : 0.019667
[00:01:21.256] iteration 16166 : model1 loss : 0.019497 model2 loss : 0.017999
[00:01:21.929] iteration 16167 : model1 loss : 0.024822 model2 loss : 0.023922
[00:01:22.604] iteration 16168 : model1 loss : 0.018694 model2 loss : 0.018789
[00:01:23.260] iteration 16169 : model1 loss : 0.015491 model2 loss : 0.017468
[00:01:23.937] iteration 16170 : model1 loss : 0.019535 model2 loss : 0.023007
[00:01:24.592] iteration 16171 : model1 loss : 0.024034 model2 loss : 0.023783
[00:01:25.254] iteration 16172 : model1 loss : 0.020760 model2 loss : 0.021854
[00:01:25.944] iteration 16173 : model1 loss : 0.024034 model2 loss : 0.025473
[00:01:26.610] iteration 16174 : model1 loss : 0.027323 model2 loss : 0.025458
[00:01:27.288] iteration 16175 : model1 loss : 0.028591 model2 loss : 0.019188
[00:01:27.961] iteration 16176 : model1 loss : 0.014999 model2 loss : 0.015987
[00:01:28.627] iteration 16177 : model1 loss : 0.023161 model2 loss : 0.025671
[00:01:29.296] iteration 16178 : model1 loss : 0.025754 model2 loss : 0.021734
[00:01:29.958] iteration 16179 : model1 loss : 0.024006 model2 loss : 0.022813
[00:01:30.632] iteration 16180 : model1 loss : 0.027302 model2 loss : 0.028421
[00:01:31.308] iteration 16181 : model1 loss : 0.023736 model2 loss : 0.020967
[00:01:31.982] iteration 16182 : model1 loss : 0.019107 model2 loss : 0.018567
[00:01:32.650] iteration 16183 : model1 loss : 0.023420 model2 loss : 0.027310
[00:01:33.324] iteration 16184 : model1 loss : 0.023832 model2 loss : 0.026948
[00:01:33.992] iteration 16185 : model1 loss : 0.149134 model2 loss : 0.148334
[00:01:34.663] iteration 16186 : model1 loss : 0.031446 model2 loss : 0.028285
[00:01:35.332] iteration 16187 : model1 loss : 0.043640 model2 loss : 0.042925
[00:01:36.002] iteration 16188 : model1 loss : 0.023443 model2 loss : 0.023369
[00:01:36.676] iteration 16189 : model1 loss : 0.019441 model2 loss : 0.020644
[00:01:37.344] iteration 16190 : model1 loss : 0.018280 model2 loss : 0.018462
[00:01:38.019] iteration 16191 : model1 loss : 0.142908 model2 loss : 0.145681
[00:01:38.678] iteration 16192 : model1 loss : 0.020053 model2 loss : 0.020043
[00:01:39.349] iteration 16193 : model1 loss : 0.021219 model2 loss : 0.020309
[00:01:40.012] iteration 16194 : model1 loss : 0.021530 model2 loss : 0.021499
[00:01:40.692] iteration 16195 : model1 loss : 0.025270 model2 loss : 0.023282
[00:01:41.374] iteration 16196 : model1 loss : 0.019011 model2 loss : 0.019000
[00:01:42.052] iteration 16197 : model1 loss : 0.019144 model2 loss : 0.020589
[00:01:42.735] iteration 16198 : model1 loss : 0.020604 model2 loss : 0.020319
[00:01:43.401] iteration 16199 : model1 loss : 0.026693 model2 loss : 0.028787
[00:01:44.064] iteration 16200 : model1 loss : 0.016868 model2 loss : 0.016360
[00:02:02.389] iteration 16200 : model1_mean_dice : 0.868606 model1_mean_hd95 : 4.000870
[00:02:20.408] iteration 16200 : model2_mean_dice : 0.867403 model2_mean_hd95 : 4.485590
[00:02:21.093] iteration 16201 : model1 loss : 0.019954 model2 loss : 0.018983
[00:02:21.750] iteration 16202 : model1 loss : 0.020868 model2 loss : 0.020665
[00:02:22.417] iteration 16203 : model1 loss : 0.037401 model2 loss : 0.024689
[00:02:23.090] iteration 16204 : model1 loss : 0.021225 model2 loss : 0.019738
[00:02:23.751] iteration 16205 : model1 loss : 0.016705 model2 loss : 0.014672
[00:02:24.416] iteration 16206 : model1 loss : 0.021929 model2 loss : 0.023752
[00:02:25.073] iteration 16207 : model1 loss : 0.027130 model2 loss : 0.027852
[00:02:25.731] iteration 16208 : model1 loss : 0.023264 model2 loss : 0.023353
[00:02:26.399] iteration 16209 : model1 loss : 0.032145 model2 loss : 0.026943
[00:02:27.071] iteration 16210 : model1 loss : 0.026530 model2 loss : 0.032209
[00:02:27.736] iteration 16211 : model1 loss : 0.016993 model2 loss : 0.016806
[00:02:28.400] iteration 16212 : model1 loss : 0.024246 model2 loss : 0.022544
[00:02:29.059] iteration 16213 : model1 loss : 0.020443 model2 loss : 0.019116
[00:02:29.721] iteration 16214 : model1 loss : 0.022520 model2 loss : 0.022866
[00:02:30.389] iteration 16215 : model1 loss : 0.017212 model2 loss : 0.018436
[00:02:31.054] iteration 16216 : model1 loss : 0.025911 model2 loss : 0.031484
[00:02:31.720] iteration 16217 : model1 loss : 0.034132 model2 loss : 0.036614
[00:02:32.397] iteration 16218 : model1 loss : 0.022392 model2 loss : 0.025005
[00:02:33.055] iteration 16219 : model1 loss : 0.023859 model2 loss : 0.021180
[00:02:33.709] iteration 16220 : model1 loss : 0.018534 model2 loss : 0.018178
[00:02:34.369] iteration 16221 : model1 loss : 0.018748 model2 loss : 0.020341
[00:02:35.034] iteration 16222 : model1 loss : 0.023589 model2 loss : 0.023650
[00:02:35.695] iteration 16223 : model1 loss : 0.020359 model2 loss : 0.020324
[00:02:36.354] iteration 16224 : model1 loss : 0.021620 model2 loss : 0.020624
[00:02:37.016] iteration 16225 : model1 loss : 0.023930 model2 loss : 0.026084
[00:02:37.677] iteration 16226 : model1 loss : 0.029283 model2 loss : 0.028292
[00:02:38.340] iteration 16227 : model1 loss : 0.017793 model2 loss : 0.016727
[00:02:39.003] iteration 16228 : model1 loss : 0.025077 model2 loss : 0.023356
[00:02:39.677] iteration 16229 : model1 loss : 0.049157 model2 loss : 0.045174
[00:02:40.345] iteration 16230 : model1 loss : 0.022364 model2 loss : 0.024279
[00:02:41.022] iteration 16231 : model1 loss : 0.019498 model2 loss : 0.020303
[00:02:41.690] iteration 16232 : model1 loss : 0.025788 model2 loss : 0.031532
[00:02:42.361] iteration 16233 : model1 loss : 0.020241 model2 loss : 0.019958
[00:02:43.026] iteration 16234 : model1 loss : 0.022432 model2 loss : 0.018838
[00:02:43.693] iteration 16235 : model1 loss : 0.021798 model2 loss : 0.023380
[00:02:44.354] iteration 16236 : model1 loss : 0.029602 model2 loss : 0.019186
[00:02:45.020] iteration 16237 : model1 loss : 0.021663 model2 loss : 0.022947
[00:02:45.689] iteration 16238 : model1 loss : 0.022662 model2 loss : 0.021342
[00:02:46.347] iteration 16239 : model1 loss : 0.017978 model2 loss : 0.020945
[00:02:47.014] iteration 16240 : model1 loss : 0.054018 model2 loss : 0.044584
[00:02:47.691] iteration 16241 : model1 loss : 0.023348 model2 loss : 0.022187
[00:02:48.350] iteration 16242 : model1 loss : 0.020222 model2 loss : 0.021194
[00:02:49.019] iteration 16243 : model1 loss : 0.024713 model2 loss : 0.026512
[00:02:49.714] iteration 16244 : model1 loss : 0.025133 model2 loss : 0.023011
[00:02:50.379] iteration 16245 : model1 loss : 0.019846 model2 loss : 0.021211
[00:02:51.067] iteration 16246 : model1 loss : 0.019250 model2 loss : 0.021732
[00:02:51.727] iteration 16247 : model1 loss : 0.029412 model2 loss : 0.023180
[00:02:52.394] iteration 16248 : model1 loss : 0.021089 model2 loss : 0.023179
[00:02:53.055] iteration 16249 : model1 loss : 0.019849 model2 loss : 0.023917
[00:02:53.736] iteration 16250 : model1 loss : 0.150732 model2 loss : 0.150022
[00:02:54.436] iteration 16251 : model1 loss : 0.037451 model2 loss : 0.031360
[00:02:55.100] iteration 16252 : model1 loss : 0.032188 model2 loss : 0.027200
[00:02:55.775] iteration 16253 : model1 loss : 0.016325 model2 loss : 0.015238
[00:02:56.443] iteration 16254 : model1 loss : 0.019499 model2 loss : 0.019832
[00:02:57.099] iteration 16255 : model1 loss : 0.030397 model2 loss : 0.030929
[00:02:57.763] iteration 16256 : model1 loss : 0.019856 model2 loss : 0.023505
[00:02:58.429] iteration 16257 : model1 loss : 0.015369 model2 loss : 0.014875
[00:02:59.101] iteration 16258 : model1 loss : 0.018474 model2 loss : 0.018154
[00:02:59.771] iteration 16259 : model1 loss : 0.037266 model2 loss : 0.045207
[00:03:00.442] iteration 16260 : model1 loss : 0.021087 model2 loss : 0.022732
[00:03:01.133] iteration 16261 : model1 loss : 0.028673 model2 loss : 0.056251
[00:03:01.801] iteration 16262 : model1 loss : 0.016647 model2 loss : 0.017934
[00:03:02.475] iteration 16263 : model1 loss : 0.033905 model2 loss : 0.048003
[00:03:03.150] iteration 16264 : model1 loss : 0.029748 model2 loss : 0.028414
[00:03:03.819] iteration 16265 : model1 loss : 0.027942 model2 loss : 0.023164
[00:03:04.477] iteration 16266 : model1 loss : 0.015616 model2 loss : 0.017366
[00:03:05.147] iteration 16267 : model1 loss : 0.018975 model2 loss : 0.021151
[00:03:05.821] iteration 16268 : model1 loss : 0.028231 model2 loss : 0.031440
[00:03:06.476] iteration 16269 : model1 loss : 0.017948 model2 loss : 0.017257
[00:03:07.136] iteration 16270 : model1 loss : 0.029993 model2 loss : 0.033724
[00:03:07.801] iteration 16271 : model1 loss : 0.019988 model2 loss : 0.020429
[00:03:08.475] iteration 16272 : model1 loss : 0.019557 model2 loss : 0.020602
[00:03:09.144] iteration 16273 : model1 loss : 0.024102 model2 loss : 0.026032
[00:03:09.816] iteration 16274 : model1 loss : 0.023112 model2 loss : 0.025475
[00:03:10.484] iteration 16275 : model1 loss : 0.024034 model2 loss : 0.023805
[00:03:11.159] iteration 16276 : model1 loss : 0.017773 model2 loss : 0.017672
[00:03:11.832] iteration 16277 : model1 loss : 0.025056 model2 loss : 0.021949
[00:03:12.493] iteration 16278 : model1 loss : 0.022125 model2 loss : 0.020628
[00:03:13.149] iteration 16279 : model1 loss : 0.023502 model2 loss : 0.027762
[00:03:13.806] iteration 16280 : model1 loss : 0.020552 model2 loss : 0.024319
[00:03:14.487] iteration 16281 : model1 loss : 0.025421 model2 loss : 0.025077
[00:03:15.148] iteration 16282 : model1 loss : 0.144889 model2 loss : 0.144244
[00:03:15.812] iteration 16283 : model1 loss : 0.019937 model2 loss : 0.019584
[00:03:16.482] iteration 16284 : model1 loss : 0.032336 model2 loss : 0.027269
[00:03:17.152] iteration 16285 : model1 loss : 0.021618 model2 loss : 0.021682
[00:03:17.820] iteration 16286 : model1 loss : 0.017552 model2 loss : 0.022117
[00:03:18.492] iteration 16287 : model1 loss : 0.024920 model2 loss : 0.026026
[00:03:19.150] iteration 16288 : model1 loss : 0.140535 model2 loss : 0.141220
[00:03:19.829] iteration 16289 : model1 loss : 0.024697 model2 loss : 0.026350
[00:03:20.501] iteration 16290 : model1 loss : 0.022426 model2 loss : 0.023400
[00:03:21.173] iteration 16291 : model1 loss : 0.021305 model2 loss : 0.021416
[00:03:21.830] iteration 16292 : model1 loss : 0.017513 model2 loss : 0.018159
[00:03:22.495] iteration 16293 : model1 loss : 0.023325 model2 loss : 0.026034
[00:03:23.163] iteration 16294 : model1 loss : 0.026840 model2 loss : 0.027752
[00:03:23.825] iteration 16295 : model1 loss : 0.020376 model2 loss : 0.025331
[00:03:24.491] iteration 16296 : model1 loss : 0.024864 model2 loss : 0.025473
[00:03:25.166] iteration 16297 : model1 loss : 0.019006 model2 loss : 0.018748
[00:03:25.832] iteration 16298 : model1 loss : 0.016919 model2 loss : 0.016589
[00:03:26.492] iteration 16299 : model1 loss : 0.023010 model2 loss : 0.023760
[00:03:27.167] iteration 16300 : model1 loss : 0.023653 model2 loss : 0.024776
[00:03:27.857] iteration 16301 : model1 loss : 0.018814 model2 loss : 0.020766
[00:03:28.522] iteration 16302 : model1 loss : 0.019478 model2 loss : 0.018644
[00:03:29.186] iteration 16303 : model1 loss : 0.087526 model2 loss : 0.033646
[00:03:29.847] iteration 16304 : model1 loss : 0.016688 model2 loss : 0.018386
[00:03:30.517] iteration 16305 : model1 loss : 0.024365 model2 loss : 0.020789
[00:03:31.191] iteration 16306 : model1 loss : 0.020489 model2 loss : 0.021892
[00:03:31.855] iteration 16307 : model1 loss : 0.022103 model2 loss : 0.022283
[00:03:32.533] iteration 16308 : model1 loss : 0.016568 model2 loss : 0.015986
[00:03:33.197] iteration 16309 : model1 loss : 0.022850 model2 loss : 0.023518
[00:03:33.874] iteration 16310 : model1 loss : 0.020707 model2 loss : 0.016135
[00:03:34.554] iteration 16311 : model1 loss : 0.022725 model2 loss : 0.018261
[00:03:35.218] iteration 16312 : model1 loss : 0.024563 model2 loss : 0.020517
[00:03:35.899] iteration 16313 : model1 loss : 0.025401 model2 loss : 0.025062
[00:03:36.568] iteration 16314 : model1 loss : 0.025964 model2 loss : 0.017428
[00:03:37.233] iteration 16315 : model1 loss : 0.047733 model2 loss : 0.025856
[00:03:37.912] iteration 16316 : model1 loss : 0.024394 model2 loss : 0.023950
[00:03:38.595] iteration 16317 : model1 loss : 0.021560 model2 loss : 0.021051
[00:03:39.259] iteration 16318 : model1 loss : 0.029507 model2 loss : 0.025543
[00:03:39.929] iteration 16319 : model1 loss : 0.017648 model2 loss : 0.016094
[00:03:40.605] iteration 16320 : model1 loss : 0.029695 model2 loss : 0.021086
[00:03:41.288] iteration 16321 : model1 loss : 0.024772 model2 loss : 0.022564
[00:03:41.950] iteration 16322 : model1 loss : 0.022931 model2 loss : 0.019468
[00:03:42.631] iteration 16323 : model1 loss : 0.024390 model2 loss : 0.022661
[00:03:43.304] iteration 16324 : model1 loss : 0.032989 model2 loss : 0.030879
[00:03:43.968] iteration 16325 : model1 loss : 0.027882 model2 loss : 0.028600
[00:03:44.638] iteration 16326 : model1 loss : 0.025515 model2 loss : 0.021322
[00:03:45.306] iteration 16327 : model1 loss : 0.027274 model2 loss : 0.021462
[00:03:45.978] iteration 16328 : model1 loss : 0.014516 model2 loss : 0.015120
[00:03:46.646] iteration 16329 : model1 loss : 0.017610 model2 loss : 0.017657
[00:03:47.316] iteration 16330 : model1 loss : 0.013464 model2 loss : 0.013542
[00:03:47.981] iteration 16331 : model1 loss : 0.048109 model2 loss : 0.036505
[00:03:48.649] iteration 16332 : model1 loss : 0.025705 model2 loss : 0.028178
[00:03:49.319] iteration 16333 : model1 loss : 0.020851 model2 loss : 0.018518
[00:03:49.997] iteration 16334 : model1 loss : 0.030349 model2 loss : 0.026731
[00:03:50.666] iteration 16335 : model1 loss : 0.026890 model2 loss : 0.030248
[00:03:51.354] iteration 16336 : model1 loss : 0.045087 model2 loss : 0.039248
[00:03:52.026] iteration 16337 : model1 loss : 0.022285 model2 loss : 0.021356
[00:03:52.693] iteration 16338 : model1 loss : 0.022704 model2 loss : 0.022140
[00:03:53.366] iteration 16339 : model1 loss : 0.020543 model2 loss : 0.020741
[00:03:54.022] iteration 16340 : model1 loss : 0.027939 model2 loss : 0.024501
[00:03:54.688] iteration 16341 : model1 loss : 0.048353 model2 loss : 0.030894
[00:03:55.367] iteration 16342 : model1 loss : 0.024251 model2 loss : 0.025682
[00:03:56.043] iteration 16343 : model1 loss : 0.024134 model2 loss : 0.024333
[00:03:56.702] iteration 16344 : model1 loss : 0.017825 model2 loss : 0.017244
[00:03:57.370] iteration 16345 : model1 loss : 0.026972 model2 loss : 0.025409
[00:03:58.043] iteration 16346 : model1 loss : 0.021968 model2 loss : 0.019810
[00:03:58.712] iteration 16347 : model1 loss : 0.027024 model2 loss : 0.026610
[00:03:59.380] iteration 16348 : model1 loss : 0.021972 model2 loss : 0.019640
[00:04:00.052] iteration 16349 : model1 loss : 0.017817 model2 loss : 0.023996
[00:04:00.726] iteration 16350 : model1 loss : 0.025808 model2 loss : 0.021968
[00:04:01.452] iteration 16351 : model1 loss : 0.018138 model2 loss : 0.017764
[00:04:02.118] iteration 16352 : model1 loss : 0.019192 model2 loss : 0.018690
[00:04:02.787] iteration 16353 : model1 loss : 0.044226 model2 loss : 0.039281
[00:04:03.459] iteration 16354 : model1 loss : 0.019631 model2 loss : 0.019555
[00:04:04.118] iteration 16355 : model1 loss : 0.017943 model2 loss : 0.018992
[00:04:04.792] iteration 16356 : model1 loss : 0.024395 model2 loss : 0.021546
[00:04:05.478] iteration 16357 : model1 loss : 0.020788 model2 loss : 0.019441
[00:04:06.158] iteration 16358 : model1 loss : 0.126934 model2 loss : 0.018157
[00:04:06.820] iteration 16359 : model1 loss : 0.028178 model2 loss : 0.028901
[00:04:07.484] iteration 16360 : model1 loss : 0.033935 model2 loss : 0.032046
[00:04:08.150] iteration 16361 : model1 loss : 0.019055 model2 loss : 0.016475
[00:04:08.802] iteration 16362 : model1 loss : 0.018389 model2 loss : 0.021830
[00:04:09.472] iteration 16363 : model1 loss : 0.022121 model2 loss : 0.023072
[00:04:10.135] iteration 16364 : model1 loss : 0.057732 model2 loss : 0.052060
[00:04:10.790] iteration 16365 : model1 loss : 0.031514 model2 loss : 0.024780
[00:04:11.455] iteration 16366 : model1 loss : 0.027467 model2 loss : 0.024613
[00:04:12.116] iteration 16367 : model1 loss : 0.019375 model2 loss : 0.022348
[00:04:12.789] iteration 16368 : model1 loss : 0.019070 model2 loss : 0.018772
[00:04:13.463] iteration 16369 : model1 loss : 0.022588 model2 loss : 0.024643
[00:04:14.126] iteration 16370 : model1 loss : 0.020031 model2 loss : 0.022833
[00:04:14.796] iteration 16371 : model1 loss : 0.032467 model2 loss : 0.025452
[00:04:15.457] iteration 16372 : model1 loss : 0.017594 model2 loss : 0.018036
[00:04:16.119] iteration 16373 : model1 loss : 0.022129 model2 loss : 0.021601
[00:04:16.790] iteration 16374 : model1 loss : 0.018838 model2 loss : 0.021274
[00:04:17.473] iteration 16375 : model1 loss : 0.018025 model2 loss : 0.019186
[00:04:18.125] iteration 16376 : model1 loss : 0.020894 model2 loss : 0.018214
[00:04:18.802] iteration 16377 : model1 loss : 0.017523 model2 loss : 0.017403
[00:04:19.466] iteration 16378 : model1 loss : 0.017768 model2 loss : 0.017111
[00:04:20.132] iteration 16379 : model1 loss : 0.022641 model2 loss : 0.020411
[00:04:20.805] iteration 16380 : model1 loss : 0.018154 model2 loss : 0.017708
[00:04:21.474] iteration 16381 : model1 loss : 0.029592 model2 loss : 0.042881
[00:04:22.147] iteration 16382 : model1 loss : 0.024847 model2 loss : 0.020779
[00:04:22.824] iteration 16383 : model1 loss : 0.058000 model2 loss : 0.018920
[00:04:23.491] iteration 16384 : model1 loss : 0.021163 model2 loss : 0.021380
[00:04:24.156] iteration 16385 : model1 loss : 0.022953 model2 loss : 0.022664
[00:04:24.821] iteration 16386 : model1 loss : 0.038005 model2 loss : 0.022855
[00:04:25.507] iteration 16387 : model1 loss : 0.018697 model2 loss : 0.019912
[00:04:26.175] iteration 16388 : model1 loss : 0.018052 model2 loss : 0.017461
[00:04:26.840] iteration 16389 : model1 loss : 0.021112 model2 loss : 0.021538
[00:04:27.503] iteration 16390 : model1 loss : 0.020940 model2 loss : 0.020855
[00:04:28.172] iteration 16391 : model1 loss : 0.042934 model2 loss : 0.034740
[00:04:28.867] iteration 16392 : model1 loss : 0.024077 model2 loss : 0.023894
[00:04:29.536] iteration 16393 : model1 loss : 0.022645 model2 loss : 0.023849
[00:04:30.195] iteration 16394 : model1 loss : 0.019041 model2 loss : 0.021368
[00:04:30.854] iteration 16395 : model1 loss : 0.027395 model2 loss : 0.022560
[00:04:31.519] iteration 16396 : model1 loss : 0.026262 model2 loss : 0.024172
[00:04:32.194] iteration 16397 : model1 loss : 0.019632 model2 loss : 0.021987
[00:04:32.853] iteration 16398 : model1 loss : 0.026291 model2 loss : 0.025177
[00:04:33.521] iteration 16399 : model1 loss : 0.016846 model2 loss : 0.017110
[00:04:34.185] iteration 16400 : model1 loss : 0.024073 model2 loss : 0.023607
[00:04:52.950] iteration 16400 : model1_mean_dice : 0.873257 model1_mean_hd95 : 6.227871
[00:05:11.091] iteration 16400 : model2_mean_dice : 0.870314 model2_mean_hd95 : 3.568212
[00:05:11.770] iteration 16401 : model1 loss : 0.022516 model2 loss : 0.025570
[00:05:12.441] iteration 16402 : model1 loss : 0.019254 model2 loss : 0.018490
[00:05:13.104] iteration 16403 : model1 loss : 0.024801 model2 loss : 0.024429
[00:05:13.772] iteration 16404 : model1 loss : 0.024737 model2 loss : 0.022192
[00:05:14.444] iteration 16405 : model1 loss : 0.084854 model2 loss : 0.042399
[00:05:15.115] iteration 16406 : model1 loss : 0.033097 model2 loss : 0.030606
[00:05:15.766] iteration 16407 : model1 loss : 0.017671 model2 loss : 0.017134
[00:05:16.441] iteration 16408 : model1 loss : 0.023072 model2 loss : 0.023405
[00:05:17.109] iteration 16409 : model1 loss : 0.019444 model2 loss : 0.021349
[00:05:17.774] iteration 16410 : model1 loss : 0.027082 model2 loss : 0.023162
[00:05:18.436] iteration 16411 : model1 loss : 0.017669 model2 loss : 0.016827
[00:05:19.101] iteration 16412 : model1 loss : 0.019583 model2 loss : 0.021021
[00:05:19.775] iteration 16413 : model1 loss : 0.023830 model2 loss : 0.022998
[00:05:20.447] iteration 16414 : model1 loss : 0.024661 model2 loss : 0.024882
[00:05:21.130] iteration 16415 : model1 loss : 0.019297 model2 loss : 0.022165
[00:05:21.796] iteration 16416 : model1 loss : 0.041831 model2 loss : 0.041826
[00:05:22.461] iteration 16417 : model1 loss : 0.020492 model2 loss : 0.020664
[00:05:23.118] iteration 16418 : model1 loss : 0.022687 model2 loss : 0.024073
[00:05:23.791] iteration 16419 : model1 loss : 0.042371 model2 loss : 0.051200
[00:05:24.462] iteration 16420 : model1 loss : 0.023676 model2 loss : 0.021822
[00:05:25.115] iteration 16421 : model1 loss : 0.015830 model2 loss : 0.015990
[00:05:25.777] iteration 16422 : model1 loss : 0.023956 model2 loss : 0.024010
[00:05:26.443] iteration 16423 : model1 loss : 0.035235 model2 loss : 0.032413
[00:05:27.099] iteration 16424 : model1 loss : 0.024314 model2 loss : 0.019508
[00:05:27.755] iteration 16425 : model1 loss : 0.021686 model2 loss : 0.023083
[00:05:28.434] iteration 16426 : model1 loss : 0.020856 model2 loss : 0.019785
[00:05:29.103] iteration 16427 : model1 loss : 0.018822 model2 loss : 0.018801
[00:05:29.765] iteration 16428 : model1 loss : 0.028364 model2 loss : 0.024380
[00:05:30.421] iteration 16429 : model1 loss : 0.017892 model2 loss : 0.017535
[00:05:31.086] iteration 16430 : model1 loss : 0.058613 model2 loss : 0.023828
[00:05:31.748] iteration 16431 : model1 loss : 0.026452 model2 loss : 0.026185
[00:05:32.442] iteration 16432 : model1 loss : 0.024316 model2 loss : 0.025465
[00:05:33.116] iteration 16433 : model1 loss : 0.023823 model2 loss : 0.022433
[00:05:33.762] iteration 16434 : model1 loss : 0.020811 model2 loss : 0.021617
[00:05:34.429] iteration 16435 : model1 loss : 0.019352 model2 loss : 0.018149
[00:05:35.088] iteration 16436 : model1 loss : 0.018287 model2 loss : 0.018050
[00:05:35.748] iteration 16437 : model1 loss : 0.024484 model2 loss : 0.023131
[00:05:36.421] iteration 16438 : model1 loss : 0.030308 model2 loss : 0.033319
[00:05:37.087] iteration 16439 : model1 loss : 0.029855 model2 loss : 0.027932
[00:05:37.751] iteration 16440 : model1 loss : 0.038460 model2 loss : 0.041204
[00:05:38.416] iteration 16441 : model1 loss : 0.017095 model2 loss : 0.017839
[00:05:39.079] iteration 16442 : model1 loss : 0.024937 model2 loss : 0.024158
[00:05:39.753] iteration 16443 : model1 loss : 0.017809 model2 loss : 0.017015
[00:05:40.447] iteration 16444 : model1 loss : 0.021722 model2 loss : 0.023622
[00:05:41.127] iteration 16445 : model1 loss : 0.014916 model2 loss : 0.014587
[00:05:41.801] iteration 16446 : model1 loss : 0.023323 model2 loss : 0.024323
[00:05:42.465] iteration 16447 : model1 loss : 0.033354 model2 loss : 0.029791
[00:05:43.136] iteration 16448 : model1 loss : 0.021622 model2 loss : 0.019884
[00:05:43.801] iteration 16449 : model1 loss : 0.019047 model2 loss : 0.019152
[00:05:44.460] iteration 16450 : model1 loss : 0.021386 model2 loss : 0.021033
[00:05:45.165] iteration 16451 : model1 loss : 0.025886 model2 loss : 0.024483
[00:05:45.826] iteration 16452 : model1 loss : 0.023092 model2 loss : 0.020174
[00:05:46.497] iteration 16453 : model1 loss : 0.025768 model2 loss : 0.021616
[00:05:47.169] iteration 16454 : model1 loss : 0.023884 model2 loss : 0.021858
[00:05:47.838] iteration 16455 : model1 loss : 0.021171 model2 loss : 0.022977
[00:05:48.506] iteration 16456 : model1 loss : 0.020434 model2 loss : 0.021079
[00:05:49.177] iteration 16457 : model1 loss : 0.021190 model2 loss : 0.016881
[00:05:49.850] iteration 16458 : model1 loss : 0.019484 model2 loss : 0.020259
[00:05:50.514] iteration 16459 : model1 loss : 0.023205 model2 loss : 0.022281
[00:05:51.212] iteration 16460 : model1 loss : 0.021579 model2 loss : 0.022071
[00:05:51.881] iteration 16461 : model1 loss : 0.020146 model2 loss : 0.019427
[00:05:52.563] iteration 16462 : model1 loss : 0.020934 model2 loss : 0.019009
[00:05:53.237] iteration 16463 : model1 loss : 0.020844 model2 loss : 0.020743
[00:05:53.908] iteration 16464 : model1 loss : 0.027794 model2 loss : 0.031437
[00:05:54.573] iteration 16465 : model1 loss : 0.028535 model2 loss : 0.032672
[00:05:55.242] iteration 16466 : model1 loss : 0.030520 model2 loss : 0.029115
[00:05:55.904] iteration 16467 : model1 loss : 0.017724 model2 loss : 0.017768
[00:05:56.572] iteration 16468 : model1 loss : 0.027219 model2 loss : 0.018712
[00:05:57.240] iteration 16469 : model1 loss : 0.021203 model2 loss : 0.021129
[00:05:57.903] iteration 16470 : model1 loss : 0.029703 model2 loss : 0.035660
[00:05:58.589] iteration 16471 : model1 loss : 0.022007 model2 loss : 0.020618
[00:05:59.259] iteration 16472 : model1 loss : 0.021724 model2 loss : 0.020999
[00:05:59.939] iteration 16473 : model1 loss : 0.018627 model2 loss : 0.019317
[00:06:00.617] iteration 16474 : model1 loss : 0.021929 model2 loss : 0.021561
[00:06:01.289] iteration 16475 : model1 loss : 0.021860 model2 loss : 0.021093
[00:06:01.957] iteration 16476 : model1 loss : 0.016025 model2 loss : 0.016312
[00:06:02.630] iteration 16477 : model1 loss : 0.019334 model2 loss : 0.022825
[00:06:03.306] iteration 16478 : model1 loss : 0.016771 model2 loss : 0.016264
[00:06:03.972] iteration 16479 : model1 loss : 0.017525 model2 loss : 0.018522
[00:06:04.630] iteration 16480 : model1 loss : 0.019352 model2 loss : 0.019546
[00:06:05.292] iteration 16481 : model1 loss : 0.020393 model2 loss : 0.021458
[00:06:05.956] iteration 16482 : model1 loss : 0.021877 model2 loss : 0.023213
[00:06:06.636] iteration 16483 : model1 loss : 0.023649 model2 loss : 0.023093
[00:06:07.302] iteration 16484 : model1 loss : 0.020859 model2 loss : 0.022862
[00:06:07.971] iteration 16485 : model1 loss : 0.020332 model2 loss : 0.019539
[00:06:08.633] iteration 16486 : model1 loss : 0.040774 model2 loss : 0.045550
[00:06:09.300] iteration 16487 : model1 loss : 0.020131 model2 loss : 0.022353
[00:06:09.997] iteration 16488 : model1 loss : 0.019360 model2 loss : 0.018424
[00:06:10.671] iteration 16489 : model1 loss : 0.021128 model2 loss : 0.024396
[00:06:11.359] iteration 16490 : model1 loss : 0.024063 model2 loss : 0.024276
[00:06:12.031] iteration 16491 : model1 loss : 0.021566 model2 loss : 0.022967
[00:06:12.690] iteration 16492 : model1 loss : 0.015954 model2 loss : 0.018327
[00:06:13.367] iteration 16493 : model1 loss : 0.021490 model2 loss : 0.021593
[00:06:14.039] iteration 16494 : model1 loss : 0.018779 model2 loss : 0.021284
[00:06:14.700] iteration 16495 : model1 loss : 0.020245 model2 loss : 0.020335
[00:06:15.383] iteration 16496 : model1 loss : 0.021788 model2 loss : 0.020306
[00:06:16.049] iteration 16497 : model1 loss : 0.026743 model2 loss : 0.027765
[00:06:16.711] iteration 16498 : model1 loss : 0.017811 model2 loss : 0.018896
[00:06:17.381] iteration 16499 : model1 loss : 0.022757 model2 loss : 0.024198
[00:06:18.051] iteration 16500 : model1 loss : 0.020353 model2 loss : 0.018091
[00:06:18.759] iteration 16501 : model1 loss : 0.023166 model2 loss : 0.022398
[00:06:19.440] iteration 16502 : model1 loss : 0.023994 model2 loss : 0.027172
[00:06:20.110] iteration 16503 : model1 loss : 0.019983 model2 loss : 0.021536
[00:06:20.791] iteration 16504 : model1 loss : 0.016284 model2 loss : 0.016139
[00:06:21.473] iteration 16505 : model1 loss : 0.021634 model2 loss : 0.020259
[00:06:22.149] iteration 16506 : model1 loss : 0.041194 model2 loss : 0.039321
[00:06:22.823] iteration 16507 : model1 loss : 0.018451 model2 loss : 0.016747
[00:06:23.584] iteration 16508 : model1 loss : 0.048498 model2 loss : 0.042848
[00:06:24.316] iteration 16509 : model1 loss : 0.020165 model2 loss : 0.019961
[00:06:25.054] iteration 16510 : model1 loss : 0.025519 model2 loss : 0.029691
[00:06:25.742] iteration 16511 : model1 loss : 0.016789 model2 loss : 0.017361
[00:06:26.414] iteration 16512 : model1 loss : 0.019342 model2 loss : 0.017960
[00:06:27.083] iteration 16513 : model1 loss : 0.016634 model2 loss : 0.017451
[00:06:27.744] iteration 16514 : model1 loss : 0.022024 model2 loss : 0.022680
[00:06:28.414] iteration 16515 : model1 loss : 0.039961 model2 loss : 0.038648
[00:06:29.088] iteration 16516 : model1 loss : 0.015283 model2 loss : 0.016157
[00:06:29.752] iteration 16517 : model1 loss : 0.015538 model2 loss : 0.015540
[00:06:30.419] iteration 16518 : model1 loss : 0.018632 model2 loss : 0.018869
[00:06:31.085] iteration 16519 : model1 loss : 0.018872 model2 loss : 0.021720
[00:06:31.760] iteration 16520 : model1 loss : 0.140782 model2 loss : 0.141734
[00:06:32.439] iteration 16521 : model1 loss : 0.025660 model2 loss : 0.020102
[00:06:33.113] iteration 16522 : model1 loss : 0.038065 model2 loss : 0.019171
[00:06:33.790] iteration 16523 : model1 loss : 0.027629 model2 loss : 0.024962
[00:06:34.463] iteration 16524 : model1 loss : 0.023181 model2 loss : 0.023197
[00:06:35.141] iteration 16525 : model1 loss : 0.022452 model2 loss : 0.022551
[00:06:35.809] iteration 16526 : model1 loss : 0.028678 model2 loss : 0.028895
[00:06:36.474] iteration 16527 : model1 loss : 0.022929 model2 loss : 0.022839
[00:06:37.139] iteration 16528 : model1 loss : 0.019657 model2 loss : 0.019640
[00:06:37.792] iteration 16529 : model1 loss : 0.034004 model2 loss : 0.036524
[00:06:38.474] iteration 16530 : model1 loss : 0.017148 model2 loss : 0.016142
[00:06:39.170] iteration 16531 : model1 loss : 0.017119 model2 loss : 0.017510
[00:06:39.823] iteration 16532 : model1 loss : 0.023314 model2 loss : 0.025084
[00:06:40.503] iteration 16533 : model1 loss : 0.017941 model2 loss : 0.019283
[00:06:41.192] iteration 16534 : model1 loss : 0.035878 model2 loss : 0.030472
[00:06:41.860] iteration 16535 : model1 loss : 0.024003 model2 loss : 0.023805
[00:06:42.541] iteration 16536 : model1 loss : 0.020675 model2 loss : 0.024421
[00:06:43.206] iteration 16537 : model1 loss : 0.054262 model2 loss : 0.041231
[00:06:43.882] iteration 16538 : model1 loss : 0.024290 model2 loss : 0.024213
[00:06:44.552] iteration 16539 : model1 loss : 0.019735 model2 loss : 0.022258
[00:06:45.230] iteration 16540 : model1 loss : 0.032067 model2 loss : 0.028125
[00:06:45.901] iteration 16541 : model1 loss : 0.019405 model2 loss : 0.020977
[00:06:46.564] iteration 16542 : model1 loss : 0.047431 model2 loss : 0.036477
[00:06:47.235] iteration 16543 : model1 loss : 0.024539 model2 loss : 0.022182
[00:06:47.900] iteration 16544 : model1 loss : 0.021178 model2 loss : 0.022282
[00:06:48.571] iteration 16545 : model1 loss : 0.020333 model2 loss : 0.020962
[00:06:49.237] iteration 16546 : model1 loss : 0.041936 model2 loss : 0.037715
[00:06:49.911] iteration 16547 : model1 loss : 0.025687 model2 loss : 0.024644
[00:06:50.578] iteration 16548 : model1 loss : 0.033456 model2 loss : 0.031726
[00:06:51.245] iteration 16549 : model1 loss : 0.031848 model2 loss : 0.029925
[00:06:51.926] iteration 16550 : model1 loss : 0.019000 model2 loss : 0.018881
[00:06:52.651] iteration 16551 : model1 loss : 0.023406 model2 loss : 0.022174
[00:06:53.322] iteration 16552 : model1 loss : 0.031076 model2 loss : 0.025025
[00:06:53.990] iteration 16553 : model1 loss : 0.023285 model2 loss : 0.022710
[00:06:54.663] iteration 16554 : model1 loss : 0.020870 model2 loss : 0.019551
[00:06:55.324] iteration 16555 : model1 loss : 0.040397 model2 loss : 0.033683
[00:06:55.995] iteration 16556 : model1 loss : 0.020112 model2 loss : 0.018892
[00:06:56.668] iteration 16557 : model1 loss : 0.025152 model2 loss : 0.018747
[00:06:57.336] iteration 16558 : model1 loss : 0.034995 model2 loss : 0.032016
[00:06:58.008] iteration 16559 : model1 loss : 0.026708 model2 loss : 0.022888
[00:06:58.673] iteration 16560 : model1 loss : 0.024360 model2 loss : 0.024126
[00:06:59.356] iteration 16561 : model1 loss : 0.030144 model2 loss : 0.027049
[00:07:00.021] iteration 16562 : model1 loss : 0.021369 model2 loss : 0.022705
[00:07:00.692] iteration 16563 : model1 loss : 0.017288 model2 loss : 0.020017
[00:07:01.375] iteration 16564 : model1 loss : 0.020119 model2 loss : 0.018043
[00:07:02.047] iteration 16565 : model1 loss : 0.025004 model2 loss : 0.024067
[00:07:02.723] iteration 16566 : model1 loss : 0.017172 model2 loss : 0.016153
[00:07:03.411] iteration 16567 : model1 loss : 0.019174 model2 loss : 0.032512
[00:07:04.078] iteration 16568 : model1 loss : 0.020535 model2 loss : 0.022156
[00:07:04.758] iteration 16569 : model1 loss : 0.032143 model2 loss : 0.030441
[00:07:05.443] iteration 16570 : model1 loss : 0.022660 model2 loss : 0.019359
[00:07:06.112] iteration 16571 : model1 loss : 0.022156 model2 loss : 0.019625
[00:07:06.790] iteration 16572 : model1 loss : 0.020682 model2 loss : 0.018329
[00:07:07.458] iteration 16573 : model1 loss : 0.020546 model2 loss : 0.018224
[00:07:08.135] iteration 16574 : model1 loss : 0.018072 model2 loss : 0.017981
[00:07:08.817] iteration 16575 : model1 loss : 0.017999 model2 loss : 0.018046
[00:07:09.481] iteration 16576 : model1 loss : 0.018578 model2 loss : 0.019434
[00:07:10.141] iteration 16577 : model1 loss : 0.018551 model2 loss : 0.018602
[00:07:10.804] iteration 16578 : model1 loss : 0.018993 model2 loss : 0.018437
[00:07:11.475] iteration 16579 : model1 loss : 0.022966 model2 loss : 0.021633
[00:07:12.153] iteration 16580 : model1 loss : 0.022179 model2 loss : 0.021012
[00:07:12.816] iteration 16581 : model1 loss : 0.028176 model2 loss : 0.025887
[00:07:13.498] iteration 16582 : model1 loss : 0.023571 model2 loss : 0.024947
[00:07:14.168] iteration 16583 : model1 loss : 0.025363 model2 loss : 0.026469
[00:07:14.835] iteration 16584 : model1 loss : 0.021210 model2 loss : 0.018613
[00:07:15.522] iteration 16585 : model1 loss : 0.021661 model2 loss : 0.020772
[00:07:16.190] iteration 16586 : model1 loss : 0.033837 model2 loss : 0.032419
[00:07:16.857] iteration 16587 : model1 loss : 0.022962 model2 loss : 0.020074
[00:07:17.529] iteration 16588 : model1 loss : 0.016464 model2 loss : 0.018581
[00:07:18.192] iteration 16589 : model1 loss : 0.029163 model2 loss : 0.032342
[00:07:18.877] iteration 16590 : model1 loss : 0.017475 model2 loss : 0.017483
[00:07:19.564] iteration 16591 : model1 loss : 0.026950 model2 loss : 0.023978
[00:07:20.237] iteration 16592 : model1 loss : 0.023199 model2 loss : 0.027693
[00:07:20.913] iteration 16593 : model1 loss : 0.028935 model2 loss : 0.024796
[00:07:21.579] iteration 16594 : model1 loss : 0.021108 model2 loss : 0.019068
[00:07:22.253] iteration 16595 : model1 loss : 0.018888 model2 loss : 0.022556
[00:07:22.927] iteration 16596 : model1 loss : 0.020214 model2 loss : 0.018123
[00:07:23.601] iteration 16597 : model1 loss : 0.020088 model2 loss : 0.018648
[00:07:24.276] iteration 16598 : model1 loss : 0.019637 model2 loss : 0.022487
[00:07:24.945] iteration 16599 : model1 loss : 0.014643 model2 loss : 0.012552
[00:07:25.620] iteration 16600 : model1 loss : 0.017518 model2 loss : 0.018047
[00:07:43.985] iteration 16600 : model1_mean_dice : 0.864271 model1_mean_hd95 : 2.330275
[00:08:02.339] iteration 16600 : model2_mean_dice : 0.863411 model2_mean_hd95 : 5.015539
[00:08:03.019] iteration 16601 : model1 loss : 0.023884 model2 loss : 0.023520
[00:08:03.698] iteration 16602 : model1 loss : 0.019889 model2 loss : 0.021642
[00:08:04.381] iteration 16603 : model1 loss : 0.020704 model2 loss : 0.018995
[00:08:05.038] iteration 16604 : model1 loss : 0.027973 model2 loss : 0.025068
[00:08:05.709] iteration 16605 : model1 loss : 0.031152 model2 loss : 0.029423
[00:08:06.376] iteration 16606 : model1 loss : 0.040822 model2 loss : 0.037774
[00:08:07.041] iteration 16607 : model1 loss : 0.018435 model2 loss : 0.018305
[00:08:07.708] iteration 16608 : model1 loss : 0.024364 model2 loss : 0.022404
[00:08:08.374] iteration 16609 : model1 loss : 0.028530 model2 loss : 0.027571
[00:08:09.038] iteration 16610 : model1 loss : 0.019518 model2 loss : 0.021049
[00:08:09.696] iteration 16611 : model1 loss : 0.144398 model2 loss : 0.146495
[00:08:10.366] iteration 16612 : model1 loss : 0.019318 model2 loss : 0.019968
[00:08:11.023] iteration 16613 : model1 loss : 0.023234 model2 loss : 0.021312
[00:08:11.684] iteration 16614 : model1 loss : 0.016811 model2 loss : 0.016973
[00:08:12.353] iteration 16615 : model1 loss : 0.018393 model2 loss : 0.018032
[00:08:13.006] iteration 16616 : model1 loss : 0.095239 model2 loss : 0.105611
[00:08:13.671] iteration 16617 : model1 loss : 0.019988 model2 loss : 0.020445
[00:08:14.340] iteration 16618 : model1 loss : 0.020577 model2 loss : 0.023240
[00:08:14.994] iteration 16619 : model1 loss : 0.019540 model2 loss : 0.017233
[00:08:15.650] iteration 16620 : model1 loss : 0.022319 model2 loss : 0.023596
[00:08:16.309] iteration 16621 : model1 loss : 0.017887 model2 loss : 0.018345
[00:08:16.965] iteration 16622 : model1 loss : 0.019644 model2 loss : 0.019617
[00:08:17.634] iteration 16623 : model1 loss : 0.026727 model2 loss : 0.025119
[00:08:18.318] iteration 16624 : model1 loss : 0.032425 model2 loss : 0.023070
[00:08:18.991] iteration 16625 : model1 loss : 0.142897 model2 loss : 0.097300
[00:08:19.664] iteration 16626 : model1 loss : 0.021931 model2 loss : 0.021466
[00:08:20.323] iteration 16627 : model1 loss : 0.011843 model2 loss : 0.011879
[00:08:20.993] iteration 16628 : model1 loss : 0.019672 model2 loss : 0.017650
[00:08:21.654] iteration 16629 : model1 loss : 0.018748 model2 loss : 0.029245
[00:08:22.321] iteration 16630 : model1 loss : 0.019154 model2 loss : 0.018359
[00:08:22.992] iteration 16631 : model1 loss : 0.022322 model2 loss : 0.023296
[00:08:23.656] iteration 16632 : model1 loss : 0.024945 model2 loss : 0.026075
[00:08:24.337] iteration 16633 : model1 loss : 0.021161 model2 loss : 0.021492
[00:08:25.000] iteration 16634 : model1 loss : 0.022231 model2 loss : 0.020301
[00:08:25.668] iteration 16635 : model1 loss : 0.016812 model2 loss : 0.019562
[00:08:26.334] iteration 16636 : model1 loss : 0.021149 model2 loss : 0.022964
[00:08:27.002] iteration 16637 : model1 loss : 0.018555 model2 loss : 0.020535
[00:08:27.675] iteration 16638 : model1 loss : 0.019343 model2 loss : 0.018271
[00:08:28.346] iteration 16639 : model1 loss : 0.045877 model2 loss : 0.092839
[00:08:29.008] iteration 16640 : model1 loss : 0.016158 model2 loss : 0.019880
[00:08:29.664] iteration 16641 : model1 loss : 0.018744 model2 loss : 0.021812
[00:08:30.337] iteration 16642 : model1 loss : 0.056783 model2 loss : 0.067395
[00:08:31.051] iteration 16643 : model1 loss : 0.019928 model2 loss : 0.017524
[00:08:31.882] iteration 16644 : model1 loss : 0.047870 model2 loss : 0.039682
[00:08:32.678] iteration 16645 : model1 loss : 0.128206 model2 loss : 0.046683
[00:08:33.418] iteration 16646 : model1 loss : 0.017198 model2 loss : 0.021643
[00:08:34.152] iteration 16647 : model1 loss : 0.052947 model2 loss : 0.047314
[00:08:34.883] iteration 16648 : model1 loss : 0.021569 model2 loss : 0.024696
[00:08:35.620] iteration 16649 : model1 loss : 0.027292 model2 loss : 0.026941
[00:08:36.357] iteration 16650 : model1 loss : 0.020475 model2 loss : 0.022370
[00:08:37.153] iteration 16651 : model1 loss : 0.026468 model2 loss : 0.024692
[00:08:37.895] iteration 16652 : model1 loss : 0.042092 model2 loss : 0.020647
[00:08:38.640] iteration 16653 : model1 loss : 0.034831 model2 loss : 0.027425
[00:08:39.378] iteration 16654 : model1 loss : 0.025176 model2 loss : 0.021669
[00:08:40.113] iteration 16655 : model1 loss : 0.030488 model2 loss : 0.028159
[00:08:40.842] iteration 16656 : model1 loss : 0.018577 model2 loss : 0.020432
[00:08:41.646] iteration 16657 : model1 loss : 0.029383 model2 loss : 0.027575
[00:08:42.457] iteration 16658 : model1 loss : 0.019168 model2 loss : 0.019372
[00:08:43.321] iteration 16659 : model1 loss : 0.021600 model2 loss : 0.022018
[00:08:44.115] iteration 16660 : model1 loss : 0.023728 model2 loss : 0.023937
[00:08:44.921] iteration 16661 : model1 loss : 0.026083 model2 loss : 0.029240
[00:08:45.715] iteration 16662 : model1 loss : 0.026886 model2 loss : 0.023844
[00:08:46.533] iteration 16663 : model1 loss : 0.017868 model2 loss : 0.020311
[00:08:47.336] iteration 16664 : model1 loss : 0.019599 model2 loss : 0.021128
[00:08:48.125] iteration 16665 : model1 loss : 0.021520 model2 loss : 0.020890
[00:08:48.888] iteration 16666 : model1 loss : 0.025279 model2 loss : 0.022253
[00:08:49.629] iteration 16667 : model1 loss : 0.027176 model2 loss : 0.027752
[00:08:50.357] iteration 16668 : model1 loss : 0.026921 model2 loss : 0.030063
[00:08:51.100] iteration 16669 : model1 loss : 0.020317 model2 loss : 0.019366
[00:08:51.834] iteration 16670 : model1 loss : 0.021372 model2 loss : 0.020079
[00:08:52.645] iteration 16671 : model1 loss : 0.018775 model2 loss : 0.021131
[00:08:53.394] iteration 16672 : model1 loss : 0.018889 model2 loss : 0.018398
[00:08:54.137] iteration 16673 : model1 loss : 0.021393 model2 loss : 0.025118
[00:08:54.933] iteration 16674 : model1 loss : 0.026524 model2 loss : 0.025210
[00:08:55.696] iteration 16675 : model1 loss : 0.018597 model2 loss : 0.017745
[00:08:56.426] iteration 16676 : model1 loss : 0.020779 model2 loss : 0.022459
[00:08:57.182] iteration 16677 : model1 loss : 0.028693 model2 loss : 0.029211
[00:08:57.947] iteration 16678 : model1 loss : 0.030383 model2 loss : 0.028020
[00:08:58.713] iteration 16679 : model1 loss : 0.029301 model2 loss : 0.032985
[00:08:59.464] iteration 16680 : model1 loss : 0.022906 model2 loss : 0.020359
[00:09:00.235] iteration 16681 : model1 loss : 0.031310 model2 loss : 0.029398
[00:09:00.976] iteration 16682 : model1 loss : 0.033210 model2 loss : 0.034953
[00:09:01.724] iteration 16683 : model1 loss : 0.021330 model2 loss : 0.021742
[00:09:02.524] iteration 16684 : model1 loss : 0.022199 model2 loss : 0.026578
[00:09:03.281] iteration 16685 : model1 loss : 0.026783 model2 loss : 0.030082
[00:09:04.027] iteration 16686 : model1 loss : 0.020550 model2 loss : 0.022283
[00:09:04.769] iteration 16687 : model1 loss : 0.019244 model2 loss : 0.022355
[00:09:05.514] iteration 16688 : model1 loss : 0.020981 model2 loss : 0.018934
[00:09:06.283] iteration 16689 : model1 loss : 0.021629 model2 loss : 0.020204
[00:09:07.073] iteration 16690 : model1 loss : 0.026781 model2 loss : 0.030492
[00:09:07.840] iteration 16691 : model1 loss : 0.018135 model2 loss : 0.017833
[00:09:08.647] iteration 16692 : model1 loss : 0.026438 model2 loss : 0.027262
[00:09:09.465] iteration 16693 : model1 loss : 0.024031 model2 loss : 0.026417
[00:09:10.272] iteration 16694 : model1 loss : 0.023050 model2 loss : 0.023625
[00:09:11.054] iteration 16695 : model1 loss : 0.020912 model2 loss : 0.020524
[00:09:11.841] iteration 16696 : model1 loss : 0.022701 model2 loss : 0.021305
[00:09:12.628] iteration 16697 : model1 loss : 0.026712 model2 loss : 0.022552
[00:09:13.355] iteration 16698 : model1 loss : 0.014892 model2 loss : 0.012983
[00:09:14.081] iteration 16699 : model1 loss : 0.025044 model2 loss : 0.024095
[00:09:14.836] iteration 16700 : model1 loss : 0.021923 model2 loss : 0.022692
[00:09:15.590] iteration 16701 : model1 loss : 0.018077 model2 loss : 0.018122
[00:09:16.316] iteration 16702 : model1 loss : 0.019289 model2 loss : 0.018281
[00:09:17.073] iteration 16703 : model1 loss : 0.021472 model2 loss : 0.020707
[00:09:17.821] iteration 16704 : model1 loss : 0.028397 model2 loss : 0.025374
[00:09:18.554] iteration 16705 : model1 loss : 0.016673 model2 loss : 0.018561
[00:09:19.301] iteration 16706 : model1 loss : 0.020706 model2 loss : 0.020922
[00:09:20.050] iteration 16707 : model1 loss : 0.021768 model2 loss : 0.020519
[00:09:20.835] iteration 16708 : model1 loss : 0.022688 model2 loss : 0.021743
[00:09:21.582] iteration 16709 : model1 loss : 0.026782 model2 loss : 0.041126
[00:09:22.340] iteration 16710 : model1 loss : 0.025460 model2 loss : 0.024596
[00:09:23.081] iteration 16711 : model1 loss : 0.034335 model2 loss : 0.035785
[00:09:23.852] iteration 16712 : model1 loss : 0.023237 model2 loss : 0.023839
[00:09:24.599] iteration 16713 : model1 loss : 0.022645 model2 loss : 0.021933
[00:09:25.368] iteration 16714 : model1 loss : 0.018464 model2 loss : 0.019295
[00:09:26.111] iteration 16715 : model1 loss : 0.015525 model2 loss : 0.015631
[00:09:26.855] iteration 16716 : model1 loss : 0.025333 model2 loss : 0.026850
[00:09:27.625] iteration 16717 : model1 loss : 0.028420 model2 loss : 0.031879
[00:09:28.371] iteration 16718 : model1 loss : 0.020384 model2 loss : 0.019169
[00:09:29.148] iteration 16719 : model1 loss : 0.020548 model2 loss : 0.019930
[00:09:29.906] iteration 16720 : model1 loss : 0.019926 model2 loss : 0.020104
[00:09:30.708] iteration 16721 : model1 loss : 0.033146 model2 loss : 0.030954
[00:09:31.427] iteration 16722 : model1 loss : 0.039389 model2 loss : 0.032838
[00:09:32.161] iteration 16723 : model1 loss : 0.022397 model2 loss : 0.021847
[00:09:32.899] iteration 16724 : model1 loss : 0.058480 model2 loss : 0.061325
[00:09:33.659] iteration 16725 : model1 loss : 0.016840 model2 loss : 0.015318
[00:09:34.380] iteration 16726 : model1 loss : 0.026280 model2 loss : 0.029032
[00:09:35.091] iteration 16727 : model1 loss : 0.018915 model2 loss : 0.020660
[00:09:35.791] iteration 16728 : model1 loss : 0.024761 model2 loss : 0.023320
[00:09:36.498] iteration 16729 : model1 loss : 0.018579 model2 loss : 0.018830
[00:09:37.252] iteration 16730 : model1 loss : 0.023360 model2 loss : 0.022400
[00:09:37.959] iteration 16731 : model1 loss : 0.021455 model2 loss : 0.022644
[00:09:38.660] iteration 16732 : model1 loss : 0.020371 model2 loss : 0.019492
[00:09:39.395] iteration 16733 : model1 loss : 0.025260 model2 loss : 0.024141
[00:09:40.101] iteration 16734 : model1 loss : 0.017001 model2 loss : 0.017585
[00:09:40.818] iteration 16735 : model1 loss : 0.017026 model2 loss : 0.017164
[00:09:41.529] iteration 16736 : model1 loss : 0.375695 model2 loss : 0.375818
[00:09:42.271] iteration 16737 : model1 loss : 0.032199 model2 loss : 0.031918
[00:09:42.983] iteration 16738 : model1 loss : 0.046255 model2 loss : 0.052140
[00:09:43.683] iteration 16739 : model1 loss : 0.022501 model2 loss : 0.021061
[00:09:44.407] iteration 16740 : model1 loss : 0.018713 model2 loss : 0.018322
[00:09:45.118] iteration 16741 : model1 loss : 0.017797 model2 loss : 0.020140
[00:09:45.818] iteration 16742 : model1 loss : 0.025959 model2 loss : 0.027132
[00:09:46.523] iteration 16743 : model1 loss : 0.018843 model2 loss : 0.016979
[00:09:47.276] iteration 16744 : model1 loss : 0.018366 model2 loss : 0.020146
[00:09:47.976] iteration 16745 : model1 loss : 0.020627 model2 loss : 0.020590
[00:09:48.676] iteration 16746 : model1 loss : 0.017128 model2 loss : 0.019643
[00:09:49.388] iteration 16747 : model1 loss : 0.018567 model2 loss : 0.020002
[00:09:50.092] iteration 16748 : model1 loss : 0.018385 model2 loss : 0.019114
[00:09:50.788] iteration 16749 : model1 loss : 0.027375 model2 loss : 0.030351
[00:09:51.486] iteration 16750 : model1 loss : 0.026017 model2 loss : 0.023251
[00:09:52.277] iteration 16751 : model1 loss : 0.020978 model2 loss : 0.020510
[00:09:53.019] iteration 16752 : model1 loss : 0.018895 model2 loss : 0.021103
[00:09:53.741] iteration 16753 : model1 loss : 0.019347 model2 loss : 0.018572
[00:09:54.438] iteration 16754 : model1 loss : 0.017988 model2 loss : 0.017814
[00:09:55.176] iteration 16755 : model1 loss : 0.023410 model2 loss : 0.021202
[00:09:55.876] iteration 16756 : model1 loss : 0.017696 model2 loss : 0.016627
[00:09:56.573] iteration 16757 : model1 loss : 0.024910 model2 loss : 0.020745
[00:09:57.316] iteration 16758 : model1 loss : 0.026577 model2 loss : 0.023975
[00:09:58.017] iteration 16759 : model1 loss : 0.025437 model2 loss : 0.028791
[00:09:58.726] iteration 16760 : model1 loss : 0.020114 model2 loss : 0.021753
[00:09:59.428] iteration 16761 : model1 loss : 0.030942 model2 loss : 0.032682
[00:10:00.123] iteration 16762 : model1 loss : 0.022456 model2 loss : 0.020848
[00:10:00.826] iteration 16763 : model1 loss : 0.017404 model2 loss : 0.019413
[00:10:01.529] iteration 16764 : model1 loss : 0.025066 model2 loss : 0.024839
[00:10:02.280] iteration 16765 : model1 loss : 0.062019 model2 loss : 0.050062
[00:10:03.003] iteration 16766 : model1 loss : 0.021410 model2 loss : 0.022437
[00:10:03.709] iteration 16767 : model1 loss : 0.022466 model2 loss : 0.022404
[00:10:04.406] iteration 16768 : model1 loss : 0.029929 model2 loss : 0.027356
[00:10:05.126] iteration 16769 : model1 loss : 0.027249 model2 loss : 0.020923
[00:10:05.824] iteration 16770 : model1 loss : 0.024028 model2 loss : 0.027049
[00:10:06.518] iteration 16771 : model1 loss : 0.019984 model2 loss : 0.017179
[00:10:07.272] iteration 16772 : model1 loss : 0.018278 model2 loss : 0.019475
[00:10:07.979] iteration 16773 : model1 loss : 0.028535 model2 loss : 0.027274
[00:10:08.692] iteration 16774 : model1 loss : 0.014623 model2 loss : 0.016755
[00:10:09.397] iteration 16775 : model1 loss : 0.024413 model2 loss : 0.023711
[00:10:10.103] iteration 16776 : model1 loss : 0.018607 model2 loss : 0.017991
[00:10:10.808] iteration 16777 : model1 loss : 0.023735 model2 loss : 0.022551
[00:10:11.518] iteration 16778 : model1 loss : 0.024180 model2 loss : 0.028578
[00:10:12.261] iteration 16779 : model1 loss : 0.017703 model2 loss : 0.015439
[00:10:12.968] iteration 16780 : model1 loss : 0.020192 model2 loss : 0.020308
[00:10:13.677] iteration 16781 : model1 loss : 0.021108 model2 loss : 0.022283
[00:10:14.381] iteration 16782 : model1 loss : 0.033360 model2 loss : 0.022089
[00:10:15.092] iteration 16783 : model1 loss : 0.030660 model2 loss : 0.029566
[00:10:15.817] iteration 16784 : model1 loss : 0.030119 model2 loss : 0.024731
[00:10:16.522] iteration 16785 : model1 loss : 0.020164 model2 loss : 0.020276
[00:10:17.273] iteration 16786 : model1 loss : 0.023709 model2 loss : 0.022680
[00:10:17.976] iteration 16787 : model1 loss : 0.053735 model2 loss : 0.041862
[00:10:18.677] iteration 16788 : model1 loss : 0.027142 model2 loss : 0.026327
[00:10:19.386] iteration 16789 : model1 loss : 0.017778 model2 loss : 0.018355
[00:10:20.099] iteration 16790 : model1 loss : 0.018453 model2 loss : 0.019270
[00:10:20.811] iteration 16791 : model1 loss : 0.026915 model2 loss : 0.028624
[00:10:21.506] iteration 16792 : model1 loss : 0.022096 model2 loss : 0.020757
[00:10:22.258] iteration 16793 : model1 loss : 0.022008 model2 loss : 0.026638
[00:10:22.995] iteration 16794 : model1 loss : 0.149355 model2 loss : 0.143570
[00:10:23.717] iteration 16795 : model1 loss : 0.031982 model2 loss : 0.022946
[00:10:24.416] iteration 16796 : model1 loss : 0.015109 model2 loss : 0.015927
[00:10:25.127] iteration 16797 : model1 loss : 0.057405 model2 loss : 0.076199
[00:10:25.838] iteration 16798 : model1 loss : 0.018981 model2 loss : 0.020389
[00:10:26.602] iteration 16799 : model1 loss : 0.021823 model2 loss : 0.021782
[00:10:27.352] iteration 16800 : model1 loss : 0.026167 model2 loss : 0.023981
[00:10:47.397] iteration 16800 : model1_mean_dice : 0.863504 model1_mean_hd95 : 6.070522
[00:11:07.275] iteration 16800 : model2_mean_dice : 0.871583 model2_mean_hd95 : 4.810490
[00:11:08.029] iteration 16801 : model1 loss : 0.020432 model2 loss : 0.020181
[00:11:08.731] iteration 16802 : model1 loss : 0.022644 model2 loss : 0.024362
[00:11:09.438] iteration 16803 : model1 loss : 0.016941 model2 loss : 0.016829
[00:11:10.134] iteration 16804 : model1 loss : 0.021631 model2 loss : 0.023833
[00:11:10.838] iteration 16805 : model1 loss : 0.044926 model2 loss : 0.041656
[00:11:11.535] iteration 16806 : model1 loss : 0.014374 model2 loss : 0.013311
[00:11:12.281] iteration 16807 : model1 loss : 0.144376 model2 loss : 0.143144
[00:11:12.979] iteration 16808 : model1 loss : 0.023235 model2 loss : 0.024649
[00:11:13.693] iteration 16809 : model1 loss : 0.029677 model2 loss : 0.024246
[00:11:14.397] iteration 16810 : model1 loss : 0.017993 model2 loss : 0.018951
[00:11:15.102] iteration 16811 : model1 loss : 0.028343 model2 loss : 0.027612
[00:11:15.804] iteration 16812 : model1 loss : 0.032690 model2 loss : 0.023790
[00:11:16.501] iteration 16813 : model1 loss : 0.018264 model2 loss : 0.016988
[00:11:17.227] iteration 16814 : model1 loss : 0.023912 model2 loss : 0.024555
[00:11:17.942] iteration 16815 : model1 loss : 0.020408 model2 loss : 0.022777
[00:11:18.645] iteration 16816 : model1 loss : 0.019960 model2 loss : 0.021140
[00:11:19.389] iteration 16817 : model1 loss : 0.022166 model2 loss : 0.020972
[00:11:20.091] iteration 16818 : model1 loss : 0.020019 model2 loss : 0.023360
[00:11:20.791] iteration 16819 : model1 loss : 0.020877 model2 loss : 0.020824
[00:11:21.496] iteration 16820 : model1 loss : 0.025129 model2 loss : 0.025920
[00:11:22.247] iteration 16821 : model1 loss : 0.019074 model2 loss : 0.023113
[00:11:22.970] iteration 16822 : model1 loss : 0.017550 model2 loss : 0.017333
[00:11:23.685] iteration 16823 : model1 loss : 0.017981 model2 loss : 0.019123
[00:11:24.385] iteration 16824 : model1 loss : 0.021806 model2 loss : 0.019383
[00:11:25.089] iteration 16825 : model1 loss : 0.018617 model2 loss : 0.018541
[00:11:25.793] iteration 16826 : model1 loss : 0.022924 model2 loss : 0.022028
[00:11:26.487] iteration 16827 : model1 loss : 0.150794 model2 loss : 0.151477
[00:11:27.220] iteration 16828 : model1 loss : 0.026686 model2 loss : 0.026214
[00:11:27.937] iteration 16829 : model1 loss : 0.025764 model2 loss : 0.026150
[00:11:28.635] iteration 16830 : model1 loss : 0.023711 model2 loss : 0.023156
[00:11:29.343] iteration 16831 : model1 loss : 0.020726 model2 loss : 0.020473
[00:11:30.052] iteration 16832 : model1 loss : 0.029477 model2 loss : 0.033981
[00:11:30.743] iteration 16833 : model1 loss : 0.019599 model2 loss : 0.019533
[00:11:31.459] iteration 16834 : model1 loss : 0.031837 model2 loss : 0.029024
[00:11:32.196] iteration 16835 : model1 loss : 0.024733 model2 loss : 0.023022
[00:11:32.906] iteration 16836 : model1 loss : 0.022269 model2 loss : 0.021802
[00:11:33.599] iteration 16837 : model1 loss : 0.020830 model2 loss : 0.024115
[00:11:34.301] iteration 16838 : model1 loss : 0.025611 model2 loss : 0.022111
[00:11:35.000] iteration 16839 : model1 loss : 0.021965 model2 loss : 0.021775
[00:11:35.711] iteration 16840 : model1 loss : 0.022081 model2 loss : 0.023348
[00:11:36.413] iteration 16841 : model1 loss : 0.018600 model2 loss : 0.018928
[00:11:37.142] iteration 16842 : model1 loss : 0.019142 model2 loss : 0.019568
[00:11:37.864] iteration 16843 : model1 loss : 0.022113 model2 loss : 0.025432
[00:11:38.575] iteration 16844 : model1 loss : 0.020243 model2 loss : 0.020433
[00:11:39.293] iteration 16845 : model1 loss : 0.017953 model2 loss : 0.018542
[00:11:39.996] iteration 16846 : model1 loss : 0.018339 model2 loss : 0.019530
[00:11:40.691] iteration 16847 : model1 loss : 0.024087 model2 loss : 0.020782
[00:11:41.399] iteration 16848 : model1 loss : 0.017138 model2 loss : 0.018460
[00:11:42.133] iteration 16849 : model1 loss : 0.022506 model2 loss : 0.021890
[00:11:42.848] iteration 16850 : model1 loss : 0.018046 model2 loss : 0.017946
[00:11:43.596] iteration 16851 : model1 loss : 0.019553 model2 loss : 0.020587
[00:11:44.304] iteration 16852 : model1 loss : 0.034697 model2 loss : 0.034959
[00:11:45.007] iteration 16853 : model1 loss : 0.023520 model2 loss : 0.022799
[00:11:45.715] iteration 16854 : model1 loss : 0.026768 model2 loss : 0.024573
[00:11:46.422] iteration 16855 : model1 loss : 0.017107 model2 loss : 0.017613
[00:11:47.175] iteration 16856 : model1 loss : 0.028879 model2 loss : 0.030595
[00:11:47.893] iteration 16857 : model1 loss : 0.023689 model2 loss : 0.023365
[00:11:48.607] iteration 16858 : model1 loss : 0.023796 model2 loss : 0.024957
[00:11:49.311] iteration 16859 : model1 loss : 0.024237 model2 loss : 0.024525
[00:11:50.011] iteration 16860 : model1 loss : 0.051598 model2 loss : 0.046996
[00:11:50.705] iteration 16861 : model1 loss : 0.021897 model2 loss : 0.021014
[00:11:51.402] iteration 16862 : model1 loss : 0.023463 model2 loss : 0.021074
[00:11:52.144] iteration 16863 : model1 loss : 0.017716 model2 loss : 0.016548
[00:11:52.880] iteration 16864 : model1 loss : 0.015956 model2 loss : 0.017429
[00:11:53.577] iteration 16865 : model1 loss : 0.021564 model2 loss : 0.020100
[00:11:54.329] iteration 16866 : model1 loss : 0.024044 model2 loss : 0.024349
[00:11:55.022] iteration 16867 : model1 loss : 0.027374 model2 loss : 0.030281
[00:11:55.720] iteration 16868 : model1 loss : 0.020876 model2 loss : 0.017436
[00:11:56.434] iteration 16869 : model1 loss : 0.019811 model2 loss : 0.018000
[00:11:57.167] iteration 16870 : model1 loss : 0.017922 model2 loss : 0.019076
[00:11:57.891] iteration 16871 : model1 loss : 0.031122 model2 loss : 0.031651
[00:11:58.587] iteration 16872 : model1 loss : 0.015268 model2 loss : 0.014871
[00:11:59.288] iteration 16873 : model1 loss : 0.025052 model2 loss : 0.026036
[00:12:00.000] iteration 16874 : model1 loss : 0.013551 model2 loss : 0.013853
[00:12:00.711] iteration 16875 : model1 loss : 0.023740 model2 loss : 0.024928
[00:12:01.425] iteration 16876 : model1 loss : 0.033293 model2 loss : 0.028670
[00:12:02.165] iteration 16877 : model1 loss : 0.021034 model2 loss : 0.021738
[00:12:02.881] iteration 16878 : model1 loss : 0.019052 model2 loss : 0.020846
[00:12:03.586] iteration 16879 : model1 loss : 0.019118 model2 loss : 0.020073
[00:12:04.301] iteration 16880 : model1 loss : 0.014715 model2 loss : 0.013257
[00:12:04.996] iteration 16881 : model1 loss : 0.028570 model2 loss : 0.029321
[00:12:05.692] iteration 16882 : model1 loss : 0.020833 model2 loss : 0.020600
[00:12:06.405] iteration 16883 : model1 loss : 0.015556 model2 loss : 0.016054
[00:12:07.136] iteration 16884 : model1 loss : 0.017851 model2 loss : 0.016753
[00:12:07.838] iteration 16885 : model1 loss : 0.020689 model2 loss : 0.023523
[00:12:08.541] iteration 16886 : model1 loss : 0.017714 model2 loss : 0.017840
[00:12:09.237] iteration 16887 : model1 loss : 0.017108 model2 loss : 0.017928
[00:12:09.947] iteration 16888 : model1 loss : 0.019606 model2 loss : 0.019259
[00:12:10.657] iteration 16889 : model1 loss : 0.020608 model2 loss : 0.020389
[00:12:11.370] iteration 16890 : model1 loss : 0.022229 model2 loss : 0.025559
[00:12:12.104] iteration 16891 : model1 loss : 0.037397 model2 loss : 0.034286
[00:12:12.831] iteration 16892 : model1 loss : 0.022630 model2 loss : 0.022479
[00:12:13.546] iteration 16893 : model1 loss : 0.023591 model2 loss : 0.028487
[00:12:14.249] iteration 16894 : model1 loss : 0.018164 model2 loss : 0.017524
[00:12:14.943] iteration 16895 : model1 loss : 0.017362 model2 loss : 0.017906
[00:12:15.653] iteration 16896 : model1 loss : 0.017374 model2 loss : 0.017668
[00:12:16.369] iteration 16897 : model1 loss : 0.022650 model2 loss : 0.022595
[00:12:17.100] iteration 16898 : model1 loss : 0.021740 model2 loss : 0.019424
[00:12:17.814] iteration 16899 : model1 loss : 0.021605 model2 loss : 0.020293
[00:12:18.525] iteration 16900 : model1 loss : 0.017841 model2 loss : 0.018792
[00:12:19.264] iteration 16901 : model1 loss : 0.017509 model2 loss : 0.017295
[00:12:19.962] iteration 16902 : model1 loss : 0.014919 model2 loss : 0.015754
[00:12:20.664] iteration 16903 : model1 loss : 0.020849 model2 loss : 0.020529
[00:12:21.374] iteration 16904 : model1 loss : 0.026153 model2 loss : 0.021947
[00:12:22.109] iteration 16905 : model1 loss : 0.028550 model2 loss : 0.031888
[00:12:22.831] iteration 16906 : model1 loss : 0.028454 model2 loss : 0.027155
[00:12:23.553] iteration 16907 : model1 loss : 0.030842 model2 loss : 0.031164
[00:12:24.269] iteration 16908 : model1 loss : 0.157452 model2 loss : 0.147568
[00:12:24.975] iteration 16909 : model1 loss : 0.024354 model2 loss : 0.020900
[00:12:25.672] iteration 16910 : model1 loss : 0.022443 model2 loss : 0.022651
[00:12:26.386] iteration 16911 : model1 loss : 0.016353 model2 loss : 0.015305
[00:12:27.118] iteration 16912 : model1 loss : 0.030337 model2 loss : 0.022966
[00:12:27.842] iteration 16913 : model1 loss : 0.035036 model2 loss : 0.029426
[00:12:28.549] iteration 16914 : model1 loss : 0.038350 model2 loss : 0.037234
[00:12:29.267] iteration 16915 : model1 loss : 0.025541 model2 loss : 0.026530
[00:12:29.985] iteration 16916 : model1 loss : 0.022789 model2 loss : 0.024257
[00:12:30.680] iteration 16917 : model1 loss : 0.022748 model2 loss : 0.025311
[00:12:31.395] iteration 16918 : model1 loss : 0.029883 model2 loss : 0.026408
[00:12:32.122] iteration 16919 : model1 loss : 0.016618 model2 loss : 0.017510
[00:12:32.845] iteration 16920 : model1 loss : 0.019748 model2 loss : 0.020401
[00:12:33.581] iteration 16921 : model1 loss : 0.020886 model2 loss : 0.020977
[00:12:34.304] iteration 16922 : model1 loss : 0.019975 model2 loss : 0.020444
[00:12:35.054] iteration 16923 : model1 loss : 0.026600 model2 loss : 0.026091
[00:12:35.781] iteration 16924 : model1 loss : 0.022292 model2 loss : 0.020409
[00:12:36.514] iteration 16925 : model1 loss : 0.021168 model2 loss : 0.020950
[00:12:37.286] iteration 16926 : model1 loss : 0.013943 model2 loss : 0.014949
[00:12:38.027] iteration 16927 : model1 loss : 0.064413 model2 loss : 0.060531
[00:12:38.776] iteration 16928 : model1 loss : 0.020338 model2 loss : 0.021441
[00:12:39.488] iteration 16929 : model1 loss : 0.024084 model2 loss : 0.021544
[00:12:40.182] iteration 16930 : model1 loss : 0.021979 model2 loss : 0.023223
[00:12:40.884] iteration 16931 : model1 loss : 0.019681 model2 loss : 0.020539
[00:12:41.588] iteration 16932 : model1 loss : 0.022850 model2 loss : 0.022231
[00:12:42.338] iteration 16933 : model1 loss : 0.017745 model2 loss : 0.016332
[00:12:43.055] iteration 16934 : model1 loss : 0.020450 model2 loss : 0.020279
[00:12:43.774] iteration 16935 : model1 loss : 0.021092 model2 loss : 0.022154
[00:12:44.472] iteration 16936 : model1 loss : 0.029639 model2 loss : 0.032725
[00:12:45.208] iteration 16937 : model1 loss : 0.026326 model2 loss : 0.027816
[00:12:45.923] iteration 16938 : model1 loss : 0.020175 model2 loss : 0.022005
[00:12:46.638] iteration 16939 : model1 loss : 0.025033 model2 loss : 0.024772
[00:12:47.401] iteration 16940 : model1 loss : 0.022121 model2 loss : 0.020384
[00:12:48.124] iteration 16941 : model1 loss : 0.025351 model2 loss : 0.023037
[00:12:48.861] iteration 16942 : model1 loss : 0.022183 model2 loss : 0.019234
[00:12:49.569] iteration 16943 : model1 loss : 0.037079 model2 loss : 0.029029
[00:12:50.271] iteration 16944 : model1 loss : 0.023945 model2 loss : 0.022656
[00:12:50.972] iteration 16945 : model1 loss : 0.018852 model2 loss : 0.019782
[00:12:51.676] iteration 16946 : model1 loss : 0.022627 model2 loss : 0.021587
[00:12:52.429] iteration 16947 : model1 loss : 0.017728 model2 loss : 0.018510
[00:12:53.144] iteration 16948 : model1 loss : 0.018377 model2 loss : 0.018922
[00:12:53.838] iteration 16949 : model1 loss : 0.019473 model2 loss : 0.021424
[00:12:54.569] iteration 16950 : model1 loss : 0.019901 model2 loss : 0.020860
[00:12:55.315] iteration 16951 : model1 loss : 0.032742 model2 loss : 0.025642
[00:12:56.056] iteration 16952 : model1 loss : 0.019942 model2 loss : 0.019438
[00:12:56.792] iteration 16953 : model1 loss : 0.042435 model2 loss : 0.041299
[00:12:57.547] iteration 16954 : model1 loss : 0.031801 model2 loss : 0.027101
[00:12:58.251] iteration 16955 : model1 loss : 0.021773 model2 loss : 0.021241
[00:12:58.988] iteration 16956 : model1 loss : 0.016068 model2 loss : 0.019467
[00:12:59.718] iteration 16957 : model1 loss : 0.017924 model2 loss : 0.017637
[00:13:00.423] iteration 16958 : model1 loss : 0.024008 model2 loss : 0.025071
[00:13:01.116] iteration 16959 : model1 loss : 0.027602 model2 loss : 0.028270
[00:13:01.832] iteration 16960 : model1 loss : 0.018964 model2 loss : 0.018585
[00:13:02.590] iteration 16961 : model1 loss : 0.023902 model2 loss : 0.024462
[00:13:03.297] iteration 16962 : model1 loss : 0.023595 model2 loss : 0.020874
[00:13:03.997] iteration 16963 : model1 loss : 0.030564 model2 loss : 0.029806
[00:13:04.699] iteration 16964 : model1 loss : 0.016773 model2 loss : 0.017709
[00:13:05.394] iteration 16965 : model1 loss : 0.016523 model2 loss : 0.016284
[00:13:06.088] iteration 16966 : model1 loss : 0.021428 model2 loss : 0.020712
[00:13:06.787] iteration 16967 : model1 loss : 0.023919 model2 loss : 0.023660
[00:13:07.542] iteration 16968 : model1 loss : 0.025969 model2 loss : 0.025700
[00:13:08.253] iteration 16969 : model1 loss : 0.029863 model2 loss : 0.022798
[00:13:08.948] iteration 16970 : model1 loss : 0.018385 model2 loss : 0.020645
[00:13:09.645] iteration 16971 : model1 loss : 0.023969 model2 loss : 0.022896
[00:13:10.353] iteration 16972 : model1 loss : 0.028166 model2 loss : 0.026600
[00:13:11.063] iteration 16973 : model1 loss : 0.020023 model2 loss : 0.020002
[00:13:11.758] iteration 16974 : model1 loss : 0.043913 model2 loss : 0.051646
[00:13:12.507] iteration 16975 : model1 loss : 0.016015 model2 loss : 0.018127
[00:13:13.223] iteration 16976 : model1 loss : 0.020559 model2 loss : 0.020325
[00:13:13.927] iteration 16977 : model1 loss : 0.018301 model2 loss : 0.018120
[00:13:14.627] iteration 16978 : model1 loss : 0.022398 model2 loss : 0.022811
[00:13:15.336] iteration 16979 : model1 loss : 0.017611 model2 loss : 0.018084
[00:13:16.040] iteration 16980 : model1 loss : 0.017009 model2 loss : 0.019792
[00:13:16.758] iteration 16981 : model1 loss : 0.017855 model2 loss : 0.018851
[00:13:17.511] iteration 16982 : model1 loss : 0.019941 model2 loss : 0.022072
[00:13:18.219] iteration 16983 : model1 loss : 0.017028 model2 loss : 0.018923
[00:13:18.954] iteration 16984 : model1 loss : 0.025992 model2 loss : 0.029170
[00:13:19.666] iteration 16985 : model1 loss : 0.021813 model2 loss : 0.027038
[00:13:20.367] iteration 16986 : model1 loss : 0.027728 model2 loss : 0.030347
[00:13:21.093] iteration 16987 : model1 loss : 0.019625 model2 loss : 0.023060
[00:13:21.787] iteration 16988 : model1 loss : 0.052778 model2 loss : 0.033363
[00:13:22.537] iteration 16989 : model1 loss : 0.019531 model2 loss : 0.021589
[00:13:23.231] iteration 16990 : model1 loss : 0.020277 model2 loss : 0.019733
[00:13:23.925] iteration 16991 : model1 loss : 0.032208 model2 loss : 0.034826
[00:13:24.614] iteration 16992 : model1 loss : 0.023787 model2 loss : 0.022046
[00:13:25.324] iteration 16993 : model1 loss : 0.021720 model2 loss : 0.020255
[00:13:26.025] iteration 16994 : model1 loss : 0.018023 model2 loss : 0.018857
[00:13:26.730] iteration 16995 : model1 loss : 0.031081 model2 loss : 0.030638
[00:13:27.476] iteration 16996 : model1 loss : 0.022398 model2 loss : 0.022084
[00:13:28.170] iteration 16997 : model1 loss : 0.023311 model2 loss : 0.021439
[00:13:28.885] iteration 16998 : model1 loss : 0.020814 model2 loss : 0.023958
[00:13:29.586] iteration 16999 : model1 loss : 0.019956 model2 loss : 0.020823
[00:13:30.281] iteration 17000 : model1 loss : 0.019013 model2 loss : 0.018413
[00:13:50.072] iteration 17000 : model1_mean_dice : 0.873103 model1_mean_hd95 : 3.713472
[00:14:09.614] iteration 17000 : model2_mean_dice : 0.870188 model2_mean_hd95 : 4.866807
[00:14:10.339] iteration 17001 : model1 loss : 0.017552 model2 loss : 0.016673
[00:14:11.045] iteration 17002 : model1 loss : 0.037447 model2 loss : 0.047021
[00:14:11.744] iteration 17003 : model1 loss : 0.028449 model2 loss : 0.027332
[00:14:12.499] iteration 17004 : model1 loss : 0.022485 model2 loss : 0.021425
[00:14:13.206] iteration 17005 : model1 loss : 0.140848 model2 loss : 0.090531
[00:14:13.894] iteration 17006 : model1 loss : 0.022784 model2 loss : 0.019372
[00:14:14.592] iteration 17007 : model1 loss : 0.015864 model2 loss : 0.017616
[00:14:15.297] iteration 17008 : model1 loss : 0.024347 model2 loss : 0.026710
[00:14:16.006] iteration 17009 : model1 loss : 0.021401 model2 loss : 0.022614
[00:14:16.717] iteration 17010 : model1 loss : 0.020196 model2 loss : 0.019438
[00:14:17.454] iteration 17011 : model1 loss : 0.029280 model2 loss : 0.026735
[00:14:18.147] iteration 17012 : model1 loss : 0.020458 model2 loss : 0.018023
[00:14:18.850] iteration 17013 : model1 loss : 0.018354 model2 loss : 0.018010
[00:14:19.547] iteration 17014 : model1 loss : 0.033974 model2 loss : 0.027615
[00:14:20.245] iteration 17015 : model1 loss : 0.021624 model2 loss : 0.020981
[00:14:20.926] iteration 17016 : model1 loss : 0.019915 model2 loss : 0.020353
[00:14:21.630] iteration 17017 : model1 loss : 0.018729 model2 loss : 0.019035
[00:14:22.370] iteration 17018 : model1 loss : 0.023970 model2 loss : 0.022506
[00:14:23.073] iteration 17019 : model1 loss : 0.032899 model2 loss : 0.029229
[00:14:23.773] iteration 17020 : model1 loss : 0.021392 model2 loss : 0.021062
[00:14:24.474] iteration 17021 : model1 loss : 0.021681 model2 loss : 0.021043
[00:14:25.167] iteration 17022 : model1 loss : 0.040350 model2 loss : 0.043549
[00:14:25.868] iteration 17023 : model1 loss : 0.021706 model2 loss : 0.022475
[00:14:26.565] iteration 17024 : model1 loss : 0.023089 model2 loss : 0.021456
[00:14:27.317] iteration 17025 : model1 loss : 0.028734 model2 loss : 0.020222
[00:14:28.020] iteration 17026 : model1 loss : 0.021026 model2 loss : 0.021423
[00:14:28.721] iteration 17027 : model1 loss : 0.059731 model2 loss : 0.041346
[00:14:29.425] iteration 17028 : model1 loss : 0.030672 model2 loss : 0.025308
[00:14:30.136] iteration 17029 : model1 loss : 0.020334 model2 loss : 0.018657
[00:14:30.838] iteration 17030 : model1 loss : 0.033565 model2 loss : 0.028079
[00:14:31.554] iteration 17031 : model1 loss : 0.025112 model2 loss : 0.022848
[00:14:32.310] iteration 17032 : model1 loss : 0.022729 model2 loss : 0.021871
[00:14:33.010] iteration 17033 : model1 loss : 0.030566 model2 loss : 0.031165
[00:14:33.711] iteration 17034 : model1 loss : 0.021200 model2 loss : 0.018250
[00:14:34.426] iteration 17035 : model1 loss : 0.017790 model2 loss : 0.019005
[00:14:35.131] iteration 17036 : model1 loss : 0.025330 model2 loss : 0.023585
[00:14:35.834] iteration 17037 : model1 loss : 0.021235 model2 loss : 0.021335
[00:14:36.568] iteration 17038 : model1 loss : 0.021652 model2 loss : 0.022549
[00:14:37.314] iteration 17039 : model1 loss : 0.021938 model2 loss : 0.020919
[00:14:38.029] iteration 17040 : model1 loss : 0.021271 model2 loss : 0.019833
[00:14:38.738] iteration 17041 : model1 loss : 0.028253 model2 loss : 0.028722
[00:14:39.435] iteration 17042 : model1 loss : 0.023593 model2 loss : 0.022819
[00:14:40.143] iteration 17043 : model1 loss : 0.015287 model2 loss : 0.014459
[00:14:40.841] iteration 17044 : model1 loss : 0.022513 model2 loss : 0.021322
[00:14:41.556] iteration 17045 : model1 loss : 0.024619 model2 loss : 0.023789
[00:14:42.311] iteration 17046 : model1 loss : 0.018845 model2 loss : 0.020395
[00:14:43.018] iteration 17047 : model1 loss : 0.020198 model2 loss : 0.016754
[00:14:43.712] iteration 17048 : model1 loss : 0.021416 model2 loss : 0.025060
[00:14:44.430] iteration 17049 : model1 loss : 0.022850 model2 loss : 0.025365
[00:14:45.129] iteration 17050 : model1 loss : 0.017062 model2 loss : 0.018313
[00:14:45.864] iteration 17051 : model1 loss : 0.019911 model2 loss : 0.020890
[00:14:46.564] iteration 17052 : model1 loss : 0.025347 model2 loss : 0.022608
[00:14:47.298] iteration 17053 : model1 loss : 0.024919 model2 loss : 0.022968
[00:14:48.005] iteration 17054 : model1 loss : 0.022243 model2 loss : 0.027809
[00:14:48.708] iteration 17055 : model1 loss : 0.020700 model2 loss : 0.021980
[00:14:49.405] iteration 17056 : model1 loss : 0.023305 model2 loss : 0.023864
[00:14:50.118] iteration 17057 : model1 loss : 0.024085 model2 loss : 0.025195
[00:14:50.830] iteration 17058 : model1 loss : 0.019147 model2 loss : 0.018279
[00:14:51.541] iteration 17059 : model1 loss : 0.020957 model2 loss : 0.020634
[00:14:52.286] iteration 17060 : model1 loss : 0.026734 model2 loss : 0.027408
[00:14:52.998] iteration 17061 : model1 loss : 0.041921 model2 loss : 0.025096
[00:14:53.696] iteration 17062 : model1 loss : 0.019400 model2 loss : 0.019155
[00:14:54.397] iteration 17063 : model1 loss : 0.026365 model2 loss : 0.022121
[00:14:55.091] iteration 17064 : model1 loss : 0.015959 model2 loss : 0.015777
[00:14:55.824] iteration 17065 : model1 loss : 0.035432 model2 loss : 0.037147
[00:14:56.524] iteration 17066 : model1 loss : 0.018073 model2 loss : 0.017660
[00:14:57.273] iteration 17067 : model1 loss : 0.029914 model2 loss : 0.029448
[00:14:58.010] iteration 17068 : model1 loss : 0.020897 model2 loss : 0.022154
[00:14:58.707] iteration 17069 : model1 loss : 0.019322 model2 loss : 0.019122
[00:14:59.409] iteration 17070 : model1 loss : 0.016371 model2 loss : 0.016875
[00:15:00.125] iteration 17071 : model1 loss : 0.013001 model2 loss : 0.012726
[00:15:00.818] iteration 17072 : model1 loss : 0.019140 model2 loss : 0.021914
[00:15:01.515] iteration 17073 : model1 loss : 0.031528 model2 loss : 0.034845
[00:15:02.268] iteration 17074 : model1 loss : 0.022596 model2 loss : 0.022832
[00:15:02.980] iteration 17075 : model1 loss : 0.021303 model2 loss : 0.023634
[00:15:03.677] iteration 17076 : model1 loss : 0.027851 model2 loss : 0.028045
[00:15:04.385] iteration 17077 : model1 loss : 0.020505 model2 loss : 0.019449
[00:15:05.079] iteration 17078 : model1 loss : 0.017790 model2 loss : 0.018133
[00:15:05.787] iteration 17079 : model1 loss : 0.051611 model2 loss : 0.082420
[00:15:06.493] iteration 17080 : model1 loss : 0.022512 model2 loss : 0.021470
[00:15:07.241] iteration 17081 : model1 loss : 0.020553 model2 loss : 0.022244
[00:15:07.948] iteration 17082 : model1 loss : 0.016175 model2 loss : 0.017440
[00:15:08.648] iteration 17083 : model1 loss : 0.020417 model2 loss : 0.020833
[00:15:09.351] iteration 17084 : model1 loss : 0.019595 model2 loss : 0.017918
[00:15:10.063] iteration 17085 : model1 loss : 0.026857 model2 loss : 0.025885
[00:15:10.761] iteration 17086 : model1 loss : 0.016268 model2 loss : 0.016788
[00:15:11.464] iteration 17087 : model1 loss : 0.021678 model2 loss : 0.021892
[00:15:12.200] iteration 17088 : model1 loss : 0.021726 model2 loss : 0.022879
[00:15:12.910] iteration 17089 : model1 loss : 0.021071 model2 loss : 0.020933
[00:15:13.612] iteration 17090 : model1 loss : 0.018964 model2 loss : 0.018851
[00:15:14.318] iteration 17091 : model1 loss : 0.019762 model2 loss : 0.020377
[00:15:15.020] iteration 17092 : model1 loss : 0.019766 model2 loss : 0.019616
[00:15:15.732] iteration 17093 : model1 loss : 0.015396 model2 loss : 0.014628
[00:15:16.432] iteration 17094 : model1 loss : 0.021955 model2 loss : 0.027030
[00:15:17.164] iteration 17095 : model1 loss : 0.023102 model2 loss : 0.026497
[00:15:17.884] iteration 17096 : model1 loss : 0.020145 model2 loss : 0.030244
[00:15:18.602] iteration 17097 : model1 loss : 0.030222 model2 loss : 0.032882
[00:15:19.307] iteration 17098 : model1 loss : 0.023673 model2 loss : 0.024857
[00:15:20.007] iteration 17099 : model1 loss : 0.018168 model2 loss : 0.017951
[00:15:20.696] iteration 17100 : model1 loss : 0.018097 model2 loss : 0.020248
[00:15:21.463] iteration 17101 : model1 loss : 0.040527 model2 loss : 0.022519
[00:15:22.212] iteration 17102 : model1 loss : 0.022308 model2 loss : 0.026385
[00:15:22.914] iteration 17103 : model1 loss : 0.030477 model2 loss : 0.033339
[00:15:23.622] iteration 17104 : model1 loss : 0.019382 model2 loss : 0.019350
[00:15:24.345] iteration 17105 : model1 loss : 0.024965 model2 loss : 0.027541
[00:15:25.048] iteration 17106 : model1 loss : 0.015824 model2 loss : 0.017649
[00:15:25.760] iteration 17107 : model1 loss : 0.019746 model2 loss : 0.023637
[00:15:26.459] iteration 17108 : model1 loss : 0.018590 model2 loss : 0.018456
[00:15:27.202] iteration 17109 : model1 loss : 0.021375 model2 loss : 0.024755
[00:15:27.915] iteration 17110 : model1 loss : 0.017459 model2 loss : 0.021751
[00:15:28.621] iteration 17111 : model1 loss : 0.019860 model2 loss : 0.021861
[00:15:29.322] iteration 17112 : model1 loss : 0.017273 model2 loss : 0.017112
[00:15:30.037] iteration 17113 : model1 loss : 0.022600 model2 loss : 0.023565
[00:15:30.739] iteration 17114 : model1 loss : 0.026733 model2 loss : 0.030050
[00:15:31.443] iteration 17115 : model1 loss : 0.019827 model2 loss : 0.025960
[00:15:32.177] iteration 17116 : model1 loss : 0.021614 model2 loss : 0.022743
[00:15:32.892] iteration 17117 : model1 loss : 0.032808 model2 loss : 0.027726
[00:15:33.601] iteration 17118 : model1 loss : 0.018055 model2 loss : 0.022148
[00:15:34.309] iteration 17119 : model1 loss : 0.025776 model2 loss : 0.030767
[00:15:35.016] iteration 17120 : model1 loss : 0.022483 model2 loss : 0.023759
[00:15:35.709] iteration 17121 : model1 loss : 0.023960 model2 loss : 0.023622
[00:15:36.417] iteration 17122 : model1 loss : 0.024212 model2 loss : 0.025009
[00:15:37.162] iteration 17123 : model1 loss : 0.026752 model2 loss : 0.032125
[00:15:37.893] iteration 17124 : model1 loss : 0.018314 model2 loss : 0.018522
[00:15:38.603] iteration 17125 : model1 loss : 0.018182 model2 loss : 0.022045
[00:15:39.309] iteration 17126 : model1 loss : 0.014336 model2 loss : 0.015425
[00:15:40.022] iteration 17127 : model1 loss : 0.024410 model2 loss : 0.024555
[00:15:40.723] iteration 17128 : model1 loss : 0.020437 model2 loss : 0.020515
[00:15:41.429] iteration 17129 : model1 loss : 0.021147 model2 loss : 0.024489
[00:15:42.162] iteration 17130 : model1 loss : 0.026260 model2 loss : 0.027938
[00:15:42.888] iteration 17131 : model1 loss : 0.020693 model2 loss : 0.024721
[00:15:43.593] iteration 17132 : model1 loss : 0.025314 model2 loss : 0.022909
[00:15:44.327] iteration 17133 : model1 loss : 0.026127 model2 loss : 0.038880
[00:15:45.028] iteration 17134 : model1 loss : 0.017744 model2 loss : 0.016986
[00:15:45.731] iteration 17135 : model1 loss : 0.019050 model2 loss : 0.017769
[00:15:46.424] iteration 17136 : model1 loss : 0.025505 model2 loss : 0.024899
[00:15:47.147] iteration 17137 : model1 loss : 0.024627 model2 loss : 0.031550
[00:15:47.864] iteration 17138 : model1 loss : 0.018377 model2 loss : 0.018855
[00:15:48.581] iteration 17139 : model1 loss : 0.024490 model2 loss : 0.023423
[00:15:49.273] iteration 17140 : model1 loss : 0.021293 model2 loss : 0.023459
[00:15:49.980] iteration 17141 : model1 loss : 0.017592 model2 loss : 0.016887
[00:15:50.682] iteration 17142 : model1 loss : 0.023377 model2 loss : 0.024451
[00:15:51.385] iteration 17143 : model1 loss : 0.019778 model2 loss : 0.021960
[00:15:52.125] iteration 17144 : model1 loss : 0.025848 model2 loss : 0.024358
[00:15:52.856] iteration 17145 : model1 loss : 0.026855 model2 loss : 0.028686
[00:15:53.567] iteration 17146 : model1 loss : 0.023450 model2 loss : 0.024729
[00:15:54.271] iteration 17147 : model1 loss : 0.017807 model2 loss : 0.016740
[00:15:54.974] iteration 17148 : model1 loss : 0.022154 model2 loss : 0.025181
[00:15:55.672] iteration 17149 : model1 loss : 0.019344 model2 loss : 0.019329
[00:15:56.392] iteration 17150 : model1 loss : 0.015028 model2 loss : 0.016131
[00:15:57.181] iteration 17151 : model1 loss : 0.020236 model2 loss : 0.020138
[00:15:57.899] iteration 17152 : model1 loss : 0.024967 model2 loss : 0.024133
[00:15:58.604] iteration 17153 : model1 loss : 0.021284 model2 loss : 0.024322
[00:15:59.303] iteration 17154 : model1 loss : 0.023069 model2 loss : 0.023416
[00:16:00.033] iteration 17155 : model1 loss : 0.016426 model2 loss : 0.016530
[00:16:00.728] iteration 17156 : model1 loss : 0.035744 model2 loss : 0.032649
[00:16:01.430] iteration 17157 : model1 loss : 0.017913 model2 loss : 0.017450
[00:16:02.168] iteration 17158 : model1 loss : 0.153427 model2 loss : 0.147585
[00:16:02.879] iteration 17159 : model1 loss : 0.024884 model2 loss : 0.023787
[00:16:03.587] iteration 17160 : model1 loss : 0.020011 model2 loss : 0.019604
[00:16:04.288] iteration 17161 : model1 loss : 0.031050 model2 loss : 0.054666
[00:16:04.991] iteration 17162 : model1 loss : 0.026469 model2 loss : 0.025454
[00:16:05.710] iteration 17163 : model1 loss : 0.016607 model2 loss : 0.018393
[00:16:06.428] iteration 17164 : model1 loss : 0.018523 model2 loss : 0.018595
[00:16:07.176] iteration 17165 : model1 loss : 0.033585 model2 loss : 0.032777
[00:16:07.896] iteration 17166 : model1 loss : 0.024035 model2 loss : 0.027437
[00:16:08.605] iteration 17167 : model1 loss : 0.061746 model2 loss : 0.051090
[00:16:09.313] iteration 17168 : model1 loss : 0.034824 model2 loss : 0.033293
[00:16:10.020] iteration 17169 : model1 loss : 0.025561 model2 loss : 0.028610
[00:16:10.736] iteration 17170 : model1 loss : 0.023453 model2 loss : 0.025572
[00:16:11.440] iteration 17171 : model1 loss : 0.034870 model2 loss : 0.036608
[00:16:12.174] iteration 17172 : model1 loss : 0.035697 model2 loss : 0.041172
[00:16:12.895] iteration 17173 : model1 loss : 0.017128 model2 loss : 0.019592
[00:16:13.593] iteration 17174 : model1 loss : 0.018750 model2 loss : 0.019218
[00:16:14.303] iteration 17175 : model1 loss : 0.019279 model2 loss : 0.018891
[00:16:15.014] iteration 17176 : model1 loss : 0.020306 model2 loss : 0.019450
[00:16:15.721] iteration 17177 : model1 loss : 0.028820 model2 loss : 0.027139
[00:16:16.427] iteration 17178 : model1 loss : 0.069909 model2 loss : 0.060694
[00:16:17.169] iteration 17179 : model1 loss : 0.015682 model2 loss : 0.015140
[00:16:17.887] iteration 17180 : model1 loss : 0.018935 model2 loss : 0.022050
[00:16:18.593] iteration 17181 : model1 loss : 0.019890 model2 loss : 0.021267
[00:16:19.302] iteration 17182 : model1 loss : 0.025746 model2 loss : 0.025588
[00:16:20.008] iteration 17183 : model1 loss : 0.021091 model2 loss : 0.023864
[00:16:20.709] iteration 17184 : model1 loss : 0.020127 model2 loss : 0.020161
[00:16:21.426] iteration 17185 : model1 loss : 0.020391 model2 loss : 0.021171
[00:16:22.158] iteration 17186 : model1 loss : 0.026995 model2 loss : 0.025456
[00:16:22.870] iteration 17187 : model1 loss : 0.024794 model2 loss : 0.025290
[00:16:23.568] iteration 17188 : model1 loss : 0.017874 model2 loss : 0.017111
[00:16:24.273] iteration 17189 : model1 loss : 0.126899 model2 loss : 0.109541
[00:16:24.965] iteration 17190 : model1 loss : 0.032925 model2 loss : 0.036004
[00:16:25.666] iteration 17191 : model1 loss : 0.019997 model2 loss : 0.026919
[00:16:26.392] iteration 17192 : model1 loss : 0.016928 model2 loss : 0.017220
[00:16:27.117] iteration 17193 : model1 loss : 0.018435 model2 loss : 0.017692
[00:16:27.832] iteration 17194 : model1 loss : 0.020083 model2 loss : 0.020210
[00:16:28.558] iteration 17195 : model1 loss : 0.019609 model2 loss : 0.017894
[00:16:29.258] iteration 17196 : model1 loss : 0.021692 model2 loss : 0.021367
[00:16:29.962] iteration 17197 : model1 loss : 0.017461 model2 loss : 0.017425
[00:16:30.656] iteration 17198 : model1 loss : 0.023999 model2 loss : 0.023590
[00:16:31.380] iteration 17199 : model1 loss : 0.024717 model2 loss : 0.022438
[00:16:32.103] iteration 17200 : model1 loss : 0.048911 model2 loss : 0.048208
[00:16:51.718] iteration 17200 : model1_mean_dice : 0.869203 model1_mean_hd95 : 7.336631
[00:17:11.444] iteration 17200 : model2_mean_dice : 0.870053 model2_mean_hd95 : 4.572005
[00:17:12.197] iteration 17201 : model1 loss : 0.040955 model2 loss : 0.033372
[00:17:12.891] iteration 17202 : model1 loss : 0.022876 model2 loss : 0.021391
[00:17:13.584] iteration 17203 : model1 loss : 0.015472 model2 loss : 0.014936
[00:17:14.270] iteration 17204 : model1 loss : 0.026916 model2 loss : 0.037429
[00:17:14.977] iteration 17205 : model1 loss : 0.021601 model2 loss : 0.020170
[00:17:15.684] iteration 17206 : model1 loss : 0.018646 model2 loss : 0.018122
[00:17:16.376] iteration 17207 : model1 loss : 0.022600 model2 loss : 0.020040
[00:17:17.100] iteration 17208 : model1 loss : 0.021047 model2 loss : 0.021542
[00:17:17.814] iteration 17209 : model1 loss : 0.026730 model2 loss : 0.023828
[00:17:18.520] iteration 17210 : model1 loss : 0.017295 model2 loss : 0.018543
[00:17:19.213] iteration 17211 : model1 loss : 0.024097 model2 loss : 0.025129
[00:17:19.907] iteration 17212 : model1 loss : 0.027414 model2 loss : 0.022708
[00:17:20.628] iteration 17213 : model1 loss : 0.026129 model2 loss : 0.026593
[00:17:21.325] iteration 17214 : model1 loss : 0.021959 model2 loss : 0.021131
[00:17:22.039] iteration 17215 : model1 loss : 0.018169 model2 loss : 0.025030
[00:17:22.762] iteration 17216 : model1 loss : 0.023212 model2 loss : 0.025364
[00:17:23.479] iteration 17217 : model1 loss : 0.025724 model2 loss : 0.034491
[00:17:24.185] iteration 17218 : model1 loss : 0.025614 model2 loss : 0.020169
[00:17:24.882] iteration 17219 : model1 loss : 0.019039 model2 loss : 0.019553
[00:17:25.580] iteration 17220 : model1 loss : 0.018527 model2 loss : 0.019699
[00:17:26.280] iteration 17221 : model1 loss : 0.017745 model2 loss : 0.020265
[00:17:26.996] iteration 17222 : model1 loss : 0.020363 model2 loss : 0.020739
[00:17:27.723] iteration 17223 : model1 loss : 0.025570 model2 loss : 0.025241
[00:17:28.427] iteration 17224 : model1 loss : 0.021763 model2 loss : 0.018342
[00:17:29.127] iteration 17225 : model1 loss : 0.019705 model2 loss : 0.020324
[00:17:29.818] iteration 17226 : model1 loss : 0.017815 model2 loss : 0.018601
[00:17:30.525] iteration 17227 : model1 loss : 0.020106 model2 loss : 0.022798
[00:17:31.229] iteration 17228 : model1 loss : 0.021584 model2 loss : 0.022403
[00:17:31.952] iteration 17229 : model1 loss : 0.026844 model2 loss : 0.026064
[00:17:32.681] iteration 17230 : model1 loss : 0.020083 model2 loss : 0.018983
[00:17:33.399] iteration 17231 : model1 loss : 0.027162 model2 loss : 0.021895
[00:17:34.085] iteration 17232 : model1 loss : 0.021303 model2 loss : 0.019922
[00:17:34.790] iteration 17233 : model1 loss : 0.022705 model2 loss : 0.021918
[00:17:35.486] iteration 17234 : model1 loss : 0.023276 model2 loss : 0.023234
[00:17:36.195] iteration 17235 : model1 loss : 0.016294 model2 loss : 0.016081
[00:17:36.917] iteration 17236 : model1 loss : 0.018312 model2 loss : 0.020368
[00:17:37.642] iteration 17237 : model1 loss : 0.016448 model2 loss : 0.017357
[00:17:38.351] iteration 17238 : model1 loss : 0.027116 model2 loss : 0.026875
[00:17:39.063] iteration 17239 : model1 loss : 0.021176 model2 loss : 0.022701
[00:17:39.789] iteration 17240 : model1 loss : 0.020106 model2 loss : 0.020383
[00:17:40.485] iteration 17241 : model1 loss : 0.021777 model2 loss : 0.022303
[00:17:41.196] iteration 17242 : model1 loss : 0.022337 model2 loss : 0.020285
[00:17:41.897] iteration 17243 : model1 loss : 0.020390 model2 loss : 0.022253
[00:17:42.647] iteration 17244 : model1 loss : 0.022686 model2 loss : 0.025260
[00:17:43.361] iteration 17245 : model1 loss : 0.021196 model2 loss : 0.018450
[00:17:44.069] iteration 17246 : model1 loss : 0.023965 model2 loss : 0.026932
[00:17:44.771] iteration 17247 : model1 loss : 0.023698 model2 loss : 0.020741
[00:17:45.479] iteration 17248 : model1 loss : 0.018381 model2 loss : 0.018198
[00:17:46.172] iteration 17249 : model1 loss : 0.027693 model2 loss : 0.028489
[00:17:46.886] iteration 17250 : model1 loss : 0.020070 model2 loss : 0.024688
[00:17:47.665] iteration 17251 : model1 loss : 0.022014 model2 loss : 0.021592
[00:17:48.368] iteration 17252 : model1 loss : 0.024492 model2 loss : 0.030469
[00:17:49.073] iteration 17253 : model1 loss : 0.017077 model2 loss : 0.022564
[00:17:49.781] iteration 17254 : model1 loss : 0.019773 model2 loss : 0.019425
[00:17:50.487] iteration 17255 : model1 loss : 0.026391 model2 loss : 0.026973
[00:17:51.192] iteration 17256 : model1 loss : 0.021782 model2 loss : 0.021217
[00:17:51.906] iteration 17257 : model1 loss : 0.022441 model2 loss : 0.021769
[00:17:52.635] iteration 17258 : model1 loss : 0.024857 model2 loss : 0.023191
[00:17:53.348] iteration 17259 : model1 loss : 0.025942 model2 loss : 0.026487
[00:17:54.044] iteration 17260 : model1 loss : 0.019678 model2 loss : 0.021180
[00:17:54.774] iteration 17261 : model1 loss : 0.027654 model2 loss : 0.028780
[00:17:55.484] iteration 17262 : model1 loss : 0.023277 model2 loss : 0.025064
[00:17:56.183] iteration 17263 : model1 loss : 0.026613 model2 loss : 0.016150
[00:17:56.916] iteration 17264 : model1 loss : 0.016898 model2 loss : 0.016573
[00:17:57.668] iteration 17265 : model1 loss : 0.014917 model2 loss : 0.016510
[00:17:58.371] iteration 17266 : model1 loss : 0.022537 model2 loss : 0.022783
[00:17:59.073] iteration 17267 : model1 loss : 0.028151 model2 loss : 0.025439
[00:17:59.792] iteration 17268 : model1 loss : 0.041541 model2 loss : 0.038275
[00:18:00.504] iteration 17269 : model1 loss : 0.018860 model2 loss : 0.017998
[00:18:01.219] iteration 17270 : model1 loss : 0.019432 model2 loss : 0.022251
[00:18:01.934] iteration 17271 : model1 loss : 0.019754 model2 loss : 0.022492
[00:18:02.675] iteration 17272 : model1 loss : 0.022223 model2 loss : 0.021145
[00:18:03.394] iteration 17273 : model1 loss : 0.018261 model2 loss : 0.019339
[00:18:04.091] iteration 17274 : model1 loss : 0.015845 model2 loss : 0.017021
[00:18:04.799] iteration 17275 : model1 loss : 0.020232 model2 loss : 0.020176
[00:18:05.516] iteration 17276 : model1 loss : 0.019001 model2 loss : 0.019866
[00:18:06.213] iteration 17277 : model1 loss : 0.017357 model2 loss : 0.015813
[00:18:06.917] iteration 17278 : model1 loss : 0.024477 model2 loss : 0.024532
[00:18:07.661] iteration 17279 : model1 loss : 0.023463 model2 loss : 0.021951
[00:18:08.368] iteration 17280 : model1 loss : 0.015899 model2 loss : 0.019449
[00:18:09.081] iteration 17281 : model1 loss : 0.018406 model2 loss : 0.017418
[00:18:09.797] iteration 17282 : model1 loss : 0.016450 model2 loss : 0.016844
[00:18:10.498] iteration 17283 : model1 loss : 0.037714 model2 loss : 0.031350
[00:18:11.198] iteration 17284 : model1 loss : 0.016912 model2 loss : 0.018230
[00:18:11.918] iteration 17285 : model1 loss : 0.030770 model2 loss : 0.034748
[00:18:12.660] iteration 17286 : model1 loss : 0.022432 model2 loss : 0.022131
[00:18:13.379] iteration 17287 : model1 loss : 0.029561 model2 loss : 0.029722
[00:18:14.083] iteration 17288 : model1 loss : 0.020473 model2 loss : 0.022972
[00:18:14.781] iteration 17289 : model1 loss : 0.022391 model2 loss : 0.020591
[00:18:15.485] iteration 17290 : model1 loss : 0.142002 model2 loss : 0.090867
[00:18:16.198] iteration 17291 : model1 loss : 0.017978 model2 loss : 0.019002
[00:18:16.910] iteration 17292 : model1 loss : 0.025007 model2 loss : 0.024525
[00:18:17.651] iteration 17293 : model1 loss : 0.021578 model2 loss : 0.020771
[00:18:18.358] iteration 17294 : model1 loss : 0.021257 model2 loss : 0.019189
[00:18:19.054] iteration 17295 : model1 loss : 0.018282 model2 loss : 0.019071
[00:18:19.760] iteration 17296 : model1 loss : 0.026784 model2 loss : 0.026811
[00:18:20.451] iteration 17297 : model1 loss : 0.031815 model2 loss : 0.039795
[00:18:21.160] iteration 17298 : model1 loss : 0.018245 model2 loss : 0.020528
[00:18:21.860] iteration 17299 : model1 loss : 0.030331 model2 loss : 0.023136
[00:18:22.606] iteration 17300 : model1 loss : 0.040279 model2 loss : 0.041144
[00:18:23.359] iteration 17301 : model1 loss : 0.018119 model2 loss : 0.020290
[00:18:24.067] iteration 17302 : model1 loss : 0.021589 model2 loss : 0.021135
[00:18:24.772] iteration 17303 : model1 loss : 0.015236 model2 loss : 0.016201
[00:18:25.482] iteration 17304 : model1 loss : 0.018616 model2 loss : 0.018328
[00:18:26.183] iteration 17305 : model1 loss : 0.018652 model2 loss : 0.019181
[00:18:26.900] iteration 17306 : model1 loss : 0.017285 model2 loss : 0.018718
[00:18:27.641] iteration 17307 : model1 loss : 0.017487 model2 loss : 0.018889
[00:18:28.339] iteration 17308 : model1 loss : 0.044198 model2 loss : 0.045424
[00:18:29.053] iteration 17309 : model1 loss : 0.022906 model2 loss : 0.021737
[00:18:29.773] iteration 17310 : model1 loss : 0.021384 model2 loss : 0.021588
[00:18:30.489] iteration 17311 : model1 loss : 0.032977 model2 loss : 0.031268
[00:18:31.195] iteration 17312 : model1 loss : 0.035258 model2 loss : 0.042157
[00:18:31.929] iteration 17313 : model1 loss : 0.025723 model2 loss : 0.025711
[00:18:32.670] iteration 17314 : model1 loss : 0.042610 model2 loss : 0.046515
[00:18:33.370] iteration 17315 : model1 loss : 0.020996 model2 loss : 0.021077
[00:18:34.064] iteration 17316 : model1 loss : 0.023723 model2 loss : 0.025859
[00:18:34.756] iteration 17317 : model1 loss : 0.016603 model2 loss : 0.017353
[00:18:35.473] iteration 17318 : model1 loss : 0.022696 model2 loss : 0.022454
[00:18:36.174] iteration 17319 : model1 loss : 0.023902 model2 loss : 0.025367
[00:18:36.883] iteration 17320 : model1 loss : 0.018071 model2 loss : 0.019469
[00:18:37.631] iteration 17321 : model1 loss : 0.025773 model2 loss : 0.031995
[00:18:38.334] iteration 17322 : model1 loss : 0.023285 model2 loss : 0.023598
[00:18:39.035] iteration 17323 : model1 loss : 0.032022 model2 loss : 0.028942
[00:18:39.742] iteration 17324 : model1 loss : 0.021384 model2 loss : 0.023516
[00:18:40.450] iteration 17325 : model1 loss : 0.016787 model2 loss : 0.017513
[00:18:41.148] iteration 17326 : model1 loss : 0.024715 model2 loss : 0.021578
[00:18:41.850] iteration 17327 : model1 loss : 0.018723 model2 loss : 0.020418
[00:18:42.595] iteration 17328 : model1 loss : 0.022536 model2 loss : 0.024462
[00:18:43.317] iteration 17329 : model1 loss : 0.021436 model2 loss : 0.021247
[00:18:44.029] iteration 17330 : model1 loss : 0.027483 model2 loss : 0.029739
[00:18:44.756] iteration 17331 : model1 loss : 0.019545 model2 loss : 0.018202
[00:18:45.472] iteration 17332 : model1 loss : 0.020340 model2 loss : 0.024612
[00:18:46.184] iteration 17333 : model1 loss : 0.020647 model2 loss : 0.023979
[00:18:46.893] iteration 17334 : model1 loss : 0.022014 model2 loss : 0.021704
[00:18:47.640] iteration 17335 : model1 loss : 0.023646 model2 loss : 0.023291
[00:18:48.342] iteration 17336 : model1 loss : 0.021739 model2 loss : 0.023304
[00:18:49.054] iteration 17337 : model1 loss : 0.023873 model2 loss : 0.023402
[00:18:49.774] iteration 17338 : model1 loss : 0.023518 model2 loss : 0.024597
[00:18:50.476] iteration 17339 : model1 loss : 0.022674 model2 loss : 0.024103
[00:18:51.181] iteration 17340 : model1 loss : 0.019158 model2 loss : 0.018115
[00:18:51.903] iteration 17341 : model1 loss : 0.028859 model2 loss : 0.023048
[00:18:52.660] iteration 17342 : model1 loss : 0.019486 model2 loss : 0.020873
[00:18:53.361] iteration 17343 : model1 loss : 0.024391 model2 loss : 0.019844
[00:18:54.080] iteration 17344 : model1 loss : 0.030215 model2 loss : 0.031237
[00:18:54.785] iteration 17345 : model1 loss : 0.019189 model2 loss : 0.017714
[00:18:55.493] iteration 17346 : model1 loss : 0.020741 model2 loss : 0.024184
[00:18:56.206] iteration 17347 : model1 loss : 0.027486 model2 loss : 0.024366
[00:18:56.918] iteration 17348 : model1 loss : 0.025044 model2 loss : 0.022967
[00:18:57.688] iteration 17349 : model1 loss : 0.025652 model2 loss : 0.026727
[00:18:58.390] iteration 17350 : model1 loss : 0.019649 model2 loss : 0.023986
[00:18:59.137] iteration 17351 : model1 loss : 0.019818 model2 loss : 0.019045
[00:18:59.852] iteration 17352 : model1 loss : 0.016360 model2 loss : 0.015556
[00:19:00.556] iteration 17353 : model1 loss : 0.020679 model2 loss : 0.020299
[00:19:01.262] iteration 17354 : model1 loss : 0.020862 model2 loss : 0.019399
[00:19:01.990] iteration 17355 : model1 loss : 0.015318 model2 loss : 0.016550
[00:19:02.730] iteration 17356 : model1 loss : 0.013707 model2 loss : 0.017319
[00:19:03.430] iteration 17357 : model1 loss : 0.013878 model2 loss : 0.014413
[00:19:04.129] iteration 17358 : model1 loss : 0.017412 model2 loss : 0.017786
[00:19:04.832] iteration 17359 : model1 loss : 0.021212 model2 loss : 0.020960
[00:19:05.531] iteration 17360 : model1 loss : 0.019116 model2 loss : 0.017097
[00:19:06.242] iteration 17361 : model1 loss : 0.014484 model2 loss : 0.014167
[00:19:06.981] iteration 17362 : model1 loss : 0.021178 model2 loss : 0.020382
[00:19:07.706] iteration 17363 : model1 loss : 0.022603 model2 loss : 0.022192
[00:19:08.408] iteration 17364 : model1 loss : 0.023647 model2 loss : 0.021049
[00:19:09.107] iteration 17365 : model1 loss : 0.028999 model2 loss : 0.023995
[00:19:09.820] iteration 17366 : model1 loss : 0.025870 model2 loss : 0.026792
[00:19:10.532] iteration 17367 : model1 loss : 0.023949 model2 loss : 0.024188
[00:19:11.224] iteration 17368 : model1 loss : 0.020883 model2 loss : 0.021833
[00:19:11.945] iteration 17369 : model1 loss : 0.020399 model2 loss : 0.021901
[00:19:12.678] iteration 17370 : model1 loss : 0.022145 model2 loss : 0.023656
[00:19:13.382] iteration 17371 : model1 loss : 0.014121 model2 loss : 0.014378
[00:19:14.091] iteration 17372 : model1 loss : 0.019292 model2 loss : 0.018139
[00:19:14.784] iteration 17373 : model1 loss : 0.021799 model2 loss : 0.022981
[00:19:15.489] iteration 17374 : model1 loss : 0.029694 model2 loss : 0.030910
[00:19:16.194] iteration 17375 : model1 loss : 0.036044 model2 loss : 0.030921
[00:19:16.907] iteration 17376 : model1 loss : 0.016915 model2 loss : 0.017972
[00:19:17.651] iteration 17377 : model1 loss : 0.022645 model2 loss : 0.022084
[00:19:18.359] iteration 17378 : model1 loss : 0.034056 model2 loss : 0.044094
[00:19:19.068] iteration 17379 : model1 loss : 0.026789 model2 loss : 0.022860
[00:19:19.793] iteration 17380 : model1 loss : 0.025687 model2 loss : 0.028903
[00:19:20.501] iteration 17381 : model1 loss : 0.026021 model2 loss : 0.026512
[00:19:21.210] iteration 17382 : model1 loss : 0.015922 model2 loss : 0.015271
[00:19:21.938] iteration 17383 : model1 loss : 0.023146 model2 loss : 0.026198
[00:19:22.670] iteration 17384 : model1 loss : 0.016788 model2 loss : 0.017168
[00:19:23.384] iteration 17385 : model1 loss : 0.017791 model2 loss : 0.020038
[00:19:24.112] iteration 17386 : model1 loss : 0.032322 model2 loss : 0.033215
[00:19:24.822] iteration 17387 : model1 loss : 0.023102 model2 loss : 0.026460
[00:19:25.524] iteration 17388 : model1 loss : 0.022510 model2 loss : 0.022849
[00:19:26.228] iteration 17389 : model1 loss : 0.025301 model2 loss : 0.023908
[00:19:26.940] iteration 17390 : model1 loss : 0.018204 model2 loss : 0.019009
[00:19:27.675] iteration 17391 : model1 loss : 0.023247 model2 loss : 0.023047
[00:19:28.393] iteration 17392 : model1 loss : 0.026882 model2 loss : 0.025307
[00:19:29.081] iteration 17393 : model1 loss : 0.028799 model2 loss : 0.029496
[00:19:29.798] iteration 17394 : model1 loss : 0.023570 model2 loss : 0.024689
[00:19:30.510] iteration 17395 : model1 loss : 0.018763 model2 loss : 0.017895
[00:19:31.216] iteration 17396 : model1 loss : 0.023804 model2 loss : 0.027773
[00:19:31.952] iteration 17397 : model1 loss : 0.019267 model2 loss : 0.020759
[00:19:32.691] iteration 17398 : model1 loss : 0.019895 model2 loss : 0.020823
[00:19:33.394] iteration 17399 : model1 loss : 0.027416 model2 loss : 0.028763
[00:19:34.122] iteration 17400 : model1 loss : 0.017760 model2 loss : 0.019072
[00:19:53.703] iteration 17400 : model1_mean_dice : 0.862434 model1_mean_hd95 : 6.844944
[00:20:13.751] iteration 17400 : model2_mean_dice : 0.867893 model2_mean_hd95 : 6.090499
[00:20:14.468] iteration 17401 : model1 loss : 0.021293 model2 loss : 0.021684
[00:20:15.160] iteration 17402 : model1 loss : 0.019260 model2 loss : 0.018983
[00:20:15.857] iteration 17403 : model1 loss : 0.017549 model2 loss : 0.017925
[00:20:16.559] iteration 17404 : model1 loss : 0.016673 model2 loss : 0.016021
[00:20:17.294] iteration 17405 : model1 loss : 0.019159 model2 loss : 0.019542
[00:20:17.997] iteration 17406 : model1 loss : 0.019006 model2 loss : 0.020628
[00:20:18.684] iteration 17407 : model1 loss : 0.020563 model2 loss : 0.032494
[00:20:19.386] iteration 17408 : model1 loss : 0.018986 model2 loss : 0.017730
[00:20:20.088] iteration 17409 : model1 loss : 0.019400 model2 loss : 0.019816
[00:20:20.780] iteration 17410 : model1 loss : 0.027177 model2 loss : 0.028579
[00:20:21.493] iteration 17411 : model1 loss : 0.022357 model2 loss : 0.021084
[00:20:22.232] iteration 17412 : model1 loss : 0.022657 model2 loss : 0.019518
[00:20:22.950] iteration 17413 : model1 loss : 0.024320 model2 loss : 0.024483
[00:20:23.651] iteration 17414 : model1 loss : 0.016438 model2 loss : 0.018740
[00:20:24.354] iteration 17415 : model1 loss : 0.152699 model2 loss : 0.155857
[00:20:25.042] iteration 17416 : model1 loss : 0.018241 model2 loss : 0.019931
[00:20:25.744] iteration 17417 : model1 loss : 0.029871 model2 loss : 0.025481
[00:20:26.440] iteration 17418 : model1 loss : 0.024961 model2 loss : 0.024805
[00:20:27.179] iteration 17419 : model1 loss : 0.023648 model2 loss : 0.024690
[00:20:27.886] iteration 17420 : model1 loss : 0.024865 model2 loss : 0.034917
[00:20:28.581] iteration 17421 : model1 loss : 0.016822 model2 loss : 0.017149
[00:20:29.293] iteration 17422 : model1 loss : 0.056093 model2 loss : 0.041172
[00:20:29.982] iteration 17423 : model1 loss : 0.033667 model2 loss : 0.048306
[00:20:30.682] iteration 17424 : model1 loss : 0.017978 model2 loss : 0.019946
[00:20:31.385] iteration 17425 : model1 loss : 0.024613 model2 loss : 0.022555
[00:20:32.124] iteration 17426 : model1 loss : 0.029232 model2 loss : 0.027896
[00:20:32.849] iteration 17427 : model1 loss : 0.101083 model2 loss : 0.084861
[00:20:33.554] iteration 17428 : model1 loss : 0.021163 model2 loss : 0.017549
[00:20:34.265] iteration 17429 : model1 loss : 0.020765 model2 loss : 0.020951
[00:20:34.955] iteration 17430 : model1 loss : 0.018968 model2 loss : 0.021333
[00:20:35.656] iteration 17431 : model1 loss : 0.024221 model2 loss : 0.022806
[00:20:36.382] iteration 17432 : model1 loss : 0.023934 model2 loss : 0.026376
[00:20:37.139] iteration 17433 : model1 loss : 0.026589 model2 loss : 0.020525
[00:20:37.869] iteration 17434 : model1 loss : 0.024610 model2 loss : 0.017203
[00:20:38.575] iteration 17435 : model1 loss : 0.026741 model2 loss : 0.030867
[00:20:39.273] iteration 17436 : model1 loss : 0.034718 model2 loss : 0.034616
[00:20:39.970] iteration 17437 : model1 loss : 0.015824 model2 loss : 0.014734
[00:20:40.677] iteration 17438 : model1 loss : 0.027848 model2 loss : 0.027225
[00:20:41.380] iteration 17439 : model1 loss : 0.019817 model2 loss : 0.018527
[00:20:42.107] iteration 17440 : model1 loss : 0.018999 model2 loss : 0.019736
[00:20:42.829] iteration 17441 : model1 loss : 0.034771 model2 loss : 0.032323
[00:20:43.546] iteration 17442 : model1 loss : 0.026194 model2 loss : 0.025037
[00:20:44.246] iteration 17443 : model1 loss : 0.022249 model2 loss : 0.021124
[00:20:44.954] iteration 17444 : model1 loss : 0.023772 model2 loss : 0.020436
[00:20:45.660] iteration 17445 : model1 loss : 0.019110 model2 loss : 0.019167
[00:20:46.352] iteration 17446 : model1 loss : 0.024610 model2 loss : 0.026256
[00:20:47.087] iteration 17447 : model1 loss : 0.033496 model2 loss : 0.030033
[00:20:47.797] iteration 17448 : model1 loss : 0.024211 model2 loss : 0.023779
[00:20:48.503] iteration 17449 : model1 loss : 0.026804 model2 loss : 0.024581
[00:20:49.210] iteration 17450 : model1 loss : 0.018432 model2 loss : 0.020215
[00:20:49.963] iteration 17451 : model1 loss : 0.017401 model2 loss : 0.018112
[00:20:50.675] iteration 17452 : model1 loss : 0.025678 model2 loss : 0.021635
[00:20:51.393] iteration 17453 : model1 loss : 0.020563 model2 loss : 0.019894
[00:20:52.115] iteration 17454 : model1 loss : 0.019004 model2 loss : 0.016350
[00:20:52.835] iteration 17455 : model1 loss : 0.021155 model2 loss : 0.022019
[00:20:53.555] iteration 17456 : model1 loss : 0.019733 model2 loss : 0.019181
[00:20:54.272] iteration 17457 : model1 loss : 0.018114 model2 loss : 0.019940
[00:20:54.979] iteration 17458 : model1 loss : 0.024015 model2 loss : 0.022435
[00:20:55.676] iteration 17459 : model1 loss : 0.015264 model2 loss : 0.016926
[00:20:56.386] iteration 17460 : model1 loss : 0.027385 model2 loss : 0.022265
[00:20:57.113] iteration 17461 : model1 loss : 0.021115 model2 loss : 0.022023
[00:20:57.840] iteration 17462 : model1 loss : 0.020808 model2 loss : 0.022557
[00:20:58.580] iteration 17463 : model1 loss : 0.021619 model2 loss : 0.023356
[00:20:59.288] iteration 17464 : model1 loss : 0.026715 model2 loss : 0.024925
[00:20:59.977] iteration 17465 : model1 loss : 0.021592 model2 loss : 0.020918
[00:21:00.672] iteration 17466 : model1 loss : 0.018805 model2 loss : 0.018488
[00:21:01.390] iteration 17467 : model1 loss : 0.019318 model2 loss : 0.018723
[00:21:02.119] iteration 17468 : model1 loss : 0.027497 model2 loss : 0.024077
[00:21:02.843] iteration 17469 : model1 loss : 0.019164 model2 loss : 0.019838
[00:21:03.552] iteration 17470 : model1 loss : 0.022008 model2 loss : 0.023209
[00:21:04.259] iteration 17471 : model1 loss : 0.023139 model2 loss : 0.020552
[00:21:04.960] iteration 17472 : model1 loss : 0.021050 model2 loss : 0.022284
[00:21:05.655] iteration 17473 : model1 loss : 0.146692 model2 loss : 0.147417
[00:21:06.361] iteration 17474 : model1 loss : 0.022309 model2 loss : 0.019831
[00:21:07.105] iteration 17475 : model1 loss : 0.030438 model2 loss : 0.033099
[00:21:07.830] iteration 17476 : model1 loss : 0.018654 model2 loss : 0.018700
[00:21:08.525] iteration 17477 : model1 loss : 0.023359 model2 loss : 0.023513
[00:21:09.221] iteration 17478 : model1 loss : 0.032850 model2 loss : 0.033024
[00:21:09.932] iteration 17479 : model1 loss : 0.023111 model2 loss : 0.021360
[00:21:10.638] iteration 17480 : model1 loss : 0.018200 model2 loss : 0.018028
[00:21:11.352] iteration 17481 : model1 loss : 0.020336 model2 loss : 0.019676
[00:21:12.069] iteration 17482 : model1 loss : 0.019192 model2 loss : 0.019152
[00:21:12.830] iteration 17483 : model1 loss : 0.021821 model2 loss : 0.022227
[00:21:13.571] iteration 17484 : model1 loss : 0.024030 model2 loss : 0.025942
[00:21:14.278] iteration 17485 : model1 loss : 0.022413 model2 loss : 0.023241
[00:21:14.977] iteration 17486 : model1 loss : 0.019089 model2 loss : 0.017561
[00:21:15.696] iteration 17487 : model1 loss : 0.025063 model2 loss : 0.024392
[00:21:16.396] iteration 17488 : model1 loss : 0.017123 model2 loss : 0.018875
[00:21:17.125] iteration 17489 : model1 loss : 0.018243 model2 loss : 0.017575
[00:21:17.831] iteration 17490 : model1 loss : 0.032554 model2 loss : 0.034268
[00:21:18.527] iteration 17491 : model1 loss : 0.036936 model2 loss : 0.040611
[00:21:19.237] iteration 17492 : model1 loss : 0.018248 model2 loss : 0.018020
[00:21:19.943] iteration 17493 : model1 loss : 0.019811 model2 loss : 0.020605
[00:21:20.654] iteration 17494 : model1 loss : 0.024977 model2 loss : 0.025877
[00:21:21.374] iteration 17495 : model1 loss : 0.017110 model2 loss : 0.017423
[00:21:22.113] iteration 17496 : model1 loss : 0.020304 model2 loss : 0.020988
[00:21:23.031] iteration 17497 : model1 loss : 0.016869 model2 loss : 0.018952
[00:21:23.797] iteration 17498 : model1 loss : 0.029806 model2 loss : 0.027858
[00:21:24.585] iteration 17499 : model1 loss : 0.017741 model2 loss : 0.018404
[00:21:25.315] iteration 17500 : model1 loss : 0.020181 model2 loss : 0.022296
[00:21:26.059] iteration 17501 : model1 loss : 0.023533 model2 loss : 0.022017
[00:21:26.768] iteration 17502 : model1 loss : 0.021860 model2 loss : 0.018348
[00:21:27.504] iteration 17503 : model1 loss : 0.018690 model2 loss : 0.019457
[00:21:28.198] iteration 17504 : model1 loss : 0.051521 model2 loss : 0.048200
[00:21:28.911] iteration 17505 : model1 loss : 0.020423 model2 loss : 0.020114
[00:21:29.617] iteration 17506 : model1 loss : 0.015011 model2 loss : 0.014478
[00:21:30.323] iteration 17507 : model1 loss : 0.019710 model2 loss : 0.021076
[00:21:31.019] iteration 17508 : model1 loss : 0.020081 model2 loss : 0.019901
[00:21:31.729] iteration 17509 : model1 loss : 0.021053 model2 loss : 0.025905
[00:21:32.486] iteration 17510 : model1 loss : 0.030636 model2 loss : 0.031000
[00:21:33.187] iteration 17511 : model1 loss : 0.030254 model2 loss : 0.027115
[00:21:33.891] iteration 17512 : model1 loss : 0.018082 model2 loss : 0.023403
[00:21:34.598] iteration 17513 : model1 loss : 0.019115 model2 loss : 0.020931
[00:21:35.296] iteration 17514 : model1 loss : 0.019881 model2 loss : 0.021007
[00:21:35.991] iteration 17515 : model1 loss : 0.021470 model2 loss : 0.020952
[00:21:36.692] iteration 17516 : model1 loss : 0.019135 model2 loss : 0.020127
[00:21:37.433] iteration 17517 : model1 loss : 0.023412 model2 loss : 0.023926
[00:21:38.140] iteration 17518 : model1 loss : 0.017126 model2 loss : 0.019080
[00:21:38.881] iteration 17519 : model1 loss : 0.021113 model2 loss : 0.019639
[00:21:39.597] iteration 17520 : model1 loss : 0.018898 model2 loss : 0.018806
[00:21:40.303] iteration 17521 : model1 loss : 0.017847 model2 loss : 0.015942
[00:21:41.003] iteration 17522 : model1 loss : 0.032353 model2 loss : 0.030912
[00:21:41.722] iteration 17523 : model1 loss : 0.159702 model2 loss : 0.189511
[00:21:42.477] iteration 17524 : model1 loss : 0.025694 model2 loss : 0.025553
[00:21:43.185] iteration 17525 : model1 loss : 0.020484 model2 loss : 0.022117
[00:21:43.885] iteration 17526 : model1 loss : 0.031988 model2 loss : 0.029771
[00:21:44.579] iteration 17527 : model1 loss : 0.018163 model2 loss : 0.019094
[00:21:45.309] iteration 17528 : model1 loss : 0.021742 model2 loss : 0.022523
[00:21:46.018] iteration 17529 : model1 loss : 0.019519 model2 loss : 0.016684
[00:21:46.717] iteration 17530 : model1 loss : 0.031487 model2 loss : 0.027495
[00:21:47.465] iteration 17531 : model1 loss : 0.021506 model2 loss : 0.016849
[00:21:48.161] iteration 17532 : model1 loss : 0.023026 model2 loss : 0.019665
[00:21:48.870] iteration 17533 : model1 loss : 0.026139 model2 loss : 0.040186
[00:21:49.575] iteration 17534 : model1 loss : 0.026201 model2 loss : 0.026796
[00:21:50.306] iteration 17535 : model1 loss : 0.022390 model2 loss : 0.021306
[00:21:51.016] iteration 17536 : model1 loss : 0.019514 model2 loss : 0.020960
[00:21:51.727] iteration 17537 : model1 loss : 0.021395 model2 loss : 0.023455
[00:21:52.492] iteration 17538 : model1 loss : 0.019818 model2 loss : 0.024965
[00:21:53.189] iteration 17539 : model1 loss : 0.031295 model2 loss : 0.053298
[00:21:53.897] iteration 17540 : model1 loss : 0.015344 model2 loss : 0.016442
[00:21:54.602] iteration 17541 : model1 loss : 0.019898 model2 loss : 0.019495
[00:21:55.313] iteration 17542 : model1 loss : 0.020964 model2 loss : 0.024214
[00:21:56.019] iteration 17543 : model1 loss : 0.024583 model2 loss : 0.027781
[00:21:56.718] iteration 17544 : model1 loss : 0.020021 model2 loss : 0.020808
[00:21:57.469] iteration 17545 : model1 loss : 0.020165 model2 loss : 0.025913
[00:21:58.174] iteration 17546 : model1 loss : 0.032921 model2 loss : 0.029924
[00:21:58.869] iteration 17547 : model1 loss : 0.027976 model2 loss : 0.028002
[00:21:59.580] iteration 17548 : model1 loss : 0.020200 model2 loss : 0.020783
[00:22:00.288] iteration 17549 : model1 loss : 0.020065 model2 loss : 0.021730
[00:22:00.993] iteration 17550 : model1 loss : 0.016530 model2 loss : 0.018657
[00:22:01.731] iteration 17551 : model1 loss : 0.022567 model2 loss : 0.022397
[00:22:02.495] iteration 17552 : model1 loss : 0.019095 model2 loss : 0.019579
[00:22:03.195] iteration 17553 : model1 loss : 0.025146 model2 loss : 0.025862
[00:22:03.899] iteration 17554 : model1 loss : 0.021692 model2 loss : 0.024398
[00:22:04.604] iteration 17555 : model1 loss : 0.017921 model2 loss : 0.023386
[00:22:05.308] iteration 17556 : model1 loss : 0.019256 model2 loss : 0.019451
[00:22:06.006] iteration 17557 : model1 loss : 0.021120 model2 loss : 0.020924
[00:22:06.711] iteration 17558 : model1 loss : 0.023072 model2 loss : 0.023355
[00:22:07.460] iteration 17559 : model1 loss : 0.023940 model2 loss : 0.023632
[00:22:08.179] iteration 17560 : model1 loss : 0.022760 model2 loss : 0.022775
[00:22:08.890] iteration 17561 : model1 loss : 0.023929 model2 loss : 0.025990
[00:22:09.589] iteration 17562 : model1 loss : 0.047804 model2 loss : 0.117348
[00:22:10.299] iteration 17563 : model1 loss : 0.020781 model2 loss : 0.023468
[00:22:11.009] iteration 17564 : model1 loss : 0.016760 model2 loss : 0.018564
[00:22:11.732] iteration 17565 : model1 loss : 0.023969 model2 loss : 0.024265
[00:22:12.476] iteration 17566 : model1 loss : 0.019737 model2 loss : 0.020531
[00:22:13.178] iteration 17567 : model1 loss : 0.020883 model2 loss : 0.021394
[00:22:13.886] iteration 17568 : model1 loss : 0.041303 model2 loss : 0.090216
[00:22:14.590] iteration 17569 : model1 loss : 0.034874 model2 loss : 0.034302
[00:22:15.290] iteration 17570 : model1 loss : 0.022507 model2 loss : 0.025294
[00:22:15.992] iteration 17571 : model1 loss : 0.021714 model2 loss : 0.027847
[00:22:16.705] iteration 17572 : model1 loss : 0.016742 model2 loss : 0.019733
[00:22:17.453] iteration 17573 : model1 loss : 0.020092 model2 loss : 0.022272
[00:22:18.157] iteration 17574 : model1 loss : 0.020650 model2 loss : 0.021867
[00:22:18.863] iteration 17575 : model1 loss : 0.063942 model2 loss : 0.122234
[00:22:19.565] iteration 17576 : model1 loss : 0.019604 model2 loss : 0.020009
[00:22:20.279] iteration 17577 : model1 loss : 0.026951 model2 loss : 0.061219
[00:22:20.971] iteration 17578 : model1 loss : 0.017629 model2 loss : 0.022415
[00:22:21.692] iteration 17579 : model1 loss : 0.022048 model2 loss : 0.023868
[00:22:22.438] iteration 17580 : model1 loss : 0.017540 model2 loss : 0.017046
[00:22:23.145] iteration 17581 : model1 loss : 0.020710 model2 loss : 0.020717
[00:22:23.859] iteration 17582 : model1 loss : 0.036296 model2 loss : 0.027501
[00:22:24.568] iteration 17583 : model1 loss : 0.021230 model2 loss : 0.020704
[00:22:25.273] iteration 17584 : model1 loss : 0.031321 model2 loss : 0.024145
[00:22:25.967] iteration 17585 : model1 loss : 0.024371 model2 loss : 0.023701
[00:22:26.659] iteration 17586 : model1 loss : 0.021326 model2 loss : 0.023316
[00:22:27.402] iteration 17587 : model1 loss : 0.020616 model2 loss : 0.021215
[00:22:28.121] iteration 17588 : model1 loss : 0.034909 model2 loss : 0.031763
[00:22:28.819] iteration 17589 : model1 loss : 0.026497 model2 loss : 0.026893
[00:22:29.520] iteration 17590 : model1 loss : 0.019642 model2 loss : 0.019759
[00:22:30.218] iteration 17591 : model1 loss : 0.016521 model2 loss : 0.017635
[00:22:30.915] iteration 17592 : model1 loss : 0.029978 model2 loss : 0.025698
[00:22:31.616] iteration 17593 : model1 loss : 0.019729 model2 loss : 0.020566
[00:22:32.361] iteration 17594 : model1 loss : 0.018114 model2 loss : 0.019018
[00:22:33.069] iteration 17595 : model1 loss : 0.027704 model2 loss : 0.027506
[00:22:33.773] iteration 17596 : model1 loss : 0.019956 model2 loss : 0.018400
[00:22:34.474] iteration 17597 : model1 loss : 0.021000 model2 loss : 0.023560
[00:22:35.189] iteration 17598 : model1 loss : 0.021796 model2 loss : 0.024569
[00:22:35.895] iteration 17599 : model1 loss : 0.029165 model2 loss : 0.034615
[00:22:36.602] iteration 17600 : model1 loss : 0.018250 model2 loss : 0.017825
[00:22:56.263] iteration 17600 : model1_mean_dice : 0.863239 model1_mean_hd95 : 7.136623
[00:23:15.936] iteration 17600 : model2_mean_dice : 0.862516 model2_mean_hd95 : 4.297278
[00:23:16.656] iteration 17601 : model1 loss : 0.022731 model2 loss : 0.024582
[00:23:17.394] iteration 17602 : model1 loss : 0.022574 model2 loss : 0.025197
[00:23:18.092] iteration 17603 : model1 loss : 0.027643 model2 loss : 0.031518
[00:23:18.808] iteration 17604 : model1 loss : 0.017160 model2 loss : 0.017596
[00:23:19.498] iteration 17605 : model1 loss : 0.046582 model2 loss : 0.039707
[00:23:20.196] iteration 17606 : model1 loss : 0.017187 model2 loss : 0.018311
[00:23:20.903] iteration 17607 : model1 loss : 0.022712 model2 loss : 0.023573
[00:23:21.605] iteration 17608 : model1 loss : 0.018482 model2 loss : 0.019675
[00:23:22.353] iteration 17609 : model1 loss : 0.021472 model2 loss : 0.026960
[00:23:23.070] iteration 17610 : model1 loss : 0.019334 model2 loss : 0.022103
[00:23:23.772] iteration 17611 : model1 loss : 0.016601 model2 loss : 0.018206
[00:23:24.466] iteration 17612 : model1 loss : 0.018318 model2 loss : 0.020454
[00:23:25.163] iteration 17613 : model1 loss : 0.026099 model2 loss : 0.023911
[00:23:25.861] iteration 17614 : model1 loss : 0.019186 model2 loss : 0.019362
[00:23:26.562] iteration 17615 : model1 loss : 0.021343 model2 loss : 0.021637
[00:23:27.291] iteration 17616 : model1 loss : 0.040164 model2 loss : 0.032381
[00:23:28.002] iteration 17617 : model1 loss : 0.019834 model2 loss : 0.021367
[00:23:28.723] iteration 17618 : model1 loss : 0.030119 model2 loss : 0.038253
[00:23:29.415] iteration 17619 : model1 loss : 0.140712 model2 loss : 0.079010
[00:23:30.130] iteration 17620 : model1 loss : 0.030212 model2 loss : 0.025425
[00:23:30.835] iteration 17621 : model1 loss : 0.020726 model2 loss : 0.020706
[00:23:31.540] iteration 17622 : model1 loss : 0.017291 model2 loss : 0.021391
[00:23:32.278] iteration 17623 : model1 loss : 0.017955 model2 loss : 0.020375
[00:23:32.985] iteration 17624 : model1 loss : 0.019293 model2 loss : 0.018974
[00:23:33.691] iteration 17625 : model1 loss : 0.022510 model2 loss : 0.022973
[00:23:34.436] iteration 17626 : model1 loss : 0.022549 model2 loss : 0.019588
[00:23:35.133] iteration 17627 : model1 loss : 0.019955 model2 loss : 0.023106
[00:23:35.835] iteration 17628 : model1 loss : 0.027832 model2 loss : 0.027307
[00:23:36.549] iteration 17629 : model1 loss : 0.031526 model2 loss : 0.029348
[00:23:37.303] iteration 17630 : model1 loss : 0.022360 model2 loss : 0.025223
[00:23:38.003] iteration 17631 : model1 loss : 0.019047 model2 loss : 0.017773
[00:23:38.708] iteration 17632 : model1 loss : 0.019186 model2 loss : 0.019705
[00:23:39.404] iteration 17633 : model1 loss : 0.019943 model2 loss : 0.021150
[00:23:40.109] iteration 17634 : model1 loss : 0.023806 model2 loss : 0.029427
[00:23:40.802] iteration 17635 : model1 loss : 0.143874 model2 loss : 0.143121
[00:23:41.511] iteration 17636 : model1 loss : 0.019082 model2 loss : 0.021034
[00:23:42.264] iteration 17637 : model1 loss : 0.023578 model2 loss : 0.025940
[00:23:42.977] iteration 17638 : model1 loss : 0.022258 model2 loss : 0.022728
[00:23:43.671] iteration 17639 : model1 loss : 0.029734 model2 loss : 0.029811
[00:23:44.371] iteration 17640 : model1 loss : 0.022501 model2 loss : 0.024475
[00:23:45.061] iteration 17641 : model1 loss : 0.028165 model2 loss : 0.021940
[00:23:45.791] iteration 17642 : model1 loss : 0.020921 model2 loss : 0.019227
[00:23:46.497] iteration 17643 : model1 loss : 0.020337 model2 loss : 0.019732
[00:23:47.239] iteration 17644 : model1 loss : 0.020697 model2 loss : 0.022590
[00:23:47.936] iteration 17645 : model1 loss : 0.019998 model2 loss : 0.019588
[00:23:48.650] iteration 17646 : model1 loss : 0.023603 model2 loss : 0.022056
[00:23:49.346] iteration 17647 : model1 loss : 0.020795 model2 loss : 0.023894
[00:23:50.062] iteration 17648 : model1 loss : 0.027169 model2 loss : 0.024702
[00:23:50.759] iteration 17649 : model1 loss : 0.021056 model2 loss : 0.021122
[00:23:51.459] iteration 17650 : model1 loss : 0.013243 model2 loss : 0.013880
[00:23:52.242] iteration 17651 : model1 loss : 0.041611 model2 loss : 0.041305
[00:23:52.945] iteration 17652 : model1 loss : 0.033811 model2 loss : 0.027017
[00:23:53.644] iteration 17653 : model1 loss : 0.022958 model2 loss : 0.024661
[00:23:54.354] iteration 17654 : model1 loss : 0.018459 model2 loss : 0.017022
[00:23:55.060] iteration 17655 : model1 loss : 0.021461 model2 loss : 0.019754
[00:23:55.754] iteration 17656 : model1 loss : 0.016173 model2 loss : 0.016476
[00:23:56.459] iteration 17657 : model1 loss : 0.016222 model2 loss : 0.017424
[00:23:57.179] iteration 17658 : model1 loss : 0.014253 model2 loss : 0.013839
[00:23:57.893] iteration 17659 : model1 loss : 0.017359 model2 loss : 0.017302
[00:23:58.618] iteration 17660 : model1 loss : 0.021867 model2 loss : 0.024981
[00:23:59.319] iteration 17661 : model1 loss : 0.020519 model2 loss : 0.019698
[00:24:00.020] iteration 17662 : model1 loss : 0.021637 model2 loss : 0.021637
[00:24:00.732] iteration 17663 : model1 loss : 0.021738 model2 loss : 0.020483
[00:24:01.437] iteration 17664 : model1 loss : 0.027566 model2 loss : 0.024432
[00:24:02.164] iteration 17665 : model1 loss : 0.031510 model2 loss : 0.027061
[00:24:02.882] iteration 17666 : model1 loss : 0.017354 model2 loss : 0.017043
[00:24:03.583] iteration 17667 : model1 loss : 0.020940 model2 loss : 0.022703
[00:24:04.293] iteration 17668 : model1 loss : 0.025300 model2 loss : 0.023669
[00:24:05.006] iteration 17669 : model1 loss : 0.023801 model2 loss : 0.024764
[00:24:05.713] iteration 17670 : model1 loss : 0.018589 model2 loss : 0.018456
[00:24:06.432] iteration 17671 : model1 loss : 0.025755 model2 loss : 0.025402
[00:24:07.154] iteration 17672 : model1 loss : 0.020569 model2 loss : 0.021324
[00:24:07.878] iteration 17673 : model1 loss : 0.022605 model2 loss : 0.020744
[00:24:08.581] iteration 17674 : model1 loss : 0.027287 model2 loss : 0.025445
[00:24:09.292] iteration 17675 : model1 loss : 0.015669 model2 loss : 0.015661
[00:24:09.989] iteration 17676 : model1 loss : 0.019464 model2 loss : 0.019462
[00:24:10.685] iteration 17677 : model1 loss : 0.021027 model2 loss : 0.020931
[00:24:11.394] iteration 17678 : model1 loss : 0.021614 model2 loss : 0.020426
[00:24:12.121] iteration 17679 : model1 loss : 0.024260 model2 loss : 0.025589
[00:24:12.849] iteration 17680 : model1 loss : 0.018299 model2 loss : 0.019917
[00:24:13.570] iteration 17681 : model1 loss : 0.017965 model2 loss : 0.018211
[00:24:14.274] iteration 17682 : model1 loss : 0.019068 model2 loss : 0.020782
[00:24:14.970] iteration 17683 : model1 loss : 0.019276 model2 loss : 0.018642
[00:24:15.691] iteration 17684 : model1 loss : 0.020313 model2 loss : 0.019964
[00:24:16.400] iteration 17685 : model1 loss : 0.020473 model2 loss : 0.018727
[00:24:17.123] iteration 17686 : model1 loss : 0.031293 model2 loss : 0.031278
[00:24:17.849] iteration 17687 : model1 loss : 0.040251 model2 loss : 0.040099
[00:24:18.556] iteration 17688 : model1 loss : 0.018545 model2 loss : 0.018754
[00:24:19.254] iteration 17689 : model1 loss : 0.014672 model2 loss : 0.015371
[00:24:19.965] iteration 17690 : model1 loss : 0.023863 model2 loss : 0.025204
[00:24:20.662] iteration 17691 : model1 loss : 0.025539 model2 loss : 0.024983
[00:24:21.374] iteration 17692 : model1 loss : 0.145140 model2 loss : 0.149854
[00:24:22.101] iteration 17693 : model1 loss : 0.028225 model2 loss : 0.020973
[00:24:22.808] iteration 17694 : model1 loss : 0.017468 model2 loss : 0.018803
[00:24:23.519] iteration 17695 : model1 loss : 0.033580 model2 loss : 0.021842
[00:24:24.223] iteration 17696 : model1 loss : 0.017113 model2 loss : 0.016483
[00:24:24.918] iteration 17697 : model1 loss : 0.018252 model2 loss : 0.019442
[00:24:25.617] iteration 17698 : model1 loss : 0.016949 model2 loss : 0.019810
[00:24:26.340] iteration 17699 : model1 loss : 0.028276 model2 loss : 0.025580
[00:24:27.067] iteration 17700 : model1 loss : 0.019328 model2 loss : 0.019153
[00:24:27.832] iteration 17701 : model1 loss : 0.020484 model2 loss : 0.021010
[00:24:28.540] iteration 17702 : model1 loss : 0.019719 model2 loss : 0.018450
[00:24:29.243] iteration 17703 : model1 loss : 0.018579 model2 loss : 0.019960
[00:24:29.960] iteration 17704 : model1 loss : 0.020808 model2 loss : 0.019903
[00:24:30.662] iteration 17705 : model1 loss : 0.058841 model2 loss : 0.054259
[00:24:31.373] iteration 17706 : model1 loss : 0.020186 model2 loss : 0.019652
[00:24:32.120] iteration 17707 : model1 loss : 0.025000 model2 loss : 0.024469
[00:24:32.848] iteration 17708 : model1 loss : 0.020877 model2 loss : 0.021161
[00:24:33.561] iteration 17709 : model1 loss : 0.020353 model2 loss : 0.019169
[00:24:34.265] iteration 17710 : model1 loss : 0.023054 model2 loss : 0.023606
[00:24:34.964] iteration 17711 : model1 loss : 0.020951 model2 loss : 0.020812
[00:24:35.669] iteration 17712 : model1 loss : 0.020297 model2 loss : 0.020341
[00:24:36.380] iteration 17713 : model1 loss : 0.019367 model2 loss : 0.017410
[00:24:37.114] iteration 17714 : model1 loss : 0.027637 model2 loss : 0.024314
[00:24:37.823] iteration 17715 : model1 loss : 0.020010 model2 loss : 0.020161
[00:24:38.541] iteration 17716 : model1 loss : 0.020687 model2 loss : 0.020453
[00:24:39.250] iteration 17717 : model1 loss : 0.024655 model2 loss : 0.024313
[00:24:39.942] iteration 17718 : model1 loss : 0.032012 model2 loss : 0.034599
[00:24:40.653] iteration 17719 : model1 loss : 0.018350 model2 loss : 0.018489
[00:24:41.361] iteration 17720 : model1 loss : 0.025719 model2 loss : 0.023657
[00:24:42.104] iteration 17721 : model1 loss : 0.019074 model2 loss : 0.020352
[00:24:42.815] iteration 17722 : model1 loss : 0.015639 model2 loss : 0.014545
[00:24:43.525] iteration 17723 : model1 loss : 0.026790 model2 loss : 0.027016
[00:24:44.227] iteration 17724 : model1 loss : 0.018829 model2 loss : 0.019405
[00:24:44.925] iteration 17725 : model1 loss : 0.018610 model2 loss : 0.017523
[00:24:45.628] iteration 17726 : model1 loss : 0.026183 model2 loss : 0.028401
[00:24:46.336] iteration 17727 : model1 loss : 0.017953 model2 loss : 0.017217
[00:24:47.060] iteration 17728 : model1 loss : 0.022950 model2 loss : 0.026006
[00:24:47.779] iteration 17729 : model1 loss : 0.020289 model2 loss : 0.020662
[00:24:48.488] iteration 17730 : model1 loss : 0.014399 model2 loss : 0.014581
[00:24:49.202] iteration 17731 : model1 loss : 0.022321 model2 loss : 0.021989
[00:24:49.904] iteration 17732 : model1 loss : 0.024173 model2 loss : 0.025095
[00:24:50.605] iteration 17733 : model1 loss : 0.023098 model2 loss : 0.022687
[00:24:51.307] iteration 17734 : model1 loss : 0.027293 model2 loss : 0.025980
[00:24:52.028] iteration 17735 : model1 loss : 0.021175 model2 loss : 0.018148
[00:24:52.759] iteration 17736 : model1 loss : 0.026301 model2 loss : 0.025627
[00:24:53.490] iteration 17737 : model1 loss : 0.019215 model2 loss : 0.021585
[00:24:54.211] iteration 17738 : model1 loss : 0.149279 model2 loss : 0.153762
[00:24:54.927] iteration 17739 : model1 loss : 0.021386 model2 loss : 0.023929
[00:24:55.626] iteration 17740 : model1 loss : 0.018329 model2 loss : 0.020949
[00:24:56.323] iteration 17741 : model1 loss : 0.017478 model2 loss : 0.019943
[00:24:57.047] iteration 17742 : model1 loss : 0.021774 model2 loss : 0.020279
[00:24:57.790] iteration 17743 : model1 loss : 0.020257 model2 loss : 0.020026
[00:24:58.496] iteration 17744 : model1 loss : 0.019144 model2 loss : 0.019471
[00:24:59.197] iteration 17745 : model1 loss : 0.029338 model2 loss : 0.027420
[00:24:59.910] iteration 17746 : model1 loss : 0.016604 model2 loss : 0.018101
[00:25:00.629] iteration 17747 : model1 loss : 0.021053 model2 loss : 0.024043
[00:25:01.332] iteration 17748 : model1 loss : 0.031810 model2 loss : 0.030337
[00:25:02.066] iteration 17749 : model1 loss : 0.108751 model2 loss : 0.039707
[00:25:02.791] iteration 17750 : model1 loss : 0.033064 model2 loss : 0.035117
[00:25:03.546] iteration 17751 : model1 loss : 0.020157 model2 loss : 0.018603
[00:25:04.248] iteration 17752 : model1 loss : 0.019388 model2 loss : 0.019083
[00:25:04.952] iteration 17753 : model1 loss : 0.021829 model2 loss : 0.020109
[00:25:05.655] iteration 17754 : model1 loss : 0.022381 model2 loss : 0.023908
[00:25:06.369] iteration 17755 : model1 loss : 0.031438 model2 loss : 0.031888
[00:25:07.088] iteration 17756 : model1 loss : 0.019358 model2 loss : 0.021081
[00:25:07.801] iteration 17757 : model1 loss : 0.020567 model2 loss : 0.019613
[00:25:08.519] iteration 17758 : model1 loss : 0.012859 model2 loss : 0.015201
[00:25:09.218] iteration 17759 : model1 loss : 0.033328 model2 loss : 0.026224
[00:25:09.921] iteration 17760 : model1 loss : 0.026514 model2 loss : 0.027398
[00:25:10.619] iteration 17761 : model1 loss : 0.029857 model2 loss : 0.029529
[00:25:11.337] iteration 17762 : model1 loss : 0.019321 model2 loss : 0.019595
[00:25:12.066] iteration 17763 : model1 loss : 0.033652 model2 loss : 0.027953
[00:25:12.796] iteration 17764 : model1 loss : 0.021985 model2 loss : 0.022420
[00:25:13.520] iteration 17765 : model1 loss : 0.023117 model2 loss : 0.023712
[00:25:14.270] iteration 17766 : model1 loss : 0.032053 model2 loss : 0.034995
[00:25:14.972] iteration 17767 : model1 loss : 0.030045 model2 loss : 0.035409
[00:25:15.681] iteration 17768 : model1 loss : 0.019216 model2 loss : 0.016859
[00:25:16.390] iteration 17769 : model1 loss : 0.027538 model2 loss : 0.028152
[00:25:17.120] iteration 17770 : model1 loss : 0.021220 model2 loss : 0.023025
[00:25:17.847] iteration 17771 : model1 loss : 0.021050 model2 loss : 0.019791
[00:25:18.552] iteration 17772 : model1 loss : 0.032126 model2 loss : 0.031940
[00:25:19.271] iteration 17773 : model1 loss : 0.025285 model2 loss : 0.025931
[00:25:19.986] iteration 17774 : model1 loss : 0.024151 model2 loss : 0.026309
[00:25:20.695] iteration 17775 : model1 loss : 0.022117 model2 loss : 0.022390
[00:25:21.399] iteration 17776 : model1 loss : 0.017393 model2 loss : 0.020301
[00:25:22.137] iteration 17777 : model1 loss : 0.015782 model2 loss : 0.018822
[00:25:22.858] iteration 17778 : model1 loss : 0.021246 model2 loss : 0.021780
[00:25:23.559] iteration 17779 : model1 loss : 0.023597 model2 loss : 0.025048
[00:25:24.273] iteration 17780 : model1 loss : 0.022200 model2 loss : 0.022637
[00:25:24.957] iteration 17781 : model1 loss : 0.016598 model2 loss : 0.018135
[00:25:25.658] iteration 17782 : model1 loss : 0.021356 model2 loss : 0.026238
[00:25:26.361] iteration 17783 : model1 loss : 0.021490 model2 loss : 0.023495
[00:25:27.081] iteration 17784 : model1 loss : 0.044970 model2 loss : 0.052843
[00:25:27.802] iteration 17785 : model1 loss : 0.023392 model2 loss : 0.020706
[00:25:28.501] iteration 17786 : model1 loss : 0.023443 model2 loss : 0.021212
[00:25:29.211] iteration 17787 : model1 loss : 0.022786 model2 loss : 0.023244
[00:25:29.923] iteration 17788 : model1 loss : 0.072920 model2 loss : 0.079180
[00:25:30.613] iteration 17789 : model1 loss : 0.023447 model2 loss : 0.019844
[00:25:31.312] iteration 17790 : model1 loss : 0.014440 model2 loss : 0.015430
[00:25:32.043] iteration 17791 : model1 loss : 0.017536 model2 loss : 0.018273
[00:25:32.778] iteration 17792 : model1 loss : 0.018758 model2 loss : 0.019394
[00:25:33.486] iteration 17793 : model1 loss : 0.016800 model2 loss : 0.016677
[00:25:34.192] iteration 17794 : model1 loss : 0.020584 model2 loss : 0.018123
[00:25:34.902] iteration 17795 : model1 loss : 0.023748 model2 loss : 0.023119
[00:25:35.602] iteration 17796 : model1 loss : 0.023120 model2 loss : 0.021357
[00:25:36.306] iteration 17797 : model1 loss : 0.025937 model2 loss : 0.026906
[00:25:37.030] iteration 17798 : model1 loss : 0.016638 model2 loss : 0.017447
[00:25:37.751] iteration 17799 : model1 loss : 0.021949 model2 loss : 0.022910
[00:25:38.464] iteration 17800 : model1 loss : 0.019432 model2 loss : 0.017649
[00:25:58.278] iteration 17800 : model1_mean_dice : 0.859681 model1_mean_hd95 : 8.580035
[00:26:17.955] iteration 17800 : model2_mean_dice : 0.870026 model2_mean_hd95 : 5.128581
[00:26:18.684] iteration 17801 : model1 loss : 0.028517 model2 loss : 0.025494
[00:26:19.371] iteration 17802 : model1 loss : 0.025603 model2 loss : 0.024145
[00:26:20.068] iteration 17803 : model1 loss : 0.026169 model2 loss : 0.025582
[00:26:20.757] iteration 17804 : model1 loss : 0.018886 model2 loss : 0.021533
[00:26:21.480] iteration 17805 : model1 loss : 0.020140 model2 loss : 0.017924
[00:26:22.217] iteration 17806 : model1 loss : 0.020483 model2 loss : 0.021118
[00:26:22.924] iteration 17807 : model1 loss : 0.022734 model2 loss : 0.020966
[00:26:23.630] iteration 17808 : model1 loss : 0.023898 model2 loss : 0.024251
[00:26:24.331] iteration 17809 : model1 loss : 0.027784 model2 loss : 0.025859
[00:26:25.039] iteration 17810 : model1 loss : 0.020745 model2 loss : 0.021593
[00:26:25.740] iteration 17811 : model1 loss : 0.141988 model2 loss : 0.143818
[00:26:26.443] iteration 17812 : model1 loss : 0.022186 model2 loss : 0.025710
[00:26:27.174] iteration 17813 : model1 loss : 0.034817 model2 loss : 0.032969
[00:26:27.882] iteration 17814 : model1 loss : 0.020241 model2 loss : 0.020775
[00:26:28.585] iteration 17815 : model1 loss : 0.060095 model2 loss : 0.034944
[00:26:29.290] iteration 17816 : model1 loss : 0.022875 model2 loss : 0.020618
[00:26:29.989] iteration 17817 : model1 loss : 0.023499 model2 loss : 0.021186
[00:26:30.695] iteration 17818 : model1 loss : 0.020800 model2 loss : 0.020053
[00:26:31.386] iteration 17819 : model1 loss : 0.020357 model2 loss : 0.022056
[00:26:32.116] iteration 17820 : model1 loss : 0.021748 model2 loss : 0.022416
[00:26:32.840] iteration 17821 : model1 loss : 0.018989 model2 loss : 0.017073
[00:26:33.550] iteration 17822 : model1 loss : 0.017917 model2 loss : 0.018037
[00:26:34.259] iteration 17823 : model1 loss : 0.018218 model2 loss : 0.018494
[00:26:34.959] iteration 17824 : model1 loss : 0.021428 model2 loss : 0.022857
[00:26:35.669] iteration 17825 : model1 loss : 0.016882 model2 loss : 0.015571
[00:26:36.373] iteration 17826 : model1 loss : 0.019141 model2 loss : 0.020405
[00:26:37.121] iteration 17827 : model1 loss : 0.021448 model2 loss : 0.019143
[00:26:37.845] iteration 17828 : model1 loss : 0.021977 model2 loss : 0.020699
[00:26:38.551] iteration 17829 : model1 loss : 0.022082 model2 loss : 0.019808
[00:26:39.240] iteration 17830 : model1 loss : 0.025085 model2 loss : 0.021431
[00:26:39.949] iteration 17831 : model1 loss : 0.022006 model2 loss : 0.022513
[00:26:40.656] iteration 17832 : model1 loss : 0.028636 model2 loss : 0.033652
[00:26:41.375] iteration 17833 : model1 loss : 0.021940 model2 loss : 0.022454
[00:26:42.111] iteration 17834 : model1 loss : 0.019215 model2 loss : 0.020148
[00:26:42.823] iteration 17835 : model1 loss : 0.055777 model2 loss : 0.059807
[00:26:43.519] iteration 17836 : model1 loss : 0.029323 model2 loss : 0.028875
[00:26:44.226] iteration 17837 : model1 loss : 0.024519 model2 loss : 0.024888
[00:26:44.919] iteration 17838 : model1 loss : 0.015592 model2 loss : 0.016034
[00:26:45.621] iteration 17839 : model1 loss : 0.020391 model2 loss : 0.020789
[00:26:46.322] iteration 17840 : model1 loss : 0.016659 model2 loss : 0.016024
[00:26:47.027] iteration 17841 : model1 loss : 0.015552 model2 loss : 0.014002
[00:26:47.757] iteration 17842 : model1 loss : 0.018824 model2 loss : 0.020168
[00:26:48.467] iteration 17843 : model1 loss : 0.018408 model2 loss : 0.022846
[00:26:49.161] iteration 17844 : model1 loss : 0.021110 model2 loss : 0.020132
[00:26:49.858] iteration 17845 : model1 loss : 0.020663 model2 loss : 0.020542
[00:26:50.555] iteration 17846 : model1 loss : 0.024529 model2 loss : 0.024142
[00:26:51.265] iteration 17847 : model1 loss : 0.028262 model2 loss : 0.039559
[00:26:51.974] iteration 17848 : model1 loss : 0.023118 model2 loss : 0.026128
[00:26:52.711] iteration 17849 : model1 loss : 0.021092 model2 loss : 0.021915
[00:26:53.416] iteration 17850 : model1 loss : 0.018973 model2 loss : 0.020995
[00:26:54.177] iteration 17851 : model1 loss : 0.022895 model2 loss : 0.027902
[00:26:54.881] iteration 17852 : model1 loss : 0.016273 model2 loss : 0.016532
[00:26:55.592] iteration 17853 : model1 loss : 0.025748 model2 loss : 0.029287
[00:26:56.288] iteration 17854 : model1 loss : 0.027972 model2 loss : 0.023280
[00:26:56.992] iteration 17855 : model1 loss : 0.023680 model2 loss : 0.021257
[00:26:57.716] iteration 17856 : model1 loss : 0.023698 model2 loss : 0.030906
[00:26:58.417] iteration 17857 : model1 loss : 0.021329 model2 loss : 0.022549
[00:26:59.118] iteration 17858 : model1 loss : 0.020723 model2 loss : 0.019500
[00:26:59.817] iteration 17859 : model1 loss : 0.031489 model2 loss : 0.036552
[00:27:00.521] iteration 17860 : model1 loss : 0.029980 model2 loss : 0.028730
[00:27:01.231] iteration 17861 : model1 loss : 0.020941 model2 loss : 0.021377
[00:27:01.974] iteration 17862 : model1 loss : 0.025934 model2 loss : 0.026370
[00:27:02.714] iteration 17863 : model1 loss : 0.029971 model2 loss : 0.031247
[00:27:03.434] iteration 17864 : model1 loss : 0.018252 model2 loss : 0.017224
[00:27:04.133] iteration 17865 : model1 loss : 0.018896 model2 loss : 0.020219
[00:27:04.838] iteration 17866 : model1 loss : 0.018381 model2 loss : 0.019761
[00:27:05.562] iteration 17867 : model1 loss : 0.016539 model2 loss : 0.016540
[00:27:06.268] iteration 17868 : model1 loss : 0.021608 model2 loss : 0.023163
[00:27:06.989] iteration 17869 : model1 loss : 0.025118 model2 loss : 0.024505
[00:27:07.712] iteration 17870 : model1 loss : 0.020285 model2 loss : 0.020072
[00:27:08.409] iteration 17871 : model1 loss : 0.021667 model2 loss : 0.021280
[00:27:09.114] iteration 17872 : model1 loss : 0.023221 model2 loss : 0.027085
[00:27:09.811] iteration 17873 : model1 loss : 0.025680 model2 loss : 0.024117
[00:27:10.516] iteration 17874 : model1 loss : 0.017645 model2 loss : 0.017026
[00:27:11.220] iteration 17875 : model1 loss : 0.023816 model2 loss : 0.024760
[00:27:11.931] iteration 17876 : model1 loss : 0.019659 model2 loss : 0.021924
[00:27:12.671] iteration 17877 : model1 loss : 0.025354 model2 loss : 0.028005
[00:27:13.404] iteration 17878 : model1 loss : 0.015922 model2 loss : 0.018497
[00:27:14.091] iteration 17879 : model1 loss : 0.023496 model2 loss : 0.021028
[00:27:14.789] iteration 17880 : model1 loss : 0.020279 model2 loss : 0.021048
[00:27:15.499] iteration 17881 : model1 loss : 0.015567 model2 loss : 0.015153
[00:27:16.196] iteration 17882 : model1 loss : 0.016891 model2 loss : 0.017523
[00:27:16.905] iteration 17883 : model1 loss : 0.021738 model2 loss : 0.022259
[00:27:17.644] iteration 17884 : model1 loss : 0.020939 model2 loss : 0.020913
[00:27:18.355] iteration 17885 : model1 loss : 0.022008 model2 loss : 0.020390
[00:27:19.061] iteration 17886 : model1 loss : 0.018322 model2 loss : 0.018475
[00:27:19.789] iteration 17887 : model1 loss : 0.022506 model2 loss : 0.021462
[00:27:20.506] iteration 17888 : model1 loss : 0.021384 model2 loss : 0.019687
[00:27:21.211] iteration 17889 : model1 loss : 0.014819 model2 loss : 0.015431
[00:27:21.929] iteration 17890 : model1 loss : 0.020728 model2 loss : 0.022240
[00:27:22.662] iteration 17891 : model1 loss : 0.022902 model2 loss : 0.023758
[00:27:23.373] iteration 17892 : model1 loss : 0.023939 model2 loss : 0.024622
[00:27:24.077] iteration 17893 : model1 loss : 0.019307 model2 loss : 0.021726
[00:27:24.776] iteration 17894 : model1 loss : 0.025060 model2 loss : 0.022456
[00:27:25.485] iteration 17895 : model1 loss : 0.022974 model2 loss : 0.020509
[00:27:26.181] iteration 17896 : model1 loss : 0.022451 model2 loss : 0.021188
[00:27:26.904] iteration 17897 : model1 loss : 0.022993 model2 loss : 0.023194
[00:27:27.648] iteration 17898 : model1 loss : 0.023822 model2 loss : 0.025651
[00:27:28.355] iteration 17899 : model1 loss : 0.017949 model2 loss : 0.018398
[00:27:29.072] iteration 17900 : model1 loss : 0.022675 model2 loss : 0.029181
[00:27:29.822] iteration 17901 : model1 loss : 0.022021 model2 loss : 0.020093
[00:27:30.524] iteration 17902 : model1 loss : 0.022166 model2 loss : 0.024733
[00:27:31.215] iteration 17903 : model1 loss : 0.017169 model2 loss : 0.018243
[00:27:31.940] iteration 17904 : model1 loss : 0.021141 model2 loss : 0.024173
[00:27:32.678] iteration 17905 : model1 loss : 0.019068 model2 loss : 0.018635
[00:27:33.384] iteration 17906 : model1 loss : 0.021624 model2 loss : 0.021597
[00:27:34.100] iteration 17907 : model1 loss : 0.018435 model2 loss : 0.017795
[00:27:34.821] iteration 17908 : model1 loss : 0.022669 model2 loss : 0.023956
[00:27:35.533] iteration 17909 : model1 loss : 0.028241 model2 loss : 0.026591
[00:27:36.228] iteration 17910 : model1 loss : 0.018871 model2 loss : 0.022026
[00:27:36.950] iteration 17911 : model1 loss : 0.021608 model2 loss : 0.022615
[00:27:37.675] iteration 17912 : model1 loss : 0.029971 model2 loss : 0.027729
[00:27:38.379] iteration 17913 : model1 loss : 0.022275 model2 loss : 0.022112
[00:27:39.085] iteration 17914 : model1 loss : 0.034061 model2 loss : 0.040151
[00:27:39.806] iteration 17915 : model1 loss : 0.025174 model2 loss : 0.024286
[00:27:40.504] iteration 17916 : model1 loss : 0.022204 model2 loss : 0.022821
[00:27:41.207] iteration 17917 : model1 loss : 0.019091 model2 loss : 0.018382
[00:27:41.944] iteration 17918 : model1 loss : 0.021565 model2 loss : 0.021528
[00:27:42.709] iteration 17919 : model1 loss : 0.020099 model2 loss : 0.020755
[00:27:43.453] iteration 17920 : model1 loss : 0.021110 model2 loss : 0.020282
[00:27:44.180] iteration 17921 : model1 loss : 0.091827 model2 loss : 0.098819
[00:27:44.914] iteration 17922 : model1 loss : 0.017673 model2 loss : 0.017790
[00:27:45.650] iteration 17923 : model1 loss : 0.021646 model2 loss : 0.022573
[00:27:46.364] iteration 17924 : model1 loss : 0.031463 model2 loss : 0.028042
[00:27:47.080] iteration 17925 : model1 loss : 0.017353 model2 loss : 0.019268
[00:27:47.796] iteration 17926 : model1 loss : 0.016439 model2 loss : 0.019442
[00:27:48.508] iteration 17927 : model1 loss : 0.021983 model2 loss : 0.032448
[00:27:49.205] iteration 17928 : model1 loss : 0.020633 model2 loss : 0.021204
[00:27:49.906] iteration 17929 : model1 loss : 0.022718 model2 loss : 0.023782
[00:27:50.607] iteration 17930 : model1 loss : 0.019811 model2 loss : 0.021751
[00:27:51.319] iteration 17931 : model1 loss : 0.142842 model2 loss : 0.143092
[00:27:52.049] iteration 17932 : model1 loss : 0.021745 model2 loss : 0.019960
[00:27:52.772] iteration 17933 : model1 loss : 0.012925 model2 loss : 0.018318
[00:27:53.472] iteration 17934 : model1 loss : 0.018532 model2 loss : 0.019391
[00:27:54.183] iteration 17935 : model1 loss : 0.018716 model2 loss : 0.020682
[00:27:54.885] iteration 17936 : model1 loss : 0.015689 model2 loss : 0.017776
[00:27:55.596] iteration 17937 : model1 loss : 0.057289 model2 loss : 0.083692
[00:27:56.295] iteration 17938 : model1 loss : 0.018566 model2 loss : 0.026951
[00:27:57.020] iteration 17939 : model1 loss : 0.021464 model2 loss : 0.025944
[00:27:57.737] iteration 17940 : model1 loss : 0.017102 model2 loss : 0.017891
[00:27:58.433] iteration 17941 : model1 loss : 0.026596 model2 loss : 0.028148
[00:27:59.138] iteration 17942 : model1 loss : 0.040665 model2 loss : 0.048120
[00:27:59.843] iteration 17943 : model1 loss : 0.022406 model2 loss : 0.024651
[00:28:00.550] iteration 17944 : model1 loss : 0.015958 model2 loss : 0.018598
[00:28:01.258] iteration 17945 : model1 loss : 0.018816 model2 loss : 0.023638
[00:28:01.989] iteration 17946 : model1 loss : 0.017529 model2 loss : 0.018913
[00:28:02.732] iteration 17947 : model1 loss : 0.028733 model2 loss : 0.030962
[00:28:03.447] iteration 17948 : model1 loss : 0.071025 model2 loss : 0.068808
[00:28:04.152] iteration 17949 : model1 loss : 0.024021 model2 loss : 0.024507
[00:28:04.871] iteration 17950 : model1 loss : 0.019646 model2 loss : 0.017232
[00:28:05.620] iteration 17951 : model1 loss : 0.020814 model2 loss : 0.023749
[00:28:06.331] iteration 17952 : model1 loss : 0.019469 model2 loss : 0.018420
[00:28:07.056] iteration 17953 : model1 loss : 0.018507 model2 loss : 0.026703
[00:28:07.775] iteration 17954 : model1 loss : 0.022336 model2 loss : 0.022235
[00:28:08.479] iteration 17955 : model1 loss : 0.030228 model2 loss : 0.032415
[00:28:09.175] iteration 17956 : model1 loss : 0.019163 model2 loss : 0.017379
[00:28:09.875] iteration 17957 : model1 loss : 0.022469 model2 loss : 0.022557
[00:28:10.585] iteration 17958 : model1 loss : 0.026193 model2 loss : 0.024914
[00:28:11.293] iteration 17959 : model1 loss : 0.026941 model2 loss : 0.023194
[00:28:12.014] iteration 17960 : model1 loss : 0.016730 model2 loss : 0.017118
[00:28:12.754] iteration 17961 : model1 loss : 0.019513 model2 loss : 0.019506
[00:28:13.467] iteration 17962 : model1 loss : 0.020514 model2 loss : 0.021250
[00:28:14.183] iteration 17963 : model1 loss : 0.022380 model2 loss : 0.022595
[00:28:14.882] iteration 17964 : model1 loss : 0.035151 model2 loss : 0.034314
[00:28:15.589] iteration 17965 : model1 loss : 0.018003 model2 loss : 0.016999
[00:28:16.300] iteration 17966 : model1 loss : 0.019202 model2 loss : 0.020249
[00:28:17.024] iteration 17967 : model1 loss : 0.030404 model2 loss : 0.026781
[00:28:17.742] iteration 17968 : model1 loss : 0.020701 model2 loss : 0.019700
[00:28:18.441] iteration 17969 : model1 loss : 0.020777 model2 loss : 0.021513
[00:28:19.151] iteration 17970 : model1 loss : 0.021625 model2 loss : 0.020043
[00:28:19.848] iteration 17971 : model1 loss : 0.024478 model2 loss : 0.021901
[00:28:20.550] iteration 17972 : model1 loss : 0.023714 model2 loss : 0.025109
[00:28:21.246] iteration 17973 : model1 loss : 0.026079 model2 loss : 0.023934
[00:28:21.966] iteration 17974 : model1 loss : 0.136983 model2 loss : 0.138397
[00:28:22.701] iteration 17975 : model1 loss : 0.028680 model2 loss : 0.026979
[00:28:23.399] iteration 17976 : model1 loss : 0.026891 model2 loss : 0.026023
[00:28:24.101] iteration 17977 : model1 loss : 0.030898 model2 loss : 0.026615
[00:28:24.802] iteration 17978 : model1 loss : 0.016033 model2 loss : 0.016486
[00:28:25.505] iteration 17979 : model1 loss : 0.020107 model2 loss : 0.022440
[00:28:26.198] iteration 17980 : model1 loss : 0.015163 model2 loss : 0.014953
[00:28:26.912] iteration 17981 : model1 loss : 0.025572 model2 loss : 0.025706
[00:28:27.648] iteration 17982 : model1 loss : 0.028941 model2 loss : 0.028964
[00:28:28.350] iteration 17983 : model1 loss : 0.023435 model2 loss : 0.025184
[00:28:29.054] iteration 17984 : model1 loss : 0.019341 model2 loss : 0.018284
[00:28:29.783] iteration 17985 : model1 loss : 0.021790 model2 loss : 0.023039
[00:28:30.489] iteration 17986 : model1 loss : 0.025206 model2 loss : 0.024005
[00:28:31.192] iteration 17987 : model1 loss : 0.040554 model2 loss : 0.036240
[00:28:31.913] iteration 17988 : model1 loss : 0.025425 model2 loss : 0.029600
[00:28:32.640] iteration 17989 : model1 loss : 0.020027 model2 loss : 0.021751
[00:28:33.341] iteration 17990 : model1 loss : 0.018601 model2 loss : 0.019877
[00:28:34.042] iteration 17991 : model1 loss : 0.025654 model2 loss : 0.024419
[00:28:34.743] iteration 17992 : model1 loss : 0.051930 model2 loss : 0.054759
[00:28:35.463] iteration 17993 : model1 loss : 0.020509 model2 loss : 0.021951
[00:28:36.162] iteration 17994 : model1 loss : 0.025971 model2 loss : 0.024785
[00:28:36.899] iteration 17995 : model1 loss : 0.017864 model2 loss : 0.020316
[00:28:37.627] iteration 17996 : model1 loss : 0.018228 model2 loss : 0.020174
[00:28:38.336] iteration 17997 : model1 loss : 0.020975 model2 loss : 0.020470
[00:28:39.032] iteration 17998 : model1 loss : 0.019530 model2 loss : 0.018597
[00:28:39.728] iteration 17999 : model1 loss : 0.022614 model2 loss : 0.020151
[00:28:40.438] iteration 18000 : model1 loss : 0.029011 model2 loss : 0.026103
[00:29:00.061] iteration 18000 : model1_mean_dice : 0.869042 model1_mean_hd95 : 6.560084
[00:29:19.558] iteration 18000 : model2_mean_dice : 0.875081 model2_mean_hd95 : 4.764730
[00:29:19.624] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_18000.pth
[00:29:19.682] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_18000.pth
[00:29:20.419] iteration 18001 : model1 loss : 0.019900 model2 loss : 0.020375
[00:29:21.133] iteration 18002 : model1 loss : 0.033711 model2 loss : 0.038460
[00:29:21.839] iteration 18003 : model1 loss : 0.014581 model2 loss : 0.017100
[00:29:22.579] iteration 18004 : model1 loss : 0.024678 model2 loss : 0.025057
[00:29:23.279] iteration 18005 : model1 loss : 0.016588 model2 loss : 0.018382
[00:29:23.966] iteration 18006 : model1 loss : 0.018919 model2 loss : 0.021051
[00:29:24.674] iteration 18007 : model1 loss : 0.019543 model2 loss : 0.020518
[00:29:25.383] iteration 18008 : model1 loss : 0.033818 model2 loss : 0.028720
[00:29:26.075] iteration 18009 : model1 loss : 0.024519 model2 loss : 0.024233
[00:29:26.771] iteration 18010 : model1 loss : 0.017374 model2 loss : 0.017159
[00:29:27.507] iteration 18011 : model1 loss : 0.015556 model2 loss : 0.015750
[00:29:28.207] iteration 18012 : model1 loss : 0.023827 model2 loss : 0.023799
[00:29:28.927] iteration 18013 : model1 loss : 0.027285 model2 loss : 0.026216
[00:29:29.613] iteration 18014 : model1 loss : 0.021220 model2 loss : 0.023899
[00:29:30.307] iteration 18015 : model1 loss : 0.022572 model2 loss : 0.024277
[00:29:31.008] iteration 18016 : model1 loss : 0.025765 model2 loss : 0.024956
[00:29:31.708] iteration 18017 : model1 loss : 0.025357 model2 loss : 0.028930
[00:29:32.451] iteration 18018 : model1 loss : 0.020399 model2 loss : 0.020514
[00:29:33.155] iteration 18019 : model1 loss : 0.024940 model2 loss : 0.025594
[00:29:33.862] iteration 18020 : model1 loss : 0.021414 model2 loss : 0.021468
[00:29:34.562] iteration 18021 : model1 loss : 0.019282 model2 loss : 0.018037
[00:29:35.258] iteration 18022 : model1 loss : 0.019367 model2 loss : 0.021046
[00:29:35.958] iteration 18023 : model1 loss : 0.028645 model2 loss : 0.027850
[00:29:36.673] iteration 18024 : model1 loss : 0.016509 model2 loss : 0.016491
[00:29:37.409] iteration 18025 : model1 loss : 0.017695 model2 loss : 0.018734
[00:29:38.109] iteration 18026 : model1 loss : 0.017848 model2 loss : 0.018569
[00:29:38.814] iteration 18027 : model1 loss : 0.023380 model2 loss : 0.021282
[00:29:39.512] iteration 18028 : model1 loss : 0.022605 model2 loss : 0.023388
[00:29:40.222] iteration 18029 : model1 loss : 0.022230 model2 loss : 0.020798
[00:29:40.943] iteration 18030 : model1 loss : 0.023146 model2 loss : 0.018392
[00:29:41.644] iteration 18031 : model1 loss : 0.031227 model2 loss : 0.024423
[00:29:42.384] iteration 18032 : model1 loss : 0.015467 model2 loss : 0.016301
[00:29:43.079] iteration 18033 : model1 loss : 0.027057 model2 loss : 0.024511
[00:29:43.779] iteration 18034 : model1 loss : 0.020038 model2 loss : 0.018286
[00:29:44.479] iteration 18035 : model1 loss : 0.020528 model2 loss : 0.020118
[00:29:45.169] iteration 18036 : model1 loss : 0.031019 model2 loss : 0.029197
[00:29:45.867] iteration 18037 : model1 loss : 0.020902 model2 loss : 0.022001
[00:29:46.567] iteration 18038 : model1 loss : 0.027621 model2 loss : 0.031802
[00:29:47.315] iteration 18039 : model1 loss : 0.027019 model2 loss : 0.023101
[00:29:48.026] iteration 18040 : model1 loss : 0.023631 model2 loss : 0.024963
[00:29:48.727] iteration 18041 : model1 loss : 0.022128 model2 loss : 0.023822
[00:29:49.446] iteration 18042 : model1 loss : 0.018829 model2 loss : 0.020542
[00:29:50.149] iteration 18043 : model1 loss : 0.017942 model2 loss : 0.017541
[00:29:50.848] iteration 18044 : model1 loss : 0.020741 model2 loss : 0.022003
[00:29:51.534] iteration 18045 : model1 loss : 0.019284 model2 loss : 0.018739
[00:29:52.287] iteration 18046 : model1 loss : 0.016441 model2 loss : 0.016014
[00:29:52.993] iteration 18047 : model1 loss : 0.024594 model2 loss : 0.026792
[00:29:53.694] iteration 18048 : model1 loss : 0.019458 model2 loss : 0.018809
[00:29:54.409] iteration 18049 : model1 loss : 0.019238 model2 loss : 0.018699
[00:29:55.114] iteration 18050 : model1 loss : 0.016550 model2 loss : 0.020858
[00:29:55.864] iteration 18051 : model1 loss : 0.021868 model2 loss : 0.023717
[00:29:56.584] iteration 18052 : model1 loss : 0.022138 model2 loss : 0.027868
[00:29:57.312] iteration 18053 : model1 loss : 0.029701 model2 loss : 0.037366
[00:29:58.004] iteration 18054 : model1 loss : 0.020337 model2 loss : 0.020039
[00:29:58.722] iteration 18055 : model1 loss : 0.032977 model2 loss : 0.032427
[00:29:59.408] iteration 18056 : model1 loss : 0.033536 model2 loss : 0.029169
[00:30:00.105] iteration 18057 : model1 loss : 0.035095 model2 loss : 0.042580
[00:30:00.796] iteration 18058 : model1 loss : 0.018157 model2 loss : 0.020244
[00:30:01.505] iteration 18059 : model1 loss : 0.020171 model2 loss : 0.023060
[00:30:02.255] iteration 18060 : model1 loss : 0.027783 model2 loss : 0.028125
[00:30:02.964] iteration 18061 : model1 loss : 0.026335 model2 loss : 0.026028
[00:30:03.678] iteration 18062 : model1 loss : 0.015528 model2 loss : 0.018567
[00:30:04.378] iteration 18063 : model1 loss : 0.023556 model2 loss : 0.021581
[00:30:05.084] iteration 18064 : model1 loss : 0.024105 model2 loss : 0.025727
[00:30:05.777] iteration 18065 : model1 loss : 0.019812 model2 loss : 0.021297
[00:30:06.492] iteration 18066 : model1 loss : 0.020967 model2 loss : 0.021522
[00:30:07.232] iteration 18067 : model1 loss : 0.019788 model2 loss : 0.020904
[00:30:07.956] iteration 18068 : model1 loss : 0.019488 model2 loss : 0.019772
[00:30:08.680] iteration 18069 : model1 loss : 0.025004 model2 loss : 0.023296
[00:30:09.394] iteration 18070 : model1 loss : 0.024546 model2 loss : 0.025965
[00:30:10.116] iteration 18071 : model1 loss : 0.022073 model2 loss : 0.020740
[00:30:10.828] iteration 18072 : model1 loss : 0.019306 model2 loss : 0.019605
[00:30:11.521] iteration 18073 : model1 loss : 0.023499 model2 loss : 0.025307
[00:30:12.267] iteration 18074 : model1 loss : 0.018803 model2 loss : 0.016283
[00:30:12.976] iteration 18075 : model1 loss : 0.034906 model2 loss : 0.039181
[00:30:13.671] iteration 18076 : model1 loss : 0.016419 model2 loss : 0.015710
[00:30:14.372] iteration 18077 : model1 loss : 0.017888 model2 loss : 0.016276
[00:30:15.091] iteration 18078 : model1 loss : 0.021448 model2 loss : 0.022775
[00:30:15.786] iteration 18079 : model1 loss : 0.019021 model2 loss : 0.018829
[00:30:16.487] iteration 18080 : model1 loss : 0.024061 model2 loss : 0.024565
[00:30:17.228] iteration 18081 : model1 loss : 0.143062 model2 loss : 0.143760
[00:30:17.935] iteration 18082 : model1 loss : 0.029112 model2 loss : 0.029281
[00:30:18.637] iteration 18083 : model1 loss : 0.020601 model2 loss : 0.019789
[00:30:19.325] iteration 18084 : model1 loss : 0.017525 model2 loss : 0.018215
[00:30:20.032] iteration 18085 : model1 loss : 0.016079 model2 loss : 0.018314
[00:30:20.728] iteration 18086 : model1 loss : 0.028220 model2 loss : 0.030354
[00:30:21.429] iteration 18087 : model1 loss : 0.024193 model2 loss : 0.024885
[00:30:22.158] iteration 18088 : model1 loss : 0.023032 model2 loss : 0.023519
[00:30:22.881] iteration 18089 : model1 loss : 0.019594 model2 loss : 0.023922
[00:30:23.582] iteration 18090 : model1 loss : 0.018095 model2 loss : 0.017365
[00:30:24.293] iteration 18091 : model1 loss : 0.028644 model2 loss : 0.028574
[00:30:24.988] iteration 18092 : model1 loss : 0.020760 model2 loss : 0.021067
[00:30:25.708] iteration 18093 : model1 loss : 0.023861 model2 loss : 0.023316
[00:30:26.407] iteration 18094 : model1 loss : 0.019413 model2 loss : 0.020053
[00:30:27.139] iteration 18095 : model1 loss : 0.014043 model2 loss : 0.017201
[00:30:27.860] iteration 18096 : model1 loss : 0.014967 model2 loss : 0.014483
[00:30:28.583] iteration 18097 : model1 loss : 0.016333 model2 loss : 0.016364
[00:30:29.294] iteration 18098 : model1 loss : 0.020894 model2 loss : 0.020978
[00:30:29.997] iteration 18099 : model1 loss : 0.020401 model2 loss : 0.019968
[00:30:30.697] iteration 18100 : model1 loss : 0.021647 model2 loss : 0.021243
[00:30:31.447] iteration 18101 : model1 loss : 0.029881 model2 loss : 0.027058
[00:30:32.192] iteration 18102 : model1 loss : 0.045568 model2 loss : 0.025646
[00:30:32.905] iteration 18103 : model1 loss : 0.022706 model2 loss : 0.023885
[00:30:33.607] iteration 18104 : model1 loss : 0.023402 model2 loss : 0.021692
[00:30:34.316] iteration 18105 : model1 loss : 0.018979 model2 loss : 0.019342
[00:30:35.020] iteration 18106 : model1 loss : 0.016877 model2 loss : 0.016947
[00:30:35.723] iteration 18107 : model1 loss : 0.041717 model2 loss : 0.037266
[00:30:36.476] iteration 18108 : model1 loss : 0.022084 model2 loss : 0.022063
[00:30:37.213] iteration 18109 : model1 loss : 0.028676 model2 loss : 0.024241
[00:30:37.927] iteration 18110 : model1 loss : 0.019454 model2 loss : 0.016310
[00:30:38.641] iteration 18111 : model1 loss : 0.032344 model2 loss : 0.017013
[00:30:39.334] iteration 18112 : model1 loss : 0.019502 model2 loss : 0.018722
[00:30:40.045] iteration 18113 : model1 loss : 0.025139 model2 loss : 0.022947
[00:30:40.741] iteration 18114 : model1 loss : 0.019265 model2 loss : 0.020660
[00:30:41.443] iteration 18115 : model1 loss : 0.023702 model2 loss : 0.020113
[00:30:42.189] iteration 18116 : model1 loss : 0.029376 model2 loss : 0.028961
[00:30:42.897] iteration 18117 : model1 loss : 0.021047 model2 loss : 0.023215
[00:30:43.600] iteration 18118 : model1 loss : 0.019519 model2 loss : 0.020324
[00:30:44.308] iteration 18119 : model1 loss : 0.022934 model2 loss : 0.023589
[00:30:44.999] iteration 18120 : model1 loss : 0.034144 model2 loss : 0.029079
[00:30:45.707] iteration 18121 : model1 loss : 0.020785 model2 loss : 0.021307
[00:30:46.440] iteration 18122 : model1 loss : 0.015234 model2 loss : 0.015468
[00:30:47.208] iteration 18123 : model1 loss : 0.036164 model2 loss : 0.031772
[00:30:47.943] iteration 18124 : model1 loss : 0.022271 model2 loss : 0.020117
[00:30:48.660] iteration 18125 : model1 loss : 0.029368 model2 loss : 0.025904
[00:30:49.357] iteration 18126 : model1 loss : 0.023343 model2 loss : 0.020261
[00:30:50.047] iteration 18127 : model1 loss : 0.021514 model2 loss : 0.020564
[00:30:50.746] iteration 18128 : model1 loss : 0.019479 model2 loss : 0.019966
[00:30:51.443] iteration 18129 : model1 loss : 0.026610 model2 loss : 0.021034
[00:30:52.191] iteration 18130 : model1 loss : 0.022602 model2 loss : 0.021133
[00:30:52.904] iteration 18131 : model1 loss : 0.017765 model2 loss : 0.020527
[00:30:53.608] iteration 18132 : model1 loss : 0.020365 model2 loss : 0.021564
[00:30:54.311] iteration 18133 : model1 loss : 0.023238 model2 loss : 0.024010
[00:30:55.010] iteration 18134 : model1 loss : 0.017738 model2 loss : 0.017998
[00:30:55.713] iteration 18135 : model1 loss : 0.017983 model2 loss : 0.018546
[00:30:56.428] iteration 18136 : model1 loss : 0.018458 model2 loss : 0.017877
[00:30:57.177] iteration 18137 : model1 loss : 0.025965 model2 loss : 0.026060
[00:30:57.884] iteration 18138 : model1 loss : 0.018207 model2 loss : 0.019528
[00:30:58.596] iteration 18139 : model1 loss : 0.024344 model2 loss : 0.025768
[00:30:59.293] iteration 18140 : model1 loss : 0.019248 model2 loss : 0.020353
[00:30:59.994] iteration 18141 : model1 loss : 0.020412 model2 loss : 0.026954
[00:31:00.710] iteration 18142 : model1 loss : 0.028142 model2 loss : 0.026255
[00:31:01.402] iteration 18143 : model1 loss : 0.020145 model2 loss : 0.017712
[00:31:02.142] iteration 18144 : model1 loss : 0.019747 model2 loss : 0.018676
[00:31:02.868] iteration 18145 : model1 loss : 0.018194 model2 loss : 0.017101
[00:31:03.589] iteration 18146 : model1 loss : 0.023486 model2 loss : 0.022520
[00:31:04.310] iteration 18147 : model1 loss : 0.018430 model2 loss : 0.017525
[00:31:05.027] iteration 18148 : model1 loss : 0.026203 model2 loss : 0.023614
[00:31:05.723] iteration 18149 : model1 loss : 0.019578 model2 loss : 0.020154
[00:31:06.426] iteration 18150 : model1 loss : 0.021878 model2 loss : 0.022526
[00:31:07.201] iteration 18151 : model1 loss : 0.018625 model2 loss : 0.019824
[00:31:07.930] iteration 18152 : model1 loss : 0.017512 model2 loss : 0.018317
[00:31:08.636] iteration 18153 : model1 loss : 0.024131 model2 loss : 0.020583
[00:31:09.330] iteration 18154 : model1 loss : 0.023653 model2 loss : 0.020807
[00:31:10.035] iteration 18155 : model1 loss : 0.022301 model2 loss : 0.020211
[00:31:10.734] iteration 18156 : model1 loss : 0.019589 model2 loss : 0.020054
[00:31:11.432] iteration 18157 : model1 loss : 0.019393 model2 loss : 0.019963
[00:31:12.162] iteration 18158 : model1 loss : 0.024952 model2 loss : 0.022283
[00:31:12.872] iteration 18159 : model1 loss : 0.017183 model2 loss : 0.018170
[00:31:13.573] iteration 18160 : model1 loss : 0.018805 model2 loss : 0.017986
[00:31:14.298] iteration 18161 : model1 loss : 0.019531 model2 loss : 0.020267
[00:31:14.996] iteration 18162 : model1 loss : 0.139517 model2 loss : 0.141974
[00:31:15.712] iteration 18163 : model1 loss : 0.024088 model2 loss : 0.028360
[00:31:16.421] iteration 18164 : model1 loss : 0.019688 model2 loss : 0.018363
[00:31:17.149] iteration 18165 : model1 loss : 0.017094 model2 loss : 0.017071
[00:31:17.871] iteration 18166 : model1 loss : 0.023071 model2 loss : 0.019775
[00:31:18.605] iteration 18167 : model1 loss : 0.031902 model2 loss : 0.028995
[00:31:19.307] iteration 18168 : model1 loss : 0.035591 model2 loss : 0.064236
[00:31:20.006] iteration 18169 : model1 loss : 0.027709 model2 loss : 0.029864
[00:31:20.725] iteration 18170 : model1 loss : 0.024224 model2 loss : 0.023373
[00:31:21.433] iteration 18171 : model1 loss : 0.018181 model2 loss : 0.017871
[00:31:22.167] iteration 18172 : model1 loss : 0.025369 model2 loss : 0.029805
[00:31:22.881] iteration 18173 : model1 loss : 0.023855 model2 loss : 0.023597
[00:31:23.585] iteration 18174 : model1 loss : 0.018496 model2 loss : 0.017960
[00:31:24.297] iteration 18175 : model1 loss : 0.019319 model2 loss : 0.020488
[00:31:24.996] iteration 18176 : model1 loss : 0.021076 model2 loss : 0.022218
[00:31:25.698] iteration 18177 : model1 loss : 0.016709 model2 loss : 0.017757
[00:31:26.392] iteration 18178 : model1 loss : 0.019766 model2 loss : 0.020828
[00:31:27.127] iteration 18179 : model1 loss : 0.030797 model2 loss : 0.037087
[00:31:27.838] iteration 18180 : model1 loss : 0.149096 model2 loss : 0.146603
[00:31:28.552] iteration 18181 : model1 loss : 0.022592 model2 loss : 0.021018
[00:31:29.252] iteration 18182 : model1 loss : 0.020024 model2 loss : 0.025527
[00:31:29.961] iteration 18183 : model1 loss : 0.019597 model2 loss : 0.020815
[00:31:30.671] iteration 18184 : model1 loss : 0.020176 model2 loss : 0.019885
[00:31:31.379] iteration 18185 : model1 loss : 0.022259 model2 loss : 0.021544
[00:31:32.110] iteration 18186 : model1 loss : 0.017039 model2 loss : 0.040554
[00:31:32.835] iteration 18187 : model1 loss : 0.019343 model2 loss : 0.019441
[00:31:33.545] iteration 18188 : model1 loss : 0.030877 model2 loss : 0.032150
[00:31:34.257] iteration 18189 : model1 loss : 0.027214 model2 loss : 0.026024
[00:31:34.954] iteration 18190 : model1 loss : 0.023667 model2 loss : 0.028224
[00:31:35.651] iteration 18191 : model1 loss : 0.022898 model2 loss : 0.021392
[00:31:36.359] iteration 18192 : model1 loss : 0.026815 model2 loss : 0.026419
[00:31:37.085] iteration 18193 : model1 loss : 0.020798 model2 loss : 0.021156
[00:31:37.793] iteration 18194 : model1 loss : 0.017189 model2 loss : 0.018103
[00:31:38.496] iteration 18195 : model1 loss : 0.020662 model2 loss : 0.018740
[00:31:39.197] iteration 18196 : model1 loss : 0.017387 model2 loss : 0.020824
[00:31:39.905] iteration 18197 : model1 loss : 0.017063 model2 loss : 0.018580
[00:31:40.606] iteration 18198 : model1 loss : 0.021089 model2 loss : 0.022379
[00:31:41.316] iteration 18199 : model1 loss : 0.018367 model2 loss : 0.017842
[00:31:42.055] iteration 18200 : model1 loss : 0.015657 model2 loss : 0.017259
[00:32:01.578] iteration 18200 : model1_mean_dice : 0.869334 model1_mean_hd95 : 8.015562
[00:32:21.099] iteration 18200 : model2_mean_dice : 0.872195 model2_mean_hd95 : 5.349952
[00:32:21.849] iteration 18201 : model1 loss : 0.017270 model2 loss : 0.017309
[00:32:22.585] iteration 18202 : model1 loss : 0.019256 model2 loss : 0.020075
[00:32:23.292] iteration 18203 : model1 loss : 0.017117 model2 loss : 0.017091
[00:32:23.978] iteration 18204 : model1 loss : 0.016166 model2 loss : 0.018978
[00:32:24.673] iteration 18205 : model1 loss : 0.017372 model2 loss : 0.019128
[00:32:25.393] iteration 18206 : model1 loss : 0.023049 model2 loss : 0.027032
[00:32:26.084] iteration 18207 : model1 loss : 0.032519 model2 loss : 0.034850
[00:32:26.781] iteration 18208 : model1 loss : 0.022075 model2 loss : 0.023672
[00:32:27.528] iteration 18209 : model1 loss : 0.020318 model2 loss : 0.023533
[00:32:28.230] iteration 18210 : model1 loss : 0.021586 model2 loss : 0.020662
[00:32:28.929] iteration 18211 : model1 loss : 0.033372 model2 loss : 0.033291
[00:32:29.623] iteration 18212 : model1 loss : 0.020437 model2 loss : 0.019273
[00:32:30.339] iteration 18213 : model1 loss : 0.028043 model2 loss : 0.036635
[00:32:31.040] iteration 18214 : model1 loss : 0.062559 model2 loss : 0.054300
[00:32:31.735] iteration 18215 : model1 loss : 0.041215 model2 loss : 0.034905
[00:32:32.490] iteration 18216 : model1 loss : 0.020058 model2 loss : 0.022720
[00:32:33.186] iteration 18217 : model1 loss : 0.051529 model2 loss : 0.051427
[00:32:33.879] iteration 18218 : model1 loss : 0.018131 model2 loss : 0.016683
[00:32:34.570] iteration 18219 : model1 loss : 0.032522 model2 loss : 0.035108
[00:32:35.262] iteration 18220 : model1 loss : 0.027975 model2 loss : 0.025274
[00:32:35.959] iteration 18221 : model1 loss : 0.017332 model2 loss : 0.019742
[00:32:36.664] iteration 18222 : model1 loss : 0.021675 model2 loss : 0.025403
[00:32:37.427] iteration 18223 : model1 loss : 0.027282 model2 loss : 0.025784
[00:32:38.132] iteration 18224 : model1 loss : 0.027200 model2 loss : 0.026316
[00:32:38.842] iteration 18225 : model1 loss : 0.020422 model2 loss : 0.019984
[00:32:39.565] iteration 18226 : model1 loss : 0.031868 model2 loss : 0.032166
[00:32:40.267] iteration 18227 : model1 loss : 0.020049 model2 loss : 0.026243
[00:32:40.965] iteration 18228 : model1 loss : 0.035479 model2 loss : 0.030782
[00:32:41.665] iteration 18229 : model1 loss : 0.021482 model2 loss : 0.023135
[00:32:42.400] iteration 18230 : model1 loss : 0.017362 model2 loss : 0.017969
[00:32:43.105] iteration 18231 : model1 loss : 0.019396 model2 loss : 0.017787
[00:32:43.798] iteration 18232 : model1 loss : 0.024657 model2 loss : 0.022118
[00:32:44.498] iteration 18233 : model1 loss : 0.023811 model2 loss : 0.020781
[00:32:45.191] iteration 18234 : model1 loss : 0.020327 model2 loss : 0.018718
[00:32:45.881] iteration 18235 : model1 loss : 0.024024 model2 loss : 0.032064
[00:32:46.584] iteration 18236 : model1 loss : 0.018703 model2 loss : 0.019316
[00:32:47.323] iteration 18237 : model1 loss : 0.023561 model2 loss : 0.021470
[00:32:48.024] iteration 18238 : model1 loss : 0.022438 model2 loss : 0.020390
[00:32:48.728] iteration 18239 : model1 loss : 0.018354 model2 loss : 0.019553
[00:32:49.425] iteration 18240 : model1 loss : 0.019221 model2 loss : 0.021539
[00:32:50.136] iteration 18241 : model1 loss : 0.016194 model2 loss : 0.016282
[00:32:50.838] iteration 18242 : model1 loss : 0.022502 model2 loss : 0.022881
[00:32:51.547] iteration 18243 : model1 loss : 0.026726 model2 loss : 0.023701
[00:32:52.281] iteration 18244 : model1 loss : 0.018703 model2 loss : 0.018338
[00:32:52.978] iteration 18245 : model1 loss : 0.023762 model2 loss : 0.024100
[00:32:53.679] iteration 18246 : model1 loss : 0.020148 model2 loss : 0.020668
[00:32:54.390] iteration 18247 : model1 loss : 0.025459 model2 loss : 0.025444
[00:32:55.088] iteration 18248 : model1 loss : 0.022069 model2 loss : 0.018751
[00:32:55.790] iteration 18249 : model1 loss : 0.016638 model2 loss : 0.019504
[00:32:56.495] iteration 18250 : model1 loss : 0.019464 model2 loss : 0.019639
[00:32:57.285] iteration 18251 : model1 loss : 0.024117 model2 loss : 0.026743
[00:32:57.988] iteration 18252 : model1 loss : 0.021300 model2 loss : 0.021276
[00:32:58.692] iteration 18253 : model1 loss : 0.017897 model2 loss : 0.017082
[00:32:59.391] iteration 18254 : model1 loss : 0.072090 model2 loss : 0.075417
[00:33:00.082] iteration 18255 : model1 loss : 0.028925 model2 loss : 0.025949
[00:33:00.781] iteration 18256 : model1 loss : 0.023231 model2 loss : 0.025797
[00:33:01.484] iteration 18257 : model1 loss : 0.027724 model2 loss : 0.034305
[00:33:02.211] iteration 18258 : model1 loss : 0.016071 model2 loss : 0.016972
[00:33:02.911] iteration 18259 : model1 loss : 0.019618 model2 loss : 0.020132
[00:33:03.623] iteration 18260 : model1 loss : 0.094696 model2 loss : 0.075681
[00:33:04.341] iteration 18261 : model1 loss : 0.018649 model2 loss : 0.017517
[00:33:05.050] iteration 18262 : model1 loss : 0.018371 model2 loss : 0.017253
[00:33:05.765] iteration 18263 : model1 loss : 0.025816 model2 loss : 0.028970
[00:33:06.472] iteration 18264 : model1 loss : 0.020495 model2 loss : 0.020491
[00:33:07.217] iteration 18265 : model1 loss : 0.022177 model2 loss : 0.021765
[00:33:07.924] iteration 18266 : model1 loss : 0.022095 model2 loss : 0.021612
[00:33:08.632] iteration 18267 : model1 loss : 0.024294 model2 loss : 0.028623
[00:33:09.338] iteration 18268 : model1 loss : 0.028229 model2 loss : 0.024730
[00:33:10.039] iteration 18269 : model1 loss : 0.024114 model2 loss : 0.021072
[00:33:10.740] iteration 18270 : model1 loss : 0.020283 model2 loss : 0.022002
[00:33:11.439] iteration 18271 : model1 loss : 0.021219 model2 loss : 0.019929
[00:33:12.173] iteration 18272 : model1 loss : 0.024421 model2 loss : 0.023569
[00:33:12.904] iteration 18273 : model1 loss : 0.022430 model2 loss : 0.023085
[00:33:13.604] iteration 18274 : model1 loss : 0.045502 model2 loss : 0.043396
[00:33:14.322] iteration 18275 : model1 loss : 0.024976 model2 loss : 0.031583
[00:33:15.030] iteration 18276 : model1 loss : 0.018417 model2 loss : 0.016962
[00:33:15.728] iteration 18277 : model1 loss : 0.024383 model2 loss : 0.034947
[00:33:16.428] iteration 18278 : model1 loss : 0.020432 model2 loss : 0.022187
[00:33:17.164] iteration 18279 : model1 loss : 0.014816 model2 loss : 0.017218
[00:33:17.873] iteration 18280 : model1 loss : 0.023607 model2 loss : 0.027752
[00:33:18.580] iteration 18281 : model1 loss : 0.018814 model2 loss : 0.021608
[00:33:19.296] iteration 18282 : model1 loss : 0.028309 model2 loss : 0.027167
[00:33:19.997] iteration 18283 : model1 loss : 0.022912 model2 loss : 0.021392
[00:33:20.701] iteration 18284 : model1 loss : 0.020032 model2 loss : 0.019934
[00:33:21.413] iteration 18285 : model1 loss : 0.023087 model2 loss : 0.025653
[00:33:22.149] iteration 18286 : model1 loss : 0.026737 model2 loss : 0.028258
[00:33:22.874] iteration 18287 : model1 loss : 0.019739 model2 loss : 0.020598
[00:33:23.581] iteration 18288 : model1 loss : 0.026000 model2 loss : 0.023618
[00:33:24.304] iteration 18289 : model1 loss : 0.027543 model2 loss : 0.027555
[00:33:25.008] iteration 18290 : model1 loss : 0.022526 model2 loss : 0.022653
[00:33:25.715] iteration 18291 : model1 loss : 0.020253 model2 loss : 0.020902
[00:33:26.420] iteration 18292 : model1 loss : 0.017584 model2 loss : 0.018767
[00:33:27.142] iteration 18293 : model1 loss : 0.014868 model2 loss : 0.015177
[00:33:27.853] iteration 18294 : model1 loss : 0.019195 model2 loss : 0.017357
[00:33:28.577] iteration 18295 : model1 loss : 0.031463 model2 loss : 0.033757
[00:33:29.277] iteration 18296 : model1 loss : 0.031079 model2 loss : 0.025962
[00:33:29.974] iteration 18297 : model1 loss : 0.021215 model2 loss : 0.021133
[00:33:30.697] iteration 18298 : model1 loss : 0.022528 model2 loss : 0.021114
[00:33:31.412] iteration 18299 : model1 loss : 0.022652 model2 loss : 0.022122
[00:33:32.134] iteration 18300 : model1 loss : 0.020628 model2 loss : 0.023280
[00:33:32.892] iteration 18301 : model1 loss : 0.016042 model2 loss : 0.016396
[00:33:33.590] iteration 18302 : model1 loss : 0.027868 model2 loss : 0.029502
[00:33:34.305] iteration 18303 : model1 loss : 0.022571 model2 loss : 0.021999
[00:33:35.032] iteration 18304 : model1 loss : 0.019009 model2 loss : 0.020663
[00:33:35.750] iteration 18305 : model1 loss : 0.024314 model2 loss : 0.023289
[00:33:36.454] iteration 18306 : model1 loss : 0.019159 model2 loss : 0.020127
[00:33:37.185] iteration 18307 : model1 loss : 0.018148 model2 loss : 0.019780
[00:33:37.894] iteration 18308 : model1 loss : 0.031119 model2 loss : 0.031053
[00:33:38.605] iteration 18309 : model1 loss : 0.018700 model2 loss : 0.018039
[00:33:39.314] iteration 18310 : model1 loss : 0.032838 model2 loss : 0.026477
[00:33:40.021] iteration 18311 : model1 loss : 0.023114 model2 loss : 0.025640
[00:33:40.738] iteration 18312 : model1 loss : 0.020364 model2 loss : 0.018740
[00:33:41.437] iteration 18313 : model1 loss : 0.027048 model2 loss : 0.025005
[00:33:42.174] iteration 18314 : model1 loss : 0.022180 model2 loss : 0.024671
[00:33:42.882] iteration 18315 : model1 loss : 0.023012 model2 loss : 0.027891
[00:33:43.581] iteration 18316 : model1 loss : 0.025460 model2 loss : 0.023720
[00:33:44.291] iteration 18317 : model1 loss : 0.017879 model2 loss : 0.019094
[00:33:44.995] iteration 18318 : model1 loss : 0.019068 model2 loss : 0.019600
[00:33:45.698] iteration 18319 : model1 loss : 0.031412 model2 loss : 0.027601
[00:33:46.395] iteration 18320 : model1 loss : 0.023529 model2 loss : 0.025201
[00:33:47.124] iteration 18321 : model1 loss : 0.019978 model2 loss : 0.020330
[00:33:47.874] iteration 18322 : model1 loss : 0.025987 model2 loss : 0.023337
[00:33:48.617] iteration 18323 : model1 loss : 0.020801 model2 loss : 0.018292
[00:33:49.321] iteration 18324 : model1 loss : 0.031895 model2 loss : 0.030848
[00:33:50.021] iteration 18325 : model1 loss : 0.025577 model2 loss : 0.026300
[00:33:50.728] iteration 18326 : model1 loss : 0.024276 model2 loss : 0.023518
[00:33:51.428] iteration 18327 : model1 loss : 0.018982 model2 loss : 0.018981
[00:33:52.156] iteration 18328 : model1 loss : 0.020610 model2 loss : 0.016494
[00:33:52.880] iteration 18329 : model1 loss : 0.024072 model2 loss : 0.025285
[00:33:53.577] iteration 18330 : model1 loss : 0.024594 model2 loss : 0.025348
[00:33:54.285] iteration 18331 : model1 loss : 0.017854 model2 loss : 0.018235
[00:33:54.997] iteration 18332 : model1 loss : 0.021561 model2 loss : 0.020688
[00:33:55.711] iteration 18333 : model1 loss : 0.026115 model2 loss : 0.023773
[00:33:56.416] iteration 18334 : model1 loss : 0.019333 model2 loss : 0.019762
[00:33:57.144] iteration 18335 : model1 loss : 0.019273 model2 loss : 0.020590
[00:33:57.847] iteration 18336 : model1 loss : 0.022825 model2 loss : 0.022058
[00:33:58.570] iteration 18337 : model1 loss : 0.020774 model2 loss : 0.021161
[00:33:59.267] iteration 18338 : model1 loss : 0.018006 model2 loss : 0.018378
[00:33:59.961] iteration 18339 : model1 loss : 0.021247 model2 loss : 0.022323
[00:34:00.670] iteration 18340 : model1 loss : 0.015736 model2 loss : 0.017975
[00:34:01.380] iteration 18341 : model1 loss : 0.022857 model2 loss : 0.024325
[00:34:02.126] iteration 18342 : model1 loss : 0.021359 model2 loss : 0.021713
[00:34:02.836] iteration 18343 : model1 loss : 0.018579 model2 loss : 0.018749
[00:34:03.537] iteration 18344 : model1 loss : 0.017602 model2 loss : 0.017596
[00:34:04.238] iteration 18345 : model1 loss : 0.034884 model2 loss : 0.037756
[00:34:04.949] iteration 18346 : model1 loss : 0.022093 model2 loss : 0.021278
[00:34:05.657] iteration 18347 : model1 loss : 0.040607 model2 loss : 0.037930
[00:34:06.364] iteration 18348 : model1 loss : 0.024555 model2 loss : 0.022663
[00:34:07.083] iteration 18349 : model1 loss : 0.019803 model2 loss : 0.021437
[00:34:07.787] iteration 18350 : model1 loss : 0.017915 model2 loss : 0.018604
[00:34:08.538] iteration 18351 : model1 loss : 0.024950 model2 loss : 0.023995
[00:34:09.249] iteration 18352 : model1 loss : 0.021694 model2 loss : 0.021598
[00:34:09.950] iteration 18353 : model1 loss : 0.019531 model2 loss : 0.017661
[00:34:10.650] iteration 18354 : model1 loss : 0.021101 model2 loss : 0.021238
[00:34:11.342] iteration 18355 : model1 loss : 0.023220 model2 loss : 0.022948
[00:34:12.072] iteration 18356 : model1 loss : 0.027603 model2 loss : 0.023697
[00:34:12.805] iteration 18357 : model1 loss : 0.032666 model2 loss : 0.027083
[00:34:13.510] iteration 18358 : model1 loss : 0.021183 model2 loss : 0.020707
[00:34:14.210] iteration 18359 : model1 loss : 0.021236 model2 loss : 0.019525
[00:34:14.916] iteration 18360 : model1 loss : 0.020086 model2 loss : 0.019777
[00:34:15.607] iteration 18361 : model1 loss : 0.019139 model2 loss : 0.023403
[00:34:16.308] iteration 18362 : model1 loss : 0.018512 model2 loss : 0.020086
[00:34:17.036] iteration 18363 : model1 loss : 0.024662 model2 loss : 0.023539
[00:34:17.746] iteration 18364 : model1 loss : 0.021380 model2 loss : 0.020550
[00:34:18.448] iteration 18365 : model1 loss : 0.021279 model2 loss : 0.022675
[00:34:19.163] iteration 18366 : model1 loss : 0.019932 model2 loss : 0.019327
[00:34:19.864] iteration 18367 : model1 loss : 0.021306 model2 loss : 0.020896
[00:34:20.574] iteration 18368 : model1 loss : 0.022799 model2 loss : 0.020652
[00:34:21.271] iteration 18369 : model1 loss : 0.015615 model2 loss : 0.015334
[00:34:21.988] iteration 18370 : model1 loss : 0.028434 model2 loss : 0.027821
[00:34:22.726] iteration 18371 : model1 loss : 0.021165 model2 loss : 0.022008
[00:34:23.416] iteration 18372 : model1 loss : 0.161591 model2 loss : 0.185525
[00:34:24.120] iteration 18373 : model1 loss : 0.025669 model2 loss : 0.028288
[00:34:24.817] iteration 18374 : model1 loss : 0.024095 model2 loss : 0.024798
[00:34:25.512] iteration 18375 : model1 loss : 0.015962 model2 loss : 0.016169
[00:34:26.222] iteration 18376 : model1 loss : 0.030303 model2 loss : 0.029877
[00:34:26.942] iteration 18377 : model1 loss : 0.020545 model2 loss : 0.021931
[00:34:27.673] iteration 18378 : model1 loss : 0.016793 model2 loss : 0.018079
[00:34:28.400] iteration 18379 : model1 loss : 0.022884 model2 loss : 0.023720
[00:34:29.103] iteration 18380 : model1 loss : 0.019894 model2 loss : 0.018393
[00:34:29.805] iteration 18381 : model1 loss : 0.018403 model2 loss : 0.017265
[00:34:30.516] iteration 18382 : model1 loss : 0.025746 model2 loss : 0.023177
[00:34:31.214] iteration 18383 : model1 loss : 0.019325 model2 loss : 0.018513
[00:34:31.928] iteration 18384 : model1 loss : 0.018956 model2 loss : 0.019729
[00:34:32.690] iteration 18385 : model1 loss : 0.018388 model2 loss : 0.016447
[00:34:33.387] iteration 18386 : model1 loss : 0.018467 model2 loss : 0.019577
[00:34:34.083] iteration 18387 : model1 loss : 0.022044 model2 loss : 0.022929
[00:34:34.797] iteration 18388 : model1 loss : 0.015644 model2 loss : 0.017093
[00:34:35.507] iteration 18389 : model1 loss : 0.024599 model2 loss : 0.024443
[00:34:36.225] iteration 18390 : model1 loss : 0.018230 model2 loss : 0.018157
[00:34:36.952] iteration 18391 : model1 loss : 0.028600 model2 loss : 0.031997
[00:34:37.680] iteration 18392 : model1 loss : 0.020477 model2 loss : 0.022469
[00:34:38.406] iteration 18393 : model1 loss : 0.031719 model2 loss : 0.028992
[00:34:39.128] iteration 18394 : model1 loss : 0.018557 model2 loss : 0.020897
[00:34:39.823] iteration 18395 : model1 loss : 0.024550 model2 loss : 0.022395
[00:34:40.553] iteration 18396 : model1 loss : 0.018144 model2 loss : 0.017764
[00:34:41.251] iteration 18397 : model1 loss : 0.022640 model2 loss : 0.025229
[00:34:41.967] iteration 18398 : model1 loss : 0.027340 model2 loss : 0.020980
[00:34:42.705] iteration 18399 : model1 loss : 0.021578 model2 loss : 0.022548
[00:34:43.419] iteration 18400 : model1 loss : 0.020736 model2 loss : 0.021508
[00:35:02.929] iteration 18400 : model1_mean_dice : 0.870199 model1_mean_hd95 : 4.334440
[00:35:22.609] iteration 18400 : model2_mean_dice : 0.868979 model2_mean_hd95 : 4.581698
[00:35:23.334] iteration 18401 : model1 loss : 0.017444 model2 loss : 0.016979
[00:35:24.025] iteration 18402 : model1 loss : 0.023537 model2 loss : 0.022388
[00:35:24.729] iteration 18403 : model1 loss : 0.050779 model2 loss : 0.050813
[00:35:25.419] iteration 18404 : model1 loss : 0.023305 model2 loss : 0.024051
[00:35:26.121] iteration 18405 : model1 loss : 0.019599 model2 loss : 0.020980
[00:35:26.813] iteration 18406 : model1 loss : 0.021090 model2 loss : 0.021785
[00:35:27.556] iteration 18407 : model1 loss : 0.020402 model2 loss : 0.023321
[00:35:28.257] iteration 18408 : model1 loss : 0.021431 model2 loss : 0.020974
[00:35:28.951] iteration 18409 : model1 loss : 0.020288 model2 loss : 0.019779
[00:35:29.665] iteration 18410 : model1 loss : 0.027317 model2 loss : 0.025276
[00:35:30.376] iteration 18411 : model1 loss : 0.024445 model2 loss : 0.023531
[00:35:31.080] iteration 18412 : model1 loss : 0.018601 model2 loss : 0.018756
[00:35:31.787] iteration 18413 : model1 loss : 0.021490 model2 loss : 0.021980
[00:35:32.520] iteration 18414 : model1 loss : 0.021984 model2 loss : 0.023037
[00:35:33.209] iteration 18415 : model1 loss : 0.020347 model2 loss : 0.021790
[00:35:33.904] iteration 18416 : model1 loss : 0.155993 model2 loss : 0.157549
[00:35:34.603] iteration 18417 : model1 loss : 0.025252 model2 loss : 0.028230
[00:35:35.311] iteration 18418 : model1 loss : 0.021657 model2 loss : 0.021982
[00:35:36.007] iteration 18419 : model1 loss : 0.020364 model2 loss : 0.020148
[00:35:36.718] iteration 18420 : model1 loss : 0.018206 model2 loss : 0.017384
[00:35:37.452] iteration 18421 : model1 loss : 0.037478 model2 loss : 0.043844
[00:35:38.142] iteration 18422 : model1 loss : 0.021678 model2 loss : 0.026045
[00:35:38.882] iteration 18423 : model1 loss : 0.027695 model2 loss : 0.027955
[00:35:39.601] iteration 18424 : model1 loss : 0.021943 model2 loss : 0.023210
[00:35:40.298] iteration 18425 : model1 loss : 0.018158 model2 loss : 0.018636
[00:35:41.007] iteration 18426 : model1 loss : 0.019871 model2 loss : 0.017590
[00:35:41.714] iteration 18427 : model1 loss : 0.042100 model2 loss : 0.043995
[00:35:42.458] iteration 18428 : model1 loss : 0.016121 model2 loss : 0.018645
[00:35:43.153] iteration 18429 : model1 loss : 0.016716 model2 loss : 0.017708
[00:35:43.855] iteration 18430 : model1 loss : 0.019157 model2 loss : 0.018176
[00:35:44.555] iteration 18431 : model1 loss : 0.023420 model2 loss : 0.024580
[00:35:45.256] iteration 18432 : model1 loss : 0.020208 model2 loss : 0.020786
[00:35:45.969] iteration 18433 : model1 loss : 0.017997 model2 loss : 0.018644
[00:35:46.655] iteration 18434 : model1 loss : 0.024920 model2 loss : 0.027252
[00:35:47.413] iteration 18435 : model1 loss : 0.026795 model2 loss : 0.031356
[00:35:48.118] iteration 18436 : model1 loss : 0.014975 model2 loss : 0.016948
[00:35:48.820] iteration 18437 : model1 loss : 0.023301 model2 loss : 0.024170
[00:35:49.531] iteration 18438 : model1 loss : 0.028233 model2 loss : 0.024917
[00:35:50.229] iteration 18439 : model1 loss : 0.021140 model2 loss : 0.022336
[00:35:50.942] iteration 18440 : model1 loss : 0.019404 model2 loss : 0.020760
[00:35:51.648] iteration 18441 : model1 loss : 0.021587 model2 loss : 0.020438
[00:35:52.383] iteration 18442 : model1 loss : 0.018997 model2 loss : 0.018787
[00:35:53.098] iteration 18443 : model1 loss : 0.020666 model2 loss : 0.020261
[00:35:53.789] iteration 18444 : model1 loss : 0.034920 model2 loss : 0.039177
[00:35:54.481] iteration 18445 : model1 loss : 0.018471 model2 loss : 0.018352
[00:35:55.187] iteration 18446 : model1 loss : 0.020226 model2 loss : 0.019300
[00:35:55.877] iteration 18447 : model1 loss : 0.017466 model2 loss : 0.017066
[00:35:56.600] iteration 18448 : model1 loss : 0.019629 model2 loss : 0.019478
[00:35:57.356] iteration 18449 : model1 loss : 0.025420 model2 loss : 0.022719
[00:35:58.058] iteration 18450 : model1 loss : 0.024844 model2 loss : 0.024757
[00:35:58.788] iteration 18451 : model1 loss : 0.024125 model2 loss : 0.026662
[00:35:59.522] iteration 18452 : model1 loss : 0.019909 model2 loss : 0.021934
[00:36:00.220] iteration 18453 : model1 loss : 0.020233 model2 loss : 0.020149
[00:36:00.920] iteration 18454 : model1 loss : 0.020066 model2 loss : 0.021406
[00:36:01.615] iteration 18455 : model1 loss : 0.036177 model2 loss : 0.034720
[00:36:02.351] iteration 18456 : model1 loss : 0.017882 model2 loss : 0.018428
[00:36:03.055] iteration 18457 : model1 loss : 0.018898 model2 loss : 0.016857
[00:36:03.749] iteration 18458 : model1 loss : 0.019973 model2 loss : 0.019328
[00:36:04.454] iteration 18459 : model1 loss : 0.019162 model2 loss : 0.020778
[00:36:05.148] iteration 18460 : model1 loss : 0.036694 model2 loss : 0.038629
[00:36:05.849] iteration 18461 : model1 loss : 0.019475 model2 loss : 0.020487
[00:36:06.553] iteration 18462 : model1 loss : 0.019325 model2 loss : 0.020859
[00:36:07.303] iteration 18463 : model1 loss : 0.024789 model2 loss : 0.024460
[00:36:07.993] iteration 18464 : model1 loss : 0.021359 model2 loss : 0.020544
[00:36:08.831] iteration 18465 : model1 loss : 0.016236 model2 loss : 0.019326
[00:36:09.523] iteration 18466 : model1 loss : 0.016514 model2 loss : 0.016179
[00:36:10.211] iteration 18467 : model1 loss : 0.025839 model2 loss : 0.028416
[00:36:10.886] iteration 18468 : model1 loss : 0.019353 model2 loss : 0.018022
[00:36:11.564] iteration 18469 : model1 loss : 0.022428 model2 loss : 0.028975
[00:36:12.256] iteration 18470 : model1 loss : 0.017096 model2 loss : 0.018260
[00:36:12.941] iteration 18471 : model1 loss : 0.022560 model2 loss : 0.023555
[00:36:13.611] iteration 18472 : model1 loss : 0.016540 model2 loss : 0.017431
[00:36:14.291] iteration 18473 : model1 loss : 0.021697 model2 loss : 0.020579
[00:36:14.978] iteration 18474 : model1 loss : 0.021398 model2 loss : 0.024549
[00:36:15.658] iteration 18475 : model1 loss : 0.017420 model2 loss : 0.015297
[00:36:16.334] iteration 18476 : model1 loss : 0.028647 model2 loss : 0.039924
[00:36:17.000] iteration 18477 : model1 loss : 0.021236 model2 loss : 0.020752
[00:36:17.660] iteration 18478 : model1 loss : 0.022810 model2 loss : 0.026824
[00:36:18.307] iteration 18479 : model1 loss : 0.020132 model2 loss : 0.020952
[00:36:18.961] iteration 18480 : model1 loss : 0.021863 model2 loss : 0.022302
[00:36:19.628] iteration 18481 : model1 loss : 0.052285 model2 loss : 0.044718
[00:36:20.286] iteration 18482 : model1 loss : 0.019151 model2 loss : 0.021670
[00:36:20.954] iteration 18483 : model1 loss : 0.022297 model2 loss : 0.021161
[00:36:21.615] iteration 18484 : model1 loss : 0.017830 model2 loss : 0.020386
[00:36:22.273] iteration 18485 : model1 loss : 0.025488 model2 loss : 0.024600
[00:36:22.924] iteration 18486 : model1 loss : 0.019701 model2 loss : 0.019880
[00:36:23.688] iteration 18487 : model1 loss : 0.018658 model2 loss : 0.016449
[00:36:24.391] iteration 18488 : model1 loss : 0.025128 model2 loss : 0.023272
[00:36:25.095] iteration 18489 : model1 loss : 0.017612 model2 loss : 0.019360
[00:36:25.764] iteration 18490 : model1 loss : 0.017695 model2 loss : 0.018219
[00:36:26.428] iteration 18491 : model1 loss : 0.018482 model2 loss : 0.016791
[00:36:27.082] iteration 18492 : model1 loss : 0.019297 model2 loss : 0.019971
[00:36:27.725] iteration 18493 : model1 loss : 0.014974 model2 loss : 0.015446
[00:36:28.379] iteration 18494 : model1 loss : 0.017786 model2 loss : 0.017166
[00:36:29.037] iteration 18495 : model1 loss : 0.019903 model2 loss : 0.021535
[00:36:29.709] iteration 18496 : model1 loss : 0.022043 model2 loss : 0.020972
[00:36:30.368] iteration 18497 : model1 loss : 0.018103 model2 loss : 0.020431
[00:36:31.019] iteration 18498 : model1 loss : 0.019880 model2 loss : 0.018821
[00:36:31.675] iteration 18499 : model1 loss : 0.019277 model2 loss : 0.020968
[00:36:32.348] iteration 18500 : model1 loss : 0.016386 model2 loss : 0.016958
[00:36:33.040] iteration 18501 : model1 loss : 0.016606 model2 loss : 0.016261
[00:36:33.719] iteration 18502 : model1 loss : 0.020692 model2 loss : 0.019941
[00:36:34.383] iteration 18503 : model1 loss : 0.023529 model2 loss : 0.025674
[00:36:35.040] iteration 18504 : model1 loss : 0.051370 model2 loss : 0.044823
[00:36:35.703] iteration 18505 : model1 loss : 0.019990 model2 loss : 0.023291
[00:36:36.354] iteration 18506 : model1 loss : 0.018744 model2 loss : 0.017978
[00:36:37.013] iteration 18507 : model1 loss : 0.028859 model2 loss : 0.030011
[00:36:37.668] iteration 18508 : model1 loss : 0.022088 model2 loss : 0.031334
[00:36:38.328] iteration 18509 : model1 loss : 0.021738 model2 loss : 0.022814
[00:36:39.012] iteration 18510 : model1 loss : 0.019917 model2 loss : 0.022811
[00:36:39.679] iteration 18511 : model1 loss : 0.020472 model2 loss : 0.021386
[00:36:40.353] iteration 18512 : model1 loss : 0.018425 model2 loss : 0.018108
[00:36:41.004] iteration 18513 : model1 loss : 0.023298 model2 loss : 0.025500
[00:36:41.666] iteration 18514 : model1 loss : 0.022350 model2 loss : 0.021435
[00:36:42.327] iteration 18515 : model1 loss : 0.018875 model2 loss : 0.019279
[00:36:42.979] iteration 18516 : model1 loss : 0.018998 model2 loss : 0.020850
[00:36:43.632] iteration 18517 : model1 loss : 0.026393 model2 loss : 0.026772
[00:36:44.295] iteration 18518 : model1 loss : 0.018831 model2 loss : 0.016681
[00:36:44.947] iteration 18519 : model1 loss : 0.023553 model2 loss : 0.023049
[00:36:45.612] iteration 18520 : model1 loss : 0.019267 model2 loss : 0.018924
[00:36:46.273] iteration 18521 : model1 loss : 0.040091 model2 loss : 0.032411
[00:36:46.940] iteration 18522 : model1 loss : 0.021649 model2 loss : 0.024120
[00:36:47.597] iteration 18523 : model1 loss : 0.020189 model2 loss : 0.019336
[00:36:48.253] iteration 18524 : model1 loss : 0.019636 model2 loss : 0.022101
[00:36:48.913] iteration 18525 : model1 loss : 0.018763 model2 loss : 0.020722
[00:36:49.570] iteration 18526 : model1 loss : 0.021098 model2 loss : 0.024045
[00:36:50.235] iteration 18527 : model1 loss : 0.027632 model2 loss : 0.029238
[00:36:50.888] iteration 18528 : model1 loss : 0.029586 model2 loss : 0.030400
[00:36:51.561] iteration 18529 : model1 loss : 0.024306 model2 loss : 0.024032
[00:36:52.217] iteration 18530 : model1 loss : 0.055373 model2 loss : 0.059736
[00:36:52.855] iteration 18531 : model1 loss : 0.017788 model2 loss : 0.020652
[00:36:53.520] iteration 18532 : model1 loss : 0.026664 model2 loss : 0.025418
[00:36:54.173] iteration 18533 : model1 loss : 0.028358 model2 loss : 0.034553
[00:36:54.834] iteration 18534 : model1 loss : 0.021236 model2 loss : 0.023297
[00:36:55.494] iteration 18535 : model1 loss : 0.017310 model2 loss : 0.017290
[00:36:56.141] iteration 18536 : model1 loss : 0.015502 model2 loss : 0.017810
[00:36:56.806] iteration 18537 : model1 loss : 0.014395 model2 loss : 0.014107
[00:36:57.466] iteration 18538 : model1 loss : 0.021422 model2 loss : 0.021443
[00:36:58.125] iteration 18539 : model1 loss : 0.015820 model2 loss : 0.014588
[00:36:58.784] iteration 18540 : model1 loss : 0.026977 model2 loss : 0.027861
[00:36:59.444] iteration 18541 : model1 loss : 0.030477 model2 loss : 0.029974
[00:37:00.107] iteration 18542 : model1 loss : 0.021913 model2 loss : 0.022568
[00:37:00.756] iteration 18543 : model1 loss : 0.024550 model2 loss : 0.025954
[00:37:01.422] iteration 18544 : model1 loss : 0.017903 model2 loss : 0.019695
[00:37:02.075] iteration 18545 : model1 loss : 0.020914 model2 loss : 0.020554
[00:37:02.731] iteration 18546 : model1 loss : 0.018774 model2 loss : 0.018438
[00:37:03.392] iteration 18547 : model1 loss : 0.036170 model2 loss : 0.033849
[00:37:04.040] iteration 18548 : model1 loss : 0.025554 model2 loss : 0.026494
[00:37:04.694] iteration 18549 : model1 loss : 0.022473 model2 loss : 0.025562
[00:37:05.345] iteration 18550 : model1 loss : 0.020529 model2 loss : 0.020928
[00:37:06.041] iteration 18551 : model1 loss : 0.017111 model2 loss : 0.016519
[00:37:06.732] iteration 18552 : model1 loss : 0.020603 model2 loss : 0.019871
[00:37:07.396] iteration 18553 : model1 loss : 0.024758 model2 loss : 0.020296
[00:37:08.061] iteration 18554 : model1 loss : 0.021231 model2 loss : 0.023287
[00:37:08.725] iteration 18555 : model1 loss : 0.019545 model2 loss : 0.018433
[00:37:09.382] iteration 18556 : model1 loss : 0.023738 model2 loss : 0.024486
[00:37:10.053] iteration 18557 : model1 loss : 0.017582 model2 loss : 0.016927
[00:37:10.714] iteration 18558 : model1 loss : 0.017537 model2 loss : 0.016263
[00:37:11.376] iteration 18559 : model1 loss : 0.023304 model2 loss : 0.024170
[00:37:12.026] iteration 18560 : model1 loss : 0.057877 model2 loss : 0.026627
[00:37:12.682] iteration 18561 : model1 loss : 0.059755 model2 loss : 0.030566
[00:37:13.337] iteration 18562 : model1 loss : 0.024124 model2 loss : 0.024831
[00:37:13.983] iteration 18563 : model1 loss : 0.021968 model2 loss : 0.024113
[00:37:14.665] iteration 18564 : model1 loss : 0.024087 model2 loss : 0.021555
[00:37:15.326] iteration 18565 : model1 loss : 0.019294 model2 loss : 0.020532
[00:37:15.977] iteration 18566 : model1 loss : 0.022169 model2 loss : 0.023238
[00:37:16.626] iteration 18567 : model1 loss : 0.018534 model2 loss : 0.017614
[00:37:17.291] iteration 18568 : model1 loss : 0.022034 model2 loss : 0.022310
[00:37:17.943] iteration 18569 : model1 loss : 0.029304 model2 loss : 0.029078
[00:37:18.605] iteration 18570 : model1 loss : 0.016105 model2 loss : 0.016478
[00:37:19.260] iteration 18571 : model1 loss : 0.021809 model2 loss : 0.021348
[00:37:19.914] iteration 18572 : model1 loss : 0.024934 model2 loss : 0.022789
[00:37:20.567] iteration 18573 : model1 loss : 0.019606 model2 loss : 0.021138
[00:37:21.229] iteration 18574 : model1 loss : 0.143656 model2 loss : 0.145397
[00:37:21.893] iteration 18575 : model1 loss : 0.021190 model2 loss : 0.020181
[00:37:22.553] iteration 18576 : model1 loss : 0.019790 model2 loss : 0.022676
[00:37:23.211] iteration 18577 : model1 loss : 0.022536 model2 loss : 0.022551
[00:37:23.857] iteration 18578 : model1 loss : 0.016303 model2 loss : 0.016060
[00:37:24.518] iteration 18579 : model1 loss : 0.016283 model2 loss : 0.016130
[00:37:25.176] iteration 18580 : model1 loss : 0.020721 model2 loss : 0.020114
[00:37:25.842] iteration 18581 : model1 loss : 0.031519 model2 loss : 0.030400
[00:37:26.495] iteration 18582 : model1 loss : 0.024147 model2 loss : 0.024645
[00:37:27.155] iteration 18583 : model1 loss : 0.020011 model2 loss : 0.019170
[00:37:27.822] iteration 18584 : model1 loss : 0.048028 model2 loss : 0.026092
[00:37:28.485] iteration 18585 : model1 loss : 0.017796 model2 loss : 0.016479
[00:37:29.148] iteration 18586 : model1 loss : 0.019157 model2 loss : 0.019281
[00:37:29.802] iteration 18587 : model1 loss : 0.019654 model2 loss : 0.018229
[00:37:30.460] iteration 18588 : model1 loss : 0.043069 model2 loss : 0.043002
[00:37:31.107] iteration 18589 : model1 loss : 0.022310 model2 loss : 0.023601
[00:37:31.778] iteration 18590 : model1 loss : 0.021684 model2 loss : 0.021073
[00:37:32.439] iteration 18591 : model1 loss : 0.025138 model2 loss : 0.026016
[00:37:33.097] iteration 18592 : model1 loss : 0.024126 model2 loss : 0.024560
[00:37:33.759] iteration 18593 : model1 loss : 0.015593 model2 loss : 0.015421
[00:37:34.402] iteration 18594 : model1 loss : 0.025496 model2 loss : 0.025563
[00:37:35.058] iteration 18595 : model1 loss : 0.024324 model2 loss : 0.025106
[00:37:35.714] iteration 18596 : model1 loss : 0.020970 model2 loss : 0.021485
[00:37:36.383] iteration 18597 : model1 loss : 0.017728 model2 loss : 0.017058
[00:37:37.068] iteration 18598 : model1 loss : 0.033463 model2 loss : 0.026638
[00:37:37.729] iteration 18599 : model1 loss : 0.023529 model2 loss : 0.022287
[00:37:38.383] iteration 18600 : model1 loss : 0.016140 model2 loss : 0.014719
[00:37:56.168] iteration 18600 : model1_mean_dice : 0.864381 model1_mean_hd95 : 8.398848
[00:38:13.969] iteration 18600 : model2_mean_dice : 0.872038 model2_mean_hd95 : 4.965907
[00:38:14.643] iteration 18601 : model1 loss : 0.018622 model2 loss : 0.019184
[00:38:15.295] iteration 18602 : model1 loss : 0.029861 model2 loss : 0.029102
[00:38:15.947] iteration 18603 : model1 loss : 0.022214 model2 loss : 0.020956
[00:38:16.603] iteration 18604 : model1 loss : 0.028840 model2 loss : 0.029737
[00:38:17.254] iteration 18605 : model1 loss : 0.027886 model2 loss : 0.029336
[00:38:17.915] iteration 18606 : model1 loss : 0.036371 model2 loss : 0.040722
[00:38:18.562] iteration 18607 : model1 loss : 0.015558 model2 loss : 0.016332
[00:38:19.222] iteration 18608 : model1 loss : 0.018711 model2 loss : 0.018974
[00:38:19.871] iteration 18609 : model1 loss : 0.023027 model2 loss : 0.022985
[00:38:20.538] iteration 18610 : model1 loss : 0.019460 model2 loss : 0.018964
[00:38:21.201] iteration 18611 : model1 loss : 0.018996 model2 loss : 0.018019
[00:38:21.864] iteration 18612 : model1 loss : 0.020484 model2 loss : 0.021875
[00:38:22.510] iteration 18613 : model1 loss : 0.020018 model2 loss : 0.018968
[00:38:23.162] iteration 18614 : model1 loss : 0.029652 model2 loss : 0.031502
[00:38:23.820] iteration 18615 : model1 loss : 0.024711 model2 loss : 0.024035
[00:38:24.469] iteration 18616 : model1 loss : 0.024848 model2 loss : 0.025171
[00:38:25.124] iteration 18617 : model1 loss : 0.021468 model2 loss : 0.021301
[00:38:25.787] iteration 18618 : model1 loss : 0.015622 model2 loss : 0.016908
[00:38:26.444] iteration 18619 : model1 loss : 0.018206 model2 loss : 0.018600
[00:38:27.101] iteration 18620 : model1 loss : 0.020742 model2 loss : 0.019056
[00:38:27.747] iteration 18621 : model1 loss : 0.027436 model2 loss : 0.022354
[00:38:28.402] iteration 18622 : model1 loss : 0.024106 model2 loss : 0.025158
[00:38:29.046] iteration 18623 : model1 loss : 0.020766 model2 loss : 0.024750
[00:38:29.690] iteration 18624 : model1 loss : 0.020574 model2 loss : 0.021449
[00:38:30.363] iteration 18625 : model1 loss : 0.013879 model2 loss : 0.013788
[00:38:31.023] iteration 18626 : model1 loss : 0.023847 model2 loss : 0.025633
[00:38:31.696] iteration 18627 : model1 loss : 0.028982 model2 loss : 0.028086
[00:38:32.371] iteration 18628 : model1 loss : 0.017095 model2 loss : 0.017603
[00:38:33.017] iteration 18629 : model1 loss : 0.025324 model2 loss : 0.023686
[00:38:33.676] iteration 18630 : model1 loss : 0.020887 model2 loss : 0.018937
[00:38:34.334] iteration 18631 : model1 loss : 0.022036 model2 loss : 0.023761
[00:38:34.990] iteration 18632 : model1 loss : 0.024042 model2 loss : 0.022091
[00:38:35.648] iteration 18633 : model1 loss : 0.018564 model2 loss : 0.017576
[00:38:36.303] iteration 18634 : model1 loss : 0.019454 model2 loss : 0.021184
[00:38:36.958] iteration 18635 : model1 loss : 0.020564 model2 loss : 0.020348
[00:38:37.617] iteration 18636 : model1 loss : 0.027438 model2 loss : 0.030096
[00:38:38.273] iteration 18637 : model1 loss : 0.020227 model2 loss : 0.019669
[00:38:38.928] iteration 18638 : model1 loss : 0.017291 model2 loss : 0.017273
[00:38:39.574] iteration 18639 : model1 loss : 0.018762 model2 loss : 0.019285
[00:38:40.228] iteration 18640 : model1 loss : 0.020721 model2 loss : 0.018721
[00:38:40.877] iteration 18641 : model1 loss : 0.018261 model2 loss : 0.017627
[00:38:41.529] iteration 18642 : model1 loss : 0.022212 model2 loss : 0.025095
[00:38:42.179] iteration 18643 : model1 loss : 0.023384 model2 loss : 0.023387
[00:38:42.832] iteration 18644 : model1 loss : 0.023905 model2 loss : 0.024021
[00:38:43.501] iteration 18645 : model1 loss : 0.020049 model2 loss : 0.019582
[00:38:44.151] iteration 18646 : model1 loss : 0.022470 model2 loss : 0.021484
[00:38:44.802] iteration 18647 : model1 loss : 0.023205 model2 loss : 0.021654
[00:38:45.465] iteration 18648 : model1 loss : 0.023332 model2 loss : 0.022036
[00:38:46.108] iteration 18649 : model1 loss : 0.014007 model2 loss : 0.013591
[00:38:46.763] iteration 18650 : model1 loss : 0.016378 model2 loss : 0.016501
[00:38:47.466] iteration 18651 : model1 loss : 0.025713 model2 loss : 0.026128
[00:38:48.119] iteration 18652 : model1 loss : 0.026189 model2 loss : 0.025551
[00:38:48.775] iteration 18653 : model1 loss : 0.031289 model2 loss : 0.030152
[00:38:49.449] iteration 18654 : model1 loss : 0.019861 model2 loss : 0.020327
[00:38:50.112] iteration 18655 : model1 loss : 0.023680 model2 loss : 0.021901
[00:38:50.771] iteration 18656 : model1 loss : 0.037336 model2 loss : 0.037039
[00:38:51.442] iteration 18657 : model1 loss : 0.015413 model2 loss : 0.015667
[00:38:52.088] iteration 18658 : model1 loss : 0.019833 model2 loss : 0.021579
[00:38:52.737] iteration 18659 : model1 loss : 0.022517 model2 loss : 0.022227
[00:38:53.401] iteration 18660 : model1 loss : 0.026121 model2 loss : 0.026841
[00:38:54.050] iteration 18661 : model1 loss : 0.026273 model2 loss : 0.026093
[00:38:54.712] iteration 18662 : model1 loss : 0.020763 model2 loss : 0.020991
[00:38:55.378] iteration 18663 : model1 loss : 0.026270 model2 loss : 0.025847
[00:38:56.031] iteration 18664 : model1 loss : 0.018970 model2 loss : 0.017762
[00:38:56.687] iteration 18665 : model1 loss : 0.019269 model2 loss : 0.018943
[00:38:57.339] iteration 18666 : model1 loss : 0.024664 model2 loss : 0.022666
[00:38:58.009] iteration 18667 : model1 loss : 0.020722 model2 loss : 0.019395
[00:38:58.675] iteration 18668 : model1 loss : 0.018901 model2 loss : 0.018371
[00:38:59.333] iteration 18669 : model1 loss : 0.023502 model2 loss : 0.023136
[00:38:59.997] iteration 18670 : model1 loss : 0.026372 model2 loss : 0.027671
[00:39:00.665] iteration 18671 : model1 loss : 0.021758 model2 loss : 0.022582
[00:39:01.326] iteration 18672 : model1 loss : 0.019234 model2 loss : 0.019743
[00:39:01.976] iteration 18673 : model1 loss : 0.020213 model2 loss : 0.019382
[00:39:02.643] iteration 18674 : model1 loss : 0.027297 model2 loss : 0.025979
[00:39:03.296] iteration 18675 : model1 loss : 0.020327 model2 loss : 0.018350
[00:39:03.950] iteration 18676 : model1 loss : 0.017767 model2 loss : 0.017846
[00:39:04.604] iteration 18677 : model1 loss : 0.144786 model2 loss : 0.144105
[00:39:05.259] iteration 18678 : model1 loss : 0.026855 model2 loss : 0.032198
[00:39:05.918] iteration 18679 : model1 loss : 0.021340 model2 loss : 0.021459
[00:39:06.570] iteration 18680 : model1 loss : 0.017405 model2 loss : 0.018682
[00:39:07.247] iteration 18681 : model1 loss : 0.017754 model2 loss : 0.019552
[00:39:07.945] iteration 18682 : model1 loss : 0.018902 model2 loss : 0.017259
[00:39:08.616] iteration 18683 : model1 loss : 0.016595 model2 loss : 0.016671
[00:39:09.272] iteration 18684 : model1 loss : 0.019219 model2 loss : 0.020798
[00:39:09.919] iteration 18685 : model1 loss : 0.018969 model2 loss : 0.020300
[00:39:10.570] iteration 18686 : model1 loss : 0.017061 model2 loss : 0.016410
[00:39:11.241] iteration 18687 : model1 loss : 0.023050 model2 loss : 0.021142
[00:39:11.896] iteration 18688 : model1 loss : 0.018953 model2 loss : 0.018624
[00:39:12.557] iteration 18689 : model1 loss : 0.023786 model2 loss : 0.021781
[00:39:13.220] iteration 18690 : model1 loss : 0.021657 model2 loss : 0.020172
[00:39:13.874] iteration 18691 : model1 loss : 0.018580 model2 loss : 0.017005
[00:39:14.528] iteration 18692 : model1 loss : 0.037130 model2 loss : 0.033612
[00:39:15.182] iteration 18693 : model1 loss : 0.040322 model2 loss : 0.045969
[00:39:15.848] iteration 18694 : model1 loss : 0.024014 model2 loss : 0.020532
[00:39:16.492] iteration 18695 : model1 loss : 0.027283 model2 loss : 0.027118
[00:39:17.139] iteration 18696 : model1 loss : 0.018833 model2 loss : 0.019734
[00:39:17.792] iteration 18697 : model1 loss : 0.031089 model2 loss : 0.028787
[00:39:18.445] iteration 18698 : model1 loss : 0.026758 model2 loss : 0.028138
[00:39:19.097] iteration 18699 : model1 loss : 0.019264 model2 loss : 0.020308
[00:39:19.753] iteration 18700 : model1 loss : 0.022328 model2 loss : 0.023745
[00:39:20.441] iteration 18701 : model1 loss : 0.020626 model2 loss : 0.020807
[00:39:21.112] iteration 18702 : model1 loss : 0.016559 model2 loss : 0.016216
[00:39:21.767] iteration 18703 : model1 loss : 0.020580 model2 loss : 0.021418
[00:39:22.446] iteration 18704 : model1 loss : 0.017782 model2 loss : 0.018356
[00:39:23.104] iteration 18705 : model1 loss : 0.039524 model2 loss : 0.035587
[00:39:23.758] iteration 18706 : model1 loss : 0.019588 model2 loss : 0.019472
[00:39:24.418] iteration 18707 : model1 loss : 0.023654 model2 loss : 0.027499
[00:39:25.069] iteration 18708 : model1 loss : 0.021327 model2 loss : 0.020203
[00:39:25.732] iteration 18709 : model1 loss : 0.027513 model2 loss : 0.026587
[00:39:26.386] iteration 18710 : model1 loss : 0.024748 model2 loss : 0.026906
[00:39:27.055] iteration 18711 : model1 loss : 0.020662 model2 loss : 0.020067
[00:39:27.715] iteration 18712 : model1 loss : 0.017682 model2 loss : 0.017846
[00:39:28.369] iteration 18713 : model1 loss : 0.022479 model2 loss : 0.020200
[00:39:29.026] iteration 18714 : model1 loss : 0.143529 model2 loss : 0.141839
[00:39:29.697] iteration 18715 : model1 loss : 0.018835 model2 loss : 0.018289
[00:39:30.350] iteration 18716 : model1 loss : 0.014042 model2 loss : 0.015385
[00:39:31.017] iteration 18717 : model1 loss : 0.028024 model2 loss : 0.027885
[00:39:31.675] iteration 18718 : model1 loss : 0.017115 model2 loss : 0.019044
[00:39:32.339] iteration 18719 : model1 loss : 0.029200 model2 loss : 0.026853
[00:39:33.008] iteration 18720 : model1 loss : 0.028015 model2 loss : 0.032894
[00:39:33.672] iteration 18721 : model1 loss : 0.024896 model2 loss : 0.023473
[00:39:34.328] iteration 18722 : model1 loss : 0.019762 model2 loss : 0.018450
[00:39:34.985] iteration 18723 : model1 loss : 0.025976 model2 loss : 0.022254
[00:39:35.645] iteration 18724 : model1 loss : 0.018324 model2 loss : 0.018273
[00:39:36.309] iteration 18725 : model1 loss : 0.018163 model2 loss : 0.018453
[00:39:36.972] iteration 18726 : model1 loss : 0.020251 model2 loss : 0.019368
[00:39:37.643] iteration 18727 : model1 loss : 0.020768 model2 loss : 0.021126
[00:39:38.301] iteration 18728 : model1 loss : 0.022624 model2 loss : 0.020686
[00:39:38.961] iteration 18729 : model1 loss : 0.019055 model2 loss : 0.017653
[00:39:39.613] iteration 18730 : model1 loss : 0.020479 model2 loss : 0.019142
[00:39:40.285] iteration 18731 : model1 loss : 0.017121 model2 loss : 0.018160
[00:39:40.951] iteration 18732 : model1 loss : 0.021249 model2 loss : 0.019484
[00:39:41.613] iteration 18733 : model1 loss : 0.021974 model2 loss : 0.019302
[00:39:42.260] iteration 18734 : model1 loss : 0.154116 model2 loss : 0.148782
[00:39:42.913] iteration 18735 : model1 loss : 0.018549 model2 loss : 0.018167
[00:39:43.571] iteration 18736 : model1 loss : 0.018263 model2 loss : 0.017868
[00:39:44.236] iteration 18737 : model1 loss : 0.018320 model2 loss : 0.018469
[00:39:44.886] iteration 18738 : model1 loss : 0.020149 model2 loss : 0.021768
[00:39:45.537] iteration 18739 : model1 loss : 0.027832 model2 loss : 0.029187
[00:39:46.211] iteration 18740 : model1 loss : 0.021752 model2 loss : 0.020567
[00:39:46.868] iteration 18741 : model1 loss : 0.018831 model2 loss : 0.019251
[00:39:47.515] iteration 18742 : model1 loss : 0.018128 model2 loss : 0.018093
[00:39:48.179] iteration 18743 : model1 loss : 0.024226 model2 loss : 0.021968
[00:39:48.837] iteration 18744 : model1 loss : 0.021793 model2 loss : 0.022258
[00:39:49.503] iteration 18745 : model1 loss : 0.019392 model2 loss : 0.019825
[00:39:50.183] iteration 18746 : model1 loss : 0.021654 model2 loss : 0.021413
[00:39:50.838] iteration 18747 : model1 loss : 0.058379 model2 loss : 0.055943
[00:39:51.509] iteration 18748 : model1 loss : 0.032139 model2 loss : 0.027682
[00:39:52.174] iteration 18749 : model1 loss : 0.020507 model2 loss : 0.023553
[00:39:52.826] iteration 18750 : model1 loss : 0.019086 model2 loss : 0.019074
[00:39:53.515] iteration 18751 : model1 loss : 0.024836 model2 loss : 0.024487
[00:39:54.183] iteration 18752 : model1 loss : 0.017184 model2 loss : 0.017285
[00:39:54.835] iteration 18753 : model1 loss : 0.019960 model2 loss : 0.018792
[00:39:55.502] iteration 18754 : model1 loss : 0.025849 model2 loss : 0.027219
[00:39:56.170] iteration 18755 : model1 loss : 0.016690 model2 loss : 0.017167
[00:39:56.842] iteration 18756 : model1 loss : 0.019211 model2 loss : 0.019707
[00:39:57.504] iteration 18757 : model1 loss : 0.015818 model2 loss : 0.014883
[00:39:58.166] iteration 18758 : model1 loss : 0.026186 model2 loss : 0.028670
[00:39:58.823] iteration 18759 : model1 loss : 0.021961 model2 loss : 0.021612
[00:39:59.490] iteration 18760 : model1 loss : 0.025697 model2 loss : 0.025405
[00:40:00.142] iteration 18761 : model1 loss : 0.027830 model2 loss : 0.020993
[00:40:00.804] iteration 18762 : model1 loss : 0.024168 model2 loss : 0.028696
[00:40:01.474] iteration 18763 : model1 loss : 0.016908 model2 loss : 0.014578
[00:40:02.129] iteration 18764 : model1 loss : 0.018031 model2 loss : 0.017863
[00:40:02.787] iteration 18765 : model1 loss : 0.016432 model2 loss : 0.016099
[00:40:03.442] iteration 18766 : model1 loss : 0.019023 model2 loss : 0.019152
[00:40:04.099] iteration 18767 : model1 loss : 0.146339 model2 loss : 0.143563
[00:40:04.753] iteration 18768 : model1 loss : 0.026982 model2 loss : 0.024347
[00:40:05.415] iteration 18769 : model1 loss : 0.017712 model2 loss : 0.018453
[00:40:06.075] iteration 18770 : model1 loss : 0.021194 model2 loss : 0.022939
[00:40:06.736] iteration 18771 : model1 loss : 0.025543 model2 loss : 0.022360
[00:40:07.395] iteration 18772 : model1 loss : 0.024981 model2 loss : 0.022084
[00:40:08.101] iteration 18773 : model1 loss : 0.021317 model2 loss : 0.025473
[00:40:08.759] iteration 18774 : model1 loss : 0.018534 model2 loss : 0.016621
[00:40:09.428] iteration 18775 : model1 loss : 0.019049 model2 loss : 0.019257
[00:40:10.083] iteration 18776 : model1 loss : 0.021761 model2 loss : 0.019920
[00:40:10.736] iteration 18777 : model1 loss : 0.023409 model2 loss : 0.023526
[00:40:11.409] iteration 18778 : model1 loss : 0.020679 model2 loss : 0.019256
[00:40:12.062] iteration 18779 : model1 loss : 0.016221 model2 loss : 0.018246
[00:40:12.737] iteration 18780 : model1 loss : 0.019386 model2 loss : 0.021056
[00:40:13.396] iteration 18781 : model1 loss : 0.022480 model2 loss : 0.020040
[00:40:14.044] iteration 18782 : model1 loss : 0.023928 model2 loss : 0.026232
[00:40:14.710] iteration 18783 : model1 loss : 0.019061 model2 loss : 0.018614
[00:40:15.370] iteration 18784 : model1 loss : 0.021733 model2 loss : 0.021481
[00:40:16.025] iteration 18785 : model1 loss : 0.150443 model2 loss : 0.143757
[00:40:16.675] iteration 18786 : model1 loss : 0.018279 model2 loss : 0.017768
[00:40:17.345] iteration 18787 : model1 loss : 0.017512 model2 loss : 0.018051
[00:40:18.010] iteration 18788 : model1 loss : 0.022321 model2 loss : 0.024607
[00:40:18.666] iteration 18789 : model1 loss : 0.023560 model2 loss : 0.023525
[00:40:19.333] iteration 18790 : model1 loss : 0.020114 model2 loss : 0.018954
[00:40:20.001] iteration 18791 : model1 loss : 0.139816 model2 loss : 0.138879
[00:40:20.668] iteration 18792 : model1 loss : 0.017441 model2 loss : 0.017798
[00:40:21.333] iteration 18793 : model1 loss : 0.019385 model2 loss : 0.020005
[00:40:22.000] iteration 18794 : model1 loss : 0.032719 model2 loss : 0.035636
[00:40:22.666] iteration 18795 : model1 loss : 0.019667 model2 loss : 0.019445
[00:40:23.331] iteration 18796 : model1 loss : 0.018690 model2 loss : 0.020321
[00:40:23.995] iteration 18797 : model1 loss : 0.019016 model2 loss : 0.018001
[00:40:24.663] iteration 18798 : model1 loss : 0.013839 model2 loss : 0.014481
[00:40:25.324] iteration 18799 : model1 loss : 0.018437 model2 loss : 0.018265
[00:40:25.978] iteration 18800 : model1 loss : 0.017296 model2 loss : 0.017205
[00:40:43.677] iteration 18800 : model1_mean_dice : 0.877170 model1_mean_hd95 : 5.919452
[00:41:01.387] iteration 18800 : model2_mean_dice : 0.875138 model2_mean_hd95 : 4.473079
[00:41:02.058] iteration 18801 : model1 loss : 0.015116 model2 loss : 0.015245
[00:41:02.705] iteration 18802 : model1 loss : 0.022317 model2 loss : 0.020690
[00:41:03.364] iteration 18803 : model1 loss : 0.025508 model2 loss : 0.026560
[00:41:04.018] iteration 18804 : model1 loss : 0.020527 model2 loss : 0.019498
[00:41:04.680] iteration 18805 : model1 loss : 0.028234 model2 loss : 0.025395
[00:41:05.341] iteration 18806 : model1 loss : 0.068739 model2 loss : 0.091537
[00:41:05.984] iteration 18807 : model1 loss : 0.022388 model2 loss : 0.022746
[00:41:06.632] iteration 18808 : model1 loss : 0.020213 model2 loss : 0.020126
[00:41:07.280] iteration 18809 : model1 loss : 0.029226 model2 loss : 0.028143
[00:41:07.940] iteration 18810 : model1 loss : 0.024798 model2 loss : 0.044386
[00:41:08.625] iteration 18811 : model1 loss : 0.022325 model2 loss : 0.024277
[00:41:09.276] iteration 18812 : model1 loss : 0.023716 model2 loss : 0.023934
[00:41:09.942] iteration 18813 : model1 loss : 0.014606 model2 loss : 0.016258
[00:41:10.588] iteration 18814 : model1 loss : 0.024854 model2 loss : 0.021941
[00:41:11.255] iteration 18815 : model1 loss : 0.022518 model2 loss : 0.023606
[00:41:11.904] iteration 18816 : model1 loss : 0.020926 model2 loss : 0.019281
[00:41:12.571] iteration 18817 : model1 loss : 0.014547 model2 loss : 0.016731
[00:41:13.232] iteration 18818 : model1 loss : 0.023937 model2 loss : 0.026150
[00:41:13.896] iteration 18819 : model1 loss : 0.024397 model2 loss : 0.022815
[00:41:14.554] iteration 18820 : model1 loss : 0.018887 model2 loss : 0.020161
[00:41:15.210] iteration 18821 : model1 loss : 0.014710 model2 loss : 0.017050
[00:41:15.879] iteration 18822 : model1 loss : 0.025339 model2 loss : 0.029471
[00:41:16.523] iteration 18823 : model1 loss : 0.031000 model2 loss : 0.028775
[00:41:17.173] iteration 18824 : model1 loss : 0.026170 model2 loss : 0.028186
[00:41:17.831] iteration 18825 : model1 loss : 0.020558 model2 loss : 0.020382
[00:41:18.493] iteration 18826 : model1 loss : 0.025279 model2 loss : 0.019600
[00:41:19.142] iteration 18827 : model1 loss : 0.026211 model2 loss : 0.031204
[00:41:19.786] iteration 18828 : model1 loss : 0.021897 model2 loss : 0.021759
[00:41:20.442] iteration 18829 : model1 loss : 0.016234 model2 loss : 0.019846
[00:41:21.114] iteration 18830 : model1 loss : 0.016929 model2 loss : 0.019830
[00:41:21.774] iteration 18831 : model1 loss : 0.018543 model2 loss : 0.021107
[00:41:22.440] iteration 18832 : model1 loss : 0.022697 model2 loss : 0.024349
[00:41:23.103] iteration 18833 : model1 loss : 0.028685 model2 loss : 0.027409
[00:41:23.750] iteration 18834 : model1 loss : 0.035935 model2 loss : 0.036984
[00:41:24.413] iteration 18835 : model1 loss : 0.020179 model2 loss : 0.021619
[00:41:25.067] iteration 18836 : model1 loss : 0.036413 model2 loss : 0.036302
[00:41:25.725] iteration 18837 : model1 loss : 0.017202 model2 loss : 0.019956
[00:41:26.380] iteration 18838 : model1 loss : 0.026951 model2 loss : 0.027545
[00:41:27.037] iteration 18839 : model1 loss : 0.019075 model2 loss : 0.018532
[00:41:27.697] iteration 18840 : model1 loss : 0.020389 model2 loss : 0.024407
[00:41:28.348] iteration 18841 : model1 loss : 0.019780 model2 loss : 0.021965
[00:41:28.998] iteration 18842 : model1 loss : 0.020310 model2 loss : 0.019948
[00:41:29.649] iteration 18843 : model1 loss : 0.023845 model2 loss : 0.022604
[00:41:30.292] iteration 18844 : model1 loss : 0.023179 model2 loss : 0.022179
[00:41:30.939] iteration 18845 : model1 loss : 0.017591 model2 loss : 0.018264
[00:41:31.601] iteration 18846 : model1 loss : 0.018963 model2 loss : 0.021267
[00:41:32.261] iteration 18847 : model1 loss : 0.020651 model2 loss : 0.019304
[00:41:32.926] iteration 18848 : model1 loss : 0.018532 model2 loss : 0.018378
[00:41:33.572] iteration 18849 : model1 loss : 0.021317 model2 loss : 0.022936
[00:41:34.228] iteration 18850 : model1 loss : 0.014726 model2 loss : 0.014965
[00:41:34.932] iteration 18851 : model1 loss : 0.015046 model2 loss : 0.016818
[00:41:35.605] iteration 18852 : model1 loss : 0.023585 model2 loss : 0.024472
[00:41:36.261] iteration 18853 : model1 loss : 0.028236 model2 loss : 0.025256
[00:41:36.912] iteration 18854 : model1 loss : 0.024709 model2 loss : 0.025916
[00:41:37.574] iteration 18855 : model1 loss : 0.017605 model2 loss : 0.021310
[00:41:38.233] iteration 18856 : model1 loss : 0.018262 model2 loss : 0.022168
[00:41:38.900] iteration 18857 : model1 loss : 0.047646 model2 loss : 0.054595
[00:41:39.550] iteration 18858 : model1 loss : 0.018643 model2 loss : 0.020756
[00:41:40.203] iteration 18859 : model1 loss : 0.022190 model2 loss : 0.023007
[00:41:40.868] iteration 18860 : model1 loss : 0.023451 model2 loss : 0.025667
[00:41:41.537] iteration 18861 : model1 loss : 0.022121 model2 loss : 0.023781
[00:41:42.218] iteration 18862 : model1 loss : 0.017821 model2 loss : 0.018272
[00:41:42.876] iteration 18863 : model1 loss : 0.043073 model2 loss : 0.038040
[00:41:43.550] iteration 18864 : model1 loss : 0.017660 model2 loss : 0.017642
[00:41:44.209] iteration 18865 : model1 loss : 0.018020 model2 loss : 0.018266
[00:41:44.862] iteration 18866 : model1 loss : 0.024702 model2 loss : 0.022569
[00:41:45.523] iteration 18867 : model1 loss : 0.020526 model2 loss : 0.019554
[00:41:46.186] iteration 18868 : model1 loss : 0.020585 model2 loss : 0.020183
[00:41:46.839] iteration 18869 : model1 loss : 0.024502 model2 loss : 0.020808
[00:41:47.495] iteration 18870 : model1 loss : 0.019010 model2 loss : 0.018444
[00:41:48.147] iteration 18871 : model1 loss : 0.019916 model2 loss : 0.017101
[00:41:48.814] iteration 18872 : model1 loss : 0.020215 model2 loss : 0.021307
[00:41:49.479] iteration 18873 : model1 loss : 0.022646 model2 loss : 0.021942
[00:41:50.132] iteration 18874 : model1 loss : 0.019334 model2 loss : 0.021541
[00:41:50.783] iteration 18875 : model1 loss : 0.019523 model2 loss : 0.020927
[00:41:51.450] iteration 18876 : model1 loss : 0.023474 model2 loss : 0.022086
[00:41:52.104] iteration 18877 : model1 loss : 0.020839 model2 loss : 0.021301
[00:41:52.765] iteration 18878 : model1 loss : 0.023835 model2 loss : 0.026136
[00:41:53.429] iteration 18879 : model1 loss : 0.034692 model2 loss : 0.032309
[00:41:54.085] iteration 18880 : model1 loss : 0.016080 model2 loss : 0.017262
[00:41:54.748] iteration 18881 : model1 loss : 0.022308 model2 loss : 0.019831
[00:41:55.405] iteration 18882 : model1 loss : 0.019744 model2 loss : 0.018723
[00:41:56.063] iteration 18883 : model1 loss : 0.023022 model2 loss : 0.026726
[00:41:56.734] iteration 18884 : model1 loss : 0.017222 model2 loss : 0.019400
[00:41:57.390] iteration 18885 : model1 loss : 0.020340 model2 loss : 0.019799
[00:41:58.049] iteration 18886 : model1 loss : 0.031947 model2 loss : 0.032031
[00:41:58.720] iteration 18887 : model1 loss : 0.022920 model2 loss : 0.025728
[00:41:59.392] iteration 18888 : model1 loss : 0.021407 model2 loss : 0.021772
[00:42:00.034] iteration 18889 : model1 loss : 0.018705 model2 loss : 0.019184
[00:42:00.697] iteration 18890 : model1 loss : 0.022960 model2 loss : 0.021910
[00:42:01.363] iteration 18891 : model1 loss : 0.016436 model2 loss : 0.016275
[00:42:02.019] iteration 18892 : model1 loss : 0.019296 model2 loss : 0.018524
[00:42:02.709] iteration 18893 : model1 loss : 0.022416 model2 loss : 0.021744
[00:42:03.381] iteration 18894 : model1 loss : 0.035974 model2 loss : 0.031484
[00:42:04.039] iteration 18895 : model1 loss : 0.012944 model2 loss : 0.015231
[00:42:04.690] iteration 18896 : model1 loss : 0.020822 model2 loss : 0.019877
[00:42:05.344] iteration 18897 : model1 loss : 0.028442 model2 loss : 0.029361
[00:42:05.998] iteration 18898 : model1 loss : 0.016595 model2 loss : 0.016367
[00:42:06.660] iteration 18899 : model1 loss : 0.029140 model2 loss : 0.027602
[00:42:07.306] iteration 18900 : model1 loss : 0.023822 model2 loss : 0.023890
[00:42:08.002] iteration 18901 : model1 loss : 0.020219 model2 loss : 0.020519
[00:42:08.663] iteration 18902 : model1 loss : 0.019193 model2 loss : 0.019233
[00:42:09.345] iteration 18903 : model1 loss : 0.022880 model2 loss : 0.020904
[00:42:10.005] iteration 18904 : model1 loss : 0.024247 model2 loss : 0.028229
[00:42:10.670] iteration 18905 : model1 loss : 0.015413 model2 loss : 0.015899
[00:42:11.343] iteration 18906 : model1 loss : 0.020735 model2 loss : 0.021038
[00:42:11.999] iteration 18907 : model1 loss : 0.021147 model2 loss : 0.018224
[00:42:12.669] iteration 18908 : model1 loss : 0.029782 model2 loss : 0.030190
[00:42:13.322] iteration 18909 : model1 loss : 0.015256 model2 loss : 0.017382
[00:42:13.985] iteration 18910 : model1 loss : 0.016361 model2 loss : 0.019690
[00:42:14.641] iteration 18911 : model1 loss : 0.016030 model2 loss : 0.015965
[00:42:15.302] iteration 18912 : model1 loss : 0.022678 model2 loss : 0.025355
[00:42:15.957] iteration 18913 : model1 loss : 0.018149 model2 loss : 0.020408
[00:42:16.605] iteration 18914 : model1 loss : 0.020584 model2 loss : 0.019091
[00:42:17.257] iteration 18915 : model1 loss : 0.017559 model2 loss : 0.020569
[00:42:17.916] iteration 18916 : model1 loss : 0.017808 model2 loss : 0.017203
[00:42:18.592] iteration 18917 : model1 loss : 0.023743 model2 loss : 0.023541
[00:42:19.251] iteration 18918 : model1 loss : 0.018669 model2 loss : 0.019633
[00:42:19.903] iteration 18919 : model1 loss : 0.019690 model2 loss : 0.021105
[00:42:20.576] iteration 18920 : model1 loss : 0.019709 model2 loss : 0.022309
[00:42:21.238] iteration 18921 : model1 loss : 0.028827 model2 loss : 0.020935
[00:42:21.889] iteration 18922 : model1 loss : 0.028061 model2 loss : 0.028668
[00:42:22.563] iteration 18923 : model1 loss : 0.022352 model2 loss : 0.026186
[00:42:23.215] iteration 18924 : model1 loss : 0.021082 model2 loss : 0.022414
[00:42:23.877] iteration 18925 : model1 loss : 0.021867 model2 loss : 0.023045
[00:42:24.541] iteration 18926 : model1 loss : 0.022156 model2 loss : 0.020117
[00:42:25.193] iteration 18927 : model1 loss : 0.032403 model2 loss : 0.031965
[00:42:25.846] iteration 18928 : model1 loss : 0.036219 model2 loss : 0.031390
[00:42:26.508] iteration 18929 : model1 loss : 0.045949 model2 loss : 0.046244
[00:42:27.172] iteration 18930 : model1 loss : 0.020587 model2 loss : 0.020899
[00:42:27.848] iteration 18931 : model1 loss : 0.020246 model2 loss : 0.023081
[00:42:28.509] iteration 18932 : model1 loss : 0.018925 model2 loss : 0.019956
[00:42:29.178] iteration 18933 : model1 loss : 0.023222 model2 loss : 0.023976
[00:42:29.822] iteration 18934 : model1 loss : 0.025268 model2 loss : 0.023032
[00:42:30.479] iteration 18935 : model1 loss : 0.019622 model2 loss : 0.021511
[00:42:31.139] iteration 18936 : model1 loss : 0.015955 model2 loss : 0.015929
[00:42:31.798] iteration 18937 : model1 loss : 0.025550 model2 loss : 0.022445
[00:42:32.470] iteration 18938 : model1 loss : 0.021783 model2 loss : 0.019296
[00:42:33.128] iteration 18939 : model1 loss : 0.018927 model2 loss : 0.017519
[00:42:33.786] iteration 18940 : model1 loss : 0.022180 model2 loss : 0.019941
[00:42:34.445] iteration 18941 : model1 loss : 0.020299 model2 loss : 0.020424
[00:42:35.090] iteration 18942 : model1 loss : 0.020123 model2 loss : 0.020243
[00:42:35.743] iteration 18943 : model1 loss : 0.020453 model2 loss : 0.022135
[00:42:36.395] iteration 18944 : model1 loss : 0.018225 model2 loss : 0.017476
[00:42:37.049] iteration 18945 : model1 loss : 0.018217 model2 loss : 0.017008
[00:42:37.708] iteration 18946 : model1 loss : 0.019001 model2 loss : 0.016983
[00:42:38.374] iteration 18947 : model1 loss : 0.023328 model2 loss : 0.027298
[00:42:39.040] iteration 18948 : model1 loss : 0.016423 model2 loss : 0.019617
[00:42:39.696] iteration 18949 : model1 loss : 0.022943 model2 loss : 0.022961
[00:42:40.363] iteration 18950 : model1 loss : 0.019463 model2 loss : 0.020760
[00:42:41.064] iteration 18951 : model1 loss : 0.018094 model2 loss : 0.018513
[00:42:41.721] iteration 18952 : model1 loss : 0.019440 model2 loss : 0.016238
[00:42:42.381] iteration 18953 : model1 loss : 0.021881 model2 loss : 0.022730
[00:42:43.047] iteration 18954 : model1 loss : 0.150193 model2 loss : 0.145335
[00:42:43.710] iteration 18955 : model1 loss : 0.036275 model2 loss : 0.044178
[00:42:44.377] iteration 18956 : model1 loss : 0.032742 model2 loss : 0.036231
[00:42:45.038] iteration 18957 : model1 loss : 0.029998 model2 loss : 0.030579
[00:42:45.728] iteration 18958 : model1 loss : 0.022006 model2 loss : 0.019862
[00:42:46.383] iteration 18959 : model1 loss : 0.019028 model2 loss : 0.019248
[00:42:47.043] iteration 18960 : model1 loss : 0.020860 model2 loss : 0.020849
[00:42:47.742] iteration 18961 : model1 loss : 0.018337 model2 loss : 0.018492
[00:42:48.424] iteration 18962 : model1 loss : 0.016117 model2 loss : 0.018667
[00:42:49.096] iteration 18963 : model1 loss : 0.026576 model2 loss : 0.027771
[00:42:49.761] iteration 18964 : model1 loss : 0.020058 model2 loss : 0.018383
[00:42:50.470] iteration 18965 : model1 loss : 0.028976 model2 loss : 0.026269
[00:42:51.166] iteration 18966 : model1 loss : 0.020156 model2 loss : 0.019688
[00:42:51.851] iteration 18967 : model1 loss : 0.019781 model2 loss : 0.018444
[00:42:52.510] iteration 18968 : model1 loss : 0.016095 model2 loss : 0.020635
[00:42:53.177] iteration 18969 : model1 loss : 0.026262 model2 loss : 0.023866
[00:42:53.838] iteration 18970 : model1 loss : 0.019945 model2 loss : 0.020180
[00:42:54.495] iteration 18971 : model1 loss : 0.029819 model2 loss : 0.030825
[00:42:55.147] iteration 18972 : model1 loss : 0.087876 model2 loss : 0.109275
[00:42:55.807] iteration 18973 : model1 loss : 0.015533 model2 loss : 0.016206
[00:42:56.463] iteration 18974 : model1 loss : 0.022337 model2 loss : 0.022542
[00:42:57.116] iteration 18975 : model1 loss : 0.020316 model2 loss : 0.021013
[00:42:57.784] iteration 18976 : model1 loss : 0.015647 model2 loss : 0.017634
[00:42:58.438] iteration 18977 : model1 loss : 0.027310 model2 loss : 0.026874
[00:42:59.099] iteration 18978 : model1 loss : 0.024172 model2 loss : 0.024300
[00:42:59.759] iteration 18979 : model1 loss : 0.016258 model2 loss : 0.015904
[00:43:00.418] iteration 18980 : model1 loss : 0.020373 model2 loss : 0.020728
[00:43:01.074] iteration 18981 : model1 loss : 0.016583 model2 loss : 0.016687
[00:43:01.725] iteration 18982 : model1 loss : 0.022273 model2 loss : 0.021648
[00:43:02.382] iteration 18983 : model1 loss : 0.017112 model2 loss : 0.014862
[00:43:03.062] iteration 18984 : model1 loss : 0.025008 model2 loss : 0.026177
[00:43:03.709] iteration 18985 : model1 loss : 0.021120 model2 loss : 0.022787
[00:43:04.373] iteration 18986 : model1 loss : 0.014911 model2 loss : 0.015698
[00:43:05.023] iteration 18987 : model1 loss : 0.023180 model2 loss : 0.024584
[00:43:05.684] iteration 18988 : model1 loss : 0.022052 model2 loss : 0.022383
[00:43:06.342] iteration 18989 : model1 loss : 0.020220 model2 loss : 0.017532
[00:43:06.995] iteration 18990 : model1 loss : 0.021647 model2 loss : 0.023231
[00:43:07.653] iteration 18991 : model1 loss : 0.018918 model2 loss : 0.018811
[00:43:08.308] iteration 18992 : model1 loss : 0.016793 model2 loss : 0.017751
[00:43:08.958] iteration 18993 : model1 loss : 0.024140 model2 loss : 0.025180
[00:43:09.627] iteration 18994 : model1 loss : 0.022298 model2 loss : 0.025144
[00:43:10.298] iteration 18995 : model1 loss : 0.018839 model2 loss : 0.018132
[00:43:10.946] iteration 18996 : model1 loss : 0.021404 model2 loss : 0.023649
[00:43:11.609] iteration 18997 : model1 loss : 0.019064 model2 loss : 0.023395
[00:43:12.271] iteration 18998 : model1 loss : 0.019026 model2 loss : 0.019724
[00:43:12.924] iteration 18999 : model1 loss : 0.019032 model2 loss : 0.020275
[00:43:13.584] iteration 19000 : model1 loss : 0.018540 model2 loss : 0.017873
[00:43:31.234] iteration 19000 : model1_mean_dice : 0.865563 model1_mean_hd95 : 6.630759
[00:43:48.644] iteration 19000 : model2_mean_dice : 0.872477 model2_mean_hd95 : 3.686762
[00:43:49.326] iteration 19001 : model1 loss : 0.027625 model2 loss : 0.029628
[00:43:49.986] iteration 19002 : model1 loss : 0.022592 model2 loss : 0.020783
[00:43:50.692] iteration 19003 : model1 loss : 0.026159 model2 loss : 0.026807
[00:43:51.347] iteration 19004 : model1 loss : 0.018552 model2 loss : 0.019320
[00:43:52.007] iteration 19005 : model1 loss : 0.021432 model2 loss : 0.019991
[00:43:52.656] iteration 19006 : model1 loss : 0.020837 model2 loss : 0.019986
[00:43:53.317] iteration 19007 : model1 loss : 0.025818 model2 loss : 0.017047
[00:43:53.999] iteration 19008 : model1 loss : 0.019308 model2 loss : 0.017775
[00:43:54.657] iteration 19009 : model1 loss : 0.025692 model2 loss : 0.024739
[00:43:55.337] iteration 19010 : model1 loss : 0.020149 model2 loss : 0.020406
[00:43:55.987] iteration 19011 : model1 loss : 0.036083 model2 loss : 0.034993
[00:43:56.629] iteration 19012 : model1 loss : 0.032911 model2 loss : 0.028644
[00:43:57.285] iteration 19013 : model1 loss : 0.021922 model2 loss : 0.017218
[00:43:57.946] iteration 19014 : model1 loss : 0.021385 model2 loss : 0.022437
[00:43:58.612] iteration 19015 : model1 loss : 0.034613 model2 loss : 0.050196
[00:43:59.255] iteration 19016 : model1 loss : 0.022127 model2 loss : 0.020687
[00:43:59.908] iteration 19017 : model1 loss : 0.020003 model2 loss : 0.021364
[00:44:00.572] iteration 19018 : model1 loss : 0.020576 model2 loss : 0.021956
[00:44:01.228] iteration 19019 : model1 loss : 0.026226 model2 loss : 0.027865
[00:44:01.883] iteration 19020 : model1 loss : 0.025312 model2 loss : 0.025949
[00:44:02.549] iteration 19021 : model1 loss : 0.023170 model2 loss : 0.024582
[00:44:03.199] iteration 19022 : model1 loss : 0.020648 model2 loss : 0.018075
[00:44:03.860] iteration 19023 : model1 loss : 0.015816 model2 loss : 0.016165
[00:44:04.507] iteration 19024 : model1 loss : 0.038121 model2 loss : 0.040347
[00:44:05.163] iteration 19025 : model1 loss : 0.019652 model2 loss : 0.019942
[00:44:05.815] iteration 19026 : model1 loss : 0.022503 model2 loss : 0.021204
[00:44:06.476] iteration 19027 : model1 loss : 0.023222 model2 loss : 0.021704
[00:44:07.125] iteration 19028 : model1 loss : 0.021156 model2 loss : 0.022014
[00:44:07.782] iteration 19029 : model1 loss : 0.021202 model2 loss : 0.021507
[00:44:08.443] iteration 19030 : model1 loss : 0.037069 model2 loss : 0.035428
[00:44:09.099] iteration 19031 : model1 loss : 0.018405 model2 loss : 0.018757
[00:44:09.784] iteration 19032 : model1 loss : 0.023635 model2 loss : 0.022787
[00:44:10.448] iteration 19033 : model1 loss : 0.020898 model2 loss : 0.022600
[00:44:11.123] iteration 19034 : model1 loss : 0.049136 model2 loss : 0.057375
[00:44:11.777] iteration 19035 : model1 loss : 0.028785 model2 loss : 0.027931
[00:44:12.433] iteration 19036 : model1 loss : 0.019181 model2 loss : 0.016334
[00:44:13.096] iteration 19037 : model1 loss : 0.015981 model2 loss : 0.018361
[00:44:13.748] iteration 19038 : model1 loss : 0.031212 model2 loss : 0.025585
[00:44:14.400] iteration 19039 : model1 loss : 0.025262 model2 loss : 0.023075
[00:44:15.067] iteration 19040 : model1 loss : 0.022645 model2 loss : 0.022022
[00:44:15.714] iteration 19041 : model1 loss : 0.017056 model2 loss : 0.017515
[00:44:16.373] iteration 19042 : model1 loss : 0.021245 model2 loss : 0.019340
[00:44:17.038] iteration 19043 : model1 loss : 0.016725 model2 loss : 0.017538
[00:44:17.698] iteration 19044 : model1 loss : 0.016826 model2 loss : 0.016174
[00:44:18.361] iteration 19045 : model1 loss : 0.036807 model2 loss : 0.034435
[00:44:19.022] iteration 19046 : model1 loss : 0.023632 model2 loss : 0.021348
[00:44:19.669] iteration 19047 : model1 loss : 0.021628 model2 loss : 0.021679
[00:44:20.321] iteration 19048 : model1 loss : 0.021451 model2 loss : 0.022124
[00:44:20.976] iteration 19049 : model1 loss : 0.022127 model2 loss : 0.026176
[00:44:21.644] iteration 19050 : model1 loss : 0.024971 model2 loss : 0.021338
[00:44:22.351] iteration 19051 : model1 loss : 0.028318 model2 loss : 0.029209
[00:44:23.020] iteration 19052 : model1 loss : 0.016765 model2 loss : 0.017800
[00:44:23.677] iteration 19053 : model1 loss : 0.027532 model2 loss : 0.021786
[00:44:24.344] iteration 19054 : model1 loss : 0.024284 model2 loss : 0.024256
[00:44:25.002] iteration 19055 : model1 loss : 0.023429 model2 loss : 0.021494
[00:44:25.658] iteration 19056 : model1 loss : 0.025117 model2 loss : 0.024811
[00:44:26.321] iteration 19057 : model1 loss : 0.041093 model2 loss : 0.042504
[00:44:26.987] iteration 19058 : model1 loss : 0.014318 model2 loss : 0.015420
[00:44:27.644] iteration 19059 : model1 loss : 0.017257 model2 loss : 0.016811
[00:44:28.293] iteration 19060 : model1 loss : 0.016431 model2 loss : 0.016569
[00:44:28.943] iteration 19061 : model1 loss : 0.020545 model2 loss : 0.020637
[00:44:29.603] iteration 19062 : model1 loss : 0.017682 model2 loss : 0.019173
[00:44:30.255] iteration 19063 : model1 loss : 0.016732 model2 loss : 0.016192
[00:44:30.913] iteration 19064 : model1 loss : 0.033205 model2 loss : 0.028782
[00:44:31.590] iteration 19065 : model1 loss : 0.016608 model2 loss : 0.016201
[00:44:32.255] iteration 19066 : model1 loss : 0.019525 model2 loss : 0.019672
[00:44:32.917] iteration 19067 : model1 loss : 0.019560 model2 loss : 0.021399
[00:44:33.569] iteration 19068 : model1 loss : 0.020719 model2 loss : 0.021737
[00:44:34.238] iteration 19069 : model1 loss : 0.018558 model2 loss : 0.017944
[00:44:34.899] iteration 19070 : model1 loss : 0.019167 model2 loss : 0.019433
[00:44:35.565] iteration 19071 : model1 loss : 0.023686 model2 loss : 0.022413
[00:44:36.223] iteration 19072 : model1 loss : 0.022901 model2 loss : 0.025550
[00:44:36.874] iteration 19073 : model1 loss : 0.021129 model2 loss : 0.020942
[00:44:37.544] iteration 19074 : model1 loss : 0.020147 model2 loss : 0.018247
[00:44:38.198] iteration 19075 : model1 loss : 0.026393 model2 loss : 0.022739
[00:44:38.868] iteration 19076 : model1 loss : 0.022590 model2 loss : 0.022809
[00:44:39.531] iteration 19077 : model1 loss : 0.042752 model2 loss : 0.038133
[00:44:40.197] iteration 19078 : model1 loss : 0.019036 model2 loss : 0.018573
[00:44:40.848] iteration 19079 : model1 loss : 0.033572 model2 loss : 0.051295
[00:44:41.509] iteration 19080 : model1 loss : 0.020099 model2 loss : 0.021480
[00:44:42.163] iteration 19081 : model1 loss : 0.016523 model2 loss : 0.015017
[00:44:42.829] iteration 19082 : model1 loss : 0.018722 model2 loss : 0.019010
[00:44:43.491] iteration 19083 : model1 loss : 0.020149 model2 loss : 0.022452
[00:44:44.154] iteration 19084 : model1 loss : 0.021078 model2 loss : 0.022181
[00:44:44.807] iteration 19085 : model1 loss : 0.018721 model2 loss : 0.019237
[00:44:45.478] iteration 19086 : model1 loss : 0.023029 model2 loss : 0.022716
[00:44:46.146] iteration 19087 : model1 loss : 0.019443 model2 loss : 0.019282
[00:44:46.813] iteration 19088 : model1 loss : 0.021338 model2 loss : 0.021852
[00:44:47.477] iteration 19089 : model1 loss : 0.030259 model2 loss : 0.030708
[00:44:48.147] iteration 19090 : model1 loss : 0.024524 model2 loss : 0.028306
[00:44:48.805] iteration 19091 : model1 loss : 0.017316 model2 loss : 0.017607
[00:44:49.467] iteration 19092 : model1 loss : 0.028360 model2 loss : 0.027496
[00:44:50.126] iteration 19093 : model1 loss : 0.023053 model2 loss : 0.023836
[00:44:50.777] iteration 19094 : model1 loss : 0.022246 model2 loss : 0.021863
[00:44:51.440] iteration 19095 : model1 loss : 0.018994 model2 loss : 0.018617
[00:44:52.098] iteration 19096 : model1 loss : 0.029793 model2 loss : 0.030181
[00:44:52.788] iteration 19097 : model1 loss : 0.026349 model2 loss : 0.022767
[00:44:53.446] iteration 19098 : model1 loss : 0.021119 model2 loss : 0.021603
[00:44:54.109] iteration 19099 : model1 loss : 0.016723 model2 loss : 0.018148
[00:44:54.781] iteration 19100 : model1 loss : 0.021640 model2 loss : 0.021866
[00:44:55.486] iteration 19101 : model1 loss : 0.037556 model2 loss : 0.035448
[00:44:56.149] iteration 19102 : model1 loss : 0.020816 model2 loss : 0.019509
[00:44:56.808] iteration 19103 : model1 loss : 0.013299 model2 loss : 0.015728
[00:44:57.461] iteration 19104 : model1 loss : 0.023106 model2 loss : 0.022194
[00:44:58.121] iteration 19105 : model1 loss : 0.021101 model2 loss : 0.020053
[00:44:58.782] iteration 19106 : model1 loss : 0.023977 model2 loss : 0.024753
[00:44:59.440] iteration 19107 : model1 loss : 0.025582 model2 loss : 0.026925
[00:45:00.114] iteration 19108 : model1 loss : 0.028847 model2 loss : 0.025170
[00:45:00.770] iteration 19109 : model1 loss : 0.018188 model2 loss : 0.017991
[00:45:01.443] iteration 19110 : model1 loss : 0.019584 model2 loss : 0.022069
[00:45:02.103] iteration 19111 : model1 loss : 0.023736 model2 loss : 0.021549
[00:45:02.758] iteration 19112 : model1 loss : 0.015738 model2 loss : 0.018714
[00:45:03.416] iteration 19113 : model1 loss : 0.025163 model2 loss : 0.026184
[00:45:04.073] iteration 19114 : model1 loss : 0.016134 model2 loss : 0.014602
[00:45:04.726] iteration 19115 : model1 loss : 0.019511 model2 loss : 0.022994
[00:45:05.384] iteration 19116 : model1 loss : 0.020813 model2 loss : 0.019940
[00:45:06.043] iteration 19117 : model1 loss : 0.020375 model2 loss : 0.020865
[00:45:06.696] iteration 19118 : model1 loss : 0.017573 model2 loss : 0.016473
[00:45:07.351] iteration 19119 : model1 loss : 0.019683 model2 loss : 0.021082
[00:45:08.011] iteration 19120 : model1 loss : 0.024909 model2 loss : 0.024472
[00:45:08.676] iteration 19121 : model1 loss : 0.018570 model2 loss : 0.018690
[00:45:09.342] iteration 19122 : model1 loss : 0.019561 model2 loss : 0.019882
[00:45:10.023] iteration 19123 : model1 loss : 0.018884 model2 loss : 0.019117
[00:45:10.694] iteration 19124 : model1 loss : 0.024877 model2 loss : 0.025595
[00:45:11.372] iteration 19125 : model1 loss : 0.147506 model2 loss : 0.147082
[00:45:12.033] iteration 19126 : model1 loss : 0.020439 model2 loss : 0.020677
[00:45:12.699] iteration 19127 : model1 loss : 0.016691 model2 loss : 0.016916
[00:45:13.362] iteration 19128 : model1 loss : 0.017767 model2 loss : 0.018690
[00:45:14.012] iteration 19129 : model1 loss : 0.024998 model2 loss : 0.020107
[00:45:14.668] iteration 19130 : model1 loss : 0.020150 model2 loss : 0.020570
[00:45:15.328] iteration 19131 : model1 loss : 0.030908 model2 loss : 0.029038
[00:45:16.001] iteration 19132 : model1 loss : 0.022999 model2 loss : 0.023759
[00:45:16.657] iteration 19133 : model1 loss : 0.029951 model2 loss : 0.068909
[00:45:17.312] iteration 19134 : model1 loss : 0.019816 model2 loss : 0.019546
[00:45:17.964] iteration 19135 : model1 loss : 0.020630 model2 loss : 0.022857
[00:45:18.617] iteration 19136 : model1 loss : 0.022126 model2 loss : 0.020396
[00:45:19.274] iteration 19137 : model1 loss : 0.016167 model2 loss : 0.018578
[00:45:19.943] iteration 19138 : model1 loss : 0.022331 model2 loss : 0.025427
[00:45:20.599] iteration 19139 : model1 loss : 0.023955 model2 loss : 0.025152
[00:45:21.272] iteration 19140 : model1 loss : 0.021923 model2 loss : 0.025643
[00:45:21.932] iteration 19141 : model1 loss : 0.018952 model2 loss : 0.020666
[00:45:22.592] iteration 19142 : model1 loss : 0.021039 model2 loss : 0.020246
[00:45:23.257] iteration 19143 : model1 loss : 0.020382 model2 loss : 0.020400
[00:45:23.917] iteration 19144 : model1 loss : 0.018100 model2 loss : 0.017395
[00:45:24.595] iteration 19145 : model1 loss : 0.017727 model2 loss : 0.016189
[00:45:25.262] iteration 19146 : model1 loss : 0.021153 model2 loss : 0.032002
[00:45:25.926] iteration 19147 : model1 loss : 0.018056 model2 loss : 0.018232
[00:45:26.585] iteration 19148 : model1 loss : 0.017489 model2 loss : 0.017971
[00:45:27.230] iteration 19149 : model1 loss : 0.015425 model2 loss : 0.016250
[00:45:27.880] iteration 19150 : model1 loss : 0.023251 model2 loss : 0.021324
[00:45:28.587] iteration 19151 : model1 loss : 0.023274 model2 loss : 0.022998
[00:45:29.233] iteration 19152 : model1 loss : 0.019863 model2 loss : 0.021472
[00:45:29.895] iteration 19153 : model1 loss : 0.023943 model2 loss : 0.023663
[00:45:30.549] iteration 19154 : model1 loss : 0.019479 model2 loss : 0.020562
[00:45:31.211] iteration 19155 : model1 loss : 0.022478 model2 loss : 0.018756
[00:45:31.857] iteration 19156 : model1 loss : 0.019625 model2 loss : 0.022919
[00:45:32.527] iteration 19157 : model1 loss : 0.020057 model2 loss : 0.038841
[00:45:33.180] iteration 19158 : model1 loss : 0.021766 model2 loss : 0.022286
[00:45:33.835] iteration 19159 : model1 loss : 0.023319 model2 loss : 0.025106
[00:45:34.494] iteration 19160 : model1 loss : 0.030630 model2 loss : 0.030848
[00:45:35.147] iteration 19161 : model1 loss : 0.033014 model2 loss : 0.033487
[00:45:35.808] iteration 19162 : model1 loss : 0.019179 model2 loss : 0.022319
[00:45:36.475] iteration 19163 : model1 loss : 0.020210 model2 loss : 0.021559
[00:45:37.145] iteration 19164 : model1 loss : 0.021010 model2 loss : 0.020249
[00:45:37.791] iteration 19165 : model1 loss : 0.016534 model2 loss : 0.017528
[00:45:38.452] iteration 19166 : model1 loss : 0.018373 model2 loss : 0.018381
[00:45:39.120] iteration 19167 : model1 loss : 0.142429 model2 loss : 0.141625
[00:45:39.776] iteration 19168 : model1 loss : 0.017903 model2 loss : 0.017864
[00:45:40.433] iteration 19169 : model1 loss : 0.028885 model2 loss : 0.022553
[00:45:41.095] iteration 19170 : model1 loss : 0.019433 model2 loss : 0.018736
[00:45:41.746] iteration 19171 : model1 loss : 0.044924 model2 loss : 0.048116
[00:45:42.407] iteration 19172 : model1 loss : 0.016789 model2 loss : 0.017795
[00:45:43.070] iteration 19173 : model1 loss : 0.138045 model2 loss : 0.139794
[00:45:43.730] iteration 19174 : model1 loss : 0.022494 model2 loss : 0.020933
[00:45:44.393] iteration 19175 : model1 loss : 0.018819 model2 loss : 0.018549
[00:45:45.047] iteration 19176 : model1 loss : 0.020872 model2 loss : 0.020634
[00:45:45.703] iteration 19177 : model1 loss : 0.027895 model2 loss : 0.026455
[00:45:46.369] iteration 19178 : model1 loss : 0.026188 model2 loss : 0.024352
[00:45:47.024] iteration 19179 : model1 loss : 0.068825 model2 loss : 0.050477
[00:45:47.688] iteration 19180 : model1 loss : 0.024617 model2 loss : 0.023002
[00:45:48.353] iteration 19181 : model1 loss : 0.015501 model2 loss : 0.016247
[00:45:49.017] iteration 19182 : model1 loss : 0.043469 model2 loss : 0.045660
[00:45:49.684] iteration 19183 : model1 loss : 0.016270 model2 loss : 0.017102
[00:45:50.342] iteration 19184 : model1 loss : 0.022185 model2 loss : 0.032307
[00:45:50.993] iteration 19185 : model1 loss : 0.015437 model2 loss : 0.017409
[00:45:51.659] iteration 19186 : model1 loss : 0.018736 model2 loss : 0.016904
[00:45:52.317] iteration 19187 : model1 loss : 0.023878 model2 loss : 0.023941
[00:45:52.969] iteration 19188 : model1 loss : 0.025042 model2 loss : 0.022631
[00:45:53.638] iteration 19189 : model1 loss : 0.022079 model2 loss : 0.023361
[00:45:54.292] iteration 19190 : model1 loss : 0.026035 model2 loss : 0.027623
[00:45:54.955] iteration 19191 : model1 loss : 0.018106 model2 loss : 0.017504
[00:45:55.614] iteration 19192 : model1 loss : 0.023655 model2 loss : 0.025289
[00:45:56.287] iteration 19193 : model1 loss : 0.022562 model2 loss : 0.021317
[00:45:56.935] iteration 19194 : model1 loss : 0.019377 model2 loss : 0.018858
[00:45:57.589] iteration 19195 : model1 loss : 0.021784 model2 loss : 0.019105
[00:45:58.253] iteration 19196 : model1 loss : 0.022191 model2 loss : 0.020950
[00:45:58.914] iteration 19197 : model1 loss : 0.019280 model2 loss : 0.019485
[00:45:59.579] iteration 19198 : model1 loss : 0.029438 model2 loss : 0.022856
[00:46:00.241] iteration 19199 : model1 loss : 0.020240 model2 loss : 0.019880
[00:46:00.898] iteration 19200 : model1 loss : 0.022133 model2 loss : 0.021566
[00:46:18.902] iteration 19200 : model1_mean_dice : 0.871077 model1_mean_hd95 : 4.257379
[00:46:36.448] iteration 19200 : model2_mean_dice : 0.868181 model2_mean_hd95 : 5.232236
[00:46:37.123] iteration 19201 : model1 loss : 0.021183 model2 loss : 0.019763
[00:46:37.770] iteration 19202 : model1 loss : 0.019543 model2 loss : 0.018245
[00:46:38.432] iteration 19203 : model1 loss : 0.018424 model2 loss : 0.019032
[00:46:39.078] iteration 19204 : model1 loss : 0.030411 model2 loss : 0.029100
[00:46:39.735] iteration 19205 : model1 loss : 0.048305 model2 loss : 0.041917
[00:46:40.388] iteration 19206 : model1 loss : 0.021382 model2 loss : 0.020016
[00:46:41.047] iteration 19207 : model1 loss : 0.020734 model2 loss : 0.022344
[00:46:41.703] iteration 19208 : model1 loss : 0.023620 model2 loss : 0.022002
[00:46:42.353] iteration 19209 : model1 loss : 0.018516 model2 loss : 0.018403
[00:46:43.010] iteration 19210 : model1 loss : 0.020368 model2 loss : 0.028054
[00:46:43.677] iteration 19211 : model1 loss : 0.022541 model2 loss : 0.026331
[00:46:44.338] iteration 19212 : model1 loss : 0.023027 model2 loss : 0.022700
[00:46:45.002] iteration 19213 : model1 loss : 0.032905 model2 loss : 0.032392
[00:46:45.656] iteration 19214 : model1 loss : 0.027883 model2 loss : 0.025273
[00:46:46.301] iteration 19215 : model1 loss : 0.019037 model2 loss : 0.019171
[00:46:46.955] iteration 19216 : model1 loss : 0.022675 model2 loss : 0.019369
[00:46:47.618] iteration 19217 : model1 loss : 0.013711 model2 loss : 0.014014
[00:46:48.286] iteration 19218 : model1 loss : 0.023159 model2 loss : 0.022276
[00:46:48.936] iteration 19219 : model1 loss : 0.021520 model2 loss : 0.021698
[00:46:49.591] iteration 19220 : model1 loss : 0.022829 model2 loss : 0.022703
[00:46:50.242] iteration 19221 : model1 loss : 0.018080 model2 loss : 0.022136
[00:46:50.889] iteration 19222 : model1 loss : 0.033027 model2 loss : 0.030750
[00:46:51.555] iteration 19223 : model1 loss : 0.021693 model2 loss : 0.020729
[00:46:52.204] iteration 19224 : model1 loss : 0.015865 model2 loss : 0.015860
[00:46:52.875] iteration 19225 : model1 loss : 0.019507 model2 loss : 0.020225
[00:46:53.522] iteration 19226 : model1 loss : 0.023465 model2 loss : 0.019920
[00:46:54.171] iteration 19227 : model1 loss : 0.022819 model2 loss : 0.021875
[00:46:54.838] iteration 19228 : model1 loss : 0.015319 model2 loss : 0.016025
[00:46:55.499] iteration 19229 : model1 loss : 0.082854 model2 loss : 0.070051
[00:46:56.154] iteration 19230 : model1 loss : 0.020533 model2 loss : 0.023650
[00:46:56.805] iteration 19231 : model1 loss : 0.018584 model2 loss : 0.020706
[00:46:57.451] iteration 19232 : model1 loss : 0.022895 model2 loss : 0.021174
[00:46:58.117] iteration 19233 : model1 loss : 0.019660 model2 loss : 0.022015
[00:46:58.777] iteration 19234 : model1 loss : 0.023229 model2 loss : 0.025225
[00:46:59.436] iteration 19235 : model1 loss : 0.018366 model2 loss : 0.017401
[00:47:00.089] iteration 19236 : model1 loss : 0.019148 model2 loss : 0.017383
[00:47:00.746] iteration 19237 : model1 loss : 0.022618 model2 loss : 0.021765
[00:47:01.400] iteration 19238 : model1 loss : 0.025814 model2 loss : 0.031649
[00:47:02.061] iteration 19239 : model1 loss : 0.022120 model2 loss : 0.019958
[00:47:02.717] iteration 19240 : model1 loss : 0.035587 model2 loss : 0.035533
[00:47:03.374] iteration 19241 : model1 loss : 0.023428 model2 loss : 0.023880
[00:47:04.035] iteration 19242 : model1 loss : 0.028013 model2 loss : 0.025865
[00:47:04.686] iteration 19243 : model1 loss : 0.025233 model2 loss : 0.023665
[00:47:05.346] iteration 19244 : model1 loss : 0.030669 model2 loss : 0.027587
[00:47:06.009] iteration 19245 : model1 loss : 0.057689 model2 loss : 0.042530
[00:47:06.659] iteration 19246 : model1 loss : 0.018902 model2 loss : 0.020143
[00:47:07.316] iteration 19247 : model1 loss : 0.034538 model2 loss : 0.025883
[00:47:07.976] iteration 19248 : model1 loss : 0.022793 model2 loss : 0.020855
[00:47:08.634] iteration 19249 : model1 loss : 0.023597 model2 loss : 0.023551
[00:47:09.292] iteration 19250 : model1 loss : 0.034022 model2 loss : 0.030769
[00:47:09.991] iteration 19251 : model1 loss : 0.025003 model2 loss : 0.027496
[00:47:10.667] iteration 19252 : model1 loss : 0.023854 model2 loss : 0.021827
[00:47:11.377] iteration 19253 : model1 loss : 0.030425 model2 loss : 0.027106
[00:47:12.037] iteration 19254 : model1 loss : 0.026359 model2 loss : 0.025867
[00:47:12.697] iteration 19255 : model1 loss : 0.022691 model2 loss : 0.024243
[00:47:13.359] iteration 19256 : model1 loss : 0.016028 model2 loss : 0.018046
[00:47:14.021] iteration 19257 : model1 loss : 0.023821 model2 loss : 0.024089
[00:47:14.670] iteration 19258 : model1 loss : 0.021415 model2 loss : 0.019954
[00:47:15.336] iteration 19259 : model1 loss : 0.020119 model2 loss : 0.018630
[00:47:16.000] iteration 19260 : model1 loss : 0.022091 model2 loss : 0.020826
[00:47:16.663] iteration 19261 : model1 loss : 0.017883 model2 loss : 0.017828
[00:47:17.320] iteration 19262 : model1 loss : 0.026177 model2 loss : 0.026616
[00:47:17.972] iteration 19263 : model1 loss : 0.026020 model2 loss : 0.026296
[00:47:18.632] iteration 19264 : model1 loss : 0.018522 model2 loss : 0.018265
[00:47:19.285] iteration 19265 : model1 loss : 0.019533 model2 loss : 0.019029
[00:47:19.957] iteration 19266 : model1 loss : 0.019026 model2 loss : 0.022203
[00:47:20.641] iteration 19267 : model1 loss : 0.017949 model2 loss : 0.019646
[00:47:21.320] iteration 19268 : model1 loss : 0.022621 model2 loss : 0.024468
[00:47:21.976] iteration 19269 : model1 loss : 0.016604 model2 loss : 0.016090
[00:47:22.640] iteration 19270 : model1 loss : 0.026008 model2 loss : 0.026762
[00:47:23.302] iteration 19271 : model1 loss : 0.017866 model2 loss : 0.016620
[00:47:23.960] iteration 19272 : model1 loss : 0.022195 model2 loss : 0.020335
[00:47:24.618] iteration 19273 : model1 loss : 0.021117 model2 loss : 0.018293
[00:47:25.282] iteration 19274 : model1 loss : 0.028716 model2 loss : 0.026491
[00:47:25.936] iteration 19275 : model1 loss : 0.020322 model2 loss : 0.020395
[00:47:26.597] iteration 19276 : model1 loss : 0.021948 model2 loss : 0.021650
[00:47:27.255] iteration 19277 : model1 loss : 0.015194 model2 loss : 0.014547
[00:47:27.912] iteration 19278 : model1 loss : 0.020294 model2 loss : 0.025643
[00:47:28.574] iteration 19279 : model1 loss : 0.019920 model2 loss : 0.019477
[00:47:29.227] iteration 19280 : model1 loss : 0.024089 model2 loss : 0.021885
[00:47:29.881] iteration 19281 : model1 loss : 0.019509 model2 loss : 0.020126
[00:47:30.534] iteration 19282 : model1 loss : 0.022083 model2 loss : 0.022685
[00:47:31.197] iteration 19283 : model1 loss : 0.025429 model2 loss : 0.028229
[00:47:31.840] iteration 19284 : model1 loss : 0.144110 model2 loss : 0.141581
[00:47:32.515] iteration 19285 : model1 loss : 0.023051 model2 loss : 0.023703
[00:47:33.185] iteration 19286 : model1 loss : 0.022083 model2 loss : 0.020799
[00:47:33.847] iteration 19287 : model1 loss : 0.021772 model2 loss : 0.021770
[00:47:34.491] iteration 19288 : model1 loss : 0.021551 model2 loss : 0.025413
[00:47:35.149] iteration 19289 : model1 loss : 0.045984 model2 loss : 0.048832
[00:47:35.810] iteration 19290 : model1 loss : 0.018061 model2 loss : 0.020799
[00:47:36.469] iteration 19291 : model1 loss : 0.020235 model2 loss : 0.020814
[00:47:37.125] iteration 19292 : model1 loss : 0.017273 model2 loss : 0.018055
[00:47:37.797] iteration 19293 : model1 loss : 0.032295 model2 loss : 0.026860
[00:47:38.451] iteration 19294 : model1 loss : 0.021663 model2 loss : 0.021103
[00:47:39.120] iteration 19295 : model1 loss : 0.017964 model2 loss : 0.016594
[00:47:39.776] iteration 19296 : model1 loss : 0.019177 model2 loss : 0.020124
[00:47:40.434] iteration 19297 : model1 loss : 0.022219 model2 loss : 0.024090
[00:47:41.088] iteration 19298 : model1 loss : 0.025640 model2 loss : 0.025330
[00:47:41.747] iteration 19299 : model1 loss : 0.025787 model2 loss : 0.026747
[00:47:42.400] iteration 19300 : model1 loss : 0.020776 model2 loss : 0.022275
[00:47:43.099] iteration 19301 : model1 loss : 0.019728 model2 loss : 0.020605
[00:47:43.760] iteration 19302 : model1 loss : 0.017944 model2 loss : 0.016766
[00:47:44.425] iteration 19303 : model1 loss : 0.025678 model2 loss : 0.028620
[00:47:45.083] iteration 19304 : model1 loss : 0.021378 model2 loss : 0.020732
[00:47:45.747] iteration 19305 : model1 loss : 0.023007 model2 loss : 0.021024
[00:47:46.404] iteration 19306 : model1 loss : 0.016687 model2 loss : 0.017615
[00:47:47.057] iteration 19307 : model1 loss : 0.021341 model2 loss : 0.027077
[00:47:47.708] iteration 19308 : model1 loss : 0.023559 model2 loss : 0.025221
[00:47:48.373] iteration 19309 : model1 loss : 0.024332 model2 loss : 0.027749
[00:47:49.037] iteration 19310 : model1 loss : 0.013391 model2 loss : 0.013446
[00:47:49.708] iteration 19311 : model1 loss : 0.018853 model2 loss : 0.015928
[00:47:50.370] iteration 19312 : model1 loss : 0.021439 model2 loss : 0.018230
[00:47:51.038] iteration 19313 : model1 loss : 0.016869 model2 loss : 0.017452
[00:47:51.703] iteration 19314 : model1 loss : 0.018301 model2 loss : 0.019842
[00:47:52.360] iteration 19315 : model1 loss : 0.016670 model2 loss : 0.018749
[00:47:53.026] iteration 19316 : model1 loss : 0.024588 model2 loss : 0.023640
[00:47:53.692] iteration 19317 : model1 loss : 0.026715 model2 loss : 0.027051
[00:47:54.352] iteration 19318 : model1 loss : 0.020480 model2 loss : 0.019061
[00:47:55.002] iteration 19319 : model1 loss : 0.024788 model2 loss : 0.025496
[00:47:55.665] iteration 19320 : model1 loss : 0.018625 model2 loss : 0.020647
[00:47:56.326] iteration 19321 : model1 loss : 0.018651 model2 loss : 0.015634
[00:47:56.977] iteration 19322 : model1 loss : 0.016871 model2 loss : 0.019273
[00:47:57.632] iteration 19323 : model1 loss : 0.031056 model2 loss : 0.026585
[00:47:58.301] iteration 19324 : model1 loss : 0.020086 model2 loss : 0.018741
[00:47:58.951] iteration 19325 : model1 loss : 0.034750 model2 loss : 0.029580
[00:47:59.619] iteration 19326 : model1 loss : 0.023351 model2 loss : 0.024444
[00:48:00.271] iteration 19327 : model1 loss : 0.021467 model2 loss : 0.019623
[00:48:00.945] iteration 19328 : model1 loss : 0.044965 model2 loss : 0.039175
[00:48:01.612] iteration 19329 : model1 loss : 0.016954 model2 loss : 0.018234
[00:48:02.268] iteration 19330 : model1 loss : 0.022264 model2 loss : 0.024032
[00:48:02.939] iteration 19331 : model1 loss : 0.021831 model2 loss : 0.021768
[00:48:03.584] iteration 19332 : model1 loss : 0.020310 model2 loss : 0.019867
[00:48:04.242] iteration 19333 : model1 loss : 0.017904 model2 loss : 0.018654
[00:48:04.895] iteration 19334 : model1 loss : 0.023866 model2 loss : 0.019089
[00:48:05.545] iteration 19335 : model1 loss : 0.022174 model2 loss : 0.029800
[00:48:06.211] iteration 19336 : model1 loss : 0.021401 model2 loss : 0.023241
[00:48:06.863] iteration 19337 : model1 loss : 0.020834 model2 loss : 0.021389
[00:48:07.531] iteration 19338 : model1 loss : 0.144472 model2 loss : 0.143110
[00:48:08.185] iteration 19339 : model1 loss : 0.029231 model2 loss : 0.030977
[00:48:08.853] iteration 19340 : model1 loss : 0.021341 model2 loss : 0.021031
[00:48:09.504] iteration 19341 : model1 loss : 0.021890 model2 loss : 0.021999
[00:48:10.159] iteration 19342 : model1 loss : 0.019521 model2 loss : 0.018806
[00:48:10.816] iteration 19343 : model1 loss : 0.016831 model2 loss : 0.017550
[00:48:11.481] iteration 19344 : model1 loss : 0.032317 model2 loss : 0.033022
[00:48:12.160] iteration 19345 : model1 loss : 0.017915 model2 loss : 0.018289
[00:48:12.827] iteration 19346 : model1 loss : 0.019845 model2 loss : 0.019421
[00:48:13.483] iteration 19347 : model1 loss : 0.020102 model2 loss : 0.018919
[00:48:14.131] iteration 19348 : model1 loss : 0.022576 model2 loss : 0.023920
[00:48:14.798] iteration 19349 : model1 loss : 0.020906 model2 loss : 0.020165
[00:48:15.452] iteration 19350 : model1 loss : 0.016096 model2 loss : 0.015129
[00:48:16.158] iteration 19351 : model1 loss : 0.017657 model2 loss : 0.017663
[00:48:16.818] iteration 19352 : model1 loss : 0.028494 model2 loss : 0.029414
[00:48:17.476] iteration 19353 : model1 loss : 0.017560 model2 loss : 0.018487
[00:48:18.133] iteration 19354 : model1 loss : 0.020351 model2 loss : 0.022343
[00:48:18.793] iteration 19355 : model1 loss : 0.014229 model2 loss : 0.015142
[00:48:19.450] iteration 19356 : model1 loss : 0.019657 model2 loss : 0.022689
[00:48:20.110] iteration 19357 : model1 loss : 0.018797 model2 loss : 0.018467
[00:48:20.766] iteration 19358 : model1 loss : 0.020093 model2 loss : 0.022269
[00:48:21.430] iteration 19359 : model1 loss : 0.022234 model2 loss : 0.020015
[00:48:22.079] iteration 19360 : model1 loss : 0.021314 model2 loss : 0.022463
[00:48:22.748] iteration 19361 : model1 loss : 0.023147 model2 loss : 0.023647
[00:48:23.413] iteration 19362 : model1 loss : 0.049644 model2 loss : 0.032272
[00:48:24.076] iteration 19363 : model1 loss : 0.018871 model2 loss : 0.018982
[00:48:24.727] iteration 19364 : model1 loss : 0.016551 model2 loss : 0.016102
[00:48:25.392] iteration 19365 : model1 loss : 0.022000 model2 loss : 0.023466
[00:48:26.053] iteration 19366 : model1 loss : 0.077823 model2 loss : 0.041906
[00:48:26.707] iteration 19367 : model1 loss : 0.023341 model2 loss : 0.025956
[00:48:27.368] iteration 19368 : model1 loss : 0.015646 model2 loss : 0.015185
[00:48:28.026] iteration 19369 : model1 loss : 0.024632 model2 loss : 0.021757
[00:48:28.680] iteration 19370 : model1 loss : 0.041036 model2 loss : 0.035808
[00:48:29.347] iteration 19371 : model1 loss : 0.036896 model2 loss : 0.035069
[00:48:30.013] iteration 19372 : model1 loss : 0.034247 model2 loss : 0.033058
[00:48:30.691] iteration 19373 : model1 loss : 0.028188 model2 loss : 0.020617
[00:48:31.351] iteration 19374 : model1 loss : 0.023444 model2 loss : 0.025219
[00:48:32.010] iteration 19375 : model1 loss : 0.022116 model2 loss : 0.022004
[00:48:32.673] iteration 19376 : model1 loss : 0.029850 model2 loss : 0.028262
[00:48:33.338] iteration 19377 : model1 loss : 0.022167 model2 loss : 0.023217
[00:48:33.990] iteration 19378 : model1 loss : 0.018708 model2 loss : 0.017134
[00:48:34.641] iteration 19379 : model1 loss : 0.022207 model2 loss : 0.024691
[00:48:35.295] iteration 19380 : model1 loss : 0.020696 model2 loss : 0.021895
[00:48:35.963] iteration 19381 : model1 loss : 0.028703 model2 loss : 0.027486
[00:48:36.637] iteration 19382 : model1 loss : 0.030671 model2 loss : 0.026060
[00:48:37.334] iteration 19383 : model1 loss : 0.022056 model2 loss : 0.023846
[00:48:37.988] iteration 19384 : model1 loss : 0.022707 model2 loss : 0.022016
[00:48:38.657] iteration 19385 : model1 loss : 0.018821 model2 loss : 0.019178
[00:48:39.327] iteration 19386 : model1 loss : 0.018110 model2 loss : 0.017402
[00:48:39.977] iteration 19387 : model1 loss : 0.020074 model2 loss : 0.020879
[00:48:40.636] iteration 19388 : model1 loss : 0.022209 model2 loss : 0.021905
[00:48:41.294] iteration 19389 : model1 loss : 0.019780 model2 loss : 0.018355
[00:48:41.946] iteration 19390 : model1 loss : 0.018254 model2 loss : 0.019869
[00:48:42.604] iteration 19391 : model1 loss : 0.019454 model2 loss : 0.020887
[00:48:43.274] iteration 19392 : model1 loss : 0.098857 model2 loss : 0.090935
[00:48:43.928] iteration 19393 : model1 loss : 0.015035 model2 loss : 0.016019
[00:48:44.588] iteration 19394 : model1 loss : 0.017338 model2 loss : 0.015458
[00:48:45.241] iteration 19395 : model1 loss : 0.022068 model2 loss : 0.022570
[00:48:45.900] iteration 19396 : model1 loss : 0.046274 model2 loss : 0.045484
[00:48:46.566] iteration 19397 : model1 loss : 0.019230 model2 loss : 0.018456
[00:48:47.225] iteration 19398 : model1 loss : 0.023703 model2 loss : 0.026144
[00:48:47.887] iteration 19399 : model1 loss : 0.021835 model2 loss : 0.023062
[00:48:48.543] iteration 19400 : model1 loss : 0.019718 model2 loss : 0.019556
[00:49:06.424] iteration 19400 : model1_mean_dice : 0.864370 model1_mean_hd95 : 6.356186
[00:49:24.249] iteration 19400 : model2_mean_dice : 0.862401 model2_mean_hd95 : 5.214444
[00:49:24.928] iteration 19401 : model1 loss : 0.019157 model2 loss : 0.021351
[00:49:25.583] iteration 19402 : model1 loss : 0.021039 model2 loss : 0.020593
[00:49:26.234] iteration 19403 : model1 loss : 0.018881 model2 loss : 0.019463
[00:49:26.885] iteration 19404 : model1 loss : 0.016700 model2 loss : 0.022378
[00:49:27.536] iteration 19405 : model1 loss : 0.021600 model2 loss : 0.024412
[00:49:28.183] iteration 19406 : model1 loss : 0.018661 model2 loss : 0.020109
[00:49:28.823] iteration 19407 : model1 loss : 0.017092 model2 loss : 0.018068
[00:49:29.479] iteration 19408 : model1 loss : 0.021097 model2 loss : 0.020319
[00:49:30.132] iteration 19409 : model1 loss : 0.017801 model2 loss : 0.019630
[00:49:30.791] iteration 19410 : model1 loss : 0.033409 model2 loss : 0.039719
[00:49:31.455] iteration 19411 : model1 loss : 0.022512 model2 loss : 0.021392
[00:49:32.104] iteration 19412 : model1 loss : 0.018281 model2 loss : 0.019258
[00:49:32.754] iteration 19413 : model1 loss : 0.020089 model2 loss : 0.022993
[00:49:33.409] iteration 19414 : model1 loss : 0.023653 model2 loss : 0.029130
[00:49:34.057] iteration 19415 : model1 loss : 0.035065 model2 loss : 0.026855
[00:49:34.718] iteration 19416 : model1 loss : 0.020520 model2 loss : 0.019673
[00:49:35.372] iteration 19417 : model1 loss : 0.020925 model2 loss : 0.020381
[00:49:36.021] iteration 19418 : model1 loss : 0.020506 model2 loss : 0.027341
[00:49:36.695] iteration 19419 : model1 loss : 0.021746 model2 loss : 0.020538
[00:49:37.354] iteration 19420 : model1 loss : 0.018900 model2 loss : 0.019567
[00:49:38.003] iteration 19421 : model1 loss : 0.022105 model2 loss : 0.022589
[00:49:38.658] iteration 19422 : model1 loss : 0.027177 model2 loss : 0.023772
[00:49:39.311] iteration 19423 : model1 loss : 0.018935 model2 loss : 0.018781
[00:49:39.960] iteration 19424 : model1 loss : 0.030193 model2 loss : 0.024598
[00:49:40.628] iteration 19425 : model1 loss : 0.025425 model2 loss : 0.024824
[00:49:41.289] iteration 19426 : model1 loss : 0.021120 model2 loss : 0.021789
[00:49:41.949] iteration 19427 : model1 loss : 0.025674 model2 loss : 0.026354
[00:49:42.614] iteration 19428 : model1 loss : 0.029021 model2 loss : 0.028836
[00:49:43.265] iteration 19429 : model1 loss : 0.018748 model2 loss : 0.020839
[00:49:43.920] iteration 19430 : model1 loss : 0.024704 model2 loss : 0.024896
[00:49:44.590] iteration 19431 : model1 loss : 0.030363 model2 loss : 0.035138
[00:49:45.254] iteration 19432 : model1 loss : 0.026608 model2 loss : 0.025618
[00:49:45.920] iteration 19433 : model1 loss : 0.047954 model2 loss : 0.039139
[00:49:46.573] iteration 19434 : model1 loss : 0.017372 model2 loss : 0.017123
[00:49:47.223] iteration 19435 : model1 loss : 0.022248 model2 loss : 0.026287
[00:49:47.877] iteration 19436 : model1 loss : 0.045771 model2 loss : 0.041202
[00:49:48.536] iteration 19437 : model1 loss : 0.017116 model2 loss : 0.020408
[00:49:49.179] iteration 19438 : model1 loss : 0.019217 model2 loss : 0.019592
[00:49:49.824] iteration 19439 : model1 loss : 0.077785 model2 loss : 0.071325
[00:49:50.476] iteration 19440 : model1 loss : 0.017906 model2 loss : 0.015594
[00:49:51.119] iteration 19441 : model1 loss : 0.017526 model2 loss : 0.016572
[00:49:51.764] iteration 19442 : model1 loss : 0.018595 model2 loss : 0.019593
[00:49:52.440] iteration 19443 : model1 loss : 0.019496 model2 loss : 0.018147
[00:49:53.104] iteration 19444 : model1 loss : 0.024568 model2 loss : 0.024685
[00:49:53.752] iteration 19445 : model1 loss : 0.023340 model2 loss : 0.022917
[00:49:54.412] iteration 19446 : model1 loss : 0.028821 model2 loss : 0.033855
[00:49:55.075] iteration 19447 : model1 loss : 0.023623 model2 loss : 0.024799
[00:49:55.734] iteration 19448 : model1 loss : 0.023490 model2 loss : 0.021620
[00:49:56.415] iteration 19449 : model1 loss : 0.022920 model2 loss : 0.033011
[00:49:57.073] iteration 19450 : model1 loss : 0.027722 model2 loss : 0.030316
[00:49:57.767] iteration 19451 : model1 loss : 0.020894 model2 loss : 0.022090
[00:49:58.429] iteration 19452 : model1 loss : 0.022777 model2 loss : 0.022982
[00:49:59.091] iteration 19453 : model1 loss : 0.023344 model2 loss : 0.019664
[00:49:59.741] iteration 19454 : model1 loss : 0.027340 model2 loss : 0.026660
[00:50:00.398] iteration 19455 : model1 loss : 0.033215 model2 loss : 0.019065
[00:50:01.066] iteration 19456 : model1 loss : 0.020954 model2 loss : 0.021412
[00:50:01.727] iteration 19457 : model1 loss : 0.022604 model2 loss : 0.023830
[00:50:02.382] iteration 19458 : model1 loss : 0.021368 model2 loss : 0.021448
[00:50:03.042] iteration 19459 : model1 loss : 0.017496 model2 loss : 0.018583
[00:50:03.693] iteration 19460 : model1 loss : 0.027943 model2 loss : 0.028437
[00:50:04.358] iteration 19461 : model1 loss : 0.030540 model2 loss : 0.031038
[00:50:05.015] iteration 19462 : model1 loss : 0.025898 model2 loss : 0.025065
[00:50:05.666] iteration 19463 : model1 loss : 0.016959 model2 loss : 0.018867
[00:50:06.330] iteration 19464 : model1 loss : 0.020616 model2 loss : 0.020850
[00:50:06.989] iteration 19465 : model1 loss : 0.021457 model2 loss : 0.019927
[00:50:07.653] iteration 19466 : model1 loss : 0.023511 model2 loss : 0.020453
[00:50:08.317] iteration 19467 : model1 loss : 0.024123 model2 loss : 0.024312
[00:50:08.969] iteration 19468 : model1 loss : 0.060994 model2 loss : 0.057920
[00:50:09.631] iteration 19469 : model1 loss : 0.016974 model2 loss : 0.018922
[00:50:10.279] iteration 19470 : model1 loss : 0.017255 model2 loss : 0.015619
[00:50:10.948] iteration 19471 : model1 loss : 0.021766 model2 loss : 0.024708
[00:50:11.607] iteration 19472 : model1 loss : 0.027611 model2 loss : 0.024845
[00:50:12.271] iteration 19473 : model1 loss : 0.022584 model2 loss : 0.022432
[00:50:12.945] iteration 19474 : model1 loss : 0.016557 model2 loss : 0.019400
[00:50:13.615] iteration 19475 : model1 loss : 0.023090 model2 loss : 0.022169
[00:50:14.283] iteration 19476 : model1 loss : 0.018227 model2 loss : 0.017517
[00:50:14.940] iteration 19477 : model1 loss : 0.019637 model2 loss : 0.017262
[00:50:15.598] iteration 19478 : model1 loss : 0.048586 model2 loss : 0.053504
[00:50:16.259] iteration 19479 : model1 loss : 0.031010 model2 loss : 0.030004
[00:50:16.915] iteration 19480 : model1 loss : 0.016286 model2 loss : 0.016265
[00:50:17.582] iteration 19481 : model1 loss : 0.024646 model2 loss : 0.026174
[00:50:18.239] iteration 19482 : model1 loss : 0.029283 model2 loss : 0.026873
[00:50:18.915] iteration 19483 : model1 loss : 0.022214 model2 loss : 0.022217
[00:50:19.565] iteration 19484 : model1 loss : 0.017567 model2 loss : 0.016775
[00:50:20.225] iteration 19485 : model1 loss : 0.020974 model2 loss : 0.021222
[00:50:20.892] iteration 19486 : model1 loss : 0.024044 model2 loss : 0.023535
[00:50:21.555] iteration 19487 : model1 loss : 0.015608 model2 loss : 0.016314
[00:50:22.211] iteration 19488 : model1 loss : 0.035879 model2 loss : 0.035045
[00:50:22.865] iteration 19489 : model1 loss : 0.021482 model2 loss : 0.022610
[00:50:23.531] iteration 19490 : model1 loss : 0.023861 model2 loss : 0.023411
[00:50:24.196] iteration 19491 : model1 loss : 0.022840 model2 loss : 0.022873
[00:50:24.850] iteration 19492 : model1 loss : 0.022666 model2 loss : 0.021791
[00:50:25.502] iteration 19493 : model1 loss : 0.026863 model2 loss : 0.019979
[00:50:26.161] iteration 19494 : model1 loss : 0.017046 model2 loss : 0.016633
[00:50:26.822] iteration 19495 : model1 loss : 0.016617 model2 loss : 0.015695
[00:50:27.485] iteration 19496 : model1 loss : 0.020554 model2 loss : 0.020705
[00:50:28.134] iteration 19497 : model1 loss : 0.026012 model2 loss : 0.026148
[00:50:28.795] iteration 19498 : model1 loss : 0.022228 model2 loss : 0.022695
[00:50:29.457] iteration 19499 : model1 loss : 0.034867 model2 loss : 0.034667
[00:50:30.114] iteration 19500 : model1 loss : 0.039918 model2 loss : 0.031054
[00:50:30.815] iteration 19501 : model1 loss : 0.032603 model2 loss : 0.033054
[00:50:31.472] iteration 19502 : model1 loss : 0.019272 model2 loss : 0.019032
[00:50:32.145] iteration 19503 : model1 loss : 0.030646 model2 loss : 0.034057
[00:50:32.800] iteration 19504 : model1 loss : 0.021968 model2 loss : 0.021008
[00:50:33.452] iteration 19505 : model1 loss : 0.020961 model2 loss : 0.018426
[00:50:34.105] iteration 19506 : model1 loss : 0.025307 model2 loss : 0.025519
[00:50:34.767] iteration 19507 : model1 loss : 0.028180 model2 loss : 0.042797
[00:50:35.425] iteration 19508 : model1 loss : 0.020188 model2 loss : 0.020546
[00:50:36.081] iteration 19509 : model1 loss : 0.017301 model2 loss : 0.017521
[00:50:36.732] iteration 19510 : model1 loss : 0.016468 model2 loss : 0.018551
[00:50:37.394] iteration 19511 : model1 loss : 0.029688 model2 loss : 0.032536
[00:50:38.041] iteration 19512 : model1 loss : 0.021018 model2 loss : 0.024918
[00:50:38.707] iteration 19513 : model1 loss : 0.021089 model2 loss : 0.021858
[00:50:39.359] iteration 19514 : model1 loss : 0.020944 model2 loss : 0.021974
[00:50:40.021] iteration 19515 : model1 loss : 0.019236 model2 loss : 0.020585
[00:50:40.694] iteration 19516 : model1 loss : 0.022052 model2 loss : 0.023759
[00:50:41.367] iteration 19517 : model1 loss : 0.023407 model2 loss : 0.024966
[00:50:42.023] iteration 19518 : model1 loss : 0.021385 model2 loss : 0.020931
[00:50:42.685] iteration 19519 : model1 loss : 0.027921 model2 loss : 0.023766
[00:50:43.340] iteration 19520 : model1 loss : 0.026868 model2 loss : 0.025479
[00:50:44.005] iteration 19521 : model1 loss : 0.027564 model2 loss : 0.022548
[00:50:44.672] iteration 19522 : model1 loss : 0.020136 model2 loss : 0.017987
[00:50:45.330] iteration 19523 : model1 loss : 0.145394 model2 loss : 0.145778
[00:50:45.978] iteration 19524 : model1 loss : 0.021027 model2 loss : 0.023380
[00:50:46.634] iteration 19525 : model1 loss : 0.027221 model2 loss : 0.026415
[00:50:47.297] iteration 19526 : model1 loss : 0.021595 model2 loss : 0.021114
[00:50:47.945] iteration 19527 : model1 loss : 0.021230 model2 loss : 0.018156
[00:50:48.611] iteration 19528 : model1 loss : 0.021669 model2 loss : 0.021771
[00:50:49.268] iteration 19529 : model1 loss : 0.018358 model2 loss : 0.020264
[00:50:49.926] iteration 19530 : model1 loss : 0.027517 model2 loss : 0.025415
[00:50:50.583] iteration 19531 : model1 loss : 0.019405 model2 loss : 0.017615
[00:50:51.243] iteration 19532 : model1 loss : 0.014136 model2 loss : 0.014645
[00:50:51.894] iteration 19533 : model1 loss : 0.017903 model2 loss : 0.018872
[00:50:52.551] iteration 19534 : model1 loss : 0.023202 model2 loss : 0.020138
[00:50:53.208] iteration 19535 : model1 loss : 0.021508 model2 loss : 0.020003
[00:50:53.873] iteration 19536 : model1 loss : 0.013425 model2 loss : 0.014586
[00:50:54.536] iteration 19537 : model1 loss : 0.022541 model2 loss : 0.022488
[00:50:55.198] iteration 19538 : model1 loss : 0.019128 model2 loss : 0.019827
[00:50:55.856] iteration 19539 : model1 loss : 0.023884 model2 loss : 0.022616
[00:50:56.519] iteration 19540 : model1 loss : 0.018648 model2 loss : 0.019084
[00:50:57.190] iteration 19541 : model1 loss : 0.035875 model2 loss : 0.029310
[00:50:57.854] iteration 19542 : model1 loss : 0.020206 model2 loss : 0.021677
[00:50:58.502] iteration 19543 : model1 loss : 0.016612 model2 loss : 0.015979
[00:50:59.150] iteration 19544 : model1 loss : 0.019330 model2 loss : 0.021384
[00:50:59.810] iteration 19545 : model1 loss : 0.019404 model2 loss : 0.020502
[00:51:00.484] iteration 19546 : model1 loss : 0.018243 model2 loss : 0.018273
[00:51:01.142] iteration 19547 : model1 loss : 0.015367 model2 loss : 0.018803
[00:51:01.794] iteration 19548 : model1 loss : 0.025700 model2 loss : 0.025787
[00:51:02.465] iteration 19549 : model1 loss : 0.018208 model2 loss : 0.017488
[00:51:03.121] iteration 19550 : model1 loss : 0.023727 model2 loss : 0.024998
[00:51:03.827] iteration 19551 : model1 loss : 0.018561 model2 loss : 0.016970
[00:51:04.487] iteration 19552 : model1 loss : 0.030272 model2 loss : 0.024454
[00:51:05.150] iteration 19553 : model1 loss : 0.021505 model2 loss : 0.022194
[00:51:05.810] iteration 19554 : model1 loss : 0.017035 model2 loss : 0.017937
[00:51:06.466] iteration 19555 : model1 loss : 0.018598 model2 loss : 0.018518
[00:51:07.128] iteration 19556 : model1 loss : 0.019685 model2 loss : 0.018157
[00:51:07.773] iteration 19557 : model1 loss : 0.019449 model2 loss : 0.018660
[00:51:08.435] iteration 19558 : model1 loss : 0.023885 model2 loss : 0.023142
[00:51:09.091] iteration 19559 : model1 loss : 0.024818 model2 loss : 0.028870
[00:51:09.741] iteration 19560 : model1 loss : 0.028527 model2 loss : 0.028334
[00:51:10.404] iteration 19561 : model1 loss : 0.018442 model2 loss : 0.016720
[00:51:11.052] iteration 19562 : model1 loss : 0.023567 model2 loss : 0.024038
[00:51:11.721] iteration 19563 : model1 loss : 0.022671 model2 loss : 0.028617
[00:51:12.374] iteration 19564 : model1 loss : 0.020718 model2 loss : 0.020005
[00:51:13.060] iteration 19565 : model1 loss : 0.029069 model2 loss : 0.027332
[00:51:13.748] iteration 19566 : model1 loss : 0.022762 model2 loss : 0.024958
[00:51:14.416] iteration 19567 : model1 loss : 0.018035 model2 loss : 0.017759
[00:51:15.085] iteration 19568 : model1 loss : 0.018733 model2 loss : 0.019089
[00:51:15.740] iteration 19569 : model1 loss : 0.022000 model2 loss : 0.022989
[00:51:16.397] iteration 19570 : model1 loss : 0.018242 model2 loss : 0.017939
[00:51:17.061] iteration 19571 : model1 loss : 0.029285 model2 loss : 0.027817
[00:51:17.713] iteration 19572 : model1 loss : 0.019509 model2 loss : 0.027315
[00:51:18.374] iteration 19573 : model1 loss : 0.037394 model2 loss : 0.033463
[00:51:19.033] iteration 19574 : model1 loss : 0.018482 model2 loss : 0.018422
[00:51:19.681] iteration 19575 : model1 loss : 0.019844 model2 loss : 0.020207
[00:51:20.344] iteration 19576 : model1 loss : 0.032167 model2 loss : 0.032696
[00:51:21.010] iteration 19577 : model1 loss : 0.020812 model2 loss : 0.019480
[00:51:21.669] iteration 19578 : model1 loss : 0.021042 model2 loss : 0.022783
[00:51:22.336] iteration 19579 : model1 loss : 0.020095 model2 loss : 0.019739
[00:51:23.136] iteration 19580 : model1 loss : 0.024921 model2 loss : 0.022519
[00:51:23.839] iteration 19581 : model1 loss : 0.025725 model2 loss : 0.026036
[00:51:24.552] iteration 19582 : model1 loss : 0.019190 model2 loss : 0.019574
[00:51:25.243] iteration 19583 : model1 loss : 0.019071 model2 loss : 0.019748
[00:51:25.901] iteration 19584 : model1 loss : 0.022263 model2 loss : 0.022581
[00:51:26.560] iteration 19585 : model1 loss : 0.019456 model2 loss : 0.021500
[00:51:27.213] iteration 19586 : model1 loss : 0.026075 model2 loss : 0.024944
[00:51:27.863] iteration 19587 : model1 loss : 0.018472 model2 loss : 0.017170
[00:51:28.523] iteration 19588 : model1 loss : 0.018112 model2 loss : 0.016815
[00:51:29.187] iteration 19589 : model1 loss : 0.018283 model2 loss : 0.018774
[00:51:29.831] iteration 19590 : model1 loss : 0.016295 model2 loss : 0.018363
[00:51:30.490] iteration 19591 : model1 loss : 0.032013 model2 loss : 0.034272
[00:51:31.147] iteration 19592 : model1 loss : 0.022058 model2 loss : 0.024159
[00:51:31.797] iteration 19593 : model1 loss : 0.018057 model2 loss : 0.019757
[00:51:32.463] iteration 19594 : model1 loss : 0.018013 model2 loss : 0.016431
[00:51:33.124] iteration 19595 : model1 loss : 0.019312 model2 loss : 0.019754
[00:51:33.777] iteration 19596 : model1 loss : 0.015784 model2 loss : 0.020418
[00:51:34.437] iteration 19597 : model1 loss : 0.022716 model2 loss : 0.024294
[00:51:35.084] iteration 19598 : model1 loss : 0.028849 model2 loss : 0.028339
[00:51:35.745] iteration 19599 : model1 loss : 0.017153 model2 loss : 0.018275
[00:51:36.398] iteration 19600 : model1 loss : 0.018897 model2 loss : 0.019307
[00:51:54.864] iteration 19600 : model1_mean_dice : 0.867225 model1_mean_hd95 : 6.385275
[00:52:12.490] iteration 19600 : model2_mean_dice : 0.866641 model2_mean_hd95 : 5.134304
[00:52:13.178] iteration 19601 : model1 loss : 0.030052 model2 loss : 0.028817
[00:52:13.865] iteration 19602 : model1 loss : 0.024512 model2 loss : 0.023021
[00:52:14.522] iteration 19603 : model1 loss : 0.020887 model2 loss : 0.022574
[00:52:15.190] iteration 19604 : model1 loss : 0.020607 model2 loss : 0.023858
[00:52:15.842] iteration 19605 : model1 loss : 0.015164 model2 loss : 0.016525
[00:52:16.487] iteration 19606 : model1 loss : 0.021412 model2 loss : 0.020125
[00:52:17.147] iteration 19607 : model1 loss : 0.034639 model2 loss : 0.022202
[00:52:17.808] iteration 19608 : model1 loss : 0.016288 model2 loss : 0.016719
[00:52:18.485] iteration 19609 : model1 loss : 0.014997 model2 loss : 0.015597
[00:52:19.139] iteration 19610 : model1 loss : 0.018896 model2 loss : 0.019311
[00:52:19.787] iteration 19611 : model1 loss : 0.017200 model2 loss : 0.016534
[00:52:20.435] iteration 19612 : model1 loss : 0.020671 model2 loss : 0.020414
[00:52:21.102] iteration 19613 : model1 loss : 0.017041 model2 loss : 0.018405
[00:52:21.751] iteration 19614 : model1 loss : 0.033870 model2 loss : 0.031999
[00:52:22.419] iteration 19615 : model1 loss : 0.018725 model2 loss : 0.019180
[00:52:23.071] iteration 19616 : model1 loss : 0.025142 model2 loss : 0.025234
[00:52:23.727] iteration 19617 : model1 loss : 0.019649 model2 loss : 0.021234
[00:52:24.386] iteration 19618 : model1 loss : 0.041068 model2 loss : 0.039230
[00:52:25.046] iteration 19619 : model1 loss : 0.023711 model2 loss : 0.025322
[00:52:25.707] iteration 19620 : model1 loss : 0.028514 model2 loss : 0.029780
[00:52:26.351] iteration 19621 : model1 loss : 0.027431 model2 loss : 0.022407
[00:52:27.007] iteration 19622 : model1 loss : 0.024170 model2 loss : 0.022527
[00:52:27.663] iteration 19623 : model1 loss : 0.018271 model2 loss : 0.018922
[00:52:28.319] iteration 19624 : model1 loss : 0.021202 model2 loss : 0.020972
[00:52:28.971] iteration 19625 : model1 loss : 0.020735 model2 loss : 0.019285
[00:52:29.618] iteration 19626 : model1 loss : 0.027706 model2 loss : 0.029916
[00:52:30.286] iteration 19627 : model1 loss : 0.017783 model2 loss : 0.020834
[00:52:30.934] iteration 19628 : model1 loss : 0.025913 model2 loss : 0.029615
[00:52:31.590] iteration 19629 : model1 loss : 0.016397 model2 loss : 0.016633
[00:52:32.243] iteration 19630 : model1 loss : 0.021227 model2 loss : 0.020277
[00:52:32.896] iteration 19631 : model1 loss : 0.015965 model2 loss : 0.015521
[00:52:33.549] iteration 19632 : model1 loss : 0.017577 model2 loss : 0.018148
[00:52:34.197] iteration 19633 : model1 loss : 0.020559 model2 loss : 0.018677
[00:52:34.856] iteration 19634 : model1 loss : 0.033942 model2 loss : 0.031344
[00:52:35.511] iteration 19635 : model1 loss : 0.018231 model2 loss : 0.016630
[00:52:36.163] iteration 19636 : model1 loss : 0.020036 model2 loss : 0.017383
[00:52:36.832] iteration 19637 : model1 loss : 0.017436 model2 loss : 0.021989
[00:52:37.482] iteration 19638 : model1 loss : 0.020888 model2 loss : 0.022856
[00:52:38.164] iteration 19639 : model1 loss : 0.015081 model2 loss : 0.015324
[00:52:38.819] iteration 19640 : model1 loss : 0.024012 model2 loss : 0.023750
[00:52:39.474] iteration 19641 : model1 loss : 0.020622 model2 loss : 0.020764
[00:52:40.135] iteration 19642 : model1 loss : 0.018529 model2 loss : 0.018341
[00:52:40.776] iteration 19643 : model1 loss : 0.020473 model2 loss : 0.020800
[00:52:41.441] iteration 19644 : model1 loss : 0.021843 model2 loss : 0.018269
[00:52:42.097] iteration 19645 : model1 loss : 0.021384 model2 loss : 0.021637
[00:52:42.757] iteration 19646 : model1 loss : 0.033579 model2 loss : 0.032778
[00:52:43.411] iteration 19647 : model1 loss : 0.027354 model2 loss : 0.026667
[00:52:44.068] iteration 19648 : model1 loss : 0.022311 model2 loss : 0.022444
[00:52:44.735] iteration 19649 : model1 loss : 0.025822 model2 loss : 0.023707
[00:52:45.378] iteration 19650 : model1 loss : 0.024834 model2 loss : 0.021470
[00:52:46.070] iteration 19651 : model1 loss : 0.017032 model2 loss : 0.018714
[00:52:46.742] iteration 19652 : model1 loss : 0.018008 model2 loss : 0.019766
[00:52:47.398] iteration 19653 : model1 loss : 0.017791 model2 loss : 0.018414
[00:52:48.058] iteration 19654 : model1 loss : 0.021993 model2 loss : 0.021153
[00:52:48.711] iteration 19655 : model1 loss : 0.026108 model2 loss : 0.029225
[00:52:49.365] iteration 19656 : model1 loss : 0.022515 model2 loss : 0.022194
[00:52:50.014] iteration 19657 : model1 loss : 0.019698 model2 loss : 0.021472
[00:52:50.675] iteration 19658 : model1 loss : 0.019357 model2 loss : 0.021858
[00:52:51.334] iteration 19659 : model1 loss : 0.015383 model2 loss : 0.017621
[00:52:51.993] iteration 19660 : model1 loss : 0.021491 model2 loss : 0.020870
[00:52:52.667] iteration 19661 : model1 loss : 0.022573 model2 loss : 0.019386
[00:52:53.319] iteration 19662 : model1 loss : 0.011560 model2 loss : 0.010854
[00:52:53.969] iteration 19663 : model1 loss : 0.014961 model2 loss : 0.015657
[00:52:54.637] iteration 19664 : model1 loss : 0.022605 model2 loss : 0.025268
[00:52:55.294] iteration 19665 : model1 loss : 0.016678 model2 loss : 0.017163
[00:52:55.948] iteration 19666 : model1 loss : 0.029278 model2 loss : 0.026386
[00:52:56.591] iteration 19667 : model1 loss : 0.015262 model2 loss : 0.013872
[00:52:57.258] iteration 19668 : model1 loss : 0.017648 model2 loss : 0.018573
[00:52:57.917] iteration 19669 : model1 loss : 0.021320 model2 loss : 0.021453
[00:52:58.579] iteration 19670 : model1 loss : 0.028488 model2 loss : 0.029712
[00:52:59.275] iteration 19671 : model1 loss : 0.028552 model2 loss : 0.027621
[00:52:59.930] iteration 19672 : model1 loss : 0.022685 model2 loss : 0.022406
[00:53:00.589] iteration 19673 : model1 loss : 0.020404 model2 loss : 0.020811
[00:53:01.230] iteration 19674 : model1 loss : 0.017697 model2 loss : 0.017299
[00:53:01.890] iteration 19675 : model1 loss : 0.021844 model2 loss : 0.021362
[00:53:02.557] iteration 19676 : model1 loss : 0.020523 model2 loss : 0.019915
[00:53:03.219] iteration 19677 : model1 loss : 0.022973 model2 loss : 0.023900
[00:53:03.872] iteration 19678 : model1 loss : 0.017525 model2 loss : 0.017657
[00:53:04.537] iteration 19679 : model1 loss : 0.023388 model2 loss : 0.024143
[00:53:05.192] iteration 19680 : model1 loss : 0.026966 model2 loss : 0.027819
[00:53:05.850] iteration 19681 : model1 loss : 0.024108 model2 loss : 0.022134
[00:53:06.502] iteration 19682 : model1 loss : 0.016272 model2 loss : 0.018919
[00:53:07.152] iteration 19683 : model1 loss : 0.019782 model2 loss : 0.020483
[00:53:07.808] iteration 19684 : model1 loss : 0.016628 model2 loss : 0.015543
[00:53:08.461] iteration 19685 : model1 loss : 0.022431 model2 loss : 0.022854
[00:53:09.127] iteration 19686 : model1 loss : 0.023571 model2 loss : 0.023726
[00:53:09.787] iteration 19687 : model1 loss : 0.023514 model2 loss : 0.026170
[00:53:10.444] iteration 19688 : model1 loss : 0.024468 model2 loss : 0.036636
[00:53:11.105] iteration 19689 : model1 loss : 0.024824 model2 loss : 0.025799
[00:53:11.767] iteration 19690 : model1 loss : 0.018547 model2 loss : 0.019716
[00:53:12.436] iteration 19691 : model1 loss : 0.028032 model2 loss : 0.032590
[00:53:13.088] iteration 19692 : model1 loss : 0.030389 model2 loss : 0.021462
[00:53:13.752] iteration 19693 : model1 loss : 0.046581 model2 loss : 0.032640
[00:53:14.421] iteration 19694 : model1 loss : 0.019238 model2 loss : 0.018893
[00:53:15.080] iteration 19695 : model1 loss : 0.023469 model2 loss : 0.023510
[00:53:15.747] iteration 19696 : model1 loss : 0.029880 model2 loss : 0.029105
[00:53:16.397] iteration 19697 : model1 loss : 0.024906 model2 loss : 0.023384
[00:53:17.050] iteration 19698 : model1 loss : 0.021479 model2 loss : 0.019260
[00:53:17.712] iteration 19699 : model1 loss : 0.024181 model2 loss : 0.025663
[00:53:18.367] iteration 19700 : model1 loss : 0.018069 model2 loss : 0.017486
[00:53:19.060] iteration 19701 : model1 loss : 0.018975 model2 loss : 0.022554
[00:53:19.711] iteration 19702 : model1 loss : 0.017243 model2 loss : 0.017731
[00:53:20.379] iteration 19703 : model1 loss : 0.019023 model2 loss : 0.020357
[00:53:21.042] iteration 19704 : model1 loss : 0.015583 model2 loss : 0.016916
[00:53:21.691] iteration 19705 : model1 loss : 0.025387 model2 loss : 0.027743
[00:53:22.354] iteration 19706 : model1 loss : 0.038437 model2 loss : 0.036912
[00:53:23.011] iteration 19707 : model1 loss : 0.019928 model2 loss : 0.020198
[00:53:23.663] iteration 19708 : model1 loss : 0.014935 model2 loss : 0.015660
[00:53:24.326] iteration 19709 : model1 loss : 0.023672 model2 loss : 0.024598
[00:53:24.990] iteration 19710 : model1 loss : 0.021469 model2 loss : 0.022870
[00:53:25.650] iteration 19711 : model1 loss : 0.016463 model2 loss : 0.015508
[00:53:26.310] iteration 19712 : model1 loss : 0.023412 model2 loss : 0.024524
[00:53:26.967] iteration 19713 : model1 loss : 0.025256 model2 loss : 0.023649
[00:53:27.626] iteration 19714 : model1 loss : 0.022897 model2 loss : 0.022033
[00:53:28.285] iteration 19715 : model1 loss : 0.020737 model2 loss : 0.022133
[00:53:28.943] iteration 19716 : model1 loss : 0.020698 model2 loss : 0.018239
[00:53:29.602] iteration 19717 : model1 loss : 0.025701 model2 loss : 0.026752
[00:53:30.253] iteration 19718 : model1 loss : 0.017264 model2 loss : 0.016092
[00:53:30.921] iteration 19719 : model1 loss : 0.020832 model2 loss : 0.020393
[00:53:31.588] iteration 19720 : model1 loss : 0.022777 model2 loss : 0.023893
[00:53:32.251] iteration 19721 : model1 loss : 0.016540 model2 loss : 0.016630
[00:53:32.911] iteration 19722 : model1 loss : 0.022369 model2 loss : 0.020234
[00:53:33.572] iteration 19723 : model1 loss : 0.015653 model2 loss : 0.015115
[00:53:34.222] iteration 19724 : model1 loss : 0.017151 model2 loss : 0.017050
[00:53:34.882] iteration 19725 : model1 loss : 0.019829 model2 loss : 0.019820
[00:53:35.541] iteration 19726 : model1 loss : 0.025436 model2 loss : 0.024063
[00:53:36.190] iteration 19727 : model1 loss : 0.020362 model2 loss : 0.019363
[00:53:36.839] iteration 19728 : model1 loss : 0.024986 model2 loss : 0.026153
[00:53:37.506] iteration 19729 : model1 loss : 0.025735 model2 loss : 0.026833
[00:53:38.164] iteration 19730 : model1 loss : 0.020961 model2 loss : 0.022993
[00:53:38.832] iteration 19731 : model1 loss : 0.025869 model2 loss : 0.029573
[00:53:39.490] iteration 19732 : model1 loss : 0.017372 model2 loss : 0.018987
[00:53:40.160] iteration 19733 : model1 loss : 0.018653 model2 loss : 0.017702
[00:53:40.825] iteration 19734 : model1 loss : 0.031147 model2 loss : 0.028170
[00:53:41.494] iteration 19735 : model1 loss : 0.027678 model2 loss : 0.029737
[00:53:42.156] iteration 19736 : model1 loss : 0.021375 model2 loss : 0.021415
[00:53:42.821] iteration 19737 : model1 loss : 0.022272 model2 loss : 0.023726
[00:53:43.473] iteration 19738 : model1 loss : 0.019150 model2 loss : 0.018420
[00:53:44.138] iteration 19739 : model1 loss : 0.022149 model2 loss : 0.020906
[00:53:44.785] iteration 19740 : model1 loss : 0.018746 model2 loss : 0.019829
[00:53:45.445] iteration 19741 : model1 loss : 0.026742 model2 loss : 0.025760
[00:53:46.105] iteration 19742 : model1 loss : 0.019508 model2 loss : 0.019739
[00:53:46.757] iteration 19743 : model1 loss : 0.017533 model2 loss : 0.016979
[00:53:47.414] iteration 19744 : model1 loss : 0.019773 model2 loss : 0.019668
[00:53:48.077] iteration 19745 : model1 loss : 0.142302 model2 loss : 0.142810
[00:53:48.733] iteration 19746 : model1 loss : 0.015931 model2 loss : 0.016856
[00:53:49.388] iteration 19747 : model1 loss : 0.017522 model2 loss : 0.018382
[00:53:50.049] iteration 19748 : model1 loss : 0.028021 model2 loss : 0.026736
[00:53:50.709] iteration 19749 : model1 loss : 0.018620 model2 loss : 0.021550
[00:53:51.368] iteration 19750 : model1 loss : 0.022984 model2 loss : 0.024211
[00:53:52.068] iteration 19751 : model1 loss : 0.029067 model2 loss : 0.029818
[00:53:52.757] iteration 19752 : model1 loss : 0.021617 model2 loss : 0.022939
[00:53:53.422] iteration 19753 : model1 loss : 0.026567 model2 loss : 0.024168
[00:53:54.069] iteration 19754 : model1 loss : 0.026155 model2 loss : 0.026071
[00:53:54.729] iteration 19755 : model1 loss : 0.017542 model2 loss : 0.018542
[00:53:55.386] iteration 19756 : model1 loss : 0.028485 model2 loss : 0.028124
[00:53:56.047] iteration 19757 : model1 loss : 0.018942 model2 loss : 0.019423
[00:53:56.712] iteration 19758 : model1 loss : 0.145968 model2 loss : 0.141864
[00:53:57.363] iteration 19759 : model1 loss : 0.021536 model2 loss : 0.022686
[00:53:58.013] iteration 19760 : model1 loss : 0.019517 model2 loss : 0.018891
[00:53:58.675] iteration 19761 : model1 loss : 0.016603 model2 loss : 0.018049
[00:53:59.350] iteration 19762 : model1 loss : 0.030238 model2 loss : 0.028235
[00:54:00.009] iteration 19763 : model1 loss : 0.029383 model2 loss : 0.036961
[00:54:00.679] iteration 19764 : model1 loss : 0.028647 model2 loss : 0.028332
[00:54:01.342] iteration 19765 : model1 loss : 0.021015 model2 loss : 0.023990
[00:54:02.003] iteration 19766 : model1 loss : 0.063756 model2 loss : 0.037279
[00:54:02.660] iteration 19767 : model1 loss : 0.024114 model2 loss : 0.025041
[00:54:03.337] iteration 19768 : model1 loss : 0.029138 model2 loss : 0.028167
[00:54:04.006] iteration 19769 : model1 loss : 0.019352 model2 loss : 0.021543
[00:54:04.667] iteration 19770 : model1 loss : 0.020170 model2 loss : 0.022195
[00:54:05.326] iteration 19771 : model1 loss : 0.026081 model2 loss : 0.023443
[00:54:05.971] iteration 19772 : model1 loss : 0.016770 model2 loss : 0.016958
[00:54:06.619] iteration 19773 : model1 loss : 0.016426 model2 loss : 0.016257
[00:54:07.271] iteration 19774 : model1 loss : 0.017599 model2 loss : 0.016388
[00:54:07.928] iteration 19775 : model1 loss : 0.015637 model2 loss : 0.015565
[00:54:08.590] iteration 19776 : model1 loss : 0.025063 model2 loss : 0.023195
[00:54:09.253] iteration 19777 : model1 loss : 0.019750 model2 loss : 0.021166
[00:54:09.911] iteration 19778 : model1 loss : 0.034294 model2 loss : 0.035329
[00:54:10.553] iteration 19779 : model1 loss : 0.018066 model2 loss : 0.018748
[00:54:11.205] iteration 19780 : model1 loss : 0.017942 model2 loss : 0.018455
[00:54:11.860] iteration 19781 : model1 loss : 0.138288 model2 loss : 0.137232
[00:54:12.516] iteration 19782 : model1 loss : 0.028513 model2 loss : 0.031030
[00:54:13.174] iteration 19783 : model1 loss : 0.022354 model2 loss : 0.021478
[00:54:13.835] iteration 19784 : model1 loss : 0.026169 model2 loss : 0.030017
[00:54:14.517] iteration 19785 : model1 loss : 0.025870 model2 loss : 0.026257
[00:54:15.191] iteration 19786 : model1 loss : 0.019351 model2 loss : 0.019012
[00:54:15.853] iteration 19787 : model1 loss : 0.017361 model2 loss : 0.020001
[00:54:16.516] iteration 19788 : model1 loss : 0.015525 model2 loss : 0.015821
[00:54:17.178] iteration 19789 : model1 loss : 0.026894 model2 loss : 0.024960
[00:54:17.832] iteration 19790 : model1 loss : 0.023356 model2 loss : 0.021328
[00:54:18.505] iteration 19791 : model1 loss : 0.019132 model2 loss : 0.018655
[00:54:19.161] iteration 19792 : model1 loss : 0.025504 model2 loss : 0.022031
[00:54:19.827] iteration 19793 : model1 loss : 0.018226 model2 loss : 0.020419
[00:54:20.486] iteration 19794 : model1 loss : 0.024309 model2 loss : 0.022924
[00:54:21.148] iteration 19795 : model1 loss : 0.021443 model2 loss : 0.020568
[00:54:21.806] iteration 19796 : model1 loss : 0.023754 model2 loss : 0.020653
[00:54:22.487] iteration 19797 : model1 loss : 0.016219 model2 loss : 0.018369
[00:54:23.135] iteration 19798 : model1 loss : 0.029787 model2 loss : 0.027167
[00:54:23.807] iteration 19799 : model1 loss : 0.025582 model2 loss : 0.023996
[00:54:24.466] iteration 19800 : model1 loss : 0.019376 model2 loss : 0.020822
[00:54:42.282] iteration 19800 : model1_mean_dice : 0.877652 model1_mean_hd95 : 6.306816
[00:55:00.146] iteration 19800 : model2_mean_dice : 0.874687 model2_mean_hd95 : 4.796023
[00:55:00.812] iteration 19801 : model1 loss : 0.022380 model2 loss : 0.024177
[00:55:01.460] iteration 19802 : model1 loss : 0.017069 model2 loss : 0.017675
[00:55:02.117] iteration 19803 : model1 loss : 0.029517 model2 loss : 0.028532
[00:55:02.784] iteration 19804 : model1 loss : 0.028416 model2 loss : 0.026143
[00:55:03.444] iteration 19805 : model1 loss : 0.018417 model2 loss : 0.018111
[00:55:04.089] iteration 19806 : model1 loss : 0.023013 model2 loss : 0.023970
[00:55:04.750] iteration 19807 : model1 loss : 0.027151 model2 loss : 0.023950
[00:55:05.397] iteration 19808 : model1 loss : 0.019766 model2 loss : 0.021048
[00:55:06.057] iteration 19809 : model1 loss : 0.015968 model2 loss : 0.018179
[00:55:06.703] iteration 19810 : model1 loss : 0.027501 model2 loss : 0.027348
[00:55:07.351] iteration 19811 : model1 loss : 0.020592 model2 loss : 0.021712
[00:55:08.022] iteration 19812 : model1 loss : 0.020125 model2 loss : 0.021262
[00:55:08.683] iteration 19813 : model1 loss : 0.021284 model2 loss : 0.020863
[00:55:09.347] iteration 19814 : model1 loss : 0.020310 model2 loss : 0.019053
[00:55:10.003] iteration 19815 : model1 loss : 0.027113 model2 loss : 0.027143
[00:55:10.656] iteration 19816 : model1 loss : 0.023903 model2 loss : 0.023786
[00:55:11.314] iteration 19817 : model1 loss : 0.036550 model2 loss : 0.083576
[00:55:11.971] iteration 19818 : model1 loss : 0.024285 model2 loss : 0.024510
[00:55:12.648] iteration 19819 : model1 loss : 0.022663 model2 loss : 0.023864
[00:55:13.312] iteration 19820 : model1 loss : 0.028017 model2 loss : 0.023835
[00:55:13.963] iteration 19821 : model1 loss : 0.022411 model2 loss : 0.024785
[00:55:14.622] iteration 19822 : model1 loss : 0.015131 model2 loss : 0.014789
[00:55:15.297] iteration 19823 : model1 loss : 0.015195 model2 loss : 0.014497
[00:55:15.960] iteration 19824 : model1 loss : 0.020743 model2 loss : 0.021927
[00:55:16.625] iteration 19825 : model1 loss : 0.024263 model2 loss : 0.024590
[00:55:17.277] iteration 19826 : model1 loss : 0.017333 model2 loss : 0.017387
[00:55:17.936] iteration 19827 : model1 loss : 0.019827 model2 loss : 0.019005
[00:55:18.587] iteration 19828 : model1 loss : 0.017762 model2 loss : 0.017489
[00:55:19.257] iteration 19829 : model1 loss : 0.022393 model2 loss : 0.021805
[00:55:19.928] iteration 19830 : model1 loss : 0.023069 model2 loss : 0.023674
[00:55:20.570] iteration 19831 : model1 loss : 0.021910 model2 loss : 0.023447
[00:55:21.229] iteration 19832 : model1 loss : 0.017449 model2 loss : 0.018078
[00:55:21.891] iteration 19833 : model1 loss : 0.025288 model2 loss : 0.025712
[00:55:22.579] iteration 19834 : model1 loss : 0.022460 model2 loss : 0.021018
[00:55:23.221] iteration 19835 : model1 loss : 0.020203 model2 loss : 0.019200
[00:55:23.874] iteration 19836 : model1 loss : 0.021479 model2 loss : 0.019387
[00:55:24.530] iteration 19837 : model1 loss : 0.017742 model2 loss : 0.016797
[00:55:25.183] iteration 19838 : model1 loss : 0.019763 model2 loss : 0.021787
[00:55:25.826] iteration 19839 : model1 loss : 0.014348 model2 loss : 0.015193
[00:55:26.497] iteration 19840 : model1 loss : 0.024585 model2 loss : 0.039647
[00:55:27.153] iteration 19841 : model1 loss : 0.020603 model2 loss : 0.020098
[00:55:27.807] iteration 19842 : model1 loss : 0.022238 model2 loss : 0.024446
[00:55:28.466] iteration 19843 : model1 loss : 0.017015 model2 loss : 0.017754
[00:55:29.135] iteration 19844 : model1 loss : 0.017742 model2 loss : 0.017174
[00:55:29.800] iteration 19845 : model1 loss : 0.103953 model2 loss : 0.088894
[00:55:30.455] iteration 19846 : model1 loss : 0.058627 model2 loss : 0.039622
[00:55:31.117] iteration 19847 : model1 loss : 0.019237 model2 loss : 0.019298
[00:55:31.767] iteration 19848 : model1 loss : 0.027879 model2 loss : 0.026492
[00:55:32.431] iteration 19849 : model1 loss : 0.017100 model2 loss : 0.018283
[00:55:33.086] iteration 19850 : model1 loss : 0.024562 model2 loss : 0.024654
[00:55:33.776] iteration 19851 : model1 loss : 0.024826 model2 loss : 0.022651
[00:55:34.443] iteration 19852 : model1 loss : 0.033804 model2 loss : 0.025973
[00:55:35.109] iteration 19853 : model1 loss : 0.019841 model2 loss : 0.018468
[00:55:35.762] iteration 19854 : model1 loss : 0.020712 model2 loss : 0.021525
[00:55:36.424] iteration 19855 : model1 loss : 0.021181 model2 loss : 0.022478
[00:55:37.082] iteration 19856 : model1 loss : 0.022132 model2 loss : 0.023979
[00:55:37.751] iteration 19857 : model1 loss : 0.020725 model2 loss : 0.021342
[00:55:38.414] iteration 19858 : model1 loss : 0.017463 model2 loss : 0.016758
[00:55:39.065] iteration 19859 : model1 loss : 0.018293 model2 loss : 0.021784
[00:55:39.714] iteration 19860 : model1 loss : 0.017979 model2 loss : 0.017362
[00:55:40.381] iteration 19861 : model1 loss : 0.018197 model2 loss : 0.018495
[00:55:41.049] iteration 19862 : model1 loss : 0.019796 model2 loss : 0.019724
[00:55:41.695] iteration 19863 : model1 loss : 0.020368 model2 loss : 0.023561
[00:55:42.360] iteration 19864 : model1 loss : 0.023812 model2 loss : 0.023311
[00:55:43.020] iteration 19865 : model1 loss : 0.016111 model2 loss : 0.017095
[00:55:43.680] iteration 19866 : model1 loss : 0.019667 model2 loss : 0.021035
[00:55:44.336] iteration 19867 : model1 loss : 0.020831 model2 loss : 0.021883
[00:55:45.003] iteration 19868 : model1 loss : 0.018375 model2 loss : 0.017034
[00:55:45.661] iteration 19869 : model1 loss : 0.020171 model2 loss : 0.021396
[00:55:46.325] iteration 19870 : model1 loss : 0.021494 model2 loss : 0.021496
[00:55:46.986] iteration 19871 : model1 loss : 0.029196 model2 loss : 0.066264
[00:55:47.643] iteration 19872 : model1 loss : 0.022467 model2 loss : 0.022359
[00:55:48.308] iteration 19873 : model1 loss : 0.022249 model2 loss : 0.020640
[00:55:48.963] iteration 19874 : model1 loss : 0.027025 model2 loss : 0.027108
[00:55:49.627] iteration 19875 : model1 loss : 0.023879 model2 loss : 0.023328
[00:55:50.308] iteration 19876 : model1 loss : 0.026394 model2 loss : 0.020362
[00:55:50.967] iteration 19877 : model1 loss : 0.013169 model2 loss : 0.015648
[00:55:51.623] iteration 19878 : model1 loss : 0.020897 model2 loss : 0.022678
[00:55:52.288] iteration 19879 : model1 loss : 0.023055 model2 loss : 0.023468
[00:55:52.946] iteration 19880 : model1 loss : 0.024043 model2 loss : 0.025216
[00:55:53.604] iteration 19881 : model1 loss : 0.016294 model2 loss : 0.016376
[00:55:54.271] iteration 19882 : model1 loss : 0.044709 model2 loss : 0.056349
[00:55:54.933] iteration 19883 : model1 loss : 0.013657 model2 loss : 0.014911
[00:55:55.593] iteration 19884 : model1 loss : 0.018475 model2 loss : 0.017446
[00:55:56.254] iteration 19885 : model1 loss : 0.020800 model2 loss : 0.019856
[00:55:56.908] iteration 19886 : model1 loss : 0.030012 model2 loss : 0.034811
[00:55:57.564] iteration 19887 : model1 loss : 0.020477 model2 loss : 0.024086
[00:55:58.246] iteration 19888 : model1 loss : 0.030798 model2 loss : 0.020532
[00:55:58.913] iteration 19889 : model1 loss : 0.031544 model2 loss : 0.032366
[00:55:59.582] iteration 19890 : model1 loss : 0.018983 model2 loss : 0.019442
[00:56:00.249] iteration 19891 : model1 loss : 0.020145 model2 loss : 0.021761
[00:56:00.902] iteration 19892 : model1 loss : 0.020907 model2 loss : 0.020213
[00:56:01.563] iteration 19893 : model1 loss : 0.019678 model2 loss : 0.021786
[00:56:02.225] iteration 19894 : model1 loss : 0.023502 model2 loss : 0.022773
[00:56:02.880] iteration 19895 : model1 loss : 0.021734 model2 loss : 0.024391
[00:56:03.527] iteration 19896 : model1 loss : 0.021105 model2 loss : 0.022460
[00:56:04.182] iteration 19897 : model1 loss : 0.020934 model2 loss : 0.019457
[00:56:04.855] iteration 19898 : model1 loss : 0.028258 model2 loss : 0.026130
[00:56:05.517] iteration 19899 : model1 loss : 0.027827 model2 loss : 0.036734
[00:56:06.173] iteration 19900 : model1 loss : 0.027371 model2 loss : 0.027207
[00:56:06.851] iteration 19901 : model1 loss : 0.022539 model2 loss : 0.027460
[00:56:07.505] iteration 19902 : model1 loss : 0.021741 model2 loss : 0.019748
[00:56:08.165] iteration 19903 : model1 loss : 0.019006 model2 loss : 0.019597
[00:56:08.818] iteration 19904 : model1 loss : 0.019086 model2 loss : 0.022524
[00:56:09.500] iteration 19905 : model1 loss : 0.019645 model2 loss : 0.020206
[00:56:10.154] iteration 19906 : model1 loss : 0.017749 model2 loss : 0.019309
[00:56:10.829] iteration 19907 : model1 loss : 0.023015 model2 loss : 0.021017
[00:56:11.491] iteration 19908 : model1 loss : 0.020626 model2 loss : 0.020972
[00:56:12.162] iteration 19909 : model1 loss : 0.020968 model2 loss : 0.023535
[00:56:12.819] iteration 19910 : model1 loss : 0.022645 model2 loss : 0.021256
[00:56:13.476] iteration 19911 : model1 loss : 0.022173 model2 loss : 0.026538
[00:56:14.135] iteration 19912 : model1 loss : 0.020594 model2 loss : 0.023244
[00:56:14.788] iteration 19913 : model1 loss : 0.021294 model2 loss : 0.022626
[00:56:15.462] iteration 19914 : model1 loss : 0.021955 model2 loss : 0.020931
[00:56:16.140] iteration 19915 : model1 loss : 0.017656 model2 loss : 0.019761
[00:56:16.789] iteration 19916 : model1 loss : 0.018560 model2 loss : 0.020618
[00:56:17.449] iteration 19917 : model1 loss : 0.021723 model2 loss : 0.020934
[00:56:18.096] iteration 19918 : model1 loss : 0.016879 model2 loss : 0.017944
[00:56:18.763] iteration 19919 : model1 loss : 0.019737 model2 loss : 0.016647
[00:56:19.428] iteration 19920 : model1 loss : 0.014952 model2 loss : 0.017659
[00:56:20.091] iteration 19921 : model1 loss : 0.021941 model2 loss : 0.022456
[00:56:20.759] iteration 19922 : model1 loss : 0.022036 model2 loss : 0.023889
[00:56:21.418] iteration 19923 : model1 loss : 0.017845 model2 loss : 0.018717
[00:56:22.071] iteration 19924 : model1 loss : 0.025587 model2 loss : 0.023407
[00:56:22.739] iteration 19925 : model1 loss : 0.022335 model2 loss : 0.020087
[00:56:23.389] iteration 19926 : model1 loss : 0.023531 model2 loss : 0.025918
[00:56:24.060] iteration 19927 : model1 loss : 0.017238 model2 loss : 0.018852
[00:56:24.725] iteration 19928 : model1 loss : 0.022911 model2 loss : 0.022888
[00:56:25.388] iteration 19929 : model1 loss : 0.017655 model2 loss : 0.016690
[00:56:26.041] iteration 19930 : model1 loss : 0.019461 model2 loss : 0.019699
[00:56:26.703] iteration 19931 : model1 loss : 0.015510 model2 loss : 0.016439
[00:56:27.364] iteration 19932 : model1 loss : 0.024046 model2 loss : 0.023531
[00:56:28.021] iteration 19933 : model1 loss : 0.020909 model2 loss : 0.022339
[00:56:28.682] iteration 19934 : model1 loss : 0.027349 model2 loss : 0.024820
[00:56:29.354] iteration 19935 : model1 loss : 0.032191 model2 loss : 0.030539
[00:56:30.009] iteration 19936 : model1 loss : 0.015771 model2 loss : 0.017364
[00:56:30.659] iteration 19937 : model1 loss : 0.027849 model2 loss : 0.028002
[00:56:31.315] iteration 19938 : model1 loss : 0.023059 model2 loss : 0.022022
[00:56:31.973] iteration 19939 : model1 loss : 0.021760 model2 loss : 0.021666
[00:56:32.660] iteration 19940 : model1 loss : 0.020202 model2 loss : 0.019981
[00:56:33.310] iteration 19941 : model1 loss : 0.029273 model2 loss : 0.026052
[00:56:33.971] iteration 19942 : model1 loss : 0.019357 model2 loss : 0.017514
[00:56:34.631] iteration 19943 : model1 loss : 0.035157 model2 loss : 0.031681
[00:56:35.279] iteration 19944 : model1 loss : 0.022794 model2 loss : 0.021656
[00:56:35.938] iteration 19945 : model1 loss : 0.016996 model2 loss : 0.015904
[00:56:36.594] iteration 19946 : model1 loss : 0.024427 model2 loss : 0.024675
[00:56:37.251] iteration 19947 : model1 loss : 0.018121 model2 loss : 0.021579
[00:56:37.897] iteration 19948 : model1 loss : 0.039153 model2 loss : 0.030796
[00:56:38.573] iteration 19949 : model1 loss : 0.024729 model2 loss : 0.025706
[00:56:39.237] iteration 19950 : model1 loss : 0.020534 model2 loss : 0.018837
[00:56:39.934] iteration 19951 : model1 loss : 0.020819 model2 loss : 0.020967
[00:56:40.595] iteration 19952 : model1 loss : 0.025545 model2 loss : 0.023827
[00:56:41.253] iteration 19953 : model1 loss : 0.019208 model2 loss : 0.018174
[00:56:41.921] iteration 19954 : model1 loss : 0.022918 model2 loss : 0.022900
[00:56:42.605] iteration 19955 : model1 loss : 0.027332 model2 loss : 0.026323
[00:56:43.291] iteration 19956 : model1 loss : 0.016097 model2 loss : 0.014628
[00:56:44.004] iteration 19957 : model1 loss : 0.056477 model2 loss : 0.061954
[00:56:44.692] iteration 19958 : model1 loss : 0.020989 model2 loss : 0.019526
[00:56:45.357] iteration 19959 : model1 loss : 0.044332 model2 loss : 0.042499
[00:56:46.007] iteration 19960 : model1 loss : 0.022328 model2 loss : 0.024355
[00:56:46.674] iteration 19961 : model1 loss : 0.026121 model2 loss : 0.027926
[00:56:47.331] iteration 19962 : model1 loss : 0.015815 model2 loss : 0.016356
[00:56:48.001] iteration 19963 : model1 loss : 0.024295 model2 loss : 0.026168
[00:56:48.669] iteration 19964 : model1 loss : 0.016763 model2 loss : 0.017451
[00:56:49.339] iteration 19965 : model1 loss : 0.021580 model2 loss : 0.023095
[00:56:49.991] iteration 19966 : model1 loss : 0.020520 model2 loss : 0.021981
[00:56:50.651] iteration 19967 : model1 loss : 0.018125 model2 loss : 0.016806
[00:56:51.327] iteration 19968 : model1 loss : 0.029163 model2 loss : 0.028057
[00:56:51.978] iteration 19969 : model1 loss : 0.025654 model2 loss : 0.024923
[00:56:52.641] iteration 19970 : model1 loss : 0.017011 model2 loss : 0.017440
[00:56:53.298] iteration 19971 : model1 loss : 0.018368 model2 loss : 0.017703
[00:56:53.951] iteration 19972 : model1 loss : 0.018777 model2 loss : 0.016617
[00:56:54.619] iteration 19973 : model1 loss : 0.018951 model2 loss : 0.017496
[00:56:55.280] iteration 19974 : model1 loss : 0.020332 model2 loss : 0.023090
[00:56:55.938] iteration 19975 : model1 loss : 0.019081 model2 loss : 0.017521
[00:56:56.600] iteration 19976 : model1 loss : 0.022900 model2 loss : 0.024075
[00:56:57.259] iteration 19977 : model1 loss : 0.020781 model2 loss : 0.022737
[00:56:57.921] iteration 19978 : model1 loss : 0.013260 model2 loss : 0.016794
[00:56:58.588] iteration 19979 : model1 loss : 0.017530 model2 loss : 0.017477
[00:56:59.256] iteration 19980 : model1 loss : 0.022989 model2 loss : 0.021672
[00:56:59.904] iteration 19981 : model1 loss : 0.021108 model2 loss : 0.020680
[00:57:00.555] iteration 19982 : model1 loss : 0.017691 model2 loss : 0.017771
[00:57:01.219] iteration 19983 : model1 loss : 0.023632 model2 loss : 0.024732
[00:57:01.873] iteration 19984 : model1 loss : 0.018332 model2 loss : 0.018944
[00:57:02.539] iteration 19985 : model1 loss : 0.041268 model2 loss : 0.052598
[00:57:03.200] iteration 19986 : model1 loss : 0.026193 model2 loss : 0.025461
[00:57:03.854] iteration 19987 : model1 loss : 0.019010 model2 loss : 0.018726
[00:57:04.507] iteration 19988 : model1 loss : 0.023935 model2 loss : 0.026122
[00:57:05.169] iteration 19989 : model1 loss : 0.021307 model2 loss : 0.020808
[00:57:05.820] iteration 19990 : model1 loss : 0.076444 model2 loss : 0.095674
[00:57:06.478] iteration 19991 : model1 loss : 0.037579 model2 loss : 0.044113
[00:57:07.135] iteration 19992 : model1 loss : 0.021757 model2 loss : 0.026163
[00:57:07.803] iteration 19993 : model1 loss : 0.018952 model2 loss : 0.021024
[00:57:08.457] iteration 19994 : model1 loss : 0.021306 model2 loss : 0.020700
[00:57:09.125] iteration 19995 : model1 loss : 0.026481 model2 loss : 0.029756
[00:57:09.782] iteration 19996 : model1 loss : 0.023288 model2 loss : 0.022512
[00:57:10.441] iteration 19997 : model1 loss : 0.023682 model2 loss : 0.022619
[00:57:11.102] iteration 19998 : model1 loss : 0.021857 model2 loss : 0.022162
[00:57:11.756] iteration 19999 : model1 loss : 0.021458 model2 loss : 0.022543
[00:57:12.428] iteration 20000 : model1 loss : 0.020122 model2 loss : 0.020024
[00:57:30.281] iteration 20000 : model1_mean_dice : 0.875158 model1_mean_hd95 : 6.206479
[00:57:47.781] iteration 20000 : model2_mean_dice : 0.864692 model2_mean_hd95 : 5.813012
[00:57:48.455] iteration 20001 : model1 loss : 0.017454 model2 loss : 0.018874
[00:57:49.106] iteration 20002 : model1 loss : 0.027726 model2 loss : 0.033597
[00:57:49.759] iteration 20003 : model1 loss : 0.023122 model2 loss : 0.025501
[00:57:50.403] iteration 20004 : model1 loss : 0.019706 model2 loss : 0.020202
[00:57:51.063] iteration 20005 : model1 loss : 0.030339 model2 loss : 0.036762
[00:57:51.718] iteration 20006 : model1 loss : 0.027770 model2 loss : 0.027299
[00:57:52.396] iteration 20007 : model1 loss : 0.027478 model2 loss : 0.025705
[00:57:53.049] iteration 20008 : model1 loss : 0.017370 model2 loss : 0.017104
[00:57:53.710] iteration 20009 : model1 loss : 0.023550 model2 loss : 0.022507
[00:57:54.376] iteration 20010 : model1 loss : 0.018833 model2 loss : 0.017477
[00:57:55.056] iteration 20011 : model1 loss : 0.044255 model2 loss : 0.037206
[00:57:55.723] iteration 20012 : model1 loss : 0.018303 model2 loss : 0.018087
[00:57:56.394] iteration 20013 : model1 loss : 0.031115 model2 loss : 0.028620
[00:57:57.099] iteration 20014 : model1 loss : 0.017541 model2 loss : 0.016822
[00:57:57.770] iteration 20015 : model1 loss : 0.018012 model2 loss : 0.018396
[00:57:58.439] iteration 20016 : model1 loss : 0.018696 model2 loss : 0.020538
[00:57:59.112] iteration 20017 : model1 loss : 0.022793 model2 loss : 0.022769
[00:57:59.769] iteration 20018 : model1 loss : 0.021297 model2 loss : 0.022706
[00:58:00.423] iteration 20019 : model1 loss : 0.034114 model2 loss : 0.039338
[00:58:01.076] iteration 20020 : model1 loss : 0.016729 model2 loss : 0.015877
[00:58:01.741] iteration 20021 : model1 loss : 0.022679 model2 loss : 0.020102
[00:58:02.389] iteration 20022 : model1 loss : 0.020211 model2 loss : 0.019624
[00:58:03.042] iteration 20023 : model1 loss : 0.021576 model2 loss : 0.023551
[00:58:03.691] iteration 20024 : model1 loss : 0.018464 model2 loss : 0.019576
[00:58:04.371] iteration 20025 : model1 loss : 0.021171 model2 loss : 0.018873
[00:58:05.023] iteration 20026 : model1 loss : 0.016565 model2 loss : 0.018679
[00:58:05.672] iteration 20027 : model1 loss : 0.022687 model2 loss : 0.022608
[00:58:06.317] iteration 20028 : model1 loss : 0.023788 model2 loss : 0.026205
[00:58:06.972] iteration 20029 : model1 loss : 0.021184 model2 loss : 0.023081
[00:58:07.632] iteration 20030 : model1 loss : 0.020152 model2 loss : 0.020948
[00:58:08.286] iteration 20031 : model1 loss : 0.018433 model2 loss : 0.019486
[00:58:08.945] iteration 20032 : model1 loss : 0.018131 model2 loss : 0.018554
[00:58:09.594] iteration 20033 : model1 loss : 0.030261 model2 loss : 0.026850
[00:58:10.243] iteration 20034 : model1 loss : 0.023918 model2 loss : 0.025050
[00:58:10.908] iteration 20035 : model1 loss : 0.151053 model2 loss : 0.147595
[00:58:11.559] iteration 20036 : model1 loss : 0.016405 model2 loss : 0.018202
[00:58:12.212] iteration 20037 : model1 loss : 0.016204 model2 loss : 0.018052
[00:58:12.864] iteration 20038 : model1 loss : 0.016396 model2 loss : 0.017166
[00:58:13.534] iteration 20039 : model1 loss : 0.019803 model2 loss : 0.020921
[00:58:14.187] iteration 20040 : model1 loss : 0.022602 model2 loss : 0.021980
[00:58:14.835] iteration 20041 : model1 loss : 0.018692 model2 loss : 0.017132
[00:58:15.491] iteration 20042 : model1 loss : 0.029273 model2 loss : 0.023866
[00:58:16.164] iteration 20043 : model1 loss : 0.025833 model2 loss : 0.022908
[00:58:16.842] iteration 20044 : model1 loss : 0.022156 model2 loss : 0.026005
[00:58:17.526] iteration 20045 : model1 loss : 0.021557 model2 loss : 0.020311
[00:58:18.191] iteration 20046 : model1 loss : 0.028004 model2 loss : 0.027612
[00:58:18.854] iteration 20047 : model1 loss : 0.022014 model2 loss : 0.023304
[00:58:19.496] iteration 20048 : model1 loss : 0.015754 model2 loss : 0.015856
[00:58:20.158] iteration 20049 : model1 loss : 0.019197 model2 loss : 0.020431
[00:58:20.809] iteration 20050 : model1 loss : 0.023672 model2 loss : 0.021879
[00:58:21.505] iteration 20051 : model1 loss : 0.022012 model2 loss : 0.023259
[00:58:22.182] iteration 20052 : model1 loss : 0.019282 model2 loss : 0.017435
[00:58:22.832] iteration 20053 : model1 loss : 0.015787 model2 loss : 0.018015
[00:58:23.497] iteration 20054 : model1 loss : 0.020597 model2 loss : 0.021718
[00:58:24.164] iteration 20055 : model1 loss : 0.020057 model2 loss : 0.020336
[00:58:24.821] iteration 20056 : model1 loss : 0.018427 model2 loss : 0.017556
[00:58:25.480] iteration 20057 : model1 loss : 0.017477 model2 loss : 0.018181
[00:58:26.124] iteration 20058 : model1 loss : 0.029696 model2 loss : 0.019047
[00:58:26.771] iteration 20059 : model1 loss : 0.014885 model2 loss : 0.013918
[00:58:27.440] iteration 20060 : model1 loss : 0.020733 model2 loss : 0.020349
[00:58:28.085] iteration 20061 : model1 loss : 0.022108 model2 loss : 0.020205
[00:58:28.742] iteration 20062 : model1 loss : 0.021120 model2 loss : 0.020640
[00:58:29.395] iteration 20063 : model1 loss : 0.026228 model2 loss : 0.024587
[00:58:30.046] iteration 20064 : model1 loss : 0.015881 model2 loss : 0.015927
[00:58:30.707] iteration 20065 : model1 loss : 0.016549 model2 loss : 0.018104
[00:58:31.371] iteration 20066 : model1 loss : 0.022441 model2 loss : 0.024823
[00:58:32.025] iteration 20067 : model1 loss : 0.016792 model2 loss : 0.017587
[00:58:32.675] iteration 20068 : model1 loss : 0.016243 model2 loss : 0.015764
[00:58:33.327] iteration 20069 : model1 loss : 0.018361 model2 loss : 0.019006
[00:58:33.990] iteration 20070 : model1 loss : 0.016691 model2 loss : 0.016697
[00:58:34.650] iteration 20071 : model1 loss : 0.019216 model2 loss : 0.017122
[00:58:35.321] iteration 20072 : model1 loss : 0.022875 model2 loss : 0.026324
[00:58:35.973] iteration 20073 : model1 loss : 0.031890 model2 loss : 0.032585
[00:58:36.628] iteration 20074 : model1 loss : 0.019407 model2 loss : 0.019741
[00:58:37.283] iteration 20075 : model1 loss : 0.047449 model2 loss : 0.039743
[00:58:37.931] iteration 20076 : model1 loss : 0.025570 model2 loss : 0.023467
[00:58:38.595] iteration 20077 : model1 loss : 0.019257 model2 loss : 0.021052
[00:58:39.253] iteration 20078 : model1 loss : 0.025652 model2 loss : 0.020503
[00:58:39.899] iteration 20079 : model1 loss : 0.051623 model2 loss : 0.047090
[00:58:40.567] iteration 20080 : model1 loss : 0.015701 model2 loss : 0.017321
[00:58:41.242] iteration 20081 : model1 loss : 0.016748 model2 loss : 0.018932
[00:58:41.909] iteration 20082 : model1 loss : 0.024311 model2 loss : 0.025662
[00:58:42.558] iteration 20083 : model1 loss : 0.026818 model2 loss : 0.029302
[00:58:43.221] iteration 20084 : model1 loss : 0.031561 model2 loss : 0.031407
[00:58:43.885] iteration 20085 : model1 loss : 0.023217 model2 loss : 0.022719
[00:58:44.537] iteration 20086 : model1 loss : 0.041091 model2 loss : 0.028557
[00:58:45.202] iteration 20087 : model1 loss : 0.034245 model2 loss : 0.035483
[00:58:45.854] iteration 20088 : model1 loss : 0.022691 model2 loss : 0.020653
[00:58:46.532] iteration 20089 : model1 loss : 0.016175 model2 loss : 0.016471
[00:58:47.183] iteration 20090 : model1 loss : 0.016450 model2 loss : 0.016759
[00:58:47.842] iteration 20091 : model1 loss : 0.022673 model2 loss : 0.023444
[00:58:48.505] iteration 20092 : model1 loss : 0.026061 model2 loss : 0.022304
[00:58:49.175] iteration 20093 : model1 loss : 0.024930 model2 loss : 0.024028
[00:58:49.837] iteration 20094 : model1 loss : 0.027770 model2 loss : 0.027823
[00:58:50.502] iteration 20095 : model1 loss : 0.025862 model2 loss : 0.023961
[00:58:51.161] iteration 20096 : model1 loss : 0.022990 model2 loss : 0.023451
[00:58:51.817] iteration 20097 : model1 loss : 0.020265 model2 loss : 0.018689
[00:58:52.490] iteration 20098 : model1 loss : 0.138709 model2 loss : 0.141676
[00:58:53.149] iteration 20099 : model1 loss : 0.026683 model2 loss : 0.026405
[00:58:53.820] iteration 20100 : model1 loss : 0.016146 model2 loss : 0.017991
[00:58:54.526] iteration 20101 : model1 loss : 0.023078 model2 loss : 0.025036
[00:58:55.180] iteration 20102 : model1 loss : 0.018167 model2 loss : 0.017714
[00:58:55.835] iteration 20103 : model1 loss : 0.023076 model2 loss : 0.022442
[00:58:56.499] iteration 20104 : model1 loss : 0.031245 model2 loss : 0.030537
[00:58:57.171] iteration 20105 : model1 loss : 0.021118 model2 loss : 0.021119
[00:58:57.832] iteration 20106 : model1 loss : 0.018013 model2 loss : 0.020061
[00:58:58.507] iteration 20107 : model1 loss : 0.017006 model2 loss : 0.017952
[00:58:59.162] iteration 20108 : model1 loss : 0.018396 model2 loss : 0.018892
[00:58:59.811] iteration 20109 : model1 loss : 0.020026 model2 loss : 0.018382
[00:59:00.464] iteration 20110 : model1 loss : 0.021983 model2 loss : 0.024338
[00:59:01.126] iteration 20111 : model1 loss : 0.016416 model2 loss : 0.017158
[00:59:01.782] iteration 20112 : model1 loss : 0.017056 model2 loss : 0.016745
[00:59:02.442] iteration 20113 : model1 loss : 0.017347 model2 loss : 0.016100
[00:59:03.104] iteration 20114 : model1 loss : 0.019225 model2 loss : 0.022021
[00:59:03.766] iteration 20115 : model1 loss : 0.019785 model2 loss : 0.021618
[00:59:04.436] iteration 20116 : model1 loss : 0.028376 model2 loss : 0.027028
[00:59:05.099] iteration 20117 : model1 loss : 0.027843 model2 loss : 0.026475
[00:59:05.759] iteration 20118 : model1 loss : 0.023469 model2 loss : 0.024573
[00:59:06.411] iteration 20119 : model1 loss : 0.019837 model2 loss : 0.016364
[00:59:07.067] iteration 20120 : model1 loss : 0.020047 model2 loss : 0.021113
[00:59:07.728] iteration 20121 : model1 loss : 0.019105 model2 loss : 0.019237
[00:59:08.392] iteration 20122 : model1 loss : 0.021158 model2 loss : 0.024432
[00:59:09.047] iteration 20123 : model1 loss : 0.023928 model2 loss : 0.023776
[00:59:09.706] iteration 20124 : model1 loss : 0.025115 model2 loss : 0.022964
[00:59:10.362] iteration 20125 : model1 loss : 0.017145 model2 loss : 0.021311
[00:59:11.029] iteration 20126 : model1 loss : 0.020932 model2 loss : 0.023409
[00:59:11.692] iteration 20127 : model1 loss : 0.022243 model2 loss : 0.023067
[00:59:12.349] iteration 20128 : model1 loss : 0.016790 model2 loss : 0.016863
[00:59:13.007] iteration 20129 : model1 loss : 0.017985 model2 loss : 0.018756
[00:59:13.663] iteration 20130 : model1 loss : 0.020176 model2 loss : 0.020990
[00:59:14.323] iteration 20131 : model1 loss : 0.021405 model2 loss : 0.022669
[00:59:14.989] iteration 20132 : model1 loss : 0.023711 model2 loss : 0.021477
[00:59:15.644] iteration 20133 : model1 loss : 0.025388 model2 loss : 0.024345
[00:59:16.290] iteration 20134 : model1 loss : 0.019511 model2 loss : 0.020475
[00:59:16.978] iteration 20135 : model1 loss : 0.017916 model2 loss : 0.017675
[00:59:17.628] iteration 20136 : model1 loss : 0.049922 model2 loss : 0.038108
[00:59:18.296] iteration 20137 : model1 loss : 0.018714 model2 loss : 0.021583
[00:59:18.963] iteration 20138 : model1 loss : 0.017102 model2 loss : 0.016211
[00:59:19.632] iteration 20139 : model1 loss : 0.019318 model2 loss : 0.019391
[00:59:20.294] iteration 20140 : model1 loss : 0.020968 model2 loss : 0.020784
[00:59:20.955] iteration 20141 : model1 loss : 0.017578 model2 loss : 0.018293
[00:59:21.625] iteration 20142 : model1 loss : 0.038028 model2 loss : 0.049625
[00:59:22.269] iteration 20143 : model1 loss : 0.022895 model2 loss : 0.021491
[00:59:22.912] iteration 20144 : model1 loss : 0.018205 model2 loss : 0.018596
[00:59:23.565] iteration 20145 : model1 loss : 0.018808 model2 loss : 0.017961
[00:59:24.227] iteration 20146 : model1 loss : 0.015281 model2 loss : 0.017094
[00:59:24.886] iteration 20147 : model1 loss : 0.021085 model2 loss : 0.021212
[00:59:25.553] iteration 20148 : model1 loss : 0.019760 model2 loss : 0.018994
[00:59:26.210] iteration 20149 : model1 loss : 0.021672 model2 loss : 0.022660
[00:59:26.866] iteration 20150 : model1 loss : 0.023663 model2 loss : 0.025316
[00:59:27.563] iteration 20151 : model1 loss : 0.016086 model2 loss : 0.017370
[00:59:28.209] iteration 20152 : model1 loss : 0.020107 model2 loss : 0.019425
[00:59:28.861] iteration 20153 : model1 loss : 0.020887 model2 loss : 0.018635
[00:59:29.517] iteration 20154 : model1 loss : 0.037487 model2 loss : 0.036111
[00:59:30.176] iteration 20155 : model1 loss : 0.017039 model2 loss : 0.018131
[00:59:30.846] iteration 20156 : model1 loss : 0.027608 model2 loss : 0.025959
[00:59:31.518] iteration 20157 : model1 loss : 0.023718 model2 loss : 0.023307
[00:59:32.186] iteration 20158 : model1 loss : 0.031401 model2 loss : 0.028687
[00:59:32.848] iteration 20159 : model1 loss : 0.020745 model2 loss : 0.020767
[00:59:33.505] iteration 20160 : model1 loss : 0.019554 model2 loss : 0.021067
[00:59:34.181] iteration 20161 : model1 loss : 0.023549 model2 loss : 0.023440
[00:59:34.859] iteration 20162 : model1 loss : 0.022117 model2 loss : 0.021149
[00:59:35.524] iteration 20163 : model1 loss : 0.020699 model2 loss : 0.023250
[00:59:36.188] iteration 20164 : model1 loss : 0.018138 model2 loss : 0.018389
[00:59:36.855] iteration 20165 : model1 loss : 0.023605 model2 loss : 0.026284
[00:59:37.529] iteration 20166 : model1 loss : 0.033631 model2 loss : 0.032953
[00:59:38.186] iteration 20167 : model1 loss : 0.016008 model2 loss : 0.017814
[00:59:38.850] iteration 20168 : model1 loss : 0.017617 model2 loss : 0.017803
[00:59:39.510] iteration 20169 : model1 loss : 0.029151 model2 loss : 0.035294
[00:59:40.166] iteration 20170 : model1 loss : 0.014424 model2 loss : 0.014683
[00:59:40.834] iteration 20171 : model1 loss : 0.022538 model2 loss : 0.023095
[00:59:41.495] iteration 20172 : model1 loss : 0.018226 model2 loss : 0.018225
[00:59:42.156] iteration 20173 : model1 loss : 0.020995 model2 loss : 0.020464
[00:59:42.807] iteration 20174 : model1 loss : 0.020092 model2 loss : 0.018885
[00:59:43.477] iteration 20175 : model1 loss : 0.017683 model2 loss : 0.019439
[00:59:44.131] iteration 20176 : model1 loss : 0.020457 model2 loss : 0.021563
[00:59:44.790] iteration 20177 : model1 loss : 0.019367 model2 loss : 0.025387
[00:59:45.456] iteration 20178 : model1 loss : 0.020734 model2 loss : 0.018481
[00:59:46.136] iteration 20179 : model1 loss : 0.017216 model2 loss : 0.018159
[00:59:46.781] iteration 20180 : model1 loss : 0.020197 model2 loss : 0.020617
[00:59:47.436] iteration 20181 : model1 loss : 0.018807 model2 loss : 0.018089
[00:59:48.087] iteration 20182 : model1 loss : 0.018460 model2 loss : 0.018923
[00:59:48.752] iteration 20183 : model1 loss : 0.020649 model2 loss : 0.018978
[00:59:49.404] iteration 20184 : model1 loss : 0.021565 model2 loss : 0.022775
[00:59:50.053] iteration 20185 : model1 loss : 0.020501 model2 loss : 0.020820
[00:59:50.712] iteration 20186 : model1 loss : 0.024209 model2 loss : 0.023737
[00:59:51.362] iteration 20187 : model1 loss : 0.021725 model2 loss : 0.021801
[00:59:52.036] iteration 20188 : model1 loss : 0.019074 model2 loss : 0.022544
[00:59:52.712] iteration 20189 : model1 loss : 0.036883 model2 loss : 0.035156
[00:59:53.371] iteration 20190 : model1 loss : 0.019677 model2 loss : 0.020307
[00:59:54.023] iteration 20191 : model1 loss : 0.024327 model2 loss : 0.025094
[00:59:54.685] iteration 20192 : model1 loss : 0.055210 model2 loss : 0.070733
[00:59:55.356] iteration 20193 : model1 loss : 0.027269 model2 loss : 0.027172
[00:59:56.008] iteration 20194 : model1 loss : 0.019274 model2 loss : 0.018079
[00:59:56.666] iteration 20195 : model1 loss : 0.023682 model2 loss : 0.025643
[00:59:57.331] iteration 20196 : model1 loss : 0.022049 model2 loss : 0.024980
[00:59:57.995] iteration 20197 : model1 loss : 0.018095 model2 loss : 0.018216
[00:59:58.680] iteration 20198 : model1 loss : 0.034027 model2 loss : 0.036842
[00:59:59.335] iteration 20199 : model1 loss : 0.020676 model2 loss : 0.021424
[00:59:59.989] iteration 20200 : model1 loss : 0.032920 model2 loss : 0.031356
[01:00:17.494] iteration 20200 : model1_mean_dice : 0.873848 model1_mean_hd95 : 7.372228
[01:00:34.911] iteration 20200 : model2_mean_dice : 0.872119 model2_mean_hd95 : 5.191123
[01:00:35.593] iteration 20201 : model1 loss : 0.032764 model2 loss : 0.038070
[01:00:36.234] iteration 20202 : model1 loss : 0.016092 model2 loss : 0.016822
[01:00:36.886] iteration 20203 : model1 loss : 0.023632 model2 loss : 0.022045
[01:00:37.537] iteration 20204 : model1 loss : 0.015199 model2 loss : 0.014801
[01:00:38.202] iteration 20205 : model1 loss : 0.022354 model2 loss : 0.020455
[01:00:38.854] iteration 20206 : model1 loss : 0.018129 model2 loss : 0.017045
[01:00:39.518] iteration 20207 : model1 loss : 0.018886 model2 loss : 0.017628
[01:00:40.170] iteration 20208 : model1 loss : 0.017444 model2 loss : 0.016895
[01:00:40.821] iteration 20209 : model1 loss : 0.017110 model2 loss : 0.017632
[01:00:41.472] iteration 20210 : model1 loss : 0.017193 model2 loss : 0.017419
[01:00:42.140] iteration 20211 : model1 loss : 0.019029 model2 loss : 0.019317
[01:00:42.790] iteration 20212 : model1 loss : 0.020152 model2 loss : 0.018828
[01:00:43.447] iteration 20213 : model1 loss : 0.021113 model2 loss : 0.021906
[01:00:44.100] iteration 20214 : model1 loss : 0.018302 model2 loss : 0.018779
[01:00:44.751] iteration 20215 : model1 loss : 0.020730 model2 loss : 0.021613
[01:00:45.404] iteration 20216 : model1 loss : 0.152059 model2 loss : 0.152391
[01:00:46.057] iteration 20217 : model1 loss : 0.019930 model2 loss : 0.022751
[01:00:46.708] iteration 20218 : model1 loss : 0.018975 model2 loss : 0.018940
[01:00:47.372] iteration 20219 : model1 loss : 0.024726 model2 loss : 0.026439
[01:00:48.029] iteration 20220 : model1 loss : 0.017750 model2 loss : 0.016055
[01:00:48.687] iteration 20221 : model1 loss : 0.017375 model2 loss : 0.017922
[01:00:49.338] iteration 20222 : model1 loss : 0.046424 model2 loss : 0.049992
[01:00:49.988] iteration 20223 : model1 loss : 0.025953 model2 loss : 0.022072
[01:00:50.641] iteration 20224 : model1 loss : 0.019421 model2 loss : 0.018841
[01:00:51.297] iteration 20225 : model1 loss : 0.022650 model2 loss : 0.020148
[01:00:51.955] iteration 20226 : model1 loss : 0.025318 model2 loss : 0.025154
[01:00:52.614] iteration 20227 : model1 loss : 0.026460 model2 loss : 0.029958
[01:00:53.262] iteration 20228 : model1 loss : 0.019101 model2 loss : 0.020257
[01:00:53.917] iteration 20229 : model1 loss : 0.016632 model2 loss : 0.016453
[01:00:54.568] iteration 20230 : model1 loss : 0.143117 model2 loss : 0.143886
[01:00:55.246] iteration 20231 : model1 loss : 0.019981 model2 loss : 0.021016
[01:00:55.895] iteration 20232 : model1 loss : 0.020338 model2 loss : 0.018969
[01:00:56.552] iteration 20233 : model1 loss : 0.017709 model2 loss : 0.019703
[01:00:57.205] iteration 20234 : model1 loss : 0.018534 model2 loss : 0.019044
[01:00:57.869] iteration 20235 : model1 loss : 0.021420 model2 loss : 0.025207
[01:00:58.530] iteration 20236 : model1 loss : 0.016204 model2 loss : 0.016299
[01:00:59.172] iteration 20237 : model1 loss : 0.018179 model2 loss : 0.019250
[01:00:59.819] iteration 20238 : model1 loss : 0.021300 model2 loss : 0.024011
[01:01:00.489] iteration 20239 : model1 loss : 0.016052 model2 loss : 0.017875
[01:01:01.134] iteration 20240 : model1 loss : 0.021164 model2 loss : 0.020140
[01:01:01.790] iteration 20241 : model1 loss : 0.019359 model2 loss : 0.019099
[01:01:02.457] iteration 20242 : model1 loss : 0.025438 model2 loss : 0.028811
[01:01:03.115] iteration 20243 : model1 loss : 0.026467 model2 loss : 0.022269
[01:01:03.772] iteration 20244 : model1 loss : 0.022714 model2 loss : 0.023041
[01:01:04.431] iteration 20245 : model1 loss : 0.021502 model2 loss : 0.021232
[01:01:05.092] iteration 20246 : model1 loss : 0.020750 model2 loss : 0.019339
[01:01:05.739] iteration 20247 : model1 loss : 0.016237 model2 loss : 0.016753
[01:01:06.393] iteration 20248 : model1 loss : 0.022211 model2 loss : 0.023408
[01:01:07.038] iteration 20249 : model1 loss : 0.018645 model2 loss : 0.016352
[01:01:07.695] iteration 20250 : model1 loss : 0.018731 model2 loss : 0.019348
[01:01:08.394] iteration 20251 : model1 loss : 0.036438 model2 loss : 0.037920
[01:01:09.043] iteration 20252 : model1 loss : 0.027447 model2 loss : 0.028850
[01:01:09.700] iteration 20253 : model1 loss : 0.020440 model2 loss : 0.019883
[01:01:10.360] iteration 20254 : model1 loss : 0.019120 model2 loss : 0.019783
[01:01:11.011] iteration 20255 : model1 loss : 0.021188 model2 loss : 0.022091
[01:01:11.682] iteration 20256 : model1 loss : 0.034530 model2 loss : 0.035191
[01:01:12.346] iteration 20257 : model1 loss : 0.025459 model2 loss : 0.027770
[01:01:13.006] iteration 20258 : model1 loss : 0.020335 model2 loss : 0.018705
[01:01:13.666] iteration 20259 : model1 loss : 0.017007 model2 loss : 0.017200
[01:01:14.328] iteration 20260 : model1 loss : 0.021213 model2 loss : 0.021395
[01:01:14.980] iteration 20261 : model1 loss : 0.029931 model2 loss : 0.025639
[01:01:15.627] iteration 20262 : model1 loss : 0.026649 model2 loss : 0.025266
[01:01:16.271] iteration 20263 : model1 loss : 0.018968 model2 loss : 0.018383
[01:01:16.931] iteration 20264 : model1 loss : 0.017065 model2 loss : 0.019013
[01:01:17.615] iteration 20265 : model1 loss : 0.027730 model2 loss : 0.024395
[01:01:18.283] iteration 20266 : model1 loss : 0.040817 model2 loss : 0.046057
[01:01:18.925] iteration 20267 : model1 loss : 0.022996 model2 loss : 0.022245
[01:01:19.593] iteration 20268 : model1 loss : 0.016336 model2 loss : 0.018329
[01:01:20.264] iteration 20269 : model1 loss : 0.016844 model2 loss : 0.018001
[01:01:20.926] iteration 20270 : model1 loss : 0.030726 model2 loss : 0.033644
[01:01:21.585] iteration 20271 : model1 loss : 0.017902 model2 loss : 0.018208
[01:01:22.243] iteration 20272 : model1 loss : 0.026440 model2 loss : 0.024837
[01:01:22.900] iteration 20273 : model1 loss : 0.024019 model2 loss : 0.024255
[01:01:23.568] iteration 20274 : model1 loss : 0.021777 model2 loss : 0.020005
[01:01:24.224] iteration 20275 : model1 loss : 0.026214 model2 loss : 0.029523
[01:01:24.880] iteration 20276 : model1 loss : 0.019972 model2 loss : 0.019565
[01:01:25.543] iteration 20277 : model1 loss : 0.020634 model2 loss : 0.021467
[01:01:26.208] iteration 20278 : model1 loss : 0.035447 model2 loss : 0.045278
[01:01:26.857] iteration 20279 : model1 loss : 0.020234 model2 loss : 0.019512
[01:01:27.525] iteration 20280 : model1 loss : 0.016480 model2 loss : 0.017859
[01:01:28.197] iteration 20281 : model1 loss : 0.016290 model2 loss : 0.016060
[01:01:28.866] iteration 20282 : model1 loss : 0.020570 model2 loss : 0.019882
[01:01:29.520] iteration 20283 : model1 loss : 0.021636 model2 loss : 0.021301
[01:01:30.189] iteration 20284 : model1 loss : 0.021693 model2 loss : 0.019228
[01:01:30.834] iteration 20285 : model1 loss : 0.016275 model2 loss : 0.016046
[01:01:31.491] iteration 20286 : model1 loss : 0.015294 model2 loss : 0.016450
[01:01:32.141] iteration 20287 : model1 loss : 0.016744 model2 loss : 0.017182
[01:01:32.805] iteration 20288 : model1 loss : 0.017842 model2 loss : 0.020024
[01:01:33.487] iteration 20289 : model1 loss : 0.017306 model2 loss : 0.017070
[01:01:34.148] iteration 20290 : model1 loss : 0.025039 model2 loss : 0.023113
[01:01:34.815] iteration 20291 : model1 loss : 0.027698 model2 loss : 0.028270
[01:01:35.474] iteration 20292 : model1 loss : 0.025935 model2 loss : 0.023712
[01:01:36.131] iteration 20293 : model1 loss : 0.024265 model2 loss : 0.028800
[01:01:36.790] iteration 20294 : model1 loss : 0.017528 model2 loss : 0.018115
[01:01:37.450] iteration 20295 : model1 loss : 0.017010 model2 loss : 0.017889
[01:01:38.115] iteration 20296 : model1 loss : 0.020592 model2 loss : 0.022008
[01:01:38.769] iteration 20297 : model1 loss : 0.020728 model2 loss : 0.020272
[01:01:39.445] iteration 20298 : model1 loss : 0.014901 model2 loss : 0.014591
[01:01:40.104] iteration 20299 : model1 loss : 0.018765 model2 loss : 0.017022
[01:01:40.756] iteration 20300 : model1 loss : 0.018470 model2 loss : 0.019299
[01:01:41.445] iteration 20301 : model1 loss : 0.019893 model2 loss : 0.019891
[01:01:42.102] iteration 20302 : model1 loss : 0.024392 model2 loss : 0.023576
[01:01:42.765] iteration 20303 : model1 loss : 0.015393 model2 loss : 0.014401
[01:01:43.434] iteration 20304 : model1 loss : 0.022262 model2 loss : 0.025094
[01:01:44.085] iteration 20305 : model1 loss : 0.018877 model2 loss : 0.019316
[01:01:44.741] iteration 20306 : model1 loss : 0.023176 model2 loss : 0.022449
[01:01:45.404] iteration 20307 : model1 loss : 0.016662 model2 loss : 0.016157
[01:01:46.054] iteration 20308 : model1 loss : 0.018716 model2 loss : 0.019070
[01:01:46.706] iteration 20309 : model1 loss : 0.016444 model2 loss : 0.017987
[01:01:47.361] iteration 20310 : model1 loss : 0.025211 model2 loss : 0.026912
[01:01:48.024] iteration 20311 : model1 loss : 0.015236 model2 loss : 0.015186
[01:01:48.683] iteration 20312 : model1 loss : 0.019298 model2 loss : 0.024401
[01:01:49.339] iteration 20313 : model1 loss : 0.021318 model2 loss : 0.020745
[01:01:49.994] iteration 20314 : model1 loss : 0.022917 model2 loss : 0.025265
[01:01:50.642] iteration 20315 : model1 loss : 0.022436 model2 loss : 0.023658
[01:01:51.301] iteration 20316 : model1 loss : 0.144710 model2 loss : 0.146538
[01:01:51.948] iteration 20317 : model1 loss : 0.020985 model2 loss : 0.021696
[01:01:52.615] iteration 20318 : model1 loss : 0.022007 model2 loss : 0.022222
[01:01:53.275] iteration 20319 : model1 loss : 0.018457 model2 loss : 0.018198
[01:01:53.927] iteration 20320 : model1 loss : 0.023468 model2 loss : 0.020921
[01:01:54.585] iteration 20321 : model1 loss : 0.024946 model2 loss : 0.025034
[01:01:55.242] iteration 20322 : model1 loss : 0.017644 model2 loss : 0.017090
[01:01:55.887] iteration 20323 : model1 loss : 0.021661 model2 loss : 0.020747
[01:01:56.550] iteration 20324 : model1 loss : 0.097786 model2 loss : 0.091614
[01:01:57.204] iteration 20325 : model1 loss : 0.033146 model2 loss : 0.032581
[01:01:57.863] iteration 20326 : model1 loss : 0.023804 model2 loss : 0.022665
[01:01:58.511] iteration 20327 : model1 loss : 0.017469 model2 loss : 0.017792
[01:01:59.171] iteration 20328 : model1 loss : 0.026993 model2 loss : 0.026819
[01:01:59.830] iteration 20329 : model1 loss : 0.032048 model2 loss : 0.029850
[01:02:00.494] iteration 20330 : model1 loss : 0.024404 model2 loss : 0.024753
[01:02:01.146] iteration 20331 : model1 loss : 0.019910 model2 loss : 0.021384
[01:02:01.817] iteration 20332 : model1 loss : 0.021010 model2 loss : 0.022218
[01:02:02.479] iteration 20333 : model1 loss : 0.024187 model2 loss : 0.023081
[01:02:03.147] iteration 20334 : model1 loss : 0.020514 model2 loss : 0.020608
[01:02:03.817] iteration 20335 : model1 loss : 0.027948 model2 loss : 0.021871
[01:02:04.471] iteration 20336 : model1 loss : 0.023502 model2 loss : 0.019178
[01:02:05.135] iteration 20337 : model1 loss : 0.022235 model2 loss : 0.019509
[01:02:05.797] iteration 20338 : model1 loss : 0.021434 model2 loss : 0.021442
[01:02:06.459] iteration 20339 : model1 loss : 0.020361 model2 loss : 0.019557
[01:02:07.119] iteration 20340 : model1 loss : 0.021080 model2 loss : 0.019573
[01:02:07.777] iteration 20341 : model1 loss : 0.019999 model2 loss : 0.018884
[01:02:08.436] iteration 20342 : model1 loss : 0.022385 model2 loss : 0.022876
[01:02:09.125] iteration 20343 : model1 loss : 0.020682 model2 loss : 0.020057
[01:02:09.816] iteration 20344 : model1 loss : 0.022227 model2 loss : 0.024529
[01:02:10.476] iteration 20345 : model1 loss : 0.021874 model2 loss : 0.019359
[01:02:11.135] iteration 20346 : model1 loss : 0.025508 model2 loss : 0.025186
[01:02:11.795] iteration 20347 : model1 loss : 0.012903 model2 loss : 0.012778
[01:02:12.450] iteration 20348 : model1 loss : 0.017898 model2 loss : 0.018652
[01:02:13.114] iteration 20349 : model1 loss : 0.017275 model2 loss : 0.016114
[01:02:13.781] iteration 20350 : model1 loss : 0.023154 model2 loss : 0.021831
[01:02:14.472] iteration 20351 : model1 loss : 0.014813 model2 loss : 0.015674
[01:02:15.130] iteration 20352 : model1 loss : 0.022649 model2 loss : 0.023273
[01:02:15.786] iteration 20353 : model1 loss : 0.011693 model2 loss : 0.012633
[01:02:16.457] iteration 20354 : model1 loss : 0.021062 model2 loss : 0.018985
[01:02:17.104] iteration 20355 : model1 loss : 0.017334 model2 loss : 0.017662
[01:02:17.768] iteration 20356 : model1 loss : 0.018306 model2 loss : 0.017688
[01:02:18.457] iteration 20357 : model1 loss : 0.024887 model2 loss : 0.027934
[01:02:19.125] iteration 20358 : model1 loss : 0.022078 model2 loss : 0.022523
[01:02:19.789] iteration 20359 : model1 loss : 0.020778 model2 loss : 0.021748
[01:02:20.446] iteration 20360 : model1 loss : 0.018000 model2 loss : 0.015770
[01:02:21.111] iteration 20361 : model1 loss : 0.018691 model2 loss : 0.021624
[01:02:21.764] iteration 20362 : model1 loss : 0.022728 model2 loss : 0.025677
[01:02:22.422] iteration 20363 : model1 loss : 0.019387 model2 loss : 0.019811
[01:02:23.088] iteration 20364 : model1 loss : 0.017784 model2 loss : 0.017158
[01:02:23.741] iteration 20365 : model1 loss : 0.016270 model2 loss : 0.016548
[01:02:24.400] iteration 20366 : model1 loss : 0.018185 model2 loss : 0.020578
[01:02:25.072] iteration 20367 : model1 loss : 0.026038 model2 loss : 0.023304
[01:02:25.725] iteration 20368 : model1 loss : 0.026463 model2 loss : 0.023763
[01:02:26.399] iteration 20369 : model1 loss : 0.023884 model2 loss : 0.025982
[01:02:27.055] iteration 20370 : model1 loss : 0.021407 model2 loss : 0.021319
[01:02:27.705] iteration 20371 : model1 loss : 0.019422 model2 loss : 0.018792
[01:02:28.372] iteration 20372 : model1 loss : 0.020456 model2 loss : 0.019891
[01:02:29.026] iteration 20373 : model1 loss : 0.025196 model2 loss : 0.026410
[01:02:29.686] iteration 20374 : model1 loss : 0.020541 model2 loss : 0.018969
[01:02:30.346] iteration 20375 : model1 loss : 0.021494 model2 loss : 0.018902
[01:02:31.009] iteration 20376 : model1 loss : 0.019546 model2 loss : 0.017630
[01:02:31.666] iteration 20377 : model1 loss : 0.019005 model2 loss : 0.021037
[01:02:32.318] iteration 20378 : model1 loss : 0.025927 model2 loss : 0.027915
[01:02:32.979] iteration 20379 : model1 loss : 0.017014 model2 loss : 0.020879
[01:02:33.642] iteration 20380 : model1 loss : 0.015810 model2 loss : 0.015563
[01:02:34.291] iteration 20381 : model1 loss : 0.020739 model2 loss : 0.022173
[01:02:34.949] iteration 20382 : model1 loss : 0.023503 model2 loss : 0.023142
[01:02:35.603] iteration 20383 : model1 loss : 0.021293 model2 loss : 0.021335
[01:02:36.259] iteration 20384 : model1 loss : 0.017464 model2 loss : 0.017834
[01:02:36.913] iteration 20385 : model1 loss : 0.028441 model2 loss : 0.024801
[01:02:37.569] iteration 20386 : model1 loss : 0.018741 model2 loss : 0.018415
[01:02:38.232] iteration 20387 : model1 loss : 0.018520 model2 loss : 0.017723
[01:02:38.888] iteration 20388 : model1 loss : 0.023249 model2 loss : 0.023506
[01:02:39.550] iteration 20389 : model1 loss : 0.022564 model2 loss : 0.020313
[01:02:40.209] iteration 20390 : model1 loss : 0.023627 model2 loss : 0.027513
[01:02:40.864] iteration 20391 : model1 loss : 0.023663 model2 loss : 0.023232
[01:02:41.534] iteration 20392 : model1 loss : 0.026995 model2 loss : 0.028183
[01:02:42.181] iteration 20393 : model1 loss : 0.020024 model2 loss : 0.020718
[01:02:42.841] iteration 20394 : model1 loss : 0.020276 model2 loss : 0.018127
[01:02:43.499] iteration 20395 : model1 loss : 0.019923 model2 loss : 0.019825
[01:02:44.167] iteration 20396 : model1 loss : 0.021642 model2 loss : 0.022609
[01:02:44.833] iteration 20397 : model1 loss : 0.024793 model2 loss : 0.025992
[01:02:45.490] iteration 20398 : model1 loss : 0.018709 model2 loss : 0.019172
[01:02:46.151] iteration 20399 : model1 loss : 0.017804 model2 loss : 0.019940
[01:02:46.819] iteration 20400 : model1 loss : 0.018571 model2 loss : 0.018911
[01:03:04.281] iteration 20400 : model1_mean_dice : 0.875978 model1_mean_hd95 : 5.969614
[01:03:21.852] iteration 20400 : model2_mean_dice : 0.876132 model2_mean_hd95 : 3.945222
[01:03:22.546] iteration 20401 : model1 loss : 0.021042 model2 loss : 0.021023
[01:03:23.192] iteration 20402 : model1 loss : 0.025947 model2 loss : 0.023257
[01:03:23.850] iteration 20403 : model1 loss : 0.020546 model2 loss : 0.017394
[01:03:24.494] iteration 20404 : model1 loss : 0.019749 model2 loss : 0.021558
[01:03:25.147] iteration 20405 : model1 loss : 0.025802 model2 loss : 0.025363
[01:03:25.797] iteration 20406 : model1 loss : 0.017757 model2 loss : 0.018594
[01:03:26.453] iteration 20407 : model1 loss : 0.025192 model2 loss : 0.026188
[01:03:27.103] iteration 20408 : model1 loss : 0.016184 model2 loss : 0.017790
[01:03:27.750] iteration 20409 : model1 loss : 0.015960 model2 loss : 0.015373
[01:03:28.396] iteration 20410 : model1 loss : 0.036945 model2 loss : 0.046624
[01:03:29.054] iteration 20411 : model1 loss : 0.018105 model2 loss : 0.020439
[01:03:29.710] iteration 20412 : model1 loss : 0.028254 model2 loss : 0.022182
[01:03:30.369] iteration 20413 : model1 loss : 0.023398 model2 loss : 0.024692
[01:03:31.022] iteration 20414 : model1 loss : 0.021117 model2 loss : 0.024699
[01:03:31.673] iteration 20415 : model1 loss : 0.015898 model2 loss : 0.016309
[01:03:32.321] iteration 20416 : model1 loss : 0.016337 model2 loss : 0.015879
[01:03:32.966] iteration 20417 : model1 loss : 0.016983 model2 loss : 0.017359
[01:03:33.626] iteration 20418 : model1 loss : 0.021649 model2 loss : 0.024375
[01:03:34.280] iteration 20419 : model1 loss : 0.021796 model2 loss : 0.024078
[01:03:34.925] iteration 20420 : model1 loss : 0.021959 model2 loss : 0.019007
[01:03:35.574] iteration 20421 : model1 loss : 0.015083 model2 loss : 0.016728
[01:03:36.215] iteration 20422 : model1 loss : 0.020878 model2 loss : 0.019625
[01:03:36.861] iteration 20423 : model1 loss : 0.014825 model2 loss : 0.015740
[01:03:37.519] iteration 20424 : model1 loss : 0.017947 model2 loss : 0.019442
[01:03:38.187] iteration 20425 : model1 loss : 0.023564 model2 loss : 0.021450
[01:03:38.844] iteration 20426 : model1 loss : 0.024604 model2 loss : 0.027471
[01:03:39.495] iteration 20427 : model1 loss : 0.023648 model2 loss : 0.022870
[01:03:40.162] iteration 20428 : model1 loss : 0.028700 model2 loss : 0.026530
[01:03:40.812] iteration 20429 : model1 loss : 0.032432 model2 loss : 0.031403
[01:03:41.477] iteration 20430 : model1 loss : 0.022902 model2 loss : 0.021816
[01:03:42.141] iteration 20431 : model1 loss : 0.019510 model2 loss : 0.020337
[01:03:42.793] iteration 20432 : model1 loss : 0.032815 model2 loss : 0.030577
[01:03:43.444] iteration 20433 : model1 loss : 0.019687 model2 loss : 0.019896
[01:03:44.096] iteration 20434 : model1 loss : 0.017193 model2 loss : 0.017387
[01:03:44.742] iteration 20435 : model1 loss : 0.062455 model2 loss : 0.040687
[01:03:45.382] iteration 20436 : model1 loss : 0.021606 model2 loss : 0.022251
[01:03:46.031] iteration 20437 : model1 loss : 0.025115 model2 loss : 0.023162
[01:03:46.685] iteration 20438 : model1 loss : 0.021496 model2 loss : 0.020508
[01:03:47.354] iteration 20439 : model1 loss : 0.140824 model2 loss : 0.142116
[01:03:48.011] iteration 20440 : model1 loss : 0.018525 model2 loss : 0.016722
[01:03:48.660] iteration 20441 : model1 loss : 0.025385 model2 loss : 0.023520
[01:03:49.312] iteration 20442 : model1 loss : 0.019797 model2 loss : 0.018755
[01:03:49.957] iteration 20443 : model1 loss : 0.019907 model2 loss : 0.020346
[01:03:50.615] iteration 20444 : model1 loss : 0.023240 model2 loss : 0.022129
[01:03:51.273] iteration 20445 : model1 loss : 0.021671 model2 loss : 0.021712
[01:03:51.925] iteration 20446 : model1 loss : 0.018460 model2 loss : 0.017170
[01:03:52.587] iteration 20447 : model1 loss : 0.019748 model2 loss : 0.020190
[01:03:53.257] iteration 20448 : model1 loss : 0.020372 model2 loss : 0.020037
[01:03:53.914] iteration 20449 : model1 loss : 0.018083 model2 loss : 0.018128
[01:03:54.569] iteration 20450 : model1 loss : 0.018137 model2 loss : 0.018107
[01:03:55.267] iteration 20451 : model1 loss : 0.024127 model2 loss : 0.026854
[01:03:55.927] iteration 20452 : model1 loss : 0.019202 model2 loss : 0.019831
[01:03:56.585] iteration 20453 : model1 loss : 0.017668 model2 loss : 0.017436
[01:03:57.242] iteration 20454 : model1 loss : 0.022250 model2 loss : 0.020995
[01:03:57.887] iteration 20455 : model1 loss : 0.022883 model2 loss : 0.021908
[01:03:58.552] iteration 20456 : model1 loss : 0.039470 model2 loss : 0.032194
[01:03:59.201] iteration 20457 : model1 loss : 0.048160 model2 loss : 0.038122
[01:03:59.854] iteration 20458 : model1 loss : 0.028767 model2 loss : 0.024989
[01:04:00.501] iteration 20459 : model1 loss : 0.021665 model2 loss : 0.022686
[01:04:01.163] iteration 20460 : model1 loss : 0.017102 model2 loss : 0.017143
[01:04:01.820] iteration 20461 : model1 loss : 0.023250 model2 loss : 0.024779
[01:04:02.479] iteration 20462 : model1 loss : 0.016662 model2 loss : 0.019485
[01:04:03.136] iteration 20463 : model1 loss : 0.026322 model2 loss : 0.023156
[01:04:03.800] iteration 20464 : model1 loss : 0.019269 model2 loss : 0.017776
[01:04:04.464] iteration 20465 : model1 loss : 0.016809 model2 loss : 0.017654
[01:04:05.119] iteration 20466 : model1 loss : 0.021726 model2 loss : 0.020922
[01:04:05.779] iteration 20467 : model1 loss : 0.020411 model2 loss : 0.018838
[01:04:06.448] iteration 20468 : model1 loss : 0.025271 model2 loss : 0.023123
[01:04:07.098] iteration 20469 : model1 loss : 0.019129 model2 loss : 0.019282
[01:04:07.762] iteration 20470 : model1 loss : 0.031729 model2 loss : 0.031837
[01:04:08.413] iteration 20471 : model1 loss : 0.016383 model2 loss : 0.016875
[01:04:09.056] iteration 20472 : model1 loss : 0.013751 model2 loss : 0.014109
[01:04:09.714] iteration 20473 : model1 loss : 0.024118 model2 loss : 0.031139
[01:04:10.368] iteration 20474 : model1 loss : 0.017257 model2 loss : 0.017429
[01:04:11.028] iteration 20475 : model1 loss : 0.016316 model2 loss : 0.015819
[01:04:11.690] iteration 20476 : model1 loss : 0.019364 model2 loss : 0.017263
[01:04:12.353] iteration 20477 : model1 loss : 0.019233 model2 loss : 0.019142
[01:04:13.012] iteration 20478 : model1 loss : 0.023097 model2 loss : 0.027073
[01:04:13.664] iteration 20479 : model1 loss : 0.027356 model2 loss : 0.024851
[01:04:14.326] iteration 20480 : model1 loss : 0.025583 model2 loss : 0.022509
[01:04:14.975] iteration 20481 : model1 loss : 0.020523 model2 loss : 0.018911
[01:04:15.627] iteration 20482 : model1 loss : 0.031958 model2 loss : 0.027281
[01:04:16.291] iteration 20483 : model1 loss : 0.021787 model2 loss : 0.021310
[01:04:16.946] iteration 20484 : model1 loss : 0.146720 model2 loss : 0.144704
[01:04:17.618] iteration 20485 : model1 loss : 0.144677 model2 loss : 0.143559
[01:04:18.276] iteration 20486 : model1 loss : 0.032324 model2 loss : 0.026854
[01:04:18.945] iteration 20487 : model1 loss : 0.025442 model2 loss : 0.023449
[01:04:19.622] iteration 20488 : model1 loss : 0.016165 model2 loss : 0.017905
[01:04:20.270] iteration 20489 : model1 loss : 0.015561 model2 loss : 0.017301
[01:04:20.934] iteration 20490 : model1 loss : 0.021621 model2 loss : 0.019641
[01:04:21.583] iteration 20491 : model1 loss : 0.021173 model2 loss : 0.019834
[01:04:22.242] iteration 20492 : model1 loss : 0.014112 model2 loss : 0.016227
[01:04:22.907] iteration 20493 : model1 loss : 0.024545 model2 loss : 0.024941
[01:04:23.573] iteration 20494 : model1 loss : 0.019240 model2 loss : 0.018087
[01:04:24.241] iteration 20495 : model1 loss : 0.024234 model2 loss : 0.026098
[01:04:24.896] iteration 20496 : model1 loss : 0.029342 model2 loss : 0.028169
[01:04:25.560] iteration 20497 : model1 loss : 0.021952 model2 loss : 0.024880
[01:04:26.226] iteration 20498 : model1 loss : 0.021645 model2 loss : 0.020452
[01:04:26.868] iteration 20499 : model1 loss : 0.029963 model2 loss : 0.033434
[01:04:27.553] iteration 20500 : model1 loss : 0.018305 model2 loss : 0.016590
[01:04:28.253] iteration 20501 : model1 loss : 0.021255 model2 loss : 0.021062
[01:04:28.917] iteration 20502 : model1 loss : 0.022426 model2 loss : 0.021760
[01:04:29.577] iteration 20503 : model1 loss : 0.016033 model2 loss : 0.017261
[01:04:30.240] iteration 20504 : model1 loss : 0.027836 model2 loss : 0.026396
[01:04:30.889] iteration 20505 : model1 loss : 0.027755 model2 loss : 0.027944
[01:04:31.548] iteration 20506 : model1 loss : 0.026598 model2 loss : 0.022587
[01:04:32.209] iteration 20507 : model1 loss : 0.015890 model2 loss : 0.015646
[01:04:32.868] iteration 20508 : model1 loss : 0.015302 model2 loss : 0.015241
[01:04:33.516] iteration 20509 : model1 loss : 0.021342 model2 loss : 0.019667
[01:04:34.192] iteration 20510 : model1 loss : 0.019729 model2 loss : 0.025143
[01:04:34.855] iteration 20511 : model1 loss : 0.019437 model2 loss : 0.019088
[01:04:35.519] iteration 20512 : model1 loss : 0.019259 model2 loss : 0.016976
[01:04:36.176] iteration 20513 : model1 loss : 0.025121 model2 loss : 0.023271
[01:04:36.830] iteration 20514 : model1 loss : 0.025392 model2 loss : 0.026627
[01:04:37.509] iteration 20515 : model1 loss : 0.018103 model2 loss : 0.017934
[01:04:38.160] iteration 20516 : model1 loss : 0.027224 model2 loss : 0.024634
[01:04:38.815] iteration 20517 : model1 loss : 0.027411 model2 loss : 0.034066
[01:04:39.477] iteration 20518 : model1 loss : 0.016673 model2 loss : 0.017613
[01:04:40.131] iteration 20519 : model1 loss : 0.024307 model2 loss : 0.025408
[01:04:40.791] iteration 20520 : model1 loss : 0.020404 model2 loss : 0.019343
[01:04:41.454] iteration 20521 : model1 loss : 0.023557 model2 loss : 0.023394
[01:04:42.097] iteration 20522 : model1 loss : 0.015838 model2 loss : 0.015700
[01:04:42.762] iteration 20523 : model1 loss : 0.015632 model2 loss : 0.016431
[01:04:43.422] iteration 20524 : model1 loss : 0.028965 model2 loss : 0.025542
[01:04:44.081] iteration 20525 : model1 loss : 0.023197 model2 loss : 0.023353
[01:04:44.745] iteration 20526 : model1 loss : 0.024036 model2 loss : 0.022270
[01:04:45.399] iteration 20527 : model1 loss : 0.022731 model2 loss : 0.021279
[01:04:46.051] iteration 20528 : model1 loss : 0.019944 model2 loss : 0.020329
[01:04:46.713] iteration 20529 : model1 loss : 0.025007 model2 loss : 0.024197
[01:04:47.376] iteration 20530 : model1 loss : 0.021213 model2 loss : 0.019673
[01:04:48.026] iteration 20531 : model1 loss : 0.043538 model2 loss : 0.040611
[01:04:48.688] iteration 20532 : model1 loss : 0.016038 model2 loss : 0.017037
[01:04:49.354] iteration 20533 : model1 loss : 0.017298 model2 loss : 0.017466
[01:04:50.005] iteration 20534 : model1 loss : 0.035689 model2 loss : 0.035313
[01:04:50.678] iteration 20535 : model1 loss : 0.022586 model2 loss : 0.022875
[01:04:51.336] iteration 20536 : model1 loss : 0.016390 model2 loss : 0.016127
[01:04:51.986] iteration 20537 : model1 loss : 0.018096 model2 loss : 0.019175
[01:04:52.644] iteration 20538 : model1 loss : 0.025762 model2 loss : 0.026058
[01:04:53.301] iteration 20539 : model1 loss : 0.041576 model2 loss : 0.022353
[01:04:53.959] iteration 20540 : model1 loss : 0.015402 model2 loss : 0.015193
[01:04:54.616] iteration 20541 : model1 loss : 0.024559 model2 loss : 0.023616
[01:04:55.263] iteration 20542 : model1 loss : 0.014301 model2 loss : 0.013941
[01:04:55.928] iteration 20543 : model1 loss : 0.015815 model2 loss : 0.017280
[01:04:56.581] iteration 20544 : model1 loss : 0.021745 model2 loss : 0.024450
[01:04:57.233] iteration 20545 : model1 loss : 0.022538 model2 loss : 0.029343
[01:04:57.892] iteration 20546 : model1 loss : 0.019267 model2 loss : 0.019563
[01:04:58.565] iteration 20547 : model1 loss : 0.016853 model2 loss : 0.017344
[01:04:59.227] iteration 20548 : model1 loss : 0.020412 model2 loss : 0.020872
[01:04:59.875] iteration 20549 : model1 loss : 0.024636 model2 loss : 0.026166
[01:05:00.556] iteration 20550 : model1 loss : 0.043049 model2 loss : 0.038526
[01:05:01.280] iteration 20551 : model1 loss : 0.025142 model2 loss : 0.021673
[01:05:01.935] iteration 20552 : model1 loss : 0.019057 model2 loss : 0.020759
[01:05:02.596] iteration 20553 : model1 loss : 0.023887 model2 loss : 0.019704
[01:05:03.251] iteration 20554 : model1 loss : 0.020005 model2 loss : 0.019573
[01:05:03.915] iteration 20555 : model1 loss : 0.023817 model2 loss : 0.022171
[01:05:04.575] iteration 20556 : model1 loss : 0.017216 model2 loss : 0.018014
[01:05:05.234] iteration 20557 : model1 loss : 0.018945 model2 loss : 0.018158
[01:05:05.881] iteration 20558 : model1 loss : 0.019089 model2 loss : 0.019113
[01:05:06.536] iteration 20559 : model1 loss : 0.020715 model2 loss : 0.022357
[01:05:07.192] iteration 20560 : model1 loss : 0.109547 model2 loss : 0.108970
[01:05:07.843] iteration 20561 : model1 loss : 0.025750 model2 loss : 0.027138
[01:05:08.502] iteration 20562 : model1 loss : 0.019373 model2 loss : 0.021489
[01:05:09.161] iteration 20563 : model1 loss : 0.015589 model2 loss : 0.015120
[01:05:09.817] iteration 20564 : model1 loss : 0.027180 model2 loss : 0.030475
[01:05:10.478] iteration 20565 : model1 loss : 0.023126 model2 loss : 0.022389
[01:05:11.139] iteration 20566 : model1 loss : 0.026862 model2 loss : 0.022902
[01:05:11.802] iteration 20567 : model1 loss : 0.026574 model2 loss : 0.026121
[01:05:12.473] iteration 20568 : model1 loss : 0.018092 model2 loss : 0.019742
[01:05:13.128] iteration 20569 : model1 loss : 0.020168 model2 loss : 0.020774
[01:05:13.788] iteration 20570 : model1 loss : 0.057458 model2 loss : 0.064316
[01:05:14.460] iteration 20571 : model1 loss : 0.022546 model2 loss : 0.023897
[01:05:15.124] iteration 20572 : model1 loss : 0.025636 model2 loss : 0.025552
[01:05:15.785] iteration 20573 : model1 loss : 0.017469 model2 loss : 0.016989
[01:05:16.433] iteration 20574 : model1 loss : 0.021274 model2 loss : 0.018656
[01:05:17.098] iteration 20575 : model1 loss : 0.017932 model2 loss : 0.019215
[01:05:17.749] iteration 20576 : model1 loss : 0.019603 model2 loss : 0.019026
[01:05:18.400] iteration 20577 : model1 loss : 0.019758 model2 loss : 0.020904
[01:05:19.069] iteration 20578 : model1 loss : 0.024611 model2 loss : 0.021439
[01:05:19.756] iteration 20579 : model1 loss : 0.018484 model2 loss : 0.018132
[01:05:20.425] iteration 20580 : model1 loss : 0.020130 model2 loss : 0.019750
[01:05:21.085] iteration 20581 : model1 loss : 0.014398 model2 loss : 0.016140
[01:05:21.731] iteration 20582 : model1 loss : 0.022997 model2 loss : 0.022023
[01:05:22.387] iteration 20583 : model1 loss : 0.019947 model2 loss : 0.018299
[01:05:23.050] iteration 20584 : model1 loss : 0.035910 model2 loss : 0.032096
[01:05:23.719] iteration 20585 : model1 loss : 0.025648 model2 loss : 0.023572
[01:05:24.390] iteration 20586 : model1 loss : 0.023222 model2 loss : 0.021267
[01:05:25.060] iteration 20587 : model1 loss : 0.017985 model2 loss : 0.016162
[01:05:25.719] iteration 20588 : model1 loss : 0.017704 model2 loss : 0.015882
[01:05:26.380] iteration 20589 : model1 loss : 0.018331 model2 loss : 0.018930
[01:05:27.027] iteration 20590 : model1 loss : 0.020989 model2 loss : 0.020672
[01:05:27.689] iteration 20591 : model1 loss : 0.031317 model2 loss : 0.029107
[01:05:28.348] iteration 20592 : model1 loss : 0.019807 model2 loss : 0.018637
[01:05:28.999] iteration 20593 : model1 loss : 0.017779 model2 loss : 0.017306
[01:05:29.650] iteration 20594 : model1 loss : 0.017443 model2 loss : 0.017263
[01:05:30.317] iteration 20595 : model1 loss : 0.033058 model2 loss : 0.044187
[01:05:30.974] iteration 20596 : model1 loss : 0.023426 model2 loss : 0.022802
[01:05:31.634] iteration 20597 : model1 loss : 0.024763 model2 loss : 0.024403
[01:05:32.288] iteration 20598 : model1 loss : 0.054251 model2 loss : 0.055053
[01:05:32.941] iteration 20599 : model1 loss : 0.019680 model2 loss : 0.018250
[01:05:33.598] iteration 20600 : model1 loss : 0.018980 model2 loss : 0.018451
[01:05:51.397] iteration 20600 : model1_mean_dice : 0.873249 model1_mean_hd95 : 7.440146
[01:06:08.871] iteration 20600 : model2_mean_dice : 0.872613 model2_mean_hd95 : 4.952144
[01:06:09.542] iteration 20601 : model1 loss : 0.018593 model2 loss : 0.018406
[01:06:10.208] iteration 20602 : model1 loss : 0.020567 model2 loss : 0.020595
[01:06:10.857] iteration 20603 : model1 loss : 0.020783 model2 loss : 0.019064
[01:06:11.505] iteration 20604 : model1 loss : 0.027392 model2 loss : 0.026039
[01:06:12.157] iteration 20605 : model1 loss : 0.014533 model2 loss : 0.015438
[01:06:12.815] iteration 20606 : model1 loss : 0.018053 model2 loss : 0.019353
[01:06:13.477] iteration 20607 : model1 loss : 0.019384 model2 loss : 0.021745
[01:06:14.140] iteration 20608 : model1 loss : 0.019713 model2 loss : 0.021809
[01:06:14.802] iteration 20609 : model1 loss : 0.021468 model2 loss : 0.021362
[01:06:15.456] iteration 20610 : model1 loss : 0.030061 model2 loss : 0.032454
[01:06:16.112] iteration 20611 : model1 loss : 0.023498 model2 loss : 0.023553
[01:06:16.777] iteration 20612 : model1 loss : 0.090401 model2 loss : 0.069136
[01:06:17.428] iteration 20613 : model1 loss : 0.027906 model2 loss : 0.027887
[01:06:18.075] iteration 20614 : model1 loss : 0.018080 model2 loss : 0.017538
[01:06:18.744] iteration 20615 : model1 loss : 0.045085 model2 loss : 0.051332
[01:06:19.402] iteration 20616 : model1 loss : 0.017208 model2 loss : 0.017562
[01:06:20.085] iteration 20617 : model1 loss : 0.027710 model2 loss : 0.027319
[01:06:20.747] iteration 20618 : model1 loss : 0.041115 model2 loss : 0.038456
[01:06:21.409] iteration 20619 : model1 loss : 0.022099 model2 loss : 0.021582
[01:06:22.065] iteration 20620 : model1 loss : 0.017560 model2 loss : 0.016514
[01:06:22.722] iteration 20621 : model1 loss : 0.022818 model2 loss : 0.025029
[01:06:23.543] iteration 20622 : model1 loss : 0.020674 model2 loss : 0.023599
[01:06:24.221] iteration 20623 : model1 loss : 0.021772 model2 loss : 0.022027
[01:06:24.949] iteration 20624 : model1 loss : 0.021396 model2 loss : 0.021302
[01:06:25.658] iteration 20625 : model1 loss : 0.021335 model2 loss : 0.026372
[01:06:26.314] iteration 20626 : model1 loss : 0.039116 model2 loss : 0.037820
[01:06:26.966] iteration 20627 : model1 loss : 0.023105 model2 loss : 0.026886
[01:06:27.618] iteration 20628 : model1 loss : 0.026005 model2 loss : 0.024093
[01:06:28.276] iteration 20629 : model1 loss : 0.020782 model2 loss : 0.021690
[01:06:28.941] iteration 20630 : model1 loss : 0.021619 model2 loss : 0.022910
[01:06:29.593] iteration 20631 : model1 loss : 0.022736 model2 loss : 0.020692
[01:06:30.254] iteration 20632 : model1 loss : 0.039353 model2 loss : 0.045277
[01:06:30.901] iteration 20633 : model1 loss : 0.018850 model2 loss : 0.018799
[01:06:31.554] iteration 20634 : model1 loss : 0.022396 model2 loss : 0.020039
[01:06:32.214] iteration 20635 : model1 loss : 0.016502 model2 loss : 0.017147
[01:06:32.866] iteration 20636 : model1 loss : 0.022352 model2 loss : 0.021533
[01:06:33.526] iteration 20637 : model1 loss : 0.019354 model2 loss : 0.019641
[01:06:34.178] iteration 20638 : model1 loss : 0.015726 model2 loss : 0.016315
[01:06:34.822] iteration 20639 : model1 loss : 0.039172 model2 loss : 0.041754
[01:06:35.484] iteration 20640 : model1 loss : 0.027563 model2 loss : 0.026308
[01:06:36.144] iteration 20641 : model1 loss : 0.028466 model2 loss : 0.025299
[01:06:36.803] iteration 20642 : model1 loss : 0.033333 model2 loss : 0.025170
[01:06:37.448] iteration 20643 : model1 loss : 0.025124 model2 loss : 0.021283
[01:06:38.106] iteration 20644 : model1 loss : 0.032292 model2 loss : 0.030256
[01:06:38.795] iteration 20645 : model1 loss : 0.020253 model2 loss : 0.020462
[01:06:39.463] iteration 20646 : model1 loss : 0.014976 model2 loss : 0.014220
[01:06:40.108] iteration 20647 : model1 loss : 0.026033 model2 loss : 0.027418
[01:06:40.756] iteration 20648 : model1 loss : 0.016129 model2 loss : 0.015921
[01:06:41.410] iteration 20649 : model1 loss : 0.021012 model2 loss : 0.021048
[01:06:42.068] iteration 20650 : model1 loss : 0.021232 model2 loss : 0.021947
[01:06:42.771] iteration 20651 : model1 loss : 0.017115 model2 loss : 0.017167
[01:06:43.428] iteration 20652 : model1 loss : 0.018575 model2 loss : 0.022894
[01:06:44.092] iteration 20653 : model1 loss : 0.018844 model2 loss : 0.018847
[01:06:44.740] iteration 20654 : model1 loss : 0.019734 model2 loss : 0.018818
[01:06:45.407] iteration 20655 : model1 loss : 0.017908 model2 loss : 0.018137
[01:06:46.070] iteration 20656 : model1 loss : 0.017532 model2 loss : 0.016585
[01:06:46.729] iteration 20657 : model1 loss : 0.034231 model2 loss : 0.031430
[01:06:47.384] iteration 20658 : model1 loss : 0.022169 model2 loss : 0.020219
[01:06:48.039] iteration 20659 : model1 loss : 0.043349 model2 loss : 0.043346
[01:06:48.709] iteration 20660 : model1 loss : 0.020912 model2 loss : 0.019555
[01:06:49.365] iteration 20661 : model1 loss : 0.017443 model2 loss : 0.017159
[01:06:50.015] iteration 20662 : model1 loss : 0.016123 model2 loss : 0.016300
[01:06:50.673] iteration 20663 : model1 loss : 0.018106 model2 loss : 0.019241
[01:06:51.346] iteration 20664 : model1 loss : 0.034236 model2 loss : 0.029457
[01:06:51.998] iteration 20665 : model1 loss : 0.020037 model2 loss : 0.020101
[01:06:52.646] iteration 20666 : model1 loss : 0.034811 model2 loss : 0.022847
[01:06:53.292] iteration 20667 : model1 loss : 0.030228 model2 loss : 0.028597
[01:06:53.950] iteration 20668 : model1 loss : 0.022821 model2 loss : 0.021924
[01:06:54.608] iteration 20669 : model1 loss : 0.029113 model2 loss : 0.029657
[01:06:55.263] iteration 20670 : model1 loss : 0.024219 model2 loss : 0.025464
[01:06:55.929] iteration 20671 : model1 loss : 0.023579 model2 loss : 0.021930
[01:06:56.594] iteration 20672 : model1 loss : 0.021338 model2 loss : 0.019035
[01:06:57.260] iteration 20673 : model1 loss : 0.016754 model2 loss : 0.018208
[01:06:57.921] iteration 20674 : model1 loss : 0.023998 model2 loss : 0.020789
[01:06:58.600] iteration 20675 : model1 loss : 0.020274 model2 loss : 0.019612
[01:06:59.256] iteration 20676 : model1 loss : 0.013343 model2 loss : 0.013826
[01:06:59.916] iteration 20677 : model1 loss : 0.021918 model2 loss : 0.021660
[01:07:00.571] iteration 20678 : model1 loss : 0.024962 model2 loss : 0.028158
[01:07:01.239] iteration 20679 : model1 loss : 0.026397 model2 loss : 0.029753
[01:07:01.898] iteration 20680 : model1 loss : 0.022104 model2 loss : 0.024041
[01:07:02.553] iteration 20681 : model1 loss : 0.022661 model2 loss : 0.018516
[01:07:03.213] iteration 20682 : model1 loss : 0.015154 model2 loss : 0.017620
[01:07:03.868] iteration 20683 : model1 loss : 0.014095 model2 loss : 0.014186
[01:07:04.530] iteration 20684 : model1 loss : 0.021457 model2 loss : 0.019200
[01:07:05.192] iteration 20685 : model1 loss : 0.023166 model2 loss : 0.019552
[01:07:05.848] iteration 20686 : model1 loss : 0.021728 model2 loss : 0.018544
[01:07:06.500] iteration 20687 : model1 loss : 0.022220 model2 loss : 0.021172
[01:07:07.165] iteration 20688 : model1 loss : 0.017444 model2 loss : 0.018129
[01:07:07.826] iteration 20689 : model1 loss : 0.034599 model2 loss : 0.032277
[01:07:08.480] iteration 20690 : model1 loss : 0.016971 model2 loss : 0.015299
[01:07:09.130] iteration 20691 : model1 loss : 0.025212 model2 loss : 0.031169
[01:07:09.791] iteration 20692 : model1 loss : 0.023539 model2 loss : 0.024385
[01:07:10.442] iteration 20693 : model1 loss : 0.017096 model2 loss : 0.019732
[01:07:11.097] iteration 20694 : model1 loss : 0.016456 model2 loss : 0.016390
[01:07:11.761] iteration 20695 : model1 loss : 0.025718 model2 loss : 0.024441
[01:07:12.411] iteration 20696 : model1 loss : 0.060061 model2 loss : 0.053032
[01:07:13.066] iteration 20697 : model1 loss : 0.016115 model2 loss : 0.016297
[01:07:13.740] iteration 20698 : model1 loss : 0.019152 model2 loss : 0.020489
[01:07:14.403] iteration 20699 : model1 loss : 0.021463 model2 loss : 0.022634
[01:07:15.061] iteration 20700 : model1 loss : 0.019248 model2 loss : 0.020769
[01:07:15.758] iteration 20701 : model1 loss : 0.022365 model2 loss : 0.023330
[01:07:16.412] iteration 20702 : model1 loss : 0.023478 model2 loss : 0.024081
[01:07:17.065] iteration 20703 : model1 loss : 0.021909 model2 loss : 0.022978
[01:07:17.727] iteration 20704 : model1 loss : 0.019065 model2 loss : 0.018731
[01:07:18.387] iteration 20705 : model1 loss : 0.016850 model2 loss : 0.017764
[01:07:19.038] iteration 20706 : model1 loss : 0.021480 model2 loss : 0.019720
[01:07:19.689] iteration 20707 : model1 loss : 0.020820 model2 loss : 0.021246
[01:07:20.401] iteration 20708 : model1 loss : 0.017724 model2 loss : 0.022691
[01:07:21.068] iteration 20709 : model1 loss : 0.020110 model2 loss : 0.019883
[01:07:21.719] iteration 20710 : model1 loss : 0.021605 model2 loss : 0.021272
[01:07:22.366] iteration 20711 : model1 loss : 0.020572 model2 loss : 0.020314
[01:07:23.035] iteration 20712 : model1 loss : 0.169796 model2 loss : 0.165316
[01:07:23.693] iteration 20713 : model1 loss : 0.017136 model2 loss : 0.036444
[01:07:24.364] iteration 20714 : model1 loss : 0.020743 model2 loss : 0.024909
[01:07:25.014] iteration 20715 : model1 loss : 0.017205 model2 loss : 0.021066
[01:07:25.677] iteration 20716 : model1 loss : 0.023497 model2 loss : 0.020356
[01:07:26.331] iteration 20717 : model1 loss : 0.025208 model2 loss : 0.022216
[01:07:26.990] iteration 20718 : model1 loss : 0.024425 model2 loss : 0.027739
[01:07:27.636] iteration 20719 : model1 loss : 0.023429 model2 loss : 0.023134
[01:07:28.307] iteration 20720 : model1 loss : 0.025257 model2 loss : 0.023950
[01:07:28.969] iteration 20721 : model1 loss : 0.017497 model2 loss : 0.017466
[01:07:29.615] iteration 20722 : model1 loss : 0.021392 model2 loss : 0.019342
[01:07:30.272] iteration 20723 : model1 loss : 0.023315 model2 loss : 0.023595
[01:07:30.929] iteration 20724 : model1 loss : 0.021453 model2 loss : 0.019439
[01:07:31.582] iteration 20725 : model1 loss : 0.029427 model2 loss : 0.028926
[01:07:32.236] iteration 20726 : model1 loss : 0.023844 model2 loss : 0.021801
[01:07:32.911] iteration 20727 : model1 loss : 0.024718 model2 loss : 0.019733
[01:07:33.628] iteration 20728 : model1 loss : 0.020985 model2 loss : 0.021665
[01:07:34.281] iteration 20729 : model1 loss : 0.015133 model2 loss : 0.015694
[01:07:34.940] iteration 20730 : model1 loss : 0.029193 model2 loss : 0.025284
[01:07:35.598] iteration 20731 : model1 loss : 0.017059 model2 loss : 0.017314
[01:07:36.254] iteration 20732 : model1 loss : 0.022740 model2 loss : 0.024353
[01:07:36.906] iteration 20733 : model1 loss : 0.021042 model2 loss : 0.019076
[01:07:37.569] iteration 20734 : model1 loss : 0.039666 model2 loss : 0.035770
[01:07:38.241] iteration 20735 : model1 loss : 0.023802 model2 loss : 0.024549
[01:07:38.911] iteration 20736 : model1 loss : 0.018040 model2 loss : 0.016024
[01:07:39.567] iteration 20737 : model1 loss : 0.021028 model2 loss : 0.023135
[01:07:40.220] iteration 20738 : model1 loss : 0.022848 model2 loss : 0.021063
[01:07:40.876] iteration 20739 : model1 loss : 0.021461 model2 loss : 0.021434
[01:07:41.537] iteration 20740 : model1 loss : 0.020870 model2 loss : 0.019386
[01:07:42.191] iteration 20741 : model1 loss : 0.020757 model2 loss : 0.020862
[01:07:42.862] iteration 20742 : model1 loss : 0.022162 model2 loss : 0.023975
[01:07:43.511] iteration 20743 : model1 loss : 0.021206 model2 loss : 0.021642
[01:07:44.181] iteration 20744 : model1 loss : 0.064216 model2 loss : 0.053132
[01:07:44.854] iteration 20745 : model1 loss : 0.018546 model2 loss : 0.017411
[01:07:45.540] iteration 20746 : model1 loss : 0.016307 model2 loss : 0.016054
[01:07:46.202] iteration 20747 : model1 loss : 0.027748 model2 loss : 0.029120
[01:07:46.849] iteration 20748 : model1 loss : 0.016504 model2 loss : 0.019680
[01:07:47.490] iteration 20749 : model1 loss : 0.017601 model2 loss : 0.018073
[01:07:48.155] iteration 20750 : model1 loss : 0.016643 model2 loss : 0.017307
[01:07:48.858] iteration 20751 : model1 loss : 0.022356 model2 loss : 0.070637
[01:07:49.511] iteration 20752 : model1 loss : 0.021414 model2 loss : 0.021186
[01:07:50.170] iteration 20753 : model1 loss : 0.023692 model2 loss : 0.023712
[01:07:50.826] iteration 20754 : model1 loss : 0.022661 model2 loss : 0.021258
[01:07:51.492] iteration 20755 : model1 loss : 0.014035 model2 loss : 0.014040
[01:07:52.152] iteration 20756 : model1 loss : 0.030260 model2 loss : 0.026777
[01:07:52.806] iteration 20757 : model1 loss : 0.019634 model2 loss : 0.020026
[01:07:53.461] iteration 20758 : model1 loss : 0.036329 model2 loss : 0.037135
[01:07:54.113] iteration 20759 : model1 loss : 0.054446 model2 loss : 0.043295
[01:07:54.765] iteration 20760 : model1 loss : 0.019603 model2 loss : 0.021071
[01:07:55.437] iteration 20761 : model1 loss : 0.020604 model2 loss : 0.021100
[01:07:56.098] iteration 20762 : model1 loss : 0.020873 model2 loss : 0.021460
[01:07:56.750] iteration 20763 : model1 loss : 0.020986 model2 loss : 0.020063
[01:07:57.409] iteration 20764 : model1 loss : 0.023008 model2 loss : 0.024659
[01:07:58.079] iteration 20765 : model1 loss : 0.021930 model2 loss : 0.028098
[01:07:58.730] iteration 20766 : model1 loss : 0.015557 model2 loss : 0.018120
[01:07:59.394] iteration 20767 : model1 loss : 0.023468 model2 loss : 0.023499
[01:08:00.058] iteration 20768 : model1 loss : 0.017985 model2 loss : 0.022607
[01:08:00.718] iteration 20769 : model1 loss : 0.021285 model2 loss : 0.018247
[01:08:01.398] iteration 20770 : model1 loss : 0.021912 model2 loss : 0.021596
[01:08:02.057] iteration 20771 : model1 loss : 0.018411 model2 loss : 0.020566
[01:08:02.726] iteration 20772 : model1 loss : 0.027554 model2 loss : 0.026945
[01:08:03.385] iteration 20773 : model1 loss : 0.020729 model2 loss : 0.018445
[01:08:04.059] iteration 20774 : model1 loss : 0.016944 model2 loss : 0.017991
[01:08:04.731] iteration 20775 : model1 loss : 0.019934 model2 loss : 0.023314
[01:08:05.390] iteration 20776 : model1 loss : 0.024540 model2 loss : 0.025321
[01:08:06.069] iteration 20777 : model1 loss : 0.018827 model2 loss : 0.018797
[01:08:06.732] iteration 20778 : model1 loss : 0.017576 model2 loss : 0.017188
[01:08:07.380] iteration 20779 : model1 loss : 0.022081 model2 loss : 0.022364
[01:08:08.036] iteration 20780 : model1 loss : 0.020208 model2 loss : 0.025886
[01:08:08.705] iteration 20781 : model1 loss : 0.018724 model2 loss : 0.020066
[01:08:09.359] iteration 20782 : model1 loss : 0.025961 model2 loss : 0.022040
[01:08:10.011] iteration 20783 : model1 loss : 0.020805 model2 loss : 0.023933
[01:08:10.662] iteration 20784 : model1 loss : 0.021847 model2 loss : 0.022830
[01:08:11.335] iteration 20785 : model1 loss : 0.021561 model2 loss : 0.021535
[01:08:11.996] iteration 20786 : model1 loss : 0.015755 model2 loss : 0.015016
[01:08:12.667] iteration 20787 : model1 loss : 0.019416 model2 loss : 0.017822
[01:08:13.327] iteration 20788 : model1 loss : 0.017495 model2 loss : 0.018968
[01:08:13.990] iteration 20789 : model1 loss : 0.023472 model2 loss : 0.026728
[01:08:14.650] iteration 20790 : model1 loss : 0.018957 model2 loss : 0.020021
[01:08:15.315] iteration 20791 : model1 loss : 0.023680 model2 loss : 0.022600
[01:08:15.977] iteration 20792 : model1 loss : 0.019520 model2 loss : 0.019456
[01:08:16.631] iteration 20793 : model1 loss : 0.019224 model2 loss : 0.019836
[01:08:17.308] iteration 20794 : model1 loss : 0.018229 model2 loss : 0.019029
[01:08:17.973] iteration 20795 : model1 loss : 0.023379 model2 loss : 0.023730
[01:08:18.641] iteration 20796 : model1 loss : 0.016595 model2 loss : 0.016701
[01:08:19.309] iteration 20797 : model1 loss : 0.017370 model2 loss : 0.019972
[01:08:19.966] iteration 20798 : model1 loss : 0.024942 model2 loss : 0.027355
[01:08:20.629] iteration 20799 : model1 loss : 0.021075 model2 loss : 0.020409
[01:08:21.314] iteration 20800 : model1 loss : 0.020759 model2 loss : 0.019963
[01:08:38.962] iteration 20800 : model1_mean_dice : 0.872491 model1_mean_hd95 : 5.330549
[01:08:56.674] iteration 20800 : model2_mean_dice : 0.875477 model2_mean_hd95 : 6.369563
[01:08:57.354] iteration 20801 : model1 loss : 0.028507 model2 loss : 0.027386
[01:08:58.004] iteration 20802 : model1 loss : 0.020380 model2 loss : 0.026608
[01:08:58.665] iteration 20803 : model1 loss : 0.017743 model2 loss : 0.021769
[01:08:59.309] iteration 20804 : model1 loss : 0.035196 model2 loss : 0.031200
[01:08:59.965] iteration 20805 : model1 loss : 0.020904 model2 loss : 0.020674
[01:09:00.624] iteration 20806 : model1 loss : 0.025201 model2 loss : 0.027343
[01:09:01.277] iteration 20807 : model1 loss : 0.020995 model2 loss : 0.018510
[01:09:01.933] iteration 20808 : model1 loss : 0.022056 model2 loss : 0.021626
[01:09:02.591] iteration 20809 : model1 loss : 0.021102 model2 loss : 0.020926
[01:09:03.251] iteration 20810 : model1 loss : 0.031927 model2 loss : 0.029341
[01:09:03.890] iteration 20811 : model1 loss : 0.020303 model2 loss : 0.020304
[01:09:04.543] iteration 20812 : model1 loss : 0.018836 model2 loss : 0.016542
[01:09:05.193] iteration 20813 : model1 loss : 0.014920 model2 loss : 0.016204
[01:09:05.841] iteration 20814 : model1 loss : 0.024759 model2 loss : 0.023715
[01:09:06.507] iteration 20815 : model1 loss : 0.035100 model2 loss : 0.042248
[01:09:07.157] iteration 20816 : model1 loss : 0.023647 model2 loss : 0.022243
[01:09:07.813] iteration 20817 : model1 loss : 0.048550 model2 loss : 0.021489
[01:09:08.471] iteration 20818 : model1 loss : 0.023136 model2 loss : 0.024389
[01:09:09.121] iteration 20819 : model1 loss : 0.025536 model2 loss : 0.022917
[01:09:09.778] iteration 20820 : model1 loss : 0.034522 model2 loss : 0.035574
[01:09:10.422] iteration 20821 : model1 loss : 0.047257 model2 loss : 0.036916
[01:09:11.087] iteration 20822 : model1 loss : 0.021364 model2 loss : 0.019693
[01:09:11.734] iteration 20823 : model1 loss : 0.021441 model2 loss : 0.019377
[01:09:12.390] iteration 20824 : model1 loss : 0.019456 model2 loss : 0.019973
[01:09:13.036] iteration 20825 : model1 loss : 0.014732 model2 loss : 0.015418
[01:09:13.689] iteration 20826 : model1 loss : 0.020565 model2 loss : 0.020977
[01:09:14.364] iteration 20827 : model1 loss : 0.017934 model2 loss : 0.018019
[01:09:15.016] iteration 20828 : model1 loss : 0.026420 model2 loss : 0.025996
[01:09:15.665] iteration 20829 : model1 loss : 0.029086 model2 loss : 0.032281
[01:09:16.322] iteration 20830 : model1 loss : 0.016446 model2 loss : 0.016889
[01:09:16.975] iteration 20831 : model1 loss : 0.023472 model2 loss : 0.020429
[01:09:17.646] iteration 20832 : model1 loss : 0.015984 model2 loss : 0.015136
[01:09:18.299] iteration 20833 : model1 loss : 0.020538 model2 loss : 0.020533
[01:09:18.956] iteration 20834 : model1 loss : 0.021952 model2 loss : 0.021869
[01:09:19.622] iteration 20835 : model1 loss : 0.023120 model2 loss : 0.022488
[01:09:20.279] iteration 20836 : model1 loss : 0.015836 model2 loss : 0.015566
[01:09:20.932] iteration 20837 : model1 loss : 0.023566 model2 loss : 0.020965
[01:09:21.617] iteration 20838 : model1 loss : 0.024918 model2 loss : 0.023368
[01:09:22.286] iteration 20839 : model1 loss : 0.020150 model2 loss : 0.019514
[01:09:22.947] iteration 20840 : model1 loss : 0.022159 model2 loss : 0.023507
[01:09:23.602] iteration 20841 : model1 loss : 0.019931 model2 loss : 0.020589
[01:09:24.256] iteration 20842 : model1 loss : 0.023001 model2 loss : 0.020299
[01:09:24.913] iteration 20843 : model1 loss : 0.033084 model2 loss : 0.025070
[01:09:25.573] iteration 20844 : model1 loss : 0.026686 model2 loss : 0.030278
[01:09:26.237] iteration 20845 : model1 loss : 0.016018 model2 loss : 0.023061
[01:09:26.891] iteration 20846 : model1 loss : 0.022590 model2 loss : 0.021808
[01:09:27.553] iteration 20847 : model1 loss : 0.019160 model2 loss : 0.017433
[01:09:28.205] iteration 20848 : model1 loss : 0.023999 model2 loss : 0.024507
[01:09:28.865] iteration 20849 : model1 loss : 0.020352 model2 loss : 0.018420
[01:09:29.522] iteration 20850 : model1 loss : 0.016185 model2 loss : 0.016245
[01:09:30.204] iteration 20851 : model1 loss : 0.021788 model2 loss : 0.023702
[01:09:30.871] iteration 20852 : model1 loss : 0.019066 model2 loss : 0.018615
[01:09:31.536] iteration 20853 : model1 loss : 0.021690 model2 loss : 0.019876
[01:09:32.185] iteration 20854 : model1 loss : 0.025588 model2 loss : 0.025915
[01:09:32.841] iteration 20855 : model1 loss : 0.022322 model2 loss : 0.020502
[01:09:33.493] iteration 20856 : model1 loss : 0.016691 model2 loss : 0.016686
[01:09:34.144] iteration 20857 : model1 loss : 0.026883 model2 loss : 0.025791
[01:09:34.802] iteration 20858 : model1 loss : 0.017175 model2 loss : 0.015042
[01:09:35.495] iteration 20859 : model1 loss : 0.020237 model2 loss : 0.022587
[01:09:36.146] iteration 20860 : model1 loss : 0.019360 model2 loss : 0.020195
[01:09:36.796] iteration 20861 : model1 loss : 0.027097 model2 loss : 0.025579
[01:09:37.457] iteration 20862 : model1 loss : 0.018566 model2 loss : 0.018377
[01:09:38.121] iteration 20863 : model1 loss : 0.025592 model2 loss : 0.025313
[01:09:38.805] iteration 20864 : model1 loss : 0.026847 model2 loss : 0.025806
[01:09:39.465] iteration 20865 : model1 loss : 0.036182 model2 loss : 0.034497
[01:09:40.127] iteration 20866 : model1 loss : 0.016966 model2 loss : 0.018493
[01:09:40.784] iteration 20867 : model1 loss : 0.018528 model2 loss : 0.018291
[01:09:41.431] iteration 20868 : model1 loss : 0.022373 model2 loss : 0.018549
[01:09:42.086] iteration 20869 : model1 loss : 0.033864 model2 loss : 0.040543
[01:09:42.758] iteration 20870 : model1 loss : 0.021721 model2 loss : 0.020569
[01:09:43.403] iteration 20871 : model1 loss : 0.018844 model2 loss : 0.021902
[01:09:44.066] iteration 20872 : model1 loss : 0.020663 model2 loss : 0.019718
[01:09:44.719] iteration 20873 : model1 loss : 0.025208 model2 loss : 0.025357
[01:09:45.372] iteration 20874 : model1 loss : 0.023290 model2 loss : 0.025714
[01:09:46.035] iteration 20875 : model1 loss : 0.020308 model2 loss : 0.019321
[01:09:46.689] iteration 20876 : model1 loss : 0.020085 model2 loss : 0.020397
[01:09:47.351] iteration 20877 : model1 loss : 0.017499 model2 loss : 0.016208
[01:09:48.002] iteration 20878 : model1 loss : 0.014238 model2 loss : 0.015043
[01:09:48.652] iteration 20879 : model1 loss : 0.017297 model2 loss : 0.017512
[01:09:49.307] iteration 20880 : model1 loss : 0.016773 model2 loss : 0.017108
[01:09:49.953] iteration 20881 : model1 loss : 0.019210 model2 loss : 0.020925
[01:09:50.616] iteration 20882 : model1 loss : 0.018645 model2 loss : 0.018586
[01:09:51.275] iteration 20883 : model1 loss : 0.023219 model2 loss : 0.022098
[01:09:51.925] iteration 20884 : model1 loss : 0.021678 model2 loss : 0.021478
[01:09:52.598] iteration 20885 : model1 loss : 0.025362 model2 loss : 0.027984
[01:09:53.266] iteration 20886 : model1 loss : 0.017497 model2 loss : 0.018618
[01:09:53.927] iteration 20887 : model1 loss : 0.024593 model2 loss : 0.023155
[01:09:54.574] iteration 20888 : model1 loss : 0.018149 model2 loss : 0.018942
[01:09:55.237] iteration 20889 : model1 loss : 0.018002 model2 loss : 0.020575
[01:09:55.881] iteration 20890 : model1 loss : 0.027120 model2 loss : 0.026052
[01:09:56.543] iteration 20891 : model1 loss : 0.019285 model2 loss : 0.017528
[01:09:57.208] iteration 20892 : model1 loss : 0.020377 model2 loss : 0.019999
[01:09:57.857] iteration 20893 : model1 loss : 0.018443 model2 loss : 0.020523
[01:09:58.515] iteration 20894 : model1 loss : 0.022255 model2 loss : 0.026217
[01:09:59.163] iteration 20895 : model1 loss : 0.018005 model2 loss : 0.018766
[01:09:59.824] iteration 20896 : model1 loss : 0.023779 model2 loss : 0.023909
[01:10:00.493] iteration 20897 : model1 loss : 0.020632 model2 loss : 0.021601
[01:10:01.146] iteration 20898 : model1 loss : 0.027841 model2 loss : 0.027393
[01:10:01.805] iteration 20899 : model1 loss : 0.030724 model2 loss : 0.028651
[01:10:02.470] iteration 20900 : model1 loss : 0.020136 model2 loss : 0.020314
[01:10:03.159] iteration 20901 : model1 loss : 0.020757 model2 loss : 0.021272
[01:10:03.820] iteration 20902 : model1 loss : 0.015614 model2 loss : 0.015685
[01:10:04.475] iteration 20903 : model1 loss : 0.020455 model2 loss : 0.024622
[01:10:05.141] iteration 20904 : model1 loss : 0.020807 model2 loss : 0.021608
[01:10:05.812] iteration 20905 : model1 loss : 0.035703 model2 loss : 0.034269
[01:10:06.471] iteration 20906 : model1 loss : 0.021051 model2 loss : 0.019894
[01:10:07.133] iteration 20907 : model1 loss : 0.017458 model2 loss : 0.018418
[01:10:07.786] iteration 20908 : model1 loss : 0.021851 model2 loss : 0.021389
[01:10:08.432] iteration 20909 : model1 loss : 0.022469 model2 loss : 0.022976
[01:10:09.098] iteration 20910 : model1 loss : 0.025300 model2 loss : 0.024300
[01:10:09.756] iteration 20911 : model1 loss : 0.025650 model2 loss : 0.022654
[01:10:10.416] iteration 20912 : model1 loss : 0.019252 model2 loss : 0.018635
[01:10:11.073] iteration 20913 : model1 loss : 0.018556 model2 loss : 0.018145
[01:10:11.732] iteration 20914 : model1 loss : 0.027029 model2 loss : 0.026892
[01:10:12.399] iteration 20915 : model1 loss : 0.023398 model2 loss : 0.022927
[01:10:13.058] iteration 20916 : model1 loss : 0.020118 model2 loss : 0.020127
[01:10:13.726] iteration 20917 : model1 loss : 0.025733 model2 loss : 0.024768
[01:10:14.383] iteration 20918 : model1 loss : 0.020662 model2 loss : 0.022721
[01:10:15.043] iteration 20919 : model1 loss : 0.040635 model2 loss : 0.033298
[01:10:15.705] iteration 20920 : model1 loss : 0.019011 model2 loss : 0.018269
[01:10:16.362] iteration 20921 : model1 loss : 0.022692 model2 loss : 0.022170
[01:10:17.016] iteration 20922 : model1 loss : 0.022477 model2 loss : 0.021936
[01:10:17.674] iteration 20923 : model1 loss : 0.023513 model2 loss : 0.021624
[01:10:18.325] iteration 20924 : model1 loss : 0.016644 model2 loss : 0.015816
[01:10:18.976] iteration 20925 : model1 loss : 0.024657 model2 loss : 0.025151
[01:10:19.627] iteration 20926 : model1 loss : 0.017513 model2 loss : 0.018291
[01:10:20.286] iteration 20927 : model1 loss : 0.023314 model2 loss : 0.025988
[01:10:20.937] iteration 20928 : model1 loss : 0.024893 model2 loss : 0.024846
[01:10:21.608] iteration 20929 : model1 loss : 0.022988 model2 loss : 0.019346
[01:10:22.297] iteration 20930 : model1 loss : 0.024515 model2 loss : 0.021406
[01:10:22.948] iteration 20931 : model1 loss : 0.017448 model2 loss : 0.015511
[01:10:23.609] iteration 20932 : model1 loss : 0.021064 model2 loss : 0.020687
[01:10:24.258] iteration 20933 : model1 loss : 0.019384 model2 loss : 0.021862
[01:10:24.918] iteration 20934 : model1 loss : 0.029294 model2 loss : 0.031442
[01:10:25.583] iteration 20935 : model1 loss : 0.027715 model2 loss : 0.036338
[01:10:26.247] iteration 20936 : model1 loss : 0.014326 model2 loss : 0.015515
[01:10:26.915] iteration 20937 : model1 loss : 0.019418 model2 loss : 0.020031
[01:10:27.571] iteration 20938 : model1 loss : 0.017878 model2 loss : 0.018133
[01:10:28.236] iteration 20939 : model1 loss : 0.029461 model2 loss : 0.024937
[01:10:28.891] iteration 20940 : model1 loss : 0.019632 model2 loss : 0.018802
[01:10:29.544] iteration 20941 : model1 loss : 0.018710 model2 loss : 0.017894
[01:10:30.198] iteration 20942 : model1 loss : 0.020319 model2 loss : 0.020273
[01:10:30.851] iteration 20943 : model1 loss : 0.022369 model2 loss : 0.021411
[01:10:31.520] iteration 20944 : model1 loss : 0.017277 model2 loss : 0.017072
[01:10:32.174] iteration 20945 : model1 loss : 0.020593 model2 loss : 0.019434
[01:10:32.833] iteration 20946 : model1 loss : 0.020135 model2 loss : 0.018605
[01:10:33.487] iteration 20947 : model1 loss : 0.019616 model2 loss : 0.019917
[01:10:34.135] iteration 20948 : model1 loss : 0.028365 model2 loss : 0.024796
[01:10:34.797] iteration 20949 : model1 loss : 0.037394 model2 loss : 0.041102
[01:10:35.465] iteration 20950 : model1 loss : 0.021480 model2 loss : 0.020067
[01:10:36.165] iteration 20951 : model1 loss : 0.016348 model2 loss : 0.016159
[01:10:36.831] iteration 20952 : model1 loss : 0.020605 model2 loss : 0.021005
[01:10:37.488] iteration 20953 : model1 loss : 0.025013 model2 loss : 0.027063
[01:10:38.144] iteration 20954 : model1 loss : 0.021916 model2 loss : 0.017197
[01:10:38.803] iteration 20955 : model1 loss : 0.021870 model2 loss : 0.021373
[01:10:39.455] iteration 20956 : model1 loss : 0.014169 model2 loss : 0.015091
[01:10:40.103] iteration 20957 : model1 loss : 0.020911 model2 loss : 0.027358
[01:10:40.771] iteration 20958 : model1 loss : 0.020038 model2 loss : 0.022387
[01:10:41.436] iteration 20959 : model1 loss : 0.020550 model2 loss : 0.019673
[01:10:42.089] iteration 20960 : model1 loss : 0.025433 model2 loss : 0.030353
[01:10:42.743] iteration 20961 : model1 loss : 0.019092 model2 loss : 0.018460
[01:10:43.402] iteration 20962 : model1 loss : 0.020085 model2 loss : 0.018505
[01:10:44.068] iteration 20963 : model1 loss : 0.021086 model2 loss : 0.020844
[01:10:44.729] iteration 20964 : model1 loss : 0.018619 model2 loss : 0.017585
[01:10:45.398] iteration 20965 : model1 loss : 0.021909 model2 loss : 0.021002
[01:10:46.049] iteration 20966 : model1 loss : 0.021196 model2 loss : 0.018652
[01:10:46.695] iteration 20967 : model1 loss : 0.021257 model2 loss : 0.022731
[01:10:47.354] iteration 20968 : model1 loss : 0.029740 model2 loss : 0.028662
[01:10:48.008] iteration 20969 : model1 loss : 0.037667 model2 loss : 0.045476
[01:10:48.684] iteration 20970 : model1 loss : 0.019939 model2 loss : 0.022550
[01:10:49.357] iteration 20971 : model1 loss : 0.024415 model2 loss : 0.025178
[01:10:50.015] iteration 20972 : model1 loss : 0.022658 model2 loss : 0.023521
[01:10:50.670] iteration 20973 : model1 loss : 0.024633 model2 loss : 0.021166
[01:10:51.330] iteration 20974 : model1 loss : 0.024115 model2 loss : 0.025619
[01:10:51.979] iteration 20975 : model1 loss : 0.039518 model2 loss : 0.029133
[01:10:52.637] iteration 20976 : model1 loss : 0.019575 model2 loss : 0.019698
[01:10:53.300] iteration 20977 : model1 loss : 0.022229 model2 loss : 0.020089
[01:10:53.958] iteration 20978 : model1 loss : 0.015844 model2 loss : 0.013585
[01:10:54.608] iteration 20979 : model1 loss : 0.017436 model2 loss : 0.018193
[01:10:55.281] iteration 20980 : model1 loss : 0.014920 model2 loss : 0.015575
[01:10:55.939] iteration 20981 : model1 loss : 0.025034 model2 loss : 0.020179
[01:10:56.599] iteration 20982 : model1 loss : 0.057496 model2 loss : 0.054111
[01:10:57.262] iteration 20983 : model1 loss : 0.022737 model2 loss : 0.019696
[01:10:57.929] iteration 20984 : model1 loss : 0.025096 model2 loss : 0.021318
[01:10:58.593] iteration 20985 : model1 loss : 0.022148 model2 loss : 0.021496
[01:10:59.251] iteration 20986 : model1 loss : 0.018037 model2 loss : 0.019689
[01:10:59.914] iteration 20987 : model1 loss : 0.020913 model2 loss : 0.021003
[01:11:00.585] iteration 20988 : model1 loss : 0.017917 model2 loss : 0.019807
[01:11:01.248] iteration 20989 : model1 loss : 0.020072 model2 loss : 0.019262
[01:11:01.912] iteration 20990 : model1 loss : 0.023168 model2 loss : 0.025341
[01:11:02.572] iteration 20991 : model1 loss : 0.019214 model2 loss : 0.020404
[01:11:03.229] iteration 20992 : model1 loss : 0.017807 model2 loss : 0.018022
[01:11:03.878] iteration 20993 : model1 loss : 0.058878 model2 loss : 0.072939
[01:11:04.536] iteration 20994 : model1 loss : 0.012437 model2 loss : 0.012873
[01:11:05.197] iteration 20995 : model1 loss : 0.017596 model2 loss : 0.018734
[01:11:05.844] iteration 20996 : model1 loss : 0.023999 model2 loss : 0.021570
[01:11:06.502] iteration 20997 : model1 loss : 0.024148 model2 loss : 0.023651
[01:11:07.163] iteration 20998 : model1 loss : 0.018769 model2 loss : 0.016844
[01:11:07.817] iteration 20999 : model1 loss : 0.021290 model2 loss : 0.021477
[01:11:08.475] iteration 21000 : model1 loss : 0.020393 model2 loss : 0.021628
[01:11:25.977] iteration 21000 : model1_mean_dice : 0.876648 model1_mean_hd95 : 3.224509
[01:11:43.561] iteration 21000 : model2_mean_dice : 0.871959 model2_mean_hd95 : 5.390865
[01:11:43.621] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_21000.pth
[01:11:43.679] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_21000.pth
[01:11:44.351] iteration 21001 : model1 loss : 0.016385 model2 loss : 0.017462
[01:11:45.006] iteration 21002 : model1 loss : 0.019307 model2 loss : 0.017867
[01:11:45.674] iteration 21003 : model1 loss : 0.022873 model2 loss : 0.021809
[01:11:46.336] iteration 21004 : model1 loss : 0.033403 model2 loss : 0.024963
[01:11:46.988] iteration 21005 : model1 loss : 0.023841 model2 loss : 0.024861
[01:11:47.653] iteration 21006 : model1 loss : 0.020631 model2 loss : 0.018573
[01:11:48.306] iteration 21007 : model1 loss : 0.015826 model2 loss : 0.019197
[01:11:48.950] iteration 21008 : model1 loss : 0.020113 model2 loss : 0.019542
[01:11:49.604] iteration 21009 : model1 loss : 0.018354 model2 loss : 0.019131
[01:11:50.264] iteration 21010 : model1 loss : 0.030666 model2 loss : 0.026734
[01:11:50.910] iteration 21011 : model1 loss : 0.022345 model2 loss : 0.022168
[01:11:51.561] iteration 21012 : model1 loss : 0.021547 model2 loss : 0.022916
[01:11:52.220] iteration 21013 : model1 loss : 0.016005 model2 loss : 0.014100
[01:11:52.881] iteration 21014 : model1 loss : 0.022060 model2 loss : 0.027229
[01:11:53.524] iteration 21015 : model1 loss : 0.019485 model2 loss : 0.020841
[01:11:54.196] iteration 21016 : model1 loss : 0.019122 model2 loss : 0.020260
[01:11:54.876] iteration 21017 : model1 loss : 0.023387 model2 loss : 0.023186
[01:11:55.523] iteration 21018 : model1 loss : 0.021052 model2 loss : 0.021549
[01:11:56.180] iteration 21019 : model1 loss : 0.016306 model2 loss : 0.016700
[01:11:56.830] iteration 21020 : model1 loss : 0.025284 model2 loss : 0.023870
[01:11:57.494] iteration 21021 : model1 loss : 0.017991 model2 loss : 0.018097
[01:11:58.158] iteration 21022 : model1 loss : 0.020786 model2 loss : 0.021034
[01:11:58.830] iteration 21023 : model1 loss : 0.023148 model2 loss : 0.023082
[01:11:59.484] iteration 21024 : model1 loss : 0.017402 model2 loss : 0.018375
[01:12:00.130] iteration 21025 : model1 loss : 0.022526 model2 loss : 0.022713
[01:12:00.782] iteration 21026 : model1 loss : 0.028987 model2 loss : 0.033054
[01:12:01.444] iteration 21027 : model1 loss : 0.026632 model2 loss : 0.028302
[01:12:02.104] iteration 21028 : model1 loss : 0.018493 model2 loss : 0.019422
[01:12:02.770] iteration 21029 : model1 loss : 0.026613 model2 loss : 0.028248
[01:12:03.424] iteration 21030 : model1 loss : 0.023727 model2 loss : 0.023631
[01:12:04.077] iteration 21031 : model1 loss : 0.019262 model2 loss : 0.018207
[01:12:04.745] iteration 21032 : model1 loss : 0.020670 model2 loss : 0.020750
[01:12:05.393] iteration 21033 : model1 loss : 0.014978 model2 loss : 0.016208
[01:12:06.045] iteration 21034 : model1 loss : 0.021410 model2 loss : 0.021345
[01:12:06.704] iteration 21035 : model1 loss : 0.023690 model2 loss : 0.027816
[01:12:07.359] iteration 21036 : model1 loss : 0.015150 model2 loss : 0.017262
[01:12:08.023] iteration 21037 : model1 loss : 0.020874 model2 loss : 0.020391
[01:12:08.671] iteration 21038 : model1 loss : 0.019886 model2 loss : 0.020291
[01:12:09.333] iteration 21039 : model1 loss : 0.019030 model2 loss : 0.020994
[01:12:09.986] iteration 21040 : model1 loss : 0.019837 model2 loss : 0.021277
[01:12:10.643] iteration 21041 : model1 loss : 0.021895 model2 loss : 0.020495
[01:12:11.307] iteration 21042 : model1 loss : 0.016988 model2 loss : 0.020239
[01:12:11.963] iteration 21043 : model1 loss : 0.019582 model2 loss : 0.018243
[01:12:12.626] iteration 21044 : model1 loss : 0.016187 model2 loss : 0.017530
[01:12:13.285] iteration 21045 : model1 loss : 0.021814 model2 loss : 0.022560
[01:12:13.935] iteration 21046 : model1 loss : 0.021667 model2 loss : 0.020290
[01:12:14.596] iteration 21047 : model1 loss : 0.017577 model2 loss : 0.016963
[01:12:15.251] iteration 21048 : model1 loss : 0.021121 model2 loss : 0.022636
[01:12:15.904] iteration 21049 : model1 loss : 0.020981 model2 loss : 0.020126
[01:12:16.552] iteration 21050 : model1 loss : 0.019294 model2 loss : 0.018309
[01:12:17.242] iteration 21051 : model1 loss : 0.022021 model2 loss : 0.022878
[01:12:17.913] iteration 21052 : model1 loss : 0.019249 model2 loss : 0.016825
[01:12:18.564] iteration 21053 : model1 loss : 0.018212 model2 loss : 0.017008
[01:12:19.225] iteration 21054 : model1 loss : 0.017166 model2 loss : 0.016547
[01:12:19.875] iteration 21055 : model1 loss : 0.019038 model2 loss : 0.018680
[01:12:20.534] iteration 21056 : model1 loss : 0.030216 model2 loss : 0.029670
[01:12:21.196] iteration 21057 : model1 loss : 0.139040 model2 loss : 0.143415
[01:12:21.859] iteration 21058 : model1 loss : 0.021547 model2 loss : 0.021989
[01:12:22.527] iteration 21059 : model1 loss : 0.017987 model2 loss : 0.017584
[01:12:23.201] iteration 21060 : model1 loss : 0.023752 model2 loss : 0.026167
[01:12:23.861] iteration 21061 : model1 loss : 0.023898 model2 loss : 0.024100
[01:12:24.531] iteration 21062 : model1 loss : 0.017693 model2 loss : 0.020729
[01:12:25.192] iteration 21063 : model1 loss : 0.018152 model2 loss : 0.017905
[01:12:25.847] iteration 21064 : model1 loss : 0.026276 model2 loss : 0.027465
[01:12:26.503] iteration 21065 : model1 loss : 0.028528 model2 loss : 0.029370
[01:12:27.156] iteration 21066 : model1 loss : 0.052846 model2 loss : 0.058274
[01:12:27.814] iteration 21067 : model1 loss : 0.026539 model2 loss : 0.025161
[01:12:28.480] iteration 21068 : model1 loss : 0.024160 model2 loss : 0.023644
[01:12:29.142] iteration 21069 : model1 loss : 0.018182 model2 loss : 0.018416
[01:12:29.800] iteration 21070 : model1 loss : 0.021505 model2 loss : 0.022536
[01:12:30.469] iteration 21071 : model1 loss : 0.017211 model2 loss : 0.018414
[01:12:31.134] iteration 21072 : model1 loss : 0.027479 model2 loss : 0.029979
[01:12:31.799] iteration 21073 : model1 loss : 0.020268 model2 loss : 0.021181
[01:12:32.474] iteration 21074 : model1 loss : 0.017784 model2 loss : 0.019100
[01:12:33.160] iteration 21075 : model1 loss : 0.020939 model2 loss : 0.020185
[01:12:33.820] iteration 21076 : model1 loss : 0.020495 model2 loss : 0.022370
[01:12:34.479] iteration 21077 : model1 loss : 0.016359 model2 loss : 0.015923
[01:12:35.134] iteration 21078 : model1 loss : 0.022970 model2 loss : 0.019974
[01:12:35.786] iteration 21079 : model1 loss : 0.017584 model2 loss : 0.017867
[01:12:36.434] iteration 21080 : model1 loss : 0.021888 model2 loss : 0.022506
[01:12:37.099] iteration 21081 : model1 loss : 0.026771 model2 loss : 0.025476
[01:12:37.756] iteration 21082 : model1 loss : 0.024539 model2 loss : 0.024434
[01:12:38.434] iteration 21083 : model1 loss : 0.020687 model2 loss : 0.021627
[01:12:39.089] iteration 21084 : model1 loss : 0.016035 model2 loss : 0.017323
[01:12:39.736] iteration 21085 : model1 loss : 0.037558 model2 loss : 0.036763
[01:12:40.383] iteration 21086 : model1 loss : 0.041827 model2 loss : 0.040814
[01:12:41.053] iteration 21087 : model1 loss : 0.024204 model2 loss : 0.025658
[01:12:41.709] iteration 21088 : model1 loss : 0.069140 model2 loss : 0.048699
[01:12:42.377] iteration 21089 : model1 loss : 0.018141 model2 loss : 0.019172
[01:12:43.029] iteration 21090 : model1 loss : 0.021974 model2 loss : 0.020103
[01:12:43.690] iteration 21091 : model1 loss : 0.019154 model2 loss : 0.017131
[01:12:44.355] iteration 21092 : model1 loss : 0.149724 model2 loss : 0.144862
[01:12:45.007] iteration 21093 : model1 loss : 0.019733 model2 loss : 0.020464
[01:12:45.662] iteration 21094 : model1 loss : 0.017015 model2 loss : 0.017420
[01:12:46.329] iteration 21095 : model1 loss : 0.013386 model2 loss : 0.014569
[01:12:46.992] iteration 21096 : model1 loss : 0.020610 model2 loss : 0.018106
[01:12:47.659] iteration 21097 : model1 loss : 0.025644 model2 loss : 0.026508
[01:12:48.322] iteration 21098 : model1 loss : 0.028822 model2 loss : 0.028249
[01:12:48.974] iteration 21099 : model1 loss : 0.021944 model2 loss : 0.022380
[01:12:49.631] iteration 21100 : model1 loss : 0.019608 model2 loss : 0.021684
[01:12:50.324] iteration 21101 : model1 loss : 0.018745 model2 loss : 0.017305
[01:12:50.983] iteration 21102 : model1 loss : 0.022110 model2 loss : 0.020832
[01:12:51.631] iteration 21103 : model1 loss : 0.013833 model2 loss : 0.012597
[01:12:52.286] iteration 21104 : model1 loss : 0.031205 model2 loss : 0.025582
[01:12:52.942] iteration 21105 : model1 loss : 0.017444 model2 loss : 0.018423
[01:12:53.598] iteration 21106 : model1 loss : 0.021557 model2 loss : 0.022309
[01:12:54.262] iteration 21107 : model1 loss : 0.017712 model2 loss : 0.017601
[01:12:54.920] iteration 21108 : model1 loss : 0.021057 model2 loss : 0.019529
[01:12:55.584] iteration 21109 : model1 loss : 0.013784 model2 loss : 0.014216
[01:12:56.233] iteration 21110 : model1 loss : 0.020846 model2 loss : 0.021228
[01:12:56.892] iteration 21111 : model1 loss : 0.020078 model2 loss : 0.019381
[01:12:57.547] iteration 21112 : model1 loss : 0.020597 model2 loss : 0.022100
[01:12:58.213] iteration 21113 : model1 loss : 0.024061 model2 loss : 0.024666
[01:12:58.875] iteration 21114 : model1 loss : 0.023694 model2 loss : 0.027172
[01:12:59.535] iteration 21115 : model1 loss : 0.021659 model2 loss : 0.019623
[01:13:00.236] iteration 21116 : model1 loss : 0.033854 model2 loss : 0.043383
[01:13:00.935] iteration 21117 : model1 loss : 0.023565 model2 loss : 0.024399
[01:13:01.592] iteration 21118 : model1 loss : 0.016635 model2 loss : 0.015419
[01:13:02.273] iteration 21119 : model1 loss : 0.020237 model2 loss : 0.022249
[01:13:02.982] iteration 21120 : model1 loss : 0.027218 model2 loss : 0.024684
[01:13:03.651] iteration 21121 : model1 loss : 0.023845 model2 loss : 0.023143
[01:13:04.337] iteration 21122 : model1 loss : 0.021288 model2 loss : 0.020849
[01:13:04.989] iteration 21123 : model1 loss : 0.019073 model2 loss : 0.020073
[01:13:05.650] iteration 21124 : model1 loss : 0.015361 model2 loss : 0.014464
[01:13:06.320] iteration 21125 : model1 loss : 0.018384 model2 loss : 0.018352
[01:13:06.968] iteration 21126 : model1 loss : 0.020989 model2 loss : 0.021079
[01:13:07.627] iteration 21127 : model1 loss : 0.013840 model2 loss : 0.015010
[01:13:08.286] iteration 21128 : model1 loss : 0.029972 model2 loss : 0.026979
[01:13:08.939] iteration 21129 : model1 loss : 0.030259 model2 loss : 0.028498
[01:13:09.614] iteration 21130 : model1 loss : 0.027680 model2 loss : 0.031383
[01:13:10.270] iteration 21131 : model1 loss : 0.021156 model2 loss : 0.020015
[01:13:10.929] iteration 21132 : model1 loss : 0.040849 model2 loss : 0.047027
[01:13:11.576] iteration 21133 : model1 loss : 0.018482 model2 loss : 0.017721
[01:13:12.228] iteration 21134 : model1 loss : 0.016703 model2 loss : 0.017073
[01:13:12.894] iteration 21135 : model1 loss : 0.021570 model2 loss : 0.022238
[01:13:13.549] iteration 21136 : model1 loss : 0.013247 model2 loss : 0.012467
[01:13:14.204] iteration 21137 : model1 loss : 0.026168 model2 loss : 0.026456
[01:13:14.855] iteration 21138 : model1 loss : 0.015462 model2 loss : 0.016626
[01:13:15.522] iteration 21139 : model1 loss : 0.019347 model2 loss : 0.018445
[01:13:16.182] iteration 21140 : model1 loss : 0.024182 model2 loss : 0.025194
[01:13:16.842] iteration 21141 : model1 loss : 0.021602 model2 loss : 0.021841
[01:13:17.504] iteration 21142 : model1 loss : 0.020551 model2 loss : 0.021753
[01:13:18.173] iteration 21143 : model1 loss : 0.030554 model2 loss : 0.024906
[01:13:18.832] iteration 21144 : model1 loss : 0.021973 model2 loss : 0.022288
[01:13:19.507] iteration 21145 : model1 loss : 0.019732 model2 loss : 0.016502
[01:13:20.169] iteration 21146 : model1 loss : 0.020806 model2 loss : 0.023063
[01:13:20.819] iteration 21147 : model1 loss : 0.021464 model2 loss : 0.020853
[01:13:21.486] iteration 21148 : model1 loss : 0.056711 model2 loss : 0.050314
[01:13:22.134] iteration 21149 : model1 loss : 0.023934 model2 loss : 0.024424
[01:13:22.785] iteration 21150 : model1 loss : 0.024386 model2 loss : 0.020009
[01:13:23.496] iteration 21151 : model1 loss : 0.015695 model2 loss : 0.016324
[01:13:24.162] iteration 21152 : model1 loss : 0.027386 model2 loss : 0.025177
[01:13:24.813] iteration 21153 : model1 loss : 0.020124 model2 loss : 0.020274
[01:13:25.460] iteration 21154 : model1 loss : 0.015461 model2 loss : 0.017288
[01:13:26.122] iteration 21155 : model1 loss : 0.017857 model2 loss : 0.018619
[01:13:26.778] iteration 21156 : model1 loss : 0.028650 model2 loss : 0.025378
[01:13:27.442] iteration 21157 : model1 loss : 0.019497 model2 loss : 0.021046
[01:13:28.096] iteration 21158 : model1 loss : 0.018247 model2 loss : 0.017121
[01:13:28.759] iteration 21159 : model1 loss : 0.022984 model2 loss : 0.023037
[01:13:29.433] iteration 21160 : model1 loss : 0.042512 model2 loss : 0.032667
[01:13:30.082] iteration 21161 : model1 loss : 0.023977 model2 loss : 0.023796
[01:13:30.742] iteration 21162 : model1 loss : 0.016986 model2 loss : 0.019149
[01:13:31.394] iteration 21163 : model1 loss : 0.017572 model2 loss : 0.017459
[01:13:32.052] iteration 21164 : model1 loss : 0.024480 model2 loss : 0.023973
[01:13:32.707] iteration 21165 : model1 loss : 0.023658 model2 loss : 0.023679
[01:13:33.355] iteration 21166 : model1 loss : 0.028676 model2 loss : 0.027513
[01:13:34.010] iteration 21167 : model1 loss : 0.019030 model2 loss : 0.018335
[01:13:34.676] iteration 21168 : model1 loss : 0.016358 model2 loss : 0.017080
[01:13:35.335] iteration 21169 : model1 loss : 0.018562 model2 loss : 0.016189
[01:13:35.981] iteration 21170 : model1 loss : 0.035243 model2 loss : 0.027761
[01:13:36.628] iteration 21171 : model1 loss : 0.018454 model2 loss : 0.016804
[01:13:37.291] iteration 21172 : model1 loss : 0.025805 model2 loss : 0.023031
[01:13:37.945] iteration 21173 : model1 loss : 0.025236 model2 loss : 0.025011
[01:13:38.628] iteration 21174 : model1 loss : 0.026173 model2 loss : 0.034384
[01:13:39.294] iteration 21175 : model1 loss : 0.017201 model2 loss : 0.018769
[01:13:39.946] iteration 21176 : model1 loss : 0.050665 model2 loss : 0.040656
[01:13:40.611] iteration 21177 : model1 loss : 0.017915 model2 loss : 0.018910
[01:13:41.285] iteration 21178 : model1 loss : 0.016466 model2 loss : 0.016932
[01:13:41.937] iteration 21179 : model1 loss : 0.020394 model2 loss : 0.020724
[01:13:42.601] iteration 21180 : model1 loss : 0.027249 model2 loss : 0.026695
[01:13:43.261] iteration 21181 : model1 loss : 0.015082 model2 loss : 0.015482
[01:13:43.910] iteration 21182 : model1 loss : 0.020754 model2 loss : 0.021935
[01:13:44.573] iteration 21183 : model1 loss : 0.023183 model2 loss : 0.023758
[01:13:45.228] iteration 21184 : model1 loss : 0.020113 model2 loss : 0.019950
[01:13:45.885] iteration 21185 : model1 loss : 0.021920 model2 loss : 0.021831
[01:13:46.546] iteration 21186 : model1 loss : 0.022915 model2 loss : 0.023085
[01:13:47.206] iteration 21187 : model1 loss : 0.018688 model2 loss : 0.017798
[01:13:47.858] iteration 21188 : model1 loss : 0.018312 model2 loss : 0.019113
[01:13:48.526] iteration 21189 : model1 loss : 0.017455 model2 loss : 0.019215
[01:13:49.193] iteration 21190 : model1 loss : 0.055317 model2 loss : 0.042998
[01:13:49.847] iteration 21191 : model1 loss : 0.018696 model2 loss : 0.019268
[01:13:50.507] iteration 21192 : model1 loss : 0.017314 model2 loss : 0.015724
[01:13:51.164] iteration 21193 : model1 loss : 0.024734 model2 loss : 0.025103
[01:13:51.823] iteration 21194 : model1 loss : 0.015539 model2 loss : 0.015285
[01:13:52.486] iteration 21195 : model1 loss : 0.020485 model2 loss : 0.017467
[01:13:53.134] iteration 21196 : model1 loss : 0.020123 model2 loss : 0.020628
[01:13:53.806] iteration 21197 : model1 loss : 0.019510 model2 loss : 0.020742
[01:13:54.473] iteration 21198 : model1 loss : 0.020019 model2 loss : 0.022830
[01:13:55.130] iteration 21199 : model1 loss : 0.021702 model2 loss : 0.022474
[01:13:55.790] iteration 21200 : model1 loss : 0.024466 model2 loss : 0.021981
[01:14:13.397] iteration 21200 : model1_mean_dice : 0.872020 model1_mean_hd95 : 8.446088
[01:14:31.010] iteration 21200 : model2_mean_dice : 0.875799 model2_mean_hd95 : 5.196050
[01:14:31.694] iteration 21201 : model1 loss : 0.019612 model2 loss : 0.019735
[01:14:32.349] iteration 21202 : model1 loss : 0.029372 model2 loss : 0.026342
[01:14:33.006] iteration 21203 : model1 loss : 0.022255 model2 loss : 0.023114
[01:14:33.649] iteration 21204 : model1 loss : 0.018898 model2 loss : 0.018198
[01:14:34.305] iteration 21205 : model1 loss : 0.019504 model2 loss : 0.020378
[01:14:34.975] iteration 21206 : model1 loss : 0.023088 model2 loss : 0.022507
[01:14:35.628] iteration 21207 : model1 loss : 0.020253 model2 loss : 0.019237
[01:14:36.283] iteration 21208 : model1 loss : 0.023310 model2 loss : 0.021538
[01:14:36.949] iteration 21209 : model1 loss : 0.016968 model2 loss : 0.016103
[01:14:37.597] iteration 21210 : model1 loss : 0.026703 model2 loss : 0.027261
[01:14:38.257] iteration 21211 : model1 loss : 0.023779 model2 loss : 0.023769
[01:14:38.937] iteration 21212 : model1 loss : 0.020296 model2 loss : 0.018496
[01:14:39.616] iteration 21213 : model1 loss : 0.046426 model2 loss : 0.047754
[01:14:40.275] iteration 21214 : model1 loss : 0.021498 model2 loss : 0.019137
[01:14:40.927] iteration 21215 : model1 loss : 0.019191 model2 loss : 0.019958
[01:14:41.588] iteration 21216 : model1 loss : 0.020660 model2 loss : 0.020573
[01:14:42.246] iteration 21217 : model1 loss : 0.018106 model2 loss : 0.017579
[01:14:42.911] iteration 21218 : model1 loss : 0.021334 model2 loss : 0.024111
[01:14:43.571] iteration 21219 : model1 loss : 0.021646 model2 loss : 0.020435
[01:14:44.223] iteration 21220 : model1 loss : 0.022407 model2 loss : 0.024432
[01:14:44.883] iteration 21221 : model1 loss : 0.024416 model2 loss : 0.024694
[01:14:45.540] iteration 21222 : model1 loss : 0.022863 model2 loss : 0.020845
[01:14:46.189] iteration 21223 : model1 loss : 0.017811 model2 loss : 0.020942
[01:14:46.834] iteration 21224 : model1 loss : 0.017478 model2 loss : 0.017953
[01:14:47.507] iteration 21225 : model1 loss : 0.032774 model2 loss : 0.033303
[01:14:48.163] iteration 21226 : model1 loss : 0.030431 model2 loss : 0.025511
[01:14:48.819] iteration 21227 : model1 loss : 0.027651 model2 loss : 0.024464
[01:14:49.470] iteration 21228 : model1 loss : 0.019963 model2 loss : 0.017858
[01:14:50.141] iteration 21229 : model1 loss : 0.018544 model2 loss : 0.018694
[01:14:50.790] iteration 21230 : model1 loss : 0.019906 model2 loss : 0.021106
[01:14:51.447] iteration 21231 : model1 loss : 0.028007 model2 loss : 0.027819
[01:14:52.102] iteration 21232 : model1 loss : 0.020544 model2 loss : 0.020552
[01:14:52.760] iteration 21233 : model1 loss : 0.019758 model2 loss : 0.021049
[01:14:53.430] iteration 21234 : model1 loss : 0.024408 model2 loss : 0.022296
[01:14:54.081] iteration 21235 : model1 loss : 0.018538 model2 loss : 0.019313
[01:14:54.741] iteration 21236 : model1 loss : 0.021677 model2 loss : 0.019853
[01:14:55.392] iteration 21237 : model1 loss : 0.020491 model2 loss : 0.019600
[01:14:56.043] iteration 21238 : model1 loss : 0.033893 model2 loss : 0.032106
[01:14:56.705] iteration 21239 : model1 loss : 0.021312 model2 loss : 0.020404
[01:14:57.360] iteration 21240 : model1 loss : 0.020628 model2 loss : 0.020384
[01:14:58.014] iteration 21241 : model1 loss : 0.020573 model2 loss : 0.019116
[01:14:58.664] iteration 21242 : model1 loss : 0.019647 model2 loss : 0.020496
[01:14:59.315] iteration 21243 : model1 loss : 0.044528 model2 loss : 0.035839
[01:14:59.972] iteration 21244 : model1 loss : 0.016965 model2 loss : 0.016652
[01:15:00.635] iteration 21245 : model1 loss : 0.021723 model2 loss : 0.018759
[01:15:01.290] iteration 21246 : model1 loss : 0.022394 model2 loss : 0.021430
[01:15:01.958] iteration 21247 : model1 loss : 0.020405 model2 loss : 0.019181
[01:15:02.629] iteration 21248 : model1 loss : 0.019037 model2 loss : 0.019353
[01:15:03.279] iteration 21249 : model1 loss : 0.016508 model2 loss : 0.016813
[01:15:03.926] iteration 21250 : model1 loss : 0.040072 model2 loss : 0.037318
[01:15:04.624] iteration 21251 : model1 loss : 0.014771 model2 loss : 0.014842
[01:15:05.313] iteration 21252 : model1 loss : 0.025261 model2 loss : 0.026919
[01:15:05.967] iteration 21253 : model1 loss : 0.016268 model2 loss : 0.017110
[01:15:06.644] iteration 21254 : model1 loss : 0.018671 model2 loss : 0.017064
[01:15:07.306] iteration 21255 : model1 loss : 0.022404 model2 loss : 0.021964
[01:15:07.960] iteration 21256 : model1 loss : 0.017891 model2 loss : 0.019178
[01:15:08.617] iteration 21257 : model1 loss : 0.063087 model2 loss : 0.044057
[01:15:09.279] iteration 21258 : model1 loss : 0.019570 model2 loss : 0.020036
[01:15:09.930] iteration 21259 : model1 loss : 0.019895 model2 loss : 0.020793
[01:15:10.589] iteration 21260 : model1 loss : 0.019382 model2 loss : 0.022190
[01:15:11.242] iteration 21261 : model1 loss : 0.016173 model2 loss : 0.016552
[01:15:11.896] iteration 21262 : model1 loss : 0.019410 model2 loss : 0.020101
[01:15:12.560] iteration 21263 : model1 loss : 0.029459 model2 loss : 0.030416
[01:15:13.227] iteration 21264 : model1 loss : 0.018807 model2 loss : 0.020499
[01:15:13.875] iteration 21265 : model1 loss : 0.030153 model2 loss : 0.026927
[01:15:14.542] iteration 21266 : model1 loss : 0.018195 model2 loss : 0.018229
[01:15:15.205] iteration 21267 : model1 loss : 0.016991 model2 loss : 0.016416
[01:15:15.871] iteration 21268 : model1 loss : 0.040227 model2 loss : 0.043380
[01:15:16.525] iteration 21269 : model1 loss : 0.020898 model2 loss : 0.018421
[01:15:17.190] iteration 21270 : model1 loss : 0.021883 model2 loss : 0.022107
[01:15:17.849] iteration 21271 : model1 loss : 0.023685 model2 loss : 0.021042
[01:15:18.512] iteration 21272 : model1 loss : 0.019741 model2 loss : 0.019922
[01:15:19.157] iteration 21273 : model1 loss : 0.020215 model2 loss : 0.020555
[01:15:19.826] iteration 21274 : model1 loss : 0.018999 model2 loss : 0.018686
[01:15:20.476] iteration 21275 : model1 loss : 0.022978 model2 loss : 0.024165
[01:15:21.146] iteration 21276 : model1 loss : 0.022545 model2 loss : 0.020380
[01:15:21.803] iteration 21277 : model1 loss : 0.023430 model2 loss : 0.020668
[01:15:22.456] iteration 21278 : model1 loss : 0.019320 model2 loss : 0.018510
[01:15:23.113] iteration 21279 : model1 loss : 0.020961 model2 loss : 0.021721
[01:15:23.767] iteration 21280 : model1 loss : 0.017759 model2 loss : 0.017069
[01:15:24.432] iteration 21281 : model1 loss : 0.029117 model2 loss : 0.030031
[01:15:25.101] iteration 21282 : model1 loss : 0.024219 model2 loss : 0.030895
[01:15:25.772] iteration 21283 : model1 loss : 0.016853 model2 loss : 0.017689
[01:15:26.427] iteration 21284 : model1 loss : 0.019592 model2 loss : 0.018618
[01:15:27.083] iteration 21285 : model1 loss : 0.023933 model2 loss : 0.022665
[01:15:27.744] iteration 21286 : model1 loss : 0.021571 model2 loss : 0.023952
[01:15:28.408] iteration 21287 : model1 loss : 0.021480 model2 loss : 0.022485
[01:15:29.060] iteration 21288 : model1 loss : 0.024745 model2 loss : 0.021120
[01:15:29.717] iteration 21289 : model1 loss : 0.026071 model2 loss : 0.027842
[01:15:30.385] iteration 21290 : model1 loss : 0.019586 model2 loss : 0.020541
[01:15:31.041] iteration 21291 : model1 loss : 0.030859 model2 loss : 0.030580
[01:15:31.703] iteration 21292 : model1 loss : 0.021316 model2 loss : 0.017496
[01:15:32.368] iteration 21293 : model1 loss : 0.018666 model2 loss : 0.019058
[01:15:33.028] iteration 21294 : model1 loss : 0.025654 model2 loss : 0.021137
[01:15:33.681] iteration 21295 : model1 loss : 0.023282 model2 loss : 0.022031
[01:15:34.347] iteration 21296 : model1 loss : 0.026823 model2 loss : 0.023641
[01:15:35.002] iteration 21297 : model1 loss : 0.015153 model2 loss : 0.015163
[01:15:35.648] iteration 21298 : model1 loss : 0.019737 model2 loss : 0.020966
[01:15:36.320] iteration 21299 : model1 loss : 0.019256 model2 loss : 0.018024
[01:15:36.979] iteration 21300 : model1 loss : 0.015496 model2 loss : 0.014887
[01:15:37.673] iteration 21301 : model1 loss : 0.020427 model2 loss : 0.019928
[01:15:38.331] iteration 21302 : model1 loss : 0.026878 model2 loss : 0.024612
[01:15:38.994] iteration 21303 : model1 loss : 0.018800 model2 loss : 0.019765
[01:15:39.651] iteration 21304 : model1 loss : 0.014069 model2 loss : 0.013616
[01:15:40.305] iteration 21305 : model1 loss : 0.019524 model2 loss : 0.018483
[01:15:40.957] iteration 21306 : model1 loss : 0.027299 model2 loss : 0.026003
[01:15:41.618] iteration 21307 : model1 loss : 0.020421 model2 loss : 0.021287
[01:15:42.267] iteration 21308 : model1 loss : 0.018618 model2 loss : 0.019290
[01:15:42.927] iteration 21309 : model1 loss : 0.023810 model2 loss : 0.022858
[01:15:43.581] iteration 21310 : model1 loss : 0.020471 model2 loss : 0.019383
[01:15:44.235] iteration 21311 : model1 loss : 0.018407 model2 loss : 0.018735
[01:15:44.895] iteration 21312 : model1 loss : 0.020003 model2 loss : 0.021466
[01:15:45.554] iteration 21313 : model1 loss : 0.020080 model2 loss : 0.017761
[01:15:46.210] iteration 21314 : model1 loss : 0.031246 model2 loss : 0.037611
[01:15:46.856] iteration 21315 : model1 loss : 0.018103 model2 loss : 0.017743
[01:15:47.511] iteration 21316 : model1 loss : 0.020339 model2 loss : 0.018218
[01:15:48.179] iteration 21317 : model1 loss : 0.024577 model2 loss : 0.022016
[01:15:48.841] iteration 21318 : model1 loss : 0.020417 model2 loss : 0.022317
[01:15:49.502] iteration 21319 : model1 loss : 0.021234 model2 loss : 0.020498
[01:15:50.151] iteration 21320 : model1 loss : 0.017992 model2 loss : 0.018537
[01:15:50.803] iteration 21321 : model1 loss : 0.020473 model2 loss : 0.019753
[01:15:51.472] iteration 21322 : model1 loss : 0.022789 model2 loss : 0.023789
[01:15:52.139] iteration 21323 : model1 loss : 0.014892 model2 loss : 0.013379
[01:15:52.790] iteration 21324 : model1 loss : 0.018341 model2 loss : 0.017008
[01:15:53.451] iteration 21325 : model1 loss : 0.019925 model2 loss : 0.020418
[01:15:54.112] iteration 21326 : model1 loss : 0.023830 model2 loss : 0.023824
[01:15:54.775] iteration 21327 : model1 loss : 0.023969 model2 loss : 0.019921
[01:15:55.437] iteration 21328 : model1 loss : 0.048364 model2 loss : 0.047414
[01:15:56.101] iteration 21329 : model1 loss : 0.030775 model2 loss : 0.023599
[01:15:56.755] iteration 21330 : model1 loss : 0.018226 model2 loss : 0.017500
[01:15:57.400] iteration 21331 : model1 loss : 0.015331 model2 loss : 0.017002
[01:15:58.065] iteration 21332 : model1 loss : 0.022311 model2 loss : 0.020969
[01:15:58.712] iteration 21333 : model1 loss : 0.017428 model2 loss : 0.018128
[01:15:59.377] iteration 21334 : model1 loss : 0.018102 model2 loss : 0.019332
[01:16:00.049] iteration 21335 : model1 loss : 0.021116 model2 loss : 0.020209
[01:16:00.704] iteration 21336 : model1 loss : 0.016586 model2 loss : 0.017437
[01:16:01.362] iteration 21337 : model1 loss : 0.017778 model2 loss : 0.017739
[01:16:02.009] iteration 21338 : model1 loss : 0.019296 model2 loss : 0.017942
[01:16:02.674] iteration 21339 : model1 loss : 0.020433 model2 loss : 0.024319
[01:16:03.338] iteration 21340 : model1 loss : 0.019506 model2 loss : 0.019445
[01:16:03.987] iteration 21341 : model1 loss : 0.021774 model2 loss : 0.023250
[01:16:04.661] iteration 21342 : model1 loss : 0.014516 model2 loss : 0.013949
[01:16:05.320] iteration 21343 : model1 loss : 0.023586 model2 loss : 0.026965
[01:16:05.972] iteration 21344 : model1 loss : 0.021934 model2 loss : 0.023152
[01:16:06.626] iteration 21345 : model1 loss : 0.030094 model2 loss : 0.027742
[01:16:07.284] iteration 21346 : model1 loss : 0.021809 model2 loss : 0.021910
[01:16:07.951] iteration 21347 : model1 loss : 0.029664 model2 loss : 0.025822
[01:16:08.603] iteration 21348 : model1 loss : 0.018014 model2 loss : 0.018015
[01:16:09.266] iteration 21349 : model1 loss : 0.144379 model2 loss : 0.145399
[01:16:09.918] iteration 21350 : model1 loss : 0.041451 model2 loss : 0.043876
[01:16:10.623] iteration 21351 : model1 loss : 0.025552 model2 loss : 0.023935
[01:16:11.284] iteration 21352 : model1 loss : 0.022837 model2 loss : 0.022665
[01:16:11.936] iteration 21353 : model1 loss : 0.017835 model2 loss : 0.018194
[01:16:12.614] iteration 21354 : model1 loss : 0.019202 model2 loss : 0.019506
[01:16:13.267] iteration 21355 : model1 loss : 0.051612 model2 loss : 0.043560
[01:16:13.922] iteration 21356 : model1 loss : 0.022128 model2 loss : 0.020140
[01:16:14.583] iteration 21357 : model1 loss : 0.029675 model2 loss : 0.024887
[01:16:15.237] iteration 21358 : model1 loss : 0.015605 model2 loss : 0.014308
[01:16:15.899] iteration 21359 : model1 loss : 0.020414 model2 loss : 0.018612
[01:16:16.551] iteration 21360 : model1 loss : 0.022881 model2 loss : 0.021558
[01:16:17.205] iteration 21361 : model1 loss : 0.018675 model2 loss : 0.016872
[01:16:17.857] iteration 21362 : model1 loss : 0.021171 model2 loss : 0.022387
[01:16:18.505] iteration 21363 : model1 loss : 0.017744 model2 loss : 0.015965
[01:16:19.163] iteration 21364 : model1 loss : 0.022014 model2 loss : 0.023029
[01:16:19.822] iteration 21365 : model1 loss : 0.020364 model2 loss : 0.019702
[01:16:20.482] iteration 21366 : model1 loss : 0.015353 model2 loss : 0.014854
[01:16:21.136] iteration 21367 : model1 loss : 0.019188 model2 loss : 0.019812
[01:16:21.777] iteration 21368 : model1 loss : 0.027330 model2 loss : 0.022895
[01:16:22.447] iteration 21369 : model1 loss : 0.023842 model2 loss : 0.025286
[01:16:23.096] iteration 21370 : model1 loss : 0.021679 model2 loss : 0.025570
[01:16:23.756] iteration 21371 : model1 loss : 0.024040 model2 loss : 0.023804
[01:16:24.440] iteration 21372 : model1 loss : 0.020080 model2 loss : 0.019019
[01:16:25.119] iteration 21373 : model1 loss : 0.018438 model2 loss : 0.017629
[01:16:25.788] iteration 21374 : model1 loss : 0.014750 model2 loss : 0.015662
[01:16:26.444] iteration 21375 : model1 loss : 0.016592 model2 loss : 0.015968
[01:16:27.107] iteration 21376 : model1 loss : 0.022183 model2 loss : 0.022365
[01:16:27.756] iteration 21377 : model1 loss : 0.022843 model2 loss : 0.022820
[01:16:28.401] iteration 21378 : model1 loss : 0.018108 model2 loss : 0.018766
[01:16:29.061] iteration 21379 : model1 loss : 0.019758 model2 loss : 0.019122
[01:16:29.703] iteration 21380 : model1 loss : 0.016375 model2 loss : 0.017078
[01:16:30.364] iteration 21381 : model1 loss : 0.023830 model2 loss : 0.020676
[01:16:31.022] iteration 21382 : model1 loss : 0.016489 model2 loss : 0.015664
[01:16:31.678] iteration 21383 : model1 loss : 0.023194 model2 loss : 0.020937
[01:16:32.325] iteration 21384 : model1 loss : 0.043795 model2 loss : 0.050007
[01:16:32.987] iteration 21385 : model1 loss : 0.024544 model2 loss : 0.024773
[01:16:33.648] iteration 21386 : model1 loss : 0.029291 model2 loss : 0.028597
[01:16:34.308] iteration 21387 : model1 loss : 0.025495 model2 loss : 0.031503
[01:16:34.960] iteration 21388 : model1 loss : 0.047188 model2 loss : 0.044291
[01:16:35.620] iteration 21389 : model1 loss : 0.015734 model2 loss : 0.016182
[01:16:36.268] iteration 21390 : model1 loss : 0.019637 model2 loss : 0.021847
[01:16:36.915] iteration 21391 : model1 loss : 0.033944 model2 loss : 0.026141
[01:16:37.579] iteration 21392 : model1 loss : 0.017444 model2 loss : 0.017895
[01:16:38.231] iteration 21393 : model1 loss : 0.024548 model2 loss : 0.029727
[01:16:38.882] iteration 21394 : model1 loss : 0.018943 model2 loss : 0.022956
[01:16:39.538] iteration 21395 : model1 loss : 0.019229 model2 loss : 0.018648
[01:16:40.202] iteration 21396 : model1 loss : 0.022602 model2 loss : 0.021541
[01:16:40.864] iteration 21397 : model1 loss : 0.017162 model2 loss : 0.017428
[01:16:41.519] iteration 21398 : model1 loss : 0.143405 model2 loss : 0.137662
[01:16:42.180] iteration 21399 : model1 loss : 0.016336 model2 loss : 0.016322
[01:16:42.837] iteration 21400 : model1 loss : 0.025069 model2 loss : 0.021176
[01:17:00.446] iteration 21400 : model1_mean_dice : 0.874834 model1_mean_hd95 : 5.098298
[01:17:17.928] iteration 21400 : model2_mean_dice : 0.876030 model2_mean_hd95 : 4.724832
[01:17:18.616] iteration 21401 : model1 loss : 0.018361 model2 loss : 0.017577
[01:17:19.267] iteration 21402 : model1 loss : 0.025851 model2 loss : 0.024948
[01:17:19.919] iteration 21403 : model1 loss : 0.017167 model2 loss : 0.016827
[01:17:20.591] iteration 21404 : model1 loss : 0.025039 model2 loss : 0.028432
[01:17:21.257] iteration 21405 : model1 loss : 0.020385 model2 loss : 0.020471
[01:17:21.905] iteration 21406 : model1 loss : 0.018186 model2 loss : 0.017130
[01:17:22.559] iteration 21407 : model1 loss : 0.021665 model2 loss : 0.021406
[01:17:23.533] iteration 21408 : model1 loss : 0.020972 model2 loss : 0.020740
[01:17:24.299] iteration 21409 : model1 loss : 0.016739 model2 loss : 0.020260
[01:17:25.163] iteration 21410 : model1 loss : 0.014463 model2 loss : 0.014780
[01:17:26.045] iteration 21411 : model1 loss : 0.025199 model2 loss : 0.019471
[01:17:26.873] iteration 21412 : model1 loss : 0.018154 model2 loss : 0.017549
[01:17:27.670] iteration 21413 : model1 loss : 0.023661 model2 loss : 0.024685
[01:17:28.363] iteration 21414 : model1 loss : 0.019690 model2 loss : 0.019871
[01:17:29.057] iteration 21415 : model1 loss : 0.024995 model2 loss : 0.024001
[01:17:29.733] iteration 21416 : model1 loss : 0.076236 model2 loss : 0.071454
[01:17:30.434] iteration 21417 : model1 loss : 0.019852 model2 loss : 0.019747
[01:17:31.117] iteration 21418 : model1 loss : 0.019484 model2 loss : 0.018026
[01:17:31.799] iteration 21419 : model1 loss : 0.016602 model2 loss : 0.017519
[01:17:32.506] iteration 21420 : model1 loss : 0.019995 model2 loss : 0.018928
[01:17:33.189] iteration 21421 : model1 loss : 0.021529 model2 loss : 0.024263
[01:17:33.873] iteration 21422 : model1 loss : 0.024106 model2 loss : 0.020716
[01:17:34.548] iteration 21423 : model1 loss : 0.020467 model2 loss : 0.021005
[01:17:35.225] iteration 21424 : model1 loss : 0.043018 model2 loss : 0.039120
[01:17:35.907] iteration 21425 : model1 loss : 0.014132 model2 loss : 0.014482
[01:17:36.582] iteration 21426 : model1 loss : 0.021963 model2 loss : 0.020894
[01:17:37.317] iteration 21427 : model1 loss : 0.017063 model2 loss : 0.018195
[01:17:38.003] iteration 21428 : model1 loss : 0.018613 model2 loss : 0.020278
[01:17:38.684] iteration 21429 : model1 loss : 0.020347 model2 loss : 0.019139
[01:17:39.385] iteration 21430 : model1 loss : 0.017891 model2 loss : 0.017571
[01:17:40.064] iteration 21431 : model1 loss : 0.016762 model2 loss : 0.015170
[01:17:40.758] iteration 21432 : model1 loss : 0.018655 model2 loss : 0.018381
[01:17:41.438] iteration 21433 : model1 loss : 0.023371 model2 loss : 0.021644
[01:17:42.138] iteration 21434 : model1 loss : 0.018964 model2 loss : 0.019723
[01:17:42.850] iteration 21435 : model1 loss : 0.024355 model2 loss : 0.021341
[01:17:43.527] iteration 21436 : model1 loss : 0.024286 model2 loss : 0.026003
[01:17:44.215] iteration 21437 : model1 loss : 0.032135 model2 loss : 0.027180
[01:17:44.892] iteration 21438 : model1 loss : 0.022230 model2 loss : 0.020259
[01:17:45.581] iteration 21439 : model1 loss : 0.024173 model2 loss : 0.022455
[01:17:46.269] iteration 21440 : model1 loss : 0.018525 model2 loss : 0.016054
[01:17:46.969] iteration 21441 : model1 loss : 0.035780 model2 loss : 0.026793
[01:17:47.679] iteration 21442 : model1 loss : 0.025463 model2 loss : 0.026562
[01:17:48.461] iteration 21443 : model1 loss : 0.020260 model2 loss : 0.019031
[01:17:49.192] iteration 21444 : model1 loss : 0.018249 model2 loss : 0.019357
[01:17:49.901] iteration 21445 : model1 loss : 0.018357 model2 loss : 0.022967
[01:17:50.644] iteration 21446 : model1 loss : 0.057749 model2 loss : 0.046353
[01:17:51.340] iteration 21447 : model1 loss : 0.027876 model2 loss : 0.026630
[01:17:52.078] iteration 21448 : model1 loss : 0.016160 model2 loss : 0.016788
[01:17:52.817] iteration 21449 : model1 loss : 0.024405 model2 loss : 0.023689
[01:17:53.507] iteration 21450 : model1 loss : 0.022365 model2 loss : 0.018097
[01:17:54.289] iteration 21451 : model1 loss : 0.019923 model2 loss : 0.019700
[01:17:55.029] iteration 21452 : model1 loss : 0.019462 model2 loss : 0.017973
[01:17:55.949] iteration 21453 : model1 loss : 0.018305 model2 loss : 0.018503
[01:17:56.641] iteration 21454 : model1 loss : 0.023107 model2 loss : 0.021824
[01:17:57.336] iteration 21455 : model1 loss : 0.022715 model2 loss : 0.024960
[01:17:58.009] iteration 21456 : model1 loss : 0.018740 model2 loss : 0.021351
[01:17:58.677] iteration 21457 : model1 loss : 0.016897 model2 loss : 0.016380
[01:17:59.373] iteration 21458 : model1 loss : 0.017368 model2 loss : 0.017908
[01:18:00.067] iteration 21459 : model1 loss : 0.018697 model2 loss : 0.019640
[01:18:00.738] iteration 21460 : model1 loss : 0.019407 model2 loss : 0.017772
[01:18:01.412] iteration 21461 : model1 loss : 0.017869 model2 loss : 0.018310
[01:18:02.071] iteration 21462 : model1 loss : 0.015929 model2 loss : 0.017990
[01:18:02.769] iteration 21463 : model1 loss : 0.015782 model2 loss : 0.017077
[01:18:03.453] iteration 21464 : model1 loss : 0.019835 model2 loss : 0.019919
[01:18:04.132] iteration 21465 : model1 loss : 0.014969 model2 loss : 0.015183
[01:18:04.795] iteration 21466 : model1 loss : 0.016841 model2 loss : 0.018327
[01:18:05.458] iteration 21467 : model1 loss : 0.036207 model2 loss : 0.045452
[01:18:06.139] iteration 21468 : model1 loss : 0.016197 model2 loss : 0.015328
[01:18:06.804] iteration 21469 : model1 loss : 0.016859 model2 loss : 0.018270
[01:18:07.495] iteration 21470 : model1 loss : 0.019681 model2 loss : 0.023539
[01:18:08.192] iteration 21471 : model1 loss : 0.020308 model2 loss : 0.019260
[01:18:08.879] iteration 21472 : model1 loss : 0.024046 model2 loss : 0.024230
[01:18:09.582] iteration 21473 : model1 loss : 0.020080 model2 loss : 0.019714
[01:18:10.245] iteration 21474 : model1 loss : 0.020252 model2 loss : 0.020182
[01:18:10.919] iteration 21475 : model1 loss : 0.020324 model2 loss : 0.019143
[01:18:11.582] iteration 21476 : model1 loss : 0.017491 model2 loss : 0.017280
[01:18:12.271] iteration 21477 : model1 loss : 0.020330 model2 loss : 0.021934
[01:18:12.978] iteration 21478 : model1 loss : 0.024376 model2 loss : 0.024002
[01:18:13.723] iteration 21479 : model1 loss : 0.023696 model2 loss : 0.026198
[01:18:14.460] iteration 21480 : model1 loss : 0.020164 model2 loss : 0.017248
[01:18:15.140] iteration 21481 : model1 loss : 0.019889 model2 loss : 0.018091
[01:18:15.806] iteration 21482 : model1 loss : 0.018937 model2 loss : 0.019375
[01:18:16.510] iteration 21483 : model1 loss : 0.032125 model2 loss : 0.026597
[01:18:17.213] iteration 21484 : model1 loss : 0.017683 model2 loss : 0.019001
[01:18:17.886] iteration 21485 : model1 loss : 0.023329 model2 loss : 0.025659
[01:18:18.573] iteration 21486 : model1 loss : 0.023091 model2 loss : 0.024928
[01:18:19.272] iteration 21487 : model1 loss : 0.018022 model2 loss : 0.016543
[01:18:19.935] iteration 21488 : model1 loss : 0.032133 model2 loss : 0.030057
[01:18:20.612] iteration 21489 : model1 loss : 0.140716 model2 loss : 0.140436
[01:18:21.290] iteration 21490 : model1 loss : 0.023395 model2 loss : 0.022054
[01:18:21.984] iteration 21491 : model1 loss : 0.023835 model2 loss : 0.022263
[01:18:22.681] iteration 21492 : model1 loss : 0.024250 model2 loss : 0.023876
[01:18:23.369] iteration 21493 : model1 loss : 0.020087 model2 loss : 0.022213
[01:18:24.037] iteration 21494 : model1 loss : 0.016875 model2 loss : 0.016318
[01:18:24.705] iteration 21495 : model1 loss : 0.025018 model2 loss : 0.025586
[01:18:25.384] iteration 21496 : model1 loss : 0.029658 model2 loss : 0.031595
[01:18:26.087] iteration 21497 : model1 loss : 0.018375 model2 loss : 0.018151
[01:18:26.806] iteration 21498 : model1 loss : 0.022028 model2 loss : 0.022714
[01:18:27.515] iteration 21499 : model1 loss : 0.026422 model2 loss : 0.021399
[01:18:28.202] iteration 21500 : model1 loss : 0.021644 model2 loss : 0.019836
[01:18:28.931] iteration 21501 : model1 loss : 0.018831 model2 loss : 0.018965
[01:18:29.620] iteration 21502 : model1 loss : 0.022633 model2 loss : 0.020376
[01:18:30.293] iteration 21503 : model1 loss : 0.018219 model2 loss : 0.021131
[01:18:30.961] iteration 21504 : model1 loss : 0.017014 model2 loss : 0.017380
[01:18:31.623] iteration 21505 : model1 loss : 0.022060 model2 loss : 0.021749
[01:18:32.284] iteration 21506 : model1 loss : 0.018788 model2 loss : 0.019496
[01:18:32.946] iteration 21507 : model1 loss : 0.018428 model2 loss : 0.018334
[01:18:33.609] iteration 21508 : model1 loss : 0.015616 model2 loss : 0.016054
[01:18:34.315] iteration 21509 : model1 loss : 0.022340 model2 loss : 0.020328
[01:18:35.093] iteration 21510 : model1 loss : 0.018323 model2 loss : 0.016716
[01:18:35.809] iteration 21511 : model1 loss : 0.021287 model2 loss : 0.021476
[01:18:36.530] iteration 21512 : model1 loss : 0.021894 model2 loss : 0.021196
[01:18:37.210] iteration 21513 : model1 loss : 0.020746 model2 loss : 0.022295
[01:18:37.881] iteration 21514 : model1 loss : 0.015258 model2 loss : 0.014731
[01:18:38.594] iteration 21515 : model1 loss : 0.041262 model2 loss : 0.037277
[01:18:39.264] iteration 21516 : model1 loss : 0.022767 model2 loss : 0.027126
[01:18:39.957] iteration 21517 : model1 loss : 0.023351 model2 loss : 0.020585
[01:18:40.650] iteration 21518 : model1 loss : 0.018336 model2 loss : 0.019068
[01:18:41.357] iteration 21519 : model1 loss : 0.019944 model2 loss : 0.018413
[01:18:42.031] iteration 21520 : model1 loss : 0.017002 model2 loss : 0.017137
[01:18:42.713] iteration 21521 : model1 loss : 0.024047 model2 loss : 0.023870
[01:18:43.384] iteration 21522 : model1 loss : 0.017083 model2 loss : 0.016579
[01:18:44.044] iteration 21523 : model1 loss : 0.020953 model2 loss : 0.020526
[01:18:44.712] iteration 21524 : model1 loss : 0.024684 model2 loss : 0.027005
[01:18:45.372] iteration 21525 : model1 loss : 0.018896 model2 loss : 0.021716
[01:18:46.058] iteration 21526 : model1 loss : 0.017676 model2 loss : 0.019062
[01:18:46.723] iteration 21527 : model1 loss : 0.017518 model2 loss : 0.017249
[01:18:47.446] iteration 21528 : model1 loss : 0.015340 model2 loss : 0.016654
[01:18:48.146] iteration 21529 : model1 loss : 0.017607 model2 loss : 0.019889
[01:18:48.833] iteration 21530 : model1 loss : 0.021886 model2 loss : 0.022074
[01:18:49.526] iteration 21531 : model1 loss : 0.019990 model2 loss : 0.023497
[01:18:50.199] iteration 21532 : model1 loss : 0.018402 model2 loss : 0.019200
[01:18:50.898] iteration 21533 : model1 loss : 0.016824 model2 loss : 0.018137
[01:18:51.586] iteration 21534 : model1 loss : 0.015349 model2 loss : 0.014674
[01:18:52.286] iteration 21535 : model1 loss : 0.038462 model2 loss : 0.039851
[01:18:52.958] iteration 21536 : model1 loss : 0.016688 model2 loss : 0.019718
[01:18:53.631] iteration 21537 : model1 loss : 0.039567 model2 loss : 0.035482
[01:18:54.296] iteration 21538 : model1 loss : 0.019608 model2 loss : 0.019873
[01:18:54.965] iteration 21539 : model1 loss : 0.014757 model2 loss : 0.015085
[01:18:55.633] iteration 21540 : model1 loss : 0.019288 model2 loss : 0.020615
[01:18:56.310] iteration 21541 : model1 loss : 0.022168 model2 loss : 0.021827
[01:18:56.975] iteration 21542 : model1 loss : 0.016883 model2 loss : 0.017002
[01:18:57.648] iteration 21543 : model1 loss : 0.018106 model2 loss : 0.017918
[01:18:58.318] iteration 21544 : model1 loss : 0.022721 model2 loss : 0.022516
[01:18:58.983] iteration 21545 : model1 loss : 0.015696 model2 loss : 0.015271
[01:18:59.648] iteration 21546 : model1 loss : 0.023606 model2 loss : 0.021793
[01:19:00.324] iteration 21547 : model1 loss : 0.018356 model2 loss : 0.020194
[01:19:00.992] iteration 21548 : model1 loss : 0.016513 model2 loss : 0.016851
[01:19:01.666] iteration 21549 : model1 loss : 0.023907 model2 loss : 0.024977
[01:19:02.344] iteration 21550 : model1 loss : 0.022375 model2 loss : 0.023147
[01:19:03.037] iteration 21551 : model1 loss : 0.014715 model2 loss : 0.015814
[01:19:03.697] iteration 21552 : model1 loss : 0.016785 model2 loss : 0.017655
[01:19:04.380] iteration 21553 : model1 loss : 0.013375 model2 loss : 0.014673
[01:19:05.039] iteration 21554 : model1 loss : 0.018920 model2 loss : 0.018185
[01:19:05.705] iteration 21555 : model1 loss : 0.019794 model2 loss : 0.019112
[01:19:06.390] iteration 21556 : model1 loss : 0.029386 model2 loss : 0.030020
[01:19:07.057] iteration 21557 : model1 loss : 0.050743 model2 loss : 0.042205
[01:19:07.734] iteration 21558 : model1 loss : 0.023016 model2 loss : 0.023112
[01:19:08.401] iteration 21559 : model1 loss : 0.021810 model2 loss : 0.019685
[01:19:09.069] iteration 21560 : model1 loss : 0.018011 model2 loss : 0.017884
[01:19:09.725] iteration 21561 : model1 loss : 0.023301 model2 loss : 0.020827
[01:19:10.404] iteration 21562 : model1 loss : 0.018215 model2 loss : 0.016741
[01:19:11.074] iteration 21563 : model1 loss : 0.020826 model2 loss : 0.018968
[01:19:11.781] iteration 21564 : model1 loss : 0.024540 model2 loss : 0.027756
[01:19:12.445] iteration 21565 : model1 loss : 0.017958 model2 loss : 0.019721
[01:19:13.120] iteration 21566 : model1 loss : 0.033938 model2 loss : 0.033377
[01:19:13.803] iteration 21567 : model1 loss : 0.038811 model2 loss : 0.036358
[01:19:14.472] iteration 21568 : model1 loss : 0.026247 model2 loss : 0.021422
[01:19:15.172] iteration 21569 : model1 loss : 0.022547 model2 loss : 0.032972
[01:19:15.875] iteration 21570 : model1 loss : 0.024784 model2 loss : 0.024766
[01:19:16.551] iteration 21571 : model1 loss : 0.018338 model2 loss : 0.019261
[01:19:17.238] iteration 21572 : model1 loss : 0.020986 model2 loss : 0.017688
[01:19:17.905] iteration 21573 : model1 loss : 0.016079 model2 loss : 0.016208
[01:19:18.599] iteration 21574 : model1 loss : 0.018932 model2 loss : 0.020990
[01:19:19.276] iteration 21575 : model1 loss : 0.015497 model2 loss : 0.015713
[01:19:19.950] iteration 21576 : model1 loss : 0.017131 model2 loss : 0.017739
[01:19:20.618] iteration 21577 : model1 loss : 0.019678 model2 loss : 0.021270
[01:19:21.307] iteration 21578 : model1 loss : 0.031550 model2 loss : 0.026535
[01:19:21.981] iteration 21579 : model1 loss : 0.025345 model2 loss : 0.026299
[01:19:22.672] iteration 21580 : model1 loss : 0.025910 model2 loss : 0.029362
[01:19:23.349] iteration 21581 : model1 loss : 0.018593 model2 loss : 0.020242
[01:19:24.006] iteration 21582 : model1 loss : 0.030634 model2 loss : 0.031548
[01:19:24.662] iteration 21583 : model1 loss : 0.018963 model2 loss : 0.019046
[01:19:25.334] iteration 21584 : model1 loss : 0.018315 model2 loss : 0.019791
[01:19:26.037] iteration 21585 : model1 loss : 0.020363 model2 loss : 0.021087
[01:19:26.728] iteration 21586 : model1 loss : 0.021018 model2 loss : 0.021944
[01:19:27.441] iteration 21587 : model1 loss : 0.021268 model2 loss : 0.019720
[01:19:28.369] iteration 21588 : model1 loss : 0.031897 model2 loss : 0.034579
[01:19:29.050] iteration 21589 : model1 loss : 0.040365 model2 loss : 0.038488
[01:19:29.711] iteration 21590 : model1 loss : 0.021285 model2 loss : 0.021681
[01:19:30.426] iteration 21591 : model1 loss : 0.018024 model2 loss : 0.020318
[01:19:31.149] iteration 21592 : model1 loss : 0.019450 model2 loss : 0.018976
[01:19:31.821] iteration 21593 : model1 loss : 0.018944 model2 loss : 0.019731
[01:19:32.507] iteration 21594 : model1 loss : 0.042385 model2 loss : 0.044844
[01:19:33.213] iteration 21595 : model1 loss : 0.022933 model2 loss : 0.020236
[01:19:33.903] iteration 21596 : model1 loss : 0.015868 model2 loss : 0.015643
[01:19:34.602] iteration 21597 : model1 loss : 0.020800 model2 loss : 0.023103
[01:19:35.342] iteration 21598 : model1 loss : 0.019030 model2 loss : 0.020442
[01:19:36.017] iteration 21599 : model1 loss : 0.029133 model2 loss : 0.026563
[01:19:36.840] iteration 21600 : model1 loss : 0.022329 model2 loss : 0.023733
[01:19:55.344] iteration 21600 : model1_mean_dice : 0.878279 model1_mean_hd95 : 4.174902
[01:20:14.952] iteration 21600 : model2_mean_dice : 0.876221 model2_mean_hd95 : 3.949694
[01:20:15.630] iteration 21601 : model1 loss : 0.021931 model2 loss : 0.021659
[01:20:16.283] iteration 21602 : model1 loss : 0.020226 model2 loss : 0.018445
[01:20:16.952] iteration 21603 : model1 loss : 0.021607 model2 loss : 0.019924
[01:20:17.652] iteration 21604 : model1 loss : 0.022205 model2 loss : 0.023323
[01:20:18.320] iteration 21605 : model1 loss : 0.031998 model2 loss : 0.037706
[01:20:18.986] iteration 21606 : model1 loss : 0.023888 model2 loss : 0.022974
[01:20:19.657] iteration 21607 : model1 loss : 0.017850 model2 loss : 0.023051
[01:20:20.354] iteration 21608 : model1 loss : 0.017726 model2 loss : 0.018018
[01:20:21.048] iteration 21609 : model1 loss : 0.036614 model2 loss : 0.041977
[01:20:21.732] iteration 21610 : model1 loss : 0.016613 model2 loss : 0.017305
[01:20:22.422] iteration 21611 : model1 loss : 0.025022 model2 loss : 0.027764
[01:20:23.093] iteration 21612 : model1 loss : 0.031269 model2 loss : 0.029232
[01:20:23.766] iteration 21613 : model1 loss : 0.020542 model2 loss : 0.021942
[01:20:24.433] iteration 21614 : model1 loss : 0.020959 model2 loss : 0.023207
[01:20:25.090] iteration 21615 : model1 loss : 0.020542 model2 loss : 0.021451
[01:20:25.761] iteration 21616 : model1 loss : 0.025555 model2 loss : 0.025065
[01:20:26.432] iteration 21617 : model1 loss : 0.019300 model2 loss : 0.020201
[01:20:27.119] iteration 21618 : model1 loss : 0.023199 model2 loss : 0.022758
[01:20:27.791] iteration 21619 : model1 loss : 0.021655 model2 loss : 0.021002
[01:20:28.461] iteration 21620 : model1 loss : 0.020196 model2 loss : 0.019857
[01:20:29.131] iteration 21621 : model1 loss : 0.023251 model2 loss : 0.023825
[01:20:29.820] iteration 21622 : model1 loss : 0.024320 model2 loss : 0.025670
[01:20:30.492] iteration 21623 : model1 loss : 0.014654 model2 loss : 0.014921
[01:20:31.168] iteration 21624 : model1 loss : 0.020421 model2 loss : 0.017675
[01:20:31.857] iteration 21625 : model1 loss : 0.029048 model2 loss : 0.022290
[01:20:32.551] iteration 21626 : model1 loss : 0.016826 model2 loss : 0.017467
[01:20:33.233] iteration 21627 : model1 loss : 0.141654 model2 loss : 0.141449
[01:20:33.898] iteration 21628 : model1 loss : 0.022928 model2 loss : 0.023073
[01:20:34.557] iteration 21629 : model1 loss : 0.022193 model2 loss : 0.024437
[01:20:35.211] iteration 21630 : model1 loss : 0.020131 model2 loss : 0.020077
[01:20:35.868] iteration 21631 : model1 loss : 0.020917 model2 loss : 0.022633
[01:20:36.538] iteration 21632 : model1 loss : 0.019117 model2 loss : 0.019347
[01:20:37.264] iteration 21633 : model1 loss : 0.020064 model2 loss : 0.020936
[01:20:37.940] iteration 21634 : model1 loss : 0.024501 model2 loss : 0.024375
[01:20:38.633] iteration 21635 : model1 loss : 0.015554 model2 loss : 0.014547
[01:20:39.304] iteration 21636 : model1 loss : 0.136433 model2 loss : 0.136659
[01:20:39.988] iteration 21637 : model1 loss : 0.022149 model2 loss : 0.022061
[01:20:40.675] iteration 21638 : model1 loss : 0.021956 model2 loss : 0.018897
[01:20:41.350] iteration 21639 : model1 loss : 0.018489 model2 loss : 0.021339
[01:20:42.051] iteration 21640 : model1 loss : 0.022391 model2 loss : 0.023005
[01:20:42.730] iteration 21641 : model1 loss : 0.026165 model2 loss : 0.026536
[01:20:43.414] iteration 21642 : model1 loss : 0.022430 model2 loss : 0.020375
[01:20:44.081] iteration 21643 : model1 loss : 0.019688 model2 loss : 0.020033
[01:20:44.748] iteration 21644 : model1 loss : 0.023641 model2 loss : 0.022079
[01:20:45.438] iteration 21645 : model1 loss : 0.021189 model2 loss : 0.022471
[01:20:46.106] iteration 21646 : model1 loss : 0.020740 model2 loss : 0.021762
[01:20:46.776] iteration 21647 : model1 loss : 0.019377 model2 loss : 0.018498
[01:20:47.449] iteration 21648 : model1 loss : 0.021635 model2 loss : 0.022132
[01:20:48.107] iteration 21649 : model1 loss : 0.026349 model2 loss : 0.028697
[01:20:48.766] iteration 21650 : model1 loss : 0.021772 model2 loss : 0.021649
[01:20:49.480] iteration 21651 : model1 loss : 0.015862 model2 loss : 0.014638
[01:20:50.144] iteration 21652 : model1 loss : 0.020013 model2 loss : 0.019724
[01:20:50.810] iteration 21653 : model1 loss : 0.019084 model2 loss : 0.017826
[01:20:51.482] iteration 21654 : model1 loss : 0.015715 model2 loss : 0.016199
[01:20:52.181] iteration 21655 : model1 loss : 0.019156 model2 loss : 0.018952
[01:20:52.888] iteration 21656 : model1 loss : 0.016382 model2 loss : 0.016547
[01:20:53.616] iteration 21657 : model1 loss : 0.020251 model2 loss : 0.020872
[01:20:54.367] iteration 21658 : model1 loss : 0.022705 model2 loss : 0.021158
[01:20:55.035] iteration 21659 : model1 loss : 0.024269 model2 loss : 0.027049
[01:20:55.705] iteration 21660 : model1 loss : 0.018374 model2 loss : 0.019637
[01:20:56.364] iteration 21661 : model1 loss : 0.024041 model2 loss : 0.022925
[01:20:57.027] iteration 21662 : model1 loss : 0.019230 model2 loss : 0.016010
[01:20:57.693] iteration 21663 : model1 loss : 0.018550 model2 loss : 0.018242
[01:20:58.359] iteration 21664 : model1 loss : 0.020355 model2 loss : 0.022049
[01:20:59.024] iteration 21665 : model1 loss : 0.020315 model2 loss : 0.019647
[01:20:59.691] iteration 21666 : model1 loss : 0.021512 model2 loss : 0.019091
[01:21:00.353] iteration 21667 : model1 loss : 0.021807 model2 loss : 0.021563
[01:21:01.024] iteration 21668 : model1 loss : 0.017187 model2 loss : 0.019682
[01:21:01.689] iteration 21669 : model1 loss : 0.017909 model2 loss : 0.022845
[01:21:02.369] iteration 21670 : model1 loss : 0.016486 model2 loss : 0.017297
[01:21:03.037] iteration 21671 : model1 loss : 0.018260 model2 loss : 0.017587
[01:21:03.751] iteration 21672 : model1 loss : 0.017991 model2 loss : 0.016066
[01:21:04.449] iteration 21673 : model1 loss : 0.026998 model2 loss : 0.030001
[01:21:05.135] iteration 21674 : model1 loss : 0.017061 model2 loss : 0.017189
[01:21:05.808] iteration 21675 : model1 loss : 0.018081 model2 loss : 0.018896
[01:21:06.490] iteration 21676 : model1 loss : 0.021978 model2 loss : 0.021531
[01:21:07.172] iteration 21677 : model1 loss : 0.022667 model2 loss : 0.025727
[01:21:07.855] iteration 21678 : model1 loss : 0.015321 model2 loss : 0.015017
[01:21:08.630] iteration 21679 : model1 loss : 0.025632 model2 loss : 0.025197
[01:21:09.320] iteration 21680 : model1 loss : 0.014730 model2 loss : 0.014963
[01:21:10.000] iteration 21681 : model1 loss : 0.021188 model2 loss : 0.023180
[01:21:10.702] iteration 21682 : model1 loss : 0.018547 model2 loss : 0.018279
[01:21:11.466] iteration 21683 : model1 loss : 0.022011 model2 loss : 0.024893
[01:21:12.328] iteration 21684 : model1 loss : 0.021822 model2 loss : 0.022438
[01:21:13.042] iteration 21685 : model1 loss : 0.017101 model2 loss : 0.017602
[01:21:13.710] iteration 21686 : model1 loss : 0.020052 model2 loss : 0.020649
[01:21:14.383] iteration 21687 : model1 loss : 0.024127 model2 loss : 0.023696
[01:21:15.079] iteration 21688 : model1 loss : 0.041366 model2 loss : 0.057676
[01:21:15.758] iteration 21689 : model1 loss : 0.021643 model2 loss : 0.021003
[01:21:16.431] iteration 21690 : model1 loss : 0.019281 model2 loss : 0.019286
[01:21:17.098] iteration 21691 : model1 loss : 0.018689 model2 loss : 0.017520
[01:21:17.768] iteration 21692 : model1 loss : 0.031339 model2 loss : 0.028563
[01:21:18.431] iteration 21693 : model1 loss : 0.019268 model2 loss : 0.019076
[01:21:19.090] iteration 21694 : model1 loss : 0.022474 model2 loss : 0.023838
[01:21:19.743] iteration 21695 : model1 loss : 0.022752 model2 loss : 0.021667
[01:21:20.416] iteration 21696 : model1 loss : 0.013533 model2 loss : 0.014403
[01:21:21.084] iteration 21697 : model1 loss : 0.024456 model2 loss : 0.024784
[01:21:21.739] iteration 21698 : model1 loss : 0.018497 model2 loss : 0.016614
[01:21:22.408] iteration 21699 : model1 loss : 0.016265 model2 loss : 0.016774
[01:21:23.163] iteration 21700 : model1 loss : 0.022453 model2 loss : 0.023315
[01:21:23.900] iteration 21701 : model1 loss : 0.020120 model2 loss : 0.020630
[01:21:24.594] iteration 21702 : model1 loss : 0.025909 model2 loss : 0.026269
[01:21:25.279] iteration 21703 : model1 loss : 0.020809 model2 loss : 0.020065
[01:21:25.942] iteration 21704 : model1 loss : 0.016337 model2 loss : 0.015260
[01:21:26.608] iteration 21705 : model1 loss : 0.016373 model2 loss : 0.019813
[01:21:27.296] iteration 21706 : model1 loss : 0.014245 model2 loss : 0.015776
[01:21:27.972] iteration 21707 : model1 loss : 0.021304 model2 loss : 0.020857
[01:21:28.621] iteration 21708 : model1 loss : 0.016299 model2 loss : 0.018841
[01:21:29.294] iteration 21709 : model1 loss : 0.017044 model2 loss : 0.017317
[01:21:29.959] iteration 21710 : model1 loss : 0.019233 model2 loss : 0.019060
[01:21:30.619] iteration 21711 : model1 loss : 0.018911 model2 loss : 0.018560
[01:21:31.287] iteration 21712 : model1 loss : 0.013915 model2 loss : 0.013992
[01:21:31.947] iteration 21713 : model1 loss : 0.015860 model2 loss : 0.016598
[01:21:32.618] iteration 21714 : model1 loss : 0.018204 model2 loss : 0.017452
[01:21:33.291] iteration 21715 : model1 loss : 0.019773 model2 loss : 0.018918
[01:21:33.956] iteration 21716 : model1 loss : 0.037130 model2 loss : 0.046148
[01:21:34.636] iteration 21717 : model1 loss : 0.031798 model2 loss : 0.029100
[01:21:35.301] iteration 21718 : model1 loss : 0.027156 model2 loss : 0.026124
[01:21:35.968] iteration 21719 : model1 loss : 0.020573 model2 loss : 0.020946
[01:21:36.636] iteration 21720 : model1 loss : 0.019734 model2 loss : 0.018590
[01:21:37.302] iteration 21721 : model1 loss : 0.021371 model2 loss : 0.023850
[01:21:37.973] iteration 21722 : model1 loss : 0.037253 model2 loss : 0.040332
[01:21:38.657] iteration 21723 : model1 loss : 0.017569 model2 loss : 0.018575
[01:21:39.368] iteration 21724 : model1 loss : 0.022880 model2 loss : 0.023442
[01:21:40.046] iteration 21725 : model1 loss : 0.061627 model2 loss : 0.056852
[01:21:40.710] iteration 21726 : model1 loss : 0.028690 model2 loss : 0.022703
[01:21:41.377] iteration 21727 : model1 loss : 0.019830 model2 loss : 0.018179
[01:21:42.046] iteration 21728 : model1 loss : 0.017760 model2 loss : 0.018389
[01:21:42.700] iteration 21729 : model1 loss : 0.014935 model2 loss : 0.015437
[01:21:43.376] iteration 21730 : model1 loss : 0.024638 model2 loss : 0.024687
[01:21:44.047] iteration 21731 : model1 loss : 0.024498 model2 loss : 0.023579
[01:21:44.717] iteration 21732 : model1 loss : 0.023169 model2 loss : 0.020836
[01:21:45.386] iteration 21733 : model1 loss : 0.017716 model2 loss : 0.019122
[01:21:46.066] iteration 21734 : model1 loss : 0.018826 model2 loss : 0.019397
[01:21:46.727] iteration 21735 : model1 loss : 0.019860 model2 loss : 0.020142
[01:21:47.397] iteration 21736 : model1 loss : 0.016129 model2 loss : 0.017429
[01:21:48.056] iteration 21737 : model1 loss : 0.024274 model2 loss : 0.023170
[01:21:48.723] iteration 21738 : model1 loss : 0.021402 model2 loss : 0.027036
[01:21:49.390] iteration 21739 : model1 loss : 0.012258 model2 loss : 0.011870
[01:21:50.047] iteration 21740 : model1 loss : 0.021564 model2 loss : 0.025249
[01:21:50.724] iteration 21741 : model1 loss : 0.024500 model2 loss : 0.023423
[01:21:51.385] iteration 21742 : model1 loss : 0.019067 model2 loss : 0.019111
[01:21:52.048] iteration 21743 : model1 loss : 0.015303 model2 loss : 0.017670
[01:21:52.732] iteration 21744 : model1 loss : 0.027453 model2 loss : 0.026299
[01:21:53.406] iteration 21745 : model1 loss : 0.021412 model2 loss : 0.020850
[01:21:54.070] iteration 21746 : model1 loss : 0.021160 model2 loss : 0.019463
[01:21:54.727] iteration 21747 : model1 loss : 0.021465 model2 loss : 0.024512
[01:21:55.392] iteration 21748 : model1 loss : 0.020468 model2 loss : 0.022421
[01:21:56.056] iteration 21749 : model1 loss : 0.023118 model2 loss : 0.024928
[01:21:56.723] iteration 21750 : model1 loss : 0.017537 model2 loss : 0.014802
[01:21:57.465] iteration 21751 : model1 loss : 0.020091 model2 loss : 0.022576
[01:21:58.123] iteration 21752 : model1 loss : 0.028201 model2 loss : 0.026036
[01:21:58.795] iteration 21753 : model1 loss : 0.018846 model2 loss : 0.019354
[01:21:59.461] iteration 21754 : model1 loss : 0.019271 model2 loss : 0.019734
[01:22:00.115] iteration 21755 : model1 loss : 0.029478 model2 loss : 0.027762
[01:22:00.793] iteration 21756 : model1 loss : 0.026682 model2 loss : 0.027217
[01:22:01.456] iteration 21757 : model1 loss : 0.033625 model2 loss : 0.028952
[01:22:02.125] iteration 21758 : model1 loss : 0.042238 model2 loss : 0.043487
[01:22:02.777] iteration 21759 : model1 loss : 0.025303 model2 loss : 0.021740
[01:22:03.445] iteration 21760 : model1 loss : 0.030710 model2 loss : 0.032021
[01:22:04.118] iteration 21761 : model1 loss : 0.022593 model2 loss : 0.025113
[01:22:04.784] iteration 21762 : model1 loss : 0.024630 model2 loss : 0.025316
[01:22:05.454] iteration 21763 : model1 loss : 0.024403 model2 loss : 0.024588
[01:22:06.132] iteration 21764 : model1 loss : 0.029950 model2 loss : 0.026814
[01:22:06.783] iteration 21765 : model1 loss : 0.016189 model2 loss : 0.017604
[01:22:07.447] iteration 21766 : model1 loss : 0.022715 model2 loss : 0.023048
[01:22:08.122] iteration 21767 : model1 loss : 0.017152 model2 loss : 0.018779
[01:22:08.785] iteration 21768 : model1 loss : 0.017002 model2 loss : 0.018344
[01:22:09.447] iteration 21769 : model1 loss : 0.017245 model2 loss : 0.019597
[01:22:10.114] iteration 21770 : model1 loss : 0.031537 model2 loss : 0.030728
[01:22:10.774] iteration 21771 : model1 loss : 0.022846 model2 loss : 0.021345
[01:22:11.444] iteration 21772 : model1 loss : 0.025651 model2 loss : 0.022794
[01:22:12.115] iteration 21773 : model1 loss : 0.024734 model2 loss : 0.025599
[01:22:12.775] iteration 21774 : model1 loss : 0.017884 model2 loss : 0.017288
[01:22:13.447] iteration 21775 : model1 loss : 0.021965 model2 loss : 0.018923
[01:22:14.121] iteration 21776 : model1 loss : 0.020686 model2 loss : 0.019212
[01:22:14.785] iteration 21777 : model1 loss : 0.021059 model2 loss : 0.022941
[01:22:15.452] iteration 21778 : model1 loss : 0.019207 model2 loss : 0.020768
[01:22:16.115] iteration 21779 : model1 loss : 0.015721 model2 loss : 0.016075
[01:22:16.774] iteration 21780 : model1 loss : 0.018194 model2 loss : 0.016752
[01:22:17.452] iteration 21781 : model1 loss : 0.021212 model2 loss : 0.028239
[01:22:18.107] iteration 21782 : model1 loss : 0.023539 model2 loss : 0.020636
[01:22:18.785] iteration 21783 : model1 loss : 0.018602 model2 loss : 0.018741
[01:22:19.446] iteration 21784 : model1 loss : 0.022888 model2 loss : 0.024224
[01:22:20.112] iteration 21785 : model1 loss : 0.016297 model2 loss : 0.017023
[01:22:20.786] iteration 21786 : model1 loss : 0.024923 model2 loss : 0.025435
[01:22:21.452] iteration 21787 : model1 loss : 0.022679 model2 loss : 0.022122
[01:22:22.112] iteration 21788 : model1 loss : 0.022037 model2 loss : 0.022281
[01:22:22.783] iteration 21789 : model1 loss : 0.045151 model2 loss : 0.039164
[01:22:23.460] iteration 21790 : model1 loss : 0.017671 model2 loss : 0.016549
[01:22:24.129] iteration 21791 : model1 loss : 0.014657 model2 loss : 0.014768
[01:22:24.796] iteration 21792 : model1 loss : 0.029273 model2 loss : 0.021721
[01:22:25.462] iteration 21793 : model1 loss : 0.018852 model2 loss : 0.020032
[01:22:26.118] iteration 21794 : model1 loss : 0.145335 model2 loss : 0.156375
[01:22:26.774] iteration 21795 : model1 loss : 0.020043 model2 loss : 0.023076
[01:22:27.458] iteration 21796 : model1 loss : 0.023073 model2 loss : 0.018835
[01:22:28.116] iteration 21797 : model1 loss : 0.017705 model2 loss : 0.017186
[01:22:28.776] iteration 21798 : model1 loss : 0.015751 model2 loss : 0.014344
[01:22:29.457] iteration 21799 : model1 loss : 0.025380 model2 loss : 0.021252
[01:22:30.128] iteration 21800 : model1 loss : 0.025329 model2 loss : 0.025950
[01:22:48.350] iteration 21800 : model1_mean_dice : 0.877098 model1_mean_hd95 : 4.385757
[01:23:06.360] iteration 21800 : model2_mean_dice : 0.875705 model2_mean_hd95 : 3.846938
[01:23:07.037] iteration 21801 : model1 loss : 0.018763 model2 loss : 0.018061
[01:23:07.702] iteration 21802 : model1 loss : 0.017992 model2 loss : 0.018216
[01:23:08.360] iteration 21803 : model1 loss : 0.032489 model2 loss : 0.033460
[01:23:09.022] iteration 21804 : model1 loss : 0.021754 model2 loss : 0.021320
[01:23:09.681] iteration 21805 : model1 loss : 0.021791 model2 loss : 0.021410
[01:23:10.335] iteration 21806 : model1 loss : 0.023012 model2 loss : 0.021015
[01:23:10.992] iteration 21807 : model1 loss : 0.017901 model2 loss : 0.021505
[01:23:11.646] iteration 21808 : model1 loss : 0.018732 model2 loss : 0.018373
[01:23:12.302] iteration 21809 : model1 loss : 0.019200 model2 loss : 0.019050
[01:23:12.971] iteration 21810 : model1 loss : 0.017965 model2 loss : 0.016404
[01:23:13.640] iteration 21811 : model1 loss : 0.019650 model2 loss : 0.023687
[01:23:14.305] iteration 21812 : model1 loss : 0.018737 model2 loss : 0.015101
[01:23:14.971] iteration 21813 : model1 loss : 0.016437 model2 loss : 0.016462
[01:23:15.623] iteration 21814 : model1 loss : 0.015048 model2 loss : 0.016139
[01:23:16.278] iteration 21815 : model1 loss : 0.017048 model2 loss : 0.016577
[01:23:16.929] iteration 21816 : model1 loss : 0.018210 model2 loss : 0.019607
[01:23:17.586] iteration 21817 : model1 loss : 0.018394 model2 loss : 0.020343
[01:23:18.246] iteration 21818 : model1 loss : 0.017928 model2 loss : 0.018378
[01:23:18.907] iteration 21819 : model1 loss : 0.019847 model2 loss : 0.020528
[01:23:19.570] iteration 21820 : model1 loss : 0.021403 model2 loss : 0.024676
[01:23:20.245] iteration 21821 : model1 loss : 0.021475 model2 loss : 0.020877
[01:23:20.903] iteration 21822 : model1 loss : 0.018660 model2 loss : 0.021067
[01:23:21.556] iteration 21823 : model1 loss : 0.016302 model2 loss : 0.018179
[01:23:22.222] iteration 21824 : model1 loss : 0.023638 model2 loss : 0.025989
[01:23:22.892] iteration 21825 : model1 loss : 0.023485 model2 loss : 0.023106
[01:23:23.548] iteration 21826 : model1 loss : 0.023519 model2 loss : 0.023855
[01:23:24.208] iteration 21827 : model1 loss : 0.020448 model2 loss : 0.023646
[01:23:24.858] iteration 21828 : model1 loss : 0.020253 model2 loss : 0.020796
[01:23:25.517] iteration 21829 : model1 loss : 0.029883 model2 loss : 0.024197
[01:23:26.177] iteration 21830 : model1 loss : 0.039014 model2 loss : 0.039832
[01:23:26.840] iteration 21831 : model1 loss : 0.019146 model2 loss : 0.017698
[01:23:27.495] iteration 21832 : model1 loss : 0.020174 model2 loss : 0.018247
[01:23:28.199] iteration 21833 : model1 loss : 0.021788 model2 loss : 0.022791
[01:23:28.864] iteration 21834 : model1 loss : 0.022839 model2 loss : 0.021428
[01:23:29.529] iteration 21835 : model1 loss : 0.015791 model2 loss : 0.015923
[01:23:30.193] iteration 21836 : model1 loss : 0.023139 model2 loss : 0.023595
[01:23:30.856] iteration 21837 : model1 loss : 0.016082 model2 loss : 0.015836
[01:23:31.518] iteration 21838 : model1 loss : 0.019448 model2 loss : 0.017756
[01:23:32.174] iteration 21839 : model1 loss : 0.027312 model2 loss : 0.021626
[01:23:32.832] iteration 21840 : model1 loss : 0.025150 model2 loss : 0.023940
[01:23:33.496] iteration 21841 : model1 loss : 0.018810 model2 loss : 0.021611
[01:23:34.171] iteration 21842 : model1 loss : 0.021225 model2 loss : 0.021678
[01:23:34.823] iteration 21843 : model1 loss : 0.015674 model2 loss : 0.016098
[01:23:35.484] iteration 21844 : model1 loss : 0.021721 model2 loss : 0.023187
[01:23:36.147] iteration 21845 : model1 loss : 0.020466 model2 loss : 0.020617
[01:23:36.809] iteration 21846 : model1 loss : 0.017711 model2 loss : 0.018327
[01:23:37.467] iteration 21847 : model1 loss : 0.016582 model2 loss : 0.016525
[01:23:38.130] iteration 21848 : model1 loss : 0.019289 model2 loss : 0.029315
[01:23:38.798] iteration 21849 : model1 loss : 0.022187 model2 loss : 0.022064
[01:23:39.463] iteration 21850 : model1 loss : 0.020289 model2 loss : 0.019248
[01:23:40.208] iteration 21851 : model1 loss : 0.024255 model2 loss : 0.025937
[01:23:40.866] iteration 21852 : model1 loss : 0.017178 model2 loss : 0.018406
[01:23:41.530] iteration 21853 : model1 loss : 0.024450 model2 loss : 0.021909
[01:23:42.202] iteration 21854 : model1 loss : 0.015993 model2 loss : 0.017075
[01:23:42.870] iteration 21855 : model1 loss : 0.023772 model2 loss : 0.024078
[01:23:43.534] iteration 21856 : model1 loss : 0.018712 model2 loss : 0.020916
[01:23:44.199] iteration 21857 : model1 loss : 0.019973 model2 loss : 0.019387
[01:23:44.863] iteration 21858 : model1 loss : 0.019132 model2 loss : 0.021256
[01:23:45.518] iteration 21859 : model1 loss : 0.026472 model2 loss : 0.025647
[01:23:46.191] iteration 21860 : model1 loss : 0.019310 model2 loss : 0.019436
[01:23:46.856] iteration 21861 : model1 loss : 0.014465 model2 loss : 0.015362
[01:23:47.529] iteration 21862 : model1 loss : 0.042622 model2 loss : 0.047853
[01:23:48.197] iteration 21863 : model1 loss : 0.020655 model2 loss : 0.022195
[01:23:48.863] iteration 21864 : model1 loss : 0.020233 model2 loss : 0.019065
[01:23:49.529] iteration 21865 : model1 loss : 0.017960 model2 loss : 0.019651
[01:23:50.199] iteration 21866 : model1 loss : 0.018045 model2 loss : 0.017773
[01:23:50.872] iteration 21867 : model1 loss : 0.020511 model2 loss : 0.017255
[01:23:51.548] iteration 21868 : model1 loss : 0.020676 model2 loss : 0.018725
[01:23:52.213] iteration 21869 : model1 loss : 0.016189 model2 loss : 0.017043
[01:23:52.882] iteration 21870 : model1 loss : 0.022353 model2 loss : 0.023141
[01:23:53.533] iteration 21871 : model1 loss : 0.021436 model2 loss : 0.020064
[01:23:54.201] iteration 21872 : model1 loss : 0.020537 model2 loss : 0.021750
[01:23:54.877] iteration 21873 : model1 loss : 0.026635 model2 loss : 0.027843
[01:23:55.536] iteration 21874 : model1 loss : 0.026542 model2 loss : 0.025785
[01:23:56.199] iteration 21875 : model1 loss : 0.020036 model2 loss : 0.020812
[01:23:56.868] iteration 21876 : model1 loss : 0.022519 model2 loss : 0.023266
[01:23:57.540] iteration 21877 : model1 loss : 0.022420 model2 loss : 0.023610
[01:23:58.216] iteration 21878 : model1 loss : 0.017801 model2 loss : 0.021245
[01:23:58.877] iteration 21879 : model1 loss : 0.020465 model2 loss : 0.024224
[01:23:59.538] iteration 21880 : model1 loss : 0.017763 model2 loss : 0.016350
[01:24:00.191] iteration 21881 : model1 loss : 0.018755 model2 loss : 0.020290
[01:24:00.859] iteration 21882 : model1 loss : 0.019917 model2 loss : 0.022606
[01:24:01.532] iteration 21883 : model1 loss : 0.020210 model2 loss : 0.018627
[01:24:02.188] iteration 21884 : model1 loss : 0.026102 model2 loss : 0.025299
[01:24:02.854] iteration 21885 : model1 loss : 0.017063 model2 loss : 0.017034
[01:24:03.533] iteration 21886 : model1 loss : 0.025884 model2 loss : 0.024566
[01:24:04.211] iteration 21887 : model1 loss : 0.021246 model2 loss : 0.020160
[01:24:04.869] iteration 21888 : model1 loss : 0.021404 model2 loss : 0.021318
[01:24:05.551] iteration 21889 : model1 loss : 0.016703 model2 loss : 0.015970
[01:24:06.215] iteration 21890 : model1 loss : 0.018506 model2 loss : 0.019516
[01:24:06.873] iteration 21891 : model1 loss : 0.022338 model2 loss : 0.022011
[01:24:07.556] iteration 21892 : model1 loss : 0.020429 model2 loss : 0.019666
[01:24:08.222] iteration 21893 : model1 loss : 0.022779 model2 loss : 0.022098
[01:24:08.878] iteration 21894 : model1 loss : 0.019865 model2 loss : 0.023122
[01:24:09.563] iteration 21895 : model1 loss : 0.038776 model2 loss : 0.057683
[01:24:10.225] iteration 21896 : model1 loss : 0.017625 model2 loss : 0.018049
[01:24:10.883] iteration 21897 : model1 loss : 0.018089 model2 loss : 0.019618
[01:24:11.561] iteration 21898 : model1 loss : 0.024473 model2 loss : 0.023033
[01:24:12.230] iteration 21899 : model1 loss : 0.021117 model2 loss : 0.022124
[01:24:12.898] iteration 21900 : model1 loss : 0.142343 model2 loss : 0.142381
[01:24:13.615] iteration 21901 : model1 loss : 0.018622 model2 loss : 0.017418
[01:24:14.290] iteration 21902 : model1 loss : 0.020687 model2 loss : 0.022007
[01:24:14.960] iteration 21903 : model1 loss : 0.018369 model2 loss : 0.019035
[01:24:15.620] iteration 21904 : model1 loss : 0.026029 model2 loss : 0.022761
[01:24:16.275] iteration 21905 : model1 loss : 0.019583 model2 loss : 0.019845
[01:24:16.950] iteration 21906 : model1 loss : 0.018608 model2 loss : 0.018376
[01:24:17.615] iteration 21907 : model1 loss : 0.014187 model2 loss : 0.015570
[01:24:18.283] iteration 21908 : model1 loss : 0.024951 model2 loss : 0.026405
[01:24:18.946] iteration 21909 : model1 loss : 0.018180 model2 loss : 0.018137
[01:24:19.607] iteration 21910 : model1 loss : 0.041212 model2 loss : 0.038239
[01:24:20.277] iteration 21911 : model1 loss : 0.037733 model2 loss : 0.040078
[01:24:20.934] iteration 21912 : model1 loss : 0.017113 model2 loss : 0.017051
[01:24:21.603] iteration 21913 : model1 loss : 0.020273 model2 loss : 0.021775
[01:24:22.273] iteration 21914 : model1 loss : 0.016923 model2 loss : 0.018664
[01:24:22.928] iteration 21915 : model1 loss : 0.020148 model2 loss : 0.019783
[01:24:23.598] iteration 21916 : model1 loss : 0.019166 model2 loss : 0.018639
[01:24:24.274] iteration 21917 : model1 loss : 0.019401 model2 loss : 0.020793
[01:24:24.945] iteration 21918 : model1 loss : 0.022401 model2 loss : 0.021499
[01:24:25.617] iteration 21919 : model1 loss : 0.035219 model2 loss : 0.041036
[01:24:26.285] iteration 21920 : model1 loss : 0.022825 model2 loss : 0.023053
[01:24:26.953] iteration 21921 : model1 loss : 0.018380 model2 loss : 0.017835
[01:24:27.608] iteration 21922 : model1 loss : 0.028605 model2 loss : 0.029446
[01:24:28.281] iteration 21923 : model1 loss : 0.017738 model2 loss : 0.018773
[01:24:28.955] iteration 21924 : model1 loss : 0.021961 model2 loss : 0.024802
[01:24:29.619] iteration 21925 : model1 loss : 0.025717 model2 loss : 0.024727
[01:24:30.292] iteration 21926 : model1 loss : 0.022445 model2 loss : 0.022688
[01:24:30.962] iteration 21927 : model1 loss : 0.018615 model2 loss : 0.018871
[01:24:31.620] iteration 21928 : model1 loss : 0.017512 model2 loss : 0.016691
[01:24:32.286] iteration 21929 : model1 loss : 0.017201 model2 loss : 0.017034
[01:24:32.962] iteration 21930 : model1 loss : 0.017239 model2 loss : 0.018275
[01:24:33.639] iteration 21931 : model1 loss : 0.017296 model2 loss : 0.017904
[01:24:34.305] iteration 21932 : model1 loss : 0.018739 model2 loss : 0.019948
[01:24:34.993] iteration 21933 : model1 loss : 0.019506 model2 loss : 0.017925
[01:24:35.664] iteration 21934 : model1 loss : 0.019622 model2 loss : 0.020296
[01:24:36.336] iteration 21935 : model1 loss : 0.018267 model2 loss : 0.020434
[01:24:36.992] iteration 21936 : model1 loss : 0.017596 model2 loss : 0.018793
[01:24:37.657] iteration 21937 : model1 loss : 0.019356 model2 loss : 0.021572
[01:24:38.319] iteration 21938 : model1 loss : 0.023247 model2 loss : 0.026610
[01:24:38.982] iteration 21939 : model1 loss : 0.021533 model2 loss : 0.023018
[01:24:39.644] iteration 21940 : model1 loss : 0.020494 model2 loss : 0.019004
[01:24:40.321] iteration 21941 : model1 loss : 0.016986 model2 loss : 0.018558
[01:24:40.977] iteration 21942 : model1 loss : 0.021281 model2 loss : 0.020861
[01:24:41.634] iteration 21943 : model1 loss : 0.021347 model2 loss : 0.021801
[01:24:42.292] iteration 21944 : model1 loss : 0.018582 model2 loss : 0.019108
[01:24:42.955] iteration 21945 : model1 loss : 0.017086 model2 loss : 0.016450
[01:24:43.655] iteration 21946 : model1 loss : 0.140950 model2 loss : 0.141674
[01:24:44.320] iteration 21947 : model1 loss : 0.061125 model2 loss : 0.062491
[01:24:44.988] iteration 21948 : model1 loss : 0.038193 model2 loss : 0.040512
[01:24:45.664] iteration 21949 : model1 loss : 0.020578 model2 loss : 0.021150
[01:24:46.326] iteration 21950 : model1 loss : 0.028674 model2 loss : 0.029638
[01:24:47.029] iteration 21951 : model1 loss : 0.023071 model2 loss : 0.022627
[01:24:47.691] iteration 21952 : model1 loss : 0.018212 model2 loss : 0.015671
[01:24:48.367] iteration 21953 : model1 loss : 0.027100 model2 loss : 0.023713
[01:24:49.031] iteration 21954 : model1 loss : 0.018055 model2 loss : 0.019951
[01:24:49.686] iteration 21955 : model1 loss : 0.023927 model2 loss : 0.023802
[01:24:50.354] iteration 21956 : model1 loss : 0.020636 model2 loss : 0.018967
[01:24:51.022] iteration 21957 : model1 loss : 0.015546 model2 loss : 0.015594
[01:24:51.690] iteration 21958 : model1 loss : 0.017797 model2 loss : 0.016763
[01:24:52.363] iteration 21959 : model1 loss : 0.018771 model2 loss : 0.021453
[01:24:53.024] iteration 21960 : model1 loss : 0.019719 model2 loss : 0.021810
[01:24:53.704] iteration 21961 : model1 loss : 0.014667 model2 loss : 0.014106
[01:24:54.374] iteration 21962 : model1 loss : 0.020378 model2 loss : 0.022418
[01:24:55.054] iteration 21963 : model1 loss : 0.026131 model2 loss : 0.029733
[01:24:55.722] iteration 21964 : model1 loss : 0.018517 model2 loss : 0.019337
[01:24:56.392] iteration 21965 : model1 loss : 0.021978 model2 loss : 0.021562
[01:24:57.057] iteration 21966 : model1 loss : 0.018658 model2 loss : 0.020056
[01:24:57.723] iteration 21967 : model1 loss : 0.019506 model2 loss : 0.018709
[01:24:58.393] iteration 21968 : model1 loss : 0.018073 model2 loss : 0.018739
[01:24:59.060] iteration 21969 : model1 loss : 0.017480 model2 loss : 0.017113
[01:24:59.730] iteration 21970 : model1 loss : 0.016285 model2 loss : 0.015891
[01:25:00.401] iteration 21971 : model1 loss : 0.025643 model2 loss : 0.023866
[01:25:01.067] iteration 21972 : model1 loss : 0.016417 model2 loss : 0.016159
[01:25:01.725] iteration 21973 : model1 loss : 0.016112 model2 loss : 0.016527
[01:25:02.393] iteration 21974 : model1 loss : 0.016861 model2 loss : 0.016149
[01:25:03.069] iteration 21975 : model1 loss : 0.017271 model2 loss : 0.019213
[01:25:03.738] iteration 21976 : model1 loss : 0.022477 model2 loss : 0.020860
[01:25:04.412] iteration 21977 : model1 loss : 0.017832 model2 loss : 0.017808
[01:25:05.073] iteration 21978 : model1 loss : 0.023837 model2 loss : 0.025131
[01:25:05.739] iteration 21979 : model1 loss : 0.020167 model2 loss : 0.020277
[01:25:06.399] iteration 21980 : model1 loss : 0.021534 model2 loss : 0.022464
[01:25:07.059] iteration 21981 : model1 loss : 0.018082 model2 loss : 0.016472
[01:25:07.721] iteration 21982 : model1 loss : 0.017107 model2 loss : 0.018297
[01:25:08.393] iteration 21983 : model1 loss : 0.023449 model2 loss : 0.025116
[01:25:09.066] iteration 21984 : model1 loss : 0.023213 model2 loss : 0.025540
[01:25:09.723] iteration 21985 : model1 loss : 0.017513 model2 loss : 0.018373
[01:25:10.383] iteration 21986 : model1 loss : 0.019765 model2 loss : 0.023172
[01:25:11.050] iteration 21987 : model1 loss : 0.140010 model2 loss : 0.139583
[01:25:11.709] iteration 21988 : model1 loss : 0.017915 model2 loss : 0.017292
[01:25:12.368] iteration 21989 : model1 loss : 0.019280 model2 loss : 0.022703
[01:25:13.038] iteration 21990 : model1 loss : 0.020376 model2 loss : 0.021289
[01:25:13.702] iteration 21991 : model1 loss : 0.021824 model2 loss : 0.023517
[01:25:14.368] iteration 21992 : model1 loss : 0.022690 model2 loss : 0.021608
[01:25:15.036] iteration 21993 : model1 loss : 0.021328 model2 loss : 0.022687
[01:25:15.717] iteration 21994 : model1 loss : 0.023608 model2 loss : 0.027681
[01:25:16.426] iteration 21995 : model1 loss : 0.024133 model2 loss : 0.023078
[01:25:17.091] iteration 21996 : model1 loss : 0.022412 model2 loss : 0.027876
[01:25:17.765] iteration 21997 : model1 loss : 0.023819 model2 loss : 0.024707
[01:25:18.428] iteration 21998 : model1 loss : 0.016615 model2 loss : 0.016300
[01:25:19.097] iteration 21999 : model1 loss : 0.027550 model2 loss : 0.026574
[01:25:19.760] iteration 22000 : model1 loss : 0.023262 model2 loss : 0.028601
[01:25:38.040] iteration 22000 : model1_mean_dice : 0.880540 model1_mean_hd95 : 5.084406
[01:25:56.303] iteration 22000 : model2_mean_dice : 0.877904 model2_mean_hd95 : 4.808161
[01:25:56.994] iteration 22001 : model1 loss : 0.021543 model2 loss : 0.020243
[01:25:57.640] iteration 22002 : model1 loss : 0.023399 model2 loss : 0.024515
[01:25:58.303] iteration 22003 : model1 loss : 0.022516 model2 loss : 0.026302
[01:25:58.963] iteration 22004 : model1 loss : 0.022902 model2 loss : 0.026244
[01:25:59.620] iteration 22005 : model1 loss : 0.017694 model2 loss : 0.017703
[01:26:00.277] iteration 22006 : model1 loss : 0.024098 model2 loss : 0.026279
[01:26:00.930] iteration 22007 : model1 loss : 0.014885 model2 loss : 0.015202
[01:26:01.584] iteration 22008 : model1 loss : 0.016662 model2 loss : 0.016741
[01:26:02.254] iteration 22009 : model1 loss : 0.023022 model2 loss : 0.026631
[01:26:02.910] iteration 22010 : model1 loss : 0.021950 model2 loss : 0.021451
[01:26:03.568] iteration 22011 : model1 loss : 0.023029 model2 loss : 0.022965
[01:26:04.253] iteration 22012 : model1 loss : 0.016146 model2 loss : 0.015382
[01:26:04.902] iteration 22013 : model1 loss : 0.025262 model2 loss : 0.025251
[01:26:05.562] iteration 22014 : model1 loss : 0.028165 model2 loss : 0.026825
[01:26:06.215] iteration 22015 : model1 loss : 0.020505 model2 loss : 0.020916
[01:26:06.885] iteration 22016 : model1 loss : 0.012874 model2 loss : 0.015348
[01:26:07.540] iteration 22017 : model1 loss : 0.021905 model2 loss : 0.021364
[01:26:08.205] iteration 22018 : model1 loss : 0.028946 model2 loss : 0.028423
[01:26:08.868] iteration 22019 : model1 loss : 0.020014 model2 loss : 0.021597
[01:26:09.524] iteration 22020 : model1 loss : 0.022286 model2 loss : 0.022077
[01:26:10.195] iteration 22021 : model1 loss : 0.022443 model2 loss : 0.021945
[01:26:10.854] iteration 22022 : model1 loss : 0.016575 model2 loss : 0.016096
[01:26:11.521] iteration 22023 : model1 loss : 0.011741 model2 loss : 0.012721
[01:26:12.180] iteration 22024 : model1 loss : 0.020914 model2 loss : 0.019855
[01:26:12.851] iteration 22025 : model1 loss : 0.023653 model2 loss : 0.024091
[01:26:13.518] iteration 22026 : model1 loss : 0.017077 model2 loss : 0.016668
[01:26:14.188] iteration 22027 : model1 loss : 0.027870 model2 loss : 0.028655
[01:26:14.842] iteration 22028 : model1 loss : 0.023833 model2 loss : 0.031209
[01:26:15.503] iteration 22029 : model1 loss : 0.019098 model2 loss : 0.019025
[01:26:16.166] iteration 22030 : model1 loss : 0.023040 model2 loss : 0.022739
[01:26:16.830] iteration 22031 : model1 loss : 0.019170 model2 loss : 0.018822
[01:26:17.486] iteration 22032 : model1 loss : 0.026001 model2 loss : 0.021496
[01:26:18.142] iteration 22033 : model1 loss : 0.018218 model2 loss : 0.019101
[01:26:18.801] iteration 22034 : model1 loss : 0.019387 model2 loss : 0.019405
[01:26:19.493] iteration 22035 : model1 loss : 0.020869 model2 loss : 0.020873
[01:26:20.161] iteration 22036 : model1 loss : 0.021637 model2 loss : 0.025925
[01:26:20.823] iteration 22037 : model1 loss : 0.017971 model2 loss : 0.018182
[01:26:21.482] iteration 22038 : model1 loss : 0.021697 model2 loss : 0.021241
[01:26:22.134] iteration 22039 : model1 loss : 0.018089 model2 loss : 0.020743
[01:26:22.806] iteration 22040 : model1 loss : 0.022791 model2 loss : 0.023398
[01:26:23.464] iteration 22041 : model1 loss : 0.018598 model2 loss : 0.018763
[01:26:24.125] iteration 22042 : model1 loss : 0.022009 model2 loss : 0.021889
[01:26:24.787] iteration 22043 : model1 loss : 0.021201 model2 loss : 0.024328
[01:26:25.459] iteration 22044 : model1 loss : 0.039660 model2 loss : 0.034739
[01:26:26.115] iteration 22045 : model1 loss : 0.017342 model2 loss : 0.019168
[01:26:26.795] iteration 22046 : model1 loss : 0.018768 model2 loss : 0.019127
[01:26:27.460] iteration 22047 : model1 loss : 0.018355 model2 loss : 0.019701
[01:26:28.108] iteration 22048 : model1 loss : 0.012311 model2 loss : 0.012507
[01:26:28.777] iteration 22049 : model1 loss : 0.024605 model2 loss : 0.023003
[01:26:29.461] iteration 22050 : model1 loss : 0.021662 model2 loss : 0.020076
[01:26:30.182] iteration 22051 : model1 loss : 0.036031 model2 loss : 0.035172
[01:26:30.852] iteration 22052 : model1 loss : 0.025083 model2 loss : 0.023086
[01:26:31.519] iteration 22053 : model1 loss : 0.027872 model2 loss : 0.027990
[01:26:32.187] iteration 22054 : model1 loss : 0.022837 model2 loss : 0.021048
[01:26:32.858] iteration 22055 : model1 loss : 0.016310 model2 loss : 0.017287
[01:26:33.515] iteration 22056 : model1 loss : 0.018496 model2 loss : 0.018769
[01:26:34.186] iteration 22057 : model1 loss : 0.017958 model2 loss : 0.017077
[01:26:34.843] iteration 22058 : model1 loss : 0.022816 model2 loss : 0.021891
[01:26:35.517] iteration 22059 : model1 loss : 0.023866 model2 loss : 0.025002
[01:26:36.182] iteration 22060 : model1 loss : 0.025742 model2 loss : 0.025774
[01:26:36.845] iteration 22061 : model1 loss : 0.020764 model2 loss : 0.022008
[01:26:37.519] iteration 22062 : model1 loss : 0.018730 model2 loss : 0.019344
[01:26:38.171] iteration 22063 : model1 loss : 0.033604 model2 loss : 0.029199
[01:26:38.850] iteration 22064 : model1 loss : 0.017138 model2 loss : 0.018000
[01:26:39.524] iteration 22065 : model1 loss : 0.022404 model2 loss : 0.024146
[01:26:40.188] iteration 22066 : model1 loss : 0.021036 model2 loss : 0.024125
[01:26:40.864] iteration 22067 : model1 loss : 0.018368 model2 loss : 0.020910
[01:26:41.522] iteration 22068 : model1 loss : 0.022890 model2 loss : 0.025483
[01:26:42.186] iteration 22069 : model1 loss : 0.018025 model2 loss : 0.018501
[01:26:42.846] iteration 22070 : model1 loss : 0.022228 model2 loss : 0.021062
[01:26:43.513] iteration 22071 : model1 loss : 0.020858 model2 loss : 0.021445
[01:26:44.176] iteration 22072 : model1 loss : 0.014707 model2 loss : 0.014241
[01:26:44.836] iteration 22073 : model1 loss : 0.024219 model2 loss : 0.025015
[01:26:45.498] iteration 22074 : model1 loss : 0.025436 model2 loss : 0.035218
[01:26:46.165] iteration 22075 : model1 loss : 0.033727 model2 loss : 0.031346
[01:26:46.836] iteration 22076 : model1 loss : 0.026266 model2 loss : 0.027615
[01:26:47.510] iteration 22077 : model1 loss : 0.016767 model2 loss : 0.019426
[01:26:48.161] iteration 22078 : model1 loss : 0.021008 model2 loss : 0.018042
[01:26:48.824] iteration 22079 : model1 loss : 0.016582 model2 loss : 0.017067
[01:26:49.482] iteration 22080 : model1 loss : 0.031900 model2 loss : 0.030247
[01:26:50.145] iteration 22081 : model1 loss : 0.019536 model2 loss : 0.020559
[01:26:50.806] iteration 22082 : model1 loss : 0.018457 model2 loss : 0.017225
[01:26:51.497] iteration 22083 : model1 loss : 0.025697 model2 loss : 0.026318
[01:26:52.156] iteration 22084 : model1 loss : 0.016809 model2 loss : 0.017284
[01:26:52.832] iteration 22085 : model1 loss : 0.018150 model2 loss : 0.018644
[01:26:53.505] iteration 22086 : model1 loss : 0.019552 model2 loss : 0.020494
[01:26:54.181] iteration 22087 : model1 loss : 0.019973 model2 loss : 0.017962
[01:26:54.838] iteration 22088 : model1 loss : 0.023483 model2 loss : 0.023401
[01:26:55.511] iteration 22089 : model1 loss : 0.023844 model2 loss : 0.024541
[01:26:56.177] iteration 22090 : model1 loss : 0.033987 model2 loss : 0.065177
[01:26:56.839] iteration 22091 : model1 loss : 0.021698 model2 loss : 0.021968
[01:26:57.545] iteration 22092 : model1 loss : 0.022382 model2 loss : 0.019991
[01:26:58.205] iteration 22093 : model1 loss : 0.020257 model2 loss : 0.020472
[01:26:58.866] iteration 22094 : model1 loss : 0.016927 model2 loss : 0.017749
[01:26:59.526] iteration 22095 : model1 loss : 0.014266 model2 loss : 0.015479
[01:27:00.191] iteration 22096 : model1 loss : 0.016547 model2 loss : 0.019654
[01:27:00.865] iteration 22097 : model1 loss : 0.026753 model2 loss : 0.026493
[01:27:01.534] iteration 22098 : model1 loss : 0.024824 model2 loss : 0.026129
[01:27:02.205] iteration 22099 : model1 loss : 0.021836 model2 loss : 0.022135
[01:27:02.874] iteration 22100 : model1 loss : 0.024338 model2 loss : 0.026590
[01:27:03.557] iteration 22101 : model1 loss : 0.022309 model2 loss : 0.020848
[01:27:04.218] iteration 22102 : model1 loss : 0.014848 model2 loss : 0.017978
[01:27:04.891] iteration 22103 : model1 loss : 0.022654 model2 loss : 0.023793
[01:27:05.581] iteration 22104 : model1 loss : 0.020909 model2 loss : 0.025160
[01:27:06.253] iteration 22105 : model1 loss : 0.020168 model2 loss : 0.022097
[01:27:06.916] iteration 22106 : model1 loss : 0.019465 model2 loss : 0.021122
[01:27:07.588] iteration 22107 : model1 loss : 0.017245 model2 loss : 0.017746
[01:27:08.252] iteration 22108 : model1 loss : 0.025150 model2 loss : 0.027020
[01:27:08.902] iteration 22109 : model1 loss : 0.028687 model2 loss : 0.024205
[01:27:09.579] iteration 22110 : model1 loss : 0.023196 model2 loss : 0.023398
[01:27:10.243] iteration 22111 : model1 loss : 0.020881 model2 loss : 0.019471
[01:27:10.898] iteration 22112 : model1 loss : 0.016564 model2 loss : 0.015013
[01:27:11.567] iteration 22113 : model1 loss : 0.019719 model2 loss : 0.020568
[01:27:12.227] iteration 22114 : model1 loss : 0.037997 model2 loss : 0.041819
[01:27:12.896] iteration 22115 : model1 loss : 0.022241 model2 loss : 0.022181
[01:27:13.551] iteration 22116 : model1 loss : 0.023693 model2 loss : 0.023518
[01:27:14.211] iteration 22117 : model1 loss : 0.027959 model2 loss : 0.026728
[01:27:14.864] iteration 22118 : model1 loss : 0.019064 model2 loss : 0.019857
[01:27:15.530] iteration 22119 : model1 loss : 0.018920 model2 loss : 0.019110
[01:27:16.197] iteration 22120 : model1 loss : 0.024273 model2 loss : 0.023304
[01:27:16.866] iteration 22121 : model1 loss : 0.028063 model2 loss : 0.031183
[01:27:17.524] iteration 22122 : model1 loss : 0.018210 model2 loss : 0.019007
[01:27:18.200] iteration 22123 : model1 loss : 0.021158 model2 loss : 0.021274
[01:27:18.860] iteration 22124 : model1 loss : 0.017557 model2 loss : 0.016945
[01:27:19.520] iteration 22125 : model1 loss : 0.021917 model2 loss : 0.026784
[01:27:20.192] iteration 22126 : model1 loss : 0.027074 model2 loss : 0.023529
[01:27:20.852] iteration 22127 : model1 loss : 0.020524 model2 loss : 0.022812
[01:27:21.522] iteration 22128 : model1 loss : 0.020578 model2 loss : 0.019955
[01:27:22.191] iteration 22129 : model1 loss : 0.023994 model2 loss : 0.020614
[01:27:22.866] iteration 22130 : model1 loss : 0.026482 model2 loss : 0.027671
[01:27:23.521] iteration 22131 : model1 loss : 0.016758 model2 loss : 0.018658
[01:27:24.183] iteration 22132 : model1 loss : 0.016221 model2 loss : 0.016533
[01:27:24.853] iteration 22133 : model1 loss : 0.015565 model2 loss : 0.016282
[01:27:25.508] iteration 22134 : model1 loss : 0.021368 model2 loss : 0.022671
[01:27:26.192] iteration 22135 : model1 loss : 0.019570 model2 loss : 0.020132
[01:27:26.855] iteration 22136 : model1 loss : 0.023794 model2 loss : 0.024069
[01:27:27.523] iteration 22137 : model1 loss : 0.016952 model2 loss : 0.018026
[01:27:28.203] iteration 22138 : model1 loss : 0.018407 model2 loss : 0.019715
[01:27:28.877] iteration 22139 : model1 loss : 0.024093 model2 loss : 0.025157
[01:27:29.542] iteration 22140 : model1 loss : 0.015480 model2 loss : 0.015537
[01:27:30.229] iteration 22141 : model1 loss : 0.025093 model2 loss : 0.022712
[01:27:30.895] iteration 22142 : model1 loss : 0.023468 model2 loss : 0.027072
[01:27:31.576] iteration 22143 : model1 loss : 0.018960 model2 loss : 0.019913
[01:27:32.229] iteration 22144 : model1 loss : 0.023148 model2 loss : 0.024417
[01:27:32.891] iteration 22145 : model1 loss : 0.019952 model2 loss : 0.018712
[01:27:33.544] iteration 22146 : model1 loss : 0.034916 model2 loss : 0.034562
[01:27:34.199] iteration 22147 : model1 loss : 0.026085 model2 loss : 0.025418
[01:27:34.863] iteration 22148 : model1 loss : 0.016474 model2 loss : 0.015866
[01:27:35.517] iteration 22149 : model1 loss : 0.015541 model2 loss : 0.016274
[01:27:36.194] iteration 22150 : model1 loss : 0.022659 model2 loss : 0.020543
[01:27:36.894] iteration 22151 : model1 loss : 0.022539 model2 loss : 0.021113
[01:27:37.557] iteration 22152 : model1 loss : 0.025060 model2 loss : 0.027271
[01:27:38.213] iteration 22153 : model1 loss : 0.020555 model2 loss : 0.020359
[01:27:38.870] iteration 22154 : model1 loss : 0.019377 model2 loss : 0.017531
[01:27:39.539] iteration 22155 : model1 loss : 0.017035 model2 loss : 0.017270
[01:27:40.212] iteration 22156 : model1 loss : 0.016822 model2 loss : 0.015324
[01:27:40.873] iteration 22157 : model1 loss : 0.021135 model2 loss : 0.021547
[01:27:41.537] iteration 22158 : model1 loss : 0.014998 model2 loss : 0.017548
[01:27:42.207] iteration 22159 : model1 loss : 0.016021 model2 loss : 0.016765
[01:27:42.873] iteration 22160 : model1 loss : 0.020841 model2 loss : 0.019823
[01:27:43.543] iteration 22161 : model1 loss : 0.018844 model2 loss : 0.017732
[01:27:44.210] iteration 22162 : model1 loss : 0.021016 model2 loss : 0.021439
[01:27:44.882] iteration 22163 : model1 loss : 0.019232 model2 loss : 0.016307
[01:27:45.548] iteration 22164 : model1 loss : 0.034814 model2 loss : 0.032413
[01:27:46.222] iteration 22165 : model1 loss : 0.020016 model2 loss : 0.018489
[01:27:46.879] iteration 22166 : model1 loss : 0.017875 model2 loss : 0.017688
[01:27:47.541] iteration 22167 : model1 loss : 0.022815 model2 loss : 0.026923
[01:27:48.207] iteration 22168 : model1 loss : 0.022518 model2 loss : 0.022560
[01:27:48.869] iteration 22169 : model1 loss : 0.029189 model2 loss : 0.027688
[01:27:49.539] iteration 22170 : model1 loss : 0.018672 model2 loss : 0.018813
[01:27:50.198] iteration 22171 : model1 loss : 0.015959 model2 loss : 0.016077
[01:27:50.864] iteration 22172 : model1 loss : 0.038755 model2 loss : 0.033505
[01:27:51.543] iteration 22173 : model1 loss : 0.018984 model2 loss : 0.020724
[01:27:52.197] iteration 22174 : model1 loss : 0.020302 model2 loss : 0.020499
[01:27:52.880] iteration 22175 : model1 loss : 0.018758 model2 loss : 0.019576
[01:27:53.549] iteration 22176 : model1 loss : 0.032279 model2 loss : 0.028620
[01:27:54.209] iteration 22177 : model1 loss : 0.026099 model2 loss : 0.028559
[01:27:54.873] iteration 22178 : model1 loss : 0.022950 model2 loss : 0.024180
[01:27:55.537] iteration 22179 : model1 loss : 0.016554 model2 loss : 0.017619
[01:27:56.197] iteration 22180 : model1 loss : 0.017865 model2 loss : 0.018558
[01:27:56.863] iteration 22181 : model1 loss : 0.023566 model2 loss : 0.028030
[01:27:57.533] iteration 22182 : model1 loss : 0.027981 model2 loss : 0.033880
[01:27:58.198] iteration 22183 : model1 loss : 0.017493 model2 loss : 0.018184
[01:27:58.871] iteration 22184 : model1 loss : 0.016751 model2 loss : 0.016742
[01:27:59.547] iteration 22185 : model1 loss : 0.018563 model2 loss : 0.019280
[01:28:00.213] iteration 22186 : model1 loss : 0.019837 model2 loss : 0.020399
[01:28:00.870] iteration 22187 : model1 loss : 0.021451 model2 loss : 0.021585
[01:28:01.529] iteration 22188 : model1 loss : 0.031518 model2 loss : 0.027470
[01:28:02.191] iteration 22189 : model1 loss : 0.022630 model2 loss : 0.020821
[01:28:02.879] iteration 22190 : model1 loss : 0.019866 model2 loss : 0.019841
[01:28:03.540] iteration 22191 : model1 loss : 0.018143 model2 loss : 0.018491
[01:28:04.200] iteration 22192 : model1 loss : 0.040785 model2 loss : 0.028247
[01:28:04.868] iteration 22193 : model1 loss : 0.019565 model2 loss : 0.019469
[01:28:05.534] iteration 22194 : model1 loss : 0.017746 model2 loss : 0.017898
[01:28:06.200] iteration 22195 : model1 loss : 0.021733 model2 loss : 0.020170
[01:28:06.866] iteration 22196 : model1 loss : 0.024674 model2 loss : 0.024438
[01:28:07.526] iteration 22197 : model1 loss : 0.018720 model2 loss : 0.018575
[01:28:08.188] iteration 22198 : model1 loss : 0.020917 model2 loss : 0.021856
[01:28:08.861] iteration 22199 : model1 loss : 0.015551 model2 loss : 0.016427
[01:28:09.531] iteration 22200 : model1 loss : 0.018682 model2 loss : 0.019378
[01:28:27.421] iteration 22200 : model1_mean_dice : 0.878455 model1_mean_hd95 : 4.685630
[01:28:45.408] iteration 22200 : model2_mean_dice : 0.876061 model2_mean_hd95 : 5.647582
[01:28:46.096] iteration 22201 : model1 loss : 0.016843 model2 loss : 0.018503
[01:28:46.754] iteration 22202 : model1 loss : 0.018657 model2 loss : 0.019809
[01:28:47.411] iteration 22203 : model1 loss : 0.021387 model2 loss : 0.019757
[01:28:48.065] iteration 22204 : model1 loss : 0.021380 model2 loss : 0.021320
[01:28:48.730] iteration 22205 : model1 loss : 0.020434 model2 loss : 0.020629
[01:28:49.393] iteration 22206 : model1 loss : 0.020550 model2 loss : 0.019485
[01:28:50.054] iteration 22207 : model1 loss : 0.019712 model2 loss : 0.020441
[01:28:50.707] iteration 22208 : model1 loss : 0.021083 model2 loss : 0.019493
[01:28:51.369] iteration 22209 : model1 loss : 0.021578 model2 loss : 0.024126
[01:28:52.020] iteration 22210 : model1 loss : 0.018602 model2 loss : 0.018675
[01:28:52.689] iteration 22211 : model1 loss : 0.017057 model2 loss : 0.018531
[01:28:53.353] iteration 22212 : model1 loss : 0.024666 model2 loss : 0.022350
[01:28:54.013] iteration 22213 : model1 loss : 0.019347 model2 loss : 0.019216
[01:28:54.680] iteration 22214 : model1 loss : 0.030639 model2 loss : 0.026760
[01:28:55.357] iteration 22215 : model1 loss : 0.023903 model2 loss : 0.024260
[01:28:56.012] iteration 22216 : model1 loss : 0.031673 model2 loss : 0.032822
[01:28:56.699] iteration 22217 : model1 loss : 0.024428 model2 loss : 0.025037
[01:28:57.367] iteration 22218 : model1 loss : 0.139288 model2 loss : 0.138636
[01:28:58.017] iteration 22219 : model1 loss : 0.141969 model2 loss : 0.139181
[01:28:58.679] iteration 22220 : model1 loss : 0.020660 model2 loss : 0.019226
[01:28:59.344] iteration 22221 : model1 loss : 0.019384 model2 loss : 0.020213
[01:29:00.022] iteration 22222 : model1 loss : 0.017325 model2 loss : 0.018898
[01:29:00.676] iteration 22223 : model1 loss : 0.016321 model2 loss : 0.017449
[01:29:01.338] iteration 22224 : model1 loss : 0.015730 model2 loss : 0.014314
[01:29:02.012] iteration 22225 : model1 loss : 0.018396 model2 loss : 0.017430
[01:29:02.766] iteration 22226 : model1 loss : 0.019347 model2 loss : 0.019087
[01:29:03.484] iteration 22227 : model1 loss : 0.020276 model2 loss : 0.018843
[01:29:04.179] iteration 22228 : model1 loss : 0.023190 model2 loss : 0.019478
[01:29:04.896] iteration 22229 : model1 loss : 0.021479 model2 loss : 0.018398
[01:29:05.603] iteration 22230 : model1 loss : 0.016992 model2 loss : 0.019434
[01:29:06.289] iteration 22231 : model1 loss : 0.019947 model2 loss : 0.019994
[01:29:06.961] iteration 22232 : model1 loss : 0.018963 model2 loss : 0.019907
[01:29:07.650] iteration 22233 : model1 loss : 0.021152 model2 loss : 0.023413
[01:29:08.313] iteration 22234 : model1 loss : 0.020433 model2 loss : 0.019656
[01:29:09.004] iteration 22235 : model1 loss : 0.025466 model2 loss : 0.027383
[01:29:09.705] iteration 22236 : model1 loss : 0.032020 model2 loss : 0.025994
[01:29:10.383] iteration 22237 : model1 loss : 0.017920 model2 loss : 0.018163
[01:29:11.045] iteration 22238 : model1 loss : 0.021693 model2 loss : 0.020092
[01:29:11.714] iteration 22239 : model1 loss : 0.027676 model2 loss : 0.025173
[01:29:12.409] iteration 22240 : model1 loss : 0.020156 model2 loss : 0.019707
[01:29:13.067] iteration 22241 : model1 loss : 0.019009 model2 loss : 0.021673
[01:29:13.755] iteration 22242 : model1 loss : 0.019917 model2 loss : 0.018870
[01:29:14.466] iteration 22243 : model1 loss : 0.028382 model2 loss : 0.027655
[01:29:15.145] iteration 22244 : model1 loss : 0.025140 model2 loss : 0.024726
[01:29:15.804] iteration 22245 : model1 loss : 0.019026 model2 loss : 0.019977
[01:29:16.495] iteration 22246 : model1 loss : 0.019916 model2 loss : 0.021073
[01:29:17.252] iteration 22247 : model1 loss : 0.019404 model2 loss : 0.019483
[01:29:17.991] iteration 22248 : model1 loss : 0.015765 model2 loss : 0.016318
[01:29:18.733] iteration 22249 : model1 loss : 0.023515 model2 loss : 0.023181
[01:29:19.701] iteration 22250 : model1 loss : 0.018477 model2 loss : 0.017762
[01:29:20.514] iteration 22251 : model1 loss : 0.026239 model2 loss : 0.024386
[01:29:21.250] iteration 22252 : model1 loss : 0.018615 model2 loss : 0.016072
[01:29:21.956] iteration 22253 : model1 loss : 0.018301 model2 loss : 0.021194
[01:29:22.660] iteration 22254 : model1 loss : 0.026991 model2 loss : 0.029313
[01:29:23.324] iteration 22255 : model1 loss : 0.021496 model2 loss : 0.022817
[01:29:23.990] iteration 22256 : model1 loss : 0.020296 model2 loss : 0.019836
[01:29:24.650] iteration 22257 : model1 loss : 0.022998 model2 loss : 0.022281
[01:29:25.319] iteration 22258 : model1 loss : 0.024318 model2 loss : 0.023810
[01:29:25.993] iteration 22259 : model1 loss : 0.017262 model2 loss : 0.017941
[01:29:26.667] iteration 22260 : model1 loss : 0.024449 model2 loss : 0.027071
[01:29:27.442] iteration 22261 : model1 loss : 0.017077 model2 loss : 0.015534
[01:29:28.193] iteration 22262 : model1 loss : 0.018898 model2 loss : 0.019191
[01:29:28.880] iteration 22263 : model1 loss : 0.016226 model2 loss : 0.015594
[01:29:29.548] iteration 22264 : model1 loss : 0.020502 model2 loss : 0.022458
[01:29:30.228] iteration 22265 : model1 loss : 0.019064 model2 loss : 0.018544
[01:29:30.943] iteration 22266 : model1 loss : 0.019665 model2 loss : 0.021728
[01:29:31.641] iteration 22267 : model1 loss : 0.022624 model2 loss : 0.022215
[01:29:32.340] iteration 22268 : model1 loss : 0.022103 model2 loss : 0.020370
[01:29:33.016] iteration 22269 : model1 loss : 0.016029 model2 loss : 0.016907
[01:29:33.696] iteration 22270 : model1 loss : 0.029384 model2 loss : 0.025392
[01:29:34.399] iteration 22271 : model1 loss : 0.029379 model2 loss : 0.034321
[01:29:35.100] iteration 22272 : model1 loss : 0.015657 model2 loss : 0.016359
[01:29:35.799] iteration 22273 : model1 loss : 0.019218 model2 loss : 0.018680
[01:29:36.495] iteration 22274 : model1 loss : 0.020255 model2 loss : 0.022113
[01:29:37.183] iteration 22275 : model1 loss : 0.013627 model2 loss : 0.013525
[01:29:37.865] iteration 22276 : model1 loss : 0.015572 model2 loss : 0.016580
[01:29:38.547] iteration 22277 : model1 loss : 0.017564 model2 loss : 0.017371
[01:29:39.231] iteration 22278 : model1 loss : 0.022075 model2 loss : 0.023033
[01:29:39.915] iteration 22279 : model1 loss : 0.019326 model2 loss : 0.018750
[01:29:40.615] iteration 22280 : model1 loss : 0.028862 model2 loss : 0.027210
[01:29:41.298] iteration 22281 : model1 loss : 0.027865 model2 loss : 0.022864
[01:29:41.988] iteration 22282 : model1 loss : 0.022937 model2 loss : 0.023573
[01:29:42.684] iteration 22283 : model1 loss : 0.024854 model2 loss : 0.026977
[01:29:43.361] iteration 22284 : model1 loss : 0.018372 model2 loss : 0.016812
[01:29:44.034] iteration 22285 : model1 loss : 0.019094 model2 loss : 0.020042
[01:29:44.719] iteration 22286 : model1 loss : 0.027594 model2 loss : 0.027969
[01:29:45.393] iteration 22287 : model1 loss : 0.025661 model2 loss : 0.024389
[01:29:46.082] iteration 22288 : model1 loss : 0.020230 model2 loss : 0.021837
[01:29:46.757] iteration 22289 : model1 loss : 0.029685 model2 loss : 0.027204
[01:29:47.463] iteration 22290 : model1 loss : 0.020838 model2 loss : 0.021450
[01:29:48.156] iteration 22291 : model1 loss : 0.018950 model2 loss : 0.021041
[01:29:48.823] iteration 22292 : model1 loss : 0.038500 model2 loss : 0.038567
[01:29:49.518] iteration 22293 : model1 loss : 0.023790 model2 loss : 0.024894
[01:29:50.194] iteration 22294 : model1 loss : 0.026976 model2 loss : 0.025827
[01:29:50.866] iteration 22295 : model1 loss : 0.016311 model2 loss : 0.018086
[01:29:51.568] iteration 22296 : model1 loss : 0.015975 model2 loss : 0.016367
[01:29:52.269] iteration 22297 : model1 loss : 0.017882 model2 loss : 0.018145
[01:29:52.963] iteration 22298 : model1 loss : 0.017908 model2 loss : 0.016669
[01:29:53.659] iteration 22299 : model1 loss : 0.017604 model2 loss : 0.017283
[01:29:54.350] iteration 22300 : model1 loss : 0.020483 model2 loss : 0.018156
[01:29:55.089] iteration 22301 : model1 loss : 0.017308 model2 loss : 0.016909
[01:29:55.774] iteration 22302 : model1 loss : 0.018776 model2 loss : 0.018185
[01:29:56.455] iteration 22303 : model1 loss : 0.017442 model2 loss : 0.016617
[01:29:57.150] iteration 22304 : model1 loss : 0.025947 model2 loss : 0.024206
[01:29:57.824] iteration 22305 : model1 loss : 0.024470 model2 loss : 0.024916
[01:29:58.508] iteration 22306 : model1 loss : 0.022113 model2 loss : 0.020985
[01:29:59.198] iteration 22307 : model1 loss : 0.021624 model2 loss : 0.022516
[01:29:59.881] iteration 22308 : model1 loss : 0.017097 model2 loss : 0.017088
[01:30:00.578] iteration 22309 : model1 loss : 0.019047 model2 loss : 0.020635
[01:30:01.261] iteration 22310 : model1 loss : 0.023193 model2 loss : 0.024813
[01:30:01.950] iteration 22311 : model1 loss : 0.024314 model2 loss : 0.022538
[01:30:02.651] iteration 22312 : model1 loss : 0.022382 model2 loss : 0.021517
[01:30:03.341] iteration 22313 : model1 loss : 0.033031 model2 loss : 0.033246
[01:30:04.032] iteration 22314 : model1 loss : 0.014876 model2 loss : 0.015566
[01:30:04.700] iteration 22315 : model1 loss : 0.025785 model2 loss : 0.025272
[01:30:05.382] iteration 22316 : model1 loss : 0.022222 model2 loss : 0.020943
[01:30:06.057] iteration 22317 : model1 loss : 0.014423 model2 loss : 0.015244
[01:30:06.736] iteration 22318 : model1 loss : 0.017668 model2 loss : 0.017440
[01:30:07.437] iteration 22319 : model1 loss : 0.014106 model2 loss : 0.016789
[01:30:08.140] iteration 22320 : model1 loss : 0.019005 model2 loss : 0.020821
[01:30:08.823] iteration 22321 : model1 loss : 0.027963 model2 loss : 0.028620
[01:30:09.509] iteration 22322 : model1 loss : 0.024380 model2 loss : 0.027172
[01:30:10.190] iteration 22323 : model1 loss : 0.016889 model2 loss : 0.016785
[01:30:10.879] iteration 22324 : model1 loss : 0.022490 model2 loss : 0.021034
[01:30:11.576] iteration 22325 : model1 loss : 0.020748 model2 loss : 0.023514
[01:30:12.250] iteration 22326 : model1 loss : 0.018815 model2 loss : 0.019097
[01:30:12.919] iteration 22327 : model1 loss : 0.019363 model2 loss : 0.017623
[01:30:13.574] iteration 22328 : model1 loss : 0.021863 model2 loss : 0.023197
[01:30:14.240] iteration 22329 : model1 loss : 0.018853 model2 loss : 0.018461
[01:30:14.911] iteration 22330 : model1 loss : 0.027546 model2 loss : 0.024155
[01:30:15.576] iteration 22331 : model1 loss : 0.015913 model2 loss : 0.016020
[01:30:16.245] iteration 22332 : model1 loss : 0.026399 model2 loss : 0.029464
[01:30:16.902] iteration 22333 : model1 loss : 0.017412 model2 loss : 0.017237
[01:30:17.557] iteration 22334 : model1 loss : 0.016971 model2 loss : 0.017821
[01:30:18.235] iteration 22335 : model1 loss : 0.021210 model2 loss : 0.020336
[01:30:18.914] iteration 22336 : model1 loss : 0.021056 model2 loss : 0.026087
[01:30:19.586] iteration 22337 : model1 loss : 0.014818 model2 loss : 0.014970
[01:30:20.243] iteration 22338 : model1 loss : 0.021297 model2 loss : 0.019014
[01:30:20.921] iteration 22339 : model1 loss : 0.025816 model2 loss : 0.025834
[01:30:21.584] iteration 22340 : model1 loss : 0.016897 model2 loss : 0.016286
[01:30:22.242] iteration 22341 : model1 loss : 0.021834 model2 loss : 0.020196
[01:30:22.910] iteration 22342 : model1 loss : 0.021694 model2 loss : 0.022248
[01:30:23.574] iteration 22343 : model1 loss : 0.019226 model2 loss : 0.018866
[01:30:24.235] iteration 22344 : model1 loss : 0.016745 model2 loss : 0.018054
[01:30:24.903] iteration 22345 : model1 loss : 0.019953 model2 loss : 0.021308
[01:30:25.569] iteration 22346 : model1 loss : 0.020023 model2 loss : 0.019941
[01:30:26.233] iteration 22347 : model1 loss : 0.024258 model2 loss : 0.024898
[01:30:26.899] iteration 22348 : model1 loss : 0.020179 model2 loss : 0.020364
[01:30:27.570] iteration 22349 : model1 loss : 0.020738 model2 loss : 0.019546
[01:30:28.236] iteration 22350 : model1 loss : 0.020363 model2 loss : 0.019137
[01:30:28.925] iteration 22351 : model1 loss : 0.018171 model2 loss : 0.018180
[01:30:29.587] iteration 22352 : model1 loss : 0.018115 model2 loss : 0.017921
[01:30:30.253] iteration 22353 : model1 loss : 0.022078 model2 loss : 0.019678
[01:30:30.909] iteration 22354 : model1 loss : 0.020124 model2 loss : 0.017889
[01:30:31.609] iteration 22355 : model1 loss : 0.022261 model2 loss : 0.024570
[01:30:32.286] iteration 22356 : model1 loss : 0.020583 model2 loss : 0.022464
[01:30:32.947] iteration 22357 : model1 loss : 0.019508 model2 loss : 0.021848
[01:30:33.623] iteration 22358 : model1 loss : 0.023635 model2 loss : 0.023556
[01:30:34.292] iteration 22359 : model1 loss : 0.017606 model2 loss : 0.017627
[01:30:34.960] iteration 22360 : model1 loss : 0.020501 model2 loss : 0.021857
[01:30:35.631] iteration 22361 : model1 loss : 0.016399 model2 loss : 0.015886
[01:30:36.295] iteration 22362 : model1 loss : 0.019428 model2 loss : 0.018630
[01:30:36.961] iteration 22363 : model1 loss : 0.013905 model2 loss : 0.014158
[01:30:37.628] iteration 22364 : model1 loss : 0.023114 model2 loss : 0.021168
[01:30:38.294] iteration 22365 : model1 loss : 0.016520 model2 loss : 0.016548
[01:30:38.957] iteration 22366 : model1 loss : 0.027549 model2 loss : 0.027308
[01:30:39.616] iteration 22367 : model1 loss : 0.013819 model2 loss : 0.014416
[01:30:40.287] iteration 22368 : model1 loss : 0.018874 model2 loss : 0.018027
[01:30:40.955] iteration 22369 : model1 loss : 0.015853 model2 loss : 0.015300
[01:30:41.618] iteration 22370 : model1 loss : 0.022577 model2 loss : 0.020521
[01:30:42.276] iteration 22371 : model1 loss : 0.018161 model2 loss : 0.019207
[01:30:42.966] iteration 22372 : model1 loss : 0.022414 model2 loss : 0.021117
[01:30:43.635] iteration 22373 : model1 loss : 0.019326 model2 loss : 0.018324
[01:30:44.302] iteration 22374 : model1 loss : 0.020561 model2 loss : 0.019742
[01:30:44.961] iteration 22375 : model1 loss : 0.017196 model2 loss : 0.017529
[01:30:45.616] iteration 22376 : model1 loss : 0.018682 model2 loss : 0.020177
[01:30:46.281] iteration 22377 : model1 loss : 0.019184 model2 loss : 0.018069
[01:30:46.937] iteration 22378 : model1 loss : 0.023568 model2 loss : 0.021995
[01:30:47.591] iteration 22379 : model1 loss : 0.018397 model2 loss : 0.018932
[01:30:48.270] iteration 22380 : model1 loss : 0.020943 model2 loss : 0.022585
[01:30:48.931] iteration 22381 : model1 loss : 0.017741 model2 loss : 0.016423
[01:30:49.591] iteration 22382 : model1 loss : 0.020508 model2 loss : 0.019043
[01:30:50.268] iteration 22383 : model1 loss : 0.020023 model2 loss : 0.021229
[01:30:50.935] iteration 22384 : model1 loss : 0.018475 model2 loss : 0.017918
[01:30:51.625] iteration 22385 : model1 loss : 0.019741 model2 loss : 0.019659
[01:30:52.299] iteration 22386 : model1 loss : 0.018364 model2 loss : 0.021589
[01:30:52.960] iteration 22387 : model1 loss : 0.023172 model2 loss : 0.025676
[01:30:53.635] iteration 22388 : model1 loss : 0.021910 model2 loss : 0.020515
[01:30:54.303] iteration 22389 : model1 loss : 0.020102 model2 loss : 0.020711
[01:30:54.965] iteration 22390 : model1 loss : 0.019226 model2 loss : 0.021946
[01:30:55.646] iteration 22391 : model1 loss : 0.025161 model2 loss : 0.025777
[01:30:56.305] iteration 22392 : model1 loss : 0.019059 model2 loss : 0.020366
[01:30:56.973] iteration 22393 : model1 loss : 0.025705 model2 loss : 0.026451
[01:30:57.640] iteration 22394 : model1 loss : 0.019190 model2 loss : 0.018253
[01:30:58.322] iteration 22395 : model1 loss : 0.021653 model2 loss : 0.022045
[01:30:58.994] iteration 22396 : model1 loss : 0.022081 model2 loss : 0.025974
[01:30:59.661] iteration 22397 : model1 loss : 0.020417 model2 loss : 0.019561
[01:31:00.335] iteration 22398 : model1 loss : 0.019239 model2 loss : 0.020334
[01:31:01.001] iteration 22399 : model1 loss : 0.023060 model2 loss : 0.020148
[01:31:01.662] iteration 22400 : model1 loss : 0.018805 model2 loss : 0.019555
[01:31:19.598] iteration 22400 : model1_mean_dice : 0.877960 model1_mean_hd95 : 5.933099
[01:31:37.729] iteration 22400 : model2_mean_dice : 0.880258 model2_mean_hd95 : 5.092606
[01:31:38.411] iteration 22401 : model1 loss : 0.039185 model2 loss : 0.037870
[01:31:39.084] iteration 22402 : model1 loss : 0.019957 model2 loss : 0.018803
[01:31:39.747] iteration 22403 : model1 loss : 0.020828 model2 loss : 0.019528
[01:31:40.414] iteration 22404 : model1 loss : 0.019088 model2 loss : 0.017969
[01:31:41.071] iteration 22405 : model1 loss : 0.024922 model2 loss : 0.026671
[01:31:41.729] iteration 22406 : model1 loss : 0.137363 model2 loss : 0.066205
[01:31:42.398] iteration 22407 : model1 loss : 0.016335 model2 loss : 0.015056
[01:31:43.054] iteration 22408 : model1 loss : 0.022820 model2 loss : 0.022245
[01:31:43.722] iteration 22409 : model1 loss : 0.015574 model2 loss : 0.015651
[01:31:44.383] iteration 22410 : model1 loss : 0.027865 model2 loss : 0.027213
[01:31:45.045] iteration 22411 : model1 loss : 0.020090 model2 loss : 0.018052
[01:31:45.723] iteration 22412 : model1 loss : 0.021490 model2 loss : 0.021534
[01:31:46.384] iteration 22413 : model1 loss : 0.019996 model2 loss : 0.020142
[01:31:47.041] iteration 22414 : model1 loss : 0.022103 model2 loss : 0.021094
[01:31:47.704] iteration 22415 : model1 loss : 0.019383 model2 loss : 0.020919
[01:31:48.384] iteration 22416 : model1 loss : 0.018059 model2 loss : 0.016061
[01:31:49.049] iteration 22417 : model1 loss : 0.022287 model2 loss : 0.020166
[01:31:49.719] iteration 22418 : model1 loss : 0.025093 model2 loss : 0.031334
[01:31:50.379] iteration 22419 : model1 loss : 0.017832 model2 loss : 0.019051
[01:31:51.029] iteration 22420 : model1 loss : 0.017752 model2 loss : 0.017171
[01:31:51.694] iteration 22421 : model1 loss : 0.020242 model2 loss : 0.019724
[01:31:52.367] iteration 22422 : model1 loss : 0.018982 model2 loss : 0.020214
[01:31:53.019] iteration 22423 : model1 loss : 0.019558 model2 loss : 0.020380
[01:31:53.686] iteration 22424 : model1 loss : 0.018932 model2 loss : 0.020752
[01:31:54.349] iteration 22425 : model1 loss : 0.023160 model2 loss : 0.022809
[01:31:54.996] iteration 22426 : model1 loss : 0.029390 model2 loss : 0.026752
[01:31:55.658] iteration 22427 : model1 loss : 0.018293 model2 loss : 0.019062
[01:31:56.329] iteration 22428 : model1 loss : 0.016801 model2 loss : 0.018701
[01:31:56.979] iteration 22429 : model1 loss : 0.018946 model2 loss : 0.020250
[01:31:57.648] iteration 22430 : model1 loss : 0.018754 model2 loss : 0.018098
[01:31:58.317] iteration 22431 : model1 loss : 0.018956 model2 loss : 0.018862
[01:31:58.984] iteration 22432 : model1 loss : 0.016902 model2 loss : 0.017901
[01:31:59.644] iteration 22433 : model1 loss : 0.023059 model2 loss : 0.022441
[01:32:00.306] iteration 22434 : model1 loss : 0.017784 model2 loss : 0.016195
[01:32:00.975] iteration 22435 : model1 loss : 0.017028 model2 loss : 0.017596
[01:32:01.642] iteration 22436 : model1 loss : 0.019460 model2 loss : 0.017215
[01:32:02.303] iteration 22437 : model1 loss : 0.018130 model2 loss : 0.020566
[01:32:02.956] iteration 22438 : model1 loss : 0.023544 model2 loss : 0.024122
[01:32:03.611] iteration 22439 : model1 loss : 0.020228 model2 loss : 0.018653
[01:32:04.272] iteration 22440 : model1 loss : 0.024097 model2 loss : 0.019634
[01:32:04.947] iteration 22441 : model1 loss : 0.022287 model2 loss : 0.021552
[01:32:05.615] iteration 22442 : model1 loss : 0.019780 model2 loss : 0.020453
[01:32:06.271] iteration 22443 : model1 loss : 0.017924 model2 loss : 0.018126
[01:32:06.933] iteration 22444 : model1 loss : 0.021073 model2 loss : 0.021491
[01:32:07.596] iteration 22445 : model1 loss : 0.024575 model2 loss : 0.022699
[01:32:08.270] iteration 22446 : model1 loss : 0.026724 model2 loss : 0.026037
[01:32:08.934] iteration 22447 : model1 loss : 0.021651 model2 loss : 0.021392
[01:32:09.598] iteration 22448 : model1 loss : 0.021887 model2 loss : 0.023291
[01:32:10.258] iteration 22449 : model1 loss : 0.024999 model2 loss : 0.020178
[01:32:10.919] iteration 22450 : model1 loss : 0.027319 model2 loss : 0.025261
[01:32:11.625] iteration 22451 : model1 loss : 0.024698 model2 loss : 0.023526
[01:32:12.301] iteration 22452 : model1 loss : 0.020447 model2 loss : 0.017690
[01:32:12.974] iteration 22453 : model1 loss : 0.027532 model2 loss : 0.028917
[01:32:13.637] iteration 22454 : model1 loss : 0.019394 model2 loss : 0.017881
[01:32:14.313] iteration 22455 : model1 loss : 0.018457 model2 loss : 0.017906
[01:32:14.992] iteration 22456 : model1 loss : 0.023334 model2 loss : 0.021400
[01:32:15.642] iteration 22457 : model1 loss : 0.024103 model2 loss : 0.021562
[01:32:16.308] iteration 22458 : model1 loss : 0.021849 model2 loss : 0.022366
[01:32:16.971] iteration 22459 : model1 loss : 0.036212 model2 loss : 0.030066
[01:32:17.637] iteration 22460 : model1 loss : 0.019979 model2 loss : 0.021263
[01:32:18.300] iteration 22461 : model1 loss : 0.016558 model2 loss : 0.020045
[01:32:18.969] iteration 22462 : model1 loss : 0.018670 model2 loss : 0.020195
[01:32:19.632] iteration 22463 : model1 loss : 0.024948 model2 loss : 0.025173
[01:32:20.299] iteration 22464 : model1 loss : 0.015670 model2 loss : 0.015202
[01:32:20.971] iteration 22465 : model1 loss : 0.024886 model2 loss : 0.021404
[01:32:21.636] iteration 22466 : model1 loss : 0.019903 model2 loss : 0.019871
[01:32:22.313] iteration 22467 : model1 loss : 0.017945 model2 loss : 0.016435
[01:32:22.981] iteration 22468 : model1 loss : 0.030797 model2 loss : 0.027710
[01:32:23.648] iteration 22469 : model1 loss : 0.014523 model2 loss : 0.014588
[01:32:24.313] iteration 22470 : model1 loss : 0.019687 model2 loss : 0.019102
[01:32:24.987] iteration 22471 : model1 loss : 0.022649 model2 loss : 0.020496
[01:32:25.652] iteration 22472 : model1 loss : 0.017393 model2 loss : 0.016447
[01:32:26.328] iteration 22473 : model1 loss : 0.018849 model2 loss : 0.020547
[01:32:26.992] iteration 22474 : model1 loss : 0.015112 model2 loss : 0.016041
[01:32:27.654] iteration 22475 : model1 loss : 0.018939 model2 loss : 0.018659
[01:32:28.323] iteration 22476 : model1 loss : 0.024729 model2 loss : 0.023443
[01:32:28.995] iteration 22477 : model1 loss : 0.023080 model2 loss : 0.022832
[01:32:29.662] iteration 22478 : model1 loss : 0.021177 model2 loss : 0.022385
[01:32:30.337] iteration 22479 : model1 loss : 0.017664 model2 loss : 0.018558
[01:32:30.994] iteration 22480 : model1 loss : 0.019617 model2 loss : 0.022029
[01:32:31.654] iteration 22481 : model1 loss : 0.019624 model2 loss : 0.020047
[01:32:32.331] iteration 22482 : model1 loss : 0.016753 model2 loss : 0.016897
[01:32:33.010] iteration 22483 : model1 loss : 0.018307 model2 loss : 0.020052
[01:32:33.666] iteration 22484 : model1 loss : 0.019211 model2 loss : 0.024511
[01:32:34.340] iteration 22485 : model1 loss : 0.023271 model2 loss : 0.021079
[01:32:35.003] iteration 22486 : model1 loss : 0.042116 model2 loss : 0.036089
[01:32:35.657] iteration 22487 : model1 loss : 0.022546 model2 loss : 0.019550
[01:32:36.334] iteration 22488 : model1 loss : 0.022215 model2 loss : 0.023907
[01:32:36.995] iteration 22489 : model1 loss : 0.018657 model2 loss : 0.019014
[01:32:37.666] iteration 22490 : model1 loss : 0.016966 model2 loss : 0.016856
[01:32:38.344] iteration 22491 : model1 loss : 0.030043 model2 loss : 0.023702
[01:32:39.021] iteration 22492 : model1 loss : 0.141228 model2 loss : 0.140312
[01:32:39.694] iteration 22493 : model1 loss : 0.028599 model2 loss : 0.028939
[01:32:40.364] iteration 22494 : model1 loss : 0.017507 model2 loss : 0.018041
[01:32:41.023] iteration 22495 : model1 loss : 0.013056 model2 loss : 0.015762
[01:32:41.683] iteration 22496 : model1 loss : 0.027751 model2 loss : 0.029515
[01:32:42.350] iteration 22497 : model1 loss : 0.019864 model2 loss : 0.021692
[01:32:43.008] iteration 22498 : model1 loss : 0.025454 model2 loss : 0.021389
[01:32:43.665] iteration 22499 : model1 loss : 0.018795 model2 loss : 0.020062
[01:32:44.329] iteration 22500 : model1 loss : 0.018417 model2 loss : 0.018920
[01:32:45.028] iteration 22501 : model1 loss : 0.023719 model2 loss : 0.023725
[01:32:45.696] iteration 22502 : model1 loss : 0.019267 model2 loss : 0.020713
[01:32:46.360] iteration 22503 : model1 loss : 0.023122 model2 loss : 0.024504
[01:32:47.026] iteration 22504 : model1 loss : 0.019490 model2 loss : 0.020488
[01:32:47.693] iteration 22505 : model1 loss : 0.025451 model2 loss : 0.026338
[01:32:48.378] iteration 22506 : model1 loss : 0.023377 model2 loss : 0.021729
[01:32:49.034] iteration 22507 : model1 loss : 0.018139 model2 loss : 0.019922
[01:32:49.698] iteration 22508 : model1 loss : 0.018163 model2 loss : 0.018370
[01:32:50.359] iteration 22509 : model1 loss : 0.020410 model2 loss : 0.019495
[01:32:51.018] iteration 22510 : model1 loss : 0.018105 model2 loss : 0.018087
[01:32:51.699] iteration 22511 : model1 loss : 0.021724 model2 loss : 0.020785
[01:32:52.356] iteration 22512 : model1 loss : 0.019735 model2 loss : 0.018855
[01:32:53.030] iteration 22513 : model1 loss : 0.017323 model2 loss : 0.018791
[01:32:53.692] iteration 22514 : model1 loss : 0.020936 model2 loss : 0.018944
[01:32:54.364] iteration 22515 : model1 loss : 0.019409 model2 loss : 0.019568
[01:32:55.034] iteration 22516 : model1 loss : 0.019905 model2 loss : 0.021830
[01:32:55.701] iteration 22517 : model1 loss : 0.019365 model2 loss : 0.021490
[01:32:56.380] iteration 22518 : model1 loss : 0.019101 model2 loss : 0.018881
[01:32:57.039] iteration 22519 : model1 loss : 0.018037 model2 loss : 0.017206
[01:32:57.705] iteration 22520 : model1 loss : 0.021754 model2 loss : 0.022816
[01:32:58.364] iteration 22521 : model1 loss : 0.028825 model2 loss : 0.026879
[01:32:59.030] iteration 22522 : model1 loss : 0.023124 model2 loss : 0.021566
[01:32:59.704] iteration 22523 : model1 loss : 0.019872 model2 loss : 0.020370
[01:33:00.378] iteration 22524 : model1 loss : 0.026449 model2 loss : 0.029956
[01:33:01.041] iteration 22525 : model1 loss : 0.021430 model2 loss : 0.022760
[01:33:01.697] iteration 22526 : model1 loss : 0.038808 model2 loss : 0.045024
[01:33:02.369] iteration 22527 : model1 loss : 0.024248 model2 loss : 0.020675
[01:33:03.034] iteration 22528 : model1 loss : 0.015423 model2 loss : 0.014984
[01:33:03.694] iteration 22529 : model1 loss : 0.021328 model2 loss : 0.022509
[01:33:04.363] iteration 22530 : model1 loss : 0.018259 model2 loss : 0.020764
[01:33:05.025] iteration 22531 : model1 loss : 0.028496 model2 loss : 0.026956
[01:33:05.689] iteration 22532 : model1 loss : 0.016579 model2 loss : 0.016276
[01:33:06.352] iteration 22533 : model1 loss : 0.023588 model2 loss : 0.025184
[01:33:07.025] iteration 22534 : model1 loss : 0.021601 model2 loss : 0.020343
[01:33:07.683] iteration 22535 : model1 loss : 0.023077 model2 loss : 0.022496
[01:33:08.358] iteration 22536 : model1 loss : 0.019338 model2 loss : 0.019769
[01:33:09.025] iteration 22537 : model1 loss : 0.021485 model2 loss : 0.021536
[01:33:09.698] iteration 22538 : model1 loss : 0.016826 model2 loss : 0.016544
[01:33:10.365] iteration 22539 : model1 loss : 0.018460 model2 loss : 0.018183
[01:33:11.032] iteration 22540 : model1 loss : 0.049071 model2 loss : 0.050579
[01:33:11.690] iteration 22541 : model1 loss : 0.013170 model2 loss : 0.015388
[01:33:12.350] iteration 22542 : model1 loss : 0.015403 model2 loss : 0.016478
[01:33:13.024] iteration 22543 : model1 loss : 0.014766 model2 loss : 0.014176
[01:33:13.684] iteration 22544 : model1 loss : 0.015036 model2 loss : 0.015115
[01:33:14.356] iteration 22545 : model1 loss : 0.024827 model2 loss : 0.023253
[01:33:15.018] iteration 22546 : model1 loss : 0.018862 model2 loss : 0.018262
[01:33:15.685] iteration 22547 : model1 loss : 0.018845 model2 loss : 0.017759
[01:33:16.353] iteration 22548 : model1 loss : 0.016817 model2 loss : 0.018724
[01:33:17.024] iteration 22549 : model1 loss : 0.023912 model2 loss : 0.023621
[01:33:17.679] iteration 22550 : model1 loss : 0.020970 model2 loss : 0.018030
[01:33:18.383] iteration 22551 : model1 loss : 0.021579 model2 loss : 0.021535
[01:33:19.058] iteration 22552 : model1 loss : 0.019359 model2 loss : 0.019362
[01:33:19.727] iteration 22553 : model1 loss : 0.023529 model2 loss : 0.023192
[01:33:20.390] iteration 22554 : model1 loss : 0.017158 model2 loss : 0.019412
[01:33:21.049] iteration 22555 : model1 loss : 0.024265 model2 loss : 0.028094
[01:33:21.700] iteration 22556 : model1 loss : 0.020285 model2 loss : 0.020600
[01:33:22.366] iteration 22557 : model1 loss : 0.021953 model2 loss : 0.021384
[01:33:23.030] iteration 22558 : model1 loss : 0.016848 model2 loss : 0.016969
[01:33:23.692] iteration 22559 : model1 loss : 0.023340 model2 loss : 0.025530
[01:33:24.369] iteration 22560 : model1 loss : 0.017063 model2 loss : 0.018006
[01:33:25.022] iteration 22561 : model1 loss : 0.021406 model2 loss : 0.022067
[01:33:25.690] iteration 22562 : model1 loss : 0.033701 model2 loss : 0.031666
[01:33:26.351] iteration 22563 : model1 loss : 0.026713 model2 loss : 0.022937
[01:33:27.015] iteration 22564 : model1 loss : 0.029761 model2 loss : 0.030500
[01:33:27.731] iteration 22565 : model1 loss : 0.020516 model2 loss : 0.021571
[01:33:28.407] iteration 22566 : model1 loss : 0.016242 model2 loss : 0.015654
[01:33:29.072] iteration 22567 : model1 loss : 0.020156 model2 loss : 0.021235
[01:33:29.731] iteration 22568 : model1 loss : 0.015856 model2 loss : 0.016463
[01:33:30.396] iteration 22569 : model1 loss : 0.018629 model2 loss : 0.018509
[01:33:31.050] iteration 22570 : model1 loss : 0.150184 model2 loss : 0.149450
[01:33:31.705] iteration 22571 : model1 loss : 0.016983 model2 loss : 0.018615
[01:33:32.368] iteration 22572 : model1 loss : 0.019052 model2 loss : 0.018924
[01:33:33.066] iteration 22573 : model1 loss : 0.020780 model2 loss : 0.023122
[01:33:33.736] iteration 22574 : model1 loss : 0.018379 model2 loss : 0.019660
[01:33:34.409] iteration 22575 : model1 loss : 0.023580 model2 loss : 0.022522
[01:33:35.076] iteration 22576 : model1 loss : 0.028053 model2 loss : 0.026372
[01:33:35.752] iteration 22577 : model1 loss : 0.021429 model2 loss : 0.020723
[01:33:36.401] iteration 22578 : model1 loss : 0.015107 model2 loss : 0.015952
[01:33:37.074] iteration 22579 : model1 loss : 0.027719 model2 loss : 0.028960
[01:33:37.741] iteration 22580 : model1 loss : 0.025426 model2 loss : 0.026004
[01:33:38.399] iteration 22581 : model1 loss : 0.016071 model2 loss : 0.016119
[01:33:39.083] iteration 22582 : model1 loss : 0.142067 model2 loss : 0.140426
[01:33:39.737] iteration 22583 : model1 loss : 0.017741 model2 loss : 0.017813
[01:33:40.396] iteration 22584 : model1 loss : 0.027531 model2 loss : 0.029597
[01:33:41.072] iteration 22585 : model1 loss : 0.019854 model2 loss : 0.020226
[01:33:41.732] iteration 22586 : model1 loss : 0.017598 model2 loss : 0.019144
[01:33:42.418] iteration 22587 : model1 loss : 0.021752 model2 loss : 0.022016
[01:33:43.106] iteration 22588 : model1 loss : 0.018142 model2 loss : 0.018693
[01:33:43.764] iteration 22589 : model1 loss : 0.017725 model2 loss : 0.019426
[01:33:44.441] iteration 22590 : model1 loss : 0.022782 model2 loss : 0.022258
[01:33:45.113] iteration 22591 : model1 loss : 0.023627 model2 loss : 0.023259
[01:33:45.767] iteration 22592 : model1 loss : 0.020530 model2 loss : 0.025097
[01:33:46.433] iteration 22593 : model1 loss : 0.027520 model2 loss : 0.034233
[01:33:47.095] iteration 22594 : model1 loss : 0.019176 model2 loss : 0.020555
[01:33:47.758] iteration 22595 : model1 loss : 0.019353 model2 loss : 0.019748
[01:33:48.428] iteration 22596 : model1 loss : 0.014662 model2 loss : 0.013644
[01:33:49.086] iteration 22597 : model1 loss : 0.018840 model2 loss : 0.018776
[01:33:49.750] iteration 22598 : model1 loss : 0.017611 model2 loss : 0.017390
[01:33:50.414] iteration 22599 : model1 loss : 0.023551 model2 loss : 0.026167
[01:33:51.088] iteration 22600 : model1 loss : 0.021555 model2 loss : 0.021342
[01:34:08.933] iteration 22600 : model1_mean_dice : 0.874735 model1_mean_hd95 : 5.449484
[01:34:26.969] iteration 22600 : model2_mean_dice : 0.876809 model2_mean_hd95 : 4.989835
[01:34:27.667] iteration 22601 : model1 loss : 0.019001 model2 loss : 0.020012
[01:34:28.320] iteration 22602 : model1 loss : 0.029399 model2 loss : 0.027011
[01:34:28.993] iteration 22603 : model1 loss : 0.024768 model2 loss : 0.024175
[01:34:29.647] iteration 22604 : model1 loss : 0.019287 model2 loss : 0.020227
[01:34:30.315] iteration 22605 : model1 loss : 0.025736 model2 loss : 0.024015
[01:34:30.975] iteration 22606 : model1 loss : 0.016098 model2 loss : 0.015680
[01:34:31.632] iteration 22607 : model1 loss : 0.016280 model2 loss : 0.016305
[01:34:32.303] iteration 22608 : model1 loss : 0.020263 model2 loss : 0.019215
[01:34:32.954] iteration 22609 : model1 loss : 0.023798 model2 loss : 0.023615
[01:34:33.656] iteration 22610 : model1 loss : 0.017815 model2 loss : 0.018491
[01:34:34.330] iteration 22611 : model1 loss : 0.024948 model2 loss : 0.026205
[01:34:35.008] iteration 22612 : model1 loss : 0.017270 model2 loss : 0.016429
[01:34:35.660] iteration 22613 : model1 loss : 0.019172 model2 loss : 0.018815
[01:34:36.344] iteration 22614 : model1 loss : 0.023639 model2 loss : 0.022236
[01:34:37.023] iteration 22615 : model1 loss : 0.051615 model2 loss : 0.051242
[01:34:37.684] iteration 22616 : model1 loss : 0.019886 model2 loss : 0.020788
[01:34:38.353] iteration 22617 : model1 loss : 0.022031 model2 loss : 0.019151
[01:34:39.008] iteration 22618 : model1 loss : 0.016479 model2 loss : 0.017483
[01:34:39.683] iteration 22619 : model1 loss : 0.017128 model2 loss : 0.016934
[01:34:40.339] iteration 22620 : model1 loss : 0.019072 model2 loss : 0.018847
[01:34:40.997] iteration 22621 : model1 loss : 0.015171 model2 loss : 0.015137
[01:34:41.662] iteration 22622 : model1 loss : 0.025317 model2 loss : 0.025775
[01:34:42.342] iteration 22623 : model1 loss : 0.020917 model2 loss : 0.021952
[01:34:43.012] iteration 22624 : model1 loss : 0.018556 model2 loss : 0.019920
[01:34:43.672] iteration 22625 : model1 loss : 0.025462 model2 loss : 0.023807
[01:34:44.335] iteration 22626 : model1 loss : 0.014528 model2 loss : 0.015053
[01:34:44.991] iteration 22627 : model1 loss : 0.020817 model2 loss : 0.020817
[01:34:45.650] iteration 22628 : model1 loss : 0.023188 model2 loss : 0.024017
[01:34:46.314] iteration 22629 : model1 loss : 0.026515 model2 loss : 0.029357
[01:34:46.989] iteration 22630 : model1 loss : 0.022661 model2 loss : 0.021860
[01:34:47.650] iteration 22631 : model1 loss : 0.027714 model2 loss : 0.029424
[01:34:48.320] iteration 22632 : model1 loss : 0.018813 model2 loss : 0.019783
[01:34:48.981] iteration 22633 : model1 loss : 0.018982 model2 loss : 0.018072
[01:34:49.650] iteration 22634 : model1 loss : 0.022348 model2 loss : 0.021795
[01:34:50.325] iteration 22635 : model1 loss : 0.019416 model2 loss : 0.019386
[01:34:50.995] iteration 22636 : model1 loss : 0.020151 model2 loss : 0.020047
[01:34:51.655] iteration 22637 : model1 loss : 0.021288 model2 loss : 0.021192
[01:34:52.320] iteration 22638 : model1 loss : 0.017866 model2 loss : 0.017330
[01:34:52.986] iteration 22639 : model1 loss : 0.015956 model2 loss : 0.017683
[01:34:53.646] iteration 22640 : model1 loss : 0.024437 model2 loss : 0.027356
[01:34:54.310] iteration 22641 : model1 loss : 0.027940 model2 loss : 0.022610
[01:34:54.978] iteration 22642 : model1 loss : 0.015411 model2 loss : 0.015496
[01:34:55.643] iteration 22643 : model1 loss : 0.018542 model2 loss : 0.019854
[01:34:56.307] iteration 22644 : model1 loss : 0.039610 model2 loss : 0.036813
[01:34:56.962] iteration 22645 : model1 loss : 0.019342 model2 loss : 0.018315
[01:34:57.632] iteration 22646 : model1 loss : 0.023613 model2 loss : 0.033655
[01:34:58.299] iteration 22647 : model1 loss : 0.020489 model2 loss : 0.021190
[01:34:58.973] iteration 22648 : model1 loss : 0.019970 model2 loss : 0.021056
[01:34:59.634] iteration 22649 : model1 loss : 0.021583 model2 loss : 0.019821
[01:35:00.297] iteration 22650 : model1 loss : 0.019666 model2 loss : 0.019384
[01:35:01.000] iteration 22651 : model1 loss : 0.019269 model2 loss : 0.020562
[01:35:01.665] iteration 22652 : model1 loss : 0.026759 model2 loss : 0.020763
[01:35:02.334] iteration 22653 : model1 loss : 0.017371 model2 loss : 0.017350
[01:35:02.995] iteration 22654 : model1 loss : 0.027019 model2 loss : 0.028251
[01:35:03.649] iteration 22655 : model1 loss : 0.025538 model2 loss : 0.019940
[01:35:04.314] iteration 22656 : model1 loss : 0.018661 model2 loss : 0.020541
[01:35:04.985] iteration 22657 : model1 loss : 0.018320 model2 loss : 0.018545
[01:35:05.658] iteration 22658 : model1 loss : 0.020505 model2 loss : 0.017255
[01:35:06.323] iteration 22659 : model1 loss : 0.017216 model2 loss : 0.018419
[01:35:06.989] iteration 22660 : model1 loss : 0.017177 model2 loss : 0.017031
[01:35:07.649] iteration 22661 : model1 loss : 0.021287 model2 loss : 0.021701
[01:35:08.318] iteration 22662 : model1 loss : 0.016742 model2 loss : 0.018578
[01:35:08.966] iteration 22663 : model1 loss : 0.016395 model2 loss : 0.015912
[01:35:09.637] iteration 22664 : model1 loss : 0.020146 model2 loss : 0.017831
[01:35:10.316] iteration 22665 : model1 loss : 0.016006 model2 loss : 0.016584
[01:35:10.996] iteration 22666 : model1 loss : 0.021111 model2 loss : 0.021171
[01:35:11.668] iteration 22667 : model1 loss : 0.021886 model2 loss : 0.020256
[01:35:12.349] iteration 22668 : model1 loss : 0.019769 model2 loss : 0.022270
[01:35:13.020] iteration 22669 : model1 loss : 0.025969 model2 loss : 0.022976
[01:35:13.674] iteration 22670 : model1 loss : 0.018723 model2 loss : 0.018666
[01:35:14.342] iteration 22671 : model1 loss : 0.018592 model2 loss : 0.017904
[01:35:14.995] iteration 22672 : model1 loss : 0.023513 model2 loss : 0.022691
[01:35:15.661] iteration 22673 : model1 loss : 0.023290 model2 loss : 0.022835
[01:35:16.337] iteration 22674 : model1 loss : 0.019564 model2 loss : 0.018440
[01:35:16.992] iteration 22675 : model1 loss : 0.020967 model2 loss : 0.023412
[01:35:17.651] iteration 22676 : model1 loss : 0.022054 model2 loss : 0.021550
[01:35:18.329] iteration 22677 : model1 loss : 0.025940 model2 loss : 0.024062
[01:35:18.991] iteration 22678 : model1 loss : 0.020364 model2 loss : 0.020345
[01:35:19.662] iteration 22679 : model1 loss : 0.024337 model2 loss : 0.020390
[01:35:20.338] iteration 22680 : model1 loss : 0.020412 model2 loss : 0.019083
[01:35:21.003] iteration 22681 : model1 loss : 0.022700 model2 loss : 0.019613
[01:35:21.697] iteration 22682 : model1 loss : 0.018261 model2 loss : 0.018050
[01:35:22.366] iteration 22683 : model1 loss : 0.042639 model2 loss : 0.035877
[01:35:23.033] iteration 22684 : model1 loss : 0.022252 model2 loss : 0.024747
[01:35:23.696] iteration 22685 : model1 loss : 0.024729 model2 loss : 0.023812
[01:35:24.351] iteration 22686 : model1 loss : 0.020054 model2 loss : 0.021641
[01:35:25.018] iteration 22687 : model1 loss : 0.024787 model2 loss : 0.024064
[01:35:25.672] iteration 22688 : model1 loss : 0.025817 model2 loss : 0.023983
[01:35:26.354] iteration 22689 : model1 loss : 0.021278 model2 loss : 0.020482
[01:35:27.022] iteration 22690 : model1 loss : 0.032245 model2 loss : 0.031291
[01:35:27.688] iteration 22691 : model1 loss : 0.016400 model2 loss : 0.015955
[01:35:28.369] iteration 22692 : model1 loss : 0.022429 model2 loss : 0.022218
[01:35:29.035] iteration 22693 : model1 loss : 0.030771 model2 loss : 0.024325
[01:35:29.695] iteration 22694 : model1 loss : 0.018145 model2 loss : 0.017897
[01:35:30.365] iteration 22695 : model1 loss : 0.022769 model2 loss : 0.022680
[01:35:31.023] iteration 22696 : model1 loss : 0.017778 model2 loss : 0.017841
[01:35:31.687] iteration 22697 : model1 loss : 0.018706 model2 loss : 0.018473
[01:35:32.352] iteration 22698 : model1 loss : 0.020884 model2 loss : 0.021187
[01:35:33.020] iteration 22699 : model1 loss : 0.022140 model2 loss : 0.022120
[01:35:33.703] iteration 22700 : model1 loss : 0.016943 model2 loss : 0.016389
[01:35:34.414] iteration 22701 : model1 loss : 0.022800 model2 loss : 0.019444
[01:35:35.068] iteration 22702 : model1 loss : 0.018601 model2 loss : 0.019303
[01:35:35.725] iteration 22703 : model1 loss : 0.027962 model2 loss : 0.024463
[01:35:36.386] iteration 22704 : model1 loss : 0.018565 model2 loss : 0.019243
[01:35:37.054] iteration 22705 : model1 loss : 0.013982 model2 loss : 0.014207
[01:35:37.716] iteration 22706 : model1 loss : 0.025296 model2 loss : 0.025864
[01:35:38.382] iteration 22707 : model1 loss : 0.018144 model2 loss : 0.016944
[01:35:39.043] iteration 22708 : model1 loss : 0.020677 model2 loss : 0.020287
[01:35:39.697] iteration 22709 : model1 loss : 0.023672 model2 loss : 0.024878
[01:35:40.365] iteration 22710 : model1 loss : 0.028806 model2 loss : 0.033738
[01:35:41.042] iteration 22711 : model1 loss : 0.027504 model2 loss : 0.027413
[01:35:41.711] iteration 22712 : model1 loss : 0.017825 model2 loss : 0.021551
[01:35:42.385] iteration 22713 : model1 loss : 0.017394 model2 loss : 0.016744
[01:35:43.051] iteration 22714 : model1 loss : 0.024037 model2 loss : 0.023335
[01:35:43.719] iteration 22715 : model1 loss : 0.024839 model2 loss : 0.025737
[01:35:44.391] iteration 22716 : model1 loss : 0.023206 model2 loss : 0.024052
[01:35:45.066] iteration 22717 : model1 loss : 0.020531 model2 loss : 0.023236
[01:35:45.730] iteration 22718 : model1 loss : 0.019613 model2 loss : 0.023457
[01:35:46.391] iteration 22719 : model1 loss : 0.014046 model2 loss : 0.014396
[01:35:47.056] iteration 22720 : model1 loss : 0.144224 model2 loss : 0.143974
[01:35:47.723] iteration 22721 : model1 loss : 0.019497 model2 loss : 0.019882
[01:35:48.373] iteration 22722 : model1 loss : 0.018336 model2 loss : 0.017675
[01:35:49.036] iteration 22723 : model1 loss : 0.024989 model2 loss : 0.030202
[01:35:49.694] iteration 22724 : model1 loss : 0.018307 model2 loss : 0.018607
[01:35:50.364] iteration 22725 : model1 loss : 0.020382 model2 loss : 0.019503
[01:35:51.024] iteration 22726 : model1 loss : 0.017644 model2 loss : 0.017068
[01:35:51.691] iteration 22727 : model1 loss : 0.017782 model2 loss : 0.017720
[01:35:52.374] iteration 22728 : model1 loss : 0.019817 model2 loss : 0.020164
[01:35:53.038] iteration 22729 : model1 loss : 0.019632 model2 loss : 0.017637
[01:35:53.707] iteration 22730 : model1 loss : 0.015082 model2 loss : 0.015570
[01:35:54.376] iteration 22731 : model1 loss : 0.021854 model2 loss : 0.021915
[01:35:55.034] iteration 22732 : model1 loss : 0.020002 model2 loss : 0.019156
[01:35:55.703] iteration 22733 : model1 loss : 0.021773 model2 loss : 0.022312
[01:35:56.367] iteration 22734 : model1 loss : 0.018892 model2 loss : 0.019447
[01:35:57.040] iteration 22735 : model1 loss : 0.012134 model2 loss : 0.013410
[01:35:57.710] iteration 22736 : model1 loss : 0.021608 model2 loss : 0.019082
[01:35:58.375] iteration 22737 : model1 loss : 0.024861 model2 loss : 0.023027
[01:35:59.040] iteration 22738 : model1 loss : 0.019843 model2 loss : 0.018328
[01:35:59.692] iteration 22739 : model1 loss : 0.016940 model2 loss : 0.017952
[01:36:00.371] iteration 22740 : model1 loss : 0.017156 model2 loss : 0.017529
[01:36:01.043] iteration 22741 : model1 loss : 0.020665 model2 loss : 0.020873
[01:36:01.704] iteration 22742 : model1 loss : 0.029180 model2 loss : 0.027873
[01:36:02.379] iteration 22743 : model1 loss : 0.017739 model2 loss : 0.019407
[01:36:03.041] iteration 22744 : model1 loss : 0.021453 model2 loss : 0.019470
[01:36:03.699] iteration 22745 : model1 loss : 0.020685 model2 loss : 0.018900
[01:36:04.359] iteration 22746 : model1 loss : 0.019855 model2 loss : 0.018385
[01:36:05.019] iteration 22747 : model1 loss : 0.026596 model2 loss : 0.024811
[01:36:05.676] iteration 22748 : model1 loss : 0.016687 model2 loss : 0.015974
[01:36:06.344] iteration 22749 : model1 loss : 0.028463 model2 loss : 0.024497
[01:36:07.009] iteration 22750 : model1 loss : 0.021796 model2 loss : 0.023848
[01:36:07.714] iteration 22751 : model1 loss : 0.023725 model2 loss : 0.025665
[01:36:08.378] iteration 22752 : model1 loss : 0.022231 model2 loss : 0.022753
[01:36:09.049] iteration 22753 : model1 loss : 0.019288 model2 loss : 0.019932
[01:36:09.712] iteration 22754 : model1 loss : 0.017418 model2 loss : 0.017161
[01:36:10.378] iteration 22755 : model1 loss : 0.020605 model2 loss : 0.020807
[01:36:11.045] iteration 22756 : model1 loss : 0.018063 model2 loss : 0.018497
[01:36:11.711] iteration 22757 : model1 loss : 0.017756 model2 loss : 0.019858
[01:36:12.373] iteration 22758 : model1 loss : 0.028261 model2 loss : 0.024864
[01:36:13.050] iteration 22759 : model1 loss : 0.017502 model2 loss : 0.017700
[01:36:13.718] iteration 22760 : model1 loss : 0.020285 model2 loss : 0.022580
[01:36:14.382] iteration 22761 : model1 loss : 0.019010 model2 loss : 0.017275
[01:36:15.032] iteration 22762 : model1 loss : 0.017432 model2 loss : 0.017485
[01:36:15.693] iteration 22763 : model1 loss : 0.013034 model2 loss : 0.013754
[01:36:16.357] iteration 22764 : model1 loss : 0.021985 model2 loss : 0.023373
[01:36:17.022] iteration 22765 : model1 loss : 0.022191 model2 loss : 0.022700
[01:36:17.694] iteration 22766 : model1 loss : 0.023137 model2 loss : 0.022550
[01:36:18.363] iteration 22767 : model1 loss : 0.020901 model2 loss : 0.021522
[01:36:19.034] iteration 22768 : model1 loss : 0.020104 model2 loss : 0.020977
[01:36:19.697] iteration 22769 : model1 loss : 0.022776 model2 loss : 0.023047
[01:36:20.368] iteration 22770 : model1 loss : 0.015835 model2 loss : 0.015094
[01:36:21.048] iteration 22771 : model1 loss : 0.022221 model2 loss : 0.022699
[01:36:21.711] iteration 22772 : model1 loss : 0.023939 model2 loss : 0.024398
[01:36:22.379] iteration 22773 : model1 loss : 0.024922 model2 loss : 0.025145
[01:36:23.059] iteration 22774 : model1 loss : 0.023224 model2 loss : 0.021676
[01:36:23.774] iteration 22775 : model1 loss : 0.022633 model2 loss : 0.023760
[01:36:24.493] iteration 22776 : model1 loss : 0.017896 model2 loss : 0.018151
[01:36:25.196] iteration 22777 : model1 loss : 0.016197 model2 loss : 0.016007
[01:36:25.868] iteration 22778 : model1 loss : 0.020212 model2 loss : 0.020172
[01:36:26.534] iteration 22779 : model1 loss : 0.020647 model2 loss : 0.027936
[01:36:27.199] iteration 22780 : model1 loss : 0.032270 model2 loss : 0.029644
[01:36:27.869] iteration 22781 : model1 loss : 0.019311 model2 loss : 0.017737
[01:36:28.529] iteration 22782 : model1 loss : 0.019383 model2 loss : 0.017376
[01:36:29.201] iteration 22783 : model1 loss : 0.020699 model2 loss : 0.018290
[01:36:29.865] iteration 22784 : model1 loss : 0.016291 model2 loss : 0.016299
[01:36:30.527] iteration 22785 : model1 loss : 0.025041 model2 loss : 0.022618
[01:36:31.192] iteration 22786 : model1 loss : 0.020562 model2 loss : 0.019070
[01:36:31.858] iteration 22787 : model1 loss : 0.027410 model2 loss : 0.016815
[01:36:32.526] iteration 22788 : model1 loss : 0.018275 model2 loss : 0.018735
[01:36:33.195] iteration 22789 : model1 loss : 0.020299 model2 loss : 0.018775
[01:36:33.859] iteration 22790 : model1 loss : 0.026250 model2 loss : 0.024712
[01:36:34.564] iteration 22791 : model1 loss : 0.019808 model2 loss : 0.019002
[01:36:35.237] iteration 22792 : model1 loss : 0.018847 model2 loss : 0.018235
[01:36:35.906] iteration 22793 : model1 loss : 0.021825 model2 loss : 0.020205
[01:36:36.569] iteration 22794 : model1 loss : 0.022194 model2 loss : 0.020663
[01:36:37.225] iteration 22795 : model1 loss : 0.025455 model2 loss : 0.025418
[01:36:37.893] iteration 22796 : model1 loss : 0.016467 model2 loss : 0.018041
[01:36:38.564] iteration 22797 : model1 loss : 0.032525 model2 loss : 0.032472
[01:36:39.267] iteration 22798 : model1 loss : 0.032477 model2 loss : 0.032285
[01:36:39.933] iteration 22799 : model1 loss : 0.020079 model2 loss : 0.021581
[01:36:40.614] iteration 22800 : model1 loss : 0.019261 model2 loss : 0.020273
[01:36:58.676] iteration 22800 : model1_mean_dice : 0.872435 model1_mean_hd95 : 4.773753
[01:37:16.593] iteration 22800 : model2_mean_dice : 0.874320 model2_mean_hd95 : 4.855510
[01:37:17.282] iteration 22801 : model1 loss : 0.023000 model2 loss : 0.022006
[01:37:17.931] iteration 22802 : model1 loss : 0.015157 model2 loss : 0.013243
[01:37:18.593] iteration 22803 : model1 loss : 0.022726 model2 loss : 0.020920
[01:37:19.254] iteration 22804 : model1 loss : 0.021769 model2 loss : 0.023209
[01:37:19.911] iteration 22805 : model1 loss : 0.017843 model2 loss : 0.018670
[01:37:20.575] iteration 22806 : model1 loss : 0.016464 model2 loss : 0.015189
[01:37:21.253] iteration 22807 : model1 loss : 0.021263 model2 loss : 0.020440
[01:37:21.916] iteration 22808 : model1 loss : 0.023270 model2 loss : 0.026749
[01:37:22.574] iteration 22809 : model1 loss : 0.022741 model2 loss : 0.023392
[01:37:23.247] iteration 22810 : model1 loss : 0.020305 model2 loss : 0.019886
[01:37:23.912] iteration 22811 : model1 loss : 0.027135 model2 loss : 0.029131
[01:37:24.567] iteration 22812 : model1 loss : 0.022103 model2 loss : 0.020745
[01:37:25.226] iteration 22813 : model1 loss : 0.015061 model2 loss : 0.014718
[01:37:25.884] iteration 22814 : model1 loss : 0.020292 model2 loss : 0.022028
[01:37:26.562] iteration 22815 : model1 loss : 0.017964 model2 loss : 0.016944
[01:37:27.227] iteration 22816 : model1 loss : 0.017032 model2 loss : 0.015550
[01:37:27.886] iteration 22817 : model1 loss : 0.014182 model2 loss : 0.014071
[01:37:28.554] iteration 22818 : model1 loss : 0.021614 model2 loss : 0.021858
[01:37:29.221] iteration 22819 : model1 loss : 0.024790 model2 loss : 0.025070
[01:37:29.876] iteration 22820 : model1 loss : 0.026366 model2 loss : 0.022174
[01:37:30.535] iteration 22821 : model1 loss : 0.018781 model2 loss : 0.018272
[01:37:31.199] iteration 22822 : model1 loss : 0.019290 model2 loss : 0.018851
[01:37:31.869] iteration 22823 : model1 loss : 0.025452 model2 loss : 0.027469
[01:37:32.538] iteration 22824 : model1 loss : 0.019029 model2 loss : 0.017405
[01:37:33.199] iteration 22825 : model1 loss : 0.024102 model2 loss : 0.025182
[01:37:33.850] iteration 22826 : model1 loss : 0.016143 model2 loss : 0.016541
[01:37:34.511] iteration 22827 : model1 loss : 0.017145 model2 loss : 0.016356
[01:37:35.187] iteration 22828 : model1 loss : 0.021186 model2 loss : 0.021902
[01:37:35.858] iteration 22829 : model1 loss : 0.017567 model2 loss : 0.017872
[01:37:36.520] iteration 22830 : model1 loss : 0.019445 model2 loss : 0.018470
[01:37:37.196] iteration 22831 : model1 loss : 0.045404 model2 loss : 0.040070
[01:37:37.876] iteration 22832 : model1 loss : 0.039410 model2 loss : 0.044907
[01:37:38.553] iteration 22833 : model1 loss : 0.026586 model2 loss : 0.024643
[01:37:39.217] iteration 22834 : model1 loss : 0.029075 model2 loss : 0.027554
[01:37:39.892] iteration 22835 : model1 loss : 0.023935 model2 loss : 0.023489
[01:37:40.558] iteration 22836 : model1 loss : 0.021070 model2 loss : 0.019855
[01:37:41.242] iteration 22837 : model1 loss : 0.025460 model2 loss : 0.024600
[01:37:41.905] iteration 22838 : model1 loss : 0.019020 model2 loss : 0.018138
[01:37:42.577] iteration 22839 : model1 loss : 0.021597 model2 loss : 0.022559
[01:37:43.251] iteration 22840 : model1 loss : 0.021401 model2 loss : 0.020508
[01:37:43.912] iteration 22841 : model1 loss : 0.020956 model2 loss : 0.023901
[01:37:44.570] iteration 22842 : model1 loss : 0.025689 model2 loss : 0.020479
[01:37:45.229] iteration 22843 : model1 loss : 0.027307 model2 loss : 0.027064
[01:37:45.892] iteration 22844 : model1 loss : 0.017754 model2 loss : 0.019052
[01:37:46.563] iteration 22845 : model1 loss : 0.026184 model2 loss : 0.026817
[01:37:47.223] iteration 22846 : model1 loss : 0.015285 model2 loss : 0.015049
[01:37:47.879] iteration 22847 : model1 loss : 0.019012 model2 loss : 0.018203
[01:37:48.551] iteration 22848 : model1 loss : 0.022624 model2 loss : 0.021267
[01:37:49.202] iteration 22849 : model1 loss : 0.033346 model2 loss : 0.028629
[01:37:49.858] iteration 22850 : model1 loss : 0.017155 model2 loss : 0.016784
[01:37:50.560] iteration 22851 : model1 loss : 0.064057 model2 loss : 0.051847
[01:37:51.218] iteration 22852 : model1 loss : 0.036338 model2 loss : 0.055964
[01:37:51.895] iteration 22853 : model1 loss : 0.019086 model2 loss : 0.018662
[01:37:52.564] iteration 22854 : model1 loss : 0.017474 model2 loss : 0.018199
[01:37:53.244] iteration 22855 : model1 loss : 0.021139 model2 loss : 0.019566
[01:37:53.904] iteration 22856 : model1 loss : 0.041576 model2 loss : 0.041858
[01:37:54.557] iteration 22857 : model1 loss : 0.020699 model2 loss : 0.018925
[01:37:55.223] iteration 22858 : model1 loss : 0.024578 model2 loss : 0.031034
[01:37:55.890] iteration 22859 : model1 loss : 0.016912 model2 loss : 0.016759
[01:37:56.563] iteration 22860 : model1 loss : 0.016604 model2 loss : 0.016160
[01:37:57.221] iteration 22861 : model1 loss : 0.019795 model2 loss : 0.018984
[01:37:57.881] iteration 22862 : model1 loss : 0.016827 model2 loss : 0.015573
[01:37:58.564] iteration 22863 : model1 loss : 0.016987 model2 loss : 0.018744
[01:37:59.223] iteration 22864 : model1 loss : 0.025014 model2 loss : 0.025421
[01:37:59.884] iteration 22865 : model1 loss : 0.021236 model2 loss : 0.018767
[01:38:00.550] iteration 22866 : model1 loss : 0.020488 model2 loss : 0.023919
[01:38:01.228] iteration 22867 : model1 loss : 0.026057 model2 loss : 0.027587
[01:38:01.908] iteration 22868 : model1 loss : 0.021772 model2 loss : 0.019693
[01:38:02.587] iteration 22869 : model1 loss : 0.016642 model2 loss : 0.016170
[01:38:03.254] iteration 22870 : model1 loss : 0.026931 model2 loss : 0.025899
[01:38:03.910] iteration 22871 : model1 loss : 0.033530 model2 loss : 0.017609
[01:38:04.591] iteration 22872 : model1 loss : 0.020628 model2 loss : 0.019863
[01:38:05.259] iteration 22873 : model1 loss : 0.018558 model2 loss : 0.019111
[01:38:05.926] iteration 22874 : model1 loss : 0.020270 model2 loss : 0.019055
[01:38:06.588] iteration 22875 : model1 loss : 0.019453 model2 loss : 0.018789
[01:38:07.259] iteration 22876 : model1 loss : 0.032505 model2 loss : 0.033229
[01:38:07.921] iteration 22877 : model1 loss : 0.016064 model2 loss : 0.016364
[01:38:08.607] iteration 22878 : model1 loss : 0.021451 model2 loss : 0.022199
[01:38:09.262] iteration 22879 : model1 loss : 0.028757 model2 loss : 0.027360
[01:38:09.922] iteration 22880 : model1 loss : 0.025034 model2 loss : 0.025121
[01:38:10.589] iteration 22881 : model1 loss : 0.029036 model2 loss : 0.025318
[01:38:11.258] iteration 22882 : model1 loss : 0.017790 model2 loss : 0.017360
[01:38:11.932] iteration 22883 : model1 loss : 0.023999 model2 loss : 0.021633
[01:38:12.590] iteration 22884 : model1 loss : 0.141656 model2 loss : 0.141328
[01:38:13.252] iteration 22885 : model1 loss : 0.028717 model2 loss : 0.029101
[01:38:13.903] iteration 22886 : model1 loss : 0.019833 model2 loss : 0.019723
[01:38:14.565] iteration 22887 : model1 loss : 0.021067 model2 loss : 0.021912
[01:38:15.228] iteration 22888 : model1 loss : 0.020945 model2 loss : 0.019900
[01:38:15.884] iteration 22889 : model1 loss : 0.021190 model2 loss : 0.019658
[01:38:16.553] iteration 22890 : model1 loss : 0.021791 model2 loss : 0.020411
[01:38:17.223] iteration 22891 : model1 loss : 0.023477 model2 loss : 0.023294
[01:38:17.876] iteration 22892 : model1 loss : 0.016680 model2 loss : 0.016115
[01:38:18.544] iteration 22893 : model1 loss : 0.021421 model2 loss : 0.022365
[01:38:19.203] iteration 22894 : model1 loss : 0.019555 model2 loss : 0.019852
[01:38:19.866] iteration 22895 : model1 loss : 0.049759 model2 loss : 0.028483
[01:38:20.544] iteration 22896 : model1 loss : 0.016111 model2 loss : 0.017239
[01:38:21.211] iteration 22897 : model1 loss : 0.024079 model2 loss : 0.023824
[01:38:21.880] iteration 22898 : model1 loss : 0.018485 model2 loss : 0.017682
[01:38:22.550] iteration 22899 : model1 loss : 0.018610 model2 loss : 0.018235
[01:38:23.215] iteration 22900 : model1 loss : 0.022404 model2 loss : 0.020238
[01:38:23.927] iteration 22901 : model1 loss : 0.018258 model2 loss : 0.018753
[01:38:24.649] iteration 22902 : model1 loss : 0.018393 model2 loss : 0.018241
[01:38:25.339] iteration 22903 : model1 loss : 0.021099 model2 loss : 0.025100
[01:38:26.003] iteration 22904 : model1 loss : 0.017291 model2 loss : 0.016742
[01:38:26.663] iteration 22905 : model1 loss : 0.023697 model2 loss : 0.022462
[01:38:27.333] iteration 22906 : model1 loss : 0.028681 model2 loss : 0.031156
[01:38:27.986] iteration 22907 : model1 loss : 0.038918 model2 loss : 0.034273
[01:38:28.650] iteration 22908 : model1 loss : 0.020753 model2 loss : 0.020142
[01:38:29.320] iteration 22909 : model1 loss : 0.017200 model2 loss : 0.015114
[01:38:29.972] iteration 22910 : model1 loss : 0.029700 model2 loss : 0.027052
[01:38:30.647] iteration 22911 : model1 loss : 0.015471 model2 loss : 0.015760
[01:38:31.314] iteration 22912 : model1 loss : 0.026209 model2 loss : 0.026444
[01:38:31.983] iteration 22913 : model1 loss : 0.021149 model2 loss : 0.021090
[01:38:32.650] iteration 22914 : model1 loss : 0.022812 model2 loss : 0.022445
[01:38:33.338] iteration 22915 : model1 loss : 0.022074 model2 loss : 0.019849
[01:38:34.006] iteration 22916 : model1 loss : 0.016056 model2 loss : 0.016338
[01:38:34.663] iteration 22917 : model1 loss : 0.019544 model2 loss : 0.019544
[01:38:35.345] iteration 22918 : model1 loss : 0.022053 model2 loss : 0.021956
[01:38:36.030] iteration 22919 : model1 loss : 0.020899 model2 loss : 0.019540
[01:38:36.709] iteration 22920 : model1 loss : 0.019202 model2 loss : 0.019640
[01:38:37.368] iteration 22921 : model1 loss : 0.018649 model2 loss : 0.019123
[01:38:38.037] iteration 22922 : model1 loss : 0.020573 model2 loss : 0.021584
[01:38:38.705] iteration 22923 : model1 loss : 0.017590 model2 loss : 0.016801
[01:38:39.366] iteration 22924 : model1 loss : 0.018328 model2 loss : 0.018676
[01:38:40.016] iteration 22925 : model1 loss : 0.014406 model2 loss : 0.018526
[01:38:40.691] iteration 22926 : model1 loss : 0.021897 model2 loss : 0.017951
[01:38:41.358] iteration 22927 : model1 loss : 0.016914 model2 loss : 0.015793
[01:38:42.012] iteration 22928 : model1 loss : 0.017058 model2 loss : 0.016227
[01:38:42.691] iteration 22929 : model1 loss : 0.022826 model2 loss : 0.023034
[01:38:43.376] iteration 22930 : model1 loss : 0.023997 model2 loss : 0.021311
[01:38:44.047] iteration 22931 : model1 loss : 0.028478 model2 loss : 0.021836
[01:38:44.710] iteration 22932 : model1 loss : 0.022642 model2 loss : 0.021837
[01:38:45.368] iteration 22933 : model1 loss : 0.021518 model2 loss : 0.020687
[01:38:46.032] iteration 22934 : model1 loss : 0.018667 model2 loss : 0.017035
[01:38:46.681] iteration 22935 : model1 loss : 0.015330 model2 loss : 0.016102
[01:38:47.350] iteration 22936 : model1 loss : 0.020456 model2 loss : 0.020592
[01:38:48.017] iteration 22937 : model1 loss : 0.024727 model2 loss : 0.024481
[01:38:48.697] iteration 22938 : model1 loss : 0.020853 model2 loss : 0.022209
[01:38:49.370] iteration 22939 : model1 loss : 0.018459 model2 loss : 0.019252
[01:38:50.027] iteration 22940 : model1 loss : 0.018153 model2 loss : 0.017335
[01:38:50.694] iteration 22941 : model1 loss : 0.018874 model2 loss : 0.017381
[01:38:51.354] iteration 22942 : model1 loss : 0.021899 model2 loss : 0.026848
[01:38:52.027] iteration 22943 : model1 loss : 0.026785 model2 loss : 0.028315
[01:38:52.711] iteration 22944 : model1 loss : 0.020327 model2 loss : 0.019458
[01:38:53.369] iteration 22945 : model1 loss : 0.019945 model2 loss : 0.019438
[01:38:54.036] iteration 22946 : model1 loss : 0.030509 model2 loss : 0.030845
[01:38:54.696] iteration 22947 : model1 loss : 0.071096 model2 loss : 0.076672
[01:38:55.368] iteration 22948 : model1 loss : 0.025008 model2 loss : 0.022345
[01:38:56.036] iteration 22949 : model1 loss : 0.025288 model2 loss : 0.025634
[01:38:56.707] iteration 22950 : model1 loss : 0.019761 model2 loss : 0.018331
[01:38:57.407] iteration 22951 : model1 loss : 0.016404 model2 loss : 0.016026
[01:38:58.070] iteration 22952 : model1 loss : 0.027995 model2 loss : 0.025875
[01:38:58.748] iteration 22953 : model1 loss : 0.025490 model2 loss : 0.021611
[01:38:59.416] iteration 22954 : model1 loss : 0.018438 model2 loss : 0.018685
[01:39:00.113] iteration 22955 : model1 loss : 0.025103 model2 loss : 0.022929
[01:39:00.770] iteration 22956 : model1 loss : 0.020305 model2 loss : 0.021017
[01:39:01.447] iteration 22957 : model1 loss : 0.014477 model2 loss : 0.014996
[01:39:02.120] iteration 22958 : model1 loss : 0.025811 model2 loss : 0.021604
[01:39:02.775] iteration 22959 : model1 loss : 0.017384 model2 loss : 0.019367
[01:39:03.445] iteration 22960 : model1 loss : 0.027388 model2 loss : 0.031101
[01:39:04.101] iteration 22961 : model1 loss : 0.020115 model2 loss : 0.021988
[01:39:04.770] iteration 22962 : model1 loss : 0.017866 model2 loss : 0.017137
[01:39:05.445] iteration 22963 : model1 loss : 0.030121 model2 loss : 0.027430
[01:39:06.115] iteration 22964 : model1 loss : 0.023223 model2 loss : 0.019469
[01:39:06.785] iteration 22965 : model1 loss : 0.015734 model2 loss : 0.015903
[01:39:07.444] iteration 22966 : model1 loss : 0.025246 model2 loss : 0.023690
[01:39:08.107] iteration 22967 : model1 loss : 0.019631 model2 loss : 0.018470
[01:39:08.779] iteration 22968 : model1 loss : 0.021265 model2 loss : 0.020235
[01:39:09.443] iteration 22969 : model1 loss : 0.023035 model2 loss : 0.024125
[01:39:10.107] iteration 22970 : model1 loss : 0.030567 model2 loss : 0.032054
[01:39:10.776] iteration 22971 : model1 loss : 0.024231 model2 loss : 0.021575
[01:39:11.464] iteration 22972 : model1 loss : 0.021619 model2 loss : 0.021823
[01:39:12.133] iteration 22973 : model1 loss : 0.021407 model2 loss : 0.023368
[01:39:12.806] iteration 22974 : model1 loss : 0.019527 model2 loss : 0.020430
[01:39:13.482] iteration 22975 : model1 loss : 0.035866 model2 loss : 0.025100
[01:39:14.172] iteration 22976 : model1 loss : 0.022336 model2 loss : 0.022138
[01:39:14.842] iteration 22977 : model1 loss : 0.019254 model2 loss : 0.018263
[01:39:15.510] iteration 22978 : model1 loss : 0.019862 model2 loss : 0.019458
[01:39:16.167] iteration 22979 : model1 loss : 0.021842 model2 loss : 0.022677
[01:39:16.839] iteration 22980 : model1 loss : 0.021471 model2 loss : 0.023488
[01:39:17.508] iteration 22981 : model1 loss : 0.035540 model2 loss : 0.031752
[01:39:18.177] iteration 22982 : model1 loss : 0.016190 model2 loss : 0.015956
[01:39:18.847] iteration 22983 : model1 loss : 0.035946 model2 loss : 0.038710
[01:39:19.536] iteration 22984 : model1 loss : 0.018114 model2 loss : 0.015761
[01:39:20.208] iteration 22985 : model1 loss : 0.018380 model2 loss : 0.019503
[01:39:20.882] iteration 22986 : model1 loss : 0.016583 model2 loss : 0.018277
[01:39:21.554] iteration 22987 : model1 loss : 0.019305 model2 loss : 0.017480
[01:39:22.221] iteration 22988 : model1 loss : 0.021839 model2 loss : 0.020164
[01:39:22.882] iteration 22989 : model1 loss : 0.026474 model2 loss : 0.022680
[01:39:23.553] iteration 22990 : model1 loss : 0.020399 model2 loss : 0.022541
[01:39:24.209] iteration 22991 : model1 loss : 0.023938 model2 loss : 0.026876
[01:39:24.870] iteration 22992 : model1 loss : 0.022604 model2 loss : 0.023165
[01:39:25.538] iteration 22993 : model1 loss : 0.038530 model2 loss : 0.037946
[01:39:26.199] iteration 22994 : model1 loss : 0.021790 model2 loss : 0.020188
[01:39:26.871] iteration 22995 : model1 loss : 0.024229 model2 loss : 0.021882
[01:39:27.594] iteration 22996 : model1 loss : 0.029452 model2 loss : 0.032047
[01:39:28.295] iteration 22997 : model1 loss : 0.019222 model2 loss : 0.019982
[01:39:28.962] iteration 22998 : model1 loss : 0.020032 model2 loss : 0.022091
[01:39:29.617] iteration 22999 : model1 loss : 0.017159 model2 loss : 0.016800
[01:39:30.289] iteration 23000 : model1 loss : 0.017174 model2 loss : 0.017256
[01:39:48.708] iteration 23000 : model1_mean_dice : 0.871766 model1_mean_hd95 : 5.129039
[01:40:06.546] iteration 23000 : model2_mean_dice : 0.875202 model2_mean_hd95 : 4.579801
[01:40:07.224] iteration 23001 : model1 loss : 0.014945 model2 loss : 0.012912
[01:40:07.875] iteration 23002 : model1 loss : 0.015516 model2 loss : 0.018154
[01:40:08.533] iteration 23003 : model1 loss : 0.025317 model2 loss : 0.025071
[01:40:09.194] iteration 23004 : model1 loss : 0.019800 model2 loss : 0.019081
[01:40:09.863] iteration 23005 : model1 loss : 0.020403 model2 loss : 0.019475
[01:40:10.531] iteration 23006 : model1 loss : 0.019959 model2 loss : 0.021441
[01:40:11.183] iteration 23007 : model1 loss : 0.021786 model2 loss : 0.021865
[01:40:11.851] iteration 23008 : model1 loss : 0.148088 model2 loss : 0.145958
[01:40:12.535] iteration 23009 : model1 loss : 0.021752 model2 loss : 0.020451
[01:40:13.183] iteration 23010 : model1 loss : 0.018224 model2 loss : 0.017114
[01:40:13.851] iteration 23011 : model1 loss : 0.020930 model2 loss : 0.021274
[01:40:14.507] iteration 23012 : model1 loss : 0.025724 model2 loss : 0.021709
[01:40:15.164] iteration 23013 : model1 loss : 0.023347 model2 loss : 0.020555
[01:40:15.822] iteration 23014 : model1 loss : 0.017091 model2 loss : 0.018340
[01:40:16.476] iteration 23015 : model1 loss : 0.017970 model2 loss : 0.017738
[01:40:17.132] iteration 23016 : model1 loss : 0.021688 model2 loss : 0.022296
[01:40:17.790] iteration 23017 : model1 loss : 0.038549 model2 loss : 0.037726
[01:40:18.457] iteration 23018 : model1 loss : 0.017422 model2 loss : 0.017654
[01:40:19.119] iteration 23019 : model1 loss : 0.019207 model2 loss : 0.018782
[01:40:19.782] iteration 23020 : model1 loss : 0.017996 model2 loss : 0.016955
[01:40:20.441] iteration 23021 : model1 loss : 0.019808 model2 loss : 0.019230
[01:40:21.124] iteration 23022 : model1 loss : 0.018537 model2 loss : 0.020141
[01:40:21.784] iteration 23023 : model1 loss : 0.024074 model2 loss : 0.024262
[01:40:22.459] iteration 23024 : model1 loss : 0.015669 model2 loss : 0.016691
[01:40:23.128] iteration 23025 : model1 loss : 0.017607 model2 loss : 0.017703
[01:40:23.784] iteration 23026 : model1 loss : 0.025504 model2 loss : 0.027722
[01:40:24.446] iteration 23027 : model1 loss : 0.021327 model2 loss : 0.021964
[01:40:25.105] iteration 23028 : model1 loss : 0.017546 model2 loss : 0.017253
[01:40:25.771] iteration 23029 : model1 loss : 0.043953 model2 loss : 0.036768
[01:40:26.437] iteration 23030 : model1 loss : 0.020398 model2 loss : 0.020002
[01:40:27.089] iteration 23031 : model1 loss : 0.019779 model2 loss : 0.018701
[01:40:27.760] iteration 23032 : model1 loss : 0.021501 model2 loss : 0.019981
[01:40:28.424] iteration 23033 : model1 loss : 0.021981 model2 loss : 0.023815
[01:40:29.088] iteration 23034 : model1 loss : 0.018706 model2 loss : 0.016913
[01:40:29.746] iteration 23035 : model1 loss : 0.020825 model2 loss : 0.022275
[01:40:30.418] iteration 23036 : model1 loss : 0.021200 model2 loss : 0.024424
[01:40:31.083] iteration 23037 : model1 loss : 0.021461 model2 loss : 0.020851
[01:40:31.766] iteration 23038 : model1 loss : 0.017806 model2 loss : 0.018863
[01:40:32.439] iteration 23039 : model1 loss : 0.018974 model2 loss : 0.018605
[01:40:33.096] iteration 23040 : model1 loss : 0.017893 model2 loss : 0.019320
[01:40:33.752] iteration 23041 : model1 loss : 0.018633 model2 loss : 0.021097
[01:40:34.414] iteration 23042 : model1 loss : 0.025715 model2 loss : 0.025162
[01:40:35.073] iteration 23043 : model1 loss : 0.032149 model2 loss : 0.033770
[01:40:35.739] iteration 23044 : model1 loss : 0.015709 model2 loss : 0.015715
[01:40:36.429] iteration 23045 : model1 loss : 0.016087 model2 loss : 0.016746
[01:40:37.094] iteration 23046 : model1 loss : 0.059690 model2 loss : 0.056409
[01:40:37.764] iteration 23047 : model1 loss : 0.024222 model2 loss : 0.025094
[01:40:38.435] iteration 23048 : model1 loss : 0.019776 model2 loss : 0.020864
[01:40:39.095] iteration 23049 : model1 loss : 0.020399 model2 loss : 0.022509
[01:40:39.763] iteration 23050 : model1 loss : 0.024041 model2 loss : 0.024263
[01:40:40.458] iteration 23051 : model1 loss : 0.018885 model2 loss : 0.020073
[01:40:41.131] iteration 23052 : model1 loss : 0.035324 model2 loss : 0.038366
[01:40:41.791] iteration 23053 : model1 loss : 0.019462 model2 loss : 0.018879
[01:40:42.468] iteration 23054 : model1 loss : 0.022172 model2 loss : 0.024594
[01:40:43.130] iteration 23055 : model1 loss : 0.015204 model2 loss : 0.017217
[01:40:43.794] iteration 23056 : model1 loss : 0.021091 model2 loss : 0.022180
[01:40:44.465] iteration 23057 : model1 loss : 0.020198 model2 loss : 0.021735
[01:40:45.123] iteration 23058 : model1 loss : 0.023733 model2 loss : 0.021926
[01:40:45.780] iteration 23059 : model1 loss : 0.022770 model2 loss : 0.023641
[01:40:46.452] iteration 23060 : model1 loss : 0.021013 model2 loss : 0.021510
[01:40:47.112] iteration 23061 : model1 loss : 0.019887 model2 loss : 0.017319
[01:40:47.769] iteration 23062 : model1 loss : 0.017872 model2 loss : 0.019572
[01:40:48.426] iteration 23063 : model1 loss : 0.017940 model2 loss : 0.015249
[01:40:49.086] iteration 23064 : model1 loss : 0.018587 model2 loss : 0.018521
[01:40:49.746] iteration 23065 : model1 loss : 0.025248 model2 loss : 0.026676
[01:40:50.411] iteration 23066 : model1 loss : 0.018067 model2 loss : 0.020626
[01:40:51.071] iteration 23067 : model1 loss : 0.025519 model2 loss : 0.022344
[01:40:51.727] iteration 23068 : model1 loss : 0.019118 model2 loss : 0.021703
[01:40:52.384] iteration 23069 : model1 loss : 0.015996 model2 loss : 0.015809
[01:40:53.050] iteration 23070 : model1 loss : 0.021199 model2 loss : 0.023416
[01:40:53.728] iteration 23071 : model1 loss : 0.015948 model2 loss : 0.015949
[01:40:54.408] iteration 23072 : model1 loss : 0.024878 model2 loss : 0.028263
[01:40:55.076] iteration 23073 : model1 loss : 0.018200 model2 loss : 0.017552
[01:40:55.745] iteration 23074 : model1 loss : 0.017970 model2 loss : 0.019016
[01:40:56.423] iteration 23075 : model1 loss : 0.023626 model2 loss : 0.023857
[01:40:57.092] iteration 23076 : model1 loss : 0.027707 model2 loss : 0.026263
[01:40:57.761] iteration 23077 : model1 loss : 0.019004 model2 loss : 0.019386
[01:40:58.439] iteration 23078 : model1 loss : 0.021078 model2 loss : 0.021950
[01:40:59.112] iteration 23079 : model1 loss : 0.018988 model2 loss : 0.021337
[01:40:59.773] iteration 23080 : model1 loss : 0.020751 model2 loss : 0.021192
[01:41:00.456] iteration 23081 : model1 loss : 0.019141 model2 loss : 0.020145
[01:41:01.122] iteration 23082 : model1 loss : 0.033274 model2 loss : 0.027698
[01:41:01.794] iteration 23083 : model1 loss : 0.025088 model2 loss : 0.024288
[01:41:02.477] iteration 23084 : model1 loss : 0.022044 model2 loss : 0.019919
[01:41:03.145] iteration 23085 : model1 loss : 0.017278 model2 loss : 0.016632
[01:41:03.816] iteration 23086 : model1 loss : 0.026258 model2 loss : 0.025995
[01:41:04.489] iteration 23087 : model1 loss : 0.019402 model2 loss : 0.019450
[01:41:05.163] iteration 23088 : model1 loss : 0.020318 model2 loss : 0.022738
[01:41:05.832] iteration 23089 : model1 loss : 0.017329 model2 loss : 0.018481
[01:41:06.501] iteration 23090 : model1 loss : 0.027054 model2 loss : 0.028239
[01:41:07.163] iteration 23091 : model1 loss : 0.023578 model2 loss : 0.024269
[01:41:07.836] iteration 23092 : model1 loss : 0.020851 model2 loss : 0.018815
[01:41:08.507] iteration 23093 : model1 loss : 0.020856 model2 loss : 0.017411
[01:41:09.180] iteration 23094 : model1 loss : 0.018505 model2 loss : 0.017442
[01:41:09.843] iteration 23095 : model1 loss : 0.020791 model2 loss : 0.021215
[01:41:10.506] iteration 23096 : model1 loss : 0.053405 model2 loss : 0.050258
[01:41:11.195] iteration 23097 : model1 loss : 0.017454 model2 loss : 0.017821
[01:41:11.864] iteration 23098 : model1 loss : 0.018247 model2 loss : 0.017206
[01:41:12.543] iteration 23099 : model1 loss : 0.019725 model2 loss : 0.019583
[01:41:13.206] iteration 23100 : model1 loss : 0.029296 model2 loss : 0.026050
[01:41:13.913] iteration 23101 : model1 loss : 0.017072 model2 loss : 0.015524
[01:41:14.583] iteration 23102 : model1 loss : 0.028334 model2 loss : 0.030241
[01:41:15.252] iteration 23103 : model1 loss : 0.019937 model2 loss : 0.019186
[01:41:15.914] iteration 23104 : model1 loss : 0.021085 model2 loss : 0.018235
[01:41:16.582] iteration 23105 : model1 loss : 0.037928 model2 loss : 0.025773
[01:41:17.251] iteration 23106 : model1 loss : 0.018249 model2 loss : 0.018328
[01:41:17.910] iteration 23107 : model1 loss : 0.016192 model2 loss : 0.016294
[01:41:18.589] iteration 23108 : model1 loss : 0.013978 model2 loss : 0.015702
[01:41:19.251] iteration 23109 : model1 loss : 0.019975 model2 loss : 0.020708
[01:41:19.917] iteration 23110 : model1 loss : 0.017883 model2 loss : 0.017352
[01:41:20.587] iteration 23111 : model1 loss : 0.017844 model2 loss : 0.020794
[01:41:21.251] iteration 23112 : model1 loss : 0.017289 model2 loss : 0.018933
[01:41:21.926] iteration 23113 : model1 loss : 0.016934 model2 loss : 0.017547
[01:41:22.600] iteration 23114 : model1 loss : 0.024171 model2 loss : 0.023421
[01:41:23.272] iteration 23115 : model1 loss : 0.017447 model2 loss : 0.017933
[01:41:23.939] iteration 23116 : model1 loss : 0.017077 model2 loss : 0.017046
[01:41:24.605] iteration 23117 : model1 loss : 0.020525 model2 loss : 0.020338
[01:41:25.271] iteration 23118 : model1 loss : 0.029108 model2 loss : 0.023305
[01:41:25.932] iteration 23119 : model1 loss : 0.020447 model2 loss : 0.020533
[01:41:26.612] iteration 23120 : model1 loss : 0.018318 model2 loss : 0.020625
[01:41:27.280] iteration 23121 : model1 loss : 0.031229 model2 loss : 0.031110
[01:41:27.953] iteration 23122 : model1 loss : 0.022279 model2 loss : 0.024111
[01:41:28.632] iteration 23123 : model1 loss : 0.021600 model2 loss : 0.021605
[01:41:29.297] iteration 23124 : model1 loss : 0.015853 model2 loss : 0.019296
[01:41:29.963] iteration 23125 : model1 loss : 0.024999 model2 loss : 0.021685
[01:41:30.630] iteration 23126 : model1 loss : 0.028489 model2 loss : 0.023088
[01:41:31.291] iteration 23127 : model1 loss : 0.015592 model2 loss : 0.016130
[01:41:31.968] iteration 23128 : model1 loss : 0.025897 model2 loss : 0.031729
[01:41:32.648] iteration 23129 : model1 loss : 0.018732 model2 loss : 0.019295
[01:41:33.316] iteration 23130 : model1 loss : 0.019830 model2 loss : 0.021140
[01:41:33.994] iteration 23131 : model1 loss : 0.022824 model2 loss : 0.024171
[01:41:34.674] iteration 23132 : model1 loss : 0.018972 model2 loss : 0.019008
[01:41:35.342] iteration 23133 : model1 loss : 0.015646 model2 loss : 0.015635
[01:41:36.004] iteration 23134 : model1 loss : 0.018359 model2 loss : 0.019100
[01:41:36.695] iteration 23135 : model1 loss : 0.017099 model2 loss : 0.019087
[01:41:37.367] iteration 23136 : model1 loss : 0.022760 model2 loss : 0.021802
[01:41:38.037] iteration 23137 : model1 loss : 0.023159 model2 loss : 0.017650
[01:41:38.714] iteration 23138 : model1 loss : 0.038568 model2 loss : 0.037298
[01:41:39.377] iteration 23139 : model1 loss : 0.021439 model2 loss : 0.021224
[01:41:40.044] iteration 23140 : model1 loss : 0.020129 model2 loss : 0.019367
[01:41:40.727] iteration 23141 : model1 loss : 0.020017 model2 loss : 0.021718
[01:41:41.407] iteration 23142 : model1 loss : 0.019685 model2 loss : 0.021417
[01:41:42.065] iteration 23143 : model1 loss : 0.023864 model2 loss : 0.023585
[01:41:42.724] iteration 23144 : model1 loss : 0.022082 model2 loss : 0.022542
[01:41:43.398] iteration 23145 : model1 loss : 0.018600 model2 loss : 0.018960
[01:41:44.075] iteration 23146 : model1 loss : 0.013783 model2 loss : 0.016045
[01:41:44.750] iteration 23147 : model1 loss : 0.018855 model2 loss : 0.020175
[01:41:45.444] iteration 23148 : model1 loss : 0.019293 model2 loss : 0.018443
[01:41:46.104] iteration 23149 : model1 loss : 0.030507 model2 loss : 0.027392
[01:41:46.780] iteration 23150 : model1 loss : 0.019337 model2 loss : 0.019071
[01:41:47.506] iteration 23151 : model1 loss : 0.019750 model2 loss : 0.019864
[01:41:48.207] iteration 23152 : model1 loss : 0.078770 model2 loss : 0.068422
[01:41:48.867] iteration 23153 : model1 loss : 0.026848 model2 loss : 0.027035
[01:41:49.529] iteration 23154 : model1 loss : 0.024880 model2 loss : 0.026797
[01:41:50.206] iteration 23155 : model1 loss : 0.018530 model2 loss : 0.017803
[01:41:50.874] iteration 23156 : model1 loss : 0.023323 model2 loss : 0.021464
[01:41:51.547] iteration 23157 : model1 loss : 0.025246 model2 loss : 0.026230
[01:41:52.209] iteration 23158 : model1 loss : 0.028548 model2 loss : 0.023666
[01:41:52.880] iteration 23159 : model1 loss : 0.022164 model2 loss : 0.020816
[01:41:53.552] iteration 23160 : model1 loss : 0.025953 model2 loss : 0.026164
[01:41:54.224] iteration 23161 : model1 loss : 0.020962 model2 loss : 0.018427
[01:41:54.884] iteration 23162 : model1 loss : 0.018093 model2 loss : 0.019593
[01:41:55.548] iteration 23163 : model1 loss : 0.019829 model2 loss : 0.019217
[01:41:56.211] iteration 23164 : model1 loss : 0.020038 model2 loss : 0.019029
[01:41:56.875] iteration 23165 : model1 loss : 0.019677 model2 loss : 0.019816
[01:41:57.538] iteration 23166 : model1 loss : 0.022419 model2 loss : 0.023575
[01:41:58.204] iteration 23167 : model1 loss : 0.033658 model2 loss : 0.042479
[01:41:58.859] iteration 23168 : model1 loss : 0.019935 model2 loss : 0.018380
[01:41:59.536] iteration 23169 : model1 loss : 0.020416 model2 loss : 0.020321
[01:42:00.197] iteration 23170 : model1 loss : 0.023336 model2 loss : 0.021811
[01:42:00.862] iteration 23171 : model1 loss : 0.018979 model2 loss : 0.018411
[01:42:01.535] iteration 23172 : model1 loss : 0.021826 model2 loss : 0.020253
[01:42:02.203] iteration 23173 : model1 loss : 0.021172 model2 loss : 0.019663
[01:42:02.870] iteration 23174 : model1 loss : 0.022783 model2 loss : 0.021761
[01:42:03.550] iteration 23175 : model1 loss : 0.025799 model2 loss : 0.024114
[01:42:04.226] iteration 23176 : model1 loss : 0.022229 model2 loss : 0.021386
[01:42:04.879] iteration 23177 : model1 loss : 0.045296 model2 loss : 0.043156
[01:42:05.543] iteration 23178 : model1 loss : 0.016541 model2 loss : 0.015757
[01:42:06.203] iteration 23179 : model1 loss : 0.022084 model2 loss : 0.020215
[01:42:06.875] iteration 23180 : model1 loss : 0.019794 model2 loss : 0.020979
[01:42:07.545] iteration 23181 : model1 loss : 0.022138 model2 loss : 0.023810
[01:42:08.214] iteration 23182 : model1 loss : 0.015930 model2 loss : 0.015483
[01:42:08.893] iteration 23183 : model1 loss : 0.016569 model2 loss : 0.016682
[01:42:09.549] iteration 23184 : model1 loss : 0.016279 model2 loss : 0.018372
[01:42:10.225] iteration 23185 : model1 loss : 0.029977 model2 loss : 0.026865
[01:42:10.884] iteration 23186 : model1 loss : 0.021924 model2 loss : 0.022704
[01:42:11.545] iteration 23187 : model1 loss : 0.019101 model2 loss : 0.018435
[01:42:12.208] iteration 23188 : model1 loss : 0.021772 model2 loss : 0.022895
[01:42:12.877] iteration 23189 : model1 loss : 0.021660 model2 loss : 0.018123
[01:42:13.543] iteration 23190 : model1 loss : 0.021185 model2 loss : 0.020755
[01:42:14.210] iteration 23191 : model1 loss : 0.021585 model2 loss : 0.021895
[01:42:14.873] iteration 23192 : model1 loss : 0.022793 model2 loss : 0.021817
[01:42:15.548] iteration 23193 : model1 loss : 0.023439 model2 loss : 0.025233
[01:42:16.224] iteration 23194 : model1 loss : 0.019100 model2 loss : 0.018064
[01:42:16.881] iteration 23195 : model1 loss : 0.024160 model2 loss : 0.023038
[01:42:17.553] iteration 23196 : model1 loss : 0.017547 model2 loss : 0.019289
[01:42:18.212] iteration 23197 : model1 loss : 0.029392 model2 loss : 0.031077
[01:42:18.873] iteration 23198 : model1 loss : 0.017312 model2 loss : 0.016969
[01:42:19.548] iteration 23199 : model1 loss : 0.018916 model2 loss : 0.019064
[01:42:20.216] iteration 23200 : model1 loss : 0.022399 model2 loss : 0.024006
[01:42:38.256] iteration 23200 : model1_mean_dice : 0.875804 model1_mean_hd95 : 4.315600
[01:42:56.260] iteration 23200 : model2_mean_dice : 0.875458 model2_mean_hd95 : 4.725698
[01:42:56.935] iteration 23201 : model1 loss : 0.015058 model2 loss : 0.015025
[01:42:57.602] iteration 23202 : model1 loss : 0.023819 model2 loss : 0.023723
[01:42:58.264] iteration 23203 : model1 loss : 0.014005 model2 loss : 0.015415
[01:42:58.915] iteration 23204 : model1 loss : 0.020037 model2 loss : 0.021223
[01:42:59.577] iteration 23205 : model1 loss : 0.024493 model2 loss : 0.020001
[01:43:00.227] iteration 23206 : model1 loss : 0.023262 model2 loss : 0.024816
[01:43:00.878] iteration 23207 : model1 loss : 0.019598 model2 loss : 0.022407
[01:43:01.537] iteration 23208 : model1 loss : 0.018850 model2 loss : 0.019618
[01:43:02.200] iteration 23209 : model1 loss : 0.022299 model2 loss : 0.021464
[01:43:02.853] iteration 23210 : model1 loss : 0.021024 model2 loss : 0.020946
[01:43:03.519] iteration 23211 : model1 loss : 0.016460 model2 loss : 0.016723
[01:43:04.190] iteration 23212 : model1 loss : 0.020180 model2 loss : 0.018741
[01:43:04.857] iteration 23213 : model1 loss : 0.016116 model2 loss : 0.015639
[01:43:05.517] iteration 23214 : model1 loss : 0.024649 model2 loss : 0.026499
[01:43:06.171] iteration 23215 : model1 loss : 0.020968 model2 loss : 0.022487
[01:43:06.831] iteration 23216 : model1 loss : 0.029578 model2 loss : 0.029217
[01:43:07.501] iteration 23217 : model1 loss : 0.023978 model2 loss : 0.024227
[01:43:08.169] iteration 23218 : model1 loss : 0.020792 model2 loss : 0.022148
[01:43:08.837] iteration 23219 : model1 loss : 0.144031 model2 loss : 0.160533
[01:43:09.503] iteration 23220 : model1 loss : 0.026420 model2 loss : 0.023181
[01:43:10.157] iteration 23221 : model1 loss : 0.020823 model2 loss : 0.018083
[01:43:10.814] iteration 23222 : model1 loss : 0.039087 model2 loss : 0.047720
[01:43:11.480] iteration 23223 : model1 loss : 0.018274 model2 loss : 0.019374
[01:43:12.137] iteration 23224 : model1 loss : 0.023978 model2 loss : 0.025057
[01:43:12.792] iteration 23225 : model1 loss : 0.019505 model2 loss : 0.021723
[01:43:13.461] iteration 23226 : model1 loss : 0.015399 model2 loss : 0.014355
[01:43:14.121] iteration 23227 : model1 loss : 0.017406 model2 loss : 0.017682
[01:43:14.779] iteration 23228 : model1 loss : 0.028766 model2 loss : 0.026991
[01:43:15.455] iteration 23229 : model1 loss : 0.022739 model2 loss : 0.023401
[01:43:16.116] iteration 23230 : model1 loss : 0.017500 model2 loss : 0.017274
[01:43:16.786] iteration 23231 : model1 loss : 0.021427 model2 loss : 0.021583
[01:43:17.459] iteration 23232 : model1 loss : 0.020195 model2 loss : 0.019275
[01:43:18.121] iteration 23233 : model1 loss : 0.018085 model2 loss : 0.019090
[01:43:18.778] iteration 23234 : model1 loss : 0.028891 model2 loss : 0.029650
[01:43:19.444] iteration 23235 : model1 loss : 0.020715 model2 loss : 0.017955
[01:43:20.103] iteration 23236 : model1 loss : 0.022151 model2 loss : 0.023486
[01:43:20.769] iteration 23237 : model1 loss : 0.022152 model2 loss : 0.022617
[01:43:21.447] iteration 23238 : model1 loss : 0.019743 model2 loss : 0.017782
[01:43:22.112] iteration 23239 : model1 loss : 0.022382 model2 loss : 0.023109
[01:43:22.772] iteration 23240 : model1 loss : 0.020298 model2 loss : 0.019495
[01:43:23.439] iteration 23241 : model1 loss : 0.017492 model2 loss : 0.017537
[01:43:24.105] iteration 23242 : model1 loss : 0.025127 model2 loss : 0.023408
[01:43:24.772] iteration 23243 : model1 loss : 0.021308 model2 loss : 0.021728
[01:43:25.443] iteration 23244 : model1 loss : 0.015392 model2 loss : 0.015830
[01:43:26.093] iteration 23245 : model1 loss : 0.017025 model2 loss : 0.015126
[01:43:26.764] iteration 23246 : model1 loss : 0.018634 model2 loss : 0.020283
[01:43:27.438] iteration 23247 : model1 loss : 0.016535 model2 loss : 0.016164
[01:43:28.095] iteration 23248 : model1 loss : 0.029032 model2 loss : 0.027974
[01:43:28.823] iteration 23249 : model1 loss : 0.020880 model2 loss : 0.018896
[01:43:29.489] iteration 23250 : model1 loss : 0.016368 model2 loss : 0.017994
[01:43:30.192] iteration 23251 : model1 loss : 0.017319 model2 loss : 0.018567
[01:43:30.854] iteration 23252 : model1 loss : 0.016758 model2 loss : 0.018403
[01:43:31.517] iteration 23253 : model1 loss : 0.019443 model2 loss : 0.020948
[01:43:32.177] iteration 23254 : model1 loss : 0.020806 model2 loss : 0.021884
[01:43:32.847] iteration 23255 : model1 loss : 0.017050 model2 loss : 0.017958
[01:43:33.508] iteration 23256 : model1 loss : 0.030484 model2 loss : 0.028967
[01:43:34.177] iteration 23257 : model1 loss : 0.021360 model2 loss : 0.021330
[01:43:34.849] iteration 23258 : model1 loss : 0.023059 model2 loss : 0.022083
[01:43:35.521] iteration 23259 : model1 loss : 0.017126 model2 loss : 0.018957
[01:43:36.181] iteration 23260 : model1 loss : 0.019073 model2 loss : 0.017630
[01:43:36.848] iteration 23261 : model1 loss : 0.038820 model2 loss : 0.044978
[01:43:37.549] iteration 23262 : model1 loss : 0.026360 model2 loss : 0.027378
[01:43:38.217] iteration 23263 : model1 loss : 0.021077 model2 loss : 0.020809
[01:43:38.872] iteration 23264 : model1 loss : 0.021359 model2 loss : 0.021018
[01:43:39.552] iteration 23265 : model1 loss : 0.019346 model2 loss : 0.016855
[01:43:40.207] iteration 23266 : model1 loss : 0.017061 model2 loss : 0.016735
[01:43:40.869] iteration 23267 : model1 loss : 0.019437 model2 loss : 0.019051
[01:43:41.547] iteration 23268 : model1 loss : 0.018974 model2 loss : 0.019796
[01:43:42.203] iteration 23269 : model1 loss : 0.026009 model2 loss : 0.023249
[01:43:42.874] iteration 23270 : model1 loss : 0.020123 model2 loss : 0.018447
[01:43:43.533] iteration 23271 : model1 loss : 0.020798 model2 loss : 0.019125
[01:43:44.212] iteration 23272 : model1 loss : 0.022384 model2 loss : 0.019011
[01:43:44.906] iteration 23273 : model1 loss : 0.014975 model2 loss : 0.014765
[01:43:45.567] iteration 23274 : model1 loss : 0.023285 model2 loss : 0.022707
[01:43:46.252] iteration 23275 : model1 loss : 0.025310 model2 loss : 0.026658
[01:43:46.906] iteration 23276 : model1 loss : 0.030771 model2 loss : 0.030391
[01:43:47.579] iteration 23277 : model1 loss : 0.019082 model2 loss : 0.020450
[01:43:48.241] iteration 23278 : model1 loss : 0.022600 model2 loss : 0.020609
[01:43:48.931] iteration 23279 : model1 loss : 0.015596 model2 loss : 0.020563
[01:43:49.620] iteration 23280 : model1 loss : 0.021079 model2 loss : 0.022385
[01:43:50.293] iteration 23281 : model1 loss : 0.028511 model2 loss : 0.026742
[01:43:50.950] iteration 23282 : model1 loss : 0.019172 model2 loss : 0.018204
[01:43:51.630] iteration 23283 : model1 loss : 0.021857 model2 loss : 0.020256
[01:43:52.288] iteration 23284 : model1 loss : 0.020055 model2 loss : 0.019475
[01:43:52.961] iteration 23285 : model1 loss : 0.017798 model2 loss : 0.018513
[01:43:53.617] iteration 23286 : model1 loss : 0.017352 model2 loss : 0.019865
[01:43:54.286] iteration 23287 : model1 loss : 0.030715 model2 loss : 0.029977
[01:43:54.971] iteration 23288 : model1 loss : 0.024625 model2 loss : 0.023546
[01:43:55.623] iteration 23289 : model1 loss : 0.014982 model2 loss : 0.015607
[01:43:56.290] iteration 23290 : model1 loss : 0.027484 model2 loss : 0.024982
[01:43:56.963] iteration 23291 : model1 loss : 0.019894 model2 loss : 0.019723
[01:43:57.630] iteration 23292 : model1 loss : 0.021514 model2 loss : 0.022726
[01:43:58.313] iteration 23293 : model1 loss : 0.016675 model2 loss : 0.017560
[01:43:58.972] iteration 23294 : model1 loss : 0.017374 model2 loss : 0.018208
[01:43:59.620] iteration 23295 : model1 loss : 0.021818 model2 loss : 0.022753
[01:44:00.282] iteration 23296 : model1 loss : 0.019804 model2 loss : 0.021397
[01:44:00.952] iteration 23297 : model1 loss : 0.023846 model2 loss : 0.023684
[01:44:01.630] iteration 23298 : model1 loss : 0.026823 model2 loss : 0.028641
[01:44:02.290] iteration 23299 : model1 loss : 0.020630 model2 loss : 0.022311
[01:44:02.964] iteration 23300 : model1 loss : 0.018756 model2 loss : 0.019065
[01:44:03.697] iteration 23301 : model1 loss : 0.018277 model2 loss : 0.019305
[01:44:04.367] iteration 23302 : model1 loss : 0.016814 model2 loss : 0.016242
[01:44:05.041] iteration 23303 : model1 loss : 0.020102 model2 loss : 0.021338
[01:44:05.710] iteration 23304 : model1 loss : 0.023704 model2 loss : 0.024136
[01:44:06.379] iteration 23305 : model1 loss : 0.021939 model2 loss : 0.024212
[01:44:07.048] iteration 23306 : model1 loss : 0.021846 model2 loss : 0.019179
[01:44:07.712] iteration 23307 : model1 loss : 0.016801 model2 loss : 0.019246
[01:44:08.396] iteration 23308 : model1 loss : 0.025581 model2 loss : 0.023303
[01:44:09.047] iteration 23309 : model1 loss : 0.022492 model2 loss : 0.022605
[01:44:09.711] iteration 23310 : model1 loss : 0.021057 model2 loss : 0.021343
[01:44:10.379] iteration 23311 : model1 loss : 0.020784 model2 loss : 0.021380
[01:44:11.039] iteration 23312 : model1 loss : 0.013975 model2 loss : 0.013633
[01:44:11.708] iteration 23313 : model1 loss : 0.018171 model2 loss : 0.021563
[01:44:12.382] iteration 23314 : model1 loss : 0.018131 model2 loss : 0.016896
[01:44:13.039] iteration 23315 : model1 loss : 0.021930 model2 loss : 0.021579
[01:44:13.714] iteration 23316 : model1 loss : 0.021146 model2 loss : 0.021107
[01:44:14.387] iteration 23317 : model1 loss : 0.018256 model2 loss : 0.018653
[01:44:15.061] iteration 23318 : model1 loss : 0.021757 model2 loss : 0.020106
[01:44:15.725] iteration 23319 : model1 loss : 0.020901 model2 loss : 0.021240
[01:44:16.393] iteration 23320 : model1 loss : 0.025038 model2 loss : 0.024680
[01:44:17.068] iteration 23321 : model1 loss : 0.015114 model2 loss : 0.016792
[01:44:17.728] iteration 23322 : model1 loss : 0.027301 model2 loss : 0.025770
[01:44:18.398] iteration 23323 : model1 loss : 0.014853 model2 loss : 0.015188
[01:44:19.069] iteration 23324 : model1 loss : 0.021426 model2 loss : 0.021549
[01:44:19.738] iteration 23325 : model1 loss : 0.022654 model2 loss : 0.024951
[01:44:20.397] iteration 23326 : model1 loss : 0.023037 model2 loss : 0.023012
[01:44:21.071] iteration 23327 : model1 loss : 0.041172 model2 loss : 0.037487
[01:44:21.738] iteration 23328 : model1 loss : 0.020005 model2 loss : 0.018935
[01:44:22.400] iteration 23329 : model1 loss : 0.015517 model2 loss : 0.017706
[01:44:23.072] iteration 23330 : model1 loss : 0.029335 model2 loss : 0.031375
[01:44:23.743] iteration 23331 : model1 loss : 0.019490 model2 loss : 0.021840
[01:44:24.407] iteration 23332 : model1 loss : 0.021905 model2 loss : 0.019744
[01:44:25.073] iteration 23333 : model1 loss : 0.024152 model2 loss : 0.022850
[01:44:25.732] iteration 23334 : model1 loss : 0.019202 model2 loss : 0.017788
[01:44:26.413] iteration 23335 : model1 loss : 0.017839 model2 loss : 0.017237
[01:44:27.079] iteration 23336 : model1 loss : 0.014591 model2 loss : 0.016264
[01:44:27.743] iteration 23337 : model1 loss : 0.020808 model2 loss : 0.022964
[01:44:28.418] iteration 23338 : model1 loss : 0.022564 model2 loss : 0.022723
[01:44:29.094] iteration 23339 : model1 loss : 0.020072 model2 loss : 0.020950
[01:44:29.756] iteration 23340 : model1 loss : 0.020086 model2 loss : 0.019152
[01:44:30.426] iteration 23341 : model1 loss : 0.018490 model2 loss : 0.020508
[01:44:31.084] iteration 23342 : model1 loss : 0.021875 model2 loss : 0.021508
[01:44:31.743] iteration 23343 : model1 loss : 0.020855 model2 loss : 0.022735
[01:44:32.411] iteration 23344 : model1 loss : 0.015677 model2 loss : 0.015701
[01:44:33.081] iteration 23345 : model1 loss : 0.017029 model2 loss : 0.016400
[01:44:33.743] iteration 23346 : model1 loss : 0.019094 model2 loss : 0.019494
[01:44:34.419] iteration 23347 : model1 loss : 0.016701 model2 loss : 0.015242
[01:44:35.089] iteration 23348 : model1 loss : 0.022353 model2 loss : 0.019655
[01:44:35.757] iteration 23349 : model1 loss : 0.020599 model2 loss : 0.017888
[01:44:36.415] iteration 23350 : model1 loss : 0.019506 model2 loss : 0.018131
[01:44:37.126] iteration 23351 : model1 loss : 0.016014 model2 loss : 0.014553
[01:44:37.797] iteration 23352 : model1 loss : 0.015100 model2 loss : 0.015703
[01:44:38.479] iteration 23353 : model1 loss : 0.017498 model2 loss : 0.018175
[01:44:39.152] iteration 23354 : model1 loss : 0.019320 model2 loss : 0.017314
[01:44:39.805] iteration 23355 : model1 loss : 0.139613 model2 loss : 0.140803
[01:44:40.472] iteration 23356 : model1 loss : 0.022231 model2 loss : 0.021802
[01:44:41.136] iteration 23357 : model1 loss : 0.020045 model2 loss : 0.020584
[01:44:41.817] iteration 23358 : model1 loss : 0.018992 model2 loss : 0.017765
[01:44:42.496] iteration 23359 : model1 loss : 0.019091 model2 loss : 0.017593
[01:44:43.159] iteration 23360 : model1 loss : 0.019741 model2 loss : 0.021533
[01:44:43.830] iteration 23361 : model1 loss : 0.032508 model2 loss : 0.031512
[01:44:44.501] iteration 23362 : model1 loss : 0.024221 model2 loss : 0.025943
[01:44:45.166] iteration 23363 : model1 loss : 0.022020 model2 loss : 0.021355
[01:44:45.831] iteration 23364 : model1 loss : 0.025661 model2 loss : 0.027816
[01:44:46.496] iteration 23365 : model1 loss : 0.020559 model2 loss : 0.020919
[01:44:47.170] iteration 23366 : model1 loss : 0.020185 model2 loss : 0.020892
[01:44:47.836] iteration 23367 : model1 loss : 0.017328 model2 loss : 0.019696
[01:44:48.511] iteration 23368 : model1 loss : 0.016618 model2 loss : 0.016916
[01:44:49.172] iteration 23369 : model1 loss : 0.026814 model2 loss : 0.028546
[01:44:49.842] iteration 23370 : model1 loss : 0.024612 model2 loss : 0.025063
[01:44:50.513] iteration 23371 : model1 loss : 0.015695 model2 loss : 0.016251
[01:44:51.189] iteration 23372 : model1 loss : 0.016343 model2 loss : 0.015963
[01:44:51.854] iteration 23373 : model1 loss : 0.031366 model2 loss : 0.035094
[01:44:52.520] iteration 23374 : model1 loss : 0.018766 model2 loss : 0.018701
[01:44:53.189] iteration 23375 : model1 loss : 0.023225 model2 loss : 0.022832
[01:44:53.862] iteration 23376 : model1 loss : 0.014956 model2 loss : 0.014625
[01:44:54.538] iteration 23377 : model1 loss : 0.026184 model2 loss : 0.025589
[01:44:55.202] iteration 23378 : model1 loss : 0.016367 model2 loss : 0.017447
[01:44:55.862] iteration 23379 : model1 loss : 0.016119 model2 loss : 0.018404
[01:44:56.528] iteration 23380 : model1 loss : 0.019930 model2 loss : 0.020789
[01:44:57.200] iteration 23381 : model1 loss : 0.123589 model2 loss : 0.072360
[01:44:57.870] iteration 23382 : model1 loss : 0.019854 model2 loss : 0.019835
[01:44:58.537] iteration 23383 : model1 loss : 0.021956 model2 loss : 0.022213
[01:44:59.193] iteration 23384 : model1 loss : 0.022519 model2 loss : 0.029911
[01:44:59.863] iteration 23385 : model1 loss : 0.021105 model2 loss : 0.021453
[01:45:00.535] iteration 23386 : model1 loss : 0.021314 model2 loss : 0.019513
[01:45:01.198] iteration 23387 : model1 loss : 0.018220 model2 loss : 0.017424
[01:45:01.855] iteration 23388 : model1 loss : 0.016597 model2 loss : 0.016863
[01:45:02.536] iteration 23389 : model1 loss : 0.018039 model2 loss : 0.018204
[01:45:03.212] iteration 23390 : model1 loss : 0.019337 model2 loss : 0.017351
[01:45:03.882] iteration 23391 : model1 loss : 0.026836 model2 loss : 0.024096
[01:45:04.552] iteration 23392 : model1 loss : 0.022327 model2 loss : 0.023870
[01:45:05.223] iteration 23393 : model1 loss : 0.024415 model2 loss : 0.022179
[01:45:05.889] iteration 23394 : model1 loss : 0.014139 model2 loss : 0.015393
[01:45:06.567] iteration 23395 : model1 loss : 0.029430 model2 loss : 0.025802
[01:45:07.234] iteration 23396 : model1 loss : 0.021132 model2 loss : 0.023212
[01:45:07.899] iteration 23397 : model1 loss : 0.018722 model2 loss : 0.019602
[01:45:08.575] iteration 23398 : model1 loss : 0.021375 model2 loss : 0.020265
[01:45:09.235] iteration 23399 : model1 loss : 0.020359 model2 loss : 0.019808
[01:45:09.910] iteration 23400 : model1 loss : 0.018594 model2 loss : 0.019923
[01:45:27.841] iteration 23400 : model1_mean_dice : 0.875925 model1_mean_hd95 : 5.060848
[01:45:45.614] iteration 23400 : model2_mean_dice : 0.872880 model2_mean_hd95 : 6.497943
[01:45:46.310] iteration 23401 : model1 loss : 0.018103 model2 loss : 0.016983
[01:45:46.960] iteration 23402 : model1 loss : 0.016454 model2 loss : 0.015579
[01:45:47.619] iteration 23403 : model1 loss : 0.019860 model2 loss : 0.017730
[01:45:48.288] iteration 23404 : model1 loss : 0.034222 model2 loss : 0.028133
[01:45:48.955] iteration 23405 : model1 loss : 0.020163 model2 loss : 0.020975
[01:45:49.605] iteration 23406 : model1 loss : 0.063948 model2 loss : 0.056584
[01:45:50.262] iteration 23407 : model1 loss : 0.019455 model2 loss : 0.018427
[01:45:50.923] iteration 23408 : model1 loss : 0.022219 model2 loss : 0.021491
[01:45:51.585] iteration 23409 : model1 loss : 0.018336 model2 loss : 0.018020
[01:45:52.257] iteration 23410 : model1 loss : 0.019459 model2 loss : 0.021265
[01:45:52.917] iteration 23411 : model1 loss : 0.021075 model2 loss : 0.023329
[01:45:53.574] iteration 23412 : model1 loss : 0.018032 model2 loss : 0.018182
[01:45:54.261] iteration 23413 : model1 loss : 0.021544 model2 loss : 0.018922
[01:45:54.921] iteration 23414 : model1 loss : 0.015789 model2 loss : 0.016488
[01:45:55.587] iteration 23415 : model1 loss : 0.019183 model2 loss : 0.017117
[01:45:56.245] iteration 23416 : model1 loss : 0.024797 model2 loss : 0.024250
[01:45:56.900] iteration 23417 : model1 loss : 0.029869 model2 loss : 0.033459
[01:45:57.569] iteration 23418 : model1 loss : 0.025246 model2 loss : 0.028594
[01:45:58.232] iteration 23419 : model1 loss : 0.023057 model2 loss : 0.023852
[01:45:58.893] iteration 23420 : model1 loss : 0.019874 model2 loss : 0.021513
[01:45:59.556] iteration 23421 : model1 loss : 0.024873 model2 loss : 0.022449
[01:46:00.211] iteration 23422 : model1 loss : 0.026526 model2 loss : 0.024700
[01:46:00.883] iteration 23423 : model1 loss : 0.019728 model2 loss : 0.018608
[01:46:01.545] iteration 23424 : model1 loss : 0.027578 model2 loss : 0.026645
[01:46:02.208] iteration 23425 : model1 loss : 0.016752 model2 loss : 0.017369
[01:46:02.868] iteration 23426 : model1 loss : 0.021505 model2 loss : 0.020679
[01:46:03.531] iteration 23427 : model1 loss : 0.019796 model2 loss : 0.019124
[01:46:04.197] iteration 23428 : model1 loss : 0.025747 model2 loss : 0.026056
[01:46:04.853] iteration 23429 : model1 loss : 0.030427 model2 loss : 0.023647
[01:46:05.528] iteration 23430 : model1 loss : 0.038187 model2 loss : 0.037469
[01:46:06.188] iteration 23431 : model1 loss : 0.023015 model2 loss : 0.024056
[01:46:06.854] iteration 23432 : model1 loss : 0.019269 model2 loss : 0.018243
[01:46:07.527] iteration 23433 : model1 loss : 0.015119 model2 loss : 0.016017
[01:46:08.186] iteration 23434 : model1 loss : 0.023097 model2 loss : 0.021792
[01:46:08.854] iteration 23435 : model1 loss : 0.027046 model2 loss : 0.029247
[01:46:09.525] iteration 23436 : model1 loss : 0.020233 model2 loss : 0.019072
[01:46:10.185] iteration 23437 : model1 loss : 0.018675 model2 loss : 0.017928
[01:46:10.840] iteration 23438 : model1 loss : 0.015878 model2 loss : 0.016729
[01:46:11.498] iteration 23439 : model1 loss : 0.017094 model2 loss : 0.018129
[01:46:12.163] iteration 23440 : model1 loss : 0.020435 model2 loss : 0.021269
[01:46:12.832] iteration 23441 : model1 loss : 0.018149 model2 loss : 0.019044
[01:46:13.493] iteration 23442 : model1 loss : 0.018955 model2 loss : 0.019217
[01:46:14.161] iteration 23443 : model1 loss : 0.031571 model2 loss : 0.030070
[01:46:14.828] iteration 23444 : model1 loss : 0.018918 model2 loss : 0.018833
[01:46:15.495] iteration 23445 : model1 loss : 0.020167 model2 loss : 0.018310
[01:46:16.174] iteration 23446 : model1 loss : 0.016234 model2 loss : 0.015735
[01:46:16.842] iteration 23447 : model1 loss : 0.020533 model2 loss : 0.018634
[01:46:17.507] iteration 23448 : model1 loss : 0.141586 model2 loss : 0.139913
[01:46:18.170] iteration 23449 : model1 loss : 0.015407 model2 loss : 0.016394
[01:46:18.826] iteration 23450 : model1 loss : 0.018446 model2 loss : 0.019035
[01:46:19.535] iteration 23451 : model1 loss : 0.018239 model2 loss : 0.017237
[01:46:20.189] iteration 23452 : model1 loss : 0.020749 model2 loss : 0.022578
[01:46:20.854] iteration 23453 : model1 loss : 0.047032 model2 loss : 0.035313
[01:46:21.515] iteration 23454 : model1 loss : 0.024354 model2 loss : 0.023943
[01:46:22.163] iteration 23455 : model1 loss : 0.020014 model2 loss : 0.020398
[01:46:22.826] iteration 23456 : model1 loss : 0.020629 model2 loss : 0.019020
[01:46:23.486] iteration 23457 : model1 loss : 0.021542 model2 loss : 0.024690
[01:46:24.153] iteration 23458 : model1 loss : 0.026432 model2 loss : 0.034149
[01:46:24.818] iteration 23459 : model1 loss : 0.025245 model2 loss : 0.025150
[01:46:25.484] iteration 23460 : model1 loss : 0.018257 model2 loss : 0.018923
[01:46:26.167] iteration 23461 : model1 loss : 0.019083 model2 loss : 0.020878
[01:46:26.824] iteration 23462 : model1 loss : 0.017265 model2 loss : 0.015823
[01:46:27.508] iteration 23463 : model1 loss : 0.020992 model2 loss : 0.020576
[01:46:28.169] iteration 23464 : model1 loss : 0.021612 model2 loss : 0.022051
[01:46:28.834] iteration 23465 : model1 loss : 0.015626 model2 loss : 0.016661
[01:46:29.493] iteration 23466 : model1 loss : 0.021580 model2 loss : 0.023235
[01:46:30.160] iteration 23467 : model1 loss : 0.016648 model2 loss : 0.016508
[01:46:30.824] iteration 23468 : model1 loss : 0.019101 model2 loss : 0.019198
[01:46:31.481] iteration 23469 : model1 loss : 0.027905 model2 loss : 0.026484
[01:46:32.147] iteration 23470 : model1 loss : 0.015323 model2 loss : 0.016525
[01:46:32.827] iteration 23471 : model1 loss : 0.024094 model2 loss : 0.023252
[01:46:33.494] iteration 23472 : model1 loss : 0.019396 model2 loss : 0.020808
[01:46:34.158] iteration 23473 : model1 loss : 0.016514 model2 loss : 0.017927
[01:46:34.823] iteration 23474 : model1 loss : 0.017329 model2 loss : 0.016561
[01:46:35.486] iteration 23475 : model1 loss : 0.016197 model2 loss : 0.017270
[01:46:36.155] iteration 23476 : model1 loss : 0.020302 model2 loss : 0.020747
[01:46:36.822] iteration 23477 : model1 loss : 0.018466 model2 loss : 0.019098
[01:46:37.491] iteration 23478 : model1 loss : 0.027859 model2 loss : 0.023911
[01:46:38.149] iteration 23479 : model1 loss : 0.018100 model2 loss : 0.018764
[01:46:38.819] iteration 23480 : model1 loss : 0.016281 model2 loss : 0.015436
[01:46:39.501] iteration 23481 : model1 loss : 0.031513 model2 loss : 0.033426
[01:46:40.166] iteration 23482 : model1 loss : 0.030823 model2 loss : 0.029289
[01:46:40.832] iteration 23483 : model1 loss : 0.021086 model2 loss : 0.021920
[01:46:41.498] iteration 23484 : model1 loss : 0.013850 model2 loss : 0.014933
[01:46:42.165] iteration 23485 : model1 loss : 0.023826 model2 loss : 0.020082
[01:46:42.837] iteration 23486 : model1 loss : 0.026518 model2 loss : 0.024582
[01:46:43.501] iteration 23487 : model1 loss : 0.019576 model2 loss : 0.019009
[01:46:44.176] iteration 23488 : model1 loss : 0.024851 model2 loss : 0.025399
[01:46:44.844] iteration 23489 : model1 loss : 0.020326 model2 loss : 0.023480
[01:46:45.511] iteration 23490 : model1 loss : 0.014694 model2 loss : 0.015252
[01:46:46.179] iteration 23491 : model1 loss : 0.019443 model2 loss : 0.018344
[01:46:46.838] iteration 23492 : model1 loss : 0.020160 model2 loss : 0.019002
[01:46:47.504] iteration 23493 : model1 loss : 0.043538 model2 loss : 0.054288
[01:46:48.174] iteration 23494 : model1 loss : 0.021563 model2 loss : 0.024026
[01:46:48.840] iteration 23495 : model1 loss : 0.016583 model2 loss : 0.018097
[01:46:49.499] iteration 23496 : model1 loss : 0.024094 model2 loss : 0.024272
[01:46:50.168] iteration 23497 : model1 loss : 0.018799 model2 loss : 0.018834
[01:46:50.828] iteration 23498 : model1 loss : 0.141517 model2 loss : 0.144084
[01:46:51.508] iteration 23499 : model1 loss : 0.024011 model2 loss : 0.021480
[01:46:52.163] iteration 23500 : model1 loss : 0.019875 model2 loss : 0.020398
[01:46:52.874] iteration 23501 : model1 loss : 0.019113 model2 loss : 0.022370
[01:46:53.540] iteration 23502 : model1 loss : 0.028964 model2 loss : 0.030149
[01:46:54.186] iteration 23503 : model1 loss : 0.018623 model2 loss : 0.018964
[01:46:54.858] iteration 23504 : model1 loss : 0.016019 model2 loss : 0.016857
[01:46:55.543] iteration 23505 : model1 loss : 0.022429 model2 loss : 0.022062
[01:46:56.210] iteration 23506 : model1 loss : 0.019628 model2 loss : 0.021000
[01:46:56.879] iteration 23507 : model1 loss : 0.025690 model2 loss : 0.026271
[01:46:57.548] iteration 23508 : model1 loss : 0.018256 model2 loss : 0.019452
[01:46:58.221] iteration 23509 : model1 loss : 0.016852 model2 loss : 0.016435
[01:46:58.879] iteration 23510 : model1 loss : 0.022297 model2 loss : 0.021901
[01:46:59.544] iteration 23511 : model1 loss : 0.022880 model2 loss : 0.029465
[01:47:00.209] iteration 23512 : model1 loss : 0.025907 model2 loss : 0.025229
[01:47:00.873] iteration 23513 : model1 loss : 0.021057 model2 loss : 0.022460
[01:47:01.535] iteration 23514 : model1 loss : 0.017974 model2 loss : 0.018394
[01:47:02.199] iteration 23515 : model1 loss : 0.018670 model2 loss : 0.019670
[01:47:02.870] iteration 23516 : model1 loss : 0.017890 model2 loss : 0.018751
[01:47:03.543] iteration 23517 : model1 loss : 0.025085 model2 loss : 0.025181
[01:47:04.197] iteration 23518 : model1 loss : 0.021104 model2 loss : 0.023987
[01:47:04.861] iteration 23519 : model1 loss : 0.018765 model2 loss : 0.019003
[01:47:05.525] iteration 23520 : model1 loss : 0.020486 model2 loss : 0.021003
[01:47:06.198] iteration 23521 : model1 loss : 0.022040 model2 loss : 0.020266
[01:47:06.856] iteration 23522 : model1 loss : 0.024659 model2 loss : 0.023388
[01:47:07.533] iteration 23523 : model1 loss : 0.022586 model2 loss : 0.018599
[01:47:08.196] iteration 23524 : model1 loss : 0.014516 model2 loss : 0.015203
[01:47:08.857] iteration 23525 : model1 loss : 0.018960 model2 loss : 0.019993
[01:47:09.539] iteration 23526 : model1 loss : 0.023541 model2 loss : 0.023285
[01:47:10.204] iteration 23527 : model1 loss : 0.018593 model2 loss : 0.019780
[01:47:10.861] iteration 23528 : model1 loss : 0.018983 model2 loss : 0.018289
[01:47:11.525] iteration 23529 : model1 loss : 0.014749 model2 loss : 0.015886
[01:47:12.178] iteration 23530 : model1 loss : 0.019322 model2 loss : 0.019154
[01:47:12.846] iteration 23531 : model1 loss : 0.016749 model2 loss : 0.016678
[01:47:13.525] iteration 23532 : model1 loss : 0.017728 model2 loss : 0.018482
[01:47:14.196] iteration 23533 : model1 loss : 0.018200 model2 loss : 0.018920
[01:47:14.858] iteration 23534 : model1 loss : 0.013678 model2 loss : 0.013322
[01:47:15.529] iteration 23535 : model1 loss : 0.019810 model2 loss : 0.023602
[01:47:16.195] iteration 23536 : model1 loss : 0.017328 model2 loss : 0.016815
[01:47:16.863] iteration 23537 : model1 loss : 0.024906 model2 loss : 0.028134
[01:47:17.536] iteration 23538 : model1 loss : 0.019957 model2 loss : 0.021701
[01:47:18.194] iteration 23539 : model1 loss : 0.025081 model2 loss : 0.023583
[01:47:18.866] iteration 23540 : model1 loss : 0.017985 model2 loss : 0.019512
[01:47:19.535] iteration 23541 : model1 loss : 0.026081 model2 loss : 0.025100
[01:47:20.210] iteration 23542 : model1 loss : 0.021902 model2 loss : 0.024204
[01:47:20.875] iteration 23543 : model1 loss : 0.016751 model2 loss : 0.016086
[01:47:21.537] iteration 23544 : model1 loss : 0.018673 model2 loss : 0.022170
[01:47:22.208] iteration 23545 : model1 loss : 0.031269 model2 loss : 0.063466
[01:47:22.867] iteration 23546 : model1 loss : 0.018441 model2 loss : 0.019116
[01:47:23.534] iteration 23547 : model1 loss : 0.017405 model2 loss : 0.017839
[01:47:24.195] iteration 23548 : model1 loss : 0.017015 model2 loss : 0.017413
[01:47:24.855] iteration 23549 : model1 loss : 0.021202 model2 loss : 0.020692
[01:47:25.528] iteration 23550 : model1 loss : 0.017478 model2 loss : 0.016676
[01:47:26.225] iteration 23551 : model1 loss : 0.017602 model2 loss : 0.018283
[01:47:26.894] iteration 23552 : model1 loss : 0.023733 model2 loss : 0.025706
[01:47:27.564] iteration 23553 : model1 loss : 0.020480 model2 loss : 0.020004
[01:47:28.239] iteration 23554 : model1 loss : 0.017298 model2 loss : 0.017610
[01:47:28.898] iteration 23555 : model1 loss : 0.016967 model2 loss : 0.017635
[01:47:29.561] iteration 23556 : model1 loss : 0.021216 model2 loss : 0.025266
[01:47:30.240] iteration 23557 : model1 loss : 0.018639 model2 loss : 0.018389
[01:47:30.909] iteration 23558 : model1 loss : 0.025499 model2 loss : 0.030179
[01:47:31.572] iteration 23559 : model1 loss : 0.022105 model2 loss : 0.024049
[01:47:32.235] iteration 23560 : model1 loss : 0.018473 model2 loss : 0.018671
[01:47:32.906] iteration 23561 : model1 loss : 0.023038 model2 loss : 0.022217
[01:47:33.560] iteration 23562 : model1 loss : 0.027246 model2 loss : 0.030719
[01:47:34.225] iteration 23563 : model1 loss : 0.025154 model2 loss : 0.026953
[01:47:34.888] iteration 23564 : model1 loss : 0.034066 model2 loss : 0.036062
[01:47:35.552] iteration 23565 : model1 loss : 0.023821 model2 loss : 0.024038
[01:47:36.211] iteration 23566 : model1 loss : 0.023241 model2 loss : 0.023595
[01:47:36.877] iteration 23567 : model1 loss : 0.031107 model2 loss : 0.028418
[01:47:37.547] iteration 23568 : model1 loss : 0.021706 model2 loss : 0.022693
[01:47:38.206] iteration 23569 : model1 loss : 0.019861 model2 loss : 0.019900
[01:47:38.881] iteration 23570 : model1 loss : 0.024578 model2 loss : 0.024152
[01:47:39.565] iteration 23571 : model1 loss : 0.014784 model2 loss : 0.014299
[01:47:40.237] iteration 23572 : model1 loss : 0.023776 model2 loss : 0.021996
[01:47:40.909] iteration 23573 : model1 loss : 0.021034 model2 loss : 0.024917
[01:47:41.559] iteration 23574 : model1 loss : 0.033138 model2 loss : 0.037469
[01:47:42.230] iteration 23575 : model1 loss : 0.026115 model2 loss : 0.026749
[01:47:42.896] iteration 23576 : model1 loss : 0.028485 model2 loss : 0.022482
[01:47:43.556] iteration 23577 : model1 loss : 0.024412 model2 loss : 0.020135
[01:47:44.219] iteration 23578 : model1 loss : 0.022060 model2 loss : 0.022053
[01:47:44.892] iteration 23579 : model1 loss : 0.016264 model2 loss : 0.018369
[01:47:45.558] iteration 23580 : model1 loss : 0.018881 model2 loss : 0.019768
[01:47:46.223] iteration 23581 : model1 loss : 0.014941 model2 loss : 0.015040
[01:47:46.892] iteration 23582 : model1 loss : 0.035652 model2 loss : 0.043170
[01:47:47.556] iteration 23583 : model1 loss : 0.019773 model2 loss : 0.019195
[01:47:48.224] iteration 23584 : model1 loss : 0.015460 model2 loss : 0.014940
[01:47:48.890] iteration 23585 : model1 loss : 0.026387 model2 loss : 0.025249
[01:47:49.545] iteration 23586 : model1 loss : 0.020334 model2 loss : 0.019303
[01:47:50.208] iteration 23587 : model1 loss : 0.016814 model2 loss : 0.017502
[01:47:50.868] iteration 23588 : model1 loss : 0.024673 model2 loss : 0.023861
[01:47:51.544] iteration 23589 : model1 loss : 0.027712 model2 loss : 0.029496
[01:47:52.202] iteration 23590 : model1 loss : 0.024325 model2 loss : 0.026356
[01:47:52.870] iteration 23591 : model1 loss : 0.016151 model2 loss : 0.015427
[01:47:53.543] iteration 23592 : model1 loss : 0.021697 model2 loss : 0.021319
[01:47:54.213] iteration 23593 : model1 loss : 0.034538 model2 loss : 0.031829
[01:47:54.884] iteration 23594 : model1 loss : 0.020318 model2 loss : 0.023711
[01:47:55.543] iteration 23595 : model1 loss : 0.018095 model2 loss : 0.017818
[01:47:56.225] iteration 23596 : model1 loss : 0.017808 model2 loss : 0.016810
[01:47:56.897] iteration 23597 : model1 loss : 0.017097 model2 loss : 0.017982
[01:47:57.565] iteration 23598 : model1 loss : 0.022439 model2 loss : 0.023700
[01:47:58.233] iteration 23599 : model1 loss : 0.019707 model2 loss : 0.020316
[01:47:58.886] iteration 23600 : model1 loss : 0.020604 model2 loss : 0.020468
[01:48:16.623] iteration 23600 : model1_mean_dice : 0.875439 model1_mean_hd95 : 6.746663
[01:48:34.366] iteration 23600 : model2_mean_dice : 0.866966 model2_mean_hd95 : 6.707647
[01:48:35.055] iteration 23601 : model1 loss : 0.021927 model2 loss : 0.019286
[01:48:35.710] iteration 23602 : model1 loss : 0.018920 model2 loss : 0.020527
[01:48:36.384] iteration 23603 : model1 loss : 0.035261 model2 loss : 0.033531
[01:48:37.041] iteration 23604 : model1 loss : 0.030172 model2 loss : 0.027510
[01:48:37.714] iteration 23605 : model1 loss : 0.029106 model2 loss : 0.029380
[01:48:38.365] iteration 23606 : model1 loss : 0.019019 model2 loss : 0.019923
[01:48:39.022] iteration 23607 : model1 loss : 0.026138 model2 loss : 0.029619
[01:48:39.697] iteration 23608 : model1 loss : 0.019999 model2 loss : 0.020017
[01:48:40.368] iteration 23609 : model1 loss : 0.019739 model2 loss : 0.021098
[01:48:41.022] iteration 23610 : model1 loss : 0.019436 model2 loss : 0.017815
[01:48:41.676] iteration 23611 : model1 loss : 0.015826 model2 loss : 0.015736
[01:48:42.333] iteration 23612 : model1 loss : 0.022153 model2 loss : 0.020941
[01:48:42.994] iteration 23613 : model1 loss : 0.022734 model2 loss : 0.019737
[01:48:43.653] iteration 23614 : model1 loss : 0.020875 model2 loss : 0.021454
[01:48:44.333] iteration 23615 : model1 loss : 0.022167 model2 loss : 0.024301
[01:48:45.001] iteration 23616 : model1 loss : 0.025088 model2 loss : 0.024883
[01:48:45.663] iteration 23617 : model1 loss : 0.018143 model2 loss : 0.017825
[01:48:46.336] iteration 23618 : model1 loss : 0.013400 model2 loss : 0.012535
[01:48:46.999] iteration 23619 : model1 loss : 0.018016 model2 loss : 0.020068
[01:48:47.660] iteration 23620 : model1 loss : 0.038401 model2 loss : 0.036382
[01:48:48.332] iteration 23621 : model1 loss : 0.038086 model2 loss : 0.032913
[01:48:48.989] iteration 23622 : model1 loss : 0.019509 model2 loss : 0.019521
[01:48:49.645] iteration 23623 : model1 loss : 0.021548 model2 loss : 0.018650
[01:48:50.295] iteration 23624 : model1 loss : 0.018091 model2 loss : 0.017819
[01:48:50.968] iteration 23625 : model1 loss : 0.022009 model2 loss : 0.023086
[01:48:51.630] iteration 23626 : model1 loss : 0.014987 model2 loss : 0.014162
[01:48:52.298] iteration 23627 : model1 loss : 0.015768 model2 loss : 0.016816
[01:48:52.965] iteration 23628 : model1 loss : 0.022135 model2 loss : 0.022986
[01:48:53.613] iteration 23629 : model1 loss : 0.018666 model2 loss : 0.019161
[01:48:54.281] iteration 23630 : model1 loss : 0.019054 model2 loss : 0.019288
[01:48:54.945] iteration 23631 : model1 loss : 0.021911 model2 loss : 0.020341
[01:48:55.610] iteration 23632 : model1 loss : 0.016851 model2 loss : 0.018102
[01:48:56.271] iteration 23633 : model1 loss : 0.020540 model2 loss : 0.023398
[01:48:56.917] iteration 23634 : model1 loss : 0.021986 model2 loss : 0.021027
[01:48:57.584] iteration 23635 : model1 loss : 0.025630 model2 loss : 0.025571
[01:48:58.244] iteration 23636 : model1 loss : 0.017482 model2 loss : 0.017064
[01:48:58.913] iteration 23637 : model1 loss : 0.018568 model2 loss : 0.018964
[01:48:59.584] iteration 23638 : model1 loss : 0.014939 model2 loss : 0.015248
[01:49:00.260] iteration 23639 : model1 loss : 0.019046 model2 loss : 0.016809
[01:49:00.938] iteration 23640 : model1 loss : 0.022778 model2 loss : 0.024279
[01:49:01.597] iteration 23641 : model1 loss : 0.018607 model2 loss : 0.016000
[01:49:02.266] iteration 23642 : model1 loss : 0.022425 model2 loss : 0.024162
[01:49:02.942] iteration 23643 : model1 loss : 0.016332 model2 loss : 0.018737
[01:49:03.612] iteration 23644 : model1 loss : 0.017479 model2 loss : 0.018503
[01:49:04.284] iteration 23645 : model1 loss : 0.023594 model2 loss : 0.022946
[01:49:04.959] iteration 23646 : model1 loss : 0.025649 model2 loss : 0.025212
[01:49:05.619] iteration 23647 : model1 loss : 0.022200 model2 loss : 0.024934
[01:49:06.285] iteration 23648 : model1 loss : 0.022897 model2 loss : 0.021981
[01:49:06.953] iteration 23649 : model1 loss : 0.022151 model2 loss : 0.022277
[01:49:07.620] iteration 23650 : model1 loss : 0.017728 model2 loss : 0.018000
[01:49:08.324] iteration 23651 : model1 loss : 0.031538 model2 loss : 0.030909
[01:49:08.980] iteration 23652 : model1 loss : 0.017233 model2 loss : 0.017883
[01:49:09.641] iteration 23653 : model1 loss : 0.018100 model2 loss : 0.016755
[01:49:10.302] iteration 23654 : model1 loss : 0.017791 model2 loss : 0.016648
[01:49:10.958] iteration 23655 : model1 loss : 0.017614 model2 loss : 0.018497
[01:49:11.615] iteration 23656 : model1 loss : 0.022921 model2 loss : 0.023023
[01:49:12.273] iteration 23657 : model1 loss : 0.017398 model2 loss : 0.017239
[01:49:12.931] iteration 23658 : model1 loss : 0.027700 model2 loss : 0.034554
[01:49:13.603] iteration 23659 : model1 loss : 0.020215 model2 loss : 0.020001
[01:49:14.265] iteration 23660 : model1 loss : 0.019649 model2 loss : 0.020217
[01:49:14.929] iteration 23661 : model1 loss : 0.024726 model2 loss : 0.023954
[01:49:15.585] iteration 23662 : model1 loss : 0.024831 model2 loss : 0.020758
[01:49:16.242] iteration 23663 : model1 loss : 0.022585 model2 loss : 0.021388
[01:49:16.903] iteration 23664 : model1 loss : 0.015603 model2 loss : 0.016722
[01:49:17.571] iteration 23665 : model1 loss : 0.021147 model2 loss : 0.021906
[01:49:18.244] iteration 23666 : model1 loss : 0.026743 model2 loss : 0.026346
[01:49:18.910] iteration 23667 : model1 loss : 0.017691 model2 loss : 0.016911
[01:49:19.591] iteration 23668 : model1 loss : 0.015032 model2 loss : 0.015605
[01:49:20.254] iteration 23669 : model1 loss : 0.053517 model2 loss : 0.054076
[01:49:20.903] iteration 23670 : model1 loss : 0.022078 model2 loss : 0.021299
[01:49:21.575] iteration 23671 : model1 loss : 0.020625 model2 loss : 0.019864
[01:49:22.243] iteration 23672 : model1 loss : 0.147119 model2 loss : 0.143536
[01:49:22.899] iteration 23673 : model1 loss : 0.018197 model2 loss : 0.017026
[01:49:23.565] iteration 23674 : model1 loss : 0.018801 model2 loss : 0.018211
[01:49:24.220] iteration 23675 : model1 loss : 0.033959 model2 loss : 0.035642
[01:49:24.887] iteration 23676 : model1 loss : 0.015083 model2 loss : 0.015091
[01:49:25.553] iteration 23677 : model1 loss : 0.034965 model2 loss : 0.033835
[01:49:26.225] iteration 23678 : model1 loss : 0.018829 model2 loss : 0.017538
[01:49:26.885] iteration 23679 : model1 loss : 0.018441 model2 loss : 0.017786
[01:49:27.558] iteration 23680 : model1 loss : 0.018953 model2 loss : 0.021625
[01:49:28.224] iteration 23681 : model1 loss : 0.025268 model2 loss : 0.029073
[01:49:28.880] iteration 23682 : model1 loss : 0.021091 model2 loss : 0.018847
[01:49:29.538] iteration 23683 : model1 loss : 0.027485 model2 loss : 0.032544
[01:49:30.207] iteration 23684 : model1 loss : 0.036188 model2 loss : 0.036568
[01:49:30.877] iteration 23685 : model1 loss : 0.016794 model2 loss : 0.018057
[01:49:31.540] iteration 23686 : model1 loss : 0.023789 model2 loss : 0.022333
[01:49:32.198] iteration 23687 : model1 loss : 0.016923 model2 loss : 0.016577
[01:49:32.854] iteration 23688 : model1 loss : 0.017426 model2 loss : 0.018263
[01:49:33.519] iteration 23689 : model1 loss : 0.019743 model2 loss : 0.020568
[01:49:34.181] iteration 23690 : model1 loss : 0.021004 model2 loss : 0.019030
[01:49:34.860] iteration 23691 : model1 loss : 0.019308 model2 loss : 0.018821
[01:49:35.532] iteration 23692 : model1 loss : 0.018608 model2 loss : 0.017895
[01:49:36.191] iteration 23693 : model1 loss : 0.020520 model2 loss : 0.021094
[01:49:36.866] iteration 23694 : model1 loss : 0.018392 model2 loss : 0.016839
[01:49:37.534] iteration 23695 : model1 loss : 0.021898 model2 loss : 0.023840
[01:49:38.211] iteration 23696 : model1 loss : 0.021104 model2 loss : 0.023044
[01:49:38.869] iteration 23697 : model1 loss : 0.016162 model2 loss : 0.019591
[01:49:39.537] iteration 23698 : model1 loss : 0.019231 model2 loss : 0.020128
[01:49:40.206] iteration 23699 : model1 loss : 0.021182 model2 loss : 0.020914
[01:49:40.894] iteration 23700 : model1 loss : 0.017502 model2 loss : 0.016720
[01:49:41.603] iteration 23701 : model1 loss : 0.020512 model2 loss : 0.019540
[01:49:42.273] iteration 23702 : model1 loss : 0.022336 model2 loss : 0.021523
[01:49:42.948] iteration 23703 : model1 loss : 0.017666 model2 loss : 0.017328
[01:49:43.615] iteration 23704 : model1 loss : 0.017793 model2 loss : 0.017233
[01:49:44.275] iteration 23705 : model1 loss : 0.021936 model2 loss : 0.023540
[01:49:44.944] iteration 23706 : model1 loss : 0.018402 model2 loss : 0.018093
[01:49:45.616] iteration 23707 : model1 loss : 0.019713 model2 loss : 0.018680
[01:49:46.274] iteration 23708 : model1 loss : 0.016987 model2 loss : 0.016893
[01:49:46.943] iteration 23709 : model1 loss : 0.024425 model2 loss : 0.025770
[01:49:47.613] iteration 23710 : model1 loss : 0.021066 model2 loss : 0.023076
[01:49:48.285] iteration 23711 : model1 loss : 0.025880 model2 loss : 0.024344
[01:49:48.955] iteration 23712 : model1 loss : 0.022371 model2 loss : 0.021361
[01:49:49.620] iteration 23713 : model1 loss : 0.018630 model2 loss : 0.016409
[01:49:50.298] iteration 23714 : model1 loss : 0.022967 model2 loss : 0.023961
[01:49:50.961] iteration 23715 : model1 loss : 0.023142 model2 loss : 0.022874
[01:49:51.626] iteration 23716 : model1 loss : 0.017676 model2 loss : 0.017287
[01:49:52.287] iteration 23717 : model1 loss : 0.140374 model2 loss : 0.140145
[01:49:52.936] iteration 23718 : model1 loss : 0.020115 model2 loss : 0.019703
[01:49:53.594] iteration 23719 : model1 loss : 0.020798 model2 loss : 0.021092
[01:49:54.260] iteration 23720 : model1 loss : 0.019868 model2 loss : 0.022738
[01:49:54.922] iteration 23721 : model1 loss : 0.019916 model2 loss : 0.020343
[01:49:55.573] iteration 23722 : model1 loss : 0.020760 model2 loss : 0.023828
[01:49:56.231] iteration 23723 : model1 loss : 0.017648 model2 loss : 0.020123
[01:49:56.897] iteration 23724 : model1 loss : 0.016424 model2 loss : 0.016548
[01:49:57.560] iteration 23725 : model1 loss : 0.016433 model2 loss : 0.017349
[01:49:58.228] iteration 23726 : model1 loss : 0.034923 model2 loss : 0.027043
[01:49:58.895] iteration 23727 : model1 loss : 0.021442 model2 loss : 0.025306
[01:49:59.573] iteration 23728 : model1 loss : 0.016915 model2 loss : 0.019944
[01:50:00.260] iteration 23729 : model1 loss : 0.017173 model2 loss : 0.016669
[01:50:00.923] iteration 23730 : model1 loss : 0.016624 model2 loss : 0.016514
[01:50:01.581] iteration 23731 : model1 loss : 0.024704 model2 loss : 0.022691
[01:50:02.257] iteration 23732 : model1 loss : 0.028836 model2 loss : 0.026275
[01:50:02.930] iteration 23733 : model1 loss : 0.036875 model2 loss : 0.033891
[01:50:03.587] iteration 23734 : model1 loss : 0.017374 model2 loss : 0.016833
[01:50:04.243] iteration 23735 : model1 loss : 0.019593 model2 loss : 0.018126
[01:50:04.905] iteration 23736 : model1 loss : 0.018140 model2 loss : 0.018378
[01:50:05.571] iteration 23737 : model1 loss : 0.016446 model2 loss : 0.016350
[01:50:06.245] iteration 23738 : model1 loss : 0.013496 model2 loss : 0.013944
[01:50:06.916] iteration 23739 : model1 loss : 0.019011 model2 loss : 0.019563
[01:50:07.578] iteration 23740 : model1 loss : 0.022301 model2 loss : 0.022155
[01:50:08.249] iteration 23741 : model1 loss : 0.024205 model2 loss : 0.026364
[01:50:08.923] iteration 23742 : model1 loss : 0.021562 model2 loss : 0.022837
[01:50:09.598] iteration 23743 : model1 loss : 0.020811 model2 loss : 0.022897
[01:50:10.274] iteration 23744 : model1 loss : 0.019563 model2 loss : 0.020374
[01:50:10.936] iteration 23745 : model1 loss : 0.016640 model2 loss : 0.016624
[01:50:11.597] iteration 23746 : model1 loss : 0.016890 model2 loss : 0.016027
[01:50:12.268] iteration 23747 : model1 loss : 0.018502 model2 loss : 0.018339
[01:50:12.925] iteration 23748 : model1 loss : 0.019905 model2 loss : 0.018611
[01:50:13.586] iteration 23749 : model1 loss : 0.020440 model2 loss : 0.020660
[01:50:14.245] iteration 23750 : model1 loss : 0.015546 model2 loss : 0.015766
[01:50:14.951] iteration 23751 : model1 loss : 0.019124 model2 loss : 0.018231
[01:50:15.618] iteration 23752 : model1 loss : 0.016329 model2 loss : 0.016695
[01:50:16.289] iteration 23753 : model1 loss : 0.028644 model2 loss : 0.029251
[01:50:16.940] iteration 23754 : model1 loss : 0.021816 model2 loss : 0.020620
[01:50:17.606] iteration 23755 : model1 loss : 0.025715 model2 loss : 0.024421
[01:50:18.284] iteration 23756 : model1 loss : 0.020700 model2 loss : 0.020839
[01:50:18.943] iteration 23757 : model1 loss : 0.016657 model2 loss : 0.017565
[01:50:19.601] iteration 23758 : model1 loss : 0.018531 model2 loss : 0.017862
[01:50:20.280] iteration 23759 : model1 loss : 0.018423 model2 loss : 0.018328
[01:50:20.933] iteration 23760 : model1 loss : 0.017227 model2 loss : 0.018206
[01:50:21.588] iteration 23761 : model1 loss : 0.017197 model2 loss : 0.016353
[01:50:22.251] iteration 23762 : model1 loss : 0.019833 model2 loss : 0.018406
[01:50:22.910] iteration 23763 : model1 loss : 0.019406 model2 loss : 0.020042
[01:50:23.583] iteration 23764 : model1 loss : 0.019859 model2 loss : 0.019200
[01:50:24.270] iteration 23765 : model1 loss : 0.012914 model2 loss : 0.012728
[01:50:24.928] iteration 23766 : model1 loss : 0.018685 model2 loss : 0.021341
[01:50:25.606] iteration 23767 : model1 loss : 0.021484 model2 loss : 0.019441
[01:50:26.270] iteration 23768 : model1 loss : 0.018026 model2 loss : 0.019713
[01:50:26.928] iteration 23769 : model1 loss : 0.023472 model2 loss : 0.023230
[01:50:27.593] iteration 23770 : model1 loss : 0.022928 model2 loss : 0.025571
[01:50:28.258] iteration 23771 : model1 loss : 0.021338 model2 loss : 0.020276
[01:50:28.923] iteration 23772 : model1 loss : 0.028348 model2 loss : 0.027580
[01:50:29.590] iteration 23773 : model1 loss : 0.021178 model2 loss : 0.019659
[01:50:30.249] iteration 23774 : model1 loss : 0.022766 model2 loss : 0.025648
[01:50:30.917] iteration 23775 : model1 loss : 0.023519 model2 loss : 0.021147
[01:50:31.580] iteration 23776 : model1 loss : 0.016696 model2 loss : 0.018561
[01:50:32.242] iteration 23777 : model1 loss : 0.017652 model2 loss : 0.017123
[01:50:32.914] iteration 23778 : model1 loss : 0.024075 model2 loss : 0.022555
[01:50:33.583] iteration 23779 : model1 loss : 0.023790 model2 loss : 0.022323
[01:50:34.259] iteration 23780 : model1 loss : 0.019834 model2 loss : 0.021456
[01:50:34.924] iteration 23781 : model1 loss : 0.023937 model2 loss : 0.024514
[01:50:35.603] iteration 23782 : model1 loss : 0.016295 model2 loss : 0.016293
[01:50:36.269] iteration 23783 : model1 loss : 0.027260 model2 loss : 0.025464
[01:50:36.932] iteration 23784 : model1 loss : 0.021628 model2 loss : 0.021963
[01:50:37.590] iteration 23785 : model1 loss : 0.024326 model2 loss : 0.024947
[01:50:38.263] iteration 23786 : model1 loss : 0.022079 model2 loss : 0.021869
[01:50:38.932] iteration 23787 : model1 loss : 0.019661 model2 loss : 0.019773
[01:50:39.595] iteration 23788 : model1 loss : 0.016211 model2 loss : 0.016361
[01:50:40.263] iteration 23789 : model1 loss : 0.019115 model2 loss : 0.018818
[01:50:40.980] iteration 23790 : model1 loss : 0.018043 model2 loss : 0.017601
[01:50:41.643] iteration 23791 : model1 loss : 0.022744 model2 loss : 0.023260
[01:50:42.316] iteration 23792 : model1 loss : 0.023858 model2 loss : 0.023143
[01:50:42.990] iteration 23793 : model1 loss : 0.020641 model2 loss : 0.017939
[01:50:43.647] iteration 23794 : model1 loss : 0.017451 model2 loss : 0.016829
[01:50:44.317] iteration 23795 : model1 loss : 0.018816 model2 loss : 0.018203
[01:50:44.976] iteration 23796 : model1 loss : 0.031641 model2 loss : 0.030282
[01:50:45.648] iteration 23797 : model1 loss : 0.019449 model2 loss : 0.020638
[01:50:46.312] iteration 23798 : model1 loss : 0.018468 model2 loss : 0.017839
[01:50:46.977] iteration 23799 : model1 loss : 0.046124 model2 loss : 0.045174
[01:50:47.647] iteration 23800 : model1 loss : 0.026001 model2 loss : 0.032478
[01:51:05.508] iteration 23800 : model1_mean_dice : 0.875292 model1_mean_hd95 : 7.511383
[01:51:23.535] iteration 23800 : model2_mean_dice : 0.874804 model2_mean_hd95 : 4.781171
[01:51:24.403] iteration 23801 : model1 loss : 0.023220 model2 loss : 0.027299
[01:51:25.101] iteration 23802 : model1 loss : 0.015437 model2 loss : 0.015053
[01:51:25.764] iteration 23803 : model1 loss : 0.019450 model2 loss : 0.020142
[01:51:26.421] iteration 23804 : model1 loss : 0.018502 model2 loss : 0.018827
[01:51:27.068] iteration 23805 : model1 loss : 0.019979 model2 loss : 0.020740
[01:51:27.741] iteration 23806 : model1 loss : 0.022600 model2 loss : 0.023319
[01:51:28.399] iteration 23807 : model1 loss : 0.022170 model2 loss : 0.025434
[01:51:29.057] iteration 23808 : model1 loss : 0.026458 model2 loss : 0.026895
[01:51:29.722] iteration 23809 : model1 loss : 0.026045 model2 loss : 0.026653
[01:51:30.384] iteration 23810 : model1 loss : 0.017751 model2 loss : 0.020753
[01:51:31.037] iteration 23811 : model1 loss : 0.017456 model2 loss : 0.016702
[01:51:31.691] iteration 23812 : model1 loss : 0.020089 model2 loss : 0.019041
[01:51:32.355] iteration 23813 : model1 loss : 0.017574 model2 loss : 0.019254
[01:51:33.012] iteration 23814 : model1 loss : 0.019243 model2 loss : 0.018520
[01:51:33.679] iteration 23815 : model1 loss : 0.016737 model2 loss : 0.016784
[01:51:34.338] iteration 23816 : model1 loss : 0.021210 model2 loss : 0.018190
[01:51:35.004] iteration 23817 : model1 loss : 0.019507 model2 loss : 0.023741
[01:51:35.667] iteration 23818 : model1 loss : 0.021342 model2 loss : 0.022925
[01:51:36.319] iteration 23819 : model1 loss : 0.023792 model2 loss : 0.022728
[01:51:36.990] iteration 23820 : model1 loss : 0.020509 model2 loss : 0.019321
[01:51:37.644] iteration 23821 : model1 loss : 0.017943 model2 loss : 0.017807
[01:51:38.308] iteration 23822 : model1 loss : 0.029392 model2 loss : 0.029134
[01:51:38.999] iteration 23823 : model1 loss : 0.016646 model2 loss : 0.016703
[01:51:39.682] iteration 23824 : model1 loss : 0.030285 model2 loss : 0.026882
[01:51:40.349] iteration 23825 : model1 loss : 0.021304 model2 loss : 0.020972
[01:51:41.027] iteration 23826 : model1 loss : 0.017271 model2 loss : 0.018824
[01:51:41.699] iteration 23827 : model1 loss : 0.016006 model2 loss : 0.015913
[01:51:42.379] iteration 23828 : model1 loss : 0.019808 model2 loss : 0.019872
[01:51:43.041] iteration 23829 : model1 loss : 0.017047 model2 loss : 0.015960
[01:51:43.698] iteration 23830 : model1 loss : 0.020004 model2 loss : 0.020062
[01:51:44.372] iteration 23831 : model1 loss : 0.021794 model2 loss : 0.022859
[01:51:45.029] iteration 23832 : model1 loss : 0.044747 model2 loss : 0.046780
[01:51:45.696] iteration 23833 : model1 loss : 0.022981 model2 loss : 0.022369
[01:51:46.377] iteration 23834 : model1 loss : 0.019693 model2 loss : 0.018746
[01:51:47.034] iteration 23835 : model1 loss : 0.019677 model2 loss : 0.020574
[01:51:47.703] iteration 23836 : model1 loss : 0.016735 model2 loss : 0.016322
[01:51:48.361] iteration 23837 : model1 loss : 0.019240 model2 loss : 0.020662
[01:51:49.027] iteration 23838 : model1 loss : 0.027065 model2 loss : 0.025514
[01:51:49.691] iteration 23839 : model1 loss : 0.024042 model2 loss : 0.024646
[01:51:50.355] iteration 23840 : model1 loss : 0.021618 model2 loss : 0.020649
[01:51:51.011] iteration 23841 : model1 loss : 0.021935 model2 loss : 0.019927
[01:51:51.665] iteration 23842 : model1 loss : 0.018569 model2 loss : 0.016649
[01:51:52.327] iteration 23843 : model1 loss : 0.020726 model2 loss : 0.023061
[01:51:52.990] iteration 23844 : model1 loss : 0.014800 model2 loss : 0.015471
[01:51:53.675] iteration 23845 : model1 loss : 0.019533 model2 loss : 0.021854
[01:51:54.349] iteration 23846 : model1 loss : 0.028545 model2 loss : 0.024309
[01:51:55.008] iteration 23847 : model1 loss : 0.020926 model2 loss : 0.021479
[01:51:55.666] iteration 23848 : model1 loss : 0.023479 model2 loss : 0.021889
[01:51:56.331] iteration 23849 : model1 loss : 0.021015 model2 loss : 0.025467
[01:51:56.996] iteration 23850 : model1 loss : 0.022511 model2 loss : 0.023227
[01:51:57.697] iteration 23851 : model1 loss : 0.020130 model2 loss : 0.017461
[01:51:58.377] iteration 23852 : model1 loss : 0.026720 model2 loss : 0.026908
[01:51:59.034] iteration 23853 : model1 loss : 0.020016 model2 loss : 0.019398
[01:51:59.702] iteration 23854 : model1 loss : 0.017937 model2 loss : 0.018021
[01:52:00.352] iteration 23855 : model1 loss : 0.023836 model2 loss : 0.024088
[01:52:01.017] iteration 23856 : model1 loss : 0.020259 model2 loss : 0.018305
[01:52:01.693] iteration 23857 : model1 loss : 0.014016 model2 loss : 0.016229
[01:52:02.359] iteration 23858 : model1 loss : 0.019318 model2 loss : 0.019371
[01:52:03.024] iteration 23859 : model1 loss : 0.015848 model2 loss : 0.015399
[01:52:03.681] iteration 23860 : model1 loss : 0.021436 model2 loss : 0.020420
[01:52:04.339] iteration 23861 : model1 loss : 0.142739 model2 loss : 0.141879
[01:52:04.997] iteration 23862 : model1 loss : 0.017517 model2 loss : 0.017895
[01:52:05.657] iteration 23863 : model1 loss : 0.045154 model2 loss : 0.042272
[01:52:06.314] iteration 23864 : model1 loss : 0.019157 model2 loss : 0.017973
[01:52:06.973] iteration 23865 : model1 loss : 0.027908 model2 loss : 0.023327
[01:52:07.642] iteration 23866 : model1 loss : 0.014773 model2 loss : 0.019775
[01:52:08.322] iteration 23867 : model1 loss : 0.020986 model2 loss : 0.022964
[01:52:08.992] iteration 23868 : model1 loss : 0.023438 model2 loss : 0.022135
[01:52:09.659] iteration 23869 : model1 loss : 0.016246 model2 loss : 0.017053
[01:52:10.333] iteration 23870 : model1 loss : 0.150634 model2 loss : 0.150934
[01:52:11.004] iteration 23871 : model1 loss : 0.019124 model2 loss : 0.020632
[01:52:11.658] iteration 23872 : model1 loss : 0.022601 model2 loss : 0.022331
[01:52:12.319] iteration 23873 : model1 loss : 0.028471 model2 loss : 0.029370
[01:52:12.993] iteration 23874 : model1 loss : 0.022504 model2 loss : 0.021419
[01:52:13.655] iteration 23875 : model1 loss : 0.013399 model2 loss : 0.013294
[01:52:14.328] iteration 23876 : model1 loss : 0.020078 model2 loss : 0.024682
[01:52:15.017] iteration 23877 : model1 loss : 0.023048 model2 loss : 0.021145
[01:52:15.711] iteration 23878 : model1 loss : 0.016485 model2 loss : 0.017427
[01:52:16.389] iteration 23879 : model1 loss : 0.016698 model2 loss : 0.017282
[01:52:17.064] iteration 23880 : model1 loss : 0.019620 model2 loss : 0.018929
[01:52:17.757] iteration 23881 : model1 loss : 0.018411 model2 loss : 0.020898
[01:52:18.438] iteration 23882 : model1 loss : 0.016113 model2 loss : 0.015223
[01:52:19.101] iteration 23883 : model1 loss : 0.021316 model2 loss : 0.020446
[01:52:19.762] iteration 23884 : model1 loss : 0.023963 model2 loss : 0.022380
[01:52:20.425] iteration 23885 : model1 loss : 0.014946 model2 loss : 0.015747
[01:52:21.084] iteration 23886 : model1 loss : 0.024808 model2 loss : 0.022293
[01:52:21.755] iteration 23887 : model1 loss : 0.017976 model2 loss : 0.020373
[01:52:22.405] iteration 23888 : model1 loss : 0.017638 model2 loss : 0.017957
[01:52:23.073] iteration 23889 : model1 loss : 0.086966 model2 loss : 0.104151
[01:52:23.740] iteration 23890 : model1 loss : 0.032052 model2 loss : 0.032290
[01:52:24.402] iteration 23891 : model1 loss : 0.015968 model2 loss : 0.016715
[01:52:25.077] iteration 23892 : model1 loss : 0.019475 model2 loss : 0.019903
[01:52:25.739] iteration 23893 : model1 loss : 0.021581 model2 loss : 0.021244
[01:52:26.393] iteration 23894 : model1 loss : 0.022908 model2 loss : 0.022298
[01:52:27.047] iteration 23895 : model1 loss : 0.025058 model2 loss : 0.021235
[01:52:27.710] iteration 23896 : model1 loss : 0.020616 model2 loss : 0.018734
[01:52:28.380] iteration 23897 : model1 loss : 0.071740 model2 loss : 0.073864
[01:52:29.054] iteration 23898 : model1 loss : 0.018360 model2 loss : 0.019839
[01:52:29.710] iteration 23899 : model1 loss : 0.015763 model2 loss : 0.015293
[01:52:30.389] iteration 23900 : model1 loss : 0.030824 model2 loss : 0.037794
[01:52:31.101] iteration 23901 : model1 loss : 0.019862 model2 loss : 0.022591
[01:52:31.762] iteration 23902 : model1 loss : 0.020453 model2 loss : 0.019805
[01:52:32.423] iteration 23903 : model1 loss : 0.041692 model2 loss : 0.046129
[01:52:33.093] iteration 23904 : model1 loss : 0.020081 model2 loss : 0.019448
[01:52:33.746] iteration 23905 : model1 loss : 0.021899 model2 loss : 0.023915
[01:52:34.404] iteration 23906 : model1 loss : 0.019371 model2 loss : 0.020148
[01:52:35.075] iteration 23907 : model1 loss : 0.017185 model2 loss : 0.018421
[01:52:35.742] iteration 23908 : model1 loss : 0.019023 model2 loss : 0.019985
[01:52:36.411] iteration 23909 : model1 loss : 0.017400 model2 loss : 0.016523
[01:52:37.075] iteration 23910 : model1 loss : 0.022603 model2 loss : 0.021646
[01:52:37.740] iteration 23911 : model1 loss : 0.026373 model2 loss : 0.025738
[01:52:38.416] iteration 23912 : model1 loss : 0.017705 model2 loss : 0.017204
[01:52:39.077] iteration 23913 : model1 loss : 0.016519 model2 loss : 0.018145
[01:52:39.746] iteration 23914 : model1 loss : 0.024831 model2 loss : 0.026824
[01:52:40.415] iteration 23915 : model1 loss : 0.021029 model2 loss : 0.022695
[01:52:41.069] iteration 23916 : model1 loss : 0.016907 model2 loss : 0.018725
[01:52:41.786] iteration 23917 : model1 loss : 0.019517 model2 loss : 0.018589
[01:52:42.490] iteration 23918 : model1 loss : 0.019542 model2 loss : 0.021014
[01:52:43.154] iteration 23919 : model1 loss : 0.027821 model2 loss : 0.024454
[01:52:43.820] iteration 23920 : model1 loss : 0.017113 model2 loss : 0.016739
[01:52:44.486] iteration 23921 : model1 loss : 0.016056 model2 loss : 0.017498
[01:52:45.141] iteration 23922 : model1 loss : 0.018378 model2 loss : 0.018858
[01:52:45.792] iteration 23923 : model1 loss : 0.021610 model2 loss : 0.021096
[01:52:46.452] iteration 23924 : model1 loss : 0.018548 model2 loss : 0.017709
[01:52:47.121] iteration 23925 : model1 loss : 0.026233 model2 loss : 0.025467
[01:52:47.775] iteration 23926 : model1 loss : 0.021517 model2 loss : 0.019633
[01:52:48.441] iteration 23927 : model1 loss : 0.023109 model2 loss : 0.022449
[01:52:49.110] iteration 23928 : model1 loss : 0.020378 model2 loss : 0.019782
[01:52:49.785] iteration 23929 : model1 loss : 0.016158 model2 loss : 0.016223
[01:52:50.458] iteration 23930 : model1 loss : 0.014793 model2 loss : 0.016010
[01:52:51.115] iteration 23931 : model1 loss : 0.021245 model2 loss : 0.020135
[01:52:51.785] iteration 23932 : model1 loss : 0.034894 model2 loss : 0.034462
[01:52:52.444] iteration 23933 : model1 loss : 0.025441 model2 loss : 0.026525
[01:52:53.114] iteration 23934 : model1 loss : 0.021482 model2 loss : 0.022258
[01:52:53.774] iteration 23935 : model1 loss : 0.032319 model2 loss : 0.040241
[01:52:54.432] iteration 23936 : model1 loss : 0.021065 model2 loss : 0.022590
[01:52:55.098] iteration 23937 : model1 loss : 0.023071 model2 loss : 0.023476
[01:52:55.770] iteration 23938 : model1 loss : 0.018399 model2 loss : 0.020127
[01:52:56.441] iteration 23939 : model1 loss : 0.027341 model2 loss : 0.029473
[01:52:57.099] iteration 23940 : model1 loss : 0.019865 model2 loss : 0.019727
[01:52:57.763] iteration 23941 : model1 loss : 0.021782 model2 loss : 0.018241
[01:52:58.436] iteration 23942 : model1 loss : 0.024533 model2 loss : 0.027543
[01:52:59.093] iteration 23943 : model1 loss : 0.017423 model2 loss : 0.019985
[01:52:59.766] iteration 23944 : model1 loss : 0.024844 model2 loss : 0.022823
[01:53:00.422] iteration 23945 : model1 loss : 0.024069 model2 loss : 0.022794
[01:53:01.099] iteration 23946 : model1 loss : 0.021394 model2 loss : 0.019467
[01:53:01.767] iteration 23947 : model1 loss : 0.021148 model2 loss : 0.019374
[01:53:02.445] iteration 23948 : model1 loss : 0.032066 model2 loss : 0.030509
[01:53:03.104] iteration 23949 : model1 loss : 0.026626 model2 loss : 0.022834
[01:53:03.773] iteration 23950 : model1 loss : 0.018296 model2 loss : 0.020600
[01:53:04.483] iteration 23951 : model1 loss : 0.018141 model2 loss : 0.019314
[01:53:05.156] iteration 23952 : model1 loss : 0.023722 model2 loss : 0.025999
[01:53:05.817] iteration 23953 : model1 loss : 0.016887 model2 loss : 0.016967
[01:53:06.475] iteration 23954 : model1 loss : 0.016013 model2 loss : 0.017941
[01:53:07.146] iteration 23955 : model1 loss : 0.027036 model2 loss : 0.025968
[01:53:07.806] iteration 23956 : model1 loss : 0.016413 model2 loss : 0.016704
[01:53:08.476] iteration 23957 : model1 loss : 0.023131 model2 loss : 0.024472
[01:53:09.137] iteration 23958 : model1 loss : 0.015824 model2 loss : 0.016964
[01:53:09.791] iteration 23959 : model1 loss : 0.020805 model2 loss : 0.021266
[01:53:10.453] iteration 23960 : model1 loss : 0.021003 model2 loss : 0.022787
[01:53:11.127] iteration 23961 : model1 loss : 0.020152 model2 loss : 0.018542
[01:53:11.786] iteration 23962 : model1 loss : 0.022519 model2 loss : 0.023798
[01:53:12.445] iteration 23963 : model1 loss : 0.022963 model2 loss : 0.021522
[01:53:13.112] iteration 23964 : model1 loss : 0.022870 model2 loss : 0.022982
[01:53:13.769] iteration 23965 : model1 loss : 0.018608 model2 loss : 0.017929
[01:53:14.431] iteration 23966 : model1 loss : 0.016358 model2 loss : 0.014787
[01:53:15.101] iteration 23967 : model1 loss : 0.019123 model2 loss : 0.017962
[01:53:15.766] iteration 23968 : model1 loss : 0.015768 model2 loss : 0.015515
[01:53:16.444] iteration 23969 : model1 loss : 0.017421 model2 loss : 0.018332
[01:53:17.114] iteration 23970 : model1 loss : 0.019724 model2 loss : 0.019646
[01:53:17.781] iteration 23971 : model1 loss : 0.025226 model2 loss : 0.031095
[01:53:18.450] iteration 23972 : model1 loss : 0.022272 model2 loss : 0.020292
[01:53:19.113] iteration 23973 : model1 loss : 0.020506 model2 loss : 0.021544
[01:53:19.779] iteration 23974 : model1 loss : 0.022737 model2 loss : 0.023223
[01:53:20.437] iteration 23975 : model1 loss : 0.023490 model2 loss : 0.025080
[01:53:21.108] iteration 23976 : model1 loss : 0.024596 model2 loss : 0.020255
[01:53:21.771] iteration 23977 : model1 loss : 0.018041 model2 loss : 0.018281
[01:53:22.440] iteration 23978 : model1 loss : 0.028091 model2 loss : 0.029385
[01:53:23.105] iteration 23979 : model1 loss : 0.019154 model2 loss : 0.019916
[01:53:23.782] iteration 23980 : model1 loss : 0.020471 model2 loss : 0.019089
[01:53:24.443] iteration 23981 : model1 loss : 0.022600 model2 loss : 0.021970
[01:53:25.109] iteration 23982 : model1 loss : 0.020947 model2 loss : 0.020061
[01:53:25.778] iteration 23983 : model1 loss : 0.025893 model2 loss : 0.028889
[01:53:26.443] iteration 23984 : model1 loss : 0.033257 model2 loss : 0.038426
[01:53:27.103] iteration 23985 : model1 loss : 0.030492 model2 loss : 0.031745
[01:53:27.769] iteration 23986 : model1 loss : 0.019544 model2 loss : 0.019487
[01:53:28.437] iteration 23987 : model1 loss : 0.014214 model2 loss : 0.014013
[01:53:29.101] iteration 23988 : model1 loss : 0.019888 model2 loss : 0.018556
[01:53:29.772] iteration 23989 : model1 loss : 0.016834 model2 loss : 0.016047
[01:53:30.448] iteration 23990 : model1 loss : 0.016100 model2 loss : 0.017639
[01:53:31.120] iteration 23991 : model1 loss : 0.017791 model2 loss : 0.018516
[01:53:31.783] iteration 23992 : model1 loss : 0.020522 model2 loss : 0.020947
[01:53:32.448] iteration 23993 : model1 loss : 0.022739 model2 loss : 0.024545
[01:53:33.119] iteration 23994 : model1 loss : 0.039534 model2 loss : 0.035028
[01:53:33.798] iteration 23995 : model1 loss : 0.017700 model2 loss : 0.017906
[01:53:34.461] iteration 23996 : model1 loss : 0.017974 model2 loss : 0.020368
[01:53:35.161] iteration 23997 : model1 loss : 0.022155 model2 loss : 0.020939
[01:53:35.826] iteration 23998 : model1 loss : 0.023917 model2 loss : 0.026338
[01:53:36.495] iteration 23999 : model1 loss : 0.020769 model2 loss : 0.021838
[01:53:37.165] iteration 24000 : model1 loss : 0.018440 model2 loss : 0.018702
[01:53:55.439] iteration 24000 : model1_mean_dice : 0.873635 model1_mean_hd95 : 5.960730
[01:54:13.507] iteration 24000 : model2_mean_dice : 0.876177 model2_mean_hd95 : 4.507354
[01:54:13.573] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_24000.pth
[01:54:13.633] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_24000.pth
[01:54:14.339] iteration 24001 : model1 loss : 0.086297 model2 loss : 0.078504
[01:54:15.011] iteration 24002 : model1 loss : 0.016678 model2 loss : 0.022200
[01:54:15.675] iteration 24003 : model1 loss : 0.026005 model2 loss : 0.023172
[01:54:16.336] iteration 24004 : model1 loss : 0.020047 model2 loss : 0.021971
[01:54:16.994] iteration 24005 : model1 loss : 0.017726 model2 loss : 0.017242
[01:54:17.655] iteration 24006 : model1 loss : 0.019826 model2 loss : 0.020579
[01:54:18.327] iteration 24007 : model1 loss : 0.021511 model2 loss : 0.018963
[01:54:18.986] iteration 24008 : model1 loss : 0.021218 model2 loss : 0.020534
[01:54:19.661] iteration 24009 : model1 loss : 0.141557 model2 loss : 0.141052
[01:54:20.330] iteration 24010 : model1 loss : 0.018258 model2 loss : 0.018502
[01:54:21.008] iteration 24011 : model1 loss : 0.022655 model2 loss : 0.020607
[01:54:21.667] iteration 24012 : model1 loss : 0.023423 model2 loss : 0.022359
[01:54:22.333] iteration 24013 : model1 loss : 0.030725 model2 loss : 0.023296
[01:54:23.148] iteration 24014 : model1 loss : 0.022755 model2 loss : 0.020416
[01:54:23.820] iteration 24015 : model1 loss : 0.022377 model2 loss : 0.022227
[01:54:24.480] iteration 24016 : model1 loss : 0.019406 model2 loss : 0.018629
[01:54:25.125] iteration 24017 : model1 loss : 0.023332 model2 loss : 0.023317
[01:54:25.775] iteration 24018 : model1 loss : 0.024760 model2 loss : 0.020843
[01:54:26.430] iteration 24019 : model1 loss : 0.027655 model2 loss : 0.021283
[01:54:27.093] iteration 24020 : model1 loss : 0.028651 model2 loss : 0.026773
[01:54:27.740] iteration 24021 : model1 loss : 0.022362 model2 loss : 0.021257
[01:54:28.414] iteration 24022 : model1 loss : 0.023458 model2 loss : 0.020483
[01:54:29.093] iteration 24023 : model1 loss : 0.019670 model2 loss : 0.019241
[01:54:29.767] iteration 24024 : model1 loss : 0.026697 model2 loss : 0.018265
[01:54:30.439] iteration 24025 : model1 loss : 0.017923 model2 loss : 0.017789
[01:54:31.103] iteration 24026 : model1 loss : 0.021362 model2 loss : 0.022827
[01:54:31.755] iteration 24027 : model1 loss : 0.018637 model2 loss : 0.018731
[01:54:32.421] iteration 24028 : model1 loss : 0.026325 model2 loss : 0.025734
[01:54:33.076] iteration 24029 : model1 loss : 0.056678 model2 loss : 0.066387
[01:54:33.728] iteration 24030 : model1 loss : 0.022638 model2 loss : 0.020033
[01:54:34.384] iteration 24031 : model1 loss : 0.019064 model2 loss : 0.017263
[01:54:35.046] iteration 24032 : model1 loss : 0.024239 model2 loss : 0.023396
[01:54:35.708] iteration 24033 : model1 loss : 0.018993 model2 loss : 0.019627
[01:54:36.364] iteration 24034 : model1 loss : 0.014205 model2 loss : 0.014840
[01:54:37.023] iteration 24035 : model1 loss : 0.017615 model2 loss : 0.019551
[01:54:37.685] iteration 24036 : model1 loss : 0.021655 model2 loss : 0.023403
[01:54:38.345] iteration 24037 : model1 loss : 0.017976 model2 loss : 0.019560
[01:54:38.997] iteration 24038 : model1 loss : 0.019836 model2 loss : 0.022383
[01:54:39.663] iteration 24039 : model1 loss : 0.025132 model2 loss : 0.024630
[01:54:40.331] iteration 24040 : model1 loss : 0.021872 model2 loss : 0.020318
[01:54:40.987] iteration 24041 : model1 loss : 0.018432 model2 loss : 0.017097
[01:54:41.663] iteration 24042 : model1 loss : 0.020063 model2 loss : 0.019626
[01:54:42.322] iteration 24043 : model1 loss : 0.031464 model2 loss : 0.028097
[01:54:43.005] iteration 24044 : model1 loss : 0.025204 model2 loss : 0.023598
[01:54:43.668] iteration 24045 : model1 loss : 0.028930 model2 loss : 0.023714
[01:54:44.333] iteration 24046 : model1 loss : 0.021867 model2 loss : 0.022521
[01:54:44.985] iteration 24047 : model1 loss : 0.019685 model2 loss : 0.021389
[01:54:45.646] iteration 24048 : model1 loss : 0.020435 model2 loss : 0.020454
[01:54:46.303] iteration 24049 : model1 loss : 0.050614 model2 loss : 0.028202
[01:54:46.967] iteration 24050 : model1 loss : 0.021542 model2 loss : 0.018744
[01:54:47.665] iteration 24051 : model1 loss : 0.019695 model2 loss : 0.019360
[01:54:48.334] iteration 24052 : model1 loss : 0.020224 model2 loss : 0.020008
[01:54:48.980] iteration 24053 : model1 loss : 0.021999 model2 loss : 0.022747
[01:54:49.631] iteration 24054 : model1 loss : 0.022528 model2 loss : 0.022416
[01:54:50.299] iteration 24055 : model1 loss : 0.017741 model2 loss : 0.017150
[01:54:50.956] iteration 24056 : model1 loss : 0.015174 model2 loss : 0.015561
[01:54:51.617] iteration 24057 : model1 loss : 0.021931 model2 loss : 0.020844
[01:54:52.271] iteration 24058 : model1 loss : 0.028844 model2 loss : 0.027664
[01:54:52.926] iteration 24059 : model1 loss : 0.020416 model2 loss : 0.020982
[01:54:53.588] iteration 24060 : model1 loss : 0.022004 model2 loss : 0.019939
[01:54:54.253] iteration 24061 : model1 loss : 0.021447 model2 loss : 0.024265
[01:54:54.904] iteration 24062 : model1 loss : 0.028355 model2 loss : 0.029814
[01:54:55.561] iteration 24063 : model1 loss : 0.029913 model2 loss : 0.030276
[01:54:56.217] iteration 24064 : model1 loss : 0.019568 model2 loss : 0.019553
[01:54:56.881] iteration 24065 : model1 loss : 0.035242 model2 loss : 0.028308
[01:54:57.534] iteration 24066 : model1 loss : 0.020359 model2 loss : 0.023721
[01:54:58.192] iteration 24067 : model1 loss : 0.018066 model2 loss : 0.018072
[01:54:58.847] iteration 24068 : model1 loss : 0.022187 model2 loss : 0.023056
[01:54:59.509] iteration 24069 : model1 loss : 0.017944 model2 loss : 0.019292
[01:55:00.173] iteration 24070 : model1 loss : 0.019122 model2 loss : 0.016658
[01:55:00.838] iteration 24071 : model1 loss : 0.019576 model2 loss : 0.018702
[01:55:01.491] iteration 24072 : model1 loss : 0.026778 model2 loss : 0.024136
[01:55:02.149] iteration 24073 : model1 loss : 0.021876 model2 loss : 0.022376
[01:55:02.802] iteration 24074 : model1 loss : 0.017097 model2 loss : 0.017137
[01:55:03.462] iteration 24075 : model1 loss : 0.021084 model2 loss : 0.021444
[01:55:04.118] iteration 24076 : model1 loss : 0.018740 model2 loss : 0.019315
[01:55:04.773] iteration 24077 : model1 loss : 0.021009 model2 loss : 0.019612
[01:55:05.442] iteration 24078 : model1 loss : 0.022150 model2 loss : 0.023209
[01:55:06.104] iteration 24079 : model1 loss : 0.015487 model2 loss : 0.014371
[01:55:06.760] iteration 24080 : model1 loss : 0.019558 model2 loss : 0.018605
[01:55:07.412] iteration 24081 : model1 loss : 0.020794 model2 loss : 0.018315
[01:55:08.070] iteration 24082 : model1 loss : 0.023903 model2 loss : 0.023977
[01:55:08.727] iteration 24083 : model1 loss : 0.017960 model2 loss : 0.018173
[01:55:09.388] iteration 24084 : model1 loss : 0.021412 model2 loss : 0.021379
[01:55:10.055] iteration 24085 : model1 loss : 0.017819 model2 loss : 0.018744
[01:55:10.711] iteration 24086 : model1 loss : 0.019545 model2 loss : 0.017817
[01:55:11.365] iteration 24087 : model1 loss : 0.028866 model2 loss : 0.029265
[01:55:12.033] iteration 24088 : model1 loss : 0.018848 model2 loss : 0.019528
[01:55:12.691] iteration 24089 : model1 loss : 0.020334 model2 loss : 0.019382
[01:55:13.356] iteration 24090 : model1 loss : 0.019564 model2 loss : 0.018784
[01:55:14.017] iteration 24091 : model1 loss : 0.021384 model2 loss : 0.020919
[01:55:14.674] iteration 24092 : model1 loss : 0.016970 model2 loss : 0.015878
[01:55:15.336] iteration 24093 : model1 loss : 0.023401 model2 loss : 0.023054
[01:55:15.994] iteration 24094 : model1 loss : 0.015660 model2 loss : 0.016126
[01:55:16.654] iteration 24095 : model1 loss : 0.021093 model2 loss : 0.020780
[01:55:17.306] iteration 24096 : model1 loss : 0.018094 model2 loss : 0.019050
[01:55:17.970] iteration 24097 : model1 loss : 0.021011 model2 loss : 0.021362
[01:55:18.635] iteration 24098 : model1 loss : 0.024453 model2 loss : 0.021851
[01:55:19.285] iteration 24099 : model1 loss : 0.017576 model2 loss : 0.016859
[01:55:19.951] iteration 24100 : model1 loss : 0.021790 model2 loss : 0.018583
[01:55:20.643] iteration 24101 : model1 loss : 0.014330 model2 loss : 0.015047
[01:55:21.317] iteration 24102 : model1 loss : 0.020554 model2 loss : 0.019712
[01:55:21.980] iteration 24103 : model1 loss : 0.022202 model2 loss : 0.024156
[01:55:22.634] iteration 24104 : model1 loss : 0.019469 model2 loss : 0.020127
[01:55:23.293] iteration 24105 : model1 loss : 0.020575 model2 loss : 0.020606
[01:55:23.948] iteration 24106 : model1 loss : 0.019715 model2 loss : 0.018448
[01:55:24.604] iteration 24107 : model1 loss : 0.016992 model2 loss : 0.015026
[01:55:25.254] iteration 24108 : model1 loss : 0.017321 model2 loss : 0.015754
[01:55:25.905] iteration 24109 : model1 loss : 0.016510 model2 loss : 0.017042
[01:55:26.571] iteration 24110 : model1 loss : 0.021258 model2 loss : 0.019357
[01:55:27.238] iteration 24111 : model1 loss : 0.014929 model2 loss : 0.014792
[01:55:27.892] iteration 24112 : model1 loss : 0.020186 model2 loss : 0.019614
[01:55:28.562] iteration 24113 : model1 loss : 0.016792 model2 loss : 0.015965
[01:55:29.213] iteration 24114 : model1 loss : 0.029499 model2 loss : 0.028119
[01:55:29.880] iteration 24115 : model1 loss : 0.018113 model2 loss : 0.014647
[01:55:30.538] iteration 24116 : model1 loss : 0.019728 model2 loss : 0.020342
[01:55:31.200] iteration 24117 : model1 loss : 0.017690 model2 loss : 0.022730
[01:55:31.875] iteration 24118 : model1 loss : 0.024928 model2 loss : 0.026616
[01:55:32.541] iteration 24119 : model1 loss : 0.022618 model2 loss : 0.022958
[01:55:33.205] iteration 24120 : model1 loss : 0.017329 model2 loss : 0.017796
[01:55:33.867] iteration 24121 : model1 loss : 0.024580 model2 loss : 0.023546
[01:55:34.527] iteration 24122 : model1 loss : 0.021196 model2 loss : 0.019194
[01:55:35.182] iteration 24123 : model1 loss : 0.021035 model2 loss : 0.019867
[01:55:35.845] iteration 24124 : model1 loss : 0.018532 model2 loss : 0.018636
[01:55:36.510] iteration 24125 : model1 loss : 0.022706 model2 loss : 0.022377
[01:55:37.169] iteration 24126 : model1 loss : 0.019157 model2 loss : 0.017967
[01:55:37.816] iteration 24127 : model1 loss : 0.020804 model2 loss : 0.021204
[01:55:38.475] iteration 24128 : model1 loss : 0.024833 model2 loss : 0.023571
[01:55:39.132] iteration 24129 : model1 loss : 0.014501 model2 loss : 0.013405
[01:55:39.804] iteration 24130 : model1 loss : 0.024967 model2 loss : 0.022721
[01:55:40.463] iteration 24131 : model1 loss : 0.030373 model2 loss : 0.029019
[01:55:41.145] iteration 24132 : model1 loss : 0.026384 model2 loss : 0.026550
[01:55:41.801] iteration 24133 : model1 loss : 0.020248 model2 loss : 0.020625
[01:55:42.460] iteration 24134 : model1 loss : 0.021360 model2 loss : 0.020866
[01:55:43.162] iteration 24135 : model1 loss : 0.035302 model2 loss : 0.039579
[01:55:43.817] iteration 24136 : model1 loss : 0.022874 model2 loss : 0.022117
[01:55:44.479] iteration 24137 : model1 loss : 0.023851 model2 loss : 0.029364
[01:55:45.140] iteration 24138 : model1 loss : 0.021760 model2 loss : 0.022687
[01:55:45.804] iteration 24139 : model1 loss : 0.019585 model2 loss : 0.021451
[01:55:46.466] iteration 24140 : model1 loss : 0.017330 model2 loss : 0.020096
[01:55:47.114] iteration 24141 : model1 loss : 0.018921 model2 loss : 0.017796
[01:55:47.772] iteration 24142 : model1 loss : 0.018124 model2 loss : 0.018677
[01:55:48.427] iteration 24143 : model1 loss : 0.039784 model2 loss : 0.034673
[01:55:49.085] iteration 24144 : model1 loss : 0.017086 model2 loss : 0.014888
[01:55:49.743] iteration 24145 : model1 loss : 0.015430 model2 loss : 0.015543
[01:55:50.393] iteration 24146 : model1 loss : 0.019123 model2 loss : 0.019493
[01:55:51.054] iteration 24147 : model1 loss : 0.022328 model2 loss : 0.019789
[01:55:51.702] iteration 24148 : model1 loss : 0.019585 model2 loss : 0.018279
[01:55:52.365] iteration 24149 : model1 loss : 0.023697 model2 loss : 0.020582
[01:55:53.021] iteration 24150 : model1 loss : 0.017681 model2 loss : 0.017936
[01:55:53.736] iteration 24151 : model1 loss : 0.027650 model2 loss : 0.025128
[01:55:54.392] iteration 24152 : model1 loss : 0.016318 model2 loss : 0.018296
[01:55:55.055] iteration 24153 : model1 loss : 0.018445 model2 loss : 0.017856
[01:55:55.720] iteration 24154 : model1 loss : 0.018199 model2 loss : 0.017513
[01:55:56.390] iteration 24155 : model1 loss : 0.018596 model2 loss : 0.019231
[01:55:57.036] iteration 24156 : model1 loss : 0.017549 model2 loss : 0.019039
[01:55:57.693] iteration 24157 : model1 loss : 0.024506 model2 loss : 0.022244
[01:55:58.354] iteration 24158 : model1 loss : 0.020291 model2 loss : 0.021129
[01:55:59.006] iteration 24159 : model1 loss : 0.141697 model2 loss : 0.139879
[01:55:59.665] iteration 24160 : model1 loss : 0.016929 model2 loss : 0.016697
[01:56:00.323] iteration 24161 : model1 loss : 0.019649 model2 loss : 0.019738
[01:56:00.981] iteration 24162 : model1 loss : 0.016591 model2 loss : 0.015767
[01:56:01.646] iteration 24163 : model1 loss : 0.017393 model2 loss : 0.016718
[01:56:02.302] iteration 24164 : model1 loss : 0.026464 model2 loss : 0.025850
[01:56:02.973] iteration 24165 : model1 loss : 0.015472 model2 loss : 0.015742
[01:56:03.636] iteration 24166 : model1 loss : 0.017866 model2 loss : 0.016654
[01:56:04.295] iteration 24167 : model1 loss : 0.017603 model2 loss : 0.017654
[01:56:04.957] iteration 24168 : model1 loss : 0.020925 model2 loss : 0.020900
[01:56:05.617] iteration 24169 : model1 loss : 0.037965 model2 loss : 0.027409
[01:56:06.275] iteration 24170 : model1 loss : 0.021078 model2 loss : 0.019012
[01:56:06.929] iteration 24171 : model1 loss : 0.017926 model2 loss : 0.017277
[01:56:07.592] iteration 24172 : model1 loss : 0.023660 model2 loss : 0.024308
[01:56:08.244] iteration 24173 : model1 loss : 0.024399 model2 loss : 0.028074
[01:56:08.897] iteration 24174 : model1 loss : 0.027156 model2 loss : 0.026280
[01:56:09.551] iteration 24175 : model1 loss : 0.018255 model2 loss : 0.019379
[01:56:10.198] iteration 24176 : model1 loss : 0.024702 model2 loss : 0.025739
[01:56:10.859] iteration 24177 : model1 loss : 0.025753 model2 loss : 0.023050
[01:56:11.519] iteration 24178 : model1 loss : 0.028710 model2 loss : 0.027134
[01:56:12.187] iteration 24179 : model1 loss : 0.031665 model2 loss : 0.036046
[01:56:12.852] iteration 24180 : model1 loss : 0.021937 model2 loss : 0.021344
[01:56:13.508] iteration 24181 : model1 loss : 0.017382 model2 loss : 0.017757
[01:56:14.169] iteration 24182 : model1 loss : 0.019495 model2 loss : 0.019284
[01:56:14.823] iteration 24183 : model1 loss : 0.024867 model2 loss : 0.028219
[01:56:15.507] iteration 24184 : model1 loss : 0.019972 model2 loss : 0.018666
[01:56:16.176] iteration 24185 : model1 loss : 0.017437 model2 loss : 0.019046
[01:56:16.830] iteration 24186 : model1 loss : 0.016496 model2 loss : 0.017201
[01:56:17.497] iteration 24187 : model1 loss : 0.021613 model2 loss : 0.020952
[01:56:18.157] iteration 24188 : model1 loss : 0.019641 model2 loss : 0.021481
[01:56:18.817] iteration 24189 : model1 loss : 0.019990 model2 loss : 0.021819
[01:56:19.476] iteration 24190 : model1 loss : 0.147204 model2 loss : 0.145606
[01:56:20.128] iteration 24191 : model1 loss : 0.027468 model2 loss : 0.030022
[01:56:20.778] iteration 24192 : model1 loss : 0.017216 model2 loss : 0.015690
[01:56:21.451] iteration 24193 : model1 loss : 0.027243 model2 loss : 0.022255
[01:56:22.106] iteration 24194 : model1 loss : 0.024895 model2 loss : 0.023276
[01:56:22.769] iteration 24195 : model1 loss : 0.021120 model2 loss : 0.023491
[01:56:23.435] iteration 24196 : model1 loss : 0.018034 model2 loss : 0.020149
[01:56:24.097] iteration 24197 : model1 loss : 0.020657 model2 loss : 0.018315
[01:56:24.758] iteration 24198 : model1 loss : 0.035580 model2 loss : 0.035384
[01:56:25.430] iteration 24199 : model1 loss : 0.022320 model2 loss : 0.024882
[01:56:26.088] iteration 24200 : model1 loss : 0.020768 model2 loss : 0.017963
[01:56:44.292] iteration 24200 : model1_mean_dice : 0.875949 model1_mean_hd95 : 7.506297
[01:57:02.080] iteration 24200 : model2_mean_dice : 0.878743 model2_mean_hd95 : 3.962599
[01:57:02.760] iteration 24201 : model1 loss : 0.017958 model2 loss : 0.019544
[01:57:03.405] iteration 24202 : model1 loss : 0.023277 model2 loss : 0.022699
[01:57:04.069] iteration 24203 : model1 loss : 0.016703 model2 loss : 0.018415
[01:57:04.709] iteration 24204 : model1 loss : 0.022267 model2 loss : 0.024206
[01:57:05.367] iteration 24205 : model1 loss : 0.030840 model2 loss : 0.022436
[01:57:06.027] iteration 24206 : model1 loss : 0.018136 model2 loss : 0.016794
[01:57:06.674] iteration 24207 : model1 loss : 0.022711 model2 loss : 0.025887
[01:57:07.332] iteration 24208 : model1 loss : 0.030396 model2 loss : 0.030884
[01:57:07.985] iteration 24209 : model1 loss : 0.028916 model2 loss : 0.025898
[01:57:08.641] iteration 24210 : model1 loss : 0.017588 model2 loss : 0.017995
[01:57:09.309] iteration 24211 : model1 loss : 0.019338 model2 loss : 0.020170
[01:57:09.973] iteration 24212 : model1 loss : 0.026676 model2 loss : 0.030615
[01:57:10.634] iteration 24213 : model1 loss : 0.022154 model2 loss : 0.021889
[01:57:11.309] iteration 24214 : model1 loss : 0.024953 model2 loss : 0.025217
[01:57:11.965] iteration 24215 : model1 loss : 0.022181 model2 loss : 0.020947
[01:57:12.646] iteration 24216 : model1 loss : 0.021824 model2 loss : 0.020107
[01:57:13.305] iteration 24217 : model1 loss : 0.023078 model2 loss : 0.024173
[01:57:13.966] iteration 24218 : model1 loss : 0.025799 model2 loss : 0.026210
[01:57:14.616] iteration 24219 : model1 loss : 0.016818 model2 loss : 0.018877
[01:57:15.267] iteration 24220 : model1 loss : 0.019353 model2 loss : 0.019535
[01:57:15.932] iteration 24221 : model1 loss : 0.024478 model2 loss : 0.024884
[01:57:16.590] iteration 24222 : model1 loss : 0.022155 model2 loss : 0.022334
[01:57:17.254] iteration 24223 : model1 loss : 0.019373 model2 loss : 0.017709
[01:57:17.907] iteration 24224 : model1 loss : 0.017994 model2 loss : 0.017538
[01:57:18.567] iteration 24225 : model1 loss : 0.017989 model2 loss : 0.016650
[01:57:19.226] iteration 24226 : model1 loss : 0.025471 model2 loss : 0.027386
[01:57:19.874] iteration 24227 : model1 loss : 0.021005 model2 loss : 0.024756
[01:57:20.540] iteration 24228 : model1 loss : 0.145054 model2 loss : 0.144714
[01:57:21.208] iteration 24229 : model1 loss : 0.020112 model2 loss : 0.020623
[01:57:21.883] iteration 24230 : model1 loss : 0.021306 model2 loss : 0.022583
[01:57:22.550] iteration 24231 : model1 loss : 0.020279 model2 loss : 0.019318
[01:57:23.200] iteration 24232 : model1 loss : 0.017678 model2 loss : 0.017453
[01:57:23.861] iteration 24233 : model1 loss : 0.021501 model2 loss : 0.022829
[01:57:24.520] iteration 24234 : model1 loss : 0.018373 model2 loss : 0.019589
[01:57:25.181] iteration 24235 : model1 loss : 0.020137 model2 loss : 0.019156
[01:57:25.832] iteration 24236 : model1 loss : 0.143900 model2 loss : 0.143140
[01:57:26.508] iteration 24237 : model1 loss : 0.015370 model2 loss : 0.021874
[01:57:27.159] iteration 24238 : model1 loss : 0.016634 model2 loss : 0.016189
[01:57:27.809] iteration 24239 : model1 loss : 0.015247 model2 loss : 0.015860
[01:57:28.468] iteration 24240 : model1 loss : 0.025250 model2 loss : 0.027302
[01:57:29.129] iteration 24241 : model1 loss : 0.077933 model2 loss : 0.077389
[01:57:29.772] iteration 24242 : model1 loss : 0.025310 model2 loss : 0.023746
[01:57:30.431] iteration 24243 : model1 loss : 0.015161 model2 loss : 0.015274
[01:57:31.087] iteration 24244 : model1 loss : 0.021481 model2 loss : 0.021606
[01:57:31.743] iteration 24245 : model1 loss : 0.028439 model2 loss : 0.028814
[01:57:32.426] iteration 24246 : model1 loss : 0.022262 model2 loss : 0.021165
[01:57:33.099] iteration 24247 : model1 loss : 0.034257 model2 loss : 0.031456
[01:57:33.769] iteration 24248 : model1 loss : 0.023697 model2 loss : 0.023008
[01:57:34.421] iteration 24249 : model1 loss : 0.022088 model2 loss : 0.019981
[01:57:35.079] iteration 24250 : model1 loss : 0.020758 model2 loss : 0.021957
[01:57:35.773] iteration 24251 : model1 loss : 0.022927 model2 loss : 0.024952
[01:57:36.425] iteration 24252 : model1 loss : 0.027013 model2 loss : 0.024202
[01:57:37.087] iteration 24253 : model1 loss : 0.022112 model2 loss : 0.021009
[01:57:37.745] iteration 24254 : model1 loss : 0.020622 model2 loss : 0.020568
[01:57:38.408] iteration 24255 : model1 loss : 0.044352 model2 loss : 0.039880
[01:57:39.074] iteration 24256 : model1 loss : 0.018645 model2 loss : 0.019729
[01:57:39.741] iteration 24257 : model1 loss : 0.026008 model2 loss : 0.026819
[01:57:40.393] iteration 24258 : model1 loss : 0.014589 model2 loss : 0.014744
[01:57:41.048] iteration 24259 : model1 loss : 0.023656 model2 loss : 0.022582
[01:57:41.712] iteration 24260 : model1 loss : 0.018047 model2 loss : 0.019834
[01:57:42.373] iteration 24261 : model1 loss : 0.019147 model2 loss : 0.018999
[01:57:43.041] iteration 24262 : model1 loss : 0.019824 model2 loss : 0.019595
[01:57:43.705] iteration 24263 : model1 loss : 0.022956 model2 loss : 0.022868
[01:57:44.380] iteration 24264 : model1 loss : 0.019885 model2 loss : 0.019705
[01:57:45.034] iteration 24265 : model1 loss : 0.032199 model2 loss : 0.032298
[01:57:45.703] iteration 24266 : model1 loss : 0.018788 model2 loss : 0.019697
[01:57:46.370] iteration 24267 : model1 loss : 0.025887 model2 loss : 0.023248
[01:57:47.028] iteration 24268 : model1 loss : 0.017833 model2 loss : 0.017925
[01:57:47.694] iteration 24269 : model1 loss : 0.022747 model2 loss : 0.023112
[01:57:48.353] iteration 24270 : model1 loss : 0.016967 model2 loss : 0.017054
[01:57:49.032] iteration 24271 : model1 loss : 0.020149 model2 loss : 0.020112
[01:57:49.688] iteration 24272 : model1 loss : 0.017590 model2 loss : 0.019484
[01:57:50.353] iteration 24273 : model1 loss : 0.016566 model2 loss : 0.018170
[01:57:51.008] iteration 24274 : model1 loss : 0.264537 model2 loss : 0.260514
[01:57:51.660] iteration 24275 : model1 loss : 0.023268 model2 loss : 0.024418
[01:57:52.334] iteration 24276 : model1 loss : 0.017609 model2 loss : 0.017448
[01:57:52.992] iteration 24277 : model1 loss : 0.017604 model2 loss : 0.017171
[01:57:53.653] iteration 24278 : model1 loss : 0.024930 model2 loss : 0.025664
[01:57:54.325] iteration 24279 : model1 loss : 0.028487 model2 loss : 0.022814
[01:57:54.975] iteration 24280 : model1 loss : 0.020396 model2 loss : 0.021182
[01:57:55.635] iteration 24281 : model1 loss : 0.020694 model2 loss : 0.018882
[01:57:56.286] iteration 24282 : model1 loss : 0.020417 model2 loss : 0.023384
[01:57:56.938] iteration 24283 : model1 loss : 0.021113 model2 loss : 0.021326
[01:57:57.601] iteration 24284 : model1 loss : 0.025484 model2 loss : 0.021933
[01:57:58.262] iteration 24285 : model1 loss : 0.023766 model2 loss : 0.021907
[01:57:58.934] iteration 24286 : model1 loss : 0.024677 model2 loss : 0.020834
[01:57:59.579] iteration 24287 : model1 loss : 0.036873 model2 loss : 0.028541
[01:58:00.247] iteration 24288 : model1 loss : 0.021131 model2 loss : 0.024957
[01:58:00.906] iteration 24289 : model1 loss : 0.015000 model2 loss : 0.015716
[01:58:01.569] iteration 24290 : model1 loss : 0.026452 model2 loss : 0.026627
[01:58:02.234] iteration 24291 : model1 loss : 0.026008 model2 loss : 0.027246
[01:58:02.885] iteration 24292 : model1 loss : 0.019951 model2 loss : 0.020269
[01:58:03.548] iteration 24293 : model1 loss : 0.019128 model2 loss : 0.024394
[01:58:04.212] iteration 24294 : model1 loss : 0.017537 model2 loss : 0.017901
[01:58:04.875] iteration 24295 : model1 loss : 0.023724 model2 loss : 0.023569
[01:58:05.552] iteration 24296 : model1 loss : 0.020231 model2 loss : 0.017843
[01:58:06.199] iteration 24297 : model1 loss : 0.022339 model2 loss : 0.021784
[01:58:06.858] iteration 24298 : model1 loss : 0.020707 model2 loss : 0.018927
[01:58:07.510] iteration 24299 : model1 loss : 0.017101 model2 loss : 0.016577
[01:58:08.168] iteration 24300 : model1 loss : 0.018680 model2 loss : 0.022661
[01:58:08.853] iteration 24301 : model1 loss : 0.019350 model2 loss : 0.017884
[01:58:09.514] iteration 24302 : model1 loss : 0.017931 model2 loss : 0.019528
[01:58:10.162] iteration 24303 : model1 loss : 0.021998 model2 loss : 0.022757
[01:58:10.814] iteration 24304 : model1 loss : 0.015308 model2 loss : 0.015663
[01:58:11.470] iteration 24305 : model1 loss : 0.020789 model2 loss : 0.020848
[01:58:12.134] iteration 24306 : model1 loss : 0.018719 model2 loss : 0.020245
[01:58:12.800] iteration 24307 : model1 loss : 0.036512 model2 loss : 0.035687
[01:58:13.457] iteration 24308 : model1 loss : 0.030719 model2 loss : 0.036390
[01:58:14.112] iteration 24309 : model1 loss : 0.019983 model2 loss : 0.018373
[01:58:14.764] iteration 24310 : model1 loss : 0.019980 model2 loss : 0.021172
[01:58:15.428] iteration 24311 : model1 loss : 0.022633 model2 loss : 0.025927
[01:58:16.086] iteration 24312 : model1 loss : 0.014815 model2 loss : 0.014642
[01:58:16.750] iteration 24313 : model1 loss : 0.021000 model2 loss : 0.021993
[01:58:17.405] iteration 24314 : model1 loss : 0.015821 model2 loss : 0.015496
[01:58:18.064] iteration 24315 : model1 loss : 0.020992 model2 loss : 0.019572
[01:58:18.741] iteration 24316 : model1 loss : 0.036125 model2 loss : 0.033743
[01:58:19.396] iteration 24317 : model1 loss : 0.021656 model2 loss : 0.022227
[01:58:20.049] iteration 24318 : model1 loss : 0.019760 model2 loss : 0.019773
[01:58:20.708] iteration 24319 : model1 loss : 0.018659 model2 loss : 0.021654
[01:58:21.369] iteration 24320 : model1 loss : 0.021671 model2 loss : 0.019670
[01:58:22.015] iteration 24321 : model1 loss : 0.030375 model2 loss : 0.035226
[01:58:22.695] iteration 24322 : model1 loss : 0.018422 model2 loss : 0.019486
[01:58:23.345] iteration 24323 : model1 loss : 0.018662 model2 loss : 0.021421
[01:58:24.007] iteration 24324 : model1 loss : 0.018304 model2 loss : 0.019034
[01:58:24.664] iteration 24325 : model1 loss : 0.017621 model2 loss : 0.017736
[01:58:25.325] iteration 24326 : model1 loss : 0.020960 model2 loss : 0.019250
[01:58:25.980] iteration 24327 : model1 loss : 0.023276 model2 loss : 0.020968
[01:58:26.650] iteration 24328 : model1 loss : 0.015920 model2 loss : 0.015671
[01:58:27.312] iteration 24329 : model1 loss : 0.026171 model2 loss : 0.025841
[01:58:27.979] iteration 24330 : model1 loss : 0.029743 model2 loss : 0.029601
[01:58:28.642] iteration 24331 : model1 loss : 0.029644 model2 loss : 0.028621
[01:58:29.294] iteration 24332 : model1 loss : 0.016218 model2 loss : 0.015910
[01:58:29.956] iteration 24333 : model1 loss : 0.016528 model2 loss : 0.017230
[01:58:30.612] iteration 24334 : model1 loss : 0.014396 model2 loss : 0.013242
[01:58:31.276] iteration 24335 : model1 loss : 0.018853 model2 loss : 0.018801
[01:58:31.947] iteration 24336 : model1 loss : 0.021082 model2 loss : 0.018349
[01:58:32.615] iteration 24337 : model1 loss : 0.020129 model2 loss : 0.023959
[01:58:33.288] iteration 24338 : model1 loss : 0.022908 model2 loss : 0.019557
[01:58:33.938] iteration 24339 : model1 loss : 0.023232 model2 loss : 0.023450
[01:58:34.598] iteration 24340 : model1 loss : 0.023834 model2 loss : 0.019914
[01:58:35.255] iteration 24341 : model1 loss : 0.037770 model2 loss : 0.033524
[01:58:35.904] iteration 24342 : model1 loss : 0.022574 model2 loss : 0.020530
[01:58:36.571] iteration 24343 : model1 loss : 0.026925 model2 loss : 0.026090
[01:58:37.221] iteration 24344 : model1 loss : 0.016649 model2 loss : 0.017340
[01:58:37.878] iteration 24345 : model1 loss : 0.018106 model2 loss : 0.017880
[01:58:38.536] iteration 24346 : model1 loss : 0.021105 model2 loss : 0.020709
[01:58:39.207] iteration 24347 : model1 loss : 0.016372 model2 loss : 0.017321
[01:58:39.863] iteration 24348 : model1 loss : 0.021532 model2 loss : 0.020845
[01:58:40.510] iteration 24349 : model1 loss : 0.021927 model2 loss : 0.019258
[01:58:41.162] iteration 24350 : model1 loss : 0.019966 model2 loss : 0.020436
[01:58:41.867] iteration 24351 : model1 loss : 0.021103 model2 loss : 0.023070
[01:58:42.537] iteration 24352 : model1 loss : 0.019489 model2 loss : 0.018167
[01:58:43.204] iteration 24353 : model1 loss : 0.028907 model2 loss : 0.029494
[01:58:43.861] iteration 24354 : model1 loss : 0.017601 model2 loss : 0.018188
[01:58:44.563] iteration 24355 : model1 loss : 0.019939 model2 loss : 0.018342
[01:58:45.230] iteration 24356 : model1 loss : 0.024018 model2 loss : 0.022263
[01:58:45.879] iteration 24357 : model1 loss : 0.039419 model2 loss : 0.038258
[01:58:46.543] iteration 24358 : model1 loss : 0.017914 model2 loss : 0.016116
[01:58:47.214] iteration 24359 : model1 loss : 0.022807 model2 loss : 0.022186
[01:58:47.881] iteration 24360 : model1 loss : 0.030360 model2 loss : 0.034676
[01:58:48.576] iteration 24361 : model1 loss : 0.029123 model2 loss : 0.026285
[01:58:49.241] iteration 24362 : model1 loss : 0.021122 model2 loss : 0.021831
[01:58:49.892] iteration 24363 : model1 loss : 0.019097 model2 loss : 0.020209
[01:58:50.586] iteration 24364 : model1 loss : 0.019617 model2 loss : 0.019607
[01:58:51.266] iteration 24365 : model1 loss : 0.023383 model2 loss : 0.023762
[01:58:51.924] iteration 24366 : model1 loss : 0.017449 model2 loss : 0.016154
[01:58:52.585] iteration 24367 : model1 loss : 0.019799 model2 loss : 0.020581
[01:58:53.244] iteration 24368 : model1 loss : 0.024313 model2 loss : 0.021849
[01:58:53.911] iteration 24369 : model1 loss : 0.029742 model2 loss : 0.029016
[01:58:54.569] iteration 24370 : model1 loss : 0.019367 model2 loss : 0.022282
[01:58:55.227] iteration 24371 : model1 loss : 0.026302 model2 loss : 0.027222
[01:58:55.891] iteration 24372 : model1 loss : 0.138299 model2 loss : 0.140587
[01:58:56.552] iteration 24373 : model1 loss : 0.022980 model2 loss : 0.023949
[01:58:57.216] iteration 24374 : model1 loss : 0.020527 model2 loss : 0.021068
[01:58:57.868] iteration 24375 : model1 loss : 0.018868 model2 loss : 0.018648
[01:58:58.524] iteration 24376 : model1 loss : 0.021396 model2 loss : 0.022723
[01:58:59.183] iteration 24377 : model1 loss : 0.021343 model2 loss : 0.019965
[01:58:59.836] iteration 24378 : model1 loss : 0.019682 model2 loss : 0.019500
[01:59:00.501] iteration 24379 : model1 loss : 0.021564 model2 loss : 0.021502
[01:59:01.151] iteration 24380 : model1 loss : 0.020313 model2 loss : 0.019710
[01:59:01.815] iteration 24381 : model1 loss : 0.016807 model2 loss : 0.018055
[01:59:02.470] iteration 24382 : model1 loss : 0.022874 model2 loss : 0.022172
[01:59:03.138] iteration 24383 : model1 loss : 0.017672 model2 loss : 0.017133
[01:59:03.800] iteration 24384 : model1 loss : 0.019318 model2 loss : 0.017492
[01:59:04.461] iteration 24385 : model1 loss : 0.020899 model2 loss : 0.023638
[01:59:05.122] iteration 24386 : model1 loss : 0.021078 model2 loss : 0.020361
[01:59:05.789] iteration 24387 : model1 loss : 0.018348 model2 loss : 0.018029
[01:59:06.451] iteration 24388 : model1 loss : 0.019759 model2 loss : 0.020447
[01:59:07.106] iteration 24389 : model1 loss : 0.025438 model2 loss : 0.024134
[01:59:07.761] iteration 24390 : model1 loss : 0.015135 model2 loss : 0.014156
[01:59:08.420] iteration 24391 : model1 loss : 0.016618 model2 loss : 0.014662
[01:59:09.079] iteration 24392 : model1 loss : 0.023463 model2 loss : 0.025025
[01:59:09.741] iteration 24393 : model1 loss : 0.024628 model2 loss : 0.025330
[01:59:10.401] iteration 24394 : model1 loss : 0.022522 model2 loss : 0.022013
[01:59:11.053] iteration 24395 : model1 loss : 0.029156 model2 loss : 0.023350
[01:59:11.707] iteration 24396 : model1 loss : 0.020893 model2 loss : 0.021939
[01:59:12.371] iteration 24397 : model1 loss : 0.021489 model2 loss : 0.018759
[01:59:13.024] iteration 24398 : model1 loss : 0.017053 model2 loss : 0.018647
[01:59:13.691] iteration 24399 : model1 loss : 0.019718 model2 loss : 0.019393
[01:59:14.355] iteration 24400 : model1 loss : 0.020476 model2 loss : 0.019892
[01:59:32.059] iteration 24400 : model1_mean_dice : 0.878813 model1_mean_hd95 : 6.646346
[01:59:50.074] iteration 24400 : model2_mean_dice : 0.879604 model2_mean_hd95 : 4.136000
[01:59:50.758] iteration 24401 : model1 loss : 0.021904 model2 loss : 0.022048
[01:59:51.410] iteration 24402 : model1 loss : 0.139883 model2 loss : 0.137914
[01:59:52.072] iteration 24403 : model1 loss : 0.027741 model2 loss : 0.024725
[01:59:52.732] iteration 24404 : model1 loss : 0.024532 model2 loss : 0.024578
[01:59:53.384] iteration 24405 : model1 loss : 0.020274 model2 loss : 0.023689
[01:59:54.021] iteration 24406 : model1 loss : 0.018777 model2 loss : 0.017559
[01:59:54.671] iteration 24407 : model1 loss : 0.031391 model2 loss : 0.026371
[01:59:55.338] iteration 24408 : model1 loss : 0.021387 model2 loss : 0.020406
[01:59:55.993] iteration 24409 : model1 loss : 0.022901 model2 loss : 0.022156
[01:59:56.643] iteration 24410 : model1 loss : 0.019546 model2 loss : 0.018103
[01:59:57.298] iteration 24411 : model1 loss : 0.017022 model2 loss : 0.016199
[01:59:57.967] iteration 24412 : model1 loss : 0.029047 model2 loss : 0.027381
[01:59:58.615] iteration 24413 : model1 loss : 0.019301 model2 loss : 0.018259
[01:59:59.270] iteration 24414 : model1 loss : 0.015929 model2 loss : 0.015753
[01:59:59.922] iteration 24415 : model1 loss : 0.017212 model2 loss : 0.018372
[02:00:00.573] iteration 24416 : model1 loss : 0.014149 model2 loss : 0.014166
[02:00:01.234] iteration 24417 : model1 loss : 0.016970 model2 loss : 0.017279
[02:00:01.881] iteration 24418 : model1 loss : 0.015025 model2 loss : 0.014833
[02:00:02.549] iteration 24419 : model1 loss : 0.015398 model2 loss : 0.015384
[02:00:03.202] iteration 24420 : model1 loss : 0.013883 model2 loss : 0.013908
[02:00:03.862] iteration 24421 : model1 loss : 0.022568 model2 loss : 0.024471
[02:00:04.516] iteration 24422 : model1 loss : 0.024797 model2 loss : 0.023103
[02:00:05.170] iteration 24423 : model1 loss : 0.014182 model2 loss : 0.013648
[02:00:05.842] iteration 24424 : model1 loss : 0.025533 model2 loss : 0.024546
[02:00:06.503] iteration 24425 : model1 loss : 0.019078 model2 loss : 0.020062
[02:00:07.174] iteration 24426 : model1 loss : 0.020560 model2 loss : 0.021336
[02:00:07.826] iteration 24427 : model1 loss : 0.018225 model2 loss : 0.019246
[02:00:08.502] iteration 24428 : model1 loss : 0.035980 model2 loss : 0.031437
[02:00:09.160] iteration 24429 : model1 loss : 0.019010 model2 loss : 0.018761
[02:00:09.813] iteration 24430 : model1 loss : 0.021289 model2 loss : 0.022156
[02:00:10.463] iteration 24431 : model1 loss : 0.020162 model2 loss : 0.019589
[02:00:11.113] iteration 24432 : model1 loss : 0.018941 model2 loss : 0.019327
[02:00:11.767] iteration 24433 : model1 loss : 0.020436 model2 loss : 0.020223
[02:00:12.436] iteration 24434 : model1 loss : 0.013415 model2 loss : 0.012479
[02:00:13.099] iteration 24435 : model1 loss : 0.020203 model2 loss : 0.018315
[02:00:13.753] iteration 24436 : model1 loss : 0.020148 model2 loss : 0.020623
[02:00:14.428] iteration 24437 : model1 loss : 0.021750 model2 loss : 0.022617
[02:00:15.071] iteration 24438 : model1 loss : 0.015695 model2 loss : 0.016508
[02:00:15.731] iteration 24439 : model1 loss : 0.024967 model2 loss : 0.026846
[02:00:16.379] iteration 24440 : model1 loss : 0.020202 model2 loss : 0.022642
[02:00:17.039] iteration 24441 : model1 loss : 0.017595 model2 loss : 0.017294
[02:00:17.690] iteration 24442 : model1 loss : 0.032363 model2 loss : 0.032880
[02:00:18.346] iteration 24443 : model1 loss : 0.022341 model2 loss : 0.026080
[02:00:19.019] iteration 24444 : model1 loss : 0.017731 model2 loss : 0.016617
[02:00:19.678] iteration 24445 : model1 loss : 0.020330 model2 loss : 0.022690
[02:00:20.338] iteration 24446 : model1 loss : 0.019973 model2 loss : 0.019359
[02:00:20.994] iteration 24447 : model1 loss : 0.021105 model2 loss : 0.020979
[02:00:21.643] iteration 24448 : model1 loss : 0.020658 model2 loss : 0.020881
[02:00:22.303] iteration 24449 : model1 loss : 0.026032 model2 loss : 0.025656
[02:00:22.958] iteration 24450 : model1 loss : 0.020238 model2 loss : 0.021175
[02:00:23.662] iteration 24451 : model1 loss : 0.015584 model2 loss : 0.017262
[02:00:24.336] iteration 24452 : model1 loss : 0.017286 model2 loss : 0.019208
[02:00:24.986] iteration 24453 : model1 loss : 0.025640 model2 loss : 0.026839
[02:00:25.651] iteration 24454 : model1 loss : 0.020166 model2 loss : 0.019927
[02:00:26.319] iteration 24455 : model1 loss : 0.020764 model2 loss : 0.021139
[02:00:26.990] iteration 24456 : model1 loss : 0.017699 model2 loss : 0.019337
[02:00:27.640] iteration 24457 : model1 loss : 0.019790 model2 loss : 0.018176
[02:00:28.306] iteration 24458 : model1 loss : 0.018073 model2 loss : 0.017263
[02:00:28.961] iteration 24459 : model1 loss : 0.020988 model2 loss : 0.023873
[02:00:29.627] iteration 24460 : model1 loss : 0.024508 model2 loss : 0.022485
[02:00:30.283] iteration 24461 : model1 loss : 0.014730 model2 loss : 0.014716
[02:00:30.946] iteration 24462 : model1 loss : 0.019778 model2 loss : 0.018379
[02:00:31.611] iteration 24463 : model1 loss : 0.023728 model2 loss : 0.023227
[02:00:32.276] iteration 24464 : model1 loss : 0.019703 model2 loss : 0.019264
[02:00:32.926] iteration 24465 : model1 loss : 0.016771 model2 loss : 0.018359
[02:00:33.594] iteration 24466 : model1 loss : 0.026326 model2 loss : 0.023408
[02:00:34.255] iteration 24467 : model1 loss : 0.020275 model2 loss : 0.022305
[02:00:34.908] iteration 24468 : model1 loss : 0.046726 model2 loss : 0.073649
[02:00:35.556] iteration 24469 : model1 loss : 0.025959 model2 loss : 0.023818
[02:00:36.210] iteration 24470 : model1 loss : 0.020401 model2 loss : 0.022597
[02:00:36.870] iteration 24471 : model1 loss : 0.025258 model2 loss : 0.027515
[02:00:37.544] iteration 24472 : model1 loss : 0.021544 model2 loss : 0.019681
[02:00:38.198] iteration 24473 : model1 loss : 0.020443 model2 loss : 0.018447
[02:00:38.850] iteration 24474 : model1 loss : 0.034425 model2 loss : 0.036397
[02:00:39.504] iteration 24475 : model1 loss : 0.144565 model2 loss : 0.145619
[02:00:40.159] iteration 24476 : model1 loss : 0.024673 model2 loss : 0.025210
[02:00:40.819] iteration 24477 : model1 loss : 0.021881 model2 loss : 0.023704
[02:00:41.477] iteration 24478 : model1 loss : 0.022674 model2 loss : 0.023035
[02:00:42.130] iteration 24479 : model1 loss : 0.016982 model2 loss : 0.017131
[02:00:42.785] iteration 24480 : model1 loss : 0.015805 model2 loss : 0.015969
[02:00:43.437] iteration 24481 : model1 loss : 0.017452 model2 loss : 0.020785
[02:00:44.094] iteration 24482 : model1 loss : 0.019957 model2 loss : 0.017859
[02:00:44.749] iteration 24483 : model1 loss : 0.020386 model2 loss : 0.019351
[02:00:45.446] iteration 24484 : model1 loss : 0.020688 model2 loss : 0.021824
[02:00:46.116] iteration 24485 : model1 loss : 0.022981 model2 loss : 0.023652
[02:00:46.774] iteration 24486 : model1 loss : 0.020766 model2 loss : 0.020361
[02:00:47.430] iteration 24487 : model1 loss : 0.021812 model2 loss : 0.021507
[02:00:48.075] iteration 24488 : model1 loss : 0.017843 model2 loss : 0.017018
[02:00:48.734] iteration 24489 : model1 loss : 0.020476 model2 loss : 0.019665
[02:00:49.391] iteration 24490 : model1 loss : 0.021683 model2 loss : 0.021174
[02:00:50.044] iteration 24491 : model1 loss : 0.031011 model2 loss : 0.029998
[02:00:50.708] iteration 24492 : model1 loss : 0.016441 model2 loss : 0.017464
[02:00:51.368] iteration 24493 : model1 loss : 0.018241 model2 loss : 0.018962
[02:00:52.039] iteration 24494 : model1 loss : 0.019421 model2 loss : 0.019841
[02:00:52.708] iteration 24495 : model1 loss : 0.015034 model2 loss : 0.014780
[02:00:53.361] iteration 24496 : model1 loss : 0.022482 model2 loss : 0.022185
[02:00:54.026] iteration 24497 : model1 loss : 0.023731 model2 loss : 0.021902
[02:00:54.684] iteration 24498 : model1 loss : 0.028702 model2 loss : 0.026465
[02:00:55.353] iteration 24499 : model1 loss : 0.017719 model2 loss : 0.020831
[02:00:56.046] iteration 24500 : model1 loss : 0.027719 model2 loss : 0.027660
[02:00:56.751] iteration 24501 : model1 loss : 0.021835 model2 loss : 0.022935
[02:00:57.409] iteration 24502 : model1 loss : 0.028052 model2 loss : 0.024557
[02:00:58.055] iteration 24503 : model1 loss : 0.017275 model2 loss : 0.016989
[02:00:58.723] iteration 24504 : model1 loss : 0.022781 model2 loss : 0.021254
[02:00:59.385] iteration 24505 : model1 loss : 0.051235 model2 loss : 0.033591
[02:01:00.038] iteration 24506 : model1 loss : 0.014997 model2 loss : 0.017086
[02:01:00.698] iteration 24507 : model1 loss : 0.016624 model2 loss : 0.017021
[02:01:01.361] iteration 24508 : model1 loss : 0.019887 model2 loss : 0.019901
[02:01:02.006] iteration 24509 : model1 loss : 0.016229 model2 loss : 0.016904
[02:01:02.684] iteration 24510 : model1 loss : 0.024492 model2 loss : 0.021362
[02:01:03.336] iteration 24511 : model1 loss : 0.020087 model2 loss : 0.018025
[02:01:03.992] iteration 24512 : model1 loss : 0.019048 model2 loss : 0.019403
[02:01:04.639] iteration 24513 : model1 loss : 0.019931 model2 loss : 0.018927
[02:01:05.291] iteration 24514 : model1 loss : 0.022154 model2 loss : 0.022453
[02:01:05.937] iteration 24515 : model1 loss : 0.019368 model2 loss : 0.019423
[02:01:06.585] iteration 24516 : model1 loss : 0.019996 model2 loss : 0.021814
[02:01:07.254] iteration 24517 : model1 loss : 0.024274 model2 loss : 0.020757
[02:01:07.908] iteration 24518 : model1 loss : 0.023688 model2 loss : 0.023098
[02:01:08.579] iteration 24519 : model1 loss : 0.015751 model2 loss : 0.015751
[02:01:09.237] iteration 24520 : model1 loss : 0.018654 model2 loss : 0.022999
[02:01:09.897] iteration 24521 : model1 loss : 0.019030 model2 loss : 0.018398
[02:01:10.553] iteration 24522 : model1 loss : 0.021405 model2 loss : 0.019912
[02:01:11.208] iteration 24523 : model1 loss : 0.027676 model2 loss : 0.025478
[02:01:11.869] iteration 24524 : model1 loss : 0.017349 model2 loss : 0.017516
[02:01:12.548] iteration 24525 : model1 loss : 0.023432 model2 loss : 0.022137
[02:01:13.201] iteration 24526 : model1 loss : 0.022823 model2 loss : 0.024657
[02:01:13.867] iteration 24527 : model1 loss : 0.017235 model2 loss : 0.019134
[02:01:14.525] iteration 24528 : model1 loss : 0.021361 model2 loss : 0.021428
[02:01:15.187] iteration 24529 : model1 loss : 0.017056 model2 loss : 0.018214
[02:01:15.855] iteration 24530 : model1 loss : 0.019390 model2 loss : 0.019862
[02:01:16.508] iteration 24531 : model1 loss : 0.017822 model2 loss : 0.018525
[02:01:17.167] iteration 24532 : model1 loss : 0.018527 model2 loss : 0.018366
[02:01:17.820] iteration 24533 : model1 loss : 0.013392 model2 loss : 0.015271
[02:01:18.473] iteration 24534 : model1 loss : 0.020088 model2 loss : 0.017427
[02:01:19.134] iteration 24535 : model1 loss : 0.026350 model2 loss : 0.028797
[02:01:19.788] iteration 24536 : model1 loss : 0.018507 model2 loss : 0.018816
[02:01:20.457] iteration 24537 : model1 loss : 0.025186 model2 loss : 0.026467
[02:01:21.125] iteration 24538 : model1 loss : 0.021202 model2 loss : 0.022164
[02:01:21.781] iteration 24539 : model1 loss : 0.016580 model2 loss : 0.016272
[02:01:22.439] iteration 24540 : model1 loss : 0.022715 model2 loss : 0.021166
[02:01:23.107] iteration 24541 : model1 loss : 0.020215 model2 loss : 0.020599
[02:01:23.772] iteration 24542 : model1 loss : 0.017064 model2 loss : 0.017825
[02:01:24.434] iteration 24543 : model1 loss : 0.028171 model2 loss : 0.026672
[02:01:25.091] iteration 24544 : model1 loss : 0.068258 model2 loss : 0.042930
[02:01:25.760] iteration 24545 : model1 loss : 0.023650 model2 loss : 0.022769
[02:01:26.423] iteration 24546 : model1 loss : 0.016811 model2 loss : 0.020065
[02:01:27.098] iteration 24547 : model1 loss : 0.017814 model2 loss : 0.017858
[02:01:27.767] iteration 24548 : model1 loss : 0.021889 model2 loss : 0.020561
[02:01:28.435] iteration 24549 : model1 loss : 0.023343 model2 loss : 0.021232
[02:01:29.088] iteration 24550 : model1 loss : 0.016491 model2 loss : 0.016594
[02:01:29.779] iteration 24551 : model1 loss : 0.018068 model2 loss : 0.016872
[02:01:30.440] iteration 24552 : model1 loss : 0.020132 model2 loss : 0.021266
[02:01:31.087] iteration 24553 : model1 loss : 0.014215 model2 loss : 0.013646
[02:01:31.737] iteration 24554 : model1 loss : 0.021774 model2 loss : 0.019538
[02:01:32.396] iteration 24555 : model1 loss : 0.027508 model2 loss : 0.027446
[02:01:33.064] iteration 24556 : model1 loss : 0.019566 model2 loss : 0.021460
[02:01:33.725] iteration 24557 : model1 loss : 0.029125 model2 loss : 0.027429
[02:01:34.386] iteration 24558 : model1 loss : 0.018399 model2 loss : 0.020160
[02:01:35.050] iteration 24559 : model1 loss : 0.020049 model2 loss : 0.019439
[02:01:35.711] iteration 24560 : model1 loss : 0.017696 model2 loss : 0.016890
[02:01:36.365] iteration 24561 : model1 loss : 0.027506 model2 loss : 0.026143
[02:01:37.023] iteration 24562 : model1 loss : 0.024652 model2 loss : 0.025065
[02:01:37.681] iteration 24563 : model1 loss : 0.022345 model2 loss : 0.020997
[02:01:38.337] iteration 24564 : model1 loss : 0.022158 model2 loss : 0.019514
[02:01:39.003] iteration 24565 : model1 loss : 0.018346 model2 loss : 0.018136
[02:01:39.664] iteration 24566 : model1 loss : 0.017696 model2 loss : 0.019591
[02:01:40.324] iteration 24567 : model1 loss : 0.022381 model2 loss : 0.021029
[02:01:40.978] iteration 24568 : model1 loss : 0.018335 model2 loss : 0.018232
[02:01:41.648] iteration 24569 : model1 loss : 0.024549 model2 loss : 0.021653
[02:01:42.311] iteration 24570 : model1 loss : 0.019274 model2 loss : 0.017958
[02:01:42.979] iteration 24571 : model1 loss : 0.019135 model2 loss : 0.018688
[02:01:43.661] iteration 24572 : model1 loss : 0.024669 model2 loss : 0.022582
[02:01:44.342] iteration 24573 : model1 loss : 0.020743 model2 loss : 0.023023
[02:01:45.009] iteration 24574 : model1 loss : 0.037285 model2 loss : 0.024293
[02:01:45.705] iteration 24575 : model1 loss : 0.018519 model2 loss : 0.020135
[02:01:46.378] iteration 24576 : model1 loss : 0.019555 model2 loss : 0.020190
[02:01:47.049] iteration 24577 : model1 loss : 0.018739 model2 loss : 0.019385
[02:01:47.697] iteration 24578 : model1 loss : 0.029837 model2 loss : 0.027326
[02:01:48.358] iteration 24579 : model1 loss : 0.014718 model2 loss : 0.014521
[02:01:49.020] iteration 24580 : model1 loss : 0.026891 model2 loss : 0.024677
[02:01:49.686] iteration 24581 : model1 loss : 0.025230 model2 loss : 0.026526
[02:01:50.334] iteration 24582 : model1 loss : 0.021603 model2 loss : 0.021454
[02:01:50.991] iteration 24583 : model1 loss : 0.020406 model2 loss : 0.020491
[02:01:51.645] iteration 24584 : model1 loss : 0.018099 model2 loss : 0.018492
[02:01:52.306] iteration 24585 : model1 loss : 0.020342 model2 loss : 0.022802
[02:01:52.953] iteration 24586 : model1 loss : 0.023904 model2 loss : 0.023066
[02:01:53.613] iteration 24587 : model1 loss : 0.016460 model2 loss : 0.017550
[02:01:54.278] iteration 24588 : model1 loss : 0.014650 model2 loss : 0.014613
[02:01:54.927] iteration 24589 : model1 loss : 0.018315 model2 loss : 0.017446
[02:01:55.589] iteration 24590 : model1 loss : 0.025169 model2 loss : 0.021554
[02:01:56.239] iteration 24591 : model1 loss : 0.023737 model2 loss : 0.024023
[02:01:56.899] iteration 24592 : model1 loss : 0.020478 model2 loss : 0.022417
[02:01:57.564] iteration 24593 : model1 loss : 0.020640 model2 loss : 0.025008
[02:01:58.213] iteration 24594 : model1 loss : 0.031406 model2 loss : 0.026542
[02:01:58.875] iteration 24595 : model1 loss : 0.025182 model2 loss : 0.023701
[02:01:59.541] iteration 24596 : model1 loss : 0.018757 model2 loss : 0.017911
[02:02:00.194] iteration 24597 : model1 loss : 0.020660 model2 loss : 0.019093
[02:02:00.837] iteration 24598 : model1 loss : 0.016404 model2 loss : 0.015391
[02:02:01.488] iteration 24599 : model1 loss : 0.019124 model2 loss : 0.018383
[02:02:02.149] iteration 24600 : model1 loss : 0.019308 model2 loss : 0.017235
[02:02:19.830] iteration 24600 : model1_mean_dice : 0.873010 model1_mean_hd95 : 8.074244
[02:02:37.244] iteration 24600 : model2_mean_dice : 0.879121 model2_mean_hd95 : 4.083933
[02:02:37.908] iteration 24601 : model1 loss : 0.019927 model2 loss : 0.021114
[02:02:38.573] iteration 24602 : model1 loss : 0.019700 model2 loss : 0.021603
[02:02:39.222] iteration 24603 : model1 loss : 0.019027 model2 loss : 0.017654
[02:02:39.875] iteration 24604 : model1 loss : 0.017835 model2 loss : 0.017575
[02:02:40.535] iteration 24605 : model1 loss : 0.026913 model2 loss : 0.025699
[02:02:41.194] iteration 24606 : model1 loss : 0.024348 model2 loss : 0.023897
[02:02:41.845] iteration 24607 : model1 loss : 0.017432 model2 loss : 0.018398
[02:02:42.501] iteration 24608 : model1 loss : 0.019828 model2 loss : 0.018860
[02:02:43.162] iteration 24609 : model1 loss : 0.016650 model2 loss : 0.015666
[02:02:43.808] iteration 24610 : model1 loss : 0.020310 model2 loss : 0.018847
[02:02:44.475] iteration 24611 : model1 loss : 0.019232 model2 loss : 0.020121
[02:02:45.142] iteration 24612 : model1 loss : 0.022863 model2 loss : 0.023816
[02:02:45.795] iteration 24613 : model1 loss : 0.014555 model2 loss : 0.014724
[02:02:46.473] iteration 24614 : model1 loss : 0.012962 model2 loss : 0.012375
[02:02:47.134] iteration 24615 : model1 loss : 0.027919 model2 loss : 0.028494
[02:02:47.790] iteration 24616 : model1 loss : 0.017564 model2 loss : 0.018551
[02:02:48.443] iteration 24617 : model1 loss : 0.018323 model2 loss : 0.017275
[02:02:49.090] iteration 24618 : model1 loss : 0.020149 model2 loss : 0.018774
[02:02:49.754] iteration 24619 : model1 loss : 0.019077 model2 loss : 0.019196
[02:02:50.415] iteration 24620 : model1 loss : 0.017885 model2 loss : 0.015300
[02:02:51.064] iteration 24621 : model1 loss : 0.023736 model2 loss : 0.023696
[02:02:51.709] iteration 24622 : model1 loss : 0.019423 model2 loss : 0.016990
[02:02:52.364] iteration 24623 : model1 loss : 0.022079 model2 loss : 0.023944
[02:02:53.022] iteration 24624 : model1 loss : 0.018694 model2 loss : 0.018197
[02:02:53.691] iteration 24625 : model1 loss : 0.020195 model2 loss : 0.022324
[02:02:54.360] iteration 24626 : model1 loss : 0.022350 model2 loss : 0.020358
[02:02:55.017] iteration 24627 : model1 loss : 0.021685 model2 loss : 0.021338
[02:02:55.670] iteration 24628 : model1 loss : 0.019707 model2 loss : 0.019966
[02:02:56.343] iteration 24629 : model1 loss : 0.037756 model2 loss : 0.030636
[02:02:56.993] iteration 24630 : model1 loss : 0.018214 model2 loss : 0.019749
[02:02:57.650] iteration 24631 : model1 loss : 0.018714 model2 loss : 0.018521
[02:02:58.292] iteration 24632 : model1 loss : 0.020363 model2 loss : 0.019659
[02:02:58.944] iteration 24633 : model1 loss : 0.018986 model2 loss : 0.020096
[02:02:59.601] iteration 24634 : model1 loss : 0.016960 model2 loss : 0.016586
[02:03:00.244] iteration 24635 : model1 loss : 0.016593 model2 loss : 0.018222
[02:03:00.894] iteration 24636 : model1 loss : 0.023164 model2 loss : 0.023674
[02:03:01.536] iteration 24637 : model1 loss : 0.146555 model2 loss : 0.143723
[02:03:02.184] iteration 24638 : model1 loss : 0.016602 model2 loss : 0.016391
[02:03:02.839] iteration 24639 : model1 loss : 0.019936 model2 loss : 0.021121
[02:03:03.504] iteration 24640 : model1 loss : 0.021263 model2 loss : 0.024076
[02:03:04.178] iteration 24641 : model1 loss : 0.019990 model2 loss : 0.018549
[02:03:04.832] iteration 24642 : model1 loss : 0.027304 model2 loss : 0.026635
[02:03:05.490] iteration 24643 : model1 loss : 0.027644 model2 loss : 0.025443
[02:03:06.158] iteration 24644 : model1 loss : 0.019441 model2 loss : 0.019651
[02:03:06.810] iteration 24645 : model1 loss : 0.020095 model2 loss : 0.025889
[02:03:07.461] iteration 24646 : model1 loss : 0.025474 model2 loss : 0.025378
[02:03:08.116] iteration 24647 : model1 loss : 0.022121 model2 loss : 0.021348
[02:03:08.777] iteration 24648 : model1 loss : 0.021742 model2 loss : 0.019192
[02:03:09.428] iteration 24649 : model1 loss : 0.020455 model2 loss : 0.018688
[02:03:10.087] iteration 24650 : model1 loss : 0.018244 model2 loss : 0.017879
[02:03:10.774] iteration 24651 : model1 loss : 0.016356 model2 loss : 0.014360
[02:03:11.441] iteration 24652 : model1 loss : 0.017369 model2 loss : 0.018979
[02:03:12.096] iteration 24653 : model1 loss : 0.018791 model2 loss : 0.017430
[02:03:12.766] iteration 24654 : model1 loss : 0.025554 model2 loss : 0.023861
[02:03:13.421] iteration 24655 : model1 loss : 0.016569 model2 loss : 0.016026
[02:03:14.075] iteration 24656 : model1 loss : 0.015947 model2 loss : 0.015998
[02:03:14.726] iteration 24657 : model1 loss : 0.017956 model2 loss : 0.017329
[02:03:15.382] iteration 24658 : model1 loss : 0.024286 model2 loss : 0.027832
[02:03:16.037] iteration 24659 : model1 loss : 0.019287 model2 loss : 0.017462
[02:03:16.687] iteration 24660 : model1 loss : 0.016191 model2 loss : 0.015770
[02:03:17.341] iteration 24661 : model1 loss : 0.022513 model2 loss : 0.022758
[02:03:18.007] iteration 24662 : model1 loss : 0.023273 model2 loss : 0.021444
[02:03:18.659] iteration 24663 : model1 loss : 0.020400 model2 loss : 0.018567
[02:03:19.327] iteration 24664 : model1 loss : 0.022885 model2 loss : 0.022810
[02:03:19.986] iteration 24665 : model1 loss : 0.018265 model2 loss : 0.019337
[02:03:20.651] iteration 24666 : model1 loss : 0.025284 model2 loss : 0.026778
[02:03:21.326] iteration 24667 : model1 loss : 0.022069 model2 loss : 0.021692
[02:03:21.979] iteration 24668 : model1 loss : 0.020479 model2 loss : 0.019199
[02:03:22.646] iteration 24669 : model1 loss : 0.021638 model2 loss : 0.024570
[02:03:23.304] iteration 24670 : model1 loss : 0.017374 model2 loss : 0.018100
[02:03:23.965] iteration 24671 : model1 loss : 0.018460 model2 loss : 0.019433
[02:03:24.624] iteration 24672 : model1 loss : 0.024703 model2 loss : 0.024608
[02:03:25.285] iteration 24673 : model1 loss : 0.019917 model2 loss : 0.019238
[02:03:25.950] iteration 24674 : model1 loss : 0.024630 model2 loss : 0.023576
[02:03:26.598] iteration 24675 : model1 loss : 0.022491 model2 loss : 0.021176
[02:03:27.272] iteration 24676 : model1 loss : 0.021584 model2 loss : 0.022335
[02:03:27.931] iteration 24677 : model1 loss : 0.019869 model2 loss : 0.019410
[02:03:28.595] iteration 24678 : model1 loss : 0.017273 model2 loss : 0.017409
[02:03:29.254] iteration 24679 : model1 loss : 0.017088 model2 loss : 0.017618
[02:03:29.914] iteration 24680 : model1 loss : 0.021177 model2 loss : 0.021957
[02:03:30.573] iteration 24681 : model1 loss : 0.016136 model2 loss : 0.017244
[02:03:31.235] iteration 24682 : model1 loss : 0.015097 model2 loss : 0.016172
[02:03:31.883] iteration 24683 : model1 loss : 0.026310 model2 loss : 0.024513
[02:03:32.565] iteration 24684 : model1 loss : 0.013915 model2 loss : 0.014035
[02:03:33.213] iteration 24685 : model1 loss : 0.015969 model2 loss : 0.015507
[02:03:33.865] iteration 24686 : model1 loss : 0.018050 model2 loss : 0.018266
[02:03:34.519] iteration 24687 : model1 loss : 0.026588 model2 loss : 0.024941
[02:03:35.174] iteration 24688 : model1 loss : 0.015185 model2 loss : 0.019237
[02:03:35.833] iteration 24689 : model1 loss : 0.021206 model2 loss : 0.020345
[02:03:36.500] iteration 24690 : model1 loss : 0.015801 model2 loss : 0.018522
[02:03:37.163] iteration 24691 : model1 loss : 0.021493 model2 loss : 0.022825
[02:03:37.816] iteration 24692 : model1 loss : 0.035492 model2 loss : 0.033476
[02:03:38.478] iteration 24693 : model1 loss : 0.016547 model2 loss : 0.018094
[02:03:39.138] iteration 24694 : model1 loss : 0.019571 model2 loss : 0.020283
[02:03:39.801] iteration 24695 : model1 loss : 0.018434 model2 loss : 0.018120
[02:03:40.461] iteration 24696 : model1 loss : 0.021206 model2 loss : 0.022179
[02:03:41.123] iteration 24697 : model1 loss : 0.017921 model2 loss : 0.017777
[02:03:41.785] iteration 24698 : model1 loss : 0.020162 model2 loss : 0.019194
[02:03:42.453] iteration 24699 : model1 loss : 0.026768 model2 loss : 0.028099
[02:03:43.116] iteration 24700 : model1 loss : 0.021876 model2 loss : 0.021942
[02:03:43.828] iteration 24701 : model1 loss : 0.024624 model2 loss : 0.024725
[02:03:44.479] iteration 24702 : model1 loss : 0.020557 model2 loss : 0.019938
[02:03:45.142] iteration 24703 : model1 loss : 0.025342 model2 loss : 0.020719
[02:03:45.805] iteration 24704 : model1 loss : 0.024740 model2 loss : 0.026015
[02:03:46.477] iteration 24705 : model1 loss : 0.015779 model2 loss : 0.016745
[02:03:47.145] iteration 24706 : model1 loss : 0.023465 model2 loss : 0.024991
[02:03:47.803] iteration 24707 : model1 loss : 0.017884 model2 loss : 0.017368
[02:03:48.455] iteration 24708 : model1 loss : 0.021559 model2 loss : 0.020247
[02:03:49.120] iteration 24709 : model1 loss : 0.028755 model2 loss : 0.028603
[02:03:49.787] iteration 24710 : model1 loss : 0.018917 model2 loss : 0.018010
[02:03:50.451] iteration 24711 : model1 loss : 0.023722 model2 loss : 0.021704
[02:03:51.108] iteration 24712 : model1 loss : 0.016916 model2 loss : 0.019254
[02:03:51.771] iteration 24713 : model1 loss : 0.151806 model2 loss : 0.145933
[02:03:52.435] iteration 24714 : model1 loss : 0.022856 model2 loss : 0.023447
[02:03:53.088] iteration 24715 : model1 loss : 0.023184 model2 loss : 0.022594
[02:03:53.738] iteration 24716 : model1 loss : 0.015906 model2 loss : 0.015407
[02:03:54.395] iteration 24717 : model1 loss : 0.012830 model2 loss : 0.013887
[02:03:55.071] iteration 24718 : model1 loss : 0.023969 model2 loss : 0.023104
[02:03:55.723] iteration 24719 : model1 loss : 0.015423 model2 loss : 0.015275
[02:03:56.374] iteration 24720 : model1 loss : 0.021657 model2 loss : 0.020920
[02:03:57.051] iteration 24721 : model1 loss : 0.025478 model2 loss : 0.026757
[02:03:57.711] iteration 24722 : model1 loss : 0.018256 model2 loss : 0.018507
[02:03:58.373] iteration 24723 : model1 loss : 0.018946 model2 loss : 0.019503
[02:03:59.040] iteration 24724 : model1 loss : 0.021717 model2 loss : 0.021703
[02:03:59.700] iteration 24725 : model1 loss : 0.019166 model2 loss : 0.021864
[02:04:00.357] iteration 24726 : model1 loss : 0.018154 model2 loss : 0.018485
[02:04:01.014] iteration 24727 : model1 loss : 0.020477 model2 loss : 0.022801
[02:04:01.676] iteration 24728 : model1 loss : 0.025480 model2 loss : 0.042892
[02:04:02.322] iteration 24729 : model1 loss : 0.017751 model2 loss : 0.018789
[02:04:02.991] iteration 24730 : model1 loss : 0.020590 model2 loss : 0.019138
[02:04:03.661] iteration 24731 : model1 loss : 0.015277 model2 loss : 0.015642
[02:04:04.327] iteration 24732 : model1 loss : 0.016594 model2 loss : 0.018131
[02:04:04.981] iteration 24733 : model1 loss : 0.025056 model2 loss : 0.023179
[02:04:05.645] iteration 24734 : model1 loss : 0.019400 model2 loss : 0.019085
[02:04:06.303] iteration 24735 : model1 loss : 0.017161 model2 loss : 0.018281
[02:04:06.967] iteration 24736 : model1 loss : 0.016482 model2 loss : 0.021910
[02:04:07.621] iteration 24737 : model1 loss : 0.017351 model2 loss : 0.017843
[02:04:08.282] iteration 24738 : model1 loss : 0.018366 model2 loss : 0.019249
[02:04:08.946] iteration 24739 : model1 loss : 0.027420 model2 loss : 0.027403
[02:04:09.599] iteration 24740 : model1 loss : 0.020321 model2 loss : 0.017770
[02:04:10.259] iteration 24741 : model1 loss : 0.017353 model2 loss : 0.016189
[02:04:10.913] iteration 24742 : model1 loss : 0.020690 model2 loss : 0.021827
[02:04:11.571] iteration 24743 : model1 loss : 0.019575 model2 loss : 0.020054
[02:04:12.224] iteration 24744 : model1 loss : 0.022910 model2 loss : 0.029807
[02:04:12.895] iteration 24745 : model1 loss : 0.013416 model2 loss : 0.013972
[02:04:13.552] iteration 24746 : model1 loss : 0.018368 model2 loss : 0.019502
[02:04:14.218] iteration 24747 : model1 loss : 0.018324 model2 loss : 0.020564
[02:04:14.881] iteration 24748 : model1 loss : 0.029673 model2 loss : 0.029351
[02:04:15.544] iteration 24749 : model1 loss : 0.024697 model2 loss : 0.021885
[02:04:16.205] iteration 24750 : model1 loss : 0.018752 model2 loss : 0.019853
[02:04:16.919] iteration 24751 : model1 loss : 0.015494 model2 loss : 0.015168
[02:04:17.583] iteration 24752 : model1 loss : 0.024001 model2 loss : 0.024723
[02:04:18.244] iteration 24753 : model1 loss : 0.019341 model2 loss : 0.021184
[02:04:18.921] iteration 24754 : model1 loss : 0.017169 model2 loss : 0.020589
[02:04:19.580] iteration 24755 : model1 loss : 0.027827 model2 loss : 0.023537
[02:04:20.242] iteration 24756 : model1 loss : 0.022162 model2 loss : 0.021276
[02:04:20.913] iteration 24757 : model1 loss : 0.020316 model2 loss : 0.018733
[02:04:21.577] iteration 24758 : model1 loss : 0.030440 model2 loss : 0.027036
[02:04:22.238] iteration 24759 : model1 loss : 0.017724 model2 loss : 0.019817
[02:04:22.895] iteration 24760 : model1 loss : 0.021364 model2 loss : 0.023166
[02:04:23.554] iteration 24761 : model1 loss : 0.026661 model2 loss : 0.024595
[02:04:24.214] iteration 24762 : model1 loss : 0.019102 model2 loss : 0.018124
[02:04:24.879] iteration 24763 : model1 loss : 0.021355 model2 loss : 0.022306
[02:04:25.561] iteration 24764 : model1 loss : 0.020803 model2 loss : 0.022158
[02:04:26.218] iteration 24765 : model1 loss : 0.018491 model2 loss : 0.018691
[02:04:26.875] iteration 24766 : model1 loss : 0.015156 model2 loss : 0.016156
[02:04:27.533] iteration 24767 : model1 loss : 0.023780 model2 loss : 0.025056
[02:04:28.186] iteration 24768 : model1 loss : 0.017194 model2 loss : 0.017287
[02:04:28.852] iteration 24769 : model1 loss : 0.024089 model2 loss : 0.022786
[02:04:29.507] iteration 24770 : model1 loss : 0.020920 model2 loss : 0.021538
[02:04:30.168] iteration 24771 : model1 loss : 0.017814 model2 loss : 0.019943
[02:04:30.846] iteration 24772 : model1 loss : 0.018270 model2 loss : 0.019511
[02:04:31.506] iteration 24773 : model1 loss : 0.018962 model2 loss : 0.020208
[02:04:32.174] iteration 24774 : model1 loss : 0.020133 model2 loss : 0.025700
[02:04:32.842] iteration 24775 : model1 loss : 0.017274 model2 loss : 0.018428
[02:04:33.492] iteration 24776 : model1 loss : 0.019334 model2 loss : 0.023669
[02:04:34.148] iteration 24777 : model1 loss : 0.015803 model2 loss : 0.017364
[02:04:34.819] iteration 24778 : model1 loss : 0.017670 model2 loss : 0.021043
[02:04:35.475] iteration 24779 : model1 loss : 0.017391 model2 loss : 0.018131
[02:04:36.124] iteration 24780 : model1 loss : 0.015834 model2 loss : 0.016574
[02:04:36.782] iteration 24781 : model1 loss : 0.019427 model2 loss : 0.019953
[02:04:37.436] iteration 24782 : model1 loss : 0.022775 model2 loss : 0.022718
[02:04:38.088] iteration 24783 : model1 loss : 0.028344 model2 loss : 0.028260
[02:04:38.754] iteration 24784 : model1 loss : 0.017048 model2 loss : 0.017546
[02:04:39.426] iteration 24785 : model1 loss : 0.017527 model2 loss : 0.020484
[02:04:40.084] iteration 24786 : model1 loss : 0.016817 model2 loss : 0.018522
[02:04:40.766] iteration 24787 : model1 loss : 0.017118 model2 loss : 0.016653
[02:04:41.446] iteration 24788 : model1 loss : 0.036773 model2 loss : 0.041605
[02:04:42.111] iteration 24789 : model1 loss : 0.017947 model2 loss : 0.017286
[02:04:42.775] iteration 24790 : model1 loss : 0.019886 model2 loss : 0.019505
[02:04:43.430] iteration 24791 : model1 loss : 0.019696 model2 loss : 0.018189
[02:04:44.083] iteration 24792 : model1 loss : 0.023446 model2 loss : 0.022475
[02:04:44.728] iteration 24793 : model1 loss : 0.020219 model2 loss : 0.020478
[02:04:45.400] iteration 24794 : model1 loss : 0.017752 model2 loss : 0.016423
[02:04:46.050] iteration 24795 : model1 loss : 0.020136 model2 loss : 0.020554
[02:04:46.715] iteration 24796 : model1 loss : 0.021763 model2 loss : 0.021405
[02:04:47.391] iteration 24797 : model1 loss : 0.022781 model2 loss : 0.023149
[02:04:48.050] iteration 24798 : model1 loss : 0.015892 model2 loss : 0.019131
[02:04:48.701] iteration 24799 : model1 loss : 0.019086 model2 loss : 0.019532
[02:04:49.355] iteration 24800 : model1 loss : 0.025757 model2 loss : 0.026897
[02:05:06.982] iteration 24800 : model1_mean_dice : 0.877847 model1_mean_hd95 : 7.554266
[02:05:24.716] iteration 24800 : model2_mean_dice : 0.882163 model2_mean_hd95 : 4.274504
[02:05:25.385] iteration 24801 : model1 loss : 0.018887 model2 loss : 0.017158
[02:05:26.047] iteration 24802 : model1 loss : 0.016854 model2 loss : 0.018496
[02:05:26.702] iteration 24803 : model1 loss : 0.026034 model2 loss : 0.024308
[02:05:27.359] iteration 24804 : model1 loss : 0.021539 model2 loss : 0.021504
[02:05:28.017] iteration 24805 : model1 loss : 0.019683 model2 loss : 0.020586
[02:05:28.677] iteration 24806 : model1 loss : 0.022926 model2 loss : 0.021336
[02:05:29.330] iteration 24807 : model1 loss : 0.021480 model2 loss : 0.023028
[02:05:29.983] iteration 24808 : model1 loss : 0.026893 model2 loss : 0.025683
[02:05:30.646] iteration 24809 : model1 loss : 0.020827 model2 loss : 0.020729
[02:05:31.300] iteration 24810 : model1 loss : 0.022082 model2 loss : 0.022284
[02:05:31.954] iteration 24811 : model1 loss : 0.019904 model2 loss : 0.018021
[02:05:32.610] iteration 24812 : model1 loss : 0.020406 model2 loss : 0.019495
[02:05:33.256] iteration 24813 : model1 loss : 0.017976 model2 loss : 0.019243
[02:05:33.909] iteration 24814 : model1 loss : 0.020249 model2 loss : 0.020229
[02:05:34.561] iteration 24815 : model1 loss : 0.019923 model2 loss : 0.020678
[02:05:35.214] iteration 24816 : model1 loss : 0.016629 model2 loss : 0.017799
[02:05:35.863] iteration 24817 : model1 loss : 0.016039 model2 loss : 0.015414
[02:05:36.521] iteration 24818 : model1 loss : 0.014696 model2 loss : 0.017028
[02:05:37.174] iteration 24819 : model1 loss : 0.030286 model2 loss : 0.025738
[02:05:37.820] iteration 24820 : model1 loss : 0.024396 model2 loss : 0.023238
[02:05:38.481] iteration 24821 : model1 loss : 0.020320 model2 loss : 0.021215
[02:05:39.136] iteration 24822 : model1 loss : 0.020871 model2 loss : 0.019782
[02:05:39.787] iteration 24823 : model1 loss : 0.021593 model2 loss : 0.022248
[02:05:40.443] iteration 24824 : model1 loss : 0.019253 model2 loss : 0.018695
[02:05:41.088] iteration 24825 : model1 loss : 0.016736 model2 loss : 0.017453
[02:05:41.745] iteration 24826 : model1 loss : 0.056023 model2 loss : 0.049616
[02:05:42.396] iteration 24827 : model1 loss : 0.025013 model2 loss : 0.024124
[02:05:43.043] iteration 24828 : model1 loss : 0.019027 model2 loss : 0.018404
[02:05:43.706] iteration 24829 : model1 loss : 0.021167 model2 loss : 0.021417
[02:05:44.368] iteration 24830 : model1 loss : 0.014074 model2 loss : 0.013981
[02:05:45.028] iteration 24831 : model1 loss : 0.021269 model2 loss : 0.021528
[02:05:45.679] iteration 24832 : model1 loss : 0.026669 model2 loss : 0.025687
[02:05:46.350] iteration 24833 : model1 loss : 0.032283 model2 loss : 0.038271
[02:05:47.011] iteration 24834 : model1 loss : 0.026600 model2 loss : 0.024760
[02:05:47.685] iteration 24835 : model1 loss : 0.019708 model2 loss : 0.020475
[02:05:48.343] iteration 24836 : model1 loss : 0.027375 model2 loss : 0.030624
[02:05:49.006] iteration 24837 : model1 loss : 0.026366 model2 loss : 0.027446
[02:05:49.659] iteration 24838 : model1 loss : 0.016339 model2 loss : 0.017829
[02:05:50.320] iteration 24839 : model1 loss : 0.017583 model2 loss : 0.019494
[02:05:50.986] iteration 24840 : model1 loss : 0.021668 model2 loss : 0.019662
[02:05:51.644] iteration 24841 : model1 loss : 0.018987 model2 loss : 0.016701
[02:05:52.289] iteration 24842 : model1 loss : 0.017268 model2 loss : 0.018805
[02:05:52.953] iteration 24843 : model1 loss : 0.020750 model2 loss : 0.018628
[02:05:53.626] iteration 24844 : model1 loss : 0.019426 model2 loss : 0.018923
[02:05:54.292] iteration 24845 : model1 loss : 0.023094 model2 loss : 0.021242
[02:05:54.943] iteration 24846 : model1 loss : 0.016589 model2 loss : 0.016294
[02:05:55.596] iteration 24847 : model1 loss : 0.018183 model2 loss : 0.019534
[02:05:56.247] iteration 24848 : model1 loss : 0.020474 model2 loss : 0.021322
[02:05:56.916] iteration 24849 : model1 loss : 0.021782 model2 loss : 0.021477
[02:05:57.575] iteration 24850 : model1 loss : 0.023822 model2 loss : 0.023623
[02:05:58.270] iteration 24851 : model1 loss : 0.015520 model2 loss : 0.017949
[02:05:58.925] iteration 24852 : model1 loss : 0.019404 model2 loss : 0.020586
[02:05:59.576] iteration 24853 : model1 loss : 0.024844 model2 loss : 0.025737
[02:06:00.224] iteration 24854 : model1 loss : 0.020724 model2 loss : 0.022125
[02:06:00.908] iteration 24855 : model1 loss : 0.019916 model2 loss : 0.028569
[02:06:01.582] iteration 24856 : model1 loss : 0.018625 model2 loss : 0.022807
[02:06:02.234] iteration 24857 : model1 loss : 0.018601 model2 loss : 0.017734
[02:06:02.888] iteration 24858 : model1 loss : 0.020771 model2 loss : 0.018306
[02:06:03.550] iteration 24859 : model1 loss : 0.015485 model2 loss : 0.015972
[02:06:04.205] iteration 24860 : model1 loss : 0.028626 model2 loss : 0.024821
[02:06:04.863] iteration 24861 : model1 loss : 0.020558 model2 loss : 0.018835
[02:06:05.527] iteration 24862 : model1 loss : 0.027993 model2 loss : 0.023618
[02:06:06.181] iteration 24863 : model1 loss : 0.019214 model2 loss : 0.019148
[02:06:06.836] iteration 24864 : model1 loss : 0.028756 model2 loss : 0.027415
[02:06:07.486] iteration 24865 : model1 loss : 0.018762 model2 loss : 0.018903
[02:06:08.138] iteration 24866 : model1 loss : 0.014014 model2 loss : 0.015407
[02:06:08.800] iteration 24867 : model1 loss : 0.017601 model2 loss : 0.016626
[02:06:09.448] iteration 24868 : model1 loss : 0.022674 model2 loss : 0.024315
[02:06:10.100] iteration 24869 : model1 loss : 0.024228 model2 loss : 0.020174
[02:06:10.757] iteration 24870 : model1 loss : 0.020276 model2 loss : 0.019983
[02:06:11.427] iteration 24871 : model1 loss : 0.018342 model2 loss : 0.018748
[02:06:12.071] iteration 24872 : model1 loss : 0.022993 model2 loss : 0.027142
[02:06:12.736] iteration 24873 : model1 loss : 0.020541 model2 loss : 0.020163
[02:06:13.403] iteration 24874 : model1 loss : 0.017048 model2 loss : 0.015826
[02:06:14.051] iteration 24875 : model1 loss : 0.019532 model2 loss : 0.019111
[02:06:14.703] iteration 24876 : model1 loss : 0.023636 model2 loss : 0.023412
[02:06:15.357] iteration 24877 : model1 loss : 0.017561 model2 loss : 0.018157
[02:06:16.023] iteration 24878 : model1 loss : 0.016371 model2 loss : 0.018076
[02:06:16.684] iteration 24879 : model1 loss : 0.020308 model2 loss : 0.020948
[02:06:17.354] iteration 24880 : model1 loss : 0.016404 model2 loss : 0.016889
[02:06:18.019] iteration 24881 : model1 loss : 0.024767 model2 loss : 0.024256
[02:06:18.675] iteration 24882 : model1 loss : 0.019497 model2 loss : 0.020065
[02:06:19.337] iteration 24883 : model1 loss : 0.021969 model2 loss : 0.019281
[02:06:19.991] iteration 24884 : model1 loss : 0.017253 model2 loss : 0.015971
[02:06:20.636] iteration 24885 : model1 loss : 0.019346 model2 loss : 0.018486
[02:06:21.318] iteration 24886 : model1 loss : 0.021046 model2 loss : 0.021168
[02:06:21.962] iteration 24887 : model1 loss : 0.018067 model2 loss : 0.016889
[02:06:22.622] iteration 24888 : model1 loss : 0.026930 model2 loss : 0.026894
[02:06:23.325] iteration 24889 : model1 loss : 0.018591 model2 loss : 0.019512
[02:06:24.023] iteration 24890 : model1 loss : 0.015115 model2 loss : 0.014728
[02:06:24.899] iteration 24891 : model1 loss : 0.019329 model2 loss : 0.021908
[02:06:25.615] iteration 24892 : model1 loss : 0.014440 model2 loss : 0.013181
[02:06:26.269] iteration 24893 : model1 loss : 0.024038 model2 loss : 0.023525
[02:06:26.916] iteration 24894 : model1 loss : 0.018891 model2 loss : 0.019783
[02:06:27.580] iteration 24895 : model1 loss : 0.023341 model2 loss : 0.026389
[02:06:28.225] iteration 24896 : model1 loss : 0.017334 model2 loss : 0.016975
[02:06:28.894] iteration 24897 : model1 loss : 0.024166 model2 loss : 0.023379
[02:06:29.552] iteration 24898 : model1 loss : 0.020862 model2 loss : 0.022230
[02:06:30.201] iteration 24899 : model1 loss : 0.022714 model2 loss : 0.020840
[02:06:30.856] iteration 24900 : model1 loss : 0.019023 model2 loss : 0.018731
[02:06:31.566] iteration 24901 : model1 loss : 0.018463 model2 loss : 0.017942
[02:06:32.218] iteration 24902 : model1 loss : 0.017792 model2 loss : 0.019052
[02:06:32.874] iteration 24903 : model1 loss : 0.021560 model2 loss : 0.022484
[02:06:33.532] iteration 24904 : model1 loss : 0.016132 model2 loss : 0.017240
[02:06:34.186] iteration 24905 : model1 loss : 0.016677 model2 loss : 0.018960
[02:06:34.844] iteration 24906 : model1 loss : 0.141160 model2 loss : 0.138793
[02:06:35.500] iteration 24907 : model1 loss : 0.027118 model2 loss : 0.024722
[02:06:36.161] iteration 24908 : model1 loss : 0.028673 model2 loss : 0.022100
[02:06:36.817] iteration 24909 : model1 loss : 0.018341 model2 loss : 0.017812
[02:06:37.479] iteration 24910 : model1 loss : 0.017416 model2 loss : 0.018504
[02:06:38.127] iteration 24911 : model1 loss : 0.021723 model2 loss : 0.022310
[02:06:38.789] iteration 24912 : model1 loss : 0.022731 model2 loss : 0.022433
[02:06:39.487] iteration 24913 : model1 loss : 0.017346 model2 loss : 0.018011
[02:06:40.144] iteration 24914 : model1 loss : 0.017251 model2 loss : 0.016505
[02:06:40.811] iteration 24915 : model1 loss : 0.017352 model2 loss : 0.018704
[02:06:41.485] iteration 24916 : model1 loss : 0.017512 model2 loss : 0.018240
[02:06:42.138] iteration 24917 : model1 loss : 0.022529 model2 loss : 0.021162
[02:06:42.801] iteration 24918 : model1 loss : 0.024124 model2 loss : 0.023463
[02:06:43.458] iteration 24919 : model1 loss : 0.022635 model2 loss : 0.023146
[02:06:44.117] iteration 24920 : model1 loss : 0.020569 model2 loss : 0.018648
[02:06:44.774] iteration 24921 : model1 loss : 0.019968 model2 loss : 0.019762
[02:06:45.441] iteration 24922 : model1 loss : 0.018814 model2 loss : 0.017708
[02:06:46.088] iteration 24923 : model1 loss : 0.026635 model2 loss : 0.024859
[02:06:46.750] iteration 24924 : model1 loss : 0.015858 model2 loss : 0.015676
[02:06:47.413] iteration 24925 : model1 loss : 0.018373 model2 loss : 0.020294
[02:06:48.098] iteration 24926 : model1 loss : 0.018900 model2 loss : 0.018960
[02:06:48.760] iteration 24927 : model1 loss : 0.020890 model2 loss : 0.020461
[02:06:49.426] iteration 24928 : model1 loss : 0.027626 model2 loss : 0.023470
[02:06:50.095] iteration 24929 : model1 loss : 0.025316 model2 loss : 0.026384
[02:06:50.755] iteration 24930 : model1 loss : 0.014191 model2 loss : 0.015617
[02:06:51.421] iteration 24931 : model1 loss : 0.020394 model2 loss : 0.021796
[02:06:52.069] iteration 24932 : model1 loss : 0.022284 model2 loss : 0.024141
[02:06:52.729] iteration 24933 : model1 loss : 0.017718 model2 loss : 0.021047
[02:06:53.394] iteration 24934 : model1 loss : 0.021773 model2 loss : 0.020607
[02:06:54.068] iteration 24935 : model1 loss : 0.020837 model2 loss : 0.022511
[02:06:54.723] iteration 24936 : model1 loss : 0.025643 model2 loss : 0.024478
[02:06:55.381] iteration 24937 : model1 loss : 0.018229 model2 loss : 0.017619
[02:06:56.043] iteration 24938 : model1 loss : 0.017431 model2 loss : 0.017209
[02:06:56.709] iteration 24939 : model1 loss : 0.018349 model2 loss : 0.018928
[02:06:57.381] iteration 24940 : model1 loss : 0.022157 model2 loss : 0.022401
[02:06:58.039] iteration 24941 : model1 loss : 0.028841 model2 loss : 0.026509
[02:06:58.685] iteration 24942 : model1 loss : 0.017440 model2 loss : 0.016261
[02:06:59.343] iteration 24943 : model1 loss : 0.018197 model2 loss : 0.016437
[02:07:00.005] iteration 24944 : model1 loss : 0.034787 model2 loss : 0.032939
[02:07:00.678] iteration 24945 : model1 loss : 0.016234 model2 loss : 0.015963
[02:07:01.341] iteration 24946 : model1 loss : 0.017496 model2 loss : 0.016635
[02:07:01.990] iteration 24947 : model1 loss : 0.014906 model2 loss : 0.015954
[02:07:02.642] iteration 24948 : model1 loss : 0.030521 model2 loss : 0.027228
[02:07:03.305] iteration 24949 : model1 loss : 0.018625 model2 loss : 0.020240
[02:07:03.965] iteration 24950 : model1 loss : 0.023421 model2 loss : 0.025398
[02:07:04.667] iteration 24951 : model1 loss : 0.029810 model2 loss : 0.031683
[02:07:05.318] iteration 24952 : model1 loss : 0.020539 model2 loss : 0.022275
[02:07:05.970] iteration 24953 : model1 loss : 0.020882 model2 loss : 0.021500
[02:07:06.634] iteration 24954 : model1 loss : 0.021154 model2 loss : 0.022271
[02:07:07.296] iteration 24955 : model1 loss : 0.018241 model2 loss : 0.020237
[02:07:07.947] iteration 24956 : model1 loss : 0.020253 model2 loss : 0.019653
[02:07:08.633] iteration 24957 : model1 loss : 0.017366 model2 loss : 0.017144
[02:07:09.326] iteration 24958 : model1 loss : 0.022647 model2 loss : 0.020948
[02:07:09.998] iteration 24959 : model1 loss : 0.015492 model2 loss : 0.015395
[02:07:10.664] iteration 24960 : model1 loss : 0.018823 model2 loss : 0.018985
[02:07:11.328] iteration 24961 : model1 loss : 0.022516 model2 loss : 0.020780
[02:07:11.980] iteration 24962 : model1 loss : 0.022751 model2 loss : 0.022198
[02:07:12.647] iteration 24963 : model1 loss : 0.020275 model2 loss : 0.022085
[02:07:13.303] iteration 24964 : model1 loss : 0.018004 model2 loss : 0.018027
[02:07:13.976] iteration 24965 : model1 loss : 0.016339 model2 loss : 0.016579
[02:07:14.630] iteration 24966 : model1 loss : 0.017024 model2 loss : 0.018484
[02:07:15.287] iteration 24967 : model1 loss : 0.018783 model2 loss : 0.015997
[02:07:15.953] iteration 24968 : model1 loss : 0.017871 model2 loss : 0.017327
[02:07:16.612] iteration 24969 : model1 loss : 0.022707 model2 loss : 0.024965
[02:07:17.270] iteration 24970 : model1 loss : 0.017753 model2 loss : 0.019793
[02:07:17.928] iteration 24971 : model1 loss : 0.140295 model2 loss : 0.138560
[02:07:18.592] iteration 24972 : model1 loss : 0.016893 model2 loss : 0.015627
[02:07:19.255] iteration 24973 : model1 loss : 0.023635 model2 loss : 0.024708
[02:07:19.910] iteration 24974 : model1 loss : 0.023359 model2 loss : 0.022493
[02:07:20.570] iteration 24975 : model1 loss : 0.022329 model2 loss : 0.023607
[02:07:21.227] iteration 24976 : model1 loss : 0.034151 model2 loss : 0.047067
[02:07:21.882] iteration 24977 : model1 loss : 0.017575 model2 loss : 0.017852
[02:07:22.544] iteration 24978 : model1 loss : 0.020191 model2 loss : 0.019690
[02:07:23.207] iteration 24979 : model1 loss : 0.020643 model2 loss : 0.019817
[02:07:23.863] iteration 24980 : model1 loss : 0.020543 model2 loss : 0.017488
[02:07:24.534] iteration 24981 : model1 loss : 0.024247 model2 loss : 0.025479
[02:07:25.185] iteration 24982 : model1 loss : 0.019682 model2 loss : 0.020922
[02:07:25.840] iteration 24983 : model1 loss : 0.019631 model2 loss : 0.018966
[02:07:26.501] iteration 24984 : model1 loss : 0.019407 model2 loss : 0.019259
[02:07:27.151] iteration 24985 : model1 loss : 0.018095 model2 loss : 0.019137
[02:07:27.812] iteration 24986 : model1 loss : 0.016170 model2 loss : 0.016801
[02:07:28.466] iteration 24987 : model1 loss : 0.020975 model2 loss : 0.020354
[02:07:29.124] iteration 24988 : model1 loss : 0.023247 model2 loss : 0.020572
[02:07:29.781] iteration 24989 : model1 loss : 0.025718 model2 loss : 0.025128
[02:07:30.449] iteration 24990 : model1 loss : 0.016922 model2 loss : 0.018105
[02:07:31.113] iteration 24991 : model1 loss : 0.021043 model2 loss : 0.019646
[02:07:31.773] iteration 24992 : model1 loss : 0.142990 model2 loss : 0.143191
[02:07:32.448] iteration 24993 : model1 loss : 0.018445 model2 loss : 0.019522
[02:07:33.103] iteration 24994 : model1 loss : 0.032068 model2 loss : 0.031488
[02:07:33.763] iteration 24995 : model1 loss : 0.020017 model2 loss : 0.020051
[02:07:34.424] iteration 24996 : model1 loss : 0.019406 model2 loss : 0.019042
[02:07:35.086] iteration 24997 : model1 loss : 0.018879 model2 loss : 0.017813
[02:07:35.745] iteration 24998 : model1 loss : 0.029475 model2 loss : 0.024313
[02:07:36.398] iteration 24999 : model1 loss : 0.023848 model2 loss : 0.024109
[02:07:37.060] iteration 25000 : model1 loss : 0.015114 model2 loss : 0.015085
[02:07:54.795] iteration 25000 : model1_mean_dice : 0.878630 model1_mean_hd95 : 6.289596
[02:08:12.422] iteration 25000 : model2_mean_dice : 0.877178 model2_mean_hd95 : 4.192070
[02:08:13.089] iteration 25001 : model1 loss : 0.020585 model2 loss : 0.020486
[02:08:13.728] iteration 25002 : model1 loss : 0.021296 model2 loss : 0.021050
[02:08:14.381] iteration 25003 : model1 loss : 0.018614 model2 loss : 0.019432
[02:08:15.038] iteration 25004 : model1 loss : 0.023833 model2 loss : 0.023868
[02:08:15.697] iteration 25005 : model1 loss : 0.019863 model2 loss : 0.017090
[02:08:16.350] iteration 25006 : model1 loss : 0.016871 model2 loss : 0.017431
[02:08:17.004] iteration 25007 : model1 loss : 0.024197 model2 loss : 0.022124
[02:08:17.649] iteration 25008 : model1 loss : 0.016243 model2 loss : 0.015886
[02:08:18.297] iteration 25009 : model1 loss : 0.019430 model2 loss : 0.019407
[02:08:18.955] iteration 25010 : model1 loss : 0.019044 model2 loss : 0.018444
[02:08:19.596] iteration 25011 : model1 loss : 0.022517 model2 loss : 0.022920
[02:08:20.259] iteration 25012 : model1 loss : 0.031551 model2 loss : 0.033237
[02:08:20.913] iteration 25013 : model1 loss : 0.021186 model2 loss : 0.020931
[02:08:21.569] iteration 25014 : model1 loss : 0.019650 model2 loss : 0.019102
[02:08:22.220] iteration 25015 : model1 loss : 0.018603 model2 loss : 0.016820
[02:08:22.862] iteration 25016 : model1 loss : 0.019376 model2 loss : 0.018883
[02:08:23.527] iteration 25017 : model1 loss : 0.023522 model2 loss : 0.021675
[02:08:24.176] iteration 25018 : model1 loss : 0.050434 model2 loss : 0.037921
[02:08:24.830] iteration 25019 : model1 loss : 0.019255 model2 loss : 0.019240
[02:08:25.483] iteration 25020 : model1 loss : 0.022275 model2 loss : 0.021033
[02:08:26.133] iteration 25021 : model1 loss : 0.022839 model2 loss : 0.019758
[02:08:26.794] iteration 25022 : model1 loss : 0.017984 model2 loss : 0.018284
[02:08:27.447] iteration 25023 : model1 loss : 0.021325 model2 loss : 0.020348
[02:08:28.100] iteration 25024 : model1 loss : 0.021965 model2 loss : 0.021742
[02:08:28.760] iteration 25025 : model1 loss : 0.015283 model2 loss : 0.013748
[02:08:29.422] iteration 25026 : model1 loss : 0.020505 model2 loss : 0.021489
[02:08:30.068] iteration 25027 : model1 loss : 0.018884 model2 loss : 0.017498
[02:08:30.728] iteration 25028 : model1 loss : 0.021661 model2 loss : 0.022176
[02:08:31.390] iteration 25029 : model1 loss : 0.020037 model2 loss : 0.020214
[02:08:32.042] iteration 25030 : model1 loss : 0.026479 model2 loss : 0.027814
[02:08:32.697] iteration 25031 : model1 loss : 0.022519 model2 loss : 0.023091
[02:08:33.348] iteration 25032 : model1 loss : 0.018681 model2 loss : 0.018459
[02:08:33.997] iteration 25033 : model1 loss : 0.034447 model2 loss : 0.041585
[02:08:34.652] iteration 25034 : model1 loss : 0.020125 model2 loss : 0.018258
[02:08:35.302] iteration 25035 : model1 loss : 0.020653 model2 loss : 0.018296
[02:08:35.959] iteration 25036 : model1 loss : 0.017663 model2 loss : 0.016814
[02:08:36.617] iteration 25037 : model1 loss : 0.016692 model2 loss : 0.018379
[02:08:37.269] iteration 25038 : model1 loss : 0.022241 model2 loss : 0.020787
[02:08:37.944] iteration 25039 : model1 loss : 0.141249 model2 loss : 0.140030
[02:08:38.603] iteration 25040 : model1 loss : 0.044568 model2 loss : 0.038511
[02:08:39.264] iteration 25041 : model1 loss : 0.016953 model2 loss : 0.017111
[02:08:39.924] iteration 25042 : model1 loss : 0.027408 model2 loss : 0.025282
[02:08:40.573] iteration 25043 : model1 loss : 0.017164 model2 loss : 0.021467
[02:08:41.240] iteration 25044 : model1 loss : 0.020895 model2 loss : 0.021936
[02:08:41.897] iteration 25045 : model1 loss : 0.017710 model2 loss : 0.017715
[02:08:42.561] iteration 25046 : model1 loss : 0.017825 model2 loss : 0.018713
[02:08:43.211] iteration 25047 : model1 loss : 0.021761 model2 loss : 0.020010
[02:08:43.871] iteration 25048 : model1 loss : 0.019300 model2 loss : 0.019945
[02:08:44.532] iteration 25049 : model1 loss : 0.020902 model2 loss : 0.021187
[02:08:45.187] iteration 25050 : model1 loss : 0.023891 model2 loss : 0.022616
[02:08:45.872] iteration 25051 : model1 loss : 0.012524 model2 loss : 0.015411
[02:08:46.534] iteration 25052 : model1 loss : 0.018093 model2 loss : 0.017677
[02:08:47.184] iteration 25053 : model1 loss : 0.016413 model2 loss : 0.014955
[02:08:47.840] iteration 25054 : model1 loss : 0.018955 model2 loss : 0.018395
[02:08:48.504] iteration 25055 : model1 loss : 0.018754 model2 loss : 0.021543
[02:08:49.170] iteration 25056 : model1 loss : 0.022708 model2 loss : 0.020973
[02:08:49.828] iteration 25057 : model1 loss : 0.017408 model2 loss : 0.017838
[02:08:50.481] iteration 25058 : model1 loss : 0.014296 model2 loss : 0.014839
[02:08:51.136] iteration 25059 : model1 loss : 0.022203 model2 loss : 0.022331
[02:08:51.794] iteration 25060 : model1 loss : 0.037827 model2 loss : 0.035807
[02:08:52.462] iteration 25061 : model1 loss : 0.019342 model2 loss : 0.018640
[02:08:53.121] iteration 25062 : model1 loss : 0.031957 model2 loss : 0.035154
[02:08:53.782] iteration 25063 : model1 loss : 0.019191 model2 loss : 0.018466
[02:08:54.437] iteration 25064 : model1 loss : 0.031126 model2 loss : 0.029964
[02:08:55.089] iteration 25065 : model1 loss : 0.017307 model2 loss : 0.017178
[02:08:55.742] iteration 25066 : model1 loss : 0.016285 model2 loss : 0.017642
[02:08:56.397] iteration 25067 : model1 loss : 0.040136 model2 loss : 0.044159
[02:08:57.042] iteration 25068 : model1 loss : 0.022415 model2 loss : 0.022826
[02:08:57.694] iteration 25069 : model1 loss : 0.016196 model2 loss : 0.015765
[02:08:58.339] iteration 25070 : model1 loss : 0.021745 model2 loss : 0.020720
[02:08:59.000] iteration 25071 : model1 loss : 0.014206 model2 loss : 0.016378
[02:08:59.661] iteration 25072 : model1 loss : 0.022001 model2 loss : 0.020060
[02:09:00.321] iteration 25073 : model1 loss : 0.021344 model2 loss : 0.020146
[02:09:00.981] iteration 25074 : model1 loss : 0.018668 model2 loss : 0.017988
[02:09:01.636] iteration 25075 : model1 loss : 0.019989 model2 loss : 0.018337
[02:09:02.290] iteration 25076 : model1 loss : 0.019898 model2 loss : 0.017623
[02:09:02.949] iteration 25077 : model1 loss : 0.137844 model2 loss : 0.138643
[02:09:03.610] iteration 25078 : model1 loss : 0.019493 model2 loss : 0.020591
[02:09:04.269] iteration 25079 : model1 loss : 0.021747 model2 loss : 0.020001
[02:09:04.916] iteration 25080 : model1 loss : 0.038260 model2 loss : 0.036317
[02:09:05.580] iteration 25081 : model1 loss : 0.022316 model2 loss : 0.021643
[02:09:06.231] iteration 25082 : model1 loss : 0.016941 model2 loss : 0.018203
[02:09:06.882] iteration 25083 : model1 loss : 0.027266 model2 loss : 0.026144
[02:09:07.539] iteration 25084 : model1 loss : 0.022439 model2 loss : 0.021208
[02:09:08.196] iteration 25085 : model1 loss : 0.015921 model2 loss : 0.016933
[02:09:08.849] iteration 25086 : model1 loss : 0.020087 model2 loss : 0.020379
[02:09:09.510] iteration 25087 : model1 loss : 0.018517 model2 loss : 0.019316
[02:09:10.161] iteration 25088 : model1 loss : 0.017853 model2 loss : 0.016849
[02:09:10.825] iteration 25089 : model1 loss : 0.020362 model2 loss : 0.020572
[02:09:11.486] iteration 25090 : model1 loss : 0.021686 model2 loss : 0.023140
[02:09:12.129] iteration 25091 : model1 loss : 0.014603 model2 loss : 0.016125
[02:09:12.792] iteration 25092 : model1 loss : 0.024392 model2 loss : 0.017962
[02:09:13.444] iteration 25093 : model1 loss : 0.038023 model2 loss : 0.030029
[02:09:14.109] iteration 25094 : model1 loss : 0.025441 model2 loss : 0.024198
[02:09:14.784] iteration 25095 : model1 loss : 0.018829 model2 loss : 0.018276
[02:09:15.447] iteration 25096 : model1 loss : 0.028238 model2 loss : 0.024644
[02:09:16.106] iteration 25097 : model1 loss : 0.019042 model2 loss : 0.018851
[02:09:16.768] iteration 25098 : model1 loss : 0.016117 model2 loss : 0.018342
[02:09:17.427] iteration 25099 : model1 loss : 0.027410 model2 loss : 0.028990
[02:09:18.091] iteration 25100 : model1 loss : 0.018481 model2 loss : 0.017903
[02:09:18.800] iteration 25101 : model1 loss : 0.018204 model2 loss : 0.018200
[02:09:19.460] iteration 25102 : model1 loss : 0.016238 model2 loss : 0.017155
[02:09:20.108] iteration 25103 : model1 loss : 0.018799 model2 loss : 0.020318
[02:09:20.783] iteration 25104 : model1 loss : 0.018131 model2 loss : 0.018647
[02:09:21.442] iteration 25105 : model1 loss : 0.144613 model2 loss : 0.144643
[02:09:22.099] iteration 25106 : model1 loss : 0.019431 model2 loss : 0.019215
[02:09:22.765] iteration 25107 : model1 loss : 0.020408 model2 loss : 0.022129
[02:09:23.426] iteration 25108 : model1 loss : 0.021599 model2 loss : 0.019655
[02:09:24.072] iteration 25109 : model1 loss : 0.018833 model2 loss : 0.019157
[02:09:24.720] iteration 25110 : model1 loss : 0.021021 model2 loss : 0.021883
[02:09:25.391] iteration 25111 : model1 loss : 0.020378 model2 loss : 0.023837
[02:09:26.046] iteration 25112 : model1 loss : 0.020257 model2 loss : 0.020469
[02:09:26.696] iteration 25113 : model1 loss : 0.015149 model2 loss : 0.015932
[02:09:27.352] iteration 25114 : model1 loss : 0.017217 model2 loss : 0.018417
[02:09:28.010] iteration 25115 : model1 loss : 0.017734 model2 loss : 0.018929
[02:09:28.670] iteration 25116 : model1 loss : 0.017501 model2 loss : 0.018011
[02:09:29.337] iteration 25117 : model1 loss : 0.018156 model2 loss : 0.018065
[02:09:30.002] iteration 25118 : model1 loss : 0.016646 model2 loss : 0.017176
[02:09:30.663] iteration 25119 : model1 loss : 0.024834 model2 loss : 0.029369
[02:09:31.329] iteration 25120 : model1 loss : 0.018383 model2 loss : 0.018669
[02:09:31.998] iteration 25121 : model1 loss : 0.016610 model2 loss : 0.017911
[02:09:32.661] iteration 25122 : model1 loss : 0.021092 model2 loss : 0.021620
[02:09:33.317] iteration 25123 : model1 loss : 0.019333 model2 loss : 0.020635
[02:09:33.974] iteration 25124 : model1 loss : 0.023243 model2 loss : 0.021552
[02:09:34.635] iteration 25125 : model1 loss : 0.014542 model2 loss : 0.014671
[02:09:35.286] iteration 25126 : model1 loss : 0.016605 model2 loss : 0.017323
[02:09:35.940] iteration 25127 : model1 loss : 0.025146 model2 loss : 0.025404
[02:09:36.602] iteration 25128 : model1 loss : 0.013443 model2 loss : 0.013472
[02:09:37.262] iteration 25129 : model1 loss : 0.020389 model2 loss : 0.020240
[02:09:37.923] iteration 25130 : model1 loss : 0.025916 model2 loss : 0.026796
[02:09:38.581] iteration 25131 : model1 loss : 0.023458 model2 loss : 0.021589
[02:09:39.254] iteration 25132 : model1 loss : 0.022383 model2 loss : 0.021409
[02:09:39.914] iteration 25133 : model1 loss : 0.029615 model2 loss : 0.022854
[02:09:40.577] iteration 25134 : model1 loss : 0.015251 model2 loss : 0.017656
[02:09:41.228] iteration 25135 : model1 loss : 0.018216 model2 loss : 0.016910
[02:09:41.901] iteration 25136 : model1 loss : 0.025023 model2 loss : 0.023585
[02:09:42.585] iteration 25137 : model1 loss : 0.016641 model2 loss : 0.016524
[02:09:43.244] iteration 25138 : model1 loss : 0.017109 model2 loss : 0.016615
[02:09:43.907] iteration 25139 : model1 loss : 0.079244 model2 loss : 0.107363
[02:09:44.574] iteration 25140 : model1 loss : 0.029780 model2 loss : 0.027001
[02:09:45.225] iteration 25141 : model1 loss : 0.028000 model2 loss : 0.026583
[02:09:45.894] iteration 25142 : model1 loss : 0.026299 model2 loss : 0.027118
[02:09:46.552] iteration 25143 : model1 loss : 0.017240 model2 loss : 0.016076
[02:09:47.212] iteration 25144 : model1 loss : 0.021832 model2 loss : 0.021576
[02:09:47.878] iteration 25145 : model1 loss : 0.019919 model2 loss : 0.020616
[02:09:48.548] iteration 25146 : model1 loss : 0.019561 model2 loss : 0.019723
[02:09:49.227] iteration 25147 : model1 loss : 0.018531 model2 loss : 0.018596
[02:09:49.885] iteration 25148 : model1 loss : 0.017758 model2 loss : 0.020108
[02:09:50.549] iteration 25149 : model1 loss : 0.021531 model2 loss : 0.022414
[02:09:51.199] iteration 25150 : model1 loss : 0.025235 model2 loss : 0.025399
[02:09:51.901] iteration 25151 : model1 loss : 0.023208 model2 loss : 0.021442
[02:09:52.580] iteration 25152 : model1 loss : 0.020182 model2 loss : 0.020516
[02:09:53.238] iteration 25153 : model1 loss : 0.019636 model2 loss : 0.020422
[02:09:53.899] iteration 25154 : model1 loss : 0.021604 model2 loss : 0.021434
[02:09:54.573] iteration 25155 : model1 loss : 0.018568 model2 loss : 0.020795
[02:09:55.224] iteration 25156 : model1 loss : 0.020142 model2 loss : 0.019959
[02:09:55.886] iteration 25157 : model1 loss : 0.026181 model2 loss : 0.034728
[02:09:56.540] iteration 25158 : model1 loss : 0.019539 model2 loss : 0.019640
[02:09:57.208] iteration 25159 : model1 loss : 0.137209 model2 loss : 0.137445
[02:09:57.883] iteration 25160 : model1 loss : 0.023338 model2 loss : 0.018305
[02:09:58.543] iteration 25161 : model1 loss : 0.021495 model2 loss : 0.021131
[02:09:59.210] iteration 25162 : model1 loss : 0.025981 model2 loss : 0.025771
[02:09:59.865] iteration 25163 : model1 loss : 0.021230 model2 loss : 0.020672
[02:10:00.541] iteration 25164 : model1 loss : 0.029208 model2 loss : 0.028957
[02:10:01.214] iteration 25165 : model1 loss : 0.022829 model2 loss : 0.024687
[02:10:01.874] iteration 25166 : model1 loss : 0.016835 model2 loss : 0.017074
[02:10:02.536] iteration 25167 : model1 loss : 0.017533 model2 loss : 0.017382
[02:10:03.188] iteration 25168 : model1 loss : 0.019642 model2 loss : 0.020447
[02:10:03.845] iteration 25169 : model1 loss : 0.024246 model2 loss : 0.022903
[02:10:04.506] iteration 25170 : model1 loss : 0.020622 model2 loss : 0.020554
[02:10:05.162] iteration 25171 : model1 loss : 0.018603 model2 loss : 0.019281
[02:10:05.826] iteration 25172 : model1 loss : 0.017734 model2 loss : 0.021264
[02:10:06.478] iteration 25173 : model1 loss : 0.139701 model2 loss : 0.141637
[02:10:07.137] iteration 25174 : model1 loss : 0.018547 model2 loss : 0.019273
[02:10:07.794] iteration 25175 : model1 loss : 0.018434 model2 loss : 0.016884
[02:10:08.452] iteration 25176 : model1 loss : 0.025126 model2 loss : 0.024763
[02:10:09.114] iteration 25177 : model1 loss : 0.032620 model2 loss : 0.032950
[02:10:09.768] iteration 25178 : model1 loss : 0.019221 model2 loss : 0.019236
[02:10:10.430] iteration 25179 : model1 loss : 0.025568 model2 loss : 0.025824
[02:10:11.099] iteration 25180 : model1 loss : 0.017470 model2 loss : 0.017180
[02:10:11.760] iteration 25181 : model1 loss : 0.016720 model2 loss : 0.017267
[02:10:12.414] iteration 25182 : model1 loss : 0.018229 model2 loss : 0.020461
[02:10:13.065] iteration 25183 : model1 loss : 0.024160 model2 loss : 0.027302
[02:10:13.724] iteration 25184 : model1 loss : 0.020618 model2 loss : 0.020682
[02:10:14.396] iteration 25185 : model1 loss : 0.020686 model2 loss : 0.021716
[02:10:15.056] iteration 25186 : model1 loss : 0.016645 model2 loss : 0.016943
[02:10:15.722] iteration 25187 : model1 loss : 0.016342 model2 loss : 0.015338
[02:10:16.382] iteration 25188 : model1 loss : 0.020721 model2 loss : 0.021322
[02:10:17.042] iteration 25189 : model1 loss : 0.024908 model2 loss : 0.024283
[02:10:17.699] iteration 25190 : model1 loss : 0.015487 model2 loss : 0.015358
[02:10:18.361] iteration 25191 : model1 loss : 0.016832 model2 loss : 0.016005
[02:10:19.013] iteration 25192 : model1 loss : 0.023514 model2 loss : 0.023356
[02:10:19.671] iteration 25193 : model1 loss : 0.018709 model2 loss : 0.018178
[02:10:20.337] iteration 25194 : model1 loss : 0.022349 model2 loss : 0.022482
[02:10:21.021] iteration 25195 : model1 loss : 0.031145 model2 loss : 0.022501
[02:10:21.686] iteration 25196 : model1 loss : 0.016169 model2 loss : 0.016512
[02:10:22.351] iteration 25197 : model1 loss : 0.020681 model2 loss : 0.021792
[02:10:23.015] iteration 25198 : model1 loss : 0.016090 model2 loss : 0.014538
[02:10:23.671] iteration 25199 : model1 loss : 0.019013 model2 loss : 0.018443
[02:10:24.339] iteration 25200 : model1 loss : 0.016750 model2 loss : 0.013733
[02:10:42.104] iteration 25200 : model1_mean_dice : 0.879085 model1_mean_hd95 : 6.211326
[02:10:59.955] iteration 25200 : model2_mean_dice : 0.881320 model2_mean_hd95 : 4.146723
[02:11:00.629] iteration 25201 : model1 loss : 0.017790 model2 loss : 0.018883
[02:11:01.280] iteration 25202 : model1 loss : 0.016049 model2 loss : 0.015490
[02:11:01.935] iteration 25203 : model1 loss : 0.015748 model2 loss : 0.016892
[02:11:02.589] iteration 25204 : model1 loss : 0.020965 model2 loss : 0.020934
[02:11:03.245] iteration 25205 : model1 loss : 0.019760 model2 loss : 0.019725
[02:11:03.904] iteration 25206 : model1 loss : 0.021014 model2 loss : 0.020117
[02:11:04.560] iteration 25207 : model1 loss : 0.018176 model2 loss : 0.016946
[02:11:05.229] iteration 25208 : model1 loss : 0.022243 model2 loss : 0.023088
[02:11:05.883] iteration 25209 : model1 loss : 0.020800 model2 loss : 0.021397
[02:11:06.547] iteration 25210 : model1 loss : 0.021673 model2 loss : 0.020470
[02:11:07.208] iteration 25211 : model1 loss : 0.020251 model2 loss : 0.020687
[02:11:07.849] iteration 25212 : model1 loss : 0.021397 model2 loss : 0.022165
[02:11:08.510] iteration 25213 : model1 loss : 0.022798 model2 loss : 0.024774
[02:11:09.174] iteration 25214 : model1 loss : 0.025722 model2 loss : 0.027692
[02:11:09.830] iteration 25215 : model1 loss : 0.016541 model2 loss : 0.016813
[02:11:10.491] iteration 25216 : model1 loss : 0.021785 model2 loss : 0.023777
[02:11:11.148] iteration 25217 : model1 loss : 0.023428 model2 loss : 0.021579
[02:11:11.800] iteration 25218 : model1 loss : 0.024660 model2 loss : 0.029826
[02:11:12.469] iteration 25219 : model1 loss : 0.015847 model2 loss : 0.018148
[02:11:13.134] iteration 25220 : model1 loss : 0.017358 model2 loss : 0.018169
[02:11:13.793] iteration 25221 : model1 loss : 0.018339 model2 loss : 0.019219
[02:11:14.457] iteration 25222 : model1 loss : 0.019557 model2 loss : 0.019320
[02:11:15.128] iteration 25223 : model1 loss : 0.018415 model2 loss : 0.018015
[02:11:15.779] iteration 25224 : model1 loss : 0.022957 model2 loss : 0.027109
[02:11:16.441] iteration 25225 : model1 loss : 0.020199 model2 loss : 0.021041
[02:11:17.089] iteration 25226 : model1 loss : 0.015941 model2 loss : 0.016581
[02:11:17.743] iteration 25227 : model1 loss : 0.022666 model2 loss : 0.022311
[02:11:18.401] iteration 25228 : model1 loss : 0.017888 model2 loss : 0.018800
[02:11:19.062] iteration 25229 : model1 loss : 0.017670 model2 loss : 0.016891
[02:11:19.722] iteration 25230 : model1 loss : 0.039367 model2 loss : 0.041986
[02:11:20.375] iteration 25231 : model1 loss : 0.019051 model2 loss : 0.017073
[02:11:21.041] iteration 25232 : model1 loss : 0.015259 model2 loss : 0.015179
[02:11:21.704] iteration 25233 : model1 loss : 0.016598 model2 loss : 0.018182
[02:11:22.363] iteration 25234 : model1 loss : 0.027139 model2 loss : 0.025550
[02:11:23.032] iteration 25235 : model1 loss : 0.020135 model2 loss : 0.020464
[02:11:23.690] iteration 25236 : model1 loss : 0.016806 model2 loss : 0.018171
[02:11:24.353] iteration 25237 : model1 loss : 0.028523 model2 loss : 0.026278
[02:11:25.005] iteration 25238 : model1 loss : 0.022818 model2 loss : 0.022191
[02:11:25.656] iteration 25239 : model1 loss : 0.021073 model2 loss : 0.020424
[02:11:26.321] iteration 25240 : model1 loss : 0.016941 model2 loss : 0.014351
[02:11:26.971] iteration 25241 : model1 loss : 0.038995 model2 loss : 0.041438
[02:11:27.634] iteration 25242 : model1 loss : 0.016993 model2 loss : 0.016291
[02:11:28.296] iteration 25243 : model1 loss : 0.019789 model2 loss : 0.019881
[02:11:28.944] iteration 25244 : model1 loss : 0.017105 model2 loss : 0.016223
[02:11:29.601] iteration 25245 : model1 loss : 0.021624 model2 loss : 0.024513
[02:11:30.270] iteration 25246 : model1 loss : 0.022966 model2 loss : 0.021576
[02:11:30.926] iteration 25247 : model1 loss : 0.019875 model2 loss : 0.018865
[02:11:31.575] iteration 25248 : model1 loss : 0.018763 model2 loss : 0.019234
[02:11:32.225] iteration 25249 : model1 loss : 0.022032 model2 loss : 0.022128
[02:11:32.886] iteration 25250 : model1 loss : 0.019497 model2 loss : 0.020518
[02:11:33.586] iteration 25251 : model1 loss : 0.140719 model2 loss : 0.140820
[02:11:34.259] iteration 25252 : model1 loss : 0.019332 model2 loss : 0.022062
[02:11:34.927] iteration 25253 : model1 loss : 0.020730 model2 loss : 0.019682
[02:11:35.581] iteration 25254 : model1 loss : 0.022175 model2 loss : 0.022502
[02:11:36.237] iteration 25255 : model1 loss : 0.019624 model2 loss : 0.020564
[02:11:36.892] iteration 25256 : model1 loss : 0.141043 model2 loss : 0.139983
[02:11:37.565] iteration 25257 : model1 loss : 0.020944 model2 loss : 0.021807
[02:11:38.227] iteration 25258 : model1 loss : 0.019885 model2 loss : 0.021310
[02:11:38.900] iteration 25259 : model1 loss : 0.020077 model2 loss : 0.017617
[02:11:39.562] iteration 25260 : model1 loss : 0.022049 model2 loss : 0.023526
[02:11:40.230] iteration 25261 : model1 loss : 0.021048 model2 loss : 0.021747
[02:11:40.880] iteration 25262 : model1 loss : 0.017843 model2 loss : 0.018635
[02:11:41.554] iteration 25263 : model1 loss : 0.016286 model2 loss : 0.016205
[02:11:42.237] iteration 25264 : model1 loss : 0.020914 model2 loss : 0.018837
[02:11:42.898] iteration 25265 : model1 loss : 0.024938 model2 loss : 0.025286
[02:11:43.566] iteration 25266 : model1 loss : 0.018542 model2 loss : 0.018713
[02:11:44.226] iteration 25267 : model1 loss : 0.018679 model2 loss : 0.017141
[02:11:44.895] iteration 25268 : model1 loss : 0.024352 model2 loss : 0.025820
[02:11:45.545] iteration 25269 : model1 loss : 0.032136 model2 loss : 0.035634
[02:11:46.197] iteration 25270 : model1 loss : 0.021298 model2 loss : 0.019299
[02:11:46.853] iteration 25271 : model1 loss : 0.017942 model2 loss : 0.016944
[02:11:47.517] iteration 25272 : model1 loss : 0.017441 model2 loss : 0.016637
[02:11:48.181] iteration 25273 : model1 loss : 0.018475 model2 loss : 0.019810
[02:11:48.839] iteration 25274 : model1 loss : 0.018102 model2 loss : 0.019801
[02:11:49.507] iteration 25275 : model1 loss : 0.014223 model2 loss : 0.015209
[02:11:50.195] iteration 25276 : model1 loss : 0.022545 model2 loss : 0.023832
[02:11:50.864] iteration 25277 : model1 loss : 0.019011 model2 loss : 0.019949
[02:11:51.524] iteration 25278 : model1 loss : 0.019728 model2 loss : 0.019988
[02:11:52.189] iteration 25279 : model1 loss : 0.018976 model2 loss : 0.020280
[02:11:52.849] iteration 25280 : model1 loss : 0.024168 model2 loss : 0.022491
[02:11:53.521] iteration 25281 : model1 loss : 0.022030 model2 loss : 0.025212
[02:11:54.182] iteration 25282 : model1 loss : 0.021556 model2 loss : 0.019459
[02:11:54.848] iteration 25283 : model1 loss : 0.012835 model2 loss : 0.011722
[02:11:55.511] iteration 25284 : model1 loss : 0.018595 model2 loss : 0.019451
[02:11:56.173] iteration 25285 : model1 loss : 0.022478 model2 loss : 0.021320
[02:11:56.830] iteration 25286 : model1 loss : 0.022053 model2 loss : 0.024928
[02:11:57.484] iteration 25287 : model1 loss : 0.017929 model2 loss : 0.019996
[02:11:58.147] iteration 25288 : model1 loss : 0.021832 model2 loss : 0.019367
[02:11:58.807] iteration 25289 : model1 loss : 0.017100 model2 loss : 0.016894
[02:11:59.485] iteration 25290 : model1 loss : 0.015826 model2 loss : 0.016747
[02:12:00.146] iteration 25291 : model1 loss : 0.021222 model2 loss : 0.022675
[02:12:00.801] iteration 25292 : model1 loss : 0.021001 model2 loss : 0.020933
[02:12:01.469] iteration 25293 : model1 loss : 0.014884 model2 loss : 0.015753
[02:12:02.123] iteration 25294 : model1 loss : 0.022845 model2 loss : 0.020908
[02:12:02.787] iteration 25295 : model1 loss : 0.057955 model2 loss : 0.043707
[02:12:03.445] iteration 25296 : model1 loss : 0.030926 model2 loss : 0.031952
[02:12:04.107] iteration 25297 : model1 loss : 0.018073 model2 loss : 0.018603
[02:12:04.770] iteration 25298 : model1 loss : 0.013934 model2 loss : 0.013465
[02:12:05.425] iteration 25299 : model1 loss : 0.020572 model2 loss : 0.019855
[02:12:06.075] iteration 25300 : model1 loss : 0.019544 model2 loss : 0.020736
[02:12:06.792] iteration 25301 : model1 loss : 0.017200 model2 loss : 0.019683
[02:12:07.449] iteration 25302 : model1 loss : 0.016140 model2 loss : 0.015787
[02:12:08.122] iteration 25303 : model1 loss : 0.025990 model2 loss : 0.028621
[02:12:08.774] iteration 25304 : model1 loss : 0.017410 model2 loss : 0.018180
[02:12:09.432] iteration 25305 : model1 loss : 0.015608 model2 loss : 0.015470
[02:12:10.097] iteration 25306 : model1 loss : 0.020664 model2 loss : 0.020962
[02:12:10.755] iteration 25307 : model1 loss : 0.023490 model2 loss : 0.024470
[02:12:11.429] iteration 25308 : model1 loss : 0.030360 model2 loss : 0.028046
[02:12:12.088] iteration 25309 : model1 loss : 0.030102 model2 loss : 0.031351
[02:12:12.748] iteration 25310 : model1 loss : 0.021750 model2 loss : 0.020136
[02:12:13.406] iteration 25311 : model1 loss : 0.015535 model2 loss : 0.017844
[02:12:14.059] iteration 25312 : model1 loss : 0.018036 model2 loss : 0.021188
[02:12:14.721] iteration 25313 : model1 loss : 0.022359 model2 loss : 0.023482
[02:12:15.376] iteration 25314 : model1 loss : 0.022753 model2 loss : 0.024224
[02:12:16.031] iteration 25315 : model1 loss : 0.023187 model2 loss : 0.022544
[02:12:16.683] iteration 25316 : model1 loss : 0.148465 model2 loss : 0.143716
[02:12:17.351] iteration 25317 : model1 loss : 0.016980 model2 loss : 0.016878
[02:12:18.021] iteration 25318 : model1 loss : 0.020552 model2 loss : 0.020205
[02:12:18.680] iteration 25319 : model1 loss : 0.031813 model2 loss : 0.033886
[02:12:19.339] iteration 25320 : model1 loss : 0.018151 model2 loss : 0.020608
[02:12:20.005] iteration 25321 : model1 loss : 0.147002 model2 loss : 0.146852
[02:12:20.662] iteration 25322 : model1 loss : 0.024331 model2 loss : 0.026095
[02:12:21.318] iteration 25323 : model1 loss : 0.020377 model2 loss : 0.017994
[02:12:21.974] iteration 25324 : model1 loss : 0.019506 model2 loss : 0.019186
[02:12:22.624] iteration 25325 : model1 loss : 0.019875 model2 loss : 0.017535
[02:12:23.289] iteration 25326 : model1 loss : 0.023149 model2 loss : 0.022598
[02:12:23.941] iteration 25327 : model1 loss : 0.016766 model2 loss : 0.018258
[02:12:24.601] iteration 25328 : model1 loss : 0.022096 model2 loss : 0.020683
[02:12:25.265] iteration 25329 : model1 loss : 0.020329 model2 loss : 0.021876
[02:12:25.933] iteration 25330 : model1 loss : 0.021872 model2 loss : 0.021185
[02:12:26.593] iteration 25331 : model1 loss : 0.026763 model2 loss : 0.022910
[02:12:27.251] iteration 25332 : model1 loss : 0.022645 model2 loss : 0.021438
[02:12:27.914] iteration 25333 : model1 loss : 0.020821 model2 loss : 0.021757
[02:12:28.581] iteration 25334 : model1 loss : 0.015741 model2 loss : 0.014462
[02:12:29.244] iteration 25335 : model1 loss : 0.025704 model2 loss : 0.024149
[02:12:29.912] iteration 25336 : model1 loss : 0.019818 model2 loss : 0.019926
[02:12:30.575] iteration 25337 : model1 loss : 0.022798 model2 loss : 0.021180
[02:12:31.239] iteration 25338 : model1 loss : 0.027587 model2 loss : 0.028718
[02:12:31.896] iteration 25339 : model1 loss : 0.022031 model2 loss : 0.022428
[02:12:32.565] iteration 25340 : model1 loss : 0.018735 model2 loss : 0.018852
[02:12:33.216] iteration 25341 : model1 loss : 0.025227 model2 loss : 0.023395
[02:12:33.879] iteration 25342 : model1 loss : 0.019876 model2 loss : 0.021086
[02:12:34.542] iteration 25343 : model1 loss : 0.019339 model2 loss : 0.019335
[02:12:35.204] iteration 25344 : model1 loss : 0.022575 model2 loss : 0.022876
[02:12:35.864] iteration 25345 : model1 loss : 0.019014 model2 loss : 0.017689
[02:12:36.520] iteration 25346 : model1 loss : 0.019377 model2 loss : 0.020842
[02:12:37.169] iteration 25347 : model1 loss : 0.019247 model2 loss : 0.019939
[02:12:37.820] iteration 25348 : model1 loss : 0.018458 model2 loss : 0.021897
[02:12:38.477] iteration 25349 : model1 loss : 0.021339 model2 loss : 0.023089
[02:12:39.122] iteration 25350 : model1 loss : 0.023146 model2 loss : 0.022143
[02:12:39.811] iteration 25351 : model1 loss : 0.137340 model2 loss : 0.137151
[02:12:40.469] iteration 25352 : model1 loss : 0.031607 model2 loss : 0.030781
[02:12:41.140] iteration 25353 : model1 loss : 0.017721 model2 loss : 0.018052
[02:12:41.792] iteration 25354 : model1 loss : 0.027242 model2 loss : 0.026155
[02:12:42.452] iteration 25355 : model1 loss : 0.017684 model2 loss : 0.018734
[02:12:43.116] iteration 25356 : model1 loss : 0.023745 model2 loss : 0.018930
[02:12:43.784] iteration 25357 : model1 loss : 0.017692 model2 loss : 0.017673
[02:12:44.447] iteration 25358 : model1 loss : 0.020143 model2 loss : 0.022073
[02:12:45.108] iteration 25359 : model1 loss : 0.015553 model2 loss : 0.015884
[02:12:45.768] iteration 25360 : model1 loss : 0.020849 model2 loss : 0.024584
[02:12:46.443] iteration 25361 : model1 loss : 0.141168 model2 loss : 0.138428
[02:12:47.095] iteration 25362 : model1 loss : 0.021634 model2 loss : 0.022402
[02:12:47.752] iteration 25363 : model1 loss : 0.021215 model2 loss : 0.020913
[02:12:48.407] iteration 25364 : model1 loss : 0.016774 model2 loss : 0.016334
[02:12:49.081] iteration 25365 : model1 loss : 0.014400 model2 loss : 0.014031
[02:12:49.733] iteration 25366 : model1 loss : 0.016094 model2 loss : 0.017229
[02:12:50.421] iteration 25367 : model1 loss : 0.017614 model2 loss : 0.018868
[02:12:51.091] iteration 25368 : model1 loss : 0.021984 model2 loss : 0.021215
[02:12:51.743] iteration 25369 : model1 loss : 0.020748 model2 loss : 0.019951
[02:12:52.405] iteration 25370 : model1 loss : 0.019352 model2 loss : 0.020266
[02:12:53.069] iteration 25371 : model1 loss : 0.020375 model2 loss : 0.020831
[02:12:53.725] iteration 25372 : model1 loss : 0.018836 model2 loss : 0.018780
[02:12:54.378] iteration 25373 : model1 loss : 0.014283 model2 loss : 0.015284
[02:12:55.043] iteration 25374 : model1 loss : 0.030964 model2 loss : 0.026468
[02:12:55.708] iteration 25375 : model1 loss : 0.019004 model2 loss : 0.019599
[02:12:56.378] iteration 25376 : model1 loss : 0.017334 model2 loss : 0.016763
[02:12:57.045] iteration 25377 : model1 loss : 0.019144 model2 loss : 0.018352
[02:12:57.693] iteration 25378 : model1 loss : 0.015383 model2 loss : 0.013014
[02:12:58.349] iteration 25379 : model1 loss : 0.019175 model2 loss : 0.020921
[02:12:59.008] iteration 25380 : model1 loss : 0.022639 model2 loss : 0.022114
[02:12:59.675] iteration 25381 : model1 loss : 0.022256 model2 loss : 0.023812
[02:13:00.336] iteration 25382 : model1 loss : 0.014627 model2 loss : 0.015235
[02:13:00.990] iteration 25383 : model1 loss : 0.022471 model2 loss : 0.020396
[02:13:01.657] iteration 25384 : model1 loss : 0.019522 model2 loss : 0.020791
[02:13:02.322] iteration 25385 : model1 loss : 0.019726 model2 loss : 0.018395
[02:13:02.979] iteration 25386 : model1 loss : 0.017726 model2 loss : 0.017688
[02:13:03.645] iteration 25387 : model1 loss : 0.022260 model2 loss : 0.021559
[02:13:04.303] iteration 25388 : model1 loss : 0.017449 model2 loss : 0.018397
[02:13:04.952] iteration 25389 : model1 loss : 0.023128 model2 loss : 0.023609
[02:13:05.604] iteration 25390 : model1 loss : 0.019589 model2 loss : 0.018709
[02:13:06.265] iteration 25391 : model1 loss : 0.018799 model2 loss : 0.018103
[02:13:06.916] iteration 25392 : model1 loss : 0.015636 model2 loss : 0.017171
[02:13:07.598] iteration 25393 : model1 loss : 0.026177 model2 loss : 0.033036
[02:13:08.258] iteration 25394 : model1 loss : 0.024861 model2 loss : 0.023533
[02:13:08.914] iteration 25395 : model1 loss : 0.022582 model2 loss : 0.021736
[02:13:09.583] iteration 25396 : model1 loss : 0.022931 model2 loss : 0.023703
[02:13:10.254] iteration 25397 : model1 loss : 0.022784 model2 loss : 0.021648
[02:13:10.936] iteration 25398 : model1 loss : 0.019984 model2 loss : 0.018509
[02:13:11.602] iteration 25399 : model1 loss : 0.023003 model2 loss : 0.023818
[02:13:12.261] iteration 25400 : model1 loss : 0.019733 model2 loss : 0.020220
[02:13:30.156] iteration 25400 : model1_mean_dice : 0.874051 model1_mean_hd95 : 7.412560
[02:13:47.965] iteration 25400 : model2_mean_dice : 0.879155 model2_mean_hd95 : 4.569354
[02:13:48.653] iteration 25401 : model1 loss : 0.025548 model2 loss : 0.023950
[02:13:49.301] iteration 25402 : model1 loss : 0.014393 model2 loss : 0.015311
[02:13:49.964] iteration 25403 : model1 loss : 0.022328 model2 loss : 0.022441
[02:13:50.613] iteration 25404 : model1 loss : 0.017046 model2 loss : 0.017147
[02:13:51.287] iteration 25405 : model1 loss : 0.022066 model2 loss : 0.024174
[02:13:51.962] iteration 25406 : model1 loss : 0.020492 model2 loss : 0.018862
[02:13:52.644] iteration 25407 : model1 loss : 0.013004 model2 loss : 0.013502
[02:13:53.298] iteration 25408 : model1 loss : 0.030435 model2 loss : 0.027550
[02:13:53.947] iteration 25409 : model1 loss : 0.035237 model2 loss : 0.040571
[02:13:54.598] iteration 25410 : model1 loss : 0.025146 model2 loss : 0.025443
[02:13:55.261] iteration 25411 : model1 loss : 0.016277 model2 loss : 0.014752
[02:13:55.907] iteration 25412 : model1 loss : 0.018466 model2 loss : 0.018188
[02:13:56.565] iteration 25413 : model1 loss : 0.016446 model2 loss : 0.016066
[02:13:57.216] iteration 25414 : model1 loss : 0.018415 model2 loss : 0.016766
[02:13:57.875] iteration 25415 : model1 loss : 0.025161 model2 loss : 0.029131
[02:13:58.534] iteration 25416 : model1 loss : 0.022744 model2 loss : 0.022808
[02:13:59.182] iteration 25417 : model1 loss : 0.017169 model2 loss : 0.018641
[02:13:59.842] iteration 25418 : model1 loss : 0.019342 model2 loss : 0.020002
[02:14:00.508] iteration 25419 : model1 loss : 0.018618 model2 loss : 0.018206
[02:14:01.165] iteration 25420 : model1 loss : 0.023910 model2 loss : 0.024245
[02:14:01.820] iteration 25421 : model1 loss : 0.020644 model2 loss : 0.023573
[02:14:02.487] iteration 25422 : model1 loss : 0.021691 model2 loss : 0.021378
[02:14:03.143] iteration 25423 : model1 loss : 0.032837 model2 loss : 0.027856
[02:14:03.804] iteration 25424 : model1 loss : 0.020685 model2 loss : 0.024571
[02:14:04.463] iteration 25425 : model1 loss : 0.022130 model2 loss : 0.020367
[02:14:05.125] iteration 25426 : model1 loss : 0.022352 model2 loss : 0.022873
[02:14:05.776] iteration 25427 : model1 loss : 0.016933 model2 loss : 0.016809
[02:14:06.432] iteration 25428 : model1 loss : 0.020739 model2 loss : 0.020043
[02:14:07.088] iteration 25429 : model1 loss : 0.028943 model2 loss : 0.024793
[02:14:07.745] iteration 25430 : model1 loss : 0.018116 model2 loss : 0.018395
[02:14:08.407] iteration 25431 : model1 loss : 0.022988 model2 loss : 0.023340
[02:14:09.059] iteration 25432 : model1 loss : 0.018901 model2 loss : 0.019047
[02:14:09.715] iteration 25433 : model1 loss : 0.144294 model2 loss : 0.148434
[02:14:10.374] iteration 25434 : model1 loss : 0.021861 model2 loss : 0.024106
[02:14:11.034] iteration 25435 : model1 loss : 0.016827 model2 loss : 0.016023
[02:14:11.685] iteration 25436 : model1 loss : 0.018520 model2 loss : 0.017660
[02:14:12.349] iteration 25437 : model1 loss : 0.019446 model2 loss : 0.020332
[02:14:13.001] iteration 25438 : model1 loss : 0.018827 model2 loss : 0.017988
[02:14:13.663] iteration 25439 : model1 loss : 0.023358 model2 loss : 0.023391
[02:14:14.329] iteration 25440 : model1 loss : 0.016721 model2 loss : 0.017541
[02:14:14.977] iteration 25441 : model1 loss : 0.016711 model2 loss : 0.017730
[02:14:15.632] iteration 25442 : model1 loss : 0.017530 model2 loss : 0.016336
[02:14:16.299] iteration 25443 : model1 loss : 0.022697 model2 loss : 0.019596
[02:14:16.966] iteration 25444 : model1 loss : 0.027464 model2 loss : 0.030238
[02:14:17.616] iteration 25445 : model1 loss : 0.019846 model2 loss : 0.021838
[02:14:18.275] iteration 25446 : model1 loss : 0.145091 model2 loss : 0.144502
[02:14:18.928] iteration 25447 : model1 loss : 0.019677 model2 loss : 0.019619
[02:14:19.585] iteration 25448 : model1 loss : 0.022927 model2 loss : 0.022560
[02:14:20.242] iteration 25449 : model1 loss : 0.024426 model2 loss : 0.025797
[02:14:20.906] iteration 25450 : model1 loss : 0.021682 model2 loss : 0.021148
[02:14:21.612] iteration 25451 : model1 loss : 0.020983 model2 loss : 0.021780
[02:14:22.270] iteration 25452 : model1 loss : 0.021189 model2 loss : 0.017798
[02:14:22.925] iteration 25453 : model1 loss : 0.020139 model2 loss : 0.018538
[02:14:23.582] iteration 25454 : model1 loss : 0.014953 model2 loss : 0.015964
[02:14:24.245] iteration 25455 : model1 loss : 0.018785 model2 loss : 0.018977
[02:14:24.901] iteration 25456 : model1 loss : 0.019082 model2 loss : 0.020214
[02:14:25.560] iteration 25457 : model1 loss : 0.016365 model2 loss : 0.016092
[02:14:26.218] iteration 25458 : model1 loss : 0.019841 model2 loss : 0.020659
[02:14:26.886] iteration 25459 : model1 loss : 0.016403 model2 loss : 0.016422
[02:14:27.548] iteration 25460 : model1 loss : 0.017087 model2 loss : 0.016451
[02:14:28.206] iteration 25461 : model1 loss : 0.019879 model2 loss : 0.022394
[02:14:28.860] iteration 25462 : model1 loss : 0.015329 model2 loss : 0.015455
[02:14:29.518] iteration 25463 : model1 loss : 0.017821 model2 loss : 0.015821
[02:14:30.192] iteration 25464 : model1 loss : 0.030411 model2 loss : 0.030558
[02:14:30.850] iteration 25465 : model1 loss : 0.017287 model2 loss : 0.017742
[02:14:31.510] iteration 25466 : model1 loss : 0.018484 model2 loss : 0.022416
[02:14:32.168] iteration 25467 : model1 loss : 0.025501 model2 loss : 0.027039
[02:14:32.823] iteration 25468 : model1 loss : 0.019547 model2 loss : 0.020527
[02:14:33.473] iteration 25469 : model1 loss : 0.014469 model2 loss : 0.014833
[02:14:34.123] iteration 25470 : model1 loss : 0.025409 model2 loss : 0.025031
[02:14:34.790] iteration 25471 : model1 loss : 0.016650 model2 loss : 0.016427
[02:14:35.446] iteration 25472 : model1 loss : 0.022599 model2 loss : 0.021616
[02:14:36.094] iteration 25473 : model1 loss : 0.018942 model2 loss : 0.019069
[02:14:36.752] iteration 25474 : model1 loss : 0.020079 model2 loss : 0.020884
[02:14:37.418] iteration 25475 : model1 loss : 0.022692 model2 loss : 0.021069
[02:14:38.072] iteration 25476 : model1 loss : 0.018503 model2 loss : 0.018314
[02:14:38.735] iteration 25477 : model1 loss : 0.017056 model2 loss : 0.017364
[02:14:39.404] iteration 25478 : model1 loss : 0.048366 model2 loss : 0.049932
[02:14:40.064] iteration 25479 : model1 loss : 0.013488 model2 loss : 0.014026
[02:14:40.720] iteration 25480 : model1 loss : 0.017930 model2 loss : 0.017804
[02:14:41.378] iteration 25481 : model1 loss : 0.019543 model2 loss : 0.018976
[02:14:42.041] iteration 25482 : model1 loss : 0.019399 model2 loss : 0.019647
[02:14:42.702] iteration 25483 : model1 loss : 0.025277 model2 loss : 0.027515
[02:14:43.378] iteration 25484 : model1 loss : 0.025204 model2 loss : 0.026515
[02:14:44.035] iteration 25485 : model1 loss : 0.018666 model2 loss : 0.017673
[02:14:44.693] iteration 25486 : model1 loss : 0.021176 model2 loss : 0.019412
[02:14:45.353] iteration 25487 : model1 loss : 0.022409 model2 loss : 0.021453
[02:14:46.001] iteration 25488 : model1 loss : 0.020820 model2 loss : 0.018869
[02:14:46.672] iteration 25489 : model1 loss : 0.016565 model2 loss : 0.024344
[02:14:47.349] iteration 25490 : model1 loss : 0.075411 model2 loss : 0.092539
[02:14:48.004] iteration 25491 : model1 loss : 0.017054 model2 loss : 0.017189
[02:14:48.675] iteration 25492 : model1 loss : 0.017316 model2 loss : 0.017074
[02:14:49.326] iteration 25493 : model1 loss : 0.021190 model2 loss : 0.022436
[02:14:49.981] iteration 25494 : model1 loss : 0.027880 model2 loss : 0.028163
[02:14:50.641] iteration 25495 : model1 loss : 0.032074 model2 loss : 0.040288
[02:14:51.322] iteration 25496 : model1 loss : 0.025999 model2 loss : 0.026433
[02:14:51.987] iteration 25497 : model1 loss : 0.021927 model2 loss : 0.020593
[02:14:52.644] iteration 25498 : model1 loss : 0.022044 model2 loss : 0.019640
[02:14:53.315] iteration 25499 : model1 loss : 0.019421 model2 loss : 0.016783
[02:14:53.965] iteration 25500 : model1 loss : 0.019740 model2 loss : 0.020261
[02:14:54.675] iteration 25501 : model1 loss : 0.023428 model2 loss : 0.019719
[02:14:55.343] iteration 25502 : model1 loss : 0.021964 model2 loss : 0.020312
[02:14:55.996] iteration 25503 : model1 loss : 0.022534 model2 loss : 0.020470
[02:14:56.653] iteration 25504 : model1 loss : 0.019989 model2 loss : 0.018660
[02:14:57.326] iteration 25505 : model1 loss : 0.025433 model2 loss : 0.023923
[02:14:57.988] iteration 25506 : model1 loss : 0.018798 model2 loss : 0.021520
[02:14:58.650] iteration 25507 : model1 loss : 0.017083 model2 loss : 0.020487
[02:14:59.303] iteration 25508 : model1 loss : 0.023046 model2 loss : 0.021577
[02:14:59.961] iteration 25509 : model1 loss : 0.018195 model2 loss : 0.019566
[02:15:00.641] iteration 25510 : model1 loss : 0.021718 model2 loss : 0.020659
[02:15:01.299] iteration 25511 : model1 loss : 0.020179 model2 loss : 0.018615
[02:15:01.955] iteration 25512 : model1 loss : 0.014918 model2 loss : 0.018711
[02:15:02.624] iteration 25513 : model1 loss : 0.029382 model2 loss : 0.031110
[02:15:03.290] iteration 25514 : model1 loss : 0.019388 model2 loss : 0.019985
[02:15:03.955] iteration 25515 : model1 loss : 0.019494 model2 loss : 0.019957
[02:15:04.604] iteration 25516 : model1 loss : 0.025333 model2 loss : 0.027044
[02:15:05.259] iteration 25517 : model1 loss : 0.018165 model2 loss : 0.017394
[02:15:05.921] iteration 25518 : model1 loss : 0.044071 model2 loss : 0.044156
[02:15:06.589] iteration 25519 : model1 loss : 0.028627 model2 loss : 0.028935
[02:15:07.254] iteration 25520 : model1 loss : 0.015962 model2 loss : 0.017115
[02:15:07.929] iteration 25521 : model1 loss : 0.025099 model2 loss : 0.030727
[02:15:08.588] iteration 25522 : model1 loss : 0.025881 model2 loss : 0.022511
[02:15:09.243] iteration 25523 : model1 loss : 0.017597 model2 loss : 0.017983
[02:15:09.911] iteration 25524 : model1 loss : 0.018979 model2 loss : 0.020351
[02:15:10.569] iteration 25525 : model1 loss : 0.016571 model2 loss : 0.016211
[02:15:11.235] iteration 25526 : model1 loss : 0.022082 model2 loss : 0.024467
[02:15:11.895] iteration 25527 : model1 loss : 0.019858 model2 loss : 0.019674
[02:15:12.561] iteration 25528 : model1 loss : 0.025279 model2 loss : 0.027705
[02:15:13.229] iteration 25529 : model1 loss : 0.018536 model2 loss : 0.018142
[02:15:13.872] iteration 25530 : model1 loss : 0.018161 model2 loss : 0.017900
[02:15:14.528] iteration 25531 : model1 loss : 0.017532 model2 loss : 0.018657
[02:15:15.185] iteration 25532 : model1 loss : 0.024332 model2 loss : 0.026002
[02:15:15.851] iteration 25533 : model1 loss : 0.017787 model2 loss : 0.017353
[02:15:16.514] iteration 25534 : model1 loss : 0.022275 model2 loss : 0.021799
[02:15:17.177] iteration 25535 : model1 loss : 0.018946 model2 loss : 0.021280
[02:15:17.829] iteration 25536 : model1 loss : 0.023446 model2 loss : 0.023045
[02:15:18.500] iteration 25537 : model1 loss : 0.024659 model2 loss : 0.026390
[02:15:19.167] iteration 25538 : model1 loss : 0.019297 model2 loss : 0.021367
[02:15:19.837] iteration 25539 : model1 loss : 0.022904 model2 loss : 0.019865
[02:15:20.492] iteration 25540 : model1 loss : 0.019733 model2 loss : 0.019375
[02:15:21.160] iteration 25541 : model1 loss : 0.022179 model2 loss : 0.022528
[02:15:21.810] iteration 25542 : model1 loss : 0.021952 model2 loss : 0.021627
[02:15:22.479] iteration 25543 : model1 loss : 0.015472 model2 loss : 0.014848
[02:15:23.137] iteration 25544 : model1 loss : 0.023600 model2 loss : 0.021638
[02:15:23.800] iteration 25545 : model1 loss : 0.018328 model2 loss : 0.017928
[02:15:24.464] iteration 25546 : model1 loss : 0.018944 model2 loss : 0.018599
[02:15:25.132] iteration 25547 : model1 loss : 0.018265 model2 loss : 0.018574
[02:15:25.779] iteration 25548 : model1 loss : 0.019773 model2 loss : 0.019165
[02:15:26.448] iteration 25549 : model1 loss : 0.019641 model2 loss : 0.021103
[02:15:27.103] iteration 25550 : model1 loss : 0.013922 model2 loss : 0.014659
[02:15:27.805] iteration 25551 : model1 loss : 0.019058 model2 loss : 0.019207
[02:15:28.464] iteration 25552 : model1 loss : 0.017128 model2 loss : 0.016476
[02:15:29.131] iteration 25553 : model1 loss : 0.019667 model2 loss : 0.020944
[02:15:29.803] iteration 25554 : model1 loss : 0.013082 model2 loss : 0.013922
[02:15:30.472] iteration 25555 : model1 loss : 0.016909 model2 loss : 0.017544
[02:15:31.136] iteration 25556 : model1 loss : 0.026190 model2 loss : 0.028479
[02:15:31.794] iteration 25557 : model1 loss : 0.019355 model2 loss : 0.019722
[02:15:32.460] iteration 25558 : model1 loss : 0.022645 model2 loss : 0.022738
[02:15:33.122] iteration 25559 : model1 loss : 0.026323 model2 loss : 0.024020
[02:15:33.786] iteration 25560 : model1 loss : 0.020974 model2 loss : 0.018428
[02:15:34.443] iteration 25561 : model1 loss : 0.023297 model2 loss : 0.037508
[02:15:35.110] iteration 25562 : model1 loss : 0.025331 model2 loss : 0.025797
[02:15:35.768] iteration 25563 : model1 loss : 0.019820 model2 loss : 0.018716
[02:15:36.436] iteration 25564 : model1 loss : 0.026458 model2 loss : 0.025614
[02:15:37.085] iteration 25565 : model1 loss : 0.015129 model2 loss : 0.015464
[02:15:37.739] iteration 25566 : model1 loss : 0.012458 model2 loss : 0.012299
[02:15:38.394] iteration 25567 : model1 loss : 0.024374 model2 loss : 0.025673
[02:15:39.052] iteration 25568 : model1 loss : 0.016054 model2 loss : 0.016672
[02:15:39.709] iteration 25569 : model1 loss : 0.017963 model2 loss : 0.018077
[02:15:40.367] iteration 25570 : model1 loss : 0.015647 model2 loss : 0.017391
[02:15:41.022] iteration 25571 : model1 loss : 0.025276 model2 loss : 0.025518
[02:15:41.696] iteration 25572 : model1 loss : 0.018543 model2 loss : 0.018583
[02:15:42.356] iteration 25573 : model1 loss : 0.021818 model2 loss : 0.021660
[02:15:43.022] iteration 25574 : model1 loss : 0.021811 model2 loss : 0.020842
[02:15:43.666] iteration 25575 : model1 loss : 0.015448 model2 loss : 0.015399
[02:15:44.328] iteration 25576 : model1 loss : 0.014496 model2 loss : 0.015244
[02:15:44.993] iteration 25577 : model1 loss : 0.021355 model2 loss : 0.022313
[02:15:45.649] iteration 25578 : model1 loss : 0.020741 model2 loss : 0.022347
[02:15:46.322] iteration 25579 : model1 loss : 0.027194 model2 loss : 0.027552
[02:15:46.973] iteration 25580 : model1 loss : 0.028918 model2 loss : 0.031599
[02:15:47.627] iteration 25581 : model1 loss : 0.016417 model2 loss : 0.014965
[02:15:48.292] iteration 25582 : model1 loss : 0.018993 model2 loss : 0.017517
[02:15:48.945] iteration 25583 : model1 loss : 0.017058 model2 loss : 0.017403
[02:15:49.597] iteration 25584 : model1 loss : 0.029807 model2 loss : 0.026618
[02:15:50.255] iteration 25585 : model1 loss : 0.016700 model2 loss : 0.017499
[02:15:50.917] iteration 25586 : model1 loss : 0.017915 model2 loss : 0.018634
[02:15:51.579] iteration 25587 : model1 loss : 0.020961 model2 loss : 0.021518
[02:15:52.255] iteration 25588 : model1 loss : 0.019243 model2 loss : 0.017667
[02:15:52.918] iteration 25589 : model1 loss : 0.018066 model2 loss : 0.018929
[02:15:53.575] iteration 25590 : model1 loss : 0.020502 model2 loss : 0.020983
[02:15:54.239] iteration 25591 : model1 loss : 0.020197 model2 loss : 0.019175
[02:15:54.902] iteration 25592 : model1 loss : 0.027024 model2 loss : 0.025892
[02:15:55.567] iteration 25593 : model1 loss : 0.017847 model2 loss : 0.017530
[02:15:56.232] iteration 25594 : model1 loss : 0.021529 model2 loss : 0.019812
[02:15:56.894] iteration 25595 : model1 loss : 0.021510 model2 loss : 0.023566
[02:15:57.553] iteration 25596 : model1 loss : 0.021753 model2 loss : 0.019532
[02:15:58.216] iteration 25597 : model1 loss : 0.021955 model2 loss : 0.023375
[02:15:58.869] iteration 25598 : model1 loss : 0.024063 model2 loss : 0.023725
[02:15:59.533] iteration 25599 : model1 loss : 0.013341 model2 loss : 0.014966
[02:16:00.183] iteration 25600 : model1 loss : 0.018975 model2 loss : 0.020272
[02:16:17.872] iteration 25600 : model1_mean_dice : 0.876304 model1_mean_hd95 : 7.289794
[02:16:35.437] iteration 25600 : model2_mean_dice : 0.866869 model2_mean_hd95 : 12.741076
[02:16:36.133] iteration 25601 : model1 loss : 0.014740 model2 loss : 0.016189
[02:16:36.775] iteration 25602 : model1 loss : 0.019780 model2 loss : 0.018550
[02:16:37.438] iteration 25603 : model1 loss : 0.017558 model2 loss : 0.017326
[02:16:38.085] iteration 25604 : model1 loss : 0.023878 model2 loss : 0.020142
[02:16:38.734] iteration 25605 : model1 loss : 0.020878 model2 loss : 0.018789
[02:16:39.388] iteration 25606 : model1 loss : 0.015991 model2 loss : 0.016622
[02:16:40.044] iteration 25607 : model1 loss : 0.035354 model2 loss : 0.047649
[02:16:40.703] iteration 25608 : model1 loss : 0.018101 model2 loss : 0.017995
[02:16:41.367] iteration 25609 : model1 loss : 0.017226 model2 loss : 0.017520
[02:16:42.010] iteration 25610 : model1 loss : 0.016919 model2 loss : 0.018956
[02:16:42.671] iteration 25611 : model1 loss : 0.015494 model2 loss : 0.015994
[02:16:43.336] iteration 25612 : model1 loss : 0.017690 model2 loss : 0.020512
[02:16:44.025] iteration 25613 : model1 loss : 0.018398 model2 loss : 0.017568
[02:16:44.673] iteration 25614 : model1 loss : 0.017207 model2 loss : 0.016034
[02:16:45.333] iteration 25615 : model1 loss : 0.018760 model2 loss : 0.018887
[02:16:45.990] iteration 25616 : model1 loss : 0.023320 model2 loss : 0.024681
[02:16:46.644] iteration 25617 : model1 loss : 0.014900 model2 loss : 0.015228
[02:16:47.294] iteration 25618 : model1 loss : 0.020793 model2 loss : 0.023081
[02:16:47.957] iteration 25619 : model1 loss : 0.018385 model2 loss : 0.018428
[02:16:48.607] iteration 25620 : model1 loss : 0.017954 model2 loss : 0.019133
[02:16:49.268] iteration 25621 : model1 loss : 0.019852 model2 loss : 0.022072
[02:16:49.925] iteration 25622 : model1 loss : 0.024495 model2 loss : 0.022385
[02:16:50.581] iteration 25623 : model1 loss : 0.018627 model2 loss : 0.019738
[02:16:51.235] iteration 25624 : model1 loss : 0.029699 model2 loss : 0.028950
[02:16:51.902] iteration 25625 : model1 loss : 0.020991 model2 loss : 0.024342
[02:16:52.600] iteration 25626 : model1 loss : 0.022176 model2 loss : 0.023522
[02:16:53.260] iteration 25627 : model1 loss : 0.018348 model2 loss : 0.018406
[02:16:53.911] iteration 25628 : model1 loss : 0.020725 model2 loss : 0.020824
[02:16:54.568] iteration 25629 : model1 loss : 0.020127 model2 loss : 0.019145
[02:16:55.218] iteration 25630 : model1 loss : 0.025063 model2 loss : 0.028600
[02:16:55.868] iteration 25631 : model1 loss : 0.017882 model2 loss : 0.019020
[02:16:56.522] iteration 25632 : model1 loss : 0.034149 model2 loss : 0.041422
[02:16:57.190] iteration 25633 : model1 loss : 0.022948 model2 loss : 0.024242
[02:16:57.859] iteration 25634 : model1 loss : 0.015901 model2 loss : 0.016774
[02:16:58.518] iteration 25635 : model1 loss : 0.015994 model2 loss : 0.015960
[02:16:59.172] iteration 25636 : model1 loss : 0.018642 model2 loss : 0.017602
[02:16:59.818] iteration 25637 : model1 loss : 0.034140 model2 loss : 0.035267
[02:17:00.486] iteration 25638 : model1 loss : 0.023098 model2 loss : 0.020212
[02:17:01.134] iteration 25639 : model1 loss : 0.023638 model2 loss : 0.022623
[02:17:01.791] iteration 25640 : model1 loss : 0.019239 model2 loss : 0.018240
[02:17:02.459] iteration 25641 : model1 loss : 0.018506 model2 loss : 0.017620
[02:17:03.114] iteration 25642 : model1 loss : 0.023300 model2 loss : 0.021925
[02:17:03.769] iteration 25643 : model1 loss : 0.032345 model2 loss : 0.027044
[02:17:04.419] iteration 25644 : model1 loss : 0.139866 model2 loss : 0.138975
[02:17:05.075] iteration 25645 : model1 loss : 0.020215 model2 loss : 0.019773
[02:17:05.736] iteration 25646 : model1 loss : 0.017834 model2 loss : 0.017886
[02:17:06.398] iteration 25647 : model1 loss : 0.021865 model2 loss : 0.021069
[02:17:07.053] iteration 25648 : model1 loss : 0.017803 model2 loss : 0.016919
[02:17:07.710] iteration 25649 : model1 loss : 0.018285 model2 loss : 0.017808
[02:17:08.369] iteration 25650 : model1 loss : 0.030217 model2 loss : 0.036140
[02:17:09.060] iteration 25651 : model1 loss : 0.025584 model2 loss : 0.021947
[02:17:09.716] iteration 25652 : model1 loss : 0.020734 model2 loss : 0.021397
[02:17:10.371] iteration 25653 : model1 loss : 0.020658 model2 loss : 0.020112
[02:17:11.028] iteration 25654 : model1 loss : 0.013315 model2 loss : 0.015121
[02:17:11.692] iteration 25655 : model1 loss : 0.019855 model2 loss : 0.021780
[02:17:12.351] iteration 25656 : model1 loss : 0.018630 model2 loss : 0.020517
[02:17:13.008] iteration 25657 : model1 loss : 0.022384 model2 loss : 0.020795
[02:17:13.663] iteration 25658 : model1 loss : 0.016553 model2 loss : 0.018413
[02:17:14.332] iteration 25659 : model1 loss : 0.020979 model2 loss : 0.023847
[02:17:14.982] iteration 25660 : model1 loss : 0.023658 model2 loss : 0.027410
[02:17:15.643] iteration 25661 : model1 loss : 0.018824 model2 loss : 0.019613
[02:17:16.300] iteration 25662 : model1 loss : 0.015118 model2 loss : 0.016395
[02:17:16.960] iteration 25663 : model1 loss : 0.022213 model2 loss : 0.020590
[02:17:17.619] iteration 25664 : model1 loss : 0.022897 model2 loss : 0.022376
[02:17:18.273] iteration 25665 : model1 loss : 0.021543 model2 loss : 0.024183
[02:17:18.944] iteration 25666 : model1 loss : 0.020263 model2 loss : 0.021816
[02:17:19.597] iteration 25667 : model1 loss : 0.019493 model2 loss : 0.019386
[02:17:20.254] iteration 25668 : model1 loss : 0.046820 model2 loss : 0.041660
[02:17:20.917] iteration 25669 : model1 loss : 0.025201 model2 loss : 0.025595
[02:17:21.576] iteration 25670 : model1 loss : 0.017228 model2 loss : 0.017874
[02:17:22.268] iteration 25671 : model1 loss : 0.019873 model2 loss : 0.018968
[02:17:22.917] iteration 25672 : model1 loss : 0.021669 model2 loss : 0.021627
[02:17:23.588] iteration 25673 : model1 loss : 0.016237 model2 loss : 0.015442
[02:17:24.250] iteration 25674 : model1 loss : 0.017997 model2 loss : 0.020380
[02:17:24.905] iteration 25675 : model1 loss : 0.020726 model2 loss : 0.024026
[02:17:25.576] iteration 25676 : model1 loss : 0.017825 model2 loss : 0.019130
[02:17:26.229] iteration 25677 : model1 loss : 0.023202 model2 loss : 0.022402
[02:17:26.889] iteration 25678 : model1 loss : 0.015533 model2 loss : 0.016009
[02:17:27.554] iteration 25679 : model1 loss : 0.021366 model2 loss : 0.020895
[02:17:28.208] iteration 25680 : model1 loss : 0.021132 model2 loss : 0.024201
[02:17:28.871] iteration 25681 : model1 loss : 0.147952 model2 loss : 0.148747
[02:17:29.535] iteration 25682 : model1 loss : 0.014247 model2 loss : 0.015813
[02:17:30.192] iteration 25683 : model1 loss : 0.016521 model2 loss : 0.018702
[02:17:30.850] iteration 25684 : model1 loss : 0.023810 model2 loss : 0.022942
[02:17:31.509] iteration 25685 : model1 loss : 0.024539 model2 loss : 0.021985
[02:17:32.170] iteration 25686 : model1 loss : 0.018162 model2 loss : 0.020269
[02:17:32.822] iteration 25687 : model1 loss : 0.015558 model2 loss : 0.020646
[02:17:33.474] iteration 25688 : model1 loss : 0.020749 model2 loss : 0.021493
[02:17:34.136] iteration 25689 : model1 loss : 0.026589 model2 loss : 0.028559
[02:17:34.791] iteration 25690 : model1 loss : 0.013411 model2 loss : 0.013671
[02:17:35.465] iteration 25691 : model1 loss : 0.017272 model2 loss : 0.018166
[02:17:36.129] iteration 25692 : model1 loss : 0.019087 model2 loss : 0.020040
[02:17:36.792] iteration 25693 : model1 loss : 0.047586 model2 loss : 0.044176
[02:17:37.461] iteration 25694 : model1 loss : 0.020192 model2 loss : 0.020072
[02:17:38.114] iteration 25695 : model1 loss : 0.021084 model2 loss : 0.019574
[02:17:38.780] iteration 25696 : model1 loss : 0.017208 model2 loss : 0.017051
[02:17:39.432] iteration 25697 : model1 loss : 0.018944 model2 loss : 0.017960
[02:17:40.088] iteration 25698 : model1 loss : 0.019443 model2 loss : 0.019213
[02:17:40.750] iteration 25699 : model1 loss : 0.052496 model2 loss : 0.062580
[02:17:41.405] iteration 25700 : model1 loss : 0.023717 model2 loss : 0.022868
[02:17:42.101] iteration 25701 : model1 loss : 0.019755 model2 loss : 0.024141
[02:17:42.757] iteration 25702 : model1 loss : 0.018320 model2 loss : 0.016923
[02:17:43.420] iteration 25703 : model1 loss : 0.020842 model2 loss : 0.020095
[02:17:44.084] iteration 25704 : model1 loss : 0.019032 model2 loss : 0.020230
[02:17:44.748] iteration 25705 : model1 loss : 0.017623 model2 loss : 0.016777
[02:17:45.411] iteration 25706 : model1 loss : 0.017537 model2 loss : 0.016708
[02:17:46.070] iteration 25707 : model1 loss : 0.026199 model2 loss : 0.024672
[02:17:46.723] iteration 25708 : model1 loss : 0.019136 model2 loss : 0.018896
[02:17:47.393] iteration 25709 : model1 loss : 0.020386 model2 loss : 0.019331
[02:17:48.046] iteration 25710 : model1 loss : 0.020430 model2 loss : 0.019906
[02:17:48.715] iteration 25711 : model1 loss : 0.035534 model2 loss : 0.032279
[02:17:49.368] iteration 25712 : model1 loss : 0.018759 model2 loss : 0.018765
[02:17:50.026] iteration 25713 : model1 loss : 0.019554 model2 loss : 0.019433
[02:17:50.693] iteration 25714 : model1 loss : 0.018759 model2 loss : 0.019843
[02:17:51.351] iteration 25715 : model1 loss : 0.030590 model2 loss : 0.023231
[02:17:52.008] iteration 25716 : model1 loss : 0.026371 model2 loss : 0.023730
[02:17:52.680] iteration 25717 : model1 loss : 0.021624 model2 loss : 0.020181
[02:17:53.349] iteration 25718 : model1 loss : 0.021493 model2 loss : 0.020241
[02:17:54.017] iteration 25719 : model1 loss : 0.015691 model2 loss : 0.020682
[02:17:54.677] iteration 25720 : model1 loss : 0.027219 model2 loss : 0.024822
[02:17:55.350] iteration 25721 : model1 loss : 0.025564 model2 loss : 0.026148
[02:17:56.004] iteration 25722 : model1 loss : 0.022826 model2 loss : 0.026440
[02:17:56.657] iteration 25723 : model1 loss : 0.022069 model2 loss : 0.022807
[02:17:57.314] iteration 25724 : model1 loss : 0.024602 model2 loss : 0.024706
[02:17:57.986] iteration 25725 : model1 loss : 0.023938 model2 loss : 0.024274
[02:17:58.657] iteration 25726 : model1 loss : 0.021118 model2 loss : 0.018651
[02:17:59.323] iteration 25727 : model1 loss : 0.021578 model2 loss : 0.019757
[02:17:59.973] iteration 25728 : model1 loss : 0.018721 model2 loss : 0.017854
[02:18:00.643] iteration 25729 : model1 loss : 0.019335 model2 loss : 0.019347
[02:18:01.294] iteration 25730 : model1 loss : 0.021960 model2 loss : 0.025245
[02:18:01.959] iteration 25731 : model1 loss : 0.026864 model2 loss : 0.027565
[02:18:02.626] iteration 25732 : model1 loss : 0.034344 model2 loss : 0.027650
[02:18:03.274] iteration 25733 : model1 loss : 0.020837 model2 loss : 0.018849
[02:18:03.922] iteration 25734 : model1 loss : 0.018349 model2 loss : 0.019290
[02:18:04.581] iteration 25735 : model1 loss : 0.014733 model2 loss : 0.015184
[02:18:05.239] iteration 25736 : model1 loss : 0.020489 model2 loss : 0.023364
[02:18:05.882] iteration 25737 : model1 loss : 0.017694 model2 loss : 0.016773
[02:18:06.536] iteration 25738 : model1 loss : 0.035133 model2 loss : 0.026433
[02:18:07.197] iteration 25739 : model1 loss : 0.016841 model2 loss : 0.018338
[02:18:07.852] iteration 25740 : model1 loss : 0.023611 model2 loss : 0.022236
[02:18:08.500] iteration 25741 : model1 loss : 0.021450 model2 loss : 0.020574
[02:18:09.157] iteration 25742 : model1 loss : 0.018396 model2 loss : 0.018425
[02:18:09.819] iteration 25743 : model1 loss : 0.019562 model2 loss : 0.020857
[02:18:10.477] iteration 25744 : model1 loss : 0.014866 model2 loss : 0.015454
[02:18:11.141] iteration 25745 : model1 loss : 0.017774 model2 loss : 0.017955
[02:18:11.798] iteration 25746 : model1 loss : 0.021349 model2 loss : 0.021099
[02:18:12.467] iteration 25747 : model1 loss : 0.017297 model2 loss : 0.017572
[02:18:13.122] iteration 25748 : model1 loss : 0.018131 model2 loss : 0.019493
[02:18:13.786] iteration 25749 : model1 loss : 0.021225 model2 loss : 0.020658
[02:18:14.456] iteration 25750 : model1 loss : 0.019388 model2 loss : 0.020692
[02:18:15.157] iteration 25751 : model1 loss : 0.016120 model2 loss : 0.015928
[02:18:15.821] iteration 25752 : model1 loss : 0.019830 model2 loss : 0.022045
[02:18:16.480] iteration 25753 : model1 loss : 0.016153 model2 loss : 0.017689
[02:18:17.134] iteration 25754 : model1 loss : 0.015343 model2 loss : 0.016232
[02:18:17.786] iteration 25755 : model1 loss : 0.020358 model2 loss : 0.021110
[02:18:18.439] iteration 25756 : model1 loss : 0.019791 model2 loss : 0.018039
[02:18:19.098] iteration 25757 : model1 loss : 0.037913 model2 loss : 0.034103
[02:18:19.750] iteration 25758 : model1 loss : 0.018352 model2 loss : 0.019640
[02:18:20.416] iteration 25759 : model1 loss : 0.016859 model2 loss : 0.017324
[02:18:21.061] iteration 25760 : model1 loss : 0.016655 model2 loss : 0.014241
[02:18:21.722] iteration 25761 : model1 loss : 0.020903 model2 loss : 0.020207
[02:18:22.394] iteration 25762 : model1 loss : 0.018759 model2 loss : 0.017896
[02:18:23.053] iteration 25763 : model1 loss : 0.025561 model2 loss : 0.027625
[02:18:23.713] iteration 25764 : model1 loss : 0.019133 model2 loss : 0.014849
[02:18:24.369] iteration 25765 : model1 loss : 0.018665 model2 loss : 0.020958
[02:18:25.037] iteration 25766 : model1 loss : 0.028113 model2 loss : 0.029386
[02:18:25.698] iteration 25767 : model1 loss : 0.019112 model2 loss : 0.020503
[02:18:26.362] iteration 25768 : model1 loss : 0.014731 model2 loss : 0.016287
[02:18:27.024] iteration 25769 : model1 loss : 0.019327 model2 loss : 0.020315
[02:18:27.677] iteration 25770 : model1 loss : 0.017357 model2 loss : 0.017677
[02:18:28.338] iteration 25771 : model1 loss : 0.019652 model2 loss : 0.019310
[02:18:28.990] iteration 25772 : model1 loss : 0.020851 model2 loss : 0.018844
[02:18:29.646] iteration 25773 : model1 loss : 0.014591 model2 loss : 0.014835
[02:18:30.318] iteration 25774 : model1 loss : 0.016382 model2 loss : 0.016277
[02:18:30.964] iteration 25775 : model1 loss : 0.018913 model2 loss : 0.020651
[02:18:31.624] iteration 25776 : model1 loss : 0.022008 model2 loss : 0.021264
[02:18:32.281] iteration 25777 : model1 loss : 0.014875 model2 loss : 0.015358
[02:18:32.949] iteration 25778 : model1 loss : 0.019563 model2 loss : 0.018732
[02:18:33.614] iteration 25779 : model1 loss : 0.037671 model2 loss : 0.036298
[02:18:34.270] iteration 25780 : model1 loss : 0.022294 model2 loss : 0.024266
[02:18:34.927] iteration 25781 : model1 loss : 0.014865 model2 loss : 0.014909
[02:18:35.584] iteration 25782 : model1 loss : 0.014838 model2 loss : 0.015497
[02:18:36.237] iteration 25783 : model1 loss : 0.014903 model2 loss : 0.015413
[02:18:36.902] iteration 25784 : model1 loss : 0.023896 model2 loss : 0.022676
[02:18:37.559] iteration 25785 : model1 loss : 0.028405 model2 loss : 0.025907
[02:18:38.211] iteration 25786 : model1 loss : 0.020429 model2 loss : 0.022364
[02:18:38.876] iteration 25787 : model1 loss : 0.013755 model2 loss : 0.015147
[02:18:39.542] iteration 25788 : model1 loss : 0.020330 model2 loss : 0.021438
[02:18:40.200] iteration 25789 : model1 loss : 0.024669 model2 loss : 0.026511
[02:18:40.861] iteration 25790 : model1 loss : 0.028670 model2 loss : 0.026413
[02:18:41.520] iteration 25791 : model1 loss : 0.018935 model2 loss : 0.018506
[02:18:42.174] iteration 25792 : model1 loss : 0.017072 model2 loss : 0.017946
[02:18:42.852] iteration 25793 : model1 loss : 0.140865 model2 loss : 0.142342
[02:18:43.519] iteration 25794 : model1 loss : 0.019941 model2 loss : 0.021213
[02:18:44.183] iteration 25795 : model1 loss : 0.020549 model2 loss : 0.020027
[02:18:44.834] iteration 25796 : model1 loss : 0.017884 model2 loss : 0.016079
[02:18:45.491] iteration 25797 : model1 loss : 0.027888 model2 loss : 0.030538
[02:18:46.148] iteration 25798 : model1 loss : 0.022870 model2 loss : 0.021392
[02:18:46.814] iteration 25799 : model1 loss : 0.019897 model2 loss : 0.020266
[02:18:47.467] iteration 25800 : model1 loss : 0.023070 model2 loss : 0.022696
[02:19:05.358] iteration 25800 : model1_mean_dice : 0.879527 model1_mean_hd95 : 6.733276
[02:19:23.002] iteration 25800 : model2_mean_dice : 0.878355 model2_mean_hd95 : 4.856120
[02:19:23.685] iteration 25801 : model1 loss : 0.014489 model2 loss : 0.015340
[02:19:24.338] iteration 25802 : model1 loss : 0.029890 model2 loss : 0.027251
[02:19:24.985] iteration 25803 : model1 loss : 0.016667 model2 loss : 0.017542
[02:19:25.648] iteration 25804 : model1 loss : 0.023156 model2 loss : 0.026819
[02:19:26.307] iteration 25805 : model1 loss : 0.018526 model2 loss : 0.017656
[02:19:26.973] iteration 25806 : model1 loss : 0.026606 model2 loss : 0.031842
[02:19:27.645] iteration 25807 : model1 loss : 0.017214 model2 loss : 0.017197
[02:19:28.298] iteration 25808 : model1 loss : 0.017268 model2 loss : 0.018856
[02:19:28.955] iteration 25809 : model1 loss : 0.015311 model2 loss : 0.015443
[02:19:29.605] iteration 25810 : model1 loss : 0.019654 model2 loss : 0.019516
[02:19:30.259] iteration 25811 : model1 loss : 0.024029 model2 loss : 0.023608
[02:19:30.926] iteration 25812 : model1 loss : 0.017289 model2 loss : 0.017260
[02:19:31.572] iteration 25813 : model1 loss : 0.030465 model2 loss : 0.032374
[02:19:32.228] iteration 25814 : model1 loss : 0.016596 model2 loss : 0.018173
[02:19:32.881] iteration 25815 : model1 loss : 0.021329 model2 loss : 0.022584
[02:19:33.554] iteration 25816 : model1 loss : 0.020427 model2 loss : 0.020013
[02:19:34.206] iteration 25817 : model1 loss : 0.023483 model2 loss : 0.022693
[02:19:34.865] iteration 25818 : model1 loss : 0.144288 model2 loss : 0.146049
[02:19:35.526] iteration 25819 : model1 loss : 0.019090 model2 loss : 0.018772
[02:19:36.180] iteration 25820 : model1 loss : 0.018213 model2 loss : 0.017972
[02:19:36.844] iteration 25821 : model1 loss : 0.017308 model2 loss : 0.018695
[02:19:37.509] iteration 25822 : model1 loss : 0.025853 model2 loss : 0.026486
[02:19:38.165] iteration 25823 : model1 loss : 0.021643 model2 loss : 0.023355
[02:19:38.821] iteration 25824 : model1 loss : 0.019019 model2 loss : 0.018718
[02:19:39.484] iteration 25825 : model1 loss : 0.016999 model2 loss : 0.018191
[02:19:40.143] iteration 25826 : model1 loss : 0.145386 model2 loss : 0.145238
[02:19:40.800] iteration 25827 : model1 loss : 0.019801 model2 loss : 0.021068
[02:19:41.458] iteration 25828 : model1 loss : 0.017158 model2 loss : 0.016100
[02:19:42.116] iteration 25829 : model1 loss : 0.017410 model2 loss : 0.016393
[02:19:42.769] iteration 25830 : model1 loss : 0.019204 model2 loss : 0.019484
[02:19:43.433] iteration 25831 : model1 loss : 0.015016 model2 loss : 0.015187
[02:19:44.102] iteration 25832 : model1 loss : 0.020554 model2 loss : 0.021938
[02:19:44.753] iteration 25833 : model1 loss : 0.017305 model2 loss : 0.017012
[02:19:45.411] iteration 25834 : model1 loss : 0.024183 model2 loss : 0.023614
[02:19:46.058] iteration 25835 : model1 loss : 0.019816 model2 loss : 0.019948
[02:19:46.716] iteration 25836 : model1 loss : 0.017131 model2 loss : 0.017918
[02:19:47.378] iteration 25837 : model1 loss : 0.027738 model2 loss : 0.026122
[02:19:48.041] iteration 25838 : model1 loss : 0.020110 model2 loss : 0.017452
[02:19:48.712] iteration 25839 : model1 loss : 0.018477 model2 loss : 0.018087
[02:19:49.362] iteration 25840 : model1 loss : 0.018006 model2 loss : 0.017245
[02:19:50.023] iteration 25841 : model1 loss : 0.020809 model2 loss : 0.021803
[02:19:50.680] iteration 25842 : model1 loss : 0.018270 model2 loss : 0.019606
[02:19:51.342] iteration 25843 : model1 loss : 0.018561 model2 loss : 0.017770
[02:19:52.003] iteration 25844 : model1 loss : 0.018555 model2 loss : 0.018326
[02:19:52.662] iteration 25845 : model1 loss : 0.022084 model2 loss : 0.022002
[02:19:53.319] iteration 25846 : model1 loss : 0.020722 model2 loss : 0.024812
[02:19:54.003] iteration 25847 : model1 loss : 0.017531 model2 loss : 0.018217
[02:19:54.656] iteration 25848 : model1 loss : 0.020122 model2 loss : 0.020741
[02:19:55.316] iteration 25849 : model1 loss : 0.020182 model2 loss : 0.020592
[02:19:55.985] iteration 25850 : model1 loss : 0.020786 model2 loss : 0.022046
[02:19:56.677] iteration 25851 : model1 loss : 0.014706 model2 loss : 0.014800
[02:19:57.326] iteration 25852 : model1 loss : 0.018943 model2 loss : 0.019626
[02:19:57.973] iteration 25853 : model1 loss : 0.015622 model2 loss : 0.015678
[02:19:58.641] iteration 25854 : model1 loss : 0.017359 model2 loss : 0.016556
[02:19:59.297] iteration 25855 : model1 loss : 0.022991 model2 loss : 0.025010
[02:19:59.955] iteration 25856 : model1 loss : 0.020133 model2 loss : 0.020184
[02:20:00.627] iteration 25857 : model1 loss : 0.024628 model2 loss : 0.027783
[02:20:01.288] iteration 25858 : model1 loss : 0.019496 model2 loss : 0.019828
[02:20:01.954] iteration 25859 : model1 loss : 0.016831 model2 loss : 0.017413
[02:20:02.623] iteration 25860 : model1 loss : 0.023814 model2 loss : 0.028054
[02:20:03.275] iteration 25861 : model1 loss : 0.026683 model2 loss : 0.026500
[02:20:03.934] iteration 25862 : model1 loss : 0.018223 model2 loss : 0.020038
[02:20:04.592] iteration 25863 : model1 loss : 0.016058 model2 loss : 0.017057
[02:20:05.243] iteration 25864 : model1 loss : 0.018674 model2 loss : 0.017472
[02:20:05.912] iteration 25865 : model1 loss : 0.018346 model2 loss : 0.021840
[02:20:06.571] iteration 25866 : model1 loss : 0.019286 model2 loss : 0.019012
[02:20:07.251] iteration 25867 : model1 loss : 0.021871 model2 loss : 0.021793
[02:20:07.912] iteration 25868 : model1 loss : 0.024565 model2 loss : 0.024411
[02:20:08.578] iteration 25869 : model1 loss : 0.021480 model2 loss : 0.017817
[02:20:09.229] iteration 25870 : model1 loss : 0.022096 model2 loss : 0.021940
[02:20:09.885] iteration 25871 : model1 loss : 0.021358 model2 loss : 0.020496
[02:20:10.539] iteration 25872 : model1 loss : 0.019926 model2 loss : 0.020550
[02:20:11.193] iteration 25873 : model1 loss : 0.022401 model2 loss : 0.021418
[02:20:11.850] iteration 25874 : model1 loss : 0.032922 model2 loss : 0.032414
[02:20:12.520] iteration 25875 : model1 loss : 0.018609 model2 loss : 0.016562
[02:20:13.173] iteration 25876 : model1 loss : 0.021813 model2 loss : 0.020625
[02:20:13.828] iteration 25877 : model1 loss : 0.030021 model2 loss : 0.031612
[02:20:14.486] iteration 25878 : model1 loss : 0.017759 model2 loss : 0.017444
[02:20:15.148] iteration 25879 : model1 loss : 0.023447 model2 loss : 0.023706
[02:20:15.809] iteration 25880 : model1 loss : 0.018359 model2 loss : 0.018972
[02:20:16.468] iteration 25881 : model1 loss : 0.021756 model2 loss : 0.018661
[02:20:17.131] iteration 25882 : model1 loss : 0.021439 model2 loss : 0.021085
[02:20:17.780] iteration 25883 : model1 loss : 0.014635 model2 loss : 0.015748
[02:20:18.445] iteration 25884 : model1 loss : 0.017599 model2 loss : 0.017469
[02:20:19.107] iteration 25885 : model1 loss : 0.021236 model2 loss : 0.021263
[02:20:19.757] iteration 25886 : model1 loss : 0.019452 model2 loss : 0.018203
[02:20:20.415] iteration 25887 : model1 loss : 0.019631 model2 loss : 0.020319
[02:20:21.078] iteration 25888 : model1 loss : 0.067295 model2 loss : 0.062490
[02:20:21.729] iteration 25889 : model1 loss : 0.030131 model2 loss : 0.021110
[02:20:22.416] iteration 25890 : model1 loss : 0.020106 model2 loss : 0.020067
[02:20:23.078] iteration 25891 : model1 loss : 0.021040 model2 loss : 0.023506
[02:20:23.740] iteration 25892 : model1 loss : 0.022022 model2 loss : 0.023747
[02:20:24.413] iteration 25893 : model1 loss : 0.019143 model2 loss : 0.019431
[02:20:25.068] iteration 25894 : model1 loss : 0.022124 model2 loss : 0.022908
[02:20:25.724] iteration 25895 : model1 loss : 0.020459 model2 loss : 0.020013
[02:20:26.392] iteration 25896 : model1 loss : 0.018570 model2 loss : 0.019431
[02:20:27.072] iteration 25897 : model1 loss : 0.020534 model2 loss : 0.021339
[02:20:27.724] iteration 25898 : model1 loss : 0.018798 model2 loss : 0.017524
[02:20:28.386] iteration 25899 : model1 loss : 0.022389 model2 loss : 0.022407
[02:20:29.033] iteration 25900 : model1 loss : 0.024548 model2 loss : 0.025926
[02:20:29.734] iteration 25901 : model1 loss : 0.015917 model2 loss : 0.016978
[02:20:30.408] iteration 25902 : model1 loss : 0.018561 model2 loss : 0.018787
[02:20:31.054] iteration 25903 : model1 loss : 0.016139 model2 loss : 0.015240
[02:20:31.702] iteration 25904 : model1 loss : 0.017463 model2 loss : 0.016549
[02:20:32.363] iteration 25905 : model1 loss : 0.019663 model2 loss : 0.017891
[02:20:33.025] iteration 25906 : model1 loss : 0.019000 model2 loss : 0.020425
[02:20:33.686] iteration 25907 : model1 loss : 0.021306 model2 loss : 0.022877
[02:20:34.338] iteration 25908 : model1 loss : 0.015955 model2 loss : 0.015549
[02:20:35.004] iteration 25909 : model1 loss : 0.024408 model2 loss : 0.024913
[02:20:35.664] iteration 25910 : model1 loss : 0.016866 model2 loss : 0.017093
[02:20:36.347] iteration 25911 : model1 loss : 0.020882 model2 loss : 0.019795
[02:20:37.013] iteration 25912 : model1 loss : 0.021548 model2 loss : 0.021608
[02:20:37.675] iteration 25913 : model1 loss : 0.017227 model2 loss : 0.019099
[02:20:38.345] iteration 25914 : model1 loss : 0.017276 model2 loss : 0.017771
[02:20:39.005] iteration 25915 : model1 loss : 0.017295 model2 loss : 0.016462
[02:20:39.663] iteration 25916 : model1 loss : 0.019668 model2 loss : 0.017558
[02:20:40.327] iteration 25917 : model1 loss : 0.015845 model2 loss : 0.015393
[02:20:40.985] iteration 25918 : model1 loss : 0.018450 model2 loss : 0.019355
[02:20:41.650] iteration 25919 : model1 loss : 0.013277 model2 loss : 0.013775
[02:20:42.311] iteration 25920 : model1 loss : 0.023209 model2 loss : 0.022104
[02:20:42.965] iteration 25921 : model1 loss : 0.023358 model2 loss : 0.022695
[02:20:43.630] iteration 25922 : model1 loss : 0.018530 model2 loss : 0.021682
[02:20:44.292] iteration 25923 : model1 loss : 0.027502 model2 loss : 0.025538
[02:20:44.955] iteration 25924 : model1 loss : 0.025667 model2 loss : 0.023002
[02:20:45.606] iteration 25925 : model1 loss : 0.024705 model2 loss : 0.025984
[02:20:46.278] iteration 25926 : model1 loss : 0.026830 model2 loss : 0.027083
[02:20:46.945] iteration 25927 : model1 loss : 0.026402 model2 loss : 0.028148
[02:20:47.600] iteration 25928 : model1 loss : 0.037409 model2 loss : 0.044054
[02:20:48.256] iteration 25929 : model1 loss : 0.019402 model2 loss : 0.019385
[02:20:48.913] iteration 25930 : model1 loss : 0.018051 model2 loss : 0.018376
[02:20:49.569] iteration 25931 : model1 loss : 0.018960 model2 loss : 0.019508
[02:20:50.226] iteration 25932 : model1 loss : 0.023063 model2 loss : 0.024156
[02:20:50.892] iteration 25933 : model1 loss : 0.019108 model2 loss : 0.019463
[02:20:51.544] iteration 25934 : model1 loss : 0.018279 model2 loss : 0.019497
[02:20:52.193] iteration 25935 : model1 loss : 0.020135 model2 loss : 0.018932
[02:20:52.856] iteration 25936 : model1 loss : 0.021282 model2 loss : 0.020636
[02:20:53.523] iteration 25937 : model1 loss : 0.022925 model2 loss : 0.021685
[02:20:54.212] iteration 25938 : model1 loss : 0.024065 model2 loss : 0.023927
[02:20:54.877] iteration 25939 : model1 loss : 0.018395 model2 loss : 0.018056
[02:20:55.542] iteration 25940 : model1 loss : 0.020055 model2 loss : 0.019776
[02:20:56.193] iteration 25941 : model1 loss : 0.016407 model2 loss : 0.016061
[02:20:56.846] iteration 25942 : model1 loss : 0.014852 model2 loss : 0.013593
[02:20:57.502] iteration 25943 : model1 loss : 0.020976 model2 loss : 0.022946
[02:20:58.159] iteration 25944 : model1 loss : 0.022906 model2 loss : 0.024702
[02:20:58.837] iteration 25945 : model1 loss : 0.018129 model2 loss : 0.017401
[02:20:59.492] iteration 25946 : model1 loss : 0.019920 model2 loss : 0.018252
[02:21:00.154] iteration 25947 : model1 loss : 0.023899 model2 loss : 0.022162
[02:21:00.808] iteration 25948 : model1 loss : 0.013834 model2 loss : 0.015415
[02:21:01.473] iteration 25949 : model1 loss : 0.024342 model2 loss : 0.022726
[02:21:02.131] iteration 25950 : model1 loss : 0.018189 model2 loss : 0.017416
[02:21:02.815] iteration 25951 : model1 loss : 0.025286 model2 loss : 0.024988
[02:21:03.474] iteration 25952 : model1 loss : 0.020597 model2 loss : 0.019828
[02:21:04.143] iteration 25953 : model1 loss : 0.018118 model2 loss : 0.017311
[02:21:04.804] iteration 25954 : model1 loss : 0.020502 model2 loss : 0.019431
[02:21:05.456] iteration 25955 : model1 loss : 0.024213 model2 loss : 0.028001
[02:21:06.114] iteration 25956 : model1 loss : 0.019097 model2 loss : 0.018754
[02:21:06.787] iteration 25957 : model1 loss : 0.032113 model2 loss : 0.034893
[02:21:07.441] iteration 25958 : model1 loss : 0.017509 model2 loss : 0.016837
[02:21:08.106] iteration 25959 : model1 loss : 0.019169 model2 loss : 0.017630
[02:21:08.777] iteration 25960 : model1 loss : 0.016453 model2 loss : 0.016173
[02:21:09.443] iteration 25961 : model1 loss : 0.016808 model2 loss : 0.016049
[02:21:10.117] iteration 25962 : model1 loss : 0.018113 model2 loss : 0.018641
[02:21:10.771] iteration 25963 : model1 loss : 0.032907 model2 loss : 0.031572
[02:21:11.430] iteration 25964 : model1 loss : 0.017782 model2 loss : 0.018223
[02:21:12.091] iteration 25965 : model1 loss : 0.025236 model2 loss : 0.024205
[02:21:12.753] iteration 25966 : model1 loss : 0.026903 model2 loss : 0.025252
[02:21:13.425] iteration 25967 : model1 loss : 0.020698 model2 loss : 0.021285
[02:21:14.084] iteration 25968 : model1 loss : 0.045931 model2 loss : 0.042738
[02:21:14.740] iteration 25969 : model1 loss : 0.018608 model2 loss : 0.017136
[02:21:15.399] iteration 25970 : model1 loss : 0.017977 model2 loss : 0.017953
[02:21:16.050] iteration 25971 : model1 loss : 0.017102 model2 loss : 0.017125
[02:21:16.708] iteration 25972 : model1 loss : 0.014859 model2 loss : 0.014891
[02:21:17.366] iteration 25973 : model1 loss : 0.022268 model2 loss : 0.022508
[02:21:18.025] iteration 25974 : model1 loss : 0.018731 model2 loss : 0.024332
[02:21:18.681] iteration 25975 : model1 loss : 0.022193 model2 loss : 0.022196
[02:21:19.346] iteration 25976 : model1 loss : 0.020719 model2 loss : 0.020139
[02:21:20.009] iteration 25977 : model1 loss : 0.021587 model2 loss : 0.021761
[02:21:20.655] iteration 25978 : model1 loss : 0.017356 model2 loss : 0.017601
[02:21:21.316] iteration 25979 : model1 loss : 0.021814 model2 loss : 0.020275
[02:21:21.975] iteration 25980 : model1 loss : 0.022530 model2 loss : 0.021928
[02:21:22.635] iteration 25981 : model1 loss : 0.023404 model2 loss : 0.024921
[02:21:23.344] iteration 25982 : model1 loss : 0.021989 model2 loss : 0.021739
[02:21:24.096] iteration 25983 : model1 loss : 0.018985 model2 loss : 0.018479
[02:21:24.812] iteration 25984 : model1 loss : 0.137139 model2 loss : 0.136520
[02:21:25.475] iteration 25985 : model1 loss : 0.014905 model2 loss : 0.014606
[02:21:26.136] iteration 25986 : model1 loss : 0.016733 model2 loss : 0.018095
[02:21:26.809] iteration 25987 : model1 loss : 0.018658 model2 loss : 0.017112
[02:21:27.460] iteration 25988 : model1 loss : 0.015157 model2 loss : 0.015373
[02:21:28.123] iteration 25989 : model1 loss : 0.016382 model2 loss : 0.016982
[02:21:28.801] iteration 25990 : model1 loss : 0.020743 model2 loss : 0.020680
[02:21:29.455] iteration 25991 : model1 loss : 0.019293 model2 loss : 0.020030
[02:21:30.114] iteration 25992 : model1 loss : 0.022183 model2 loss : 0.022739
[02:21:30.776] iteration 25993 : model1 loss : 0.025283 model2 loss : 0.029256
[02:21:31.442] iteration 25994 : model1 loss : 0.023816 model2 loss : 0.024761
[02:21:32.100] iteration 25995 : model1 loss : 0.015300 model2 loss : 0.014941
[02:21:32.762] iteration 25996 : model1 loss : 0.016860 model2 loss : 0.019680
[02:21:33.427] iteration 25997 : model1 loss : 0.013308 model2 loss : 0.014217
[02:21:34.083] iteration 25998 : model1 loss : 0.023304 model2 loss : 0.024878
[02:21:34.741] iteration 25999 : model1 loss : 0.145314 model2 loss : 0.143372
[02:21:35.408] iteration 26000 : model1 loss : 0.025105 model2 loss : 0.028850
[02:21:53.436] iteration 26000 : model1_mean_dice : 0.875946 model1_mean_hd95 : 7.319800
[02:22:11.307] iteration 26000 : model2_mean_dice : 0.877700 model2_mean_hd95 : 5.659426
[02:22:11.974] iteration 26001 : model1 loss : 0.020931 model2 loss : 0.020837
[02:22:12.629] iteration 26002 : model1 loss : 0.019632 model2 loss : 0.023041
[02:22:13.300] iteration 26003 : model1 loss : 0.021447 model2 loss : 0.022075
[02:22:13.945] iteration 26004 : model1 loss : 0.020984 model2 loss : 0.021198
[02:22:14.605] iteration 26005 : model1 loss : 0.022755 model2 loss : 0.022262
[02:22:15.262] iteration 26006 : model1 loss : 0.014100 model2 loss : 0.015962
[02:22:15.915] iteration 26007 : model1 loss : 0.017598 model2 loss : 0.016258
[02:22:16.570] iteration 26008 : model1 loss : 0.016095 model2 loss : 0.016432
[02:22:17.217] iteration 26009 : model1 loss : 0.019388 model2 loss : 0.019222
[02:22:17.876] iteration 26010 : model1 loss : 0.023327 model2 loss : 0.024002
[02:22:18.528] iteration 26011 : model1 loss : 0.018365 model2 loss : 0.017318
[02:22:19.184] iteration 26012 : model1 loss : 0.019299 model2 loss : 0.017998
[02:22:19.842] iteration 26013 : model1 loss : 0.025585 model2 loss : 0.024010
[02:22:20.497] iteration 26014 : model1 loss : 0.017282 model2 loss : 0.018289
[02:22:21.163] iteration 26015 : model1 loss : 0.018436 model2 loss : 0.017343
[02:22:21.813] iteration 26016 : model1 loss : 0.019657 model2 loss : 0.019292
[02:22:22.475] iteration 26017 : model1 loss : 0.037309 model2 loss : 0.033598
[02:22:23.129] iteration 26018 : model1 loss : 0.022453 model2 loss : 0.020410
[02:22:23.800] iteration 26019 : model1 loss : 0.019630 model2 loss : 0.020442
[02:22:24.456] iteration 26020 : model1 loss : 0.019581 model2 loss : 0.018612
[02:22:25.101] iteration 26021 : model1 loss : 0.020834 model2 loss : 0.019110
[02:22:25.756] iteration 26022 : model1 loss : 0.019554 model2 loss : 0.018651
[02:22:26.404] iteration 26023 : model1 loss : 0.019736 model2 loss : 0.019066
[02:22:27.057] iteration 26024 : model1 loss : 0.016104 model2 loss : 0.019487
[02:22:27.719] iteration 26025 : model1 loss : 0.017855 model2 loss : 0.018665
[02:22:28.367] iteration 26026 : model1 loss : 0.024251 model2 loss : 0.019781
[02:22:29.030] iteration 26027 : model1 loss : 0.033713 model2 loss : 0.031443
[02:22:29.680] iteration 26028 : model1 loss : 0.015311 model2 loss : 0.016769
[02:22:30.334] iteration 26029 : model1 loss : 0.021301 model2 loss : 0.021668
[02:22:30.985] iteration 26030 : model1 loss : 0.019772 model2 loss : 0.017783
[02:22:31.649] iteration 26031 : model1 loss : 0.018697 model2 loss : 0.020714
[02:22:32.306] iteration 26032 : model1 loss : 0.017713 model2 loss : 0.019145
[02:22:32.960] iteration 26033 : model1 loss : 0.023683 model2 loss : 0.022867
[02:22:33.617] iteration 26034 : model1 loss : 0.018398 model2 loss : 0.019501
[02:22:34.268] iteration 26035 : model1 loss : 0.024151 model2 loss : 0.024792
[02:22:34.929] iteration 26036 : model1 loss : 0.016044 model2 loss : 0.015991
[02:22:35.586] iteration 26037 : model1 loss : 0.026420 model2 loss : 0.026993
[02:22:36.240] iteration 26038 : model1 loss : 0.027230 model2 loss : 0.023122
[02:22:36.885] iteration 26039 : model1 loss : 0.020500 model2 loss : 0.021160
[02:22:37.534] iteration 26040 : model1 loss : 0.017169 model2 loss : 0.017814
[02:22:38.184] iteration 26041 : model1 loss : 0.017700 model2 loss : 0.018610
[02:22:38.836] iteration 26042 : model1 loss : 0.018625 model2 loss : 0.019550
[02:22:39.489] iteration 26043 : model1 loss : 0.026427 model2 loss : 0.025492
[02:22:40.145] iteration 26044 : model1 loss : 0.015086 model2 loss : 0.016181
[02:22:40.818] iteration 26045 : model1 loss : 0.019850 model2 loss : 0.021211
[02:22:41.476] iteration 26046 : model1 loss : 0.016061 model2 loss : 0.016133
[02:22:42.129] iteration 26047 : model1 loss : 0.018530 model2 loss : 0.017673
[02:22:42.796] iteration 26048 : model1 loss : 0.019571 model2 loss : 0.021005
[02:22:43.448] iteration 26049 : model1 loss : 0.021127 model2 loss : 0.022546
[02:22:44.113] iteration 26050 : model1 loss : 0.016716 model2 loss : 0.016750
[02:22:44.817] iteration 26051 : model1 loss : 0.021209 model2 loss : 0.020022
[02:22:45.473] iteration 26052 : model1 loss : 0.018227 model2 loss : 0.017805
[02:22:46.133] iteration 26053 : model1 loss : 0.018832 model2 loss : 0.018712
[02:22:46.780] iteration 26054 : model1 loss : 0.017043 model2 loss : 0.021166
[02:22:47.443] iteration 26055 : model1 loss : 0.022738 model2 loss : 0.019254
[02:22:48.104] iteration 26056 : model1 loss : 0.119430 model2 loss : 0.083742
[02:22:48.769] iteration 26057 : model1 loss : 0.016823 model2 loss : 0.016955
[02:22:49.430] iteration 26058 : model1 loss : 0.020326 model2 loss : 0.019214
[02:22:50.086] iteration 26059 : model1 loss : 0.017931 model2 loss : 0.016769
[02:22:50.748] iteration 26060 : model1 loss : 0.018411 model2 loss : 0.018143
[02:22:51.426] iteration 26061 : model1 loss : 0.020064 model2 loss : 0.020946
[02:22:52.085] iteration 26062 : model1 loss : 0.021855 model2 loss : 0.022087
[02:22:52.741] iteration 26063 : model1 loss : 0.012025 model2 loss : 0.012395
[02:22:53.406] iteration 26064 : model1 loss : 0.017210 model2 loss : 0.017185
[02:22:54.064] iteration 26065 : model1 loss : 0.024349 model2 loss : 0.022848
[02:22:54.735] iteration 26066 : model1 loss : 0.021818 model2 loss : 0.022896
[02:22:55.440] iteration 26067 : model1 loss : 0.021225 model2 loss : 0.020602
[02:22:56.095] iteration 26068 : model1 loss : 0.032387 model2 loss : 0.033127
[02:22:56.765] iteration 26069 : model1 loss : 0.023090 model2 loss : 0.024455
[02:22:57.428] iteration 26070 : model1 loss : 0.024882 model2 loss : 0.024919
[02:22:58.089] iteration 26071 : model1 loss : 0.019387 model2 loss : 0.020190
[02:22:58.752] iteration 26072 : model1 loss : 0.018689 model2 loss : 0.018068
[02:22:59.422] iteration 26073 : model1 loss : 0.023367 model2 loss : 0.021521
[02:23:00.081] iteration 26074 : model1 loss : 0.021661 model2 loss : 0.019766
[02:23:00.743] iteration 26075 : model1 loss : 0.039191 model2 loss : 0.037830
[02:23:01.402] iteration 26076 : model1 loss : 0.017356 model2 loss : 0.016942
[02:23:02.068] iteration 26077 : model1 loss : 0.020408 model2 loss : 0.016833
[02:23:02.730] iteration 26078 : model1 loss : 0.014781 model2 loss : 0.013112
[02:23:03.414] iteration 26079 : model1 loss : 0.015421 model2 loss : 0.016444
[02:23:04.071] iteration 26080 : model1 loss : 0.019836 model2 loss : 0.020152
[02:23:04.744] iteration 26081 : model1 loss : 0.026086 model2 loss : 0.025074
[02:23:05.400] iteration 26082 : model1 loss : 0.026374 model2 loss : 0.024288
[02:23:06.057] iteration 26083 : model1 loss : 0.016569 model2 loss : 0.015170
[02:23:06.711] iteration 26084 : model1 loss : 0.030420 model2 loss : 0.029566
[02:23:07.377] iteration 26085 : model1 loss : 0.022201 model2 loss : 0.021496
[02:23:08.041] iteration 26086 : model1 loss : 0.014515 model2 loss : 0.015400
[02:23:08.696] iteration 26087 : model1 loss : 0.019719 model2 loss : 0.018676
[02:23:09.361] iteration 26088 : model1 loss : 0.016658 model2 loss : 0.017232
[02:23:10.026] iteration 26089 : model1 loss : 0.020769 model2 loss : 0.020889
[02:23:10.693] iteration 26090 : model1 loss : 0.022480 model2 loss : 0.024250
[02:23:11.356] iteration 26091 : model1 loss : 0.024003 model2 loss : 0.023798
[02:23:12.003] iteration 26092 : model1 loss : 0.013073 model2 loss : 0.013096
[02:23:12.651] iteration 26093 : model1 loss : 0.014587 model2 loss : 0.015605
[02:23:13.331] iteration 26094 : model1 loss : 0.018588 model2 loss : 0.018645
[02:23:13.985] iteration 26095 : model1 loss : 0.025716 model2 loss : 0.030605
[02:23:14.653] iteration 26096 : model1 loss : 0.024207 model2 loss : 0.024198
[02:23:15.328] iteration 26097 : model1 loss : 0.148013 model2 loss : 0.148969
[02:23:15.975] iteration 26098 : model1 loss : 0.019323 model2 loss : 0.018411
[02:23:16.636] iteration 26099 : model1 loss : 0.015988 model2 loss : 0.015299
[02:23:17.303] iteration 26100 : model1 loss : 0.027235 model2 loss : 0.026359
[02:23:17.997] iteration 26101 : model1 loss : 0.019926 model2 loss : 0.021241
[02:23:18.658] iteration 26102 : model1 loss : 0.023966 model2 loss : 0.024094
[02:23:19.322] iteration 26103 : model1 loss : 0.020359 model2 loss : 0.019517
[02:23:19.979] iteration 26104 : model1 loss : 0.020915 model2 loss : 0.019876
[02:23:20.639] iteration 26105 : model1 loss : 0.019672 model2 loss : 0.019513
[02:23:21.315] iteration 26106 : model1 loss : 0.032178 model2 loss : 0.040119
[02:23:21.971] iteration 26107 : model1 loss : 0.017328 model2 loss : 0.017186
[02:23:22.655] iteration 26108 : model1 loss : 0.020881 model2 loss : 0.020413
[02:23:23.321] iteration 26109 : model1 loss : 0.022366 model2 loss : 0.022517
[02:23:23.986] iteration 26110 : model1 loss : 0.018273 model2 loss : 0.019918
[02:23:24.646] iteration 26111 : model1 loss : 0.019430 model2 loss : 0.018625
[02:23:25.322] iteration 26112 : model1 loss : 0.020558 model2 loss : 0.020658
[02:23:25.977] iteration 26113 : model1 loss : 0.034314 model2 loss : 0.042879
[02:23:26.643] iteration 26114 : model1 loss : 0.018220 model2 loss : 0.020595
[02:23:27.306] iteration 26115 : model1 loss : 0.029331 model2 loss : 0.035170
[02:23:27.961] iteration 26116 : model1 loss : 0.019558 model2 loss : 0.019604
[02:23:28.619] iteration 26117 : model1 loss : 0.014816 model2 loss : 0.014418
[02:23:29.287] iteration 26118 : model1 loss : 0.020562 model2 loss : 0.020701
[02:23:29.947] iteration 26119 : model1 loss : 0.026349 model2 loss : 0.025467
[02:23:30.607] iteration 26120 : model1 loss : 0.016924 model2 loss : 0.018266
[02:23:31.276] iteration 26121 : model1 loss : 0.023926 model2 loss : 0.024606
[02:23:31.933] iteration 26122 : model1 loss : 0.030550 model2 loss : 0.025611
[02:23:32.605] iteration 26123 : model1 loss : 0.020583 model2 loss : 0.019771
[02:23:33.256] iteration 26124 : model1 loss : 0.051406 model2 loss : 0.040358
[02:23:33.915] iteration 26125 : model1 loss : 0.022103 model2 loss : 0.023036
[02:23:34.569] iteration 26126 : model1 loss : 0.025821 model2 loss : 0.027631
[02:23:35.228] iteration 26127 : model1 loss : 0.017066 model2 loss : 0.016634
[02:23:35.890] iteration 26128 : model1 loss : 0.032321 model2 loss : 0.033685
[02:23:36.555] iteration 26129 : model1 loss : 0.016945 model2 loss : 0.018736
[02:23:37.218] iteration 26130 : model1 loss : 0.031731 model2 loss : 0.035165
[02:23:37.871] iteration 26131 : model1 loss : 0.021842 model2 loss : 0.021955
[02:23:38.541] iteration 26132 : model1 loss : 0.024328 model2 loss : 0.023086
[02:23:39.198] iteration 26133 : model1 loss : 0.022534 model2 loss : 0.021486
[02:23:39.867] iteration 26134 : model1 loss : 0.020883 model2 loss : 0.019665
[02:23:40.540] iteration 26135 : model1 loss : 0.014088 model2 loss : 0.014414
[02:23:41.198] iteration 26136 : model1 loss : 0.031004 model2 loss : 0.031830
[02:23:41.865] iteration 26137 : model1 loss : 0.016402 model2 loss : 0.015895
[02:23:42.522] iteration 26138 : model1 loss : 0.017972 model2 loss : 0.019204
[02:23:43.183] iteration 26139 : model1 loss : 0.024036 model2 loss : 0.021915
[02:23:43.850] iteration 26140 : model1 loss : 0.019540 model2 loss : 0.019537
[02:23:44.539] iteration 26141 : model1 loss : 0.016156 model2 loss : 0.017304
[02:23:45.187] iteration 26142 : model1 loss : 0.024901 model2 loss : 0.022618
[02:23:45.865] iteration 26143 : model1 loss : 0.018659 model2 loss : 0.019564
[02:23:46.525] iteration 26144 : model1 loss : 0.020583 model2 loss : 0.021504
[02:23:47.181] iteration 26145 : model1 loss : 0.023724 model2 loss : 0.026571
[02:23:47.849] iteration 26146 : model1 loss : 0.020842 model2 loss : 0.023897
[02:23:48.517] iteration 26147 : model1 loss : 0.018227 model2 loss : 0.018284
[02:23:49.176] iteration 26148 : model1 loss : 0.012414 model2 loss : 0.012205
[02:23:49.833] iteration 26149 : model1 loss : 0.018582 model2 loss : 0.019581
[02:23:50.496] iteration 26150 : model1 loss : 0.019982 model2 loss : 0.019511
[02:23:51.181] iteration 26151 : model1 loss : 0.043414 model2 loss : 0.035178
[02:23:51.840] iteration 26152 : model1 loss : 0.020953 model2 loss : 0.022307
[02:23:52.512] iteration 26153 : model1 loss : 0.014051 model2 loss : 0.013915
[02:23:53.174] iteration 26154 : model1 loss : 0.015095 model2 loss : 0.014803
[02:23:53.828] iteration 26155 : model1 loss : 0.018656 model2 loss : 0.019212
[02:23:54.477] iteration 26156 : model1 loss : 0.020201 model2 loss : 0.019457
[02:23:55.156] iteration 26157 : model1 loss : 0.019575 model2 loss : 0.020748
[02:23:55.865] iteration 26158 : model1 loss : 0.018372 model2 loss : 0.018682
[02:23:56.525] iteration 26159 : model1 loss : 0.021358 model2 loss : 0.021344
[02:23:57.180] iteration 26160 : model1 loss : 0.018957 model2 loss : 0.017735
[02:23:57.834] iteration 26161 : model1 loss : 0.016653 model2 loss : 0.015092
[02:23:58.502] iteration 26162 : model1 loss : 0.020568 model2 loss : 0.018933
[02:23:59.174] iteration 26163 : model1 loss : 0.025323 model2 loss : 0.023340
[02:23:59.822] iteration 26164 : model1 loss : 0.018718 model2 loss : 0.022654
[02:24:00.491] iteration 26165 : model1 loss : 0.016271 model2 loss : 0.019283
[02:24:01.167] iteration 26166 : model1 loss : 0.020176 model2 loss : 0.018338
[02:24:01.822] iteration 26167 : model1 loss : 0.016012 model2 loss : 0.014984
[02:24:02.487] iteration 26168 : model1 loss : 0.023401 model2 loss : 0.022373
[02:24:03.146] iteration 26169 : model1 loss : 0.020334 model2 loss : 0.022671
[02:24:03.802] iteration 26170 : model1 loss : 0.021811 model2 loss : 0.024765
[02:24:04.460] iteration 26171 : model1 loss : 0.019567 model2 loss : 0.019923
[02:24:05.129] iteration 26172 : model1 loss : 0.019463 model2 loss : 0.018904
[02:24:05.782] iteration 26173 : model1 loss : 0.021067 model2 loss : 0.018700
[02:24:06.451] iteration 26174 : model1 loss : 0.020216 model2 loss : 0.019994
[02:24:07.105] iteration 26175 : model1 loss : 0.019781 model2 loss : 0.020665
[02:24:07.764] iteration 26176 : model1 loss : 0.021049 model2 loss : 0.020940
[02:24:08.414] iteration 26177 : model1 loss : 0.018188 model2 loss : 0.017707
[02:24:09.084] iteration 26178 : model1 loss : 0.020485 model2 loss : 0.021515
[02:24:09.736] iteration 26179 : model1 loss : 0.040784 model2 loss : 0.043371
[02:24:10.397] iteration 26180 : model1 loss : 0.022696 model2 loss : 0.023276
[02:24:11.054] iteration 26181 : model1 loss : 0.018203 model2 loss : 0.022250
[02:24:11.711] iteration 26182 : model1 loss : 0.019206 model2 loss : 0.019304
[02:24:12.374] iteration 26183 : model1 loss : 0.019999 model2 loss : 0.020867
[02:24:13.041] iteration 26184 : model1 loss : 0.018752 model2 loss : 0.017837
[02:24:13.695] iteration 26185 : model1 loss : 0.023090 model2 loss : 0.021045
[02:24:14.366] iteration 26186 : model1 loss : 0.019003 model2 loss : 0.018577
[02:24:15.017] iteration 26187 : model1 loss : 0.017896 model2 loss : 0.017179
[02:24:15.677] iteration 26188 : model1 loss : 0.026952 model2 loss : 0.023289
[02:24:16.346] iteration 26189 : model1 loss : 0.020781 model2 loss : 0.020643
[02:24:17.009] iteration 26190 : model1 loss : 0.019181 model2 loss : 0.018824
[02:24:17.665] iteration 26191 : model1 loss : 0.019154 model2 loss : 0.022145
[02:24:18.326] iteration 26192 : model1 loss : 0.018560 model2 loss : 0.018943
[02:24:18.998] iteration 26193 : model1 loss : 0.021972 model2 loss : 0.020070
[02:24:19.649] iteration 26194 : model1 loss : 0.019019 model2 loss : 0.020835
[02:24:20.306] iteration 26195 : model1 loss : 0.017448 model2 loss : 0.016520
[02:24:20.960] iteration 26196 : model1 loss : 0.018669 model2 loss : 0.017907
[02:24:21.617] iteration 26197 : model1 loss : 0.020025 model2 loss : 0.019192
[02:24:22.313] iteration 26198 : model1 loss : 0.015936 model2 loss : 0.015794
[02:24:22.992] iteration 26199 : model1 loss : 0.015909 model2 loss : 0.014696
[02:24:23.659] iteration 26200 : model1 loss : 0.140405 model2 loss : 0.141143
[02:24:41.451] iteration 26200 : model1_mean_dice : 0.876084 model1_mean_hd95 : 6.346788
[02:24:59.317] iteration 26200 : model2_mean_dice : 0.879286 model2_mean_hd95 : 4.432211
[02:24:59.998] iteration 26201 : model1 loss : 0.016665 model2 loss : 0.016834
[02:25:00.674] iteration 26202 : model1 loss : 0.019521 model2 loss : 0.021748
[02:25:01.328] iteration 26203 : model1 loss : 0.016002 model2 loss : 0.017652
[02:25:01.987] iteration 26204 : model1 loss : 0.038608 model2 loss : 0.045290
[02:25:02.640] iteration 26205 : model1 loss : 0.019784 model2 loss : 0.018736
[02:25:03.310] iteration 26206 : model1 loss : 0.024095 model2 loss : 0.021926
[02:25:03.959] iteration 26207 : model1 loss : 0.020879 model2 loss : 0.018893
[02:25:04.630] iteration 26208 : model1 loss : 0.019858 model2 loss : 0.019343
[02:25:05.283] iteration 26209 : model1 loss : 0.023129 model2 loss : 0.022347
[02:25:05.938] iteration 26210 : model1 loss : 0.018910 model2 loss : 0.019748
[02:25:06.603] iteration 26211 : model1 loss : 0.023986 model2 loss : 0.024622
[02:25:07.255] iteration 26212 : model1 loss : 0.016044 model2 loss : 0.014752
[02:25:07.917] iteration 26213 : model1 loss : 0.032838 model2 loss : 0.031465
[02:25:08.581] iteration 26214 : model1 loss : 0.018532 model2 loss : 0.019260
[02:25:09.239] iteration 26215 : model1 loss : 0.016239 model2 loss : 0.016915
[02:25:09.893] iteration 26216 : model1 loss : 0.016210 model2 loss : 0.018286
[02:25:10.548] iteration 26217 : model1 loss : 0.018706 model2 loss : 0.019051
[02:25:11.211] iteration 26218 : model1 loss : 0.027083 model2 loss : 0.022613
[02:25:11.859] iteration 26219 : model1 loss : 0.018950 model2 loss : 0.022622
[02:25:12.519] iteration 26220 : model1 loss : 0.020267 model2 loss : 0.020446
[02:25:13.176] iteration 26221 : model1 loss : 0.018159 model2 loss : 0.017139
[02:25:13.834] iteration 26222 : model1 loss : 0.032024 model2 loss : 0.023189
[02:25:14.487] iteration 26223 : model1 loss : 0.023274 model2 loss : 0.026274
[02:25:15.153] iteration 26224 : model1 loss : 0.017205 model2 loss : 0.018095
[02:25:15.818] iteration 26225 : model1 loss : 0.018087 model2 loss : 0.017049
[02:25:16.485] iteration 26226 : model1 loss : 0.020631 model2 loss : 0.021579
[02:25:17.138] iteration 26227 : model1 loss : 0.019388 model2 loss : 0.017812
[02:25:17.787] iteration 26228 : model1 loss : 0.024230 model2 loss : 0.022129
[02:25:18.447] iteration 26229 : model1 loss : 0.025007 model2 loss : 0.024466
[02:25:19.102] iteration 26230 : model1 loss : 0.023012 model2 loss : 0.023190
[02:25:19.767] iteration 26231 : model1 loss : 0.017252 model2 loss : 0.015341
[02:25:20.433] iteration 26232 : model1 loss : 0.032330 model2 loss : 0.032342
[02:25:21.097] iteration 26233 : model1 loss : 0.025013 model2 loss : 0.024045
[02:25:21.753] iteration 26234 : model1 loss : 0.017451 model2 loss : 0.017980
[02:25:22.401] iteration 26235 : model1 loss : 0.021111 model2 loss : 0.020496
[02:25:23.059] iteration 26236 : model1 loss : 0.021342 model2 loss : 0.022860
[02:25:23.711] iteration 26237 : model1 loss : 0.025502 model2 loss : 0.027566
[02:25:24.381] iteration 26238 : model1 loss : 0.027894 model2 loss : 0.028879
[02:25:25.040] iteration 26239 : model1 loss : 0.016559 model2 loss : 0.018507
[02:25:25.711] iteration 26240 : model1 loss : 0.032370 model2 loss : 0.030844
[02:25:26.376] iteration 26241 : model1 loss : 0.020444 model2 loss : 0.022066
[02:25:27.025] iteration 26242 : model1 loss : 0.142139 model2 loss : 0.140868
[02:25:27.675] iteration 26243 : model1 loss : 0.018970 model2 loss : 0.019832
[02:25:28.328] iteration 26244 : model1 loss : 0.018036 model2 loss : 0.017976
[02:25:28.984] iteration 26245 : model1 loss : 0.018475 model2 loss : 0.017429
[02:25:29.648] iteration 26246 : model1 loss : 0.020991 model2 loss : 0.018495
[02:25:30.305] iteration 26247 : model1 loss : 0.018829 model2 loss : 0.019730
[02:25:30.966] iteration 26248 : model1 loss : 0.019534 model2 loss : 0.017755
[02:25:31.619] iteration 26249 : model1 loss : 0.017668 model2 loss : 0.020142
[02:25:32.291] iteration 26250 : model1 loss : 0.030209 model2 loss : 0.028814
[02:25:32.978] iteration 26251 : model1 loss : 0.018450 model2 loss : 0.018920
[02:25:33.646] iteration 26252 : model1 loss : 0.015536 model2 loss : 0.015628
[02:25:34.300] iteration 26253 : model1 loss : 0.017201 model2 loss : 0.016772
[02:25:34.961] iteration 26254 : model1 loss : 0.021577 model2 loss : 0.022164
[02:25:35.618] iteration 26255 : model1 loss : 0.021464 model2 loss : 0.022892
[02:25:36.277] iteration 26256 : model1 loss : 0.030236 model2 loss : 0.030410
[02:25:36.938] iteration 26257 : model1 loss : 0.020169 model2 loss : 0.018494
[02:25:37.591] iteration 26258 : model1 loss : 0.025251 model2 loss : 0.024934
[02:25:38.259] iteration 26259 : model1 loss : 0.022075 model2 loss : 0.022862
[02:25:38.914] iteration 26260 : model1 loss : 0.022179 model2 loss : 0.020890
[02:25:39.582] iteration 26261 : model1 loss : 0.016703 model2 loss : 0.016229
[02:25:40.238] iteration 26262 : model1 loss : 0.023206 model2 loss : 0.023816
[02:25:40.892] iteration 26263 : model1 loss : 0.017024 model2 loss : 0.016668
[02:25:41.553] iteration 26264 : model1 loss : 0.022849 model2 loss : 0.019106
[02:25:42.214] iteration 26265 : model1 loss : 0.015860 model2 loss : 0.015844
[02:25:42.891] iteration 26266 : model1 loss : 0.022317 model2 loss : 0.025888
[02:25:43.547] iteration 26267 : model1 loss : 0.018862 model2 loss : 0.018305
[02:25:44.196] iteration 26268 : model1 loss : 0.017546 model2 loss : 0.019440
[02:25:44.855] iteration 26269 : model1 loss : 0.019543 model2 loss : 0.016909
[02:25:45.529] iteration 26270 : model1 loss : 0.019779 model2 loss : 0.018720
[02:25:46.198] iteration 26271 : model1 loss : 0.016587 model2 loss : 0.016203
[02:25:46.860] iteration 26272 : model1 loss : 0.015250 model2 loss : 0.014552
[02:25:47.522] iteration 26273 : model1 loss : 0.019346 model2 loss : 0.020325
[02:25:48.182] iteration 26274 : model1 loss : 0.021995 model2 loss : 0.022193
[02:25:48.852] iteration 26275 : model1 loss : 0.030030 model2 loss : 0.028010
[02:25:49.507] iteration 26276 : model1 loss : 0.019926 model2 loss : 0.019773
[02:25:50.171] iteration 26277 : model1 loss : 0.015401 model2 loss : 0.015699
[02:25:50.826] iteration 26278 : model1 loss : 0.022179 model2 loss : 0.022463
[02:25:51.488] iteration 26279 : model1 loss : 0.017733 model2 loss : 0.017850
[02:25:52.143] iteration 26280 : model1 loss : 0.020587 model2 loss : 0.021061
[02:25:52.803] iteration 26281 : model1 loss : 0.020358 model2 loss : 0.022590
[02:25:53.460] iteration 26282 : model1 loss : 0.026147 model2 loss : 0.026835
[02:25:54.118] iteration 26283 : model1 loss : 0.016160 model2 loss : 0.017652
[02:25:54.784] iteration 26284 : model1 loss : 0.024122 model2 loss : 0.017171
[02:25:55.439] iteration 26285 : model1 loss : 0.019175 model2 loss : 0.019986
[02:25:56.100] iteration 26286 : model1 loss : 0.020226 model2 loss : 0.019779
[02:25:56.789] iteration 26287 : model1 loss : 0.014899 model2 loss : 0.014260
[02:25:57.454] iteration 26288 : model1 loss : 0.023449 model2 loss : 0.024110
[02:25:58.115] iteration 26289 : model1 loss : 0.022136 model2 loss : 0.021383
[02:25:58.769] iteration 26290 : model1 loss : 0.019028 model2 loss : 0.020023
[02:25:59.440] iteration 26291 : model1 loss : 0.020355 model2 loss : 0.020320
[02:26:00.099] iteration 26292 : model1 loss : 0.017346 model2 loss : 0.016393
[02:26:00.759] iteration 26293 : model1 loss : 0.023978 model2 loss : 0.021368
[02:26:01.425] iteration 26294 : model1 loss : 0.143069 model2 loss : 0.144994
[02:26:02.086] iteration 26295 : model1 loss : 0.023047 model2 loss : 0.024315
[02:26:02.748] iteration 26296 : model1 loss : 0.053969 model2 loss : 0.050578
[02:26:03.408] iteration 26297 : model1 loss : 0.023009 model2 loss : 0.023664
[02:26:04.075] iteration 26298 : model1 loss : 0.020924 model2 loss : 0.021514
[02:26:04.729] iteration 26299 : model1 loss : 0.018070 model2 loss : 0.016472
[02:26:05.388] iteration 26300 : model1 loss : 0.018512 model2 loss : 0.018512
[02:26:06.099] iteration 26301 : model1 loss : 0.017776 model2 loss : 0.018451
[02:26:06.765] iteration 26302 : model1 loss : 0.022333 model2 loss : 0.022315
[02:26:07.429] iteration 26303 : model1 loss : 0.028763 model2 loss : 0.024200
[02:26:08.082] iteration 26304 : model1 loss : 0.020069 model2 loss : 0.021899
[02:26:08.741] iteration 26305 : model1 loss : 0.015438 model2 loss : 0.016883
[02:26:09.401] iteration 26306 : model1 loss : 0.017055 model2 loss : 0.017746
[02:26:10.066] iteration 26307 : model1 loss : 0.018742 model2 loss : 0.019001
[02:26:10.721] iteration 26308 : model1 loss : 0.017868 model2 loss : 0.017468
[02:26:11.379] iteration 26309 : model1 loss : 0.018735 model2 loss : 0.019419
[02:26:12.036] iteration 26310 : model1 loss : 0.022402 model2 loss : 0.024333
[02:26:12.695] iteration 26311 : model1 loss : 0.017298 model2 loss : 0.016345
[02:26:13.356] iteration 26312 : model1 loss : 0.021956 model2 loss : 0.022235
[02:26:14.007] iteration 26313 : model1 loss : 0.027783 model2 loss : 0.027434
[02:26:14.663] iteration 26314 : model1 loss : 0.023680 model2 loss : 0.025136
[02:26:15.313] iteration 26315 : model1 loss : 0.020120 model2 loss : 0.020811
[02:26:15.973] iteration 26316 : model1 loss : 0.018940 model2 loss : 0.020042
[02:26:16.644] iteration 26317 : model1 loss : 0.018502 model2 loss : 0.018543
[02:26:17.290] iteration 26318 : model1 loss : 0.017532 model2 loss : 0.016820
[02:26:17.960] iteration 26319 : model1 loss : 0.016865 model2 loss : 0.016330
[02:26:18.606] iteration 26320 : model1 loss : 0.020875 model2 loss : 0.021046
[02:26:19.260] iteration 26321 : model1 loss : 0.022259 model2 loss : 0.020290
[02:26:19.925] iteration 26322 : model1 loss : 0.017252 model2 loss : 0.014484
[02:26:20.585] iteration 26323 : model1 loss : 0.031370 model2 loss : 0.028180
[02:26:21.255] iteration 26324 : model1 loss : 0.028734 model2 loss : 0.027424
[02:26:21.929] iteration 26325 : model1 loss : 0.020272 model2 loss : 0.020508
[02:26:22.600] iteration 26326 : model1 loss : 0.025347 model2 loss : 0.021764
[02:26:23.254] iteration 26327 : model1 loss : 0.020737 model2 loss : 0.019710
[02:26:23.922] iteration 26328 : model1 loss : 0.017948 model2 loss : 0.017347
[02:26:24.580] iteration 26329 : model1 loss : 0.019527 model2 loss : 0.020574
[02:26:25.243] iteration 26330 : model1 loss : 0.021990 model2 loss : 0.020889
[02:26:25.908] iteration 26331 : model1 loss : 0.030976 model2 loss : 0.024638
[02:26:26.571] iteration 26332 : model1 loss : 0.017243 model2 loss : 0.017434
[02:26:27.227] iteration 26333 : model1 loss : 0.018231 model2 loss : 0.017774
[02:26:27.883] iteration 26334 : model1 loss : 0.016002 model2 loss : 0.016971
[02:26:28.547] iteration 26335 : model1 loss : 0.020646 model2 loss : 0.018751
[02:26:29.213] iteration 26336 : model1 loss : 0.023298 model2 loss : 0.025910
[02:26:29.878] iteration 26337 : model1 loss : 0.019955 model2 loss : 0.018606
[02:26:30.541] iteration 26338 : model1 loss : 0.019538 model2 loss : 0.018624
[02:26:31.195] iteration 26339 : model1 loss : 0.025720 model2 loss : 0.028529
[02:26:31.855] iteration 26340 : model1 loss : 0.022961 model2 loss : 0.022317
[02:26:32.519] iteration 26341 : model1 loss : 0.014499 model2 loss : 0.015951
[02:26:33.175] iteration 26342 : model1 loss : 0.013940 model2 loss : 0.014901
[02:26:33.836] iteration 26343 : model1 loss : 0.018655 model2 loss : 0.021486
[02:26:34.491] iteration 26344 : model1 loss : 0.027839 model2 loss : 0.028585
[02:26:35.150] iteration 26345 : model1 loss : 0.024638 model2 loss : 0.025111
[02:26:35.808] iteration 26346 : model1 loss : 0.026101 model2 loss : 0.029072
[02:26:36.472] iteration 26347 : model1 loss : 0.018697 model2 loss : 0.020030
[02:26:37.140] iteration 26348 : model1 loss : 0.019117 model2 loss : 0.017271
[02:26:37.792] iteration 26349 : model1 loss : 0.018101 model2 loss : 0.018179
[02:26:38.462] iteration 26350 : model1 loss : 0.019928 model2 loss : 0.020309
[02:26:39.160] iteration 26351 : model1 loss : 0.015452 model2 loss : 0.017000
[02:26:39.815] iteration 26352 : model1 loss : 0.018217 model2 loss : 0.018280
[02:26:40.467] iteration 26353 : model1 loss : 0.013389 model2 loss : 0.012899
[02:26:41.131] iteration 26354 : model1 loss : 0.026694 model2 loss : 0.025625
[02:26:41.785] iteration 26355 : model1 loss : 0.138174 model2 loss : 0.137590
[02:26:42.475] iteration 26356 : model1 loss : 0.021506 model2 loss : 0.020174
[02:26:43.142] iteration 26357 : model1 loss : 0.018633 model2 loss : 0.019073
[02:26:43.809] iteration 26358 : model1 loss : 0.023756 model2 loss : 0.022373
[02:26:44.488] iteration 26359 : model1 loss : 0.017127 model2 loss : 0.017466
[02:26:45.140] iteration 26360 : model1 loss : 0.035130 model2 loss : 0.034333
[02:26:45.808] iteration 26361 : model1 loss : 0.019497 model2 loss : 0.015789
[02:26:46.467] iteration 26362 : model1 loss : 0.020367 model2 loss : 0.020344
[02:26:47.129] iteration 26363 : model1 loss : 0.022938 model2 loss : 0.022125
[02:26:47.787] iteration 26364 : model1 loss : 0.025923 model2 loss : 0.024141
[02:26:48.461] iteration 26365 : model1 loss : 0.032854 model2 loss : 0.031401
[02:26:49.113] iteration 26366 : model1 loss : 0.022537 model2 loss : 0.023079
[02:26:49.780] iteration 26367 : model1 loss : 0.018997 model2 loss : 0.018885
[02:26:50.440] iteration 26368 : model1 loss : 0.021657 model2 loss : 0.019018
[02:26:51.111] iteration 26369 : model1 loss : 0.017434 model2 loss : 0.019018
[02:26:51.758] iteration 26370 : model1 loss : 0.019492 model2 loss : 0.018634
[02:26:52.424] iteration 26371 : model1 loss : 0.019365 model2 loss : 0.019699
[02:26:53.085] iteration 26372 : model1 loss : 0.029917 model2 loss : 0.026399
[02:26:53.740] iteration 26373 : model1 loss : 0.017538 model2 loss : 0.017557
[02:26:54.400] iteration 26374 : model1 loss : 0.016294 model2 loss : 0.016197
[02:26:55.059] iteration 26375 : model1 loss : 0.017871 model2 loss : 0.018488
[02:26:55.728] iteration 26376 : model1 loss : 0.017411 model2 loss : 0.017289
[02:26:56.383] iteration 26377 : model1 loss : 0.018394 model2 loss : 0.019239
[02:26:57.098] iteration 26378 : model1 loss : 0.026370 model2 loss : 0.024744
[02:26:57.764] iteration 26379 : model1 loss : 0.017563 model2 loss : 0.016597
[02:26:58.423] iteration 26380 : model1 loss : 0.021495 model2 loss : 0.021737
[02:26:59.082] iteration 26381 : model1 loss : 0.025809 model2 loss : 0.019218
[02:26:59.745] iteration 26382 : model1 loss : 0.027346 model2 loss : 0.026964
[02:27:00.396] iteration 26383 : model1 loss : 0.019705 model2 loss : 0.020529
[02:27:01.056] iteration 26384 : model1 loss : 0.025218 model2 loss : 0.025571
[02:27:01.712] iteration 26385 : model1 loss : 0.022813 model2 loss : 0.020241
[02:27:02.371] iteration 26386 : model1 loss : 0.015676 model2 loss : 0.014264
[02:27:03.013] iteration 26387 : model1 loss : 0.063208 model2 loss : 0.055441
[02:27:03.672] iteration 26388 : model1 loss : 0.021010 model2 loss : 0.022128
[02:27:04.331] iteration 26389 : model1 loss : 0.018196 model2 loss : 0.018450
[02:27:04.985] iteration 26390 : model1 loss : 0.031005 model2 loss : 0.034674
[02:27:05.642] iteration 26391 : model1 loss : 0.018871 model2 loss : 0.018736
[02:27:06.291] iteration 26392 : model1 loss : 0.024913 model2 loss : 0.026614
[02:27:06.964] iteration 26393 : model1 loss : 0.021561 model2 loss : 0.022571
[02:27:07.616] iteration 26394 : model1 loss : 0.022582 model2 loss : 0.020740
[02:27:08.297] iteration 26395 : model1 loss : 0.022020 model2 loss : 0.022567
[02:27:08.958] iteration 26396 : model1 loss : 0.019265 model2 loss : 0.020266
[02:27:09.614] iteration 26397 : model1 loss : 0.020424 model2 loss : 0.019140
[02:27:10.271] iteration 26398 : model1 loss : 0.022335 model2 loss : 0.021840
[02:27:10.931] iteration 26399 : model1 loss : 0.025363 model2 loss : 0.022764
[02:27:11.595] iteration 26400 : model1 loss : 0.016819 model2 loss : 0.017587
[02:27:29.426] iteration 26400 : model1_mean_dice : 0.877538 model1_mean_hd95 : 7.223280
[02:27:47.056] iteration 26400 : model2_mean_dice : 0.879484 model2_mean_hd95 : 4.554930
[02:27:47.736] iteration 26401 : model1 loss : 0.019770 model2 loss : 0.021597
[02:27:48.393] iteration 26402 : model1 loss : 0.015422 model2 loss : 0.014923
[02:27:49.043] iteration 26403 : model1 loss : 0.024217 model2 loss : 0.026575
[02:27:49.705] iteration 26404 : model1 loss : 0.019770 model2 loss : 0.019230
[02:27:50.356] iteration 26405 : model1 loss : 0.137936 model2 loss : 0.138109
[02:27:51.018] iteration 26406 : model1 loss : 0.016423 model2 loss : 0.017403
[02:27:51.665] iteration 26407 : model1 loss : 0.019281 model2 loss : 0.019684
[02:27:52.315] iteration 26408 : model1 loss : 0.018914 model2 loss : 0.018952
[02:27:52.970] iteration 26409 : model1 loss : 0.020344 model2 loss : 0.019049
[02:27:53.623] iteration 26410 : model1 loss : 0.021887 model2 loss : 0.023031
[02:27:54.287] iteration 26411 : model1 loss : 0.018075 model2 loss : 0.017902
[02:27:54.926] iteration 26412 : model1 loss : 0.021043 model2 loss : 0.020624
[02:27:55.588] iteration 26413 : model1 loss : 0.016384 model2 loss : 0.015342
[02:27:56.243] iteration 26414 : model1 loss : 0.016475 model2 loss : 0.017822
[02:27:56.894] iteration 26415 : model1 loss : 0.015466 model2 loss : 0.015780
[02:27:57.577] iteration 26416 : model1 loss : 0.016225 model2 loss : 0.017252
[02:27:58.229] iteration 26417 : model1 loss : 0.019886 model2 loss : 0.019252
[02:27:58.883] iteration 26418 : model1 loss : 0.020641 model2 loss : 0.021330
[02:27:59.539] iteration 26419 : model1 loss : 0.021755 model2 loss : 0.021811
[02:28:00.192] iteration 26420 : model1 loss : 0.025583 model2 loss : 0.026696
[02:28:00.847] iteration 26421 : model1 loss : 0.031706 model2 loss : 0.022914
[02:28:01.510] iteration 26422 : model1 loss : 0.020733 model2 loss : 0.019525
[02:28:02.165] iteration 26423 : model1 loss : 0.019267 model2 loss : 0.018791
[02:28:02.828] iteration 26424 : model1 loss : 0.019619 model2 loss : 0.020672
[02:28:03.473] iteration 26425 : model1 loss : 0.018746 model2 loss : 0.021037
[02:28:04.136] iteration 26426 : model1 loss : 0.017834 model2 loss : 0.018233
[02:28:04.787] iteration 26427 : model1 loss : 0.022573 model2 loss : 0.022678
[02:28:05.448] iteration 26428 : model1 loss : 0.031589 model2 loss : 0.036293
[02:28:06.103] iteration 26429 : model1 loss : 0.019420 model2 loss : 0.016765
[02:28:06.754] iteration 26430 : model1 loss : 0.015938 model2 loss : 0.017406
[02:28:07.415] iteration 26431 : model1 loss : 0.014669 model2 loss : 0.016214
[02:28:08.067] iteration 26432 : model1 loss : 0.027055 model2 loss : 0.028876
[02:28:08.733] iteration 26433 : model1 loss : 0.021815 model2 loss : 0.021009
[02:28:09.397] iteration 26434 : model1 loss : 0.021577 model2 loss : 0.020331
[02:28:10.051] iteration 26435 : model1 loss : 0.025803 model2 loss : 0.021257
[02:28:10.719] iteration 26436 : model1 loss : 0.018180 model2 loss : 0.016852
[02:28:11.374] iteration 26437 : model1 loss : 0.024672 model2 loss : 0.025712
[02:28:12.029] iteration 26438 : model1 loss : 0.024224 model2 loss : 0.024989
[02:28:12.695] iteration 26439 : model1 loss : 0.020480 model2 loss : 0.021080
[02:28:13.343] iteration 26440 : model1 loss : 0.018001 model2 loss : 0.018874
[02:28:14.011] iteration 26441 : model1 loss : 0.019835 model2 loss : 0.018698
[02:28:14.663] iteration 26442 : model1 loss : 0.018588 model2 loss : 0.019630
[02:28:15.318] iteration 26443 : model1 loss : 0.015188 model2 loss : 0.015800
[02:28:15.977] iteration 26444 : model1 loss : 0.018562 model2 loss : 0.017915
[02:28:16.623] iteration 26445 : model1 loss : 0.017888 model2 loss : 0.017900
[02:28:17.287] iteration 26446 : model1 loss : 0.016953 model2 loss : 0.015089
[02:28:17.945] iteration 26447 : model1 loss : 0.018124 model2 loss : 0.015151
[02:28:18.616] iteration 26448 : model1 loss : 0.017287 model2 loss : 0.017370
[02:28:19.276] iteration 26449 : model1 loss : 0.027898 model2 loss : 0.026656
[02:28:19.927] iteration 26450 : model1 loss : 0.015441 model2 loss : 0.014988
[02:28:20.621] iteration 26451 : model1 loss : 0.017527 model2 loss : 0.016174
[02:28:21.286] iteration 26452 : model1 loss : 0.029213 model2 loss : 0.030212
[02:28:21.942] iteration 26453 : model1 loss : 0.016236 model2 loss : 0.017725
[02:28:22.595] iteration 26454 : model1 loss : 0.018140 model2 loss : 0.020257
[02:28:23.247] iteration 26455 : model1 loss : 0.018311 model2 loss : 0.018139
[02:28:23.926] iteration 26456 : model1 loss : 0.018096 model2 loss : 0.018334
[02:28:24.582] iteration 26457 : model1 loss : 0.029912 model2 loss : 0.033606
[02:28:25.242] iteration 26458 : model1 loss : 0.022796 model2 loss : 0.023025
[02:28:25.903] iteration 26459 : model1 loss : 0.020266 model2 loss : 0.021389
[02:28:26.575] iteration 26460 : model1 loss : 0.020939 model2 loss : 0.019497
[02:28:27.231] iteration 26461 : model1 loss : 0.021735 model2 loss : 0.021086
[02:28:27.881] iteration 26462 : model1 loss : 0.014547 model2 loss : 0.014636
[02:28:28.541] iteration 26463 : model1 loss : 0.022118 model2 loss : 0.019491
[02:28:29.192] iteration 26464 : model1 loss : 0.015327 model2 loss : 0.016576
[02:28:29.846] iteration 26465 : model1 loss : 0.023114 model2 loss : 0.022018
[02:28:30.508] iteration 26466 : model1 loss : 0.032198 model2 loss : 0.024023
[02:28:31.166] iteration 26467 : model1 loss : 0.017875 model2 loss : 0.017880
[02:28:31.828] iteration 26468 : model1 loss : 0.034270 model2 loss : 0.039524
[02:28:32.504] iteration 26469 : model1 loss : 0.020364 model2 loss : 0.018953
[02:28:33.186] iteration 26470 : model1 loss : 0.019036 model2 loss : 0.018081
[02:28:33.846] iteration 26471 : model1 loss : 0.023520 model2 loss : 0.023313
[02:28:34.493] iteration 26472 : model1 loss : 0.016524 model2 loss : 0.018507
[02:28:35.152] iteration 26473 : model1 loss : 0.021278 model2 loss : 0.023113
[02:28:35.808] iteration 26474 : model1 loss : 0.037298 model2 loss : 0.035459
[02:28:36.475] iteration 26475 : model1 loss : 0.017137 model2 loss : 0.017132
[02:28:37.135] iteration 26476 : model1 loss : 0.028847 model2 loss : 0.029250
[02:28:37.793] iteration 26477 : model1 loss : 0.017147 model2 loss : 0.017561
[02:28:38.448] iteration 26478 : model1 loss : 0.023189 model2 loss : 0.024391
[02:28:39.100] iteration 26479 : model1 loss : 0.023307 model2 loss : 0.021497
[02:28:39.754] iteration 26480 : model1 loss : 0.017996 model2 loss : 0.016913
[02:28:40.423] iteration 26481 : model1 loss : 0.025774 model2 loss : 0.022986
[02:28:41.078] iteration 26482 : model1 loss : 0.017711 model2 loss : 0.019049
[02:28:41.739] iteration 26483 : model1 loss : 0.014793 model2 loss : 0.015034
[02:28:42.400] iteration 26484 : model1 loss : 0.016414 model2 loss : 0.015410
[02:28:43.065] iteration 26485 : model1 loss : 0.024537 model2 loss : 0.022285
[02:28:43.725] iteration 26486 : model1 loss : 0.019612 model2 loss : 0.019352
[02:28:44.382] iteration 26487 : model1 loss : 0.020568 model2 loss : 0.020321
[02:28:45.038] iteration 26488 : model1 loss : 0.019302 model2 loss : 0.021247
[02:28:45.684] iteration 26489 : model1 loss : 0.022243 model2 loss : 0.022661
[02:28:46.348] iteration 26490 : model1 loss : 0.020252 model2 loss : 0.021288
[02:28:47.006] iteration 26491 : model1 loss : 0.016775 model2 loss : 0.014095
[02:28:47.673] iteration 26492 : model1 loss : 0.018523 model2 loss : 0.019935
[02:28:48.344] iteration 26493 : model1 loss : 0.019229 model2 loss : 0.019976
[02:28:49.006] iteration 26494 : model1 loss : 0.017742 model2 loss : 0.018580
[02:28:49.661] iteration 26495 : model1 loss : 0.027304 model2 loss : 0.023452
[02:28:50.325] iteration 26496 : model1 loss : 0.020099 model2 loss : 0.019854
[02:28:50.979] iteration 26497 : model1 loss : 0.020476 model2 loss : 0.022090
[02:28:51.631] iteration 26498 : model1 loss : 0.020929 model2 loss : 0.020059
[02:28:52.291] iteration 26499 : model1 loss : 0.019835 model2 loss : 0.019447
[02:28:52.965] iteration 26500 : model1 loss : 0.023964 model2 loss : 0.025409
[02:28:53.658] iteration 26501 : model1 loss : 0.029330 model2 loss : 0.031516
[02:28:54.340] iteration 26502 : model1 loss : 0.016038 model2 loss : 0.016736
[02:28:55.006] iteration 26503 : model1 loss : 0.021473 model2 loss : 0.024668
[02:28:55.664] iteration 26504 : model1 loss : 0.025341 model2 loss : 0.023693
[02:28:56.318] iteration 26505 : model1 loss : 0.023137 model2 loss : 0.023967
[02:28:56.976] iteration 26506 : model1 loss : 0.026295 model2 loss : 0.029922
[02:28:57.650] iteration 26507 : model1 loss : 0.015320 model2 loss : 0.016226
[02:28:58.320] iteration 26508 : model1 loss : 0.026004 model2 loss : 0.025960
[02:28:58.977] iteration 26509 : model1 loss : 0.018744 model2 loss : 0.019722
[02:28:59.642] iteration 26510 : model1 loss : 0.018682 model2 loss : 0.019966
[02:29:00.309] iteration 26511 : model1 loss : 0.023690 model2 loss : 0.024711
[02:29:00.958] iteration 26512 : model1 loss : 0.019781 model2 loss : 0.019687
[02:29:01.612] iteration 26513 : model1 loss : 0.021854 model2 loss : 0.024250
[02:29:02.269] iteration 26514 : model1 loss : 0.024974 model2 loss : 0.021814
[02:29:02.929] iteration 26515 : model1 loss : 0.013071 model2 loss : 0.012779
[02:29:03.591] iteration 26516 : model1 loss : 0.020578 model2 loss : 0.018440
[02:29:04.257] iteration 26517 : model1 loss : 0.014955 model2 loss : 0.013346
[02:29:04.912] iteration 26518 : model1 loss : 0.027015 model2 loss : 0.024091
[02:29:05.572] iteration 26519 : model1 loss : 0.016950 model2 loss : 0.017028
[02:29:06.230] iteration 26520 : model1 loss : 0.015369 model2 loss : 0.016414
[02:29:06.885] iteration 26521 : model1 loss : 0.018079 model2 loss : 0.017945
[02:29:07.537] iteration 26522 : model1 loss : 0.021802 model2 loss : 0.021554
[02:29:08.196] iteration 26523 : model1 loss : 0.018728 model2 loss : 0.017294
[02:29:08.850] iteration 26524 : model1 loss : 0.018639 model2 loss : 0.018168
[02:29:09.512] iteration 26525 : model1 loss : 0.018257 model2 loss : 0.018794
[02:29:10.179] iteration 26526 : model1 loss : 0.027941 model2 loss : 0.024114
[02:29:10.830] iteration 26527 : model1 loss : 0.020851 model2 loss : 0.018155
[02:29:11.486] iteration 26528 : model1 loss : 0.029198 model2 loss : 0.032028
[02:29:12.145] iteration 26529 : model1 loss : 0.144331 model2 loss : 0.141378
[02:29:12.799] iteration 26530 : model1 loss : 0.019601 model2 loss : 0.022163
[02:29:13.465] iteration 26531 : model1 loss : 0.018075 model2 loss : 0.017576
[02:29:14.120] iteration 26532 : model1 loss : 0.015925 model2 loss : 0.017586
[02:29:14.785] iteration 26533 : model1 loss : 0.023910 model2 loss : 0.024508
[02:29:15.450] iteration 26534 : model1 loss : 0.023873 model2 loss : 0.023386
[02:29:16.124] iteration 26535 : model1 loss : 0.019376 model2 loss : 0.019208
[02:29:16.790] iteration 26536 : model1 loss : 0.016535 model2 loss : 0.015958
[02:29:17.450] iteration 26537 : model1 loss : 0.018308 model2 loss : 0.019355
[02:29:18.110] iteration 26538 : model1 loss : 0.017720 model2 loss : 0.018873
[02:29:18.770] iteration 26539 : model1 loss : 0.019791 model2 loss : 0.018267
[02:29:19.443] iteration 26540 : model1 loss : 0.016869 model2 loss : 0.016460
[02:29:20.116] iteration 26541 : model1 loss : 0.026579 model2 loss : 0.025692
[02:29:20.775] iteration 26542 : model1 loss : 0.017699 model2 loss : 0.018959
[02:29:21.447] iteration 26543 : model1 loss : 0.018848 model2 loss : 0.022082
[02:29:22.105] iteration 26544 : model1 loss : 0.021374 model2 loss : 0.022660
[02:29:22.770] iteration 26545 : model1 loss : 0.029388 model2 loss : 0.032731
[02:29:23.431] iteration 26546 : model1 loss : 0.023528 model2 loss : 0.023814
[02:29:24.097] iteration 26547 : model1 loss : 0.018405 model2 loss : 0.020446
[02:29:24.765] iteration 26548 : model1 loss : 0.018917 model2 loss : 0.019357
[02:29:25.426] iteration 26549 : model1 loss : 0.021293 model2 loss : 0.021974
[02:29:26.086] iteration 26550 : model1 loss : 0.021493 model2 loss : 0.021304
[02:29:26.789] iteration 26551 : model1 loss : 0.017491 model2 loss : 0.018081
[02:29:27.450] iteration 26552 : model1 loss : 0.020097 model2 loss : 0.017397
[02:29:28.112] iteration 26553 : model1 loss : 0.018268 model2 loss : 0.018933
[02:29:28.786] iteration 26554 : model1 loss : 0.017457 model2 loss : 0.018960
[02:29:29.443] iteration 26555 : model1 loss : 0.014776 model2 loss : 0.016410
[02:29:30.102] iteration 26556 : model1 loss : 0.021955 model2 loss : 0.021787
[02:29:30.759] iteration 26557 : model1 loss : 0.025286 model2 loss : 0.022264
[02:29:31.414] iteration 26558 : model1 loss : 0.023496 model2 loss : 0.022912
[02:29:32.083] iteration 26559 : model1 loss : 0.015493 model2 loss : 0.015480
[02:29:32.749] iteration 26560 : model1 loss : 0.032657 model2 loss : 0.030165
[02:29:33.415] iteration 26561 : model1 loss : 0.026476 model2 loss : 0.025389
[02:29:34.096] iteration 26562 : model1 loss : 0.026235 model2 loss : 0.024735
[02:29:34.743] iteration 26563 : model1 loss : 0.016274 model2 loss : 0.015438
[02:29:35.402] iteration 26564 : model1 loss : 0.018114 model2 loss : 0.017634
[02:29:36.053] iteration 26565 : model1 loss : 0.022032 model2 loss : 0.022622
[02:29:36.710] iteration 26566 : model1 loss : 0.029026 model2 loss : 0.026187
[02:29:37.363] iteration 26567 : model1 loss : 0.016512 model2 loss : 0.018196
[02:29:38.036] iteration 26568 : model1 loss : 0.022321 model2 loss : 0.023871
[02:29:38.717] iteration 26569 : model1 loss : 0.022453 model2 loss : 0.020889
[02:29:39.380] iteration 26570 : model1 loss : 0.017491 model2 loss : 0.017455
[02:29:40.038] iteration 26571 : model1 loss : 0.016869 model2 loss : 0.016849
[02:29:40.701] iteration 26572 : model1 loss : 0.020505 model2 loss : 0.017961
[02:29:41.353] iteration 26573 : model1 loss : 0.047751 model2 loss : 0.032100
[02:29:42.014] iteration 26574 : model1 loss : 0.021566 model2 loss : 0.019754
[02:29:42.676] iteration 26575 : model1 loss : 0.018039 model2 loss : 0.020590
[02:29:43.368] iteration 26576 : model1 loss : 0.015778 model2 loss : 0.016267
[02:29:44.022] iteration 26577 : model1 loss : 0.023873 model2 loss : 0.023981
[02:29:44.682] iteration 26578 : model1 loss : 0.016222 model2 loss : 0.016613
[02:29:45.346] iteration 26579 : model1 loss : 0.051758 model2 loss : 0.047528
[02:29:46.005] iteration 26580 : model1 loss : 0.015897 model2 loss : 0.015143
[02:29:46.682] iteration 26581 : model1 loss : 0.018591 model2 loss : 0.019359
[02:29:47.343] iteration 26582 : model1 loss : 0.020672 model2 loss : 0.017998
[02:29:48.009] iteration 26583 : model1 loss : 0.031020 model2 loss : 0.029793
[02:29:48.684] iteration 26584 : model1 loss : 0.021172 model2 loss : 0.021453
[02:29:49.338] iteration 26585 : model1 loss : 0.018038 model2 loss : 0.018529
[02:29:50.005] iteration 26586 : model1 loss : 0.017892 model2 loss : 0.016369
[02:29:50.664] iteration 26587 : model1 loss : 0.027497 model2 loss : 0.026462
[02:29:51.329] iteration 26588 : model1 loss : 0.051835 model2 loss : 0.048394
[02:29:51.998] iteration 26589 : model1 loss : 0.023087 model2 loss : 0.023304
[02:29:52.664] iteration 26590 : model1 loss : 0.016825 model2 loss : 0.016949
[02:29:53.321] iteration 26591 : model1 loss : 0.018485 model2 loss : 0.019515
[02:29:53.989] iteration 26592 : model1 loss : 0.021168 model2 loss : 0.021524
[02:29:54.644] iteration 26593 : model1 loss : 0.015553 model2 loss : 0.016679
[02:29:55.301] iteration 26594 : model1 loss : 0.017785 model2 loss : 0.018056
[02:29:55.966] iteration 26595 : model1 loss : 0.022046 model2 loss : 0.024261
[02:29:56.627] iteration 26596 : model1 loss : 0.017034 model2 loss : 0.018225
[02:29:57.295] iteration 26597 : model1 loss : 0.019340 model2 loss : 0.019921
[02:29:57.954] iteration 26598 : model1 loss : 0.014839 model2 loss : 0.016710
[02:29:58.631] iteration 26599 : model1 loss : 0.022760 model2 loss : 0.023731
[02:29:59.286] iteration 26600 : model1 loss : 0.018799 model2 loss : 0.018607
[02:30:16.989] iteration 26600 : model1_mean_dice : 0.874211 model1_mean_hd95 : 7.519996
[02:30:34.678] iteration 26600 : model2_mean_dice : 0.879727 model2_mean_hd95 : 4.699338
[02:30:35.353] iteration 26601 : model1 loss : 0.015781 model2 loss : 0.017217
[02:30:35.993] iteration 26602 : model1 loss : 0.017564 model2 loss : 0.018979
[02:30:36.647] iteration 26603 : model1 loss : 0.018883 model2 loss : 0.018149
[02:30:37.282] iteration 26604 : model1 loss : 0.017745 model2 loss : 0.017325
[02:30:37.947] iteration 26605 : model1 loss : 0.019833 model2 loss : 0.017541
[02:30:38.614] iteration 26606 : model1 loss : 0.030748 model2 loss : 0.032821
[02:30:39.282] iteration 26607 : model1 loss : 0.016536 model2 loss : 0.016986
[02:30:39.957] iteration 26608 : model1 loss : 0.022643 model2 loss : 0.020931
[02:30:40.611] iteration 26609 : model1 loss : 0.035706 model2 loss : 0.030285
[02:30:41.271] iteration 26610 : model1 loss : 0.021906 model2 loss : 0.023713
[02:30:41.918] iteration 26611 : model1 loss : 0.025955 model2 loss : 0.028180
[02:30:42.575] iteration 26612 : model1 loss : 0.021552 model2 loss : 0.019171
[02:30:43.232] iteration 26613 : model1 loss : 0.021279 model2 loss : 0.021765
[02:30:43.881] iteration 26614 : model1 loss : 0.020776 model2 loss : 0.021185
[02:30:44.532] iteration 26615 : model1 loss : 0.017587 model2 loss : 0.016608
[02:30:45.181] iteration 26616 : model1 loss : 0.021821 model2 loss : 0.021708
[02:30:45.828] iteration 26617 : model1 loss : 0.019545 model2 loss : 0.020866
[02:30:46.504] iteration 26618 : model1 loss : 0.017696 model2 loss : 0.017398
[02:30:47.150] iteration 26619 : model1 loss : 0.020462 model2 loss : 0.023478
[02:30:47.803] iteration 26620 : model1 loss : 0.028429 model2 loss : 0.034607
[02:30:48.471] iteration 26621 : model1 loss : 0.017744 model2 loss : 0.018205
[02:30:49.130] iteration 26622 : model1 loss : 0.017826 model2 loss : 0.017239
[02:30:49.785] iteration 26623 : model1 loss : 0.020095 model2 loss : 0.019544
[02:30:50.447] iteration 26624 : model1 loss : 0.049649 model2 loss : 0.049585
[02:30:51.109] iteration 26625 : model1 loss : 0.017898 model2 loss : 0.019922
[02:30:51.764] iteration 26626 : model1 loss : 0.018462 model2 loss : 0.019464
[02:30:52.427] iteration 26627 : model1 loss : 0.018028 model2 loss : 0.017977
[02:30:53.096] iteration 26628 : model1 loss : 0.021214 model2 loss : 0.019760
[02:30:53.748] iteration 26629 : model1 loss : 0.017766 model2 loss : 0.017037
[02:30:54.404] iteration 26630 : model1 loss : 0.015537 model2 loss : 0.014947
[02:30:55.066] iteration 26631 : model1 loss : 0.018474 model2 loss : 0.018867
[02:30:55.724] iteration 26632 : model1 loss : 0.017276 model2 loss : 0.017838
[02:30:56.382] iteration 26633 : model1 loss : 0.025908 model2 loss : 0.027543
[02:30:57.036] iteration 26634 : model1 loss : 0.026491 model2 loss : 0.027027
[02:30:57.692] iteration 26635 : model1 loss : 0.019123 model2 loss : 0.022995
[02:30:58.363] iteration 26636 : model1 loss : 0.020502 model2 loss : 0.023695
[02:30:59.029] iteration 26637 : model1 loss : 0.019613 model2 loss : 0.020013
[02:30:59.699] iteration 26638 : model1 loss : 0.020762 model2 loss : 0.021210
[02:31:00.365] iteration 26639 : model1 loss : 0.016509 model2 loss : 0.015652
[02:31:01.021] iteration 26640 : model1 loss : 0.022332 model2 loss : 0.022675
[02:31:01.680] iteration 26641 : model1 loss : 0.019123 model2 loss : 0.017664
[02:31:02.341] iteration 26642 : model1 loss : 0.019050 model2 loss : 0.019561
[02:31:02.992] iteration 26643 : model1 loss : 0.017259 model2 loss : 0.017326
[02:31:03.665] iteration 26644 : model1 loss : 0.016489 model2 loss : 0.013872
[02:31:04.325] iteration 26645 : model1 loss : 0.018692 model2 loss : 0.018150
[02:31:04.982] iteration 26646 : model1 loss : 0.020716 model2 loss : 0.019068
[02:31:05.633] iteration 26647 : model1 loss : 0.022857 model2 loss : 0.022420
[02:31:06.307] iteration 26648 : model1 loss : 0.019470 model2 loss : 0.018775
[02:31:06.956] iteration 26649 : model1 loss : 0.017819 model2 loss : 0.019096
[02:31:07.600] iteration 26650 : model1 loss : 0.022722 model2 loss : 0.021228
[02:31:08.318] iteration 26651 : model1 loss : 0.021969 model2 loss : 0.025498
[02:31:08.984] iteration 26652 : model1 loss : 0.020026 model2 loss : 0.020696
[02:31:09.645] iteration 26653 : model1 loss : 0.017575 model2 loss : 0.017409
[02:31:10.304] iteration 26654 : model1 loss : 0.032624 model2 loss : 0.030943
[02:31:10.960] iteration 26655 : model1 loss : 0.014221 model2 loss : 0.013994
[02:31:11.626] iteration 26656 : model1 loss : 0.025575 model2 loss : 0.022693
[02:31:12.276] iteration 26657 : model1 loss : 0.016767 model2 loss : 0.017639
[02:31:12.932] iteration 26658 : model1 loss : 0.020062 model2 loss : 0.017364
[02:31:13.579] iteration 26659 : model1 loss : 0.022018 model2 loss : 0.023581
[02:31:14.238] iteration 26660 : model1 loss : 0.023812 model2 loss : 0.022133
[02:31:14.902] iteration 26661 : model1 loss : 0.018601 model2 loss : 0.018942
[02:31:15.562] iteration 26662 : model1 loss : 0.017948 model2 loss : 0.017274
[02:31:16.209] iteration 26663 : model1 loss : 0.015372 model2 loss : 0.015795
[02:31:16.862] iteration 26664 : model1 loss : 0.019661 model2 loss : 0.023617
[02:31:17.518] iteration 26665 : model1 loss : 0.016855 model2 loss : 0.015852
[02:31:18.172] iteration 26666 : model1 loss : 0.016347 model2 loss : 0.016893
[02:31:18.840] iteration 26667 : model1 loss : 0.018151 model2 loss : 0.025240
[02:31:19.511] iteration 26668 : model1 loss : 0.018515 model2 loss : 0.017882
[02:31:20.169] iteration 26669 : model1 loss : 0.022090 model2 loss : 0.021497
[02:31:20.818] iteration 26670 : model1 loss : 0.024036 model2 loss : 0.023154
[02:31:21.488] iteration 26671 : model1 loss : 0.020727 model2 loss : 0.020843
[02:31:22.142] iteration 26672 : model1 loss : 0.020556 model2 loss : 0.019322
[02:31:22.814] iteration 26673 : model1 loss : 0.024762 model2 loss : 0.026120
[02:31:23.470] iteration 26674 : model1 loss : 0.021744 model2 loss : 0.024647
[02:31:24.120] iteration 26675 : model1 loss : 0.018763 model2 loss : 0.019665
[02:31:24.793] iteration 26676 : model1 loss : 0.019819 model2 loss : 0.018758
[02:31:25.449] iteration 26677 : model1 loss : 0.020134 model2 loss : 0.018333
[02:31:26.124] iteration 26678 : model1 loss : 0.021282 model2 loss : 0.021454
[02:31:26.777] iteration 26679 : model1 loss : 0.015639 model2 loss : 0.015054
[02:31:27.433] iteration 26680 : model1 loss : 0.023370 model2 loss : 0.022789
[02:31:28.092] iteration 26681 : model1 loss : 0.022852 model2 loss : 0.021143
[02:31:28.744] iteration 26682 : model1 loss : 0.018493 model2 loss : 0.020814
[02:31:29.391] iteration 26683 : model1 loss : 0.017589 model2 loss : 0.018251
[02:31:30.060] iteration 26684 : model1 loss : 0.022745 model2 loss : 0.021396
[02:31:30.714] iteration 26685 : model1 loss : 0.016798 model2 loss : 0.017772
[02:31:31.384] iteration 26686 : model1 loss : 0.021399 model2 loss : 0.023262
[02:31:32.037] iteration 26687 : model1 loss : 0.016534 model2 loss : 0.017787
[02:31:32.691] iteration 26688 : model1 loss : 0.017494 model2 loss : 0.018613
[02:31:33.338] iteration 26689 : model1 loss : 0.019245 model2 loss : 0.018262
[02:31:33.997] iteration 26690 : model1 loss : 0.016702 model2 loss : 0.017266
[02:31:34.654] iteration 26691 : model1 loss : 0.019368 model2 loss : 0.019379
[02:31:35.307] iteration 26692 : model1 loss : 0.016977 model2 loss : 0.017089
[02:31:35.964] iteration 26693 : model1 loss : 0.013594 model2 loss : 0.014346
[02:31:36.627] iteration 26694 : model1 loss : 0.016353 model2 loss : 0.016102
[02:31:37.270] iteration 26695 : model1 loss : 0.020028 model2 loss : 0.020617
[02:31:37.933] iteration 26696 : model1 loss : 0.015412 model2 loss : 0.016536
[02:31:38.598] iteration 26697 : model1 loss : 0.024060 model2 loss : 0.025072
[02:31:39.265] iteration 26698 : model1 loss : 0.022497 model2 loss : 0.023177
[02:31:39.932] iteration 26699 : model1 loss : 0.025488 model2 loss : 0.024920
[02:31:40.584] iteration 26700 : model1 loss : 0.026780 model2 loss : 0.030874
[02:31:41.286] iteration 26701 : model1 loss : 0.023734 model2 loss : 0.023851
[02:31:41.953] iteration 26702 : model1 loss : 0.019825 model2 loss : 0.019433
[02:31:42.628] iteration 26703 : model1 loss : 0.020568 model2 loss : 0.019093
[02:31:43.285] iteration 26704 : model1 loss : 0.016498 model2 loss : 0.017173
[02:31:43.944] iteration 26705 : model1 loss : 0.014587 model2 loss : 0.014124
[02:31:44.599] iteration 26706 : model1 loss : 0.031192 model2 loss : 0.028162
[02:31:45.261] iteration 26707 : model1 loss : 0.028291 model2 loss : 0.028464
[02:31:45.916] iteration 26708 : model1 loss : 0.023072 model2 loss : 0.022583
[02:31:46.568] iteration 26709 : model1 loss : 0.020719 model2 loss : 0.020237
[02:31:47.247] iteration 26710 : model1 loss : 0.019346 model2 loss : 0.017345
[02:31:47.909] iteration 26711 : model1 loss : 0.026787 model2 loss : 0.022115
[02:31:48.568] iteration 26712 : model1 loss : 0.015711 model2 loss : 0.015731
[02:31:49.224] iteration 26713 : model1 loss : 0.019817 model2 loss : 0.017002
[02:31:49.875] iteration 26714 : model1 loss : 0.024264 model2 loss : 0.021250
[02:31:50.535] iteration 26715 : model1 loss : 0.022165 model2 loss : 0.022448
[02:31:51.195] iteration 26716 : model1 loss : 0.026786 model2 loss : 0.031470
[02:31:51.851] iteration 26717 : model1 loss : 0.015905 model2 loss : 0.018069
[02:31:52.507] iteration 26718 : model1 loss : 0.023632 model2 loss : 0.022114
[02:31:53.163] iteration 26719 : model1 loss : 0.018857 model2 loss : 0.019236
[02:31:53.825] iteration 26720 : model1 loss : 0.016089 model2 loss : 0.015757
[02:31:54.503] iteration 26721 : model1 loss : 0.062716 model2 loss : 0.055703
[02:31:55.158] iteration 26722 : model1 loss : 0.025736 model2 loss : 0.025252
[02:31:55.811] iteration 26723 : model1 loss : 0.019229 model2 loss : 0.020027
[02:31:56.458] iteration 26724 : model1 loss : 0.017269 model2 loss : 0.015465
[02:31:57.129] iteration 26725 : model1 loss : 0.024594 model2 loss : 0.023503
[02:31:57.784] iteration 26726 : model1 loss : 0.018945 model2 loss : 0.021069
[02:31:58.442] iteration 26727 : model1 loss : 0.020927 model2 loss : 0.021820
[02:31:59.132] iteration 26728 : model1 loss : 0.020321 model2 loss : 0.021277
[02:31:59.804] iteration 26729 : model1 loss : 0.025783 model2 loss : 0.024365
[02:32:00.467] iteration 26730 : model1 loss : 0.018794 model2 loss : 0.020288
[02:32:01.131] iteration 26731 : model1 loss : 0.021606 model2 loss : 0.023418
[02:32:01.796] iteration 26732 : model1 loss : 0.016571 model2 loss : 0.018071
[02:32:02.465] iteration 26733 : model1 loss : 0.024437 model2 loss : 0.022280
[02:32:03.124] iteration 26734 : model1 loss : 0.023897 model2 loss : 0.023014
[02:32:03.802] iteration 26735 : model1 loss : 0.021430 model2 loss : 0.021408
[02:32:04.460] iteration 26736 : model1 loss : 0.021747 model2 loss : 0.020556
[02:32:05.117] iteration 26737 : model1 loss : 0.018614 model2 loss : 0.018822
[02:32:05.774] iteration 26738 : model1 loss : 0.016802 model2 loss : 0.016846
[02:32:06.447] iteration 26739 : model1 loss : 0.020246 model2 loss : 0.019199
[02:32:07.106] iteration 26740 : model1 loss : 0.016915 model2 loss : 0.016348
[02:32:07.770] iteration 26741 : model1 loss : 0.024990 model2 loss : 0.027978
[02:32:08.425] iteration 26742 : model1 loss : 0.019454 model2 loss : 0.019670
[02:32:09.089] iteration 26743 : model1 loss : 0.020668 model2 loss : 0.019590
[02:32:09.745] iteration 26744 : model1 loss : 0.020339 model2 loss : 0.021590
[02:32:10.405] iteration 26745 : model1 loss : 0.022359 model2 loss : 0.021505
[02:32:11.069] iteration 26746 : model1 loss : 0.032182 model2 loss : 0.029014
[02:32:11.725] iteration 26747 : model1 loss : 0.026722 model2 loss : 0.021948
[02:32:12.380] iteration 26748 : model1 loss : 0.017492 model2 loss : 0.017690
[02:32:13.031] iteration 26749 : model1 loss : 0.017961 model2 loss : 0.020052
[02:32:13.691] iteration 26750 : model1 loss : 0.019229 model2 loss : 0.019422
[02:32:14.401] iteration 26751 : model1 loss : 0.019712 model2 loss : 0.018573
[02:32:15.056] iteration 26752 : model1 loss : 0.033184 model2 loss : 0.028676
[02:32:15.708] iteration 26753 : model1 loss : 0.025138 model2 loss : 0.025832
[02:32:16.368] iteration 26754 : model1 loss : 0.018775 model2 loss : 0.017274
[02:32:17.019] iteration 26755 : model1 loss : 0.019658 model2 loss : 0.017904
[02:32:17.679] iteration 26756 : model1 loss : 0.018039 model2 loss : 0.017525
[02:32:18.337] iteration 26757 : model1 loss : 0.013752 model2 loss : 0.012106
[02:32:18.991] iteration 26758 : model1 loss : 0.015947 model2 loss : 0.015712
[02:32:19.656] iteration 26759 : model1 loss : 0.020764 model2 loss : 0.018226
[02:32:20.321] iteration 26760 : model1 loss : 0.019276 model2 loss : 0.018838
[02:32:20.975] iteration 26761 : model1 loss : 0.018381 model2 loss : 0.017951
[02:32:21.633] iteration 26762 : model1 loss : 0.017522 model2 loss : 0.017968
[02:32:22.287] iteration 26763 : model1 loss : 0.026496 model2 loss : 0.028757
[02:32:22.944] iteration 26764 : model1 loss : 0.032516 model2 loss : 0.033735
[02:32:23.603] iteration 26765 : model1 loss : 0.018540 model2 loss : 0.020334
[02:32:24.267] iteration 26766 : model1 loss : 0.026179 model2 loss : 0.025868
[02:32:24.916] iteration 26767 : model1 loss : 0.016961 model2 loss : 0.018042
[02:32:25.582] iteration 26768 : model1 loss : 0.024679 model2 loss : 0.026171
[02:32:26.226] iteration 26769 : model1 loss : 0.016868 model2 loss : 0.017280
[02:32:26.870] iteration 26770 : model1 loss : 0.020842 model2 loss : 0.021529
[02:32:27.535] iteration 26771 : model1 loss : 0.019988 model2 loss : 0.020209
[02:32:28.195] iteration 26772 : model1 loss : 0.020772 model2 loss : 0.021826
[02:32:28.846] iteration 26773 : model1 loss : 0.016689 model2 loss : 0.016916
[02:32:29.504] iteration 26774 : model1 loss : 0.026607 model2 loss : 0.027830
[02:32:30.151] iteration 26775 : model1 loss : 0.022641 model2 loss : 0.019646
[02:32:30.813] iteration 26776 : model1 loss : 0.024349 model2 loss : 0.023339
[02:32:31.477] iteration 26777 : model1 loss : 0.015053 model2 loss : 0.016168
[02:32:32.143] iteration 26778 : model1 loss : 0.027451 model2 loss : 0.025066
[02:32:32.806] iteration 26779 : model1 loss : 0.025030 model2 loss : 0.024463
[02:32:33.460] iteration 26780 : model1 loss : 0.023365 model2 loss : 0.023273
[02:32:34.119] iteration 26781 : model1 loss : 0.024824 model2 loss : 0.021761
[02:32:34.772] iteration 26782 : model1 loss : 0.032399 model2 loss : 0.031704
[02:32:35.443] iteration 26783 : model1 loss : 0.020701 model2 loss : 0.019629
[02:32:36.101] iteration 26784 : model1 loss : 0.015490 model2 loss : 0.017777
[02:32:36.753] iteration 26785 : model1 loss : 0.020893 model2 loss : 0.021709
[02:32:37.428] iteration 26786 : model1 loss : 0.016340 model2 loss : 0.019007
[02:32:38.085] iteration 26787 : model1 loss : 0.019470 model2 loss : 0.022538
[02:32:38.768] iteration 26788 : model1 loss : 0.032674 model2 loss : 0.033781
[02:32:39.420] iteration 26789 : model1 loss : 0.022880 model2 loss : 0.020649
[02:32:40.077] iteration 26790 : model1 loss : 0.018711 model2 loss : 0.019288
[02:32:40.742] iteration 26791 : model1 loss : 0.025120 model2 loss : 0.028568
[02:32:41.401] iteration 26792 : model1 loss : 0.027503 model2 loss : 0.025584
[02:32:42.069] iteration 26793 : model1 loss : 0.020957 model2 loss : 0.019966
[02:32:42.728] iteration 26794 : model1 loss : 0.018389 model2 loss : 0.016981
[02:32:43.390] iteration 26795 : model1 loss : 0.016677 model2 loss : 0.017590
[02:32:44.049] iteration 26796 : model1 loss : 0.017058 model2 loss : 0.016553
[02:32:44.715] iteration 26797 : model1 loss : 0.017450 model2 loss : 0.017714
[02:32:45.379] iteration 26798 : model1 loss : 0.017886 model2 loss : 0.018907
[02:32:46.030] iteration 26799 : model1 loss : 0.016813 model2 loss : 0.015612
[02:32:46.690] iteration 26800 : model1 loss : 0.022341 model2 loss : 0.022522
[02:33:04.479] iteration 26800 : model1_mean_dice : 0.877074 model1_mean_hd95 : 7.570937
[02:33:22.150] iteration 26800 : model2_mean_dice : 0.875694 model2_mean_hd95 : 5.169753
[02:33:22.823] iteration 26801 : model1 loss : 0.022831 model2 loss : 0.022964
[02:33:23.476] iteration 26802 : model1 loss : 0.027787 model2 loss : 0.025642
[02:33:24.125] iteration 26803 : model1 loss : 0.018576 model2 loss : 0.019445
[02:33:24.765] iteration 26804 : model1 loss : 0.021983 model2 loss : 0.020192
[02:33:25.430] iteration 26805 : model1 loss : 0.016672 model2 loss : 0.017219
[02:33:26.078] iteration 26806 : model1 loss : 0.020957 model2 loss : 0.021397
[02:33:26.714] iteration 26807 : model1 loss : 0.022568 model2 loss : 0.022944
[02:33:27.368] iteration 26808 : model1 loss : 0.018349 model2 loss : 0.018722
[02:33:28.033] iteration 26809 : model1 loss : 0.023292 model2 loss : 0.022589
[02:33:28.695] iteration 26810 : model1 loss : 0.021069 model2 loss : 0.020029
[02:33:29.346] iteration 26811 : model1 loss : 0.017128 model2 loss : 0.017714
[02:33:29.996] iteration 26812 : model1 loss : 0.019792 model2 loss : 0.019427
[02:33:30.662] iteration 26813 : model1 loss : 0.024595 model2 loss : 0.028161
[02:33:31.323] iteration 26814 : model1 loss : 0.015961 model2 loss : 0.017125
[02:33:31.977] iteration 26815 : model1 loss : 0.017829 model2 loss : 0.018171
[02:33:32.636] iteration 26816 : model1 loss : 0.017533 model2 loss : 0.017082
[02:33:33.289] iteration 26817 : model1 loss : 0.018741 model2 loss : 0.017454
[02:33:33.941] iteration 26818 : model1 loss : 0.022940 model2 loss : 0.025408
[02:33:34.596] iteration 26819 : model1 loss : 0.017086 model2 loss : 0.019401
[02:33:35.252] iteration 26820 : model1 loss : 0.020802 model2 loss : 0.021810
[02:33:35.915] iteration 26821 : model1 loss : 0.140140 model2 loss : 0.140981
[02:33:36.567] iteration 26822 : model1 loss : 0.021263 model2 loss : 0.020885
[02:33:37.241] iteration 26823 : model1 loss : 0.018848 model2 loss : 0.017478
[02:33:37.894] iteration 26824 : model1 loss : 0.021255 model2 loss : 0.022034
[02:33:38.561] iteration 26825 : model1 loss : 0.019068 model2 loss : 0.019228
[02:33:39.212] iteration 26826 : model1 loss : 0.019032 model2 loss : 0.018952
[02:33:39.875] iteration 26827 : model1 loss : 0.020975 model2 loss : 0.023518
[02:33:40.515] iteration 26828 : model1 loss : 0.015261 model2 loss : 0.017555
[02:33:41.169] iteration 26829 : model1 loss : 0.019242 model2 loss : 0.017394
[02:33:41.825] iteration 26830 : model1 loss : 0.036549 model2 loss : 0.033202
[02:33:42.488] iteration 26831 : model1 loss : 0.020313 model2 loss : 0.019479
[02:33:43.150] iteration 26832 : model1 loss : 0.016601 model2 loss : 0.015581
[02:33:43.799] iteration 26833 : model1 loss : 0.015556 model2 loss : 0.016709
[02:33:44.446] iteration 26834 : model1 loss : 0.026892 model2 loss : 0.031989
[02:33:45.124] iteration 26835 : model1 loss : 0.032204 model2 loss : 0.033560
[02:33:45.768] iteration 26836 : model1 loss : 0.017281 model2 loss : 0.018872
[02:33:46.413] iteration 26837 : model1 loss : 0.019843 model2 loss : 0.020192
[02:33:47.085] iteration 26838 : model1 loss : 0.020457 model2 loss : 0.021147
[02:33:47.745] iteration 26839 : model1 loss : 0.024076 model2 loss : 0.025932
[02:33:48.398] iteration 26840 : model1 loss : 0.015365 model2 loss : 0.015744
[02:33:49.044] iteration 26841 : model1 loss : 0.019255 model2 loss : 0.018968
[02:33:49.708] iteration 26842 : model1 loss : 0.020266 model2 loss : 0.018649
[02:33:50.363] iteration 26843 : model1 loss : 0.014136 model2 loss : 0.015035
[02:33:51.026] iteration 26844 : model1 loss : 0.018409 model2 loss : 0.017269
[02:33:51.680] iteration 26845 : model1 loss : 0.018786 model2 loss : 0.017850
[02:33:52.340] iteration 26846 : model1 loss : 0.017307 model2 loss : 0.018433
[02:33:53.010] iteration 26847 : model1 loss : 0.015431 model2 loss : 0.015545
[02:33:53.662] iteration 26848 : model1 loss : 0.012251 model2 loss : 0.011934
[02:33:54.320] iteration 26849 : model1 loss : 0.020892 model2 loss : 0.021187
[02:33:54.975] iteration 26850 : model1 loss : 0.024397 model2 loss : 0.022287
[02:33:55.667] iteration 26851 : model1 loss : 0.019038 model2 loss : 0.020827
[02:33:56.335] iteration 26852 : model1 loss : 0.016522 model2 loss : 0.016481
[02:33:56.992] iteration 26853 : model1 loss : 0.021609 model2 loss : 0.018967
[02:33:57.648] iteration 26854 : model1 loss : 0.027971 model2 loss : 0.024480
[02:33:58.319] iteration 26855 : model1 loss : 0.017986 model2 loss : 0.017764
[02:33:58.970] iteration 26856 : model1 loss : 0.022093 model2 loss : 0.020341
[02:33:59.618] iteration 26857 : model1 loss : 0.019069 model2 loss : 0.019825
[02:34:00.308] iteration 26858 : model1 loss : 0.021762 model2 loss : 0.020389
[02:34:00.960] iteration 26859 : model1 loss : 0.020100 model2 loss : 0.019660
[02:34:01.610] iteration 26860 : model1 loss : 0.018342 model2 loss : 0.019605
[02:34:02.254] iteration 26861 : model1 loss : 0.018768 model2 loss : 0.018807
[02:34:02.915] iteration 26862 : model1 loss : 0.021043 model2 loss : 0.018366
[02:34:03.574] iteration 26863 : model1 loss : 0.017660 model2 loss : 0.018249
[02:34:04.249] iteration 26864 : model1 loss : 0.025707 model2 loss : 0.028296
[02:34:04.902] iteration 26865 : model1 loss : 0.017070 model2 loss : 0.017546
[02:34:05.555] iteration 26866 : model1 loss : 0.021152 model2 loss : 0.022956
[02:34:06.205] iteration 26867 : model1 loss : 0.018691 model2 loss : 0.017601
[02:34:06.854] iteration 26868 : model1 loss : 0.018510 model2 loss : 0.018870
[02:34:07.515] iteration 26869 : model1 loss : 0.019830 model2 loss : 0.018736
[02:34:08.167] iteration 26870 : model1 loss : 0.018257 model2 loss : 0.016603
[02:34:08.822] iteration 26871 : model1 loss : 0.022164 model2 loss : 0.023601
[02:34:09.472] iteration 26872 : model1 loss : 0.017989 model2 loss : 0.018030
[02:34:10.119] iteration 26873 : model1 loss : 0.022653 model2 loss : 0.024293
[02:34:10.765] iteration 26874 : model1 loss : 0.018834 model2 loss : 0.020620
[02:34:11.442] iteration 26875 : model1 loss : 0.024693 model2 loss : 0.025849
[02:34:12.098] iteration 26876 : model1 loss : 0.016491 model2 loss : 0.017785
[02:34:12.759] iteration 26877 : model1 loss : 0.018449 model2 loss : 0.019187
[02:34:13.426] iteration 26878 : model1 loss : 0.027302 model2 loss : 0.024939
[02:34:14.079] iteration 26879 : model1 loss : 0.023214 model2 loss : 0.022489
[02:34:14.727] iteration 26880 : model1 loss : 0.015714 model2 loss : 0.015947
[02:34:15.397] iteration 26881 : model1 loss : 0.024953 model2 loss : 0.025666
[02:34:16.052] iteration 26882 : model1 loss : 0.023454 model2 loss : 0.023926
[02:34:16.708] iteration 26883 : model1 loss : 0.016603 model2 loss : 0.017041
[02:34:17.359] iteration 26884 : model1 loss : 0.017498 model2 loss : 0.017201
[02:34:18.023] iteration 26885 : model1 loss : 0.020285 model2 loss : 0.019788
[02:34:18.686] iteration 26886 : model1 loss : 0.025140 model2 loss : 0.022007
[02:34:19.352] iteration 26887 : model1 loss : 0.016614 model2 loss : 0.018879
[02:34:20.014] iteration 26888 : model1 loss : 0.016579 model2 loss : 0.018420
[02:34:20.683] iteration 26889 : model1 loss : 0.018178 model2 loss : 0.018669
[02:34:21.347] iteration 26890 : model1 loss : 0.023332 model2 loss : 0.022715
[02:34:21.997] iteration 26891 : model1 loss : 0.016900 model2 loss : 0.016841
[02:34:22.651] iteration 26892 : model1 loss : 0.022176 model2 loss : 0.024535
[02:34:23.319] iteration 26893 : model1 loss : 0.023288 model2 loss : 0.026708
[02:34:23.982] iteration 26894 : model1 loss : 0.023381 model2 loss : 0.022297
[02:34:24.633] iteration 26895 : model1 loss : 0.018928 model2 loss : 0.017935
[02:34:25.288] iteration 26896 : model1 loss : 0.024489 model2 loss : 0.022731
[02:34:25.940] iteration 26897 : model1 loss : 0.016841 model2 loss : 0.018979
[02:34:26.597] iteration 26898 : model1 loss : 0.015747 model2 loss : 0.018629
[02:34:27.245] iteration 26899 : model1 loss : 0.021395 model2 loss : 0.021327
[02:34:27.915] iteration 26900 : model1 loss : 0.021460 model2 loss : 0.021331
[02:34:28.600] iteration 26901 : model1 loss : 0.019332 model2 loss : 0.018689
[02:34:29.258] iteration 26902 : model1 loss : 0.025535 model2 loss : 0.021067
[02:34:29.925] iteration 26903 : model1 loss : 0.018114 model2 loss : 0.017621
[02:34:30.579] iteration 26904 : model1 loss : 0.139836 model2 loss : 0.141763
[02:34:31.233] iteration 26905 : model1 loss : 0.023163 model2 loss : 0.023183
[02:34:31.887] iteration 26906 : model1 loss : 0.016097 model2 loss : 0.016344
[02:34:32.548] iteration 26907 : model1 loss : 0.019102 model2 loss : 0.020155
[02:34:33.207] iteration 26908 : model1 loss : 0.023390 model2 loss : 0.022801
[02:34:33.869] iteration 26909 : model1 loss : 0.022038 model2 loss : 0.022142
[02:34:34.541] iteration 26910 : model1 loss : 0.019097 model2 loss : 0.019189
[02:34:35.183] iteration 26911 : model1 loss : 0.019725 model2 loss : 0.018072
[02:34:35.835] iteration 26912 : model1 loss : 0.019692 model2 loss : 0.018346
[02:34:36.492] iteration 26913 : model1 loss : 0.018479 model2 loss : 0.018140
[02:34:37.146] iteration 26914 : model1 loss : 0.015273 model2 loss : 0.015504
[02:34:37.803] iteration 26915 : model1 loss : 0.020888 model2 loss : 0.019771
[02:34:38.458] iteration 26916 : model1 loss : 0.023899 model2 loss : 0.021434
[02:34:39.129] iteration 26917 : model1 loss : 0.021680 model2 loss : 0.020009
[02:34:39.806] iteration 26918 : model1 loss : 0.023782 model2 loss : 0.024422
[02:34:40.467] iteration 26919 : model1 loss : 0.020577 model2 loss : 0.018434
[02:34:41.116] iteration 26920 : model1 loss : 0.017610 model2 loss : 0.017249
[02:34:41.772] iteration 26921 : model1 loss : 0.022663 model2 loss : 0.020463
[02:34:42.442] iteration 26922 : model1 loss : 0.016727 model2 loss : 0.016129
[02:34:43.120] iteration 26923 : model1 loss : 0.018435 model2 loss : 0.018243
[02:34:43.773] iteration 26924 : model1 loss : 0.015846 model2 loss : 0.016386
[02:34:44.433] iteration 26925 : model1 loss : 0.023542 model2 loss : 0.021210
[02:34:45.096] iteration 26926 : model1 loss : 0.017136 model2 loss : 0.017680
[02:34:45.741] iteration 26927 : model1 loss : 0.024953 model2 loss : 0.025112
[02:34:46.401] iteration 26928 : model1 loss : 0.016765 model2 loss : 0.015980
[02:34:47.072] iteration 26929 : model1 loss : 0.018163 model2 loss : 0.020316
[02:34:47.738] iteration 26930 : model1 loss : 0.024383 model2 loss : 0.026192
[02:34:48.400] iteration 26931 : model1 loss : 0.144198 model2 loss : 0.147003
[02:34:49.053] iteration 26932 : model1 loss : 0.018797 model2 loss : 0.018320
[02:34:49.720] iteration 26933 : model1 loss : 0.019234 model2 loss : 0.020652
[02:34:50.367] iteration 26934 : model1 loss : 0.026407 model2 loss : 0.028152
[02:34:51.032] iteration 26935 : model1 loss : 0.020479 model2 loss : 0.020784
[02:34:51.684] iteration 26936 : model1 loss : 0.018698 model2 loss : 0.017432
[02:34:52.344] iteration 26937 : model1 loss : 0.027513 model2 loss : 0.022323
[02:34:53.006] iteration 26938 : model1 loss : 0.019089 model2 loss : 0.017642
[02:34:53.665] iteration 26939 : model1 loss : 0.021476 model2 loss : 0.021664
[02:34:54.328] iteration 26940 : model1 loss : 0.146630 model2 loss : 0.145922
[02:34:54.983] iteration 26941 : model1 loss : 0.018758 model2 loss : 0.017384
[02:34:55.650] iteration 26942 : model1 loss : 0.014766 model2 loss : 0.014554
[02:34:56.323] iteration 26943 : model1 loss : 0.019754 model2 loss : 0.019437
[02:34:56.973] iteration 26944 : model1 loss : 0.020577 model2 loss : 0.021076
[02:34:57.629] iteration 26945 : model1 loss : 0.023329 model2 loss : 0.023150
[02:34:58.287] iteration 26946 : model1 loss : 0.020107 model2 loss : 0.020476
[02:34:58.939] iteration 26947 : model1 loss : 0.018279 model2 loss : 0.018619
[02:34:59.601] iteration 26948 : model1 loss : 0.021407 model2 loss : 0.023388
[02:35:00.276] iteration 26949 : model1 loss : 0.020713 model2 loss : 0.020397
[02:35:00.944] iteration 26950 : model1 loss : 0.015811 model2 loss : 0.015223
[02:35:01.636] iteration 26951 : model1 loss : 0.020154 model2 loss : 0.019962
[02:35:02.300] iteration 26952 : model1 loss : 0.140521 model2 loss : 0.139504
[02:35:02.965] iteration 26953 : model1 loss : 0.018246 model2 loss : 0.017676
[02:35:03.628] iteration 26954 : model1 loss : 0.022808 model2 loss : 0.021314
[02:35:04.280] iteration 26955 : model1 loss : 0.015278 model2 loss : 0.016059
[02:35:04.942] iteration 26956 : model1 loss : 0.021776 model2 loss : 0.021264
[02:35:05.593] iteration 26957 : model1 loss : 0.023019 model2 loss : 0.023902
[02:35:06.257] iteration 26958 : model1 loss : 0.020272 model2 loss : 0.020528
[02:35:06.917] iteration 26959 : model1 loss : 0.017212 model2 loss : 0.015857
[02:35:07.579] iteration 26960 : model1 loss : 0.019846 model2 loss : 0.018818
[02:35:08.244] iteration 26961 : model1 loss : 0.021827 model2 loss : 0.033404
[02:35:08.911] iteration 26962 : model1 loss : 0.019295 model2 loss : 0.019926
[02:35:09.573] iteration 26963 : model1 loss : 0.020637 model2 loss : 0.018461
[02:35:10.235] iteration 26964 : model1 loss : 0.016565 model2 loss : 0.014483
[02:35:10.905] iteration 26965 : model1 loss : 0.015726 model2 loss : 0.016200
[02:35:11.558] iteration 26966 : model1 loss : 0.017749 model2 loss : 0.018169
[02:35:12.215] iteration 26967 : model1 loss : 0.028193 model2 loss : 0.025259
[02:35:12.896] iteration 26968 : model1 loss : 0.020751 model2 loss : 0.022040
[02:35:13.556] iteration 26969 : model1 loss : 0.019721 model2 loss : 0.017633
[02:35:14.219] iteration 26970 : model1 loss : 0.026014 model2 loss : 0.027695
[02:35:14.877] iteration 26971 : model1 loss : 0.022230 model2 loss : 0.024194
[02:35:15.525] iteration 26972 : model1 loss : 0.024753 model2 loss : 0.024742
[02:35:16.187] iteration 26973 : model1 loss : 0.022812 model2 loss : 0.022246
[02:35:16.852] iteration 26974 : model1 loss : 0.022919 model2 loss : 0.020397
[02:35:17.505] iteration 26975 : model1 loss : 0.022977 model2 loss : 0.023993
[02:35:18.165] iteration 26976 : model1 loss : 0.018891 model2 loss : 0.019753
[02:35:18.809] iteration 26977 : model1 loss : 0.021333 model2 loss : 0.021184
[02:35:19.464] iteration 26978 : model1 loss : 0.025226 model2 loss : 0.025595
[02:35:20.115] iteration 26979 : model1 loss : 0.022523 model2 loss : 0.021012
[02:35:20.773] iteration 26980 : model1 loss : 0.018071 model2 loss : 0.018705
[02:35:21.428] iteration 26981 : model1 loss : 0.017905 model2 loss : 0.019240
[02:35:22.082] iteration 26982 : model1 loss : 0.016209 model2 loss : 0.018762
[02:35:22.741] iteration 26983 : model1 loss : 0.021961 model2 loss : 0.023021
[02:35:23.397] iteration 26984 : model1 loss : 0.020728 model2 loss : 0.019309
[02:35:24.057] iteration 26985 : model1 loss : 0.014678 model2 loss : 0.014324
[02:35:24.711] iteration 26986 : model1 loss : 0.020173 model2 loss : 0.020189
[02:35:25.374] iteration 26987 : model1 loss : 0.146422 model2 loss : 0.144348
[02:35:26.046] iteration 26988 : model1 loss : 0.019714 model2 loss : 0.021064
[02:35:26.696] iteration 26989 : model1 loss : 0.015822 model2 loss : 0.017703
[02:35:27.352] iteration 26990 : model1 loss : 0.018765 model2 loss : 0.020571
[02:35:28.013] iteration 26991 : model1 loss : 0.017712 model2 loss : 0.016801
[02:35:28.684] iteration 26992 : model1 loss : 0.015633 model2 loss : 0.016643
[02:35:29.356] iteration 26993 : model1 loss : 0.016648 model2 loss : 0.015856
[02:35:30.008] iteration 26994 : model1 loss : 0.019755 model2 loss : 0.018238
[02:35:30.670] iteration 26995 : model1 loss : 0.014430 model2 loss : 0.014222
[02:35:31.329] iteration 26996 : model1 loss : 0.020320 model2 loss : 0.021617
[02:35:32.006] iteration 26997 : model1 loss : 0.026255 model2 loss : 0.025996
[02:35:32.679] iteration 26998 : model1 loss : 0.018041 model2 loss : 0.017267
[02:35:33.340] iteration 26999 : model1 loss : 0.019211 model2 loss : 0.018842
[02:35:33.990] iteration 27000 : model1 loss : 0.018818 model2 loss : 0.020494
[02:35:51.856] iteration 27000 : model1_mean_dice : 0.877454 model1_mean_hd95 : 6.860426
[02:36:09.697] iteration 27000 : model2_mean_dice : 0.878364 model2_mean_hd95 : 4.605724
[02:36:09.760] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_27000.pth
[02:36:09.815] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_27000.pth
[02:36:10.487] iteration 27001 : model1 loss : 0.019701 model2 loss : 0.020019
[02:36:11.138] iteration 27002 : model1 loss : 0.014430 model2 loss : 0.014572
[02:36:11.800] iteration 27003 : model1 loss : 0.022203 model2 loss : 0.023233
[02:36:12.446] iteration 27004 : model1 loss : 0.019421 model2 loss : 0.019561
[02:36:13.097] iteration 27005 : model1 loss : 0.021374 model2 loss : 0.024031
[02:36:13.760] iteration 27006 : model1 loss : 0.023202 model2 loss : 0.025294
[02:36:14.408] iteration 27007 : model1 loss : 0.017590 model2 loss : 0.016573
[02:36:15.075] iteration 27008 : model1 loss : 0.016246 model2 loss : 0.016216
[02:36:15.734] iteration 27009 : model1 loss : 0.018592 model2 loss : 0.018003
[02:36:16.387] iteration 27010 : model1 loss : 0.018787 model2 loss : 0.022453
[02:36:17.025] iteration 27011 : model1 loss : 0.017825 model2 loss : 0.019514
[02:36:17.665] iteration 27012 : model1 loss : 0.020199 model2 loss : 0.020532
[02:36:18.330] iteration 27013 : model1 loss : 0.018942 model2 loss : 0.019008
[02:36:18.980] iteration 27014 : model1 loss : 0.020597 model2 loss : 0.021732
[02:36:19.636] iteration 27015 : model1 loss : 0.033250 model2 loss : 0.032927
[02:36:20.292] iteration 27016 : model1 loss : 0.016426 model2 loss : 0.015864
[02:36:20.957] iteration 27017 : model1 loss : 0.017639 model2 loss : 0.016496
[02:36:21.623] iteration 27018 : model1 loss : 0.020534 model2 loss : 0.018495
[02:36:22.275] iteration 27019 : model1 loss : 0.021354 model2 loss : 0.021913
[02:36:22.943] iteration 27020 : model1 loss : 0.024945 model2 loss : 0.025618
[02:36:23.679] iteration 27021 : model1 loss : 0.039566 model2 loss : 0.037623
[02:36:24.366] iteration 27022 : model1 loss : 0.019006 model2 loss : 0.019646
[02:36:25.079] iteration 27023 : model1 loss : 0.018073 model2 loss : 0.019885
[02:36:25.772] iteration 27024 : model1 loss : 0.054786 model2 loss : 0.069956
[02:36:26.426] iteration 27025 : model1 loss : 0.020457 model2 loss : 0.020171
[02:36:27.076] iteration 27026 : model1 loss : 0.017848 model2 loss : 0.017011
[02:36:27.742] iteration 27027 : model1 loss : 0.022037 model2 loss : 0.020136
[02:36:28.406] iteration 27028 : model1 loss : 0.019376 model2 loss : 0.016943
[02:36:29.058] iteration 27029 : model1 loss : 0.026234 model2 loss : 0.027438
[02:36:29.707] iteration 27030 : model1 loss : 0.033343 model2 loss : 0.032314
[02:36:30.361] iteration 27031 : model1 loss : 0.014464 model2 loss : 0.017497
[02:36:31.009] iteration 27032 : model1 loss : 0.017243 model2 loss : 0.017589
[02:36:31.674] iteration 27033 : model1 loss : 0.016939 model2 loss : 0.017091
[02:36:32.337] iteration 27034 : model1 loss : 0.021275 model2 loss : 0.019444
[02:36:32.995] iteration 27035 : model1 loss : 0.021562 model2 loss : 0.021688
[02:36:33.661] iteration 27036 : model1 loss : 0.017415 model2 loss : 0.018758
[02:36:34.332] iteration 27037 : model1 loss : 0.016277 model2 loss : 0.015523
[02:36:34.993] iteration 27038 : model1 loss : 0.021256 model2 loss : 0.024785
[02:36:35.659] iteration 27039 : model1 loss : 0.021873 model2 loss : 0.021864
[02:36:36.319] iteration 27040 : model1 loss : 0.022372 model2 loss : 0.023458
[02:36:36.980] iteration 27041 : model1 loss : 0.019101 model2 loss : 0.018667
[02:36:37.633] iteration 27042 : model1 loss : 0.020752 model2 loss : 0.020368
[02:36:38.280] iteration 27043 : model1 loss : 0.025539 model2 loss : 0.025823
[02:36:38.944] iteration 27044 : model1 loss : 0.140426 model2 loss : 0.139916
[02:36:39.631] iteration 27045 : model1 loss : 0.020005 model2 loss : 0.020323
[02:36:40.293] iteration 27046 : model1 loss : 0.020582 model2 loss : 0.020414
[02:36:40.953] iteration 27047 : model1 loss : 0.016823 model2 loss : 0.015930
[02:36:41.635] iteration 27048 : model1 loss : 0.032026 model2 loss : 0.031188
[02:36:42.302] iteration 27049 : model1 loss : 0.018387 model2 loss : 0.019818
[02:36:42.968] iteration 27050 : model1 loss : 0.025091 model2 loss : 0.024228
[02:36:43.652] iteration 27051 : model1 loss : 0.016219 model2 loss : 0.016516
[02:36:44.301] iteration 27052 : model1 loss : 0.020668 model2 loss : 0.020888
[02:36:44.946] iteration 27053 : model1 loss : 0.017329 model2 loss : 0.016629
[02:36:45.607] iteration 27054 : model1 loss : 0.021242 model2 loss : 0.024399
[02:36:46.255] iteration 27055 : model1 loss : 0.023575 model2 loss : 0.022007
[02:36:46.912] iteration 27056 : model1 loss : 0.018592 model2 loss : 0.021077
[02:36:47.571] iteration 27057 : model1 loss : 0.020981 model2 loss : 0.021045
[02:36:48.223] iteration 27058 : model1 loss : 0.016826 model2 loss : 0.017638
[02:36:48.880] iteration 27059 : model1 loss : 0.020849 model2 loss : 0.023587
[02:36:49.537] iteration 27060 : model1 loss : 0.016741 model2 loss : 0.017344
[02:36:50.197] iteration 27061 : model1 loss : 0.026867 model2 loss : 0.029456
[02:36:50.853] iteration 27062 : model1 loss : 0.020307 model2 loss : 0.020217
[02:36:51.507] iteration 27063 : model1 loss : 0.017796 model2 loss : 0.017220
[02:36:52.167] iteration 27064 : model1 loss : 0.018145 model2 loss : 0.017557
[02:36:52.835] iteration 27065 : model1 loss : 0.018105 model2 loss : 0.016963
[02:36:53.488] iteration 27066 : model1 loss : 0.016423 model2 loss : 0.016808
[02:36:54.143] iteration 27067 : model1 loss : 0.015264 model2 loss : 0.016046
[02:36:54.801] iteration 27068 : model1 loss : 0.016150 model2 loss : 0.015561
[02:36:55.469] iteration 27069 : model1 loss : 0.028955 model2 loss : 0.032715
[02:36:56.126] iteration 27070 : model1 loss : 0.016066 model2 loss : 0.015957
[02:36:56.805] iteration 27071 : model1 loss : 0.017698 model2 loss : 0.018090
[02:36:57.461] iteration 27072 : model1 loss : 0.026542 model2 loss : 0.024095
[02:36:58.129] iteration 27073 : model1 loss : 0.020597 model2 loss : 0.024660
[02:36:58.783] iteration 27074 : model1 loss : 0.026558 model2 loss : 0.028493
[02:36:59.438] iteration 27075 : model1 loss : 0.027136 model2 loss : 0.028902
[02:37:00.098] iteration 27076 : model1 loss : 0.019414 model2 loss : 0.019470
[02:37:00.761] iteration 27077 : model1 loss : 0.017408 model2 loss : 0.015105
[02:37:01.438] iteration 27078 : model1 loss : 0.019058 model2 loss : 0.021668
[02:37:02.097] iteration 27079 : model1 loss : 0.017891 model2 loss : 0.016764
[02:37:02.762] iteration 27080 : model1 loss : 0.021103 model2 loss : 0.021034
[02:37:03.418] iteration 27081 : model1 loss : 0.017154 model2 loss : 0.018341
[02:37:04.075] iteration 27082 : model1 loss : 0.021526 model2 loss : 0.023583
[02:37:04.742] iteration 27083 : model1 loss : 0.020485 model2 loss : 0.020455
[02:37:05.392] iteration 27084 : model1 loss : 0.018336 model2 loss : 0.017955
[02:37:06.037] iteration 27085 : model1 loss : 0.015767 model2 loss : 0.015253
[02:37:06.696] iteration 27086 : model1 loss : 0.018119 model2 loss : 0.017775
[02:37:07.355] iteration 27087 : model1 loss : 0.018453 model2 loss : 0.019254
[02:37:08.009] iteration 27088 : model1 loss : 0.017684 model2 loss : 0.019676
[02:37:08.660] iteration 27089 : model1 loss : 0.019011 model2 loss : 0.018760
[02:37:09.304] iteration 27090 : model1 loss : 0.018455 model2 loss : 0.019524
[02:37:09.961] iteration 27091 : model1 loss : 0.018815 model2 loss : 0.017916
[02:37:10.613] iteration 27092 : model1 loss : 0.021637 model2 loss : 0.021081
[02:37:11.273] iteration 27093 : model1 loss : 0.020622 model2 loss : 0.019574
[02:37:11.945] iteration 27094 : model1 loss : 0.023410 model2 loss : 0.023664
[02:37:12.603] iteration 27095 : model1 loss : 0.015119 model2 loss : 0.016301
[02:37:13.258] iteration 27096 : model1 loss : 0.018331 model2 loss : 0.018867
[02:37:13.917] iteration 27097 : model1 loss : 0.021108 model2 loss : 0.022252
[02:37:14.569] iteration 27098 : model1 loss : 0.019407 model2 loss : 0.019881
[02:37:15.230] iteration 27099 : model1 loss : 0.023270 model2 loss : 0.020282
[02:37:15.882] iteration 27100 : model1 loss : 0.019492 model2 loss : 0.017553
[02:37:16.589] iteration 27101 : model1 loss : 0.018920 model2 loss : 0.018099
[02:37:17.243] iteration 27102 : model1 loss : 0.018324 model2 loss : 0.019389
[02:37:17.910] iteration 27103 : model1 loss : 0.017835 model2 loss : 0.017202
[02:37:18.586] iteration 27104 : model1 loss : 0.023080 model2 loss : 0.022673
[02:37:19.246] iteration 27105 : model1 loss : 0.058546 model2 loss : 0.044499
[02:37:19.901] iteration 27106 : model1 loss : 0.147649 model2 loss : 0.143705
[02:37:20.571] iteration 27107 : model1 loss : 0.020486 model2 loss : 0.016225
[02:37:21.234] iteration 27108 : model1 loss : 0.033925 model2 loss : 0.035582
[02:37:21.891] iteration 27109 : model1 loss : 0.013627 model2 loss : 0.014388
[02:37:22.551] iteration 27110 : model1 loss : 0.018307 model2 loss : 0.017540
[02:37:23.210] iteration 27111 : model1 loss : 0.022731 model2 loss : 0.022655
[02:37:23.867] iteration 27112 : model1 loss : 0.017517 model2 loss : 0.018052
[02:37:24.532] iteration 27113 : model1 loss : 0.022106 model2 loss : 0.022831
[02:37:25.207] iteration 27114 : model1 loss : 0.022705 model2 loss : 0.022615
[02:37:25.858] iteration 27115 : model1 loss : 0.017073 model2 loss : 0.017321
[02:37:26.540] iteration 27116 : model1 loss : 0.022499 model2 loss : 0.019131
[02:37:27.209] iteration 27117 : model1 loss : 0.019069 model2 loss : 0.019552
[02:37:27.859] iteration 27118 : model1 loss : 0.025941 model2 loss : 0.028470
[02:37:28.523] iteration 27119 : model1 loss : 0.021263 model2 loss : 0.020227
[02:37:29.177] iteration 27120 : model1 loss : 0.018779 model2 loss : 0.019047
[02:37:29.845] iteration 27121 : model1 loss : 0.016441 model2 loss : 0.015168
[02:37:30.503] iteration 27122 : model1 loss : 0.033572 model2 loss : 0.029321
[02:37:31.158] iteration 27123 : model1 loss : 0.022840 model2 loss : 0.023765
[02:37:31.811] iteration 27124 : model1 loss : 0.029250 model2 loss : 0.026082
[02:37:32.482] iteration 27125 : model1 loss : 0.143207 model2 loss : 0.142716
[02:37:33.150] iteration 27126 : model1 loss : 0.021714 model2 loss : 0.020370
[02:37:33.813] iteration 27127 : model1 loss : 0.018581 model2 loss : 0.018366
[02:37:34.470] iteration 27128 : model1 loss : 0.017498 model2 loss : 0.017871
[02:37:35.118] iteration 27129 : model1 loss : 0.043247 model2 loss : 0.059964
[02:37:35.780] iteration 27130 : model1 loss : 0.016817 model2 loss : 0.015655
[02:37:36.444] iteration 27131 : model1 loss : 0.021041 model2 loss : 0.021437
[02:37:37.114] iteration 27132 : model1 loss : 0.018331 model2 loss : 0.017801
[02:37:37.781] iteration 27133 : model1 loss : 0.023426 model2 loss : 0.021663
[02:37:38.431] iteration 27134 : model1 loss : 0.015904 model2 loss : 0.016626
[02:37:39.098] iteration 27135 : model1 loss : 0.024147 model2 loss : 0.020572
[02:37:39.767] iteration 27136 : model1 loss : 0.021484 model2 loss : 0.021394
[02:37:40.429] iteration 27137 : model1 loss : 0.024140 model2 loss : 0.025633
[02:37:41.093] iteration 27138 : model1 loss : 0.016564 model2 loss : 0.016301
[02:37:41.754] iteration 27139 : model1 loss : 0.023467 model2 loss : 0.027946
[02:37:42.437] iteration 27140 : model1 loss : 0.017737 model2 loss : 0.019019
[02:37:43.097] iteration 27141 : model1 loss : 0.022395 model2 loss : 0.022859
[02:37:43.756] iteration 27142 : model1 loss : 0.020908 model2 loss : 0.020808
[02:37:44.412] iteration 27143 : model1 loss : 0.022137 model2 loss : 0.022007
[02:37:45.076] iteration 27144 : model1 loss : 0.021781 model2 loss : 0.021649
[02:37:45.732] iteration 27145 : model1 loss : 0.020420 model2 loss : 0.022830
[02:37:46.398] iteration 27146 : model1 loss : 0.027544 model2 loss : 0.027843
[02:37:47.068] iteration 27147 : model1 loss : 0.017328 model2 loss : 0.017054
[02:37:47.740] iteration 27148 : model1 loss : 0.137379 model2 loss : 0.124848
[02:37:48.390] iteration 27149 : model1 loss : 0.014881 model2 loss : 0.015951
[02:37:49.050] iteration 27150 : model1 loss : 0.020211 model2 loss : 0.020316
[02:37:49.746] iteration 27151 : model1 loss : 0.018854 model2 loss : 0.020105
[02:37:50.406] iteration 27152 : model1 loss : 0.024489 model2 loss : 0.024889
[02:37:51.052] iteration 27153 : model1 loss : 0.017104 model2 loss : 0.017129
[02:37:51.705] iteration 27154 : model1 loss : 0.015119 model2 loss : 0.017539
[02:37:52.363] iteration 27155 : model1 loss : 0.017976 model2 loss : 0.017744
[02:37:53.036] iteration 27156 : model1 loss : 0.143109 model2 loss : 0.144009
[02:37:53.690] iteration 27157 : model1 loss : 0.027716 model2 loss : 0.024611
[02:37:54.351] iteration 27158 : model1 loss : 0.021145 model2 loss : 0.021978
[02:37:54.998] iteration 27159 : model1 loss : 0.020265 model2 loss : 0.019071
[02:37:55.655] iteration 27160 : model1 loss : 0.018850 model2 loss : 0.018475
[02:37:56.316] iteration 27161 : model1 loss : 0.020426 model2 loss : 0.021997
[02:37:56.980] iteration 27162 : model1 loss : 0.016943 model2 loss : 0.019972
[02:37:57.636] iteration 27163 : model1 loss : 0.021012 model2 loss : 0.021936
[02:37:58.305] iteration 27164 : model1 loss : 0.016160 model2 loss : 0.015307
[02:37:58.968] iteration 27165 : model1 loss : 0.020214 model2 loss : 0.020503
[02:37:59.638] iteration 27166 : model1 loss : 0.015282 model2 loss : 0.014929
[02:38:00.289] iteration 27167 : model1 loss : 0.018302 model2 loss : 0.018344
[02:38:00.962] iteration 27168 : model1 loss : 0.017085 model2 loss : 0.016919
[02:38:01.630] iteration 27169 : model1 loss : 0.023099 model2 loss : 0.022276
[02:38:02.319] iteration 27170 : model1 loss : 0.014070 model2 loss : 0.016779
[02:38:03.010] iteration 27171 : model1 loss : 0.017133 model2 loss : 0.016389
[02:38:03.670] iteration 27172 : model1 loss : 0.034137 model2 loss : 0.032019
[02:38:04.347] iteration 27173 : model1 loss : 0.016492 model2 loss : 0.017230
[02:38:04.999] iteration 27174 : model1 loss : 0.023422 model2 loss : 0.024159
[02:38:05.667] iteration 27175 : model1 loss : 0.026819 model2 loss : 0.026216
[02:38:06.332] iteration 27176 : model1 loss : 0.015619 model2 loss : 0.015890
[02:38:06.977] iteration 27177 : model1 loss : 0.029590 model2 loss : 0.030782
[02:38:07.625] iteration 27178 : model1 loss : 0.024891 model2 loss : 0.023978
[02:38:08.281] iteration 27179 : model1 loss : 0.021198 model2 loss : 0.020937
[02:38:08.937] iteration 27180 : model1 loss : 0.019962 model2 loss : 0.021318
[02:38:09.604] iteration 27181 : model1 loss : 0.017419 model2 loss : 0.016265
[02:38:10.265] iteration 27182 : model1 loss : 0.017637 model2 loss : 0.019088
[02:38:10.912] iteration 27183 : model1 loss : 0.019320 model2 loss : 0.019402
[02:38:11.578] iteration 27184 : model1 loss : 0.021610 model2 loss : 0.022216
[02:38:12.245] iteration 27185 : model1 loss : 0.018705 model2 loss : 0.019656
[02:38:12.909] iteration 27186 : model1 loss : 0.017809 model2 loss : 0.016707
[02:38:13.571] iteration 27187 : model1 loss : 0.024747 model2 loss : 0.022972
[02:38:14.230] iteration 27188 : model1 loss : 0.017676 model2 loss : 0.017520
[02:38:14.895] iteration 27189 : model1 loss : 0.017481 model2 loss : 0.016916
[02:38:15.572] iteration 27190 : model1 loss : 0.022793 model2 loss : 0.024390
[02:38:16.245] iteration 27191 : model1 loss : 0.025177 model2 loss : 0.022772
[02:38:16.905] iteration 27192 : model1 loss : 0.019828 model2 loss : 0.017762
[02:38:17.552] iteration 27193 : model1 loss : 0.019387 model2 loss : 0.020516
[02:38:18.203] iteration 27194 : model1 loss : 0.017707 model2 loss : 0.017755
[02:38:18.858] iteration 27195 : model1 loss : 0.022230 model2 loss : 0.022934
[02:38:19.518] iteration 27196 : model1 loss : 0.017763 model2 loss : 0.016731
[02:38:20.191] iteration 27197 : model1 loss : 0.018991 model2 loss : 0.018019
[02:38:20.843] iteration 27198 : model1 loss : 0.018004 model2 loss : 0.018748
[02:38:21.506] iteration 27199 : model1 loss : 0.025293 model2 loss : 0.026066
[02:38:22.171] iteration 27200 : model1 loss : 0.018400 model2 loss : 0.017622
[02:38:39.802] iteration 27200 : model1_mean_dice : 0.876100 model1_mean_hd95 : 7.554882
[02:38:57.475] iteration 27200 : model2_mean_dice : 0.879079 model2_mean_hd95 : 4.743964
[02:38:58.155] iteration 27201 : model1 loss : 0.019618 model2 loss : 0.018381
[02:38:58.810] iteration 27202 : model1 loss : 0.083331 model2 loss : 0.077138
[02:38:59.464] iteration 27203 : model1 loss : 0.020962 model2 loss : 0.022933
[02:39:00.120] iteration 27204 : model1 loss : 0.017347 model2 loss : 0.016700
[02:39:00.775] iteration 27205 : model1 loss : 0.028005 model2 loss : 0.030399
[02:39:01.423] iteration 27206 : model1 loss : 0.021348 model2 loss : 0.020210
[02:39:02.081] iteration 27207 : model1 loss : 0.017255 model2 loss : 0.017877
[02:39:02.750] iteration 27208 : model1 loss : 0.018079 model2 loss : 0.018147
[02:39:03.407] iteration 27209 : model1 loss : 0.021820 model2 loss : 0.019323
[02:39:04.059] iteration 27210 : model1 loss : 0.021754 model2 loss : 0.021503
[02:39:04.700] iteration 27211 : model1 loss : 0.024054 model2 loss : 0.022877
[02:39:05.359] iteration 27212 : model1 loss : 0.025424 model2 loss : 0.025471
[02:39:06.007] iteration 27213 : model1 loss : 0.021950 model2 loss : 0.022540
[02:39:06.664] iteration 27214 : model1 loss : 0.017061 model2 loss : 0.016399
[02:39:07.331] iteration 27215 : model1 loss : 0.023037 model2 loss : 0.024074
[02:39:07.985] iteration 27216 : model1 loss : 0.020072 model2 loss : 0.021169
[02:39:08.644] iteration 27217 : model1 loss : 0.017147 model2 loss : 0.017327
[02:39:09.301] iteration 27218 : model1 loss : 0.023927 model2 loss : 0.026251
[02:39:09.946] iteration 27219 : model1 loss : 0.024587 model2 loss : 0.024172
[02:39:10.612] iteration 27220 : model1 loss : 0.025618 model2 loss : 0.024976
[02:39:11.274] iteration 27221 : model1 loss : 0.020437 model2 loss : 0.021061
[02:39:11.923] iteration 27222 : model1 loss : 0.016370 model2 loss : 0.017554
[02:39:12.586] iteration 27223 : model1 loss : 0.016585 model2 loss : 0.015983
[02:39:13.247] iteration 27224 : model1 loss : 0.021782 model2 loss : 0.018823
[02:39:13.910] iteration 27225 : model1 loss : 0.020897 model2 loss : 0.018578
[02:39:14.552] iteration 27226 : model1 loss : 0.014762 model2 loss : 0.016233
[02:39:15.216] iteration 27227 : model1 loss : 0.019009 model2 loss : 0.018328
[02:39:15.874] iteration 27228 : model1 loss : 0.018846 model2 loss : 0.018222
[02:39:16.530] iteration 27229 : model1 loss : 0.139485 model2 loss : 0.138303
[02:39:17.184] iteration 27230 : model1 loss : 0.016790 model2 loss : 0.016711
[02:39:17.841] iteration 27231 : model1 loss : 0.021045 model2 loss : 0.023137
[02:39:18.500] iteration 27232 : model1 loss : 0.017736 model2 loss : 0.017861
[02:39:19.165] iteration 27233 : model1 loss : 0.018154 model2 loss : 0.017638
[02:39:19.822] iteration 27234 : model1 loss : 0.029441 model2 loss : 0.028021
[02:39:20.515] iteration 27235 : model1 loss : 0.022542 model2 loss : 0.022311
[02:39:21.165] iteration 27236 : model1 loss : 0.020353 model2 loss : 0.018332
[02:39:21.829] iteration 27237 : model1 loss : 0.019299 model2 loss : 0.020711
[02:39:22.485] iteration 27238 : model1 loss : 0.016252 model2 loss : 0.015930
[02:39:23.146] iteration 27239 : model1 loss : 0.024248 model2 loss : 0.022506
[02:39:23.810] iteration 27240 : model1 loss : 0.016760 model2 loss : 0.017129
[02:39:24.472] iteration 27241 : model1 loss : 0.015199 model2 loss : 0.015041
[02:39:25.119] iteration 27242 : model1 loss : 0.015971 model2 loss : 0.016353
[02:39:25.775] iteration 27243 : model1 loss : 0.016423 model2 loss : 0.016985
[02:39:26.423] iteration 27244 : model1 loss : 0.141557 model2 loss : 0.142025
[02:39:27.072] iteration 27245 : model1 loss : 0.020393 model2 loss : 0.019134
[02:39:27.720] iteration 27246 : model1 loss : 0.025163 model2 loss : 0.026313
[02:39:28.379] iteration 27247 : model1 loss : 0.021964 model2 loss : 0.019659
[02:39:29.039] iteration 27248 : model1 loss : 0.140175 model2 loss : 0.141040
[02:39:29.711] iteration 27249 : model1 loss : 0.027583 model2 loss : 0.028600
[02:39:30.378] iteration 27250 : model1 loss : 0.020679 model2 loss : 0.021436
[02:39:31.070] iteration 27251 : model1 loss : 0.016258 model2 loss : 0.017581
[02:39:31.727] iteration 27252 : model1 loss : 0.017994 model2 loss : 0.017672
[02:39:32.383] iteration 27253 : model1 loss : 0.028885 model2 loss : 0.027808
[02:39:33.046] iteration 27254 : model1 loss : 0.017009 model2 loss : 0.018616
[02:39:33.706] iteration 27255 : model1 loss : 0.022550 model2 loss : 0.021654
[02:39:34.363] iteration 27256 : model1 loss : 0.024201 model2 loss : 0.023474
[02:39:35.018] iteration 27257 : model1 loss : 0.021002 model2 loss : 0.020198
[02:39:35.679] iteration 27258 : model1 loss : 0.023325 model2 loss : 0.021164
[02:39:36.330] iteration 27259 : model1 loss : 0.017221 model2 loss : 0.018253
[02:39:36.987] iteration 27260 : model1 loss : 0.085435 model2 loss : 0.067742
[02:39:37.641] iteration 27261 : model1 loss : 0.015747 model2 loss : 0.015395
[02:39:38.294] iteration 27262 : model1 loss : 0.018942 model2 loss : 0.019795
[02:39:38.946] iteration 27263 : model1 loss : 0.020904 model2 loss : 0.021489
[02:39:39.610] iteration 27264 : model1 loss : 0.018021 model2 loss : 0.019095
[02:39:40.267] iteration 27265 : model1 loss : 0.024454 model2 loss : 0.021356
[02:39:40.921] iteration 27266 : model1 loss : 0.018865 model2 loss : 0.017563
[02:39:41.587] iteration 27267 : model1 loss : 0.017557 model2 loss : 0.017569
[02:39:42.241] iteration 27268 : model1 loss : 0.020382 model2 loss : 0.018829
[02:39:42.906] iteration 27269 : model1 loss : 0.019123 model2 loss : 0.018350
[02:39:43.570] iteration 27270 : model1 loss : 0.019573 model2 loss : 0.019250
[02:39:44.217] iteration 27271 : model1 loss : 0.019811 model2 loss : 0.019638
[02:39:44.878] iteration 27272 : model1 loss : 0.020090 model2 loss : 0.019183
[02:39:45.536] iteration 27273 : model1 loss : 0.015725 model2 loss : 0.016071
[02:39:46.200] iteration 27274 : model1 loss : 0.017905 model2 loss : 0.016737
[02:39:46.870] iteration 27275 : model1 loss : 0.025095 model2 loss : 0.026494
[02:39:47.527] iteration 27276 : model1 loss : 0.013344 model2 loss : 0.013720
[02:39:48.189] iteration 27277 : model1 loss : 0.018973 model2 loss : 0.018279
[02:39:48.860] iteration 27278 : model1 loss : 0.017242 model2 loss : 0.018540
[02:39:49.506] iteration 27279 : model1 loss : 0.018811 model2 loss : 0.019289
[02:39:50.156] iteration 27280 : model1 loss : 0.017180 model2 loss : 0.017063
[02:39:50.820] iteration 27281 : model1 loss : 0.015929 model2 loss : 0.016119
[02:39:51.486] iteration 27282 : model1 loss : 0.014902 model2 loss : 0.015220
[02:39:52.142] iteration 27283 : model1 loss : 0.015878 model2 loss : 0.016813
[02:39:52.801] iteration 27284 : model1 loss : 0.017768 model2 loss : 0.020951
[02:39:53.465] iteration 27285 : model1 loss : 0.018187 model2 loss : 0.021256
[02:39:54.130] iteration 27286 : model1 loss : 0.019536 model2 loss : 0.019759
[02:39:54.790] iteration 27287 : model1 loss : 0.032327 model2 loss : 0.028366
[02:39:55.440] iteration 27288 : model1 loss : 0.016954 model2 loss : 0.018246
[02:39:56.102] iteration 27289 : model1 loss : 0.019882 model2 loss : 0.024317
[02:39:56.768] iteration 27290 : model1 loss : 0.022559 model2 loss : 0.020860
[02:39:57.427] iteration 27291 : model1 loss : 0.024554 model2 loss : 0.023657
[02:39:58.081] iteration 27292 : model1 loss : 0.015654 model2 loss : 0.016214
[02:39:58.752] iteration 27293 : model1 loss : 0.024115 model2 loss : 0.023597
[02:39:59.402] iteration 27294 : model1 loss : 0.017352 model2 loss : 0.016651
[02:40:00.067] iteration 27295 : model1 loss : 0.020317 model2 loss : 0.018499
[02:40:00.730] iteration 27296 : model1 loss : 0.016039 model2 loss : 0.014749
[02:40:01.384] iteration 27297 : model1 loss : 0.021037 model2 loss : 0.019812
[02:40:02.039] iteration 27298 : model1 loss : 0.016048 model2 loss : 0.015197
[02:40:02.710] iteration 27299 : model1 loss : 0.015867 model2 loss : 0.014762
[02:40:03.377] iteration 27300 : model1 loss : 0.019532 model2 loss : 0.018932
[02:40:04.091] iteration 27301 : model1 loss : 0.025346 model2 loss : 0.028418
[02:40:04.739] iteration 27302 : model1 loss : 0.019673 model2 loss : 0.018003
[02:40:05.387] iteration 27303 : model1 loss : 0.138168 model2 loss : 0.139350
[02:40:06.038] iteration 27304 : model1 loss : 0.019947 model2 loss : 0.020039
[02:40:06.699] iteration 27305 : model1 loss : 0.024794 model2 loss : 0.023959
[02:40:07.354] iteration 27306 : model1 loss : 0.016682 model2 loss : 0.016331
[02:40:08.019] iteration 27307 : model1 loss : 0.019829 model2 loss : 0.020191
[02:40:08.674] iteration 27308 : model1 loss : 0.055607 model2 loss : 0.055717
[02:40:09.332] iteration 27309 : model1 loss : 0.017070 model2 loss : 0.016268
[02:40:09.977] iteration 27310 : model1 loss : 0.021480 model2 loss : 0.019911
[02:40:10.632] iteration 27311 : model1 loss : 0.024083 model2 loss : 0.023917
[02:40:11.292] iteration 27312 : model1 loss : 0.017603 model2 loss : 0.017012
[02:40:11.942] iteration 27313 : model1 loss : 0.017326 model2 loss : 0.017948
[02:40:12.617] iteration 27314 : model1 loss : 0.017037 model2 loss : 0.019107
[02:40:13.285] iteration 27315 : model1 loss : 0.015242 model2 loss : 0.016317
[02:40:13.935] iteration 27316 : model1 loss : 0.018669 model2 loss : 0.019737
[02:40:14.597] iteration 27317 : model1 loss : 0.018850 model2 loss : 0.019482
[02:40:15.246] iteration 27318 : model1 loss : 0.014323 model2 loss : 0.013686
[02:40:15.903] iteration 27319 : model1 loss : 0.016817 model2 loss : 0.019942
[02:40:16.556] iteration 27320 : model1 loss : 0.015900 model2 loss : 0.015985
[02:40:17.209] iteration 27321 : model1 loss : 0.019247 model2 loss : 0.018540
[02:40:17.863] iteration 27322 : model1 loss : 0.020843 model2 loss : 0.020483
[02:40:18.512] iteration 27323 : model1 loss : 0.021012 model2 loss : 0.019756
[02:40:19.166] iteration 27324 : model1 loss : 0.014998 model2 loss : 0.015625
[02:40:19.820] iteration 27325 : model1 loss : 0.019858 model2 loss : 0.018385
[02:40:20.480] iteration 27326 : model1 loss : 0.036549 model2 loss : 0.030485
[02:40:21.129] iteration 27327 : model1 loss : 0.030368 model2 loss : 0.031484
[02:40:21.779] iteration 27328 : model1 loss : 0.017194 model2 loss : 0.017281
[02:40:22.436] iteration 27329 : model1 loss : 0.023725 model2 loss : 0.023024
[02:40:23.108] iteration 27330 : model1 loss : 0.019629 model2 loss : 0.019235
[02:40:23.765] iteration 27331 : model1 loss : 0.022186 model2 loss : 0.020558
[02:40:24.426] iteration 27332 : model1 loss : 0.018821 model2 loss : 0.018384
[02:40:25.075] iteration 27333 : model1 loss : 0.018462 model2 loss : 0.015804
[02:40:25.733] iteration 27334 : model1 loss : 0.028161 model2 loss : 0.025947
[02:40:26.389] iteration 27335 : model1 loss : 0.018493 model2 loss : 0.019159
[02:40:27.044] iteration 27336 : model1 loss : 0.019604 model2 loss : 0.024016
[02:40:27.705] iteration 27337 : model1 loss : 0.017623 model2 loss : 0.018369
[02:40:28.365] iteration 27338 : model1 loss : 0.019467 model2 loss : 0.020077
[02:40:29.021] iteration 27339 : model1 loss : 0.025838 model2 loss : 0.024251
[02:40:29.679] iteration 27340 : model1 loss : 0.021083 model2 loss : 0.019579
[02:40:30.335] iteration 27341 : model1 loss : 0.019413 model2 loss : 0.019805
[02:40:30.998] iteration 27342 : model1 loss : 0.018561 model2 loss : 0.019884
[02:40:31.648] iteration 27343 : model1 loss : 0.020375 model2 loss : 0.019714
[02:40:32.316] iteration 27344 : model1 loss : 0.024753 model2 loss : 0.023126
[02:40:32.966] iteration 27345 : model1 loss : 0.018104 model2 loss : 0.017919
[02:40:33.632] iteration 27346 : model1 loss : 0.019183 model2 loss : 0.016975
[02:40:34.290] iteration 27347 : model1 loss : 0.016706 model2 loss : 0.018089
[02:40:34.948] iteration 27348 : model1 loss : 0.021828 model2 loss : 0.023345
[02:40:35.615] iteration 27349 : model1 loss : 0.021155 model2 loss : 0.021511
[02:40:36.277] iteration 27350 : model1 loss : 0.022239 model2 loss : 0.024012
[02:40:36.972] iteration 27351 : model1 loss : 0.021218 model2 loss : 0.021942
[02:40:37.623] iteration 27352 : model1 loss : 0.014229 model2 loss : 0.014925
[02:40:38.271] iteration 27353 : model1 loss : 0.017341 model2 loss : 0.018093
[02:40:38.926] iteration 27354 : model1 loss : 0.017740 model2 loss : 0.021772
[02:40:39.589] iteration 27355 : model1 loss : 0.018514 model2 loss : 0.016080
[02:40:40.247] iteration 27356 : model1 loss : 0.036904 model2 loss : 0.050499
[02:40:40.904] iteration 27357 : model1 loss : 0.020177 model2 loss : 0.020604
[02:40:41.560] iteration 27358 : model1 loss : 0.016033 model2 loss : 0.016463
[02:40:42.223] iteration 27359 : model1 loss : 0.028837 model2 loss : 0.029562
[02:40:42.890] iteration 27360 : model1 loss : 0.018882 model2 loss : 0.017345
[02:40:43.547] iteration 27361 : model1 loss : 0.022661 model2 loss : 0.021484
[02:40:44.211] iteration 27362 : model1 loss : 0.021537 model2 loss : 0.022611
[02:40:44.865] iteration 27363 : model1 loss : 0.018668 model2 loss : 0.017745
[02:40:45.526] iteration 27364 : model1 loss : 0.020084 model2 loss : 0.020698
[02:40:46.200] iteration 27365 : model1 loss : 0.016649 model2 loss : 0.017171
[02:40:46.856] iteration 27366 : model1 loss : 0.020067 model2 loss : 0.019915
[02:40:47.525] iteration 27367 : model1 loss : 0.015650 model2 loss : 0.015666
[02:40:48.190] iteration 27368 : model1 loss : 0.021602 model2 loss : 0.019611
[02:40:48.845] iteration 27369 : model1 loss : 0.019127 model2 loss : 0.020581
[02:40:49.506] iteration 27370 : model1 loss : 0.018616 model2 loss : 0.017944
[02:40:50.168] iteration 27371 : model1 loss : 0.023977 model2 loss : 0.022985
[02:40:50.832] iteration 27372 : model1 loss : 0.021586 model2 loss : 0.022053
[02:40:51.493] iteration 27373 : model1 loss : 0.023017 model2 loss : 0.023655
[02:40:52.150] iteration 27374 : model1 loss : 0.018030 model2 loss : 0.017944
[02:40:52.812] iteration 27375 : model1 loss : 0.016610 model2 loss : 0.016432
[02:40:53.470] iteration 27376 : model1 loss : 0.015028 model2 loss : 0.014661
[02:40:54.132] iteration 27377 : model1 loss : 0.017400 model2 loss : 0.016517
[02:40:54.792] iteration 27378 : model1 loss : 0.019328 model2 loss : 0.021800
[02:40:55.480] iteration 27379 : model1 loss : 0.020263 model2 loss : 0.018187
[02:40:56.147] iteration 27380 : model1 loss : 0.014143 model2 loss : 0.015025
[02:40:56.809] iteration 27381 : model1 loss : 0.022116 model2 loss : 0.019821
[02:40:57.477] iteration 27382 : model1 loss : 0.021090 model2 loss : 0.021927
[02:40:58.146] iteration 27383 : model1 loss : 0.021003 model2 loss : 0.020732
[02:40:58.801] iteration 27384 : model1 loss : 0.016669 model2 loss : 0.017954
[02:40:59.473] iteration 27385 : model1 loss : 0.020045 model2 loss : 0.019836
[02:41:00.135] iteration 27386 : model1 loss : 0.036095 model2 loss : 0.038630
[02:41:00.791] iteration 27387 : model1 loss : 0.017473 model2 loss : 0.017161
[02:41:01.465] iteration 27388 : model1 loss : 0.017859 model2 loss : 0.022002
[02:41:02.121] iteration 27389 : model1 loss : 0.019676 model2 loss : 0.019041
[02:41:02.786] iteration 27390 : model1 loss : 0.015326 model2 loss : 0.014905
[02:41:03.487] iteration 27391 : model1 loss : 0.024391 model2 loss : 0.027800
[02:41:04.147] iteration 27392 : model1 loss : 0.019274 model2 loss : 0.018924
[02:41:04.806] iteration 27393 : model1 loss : 0.018455 model2 loss : 0.018108
[02:41:05.475] iteration 27394 : model1 loss : 0.023261 model2 loss : 0.022056
[02:41:06.131] iteration 27395 : model1 loss : 0.017880 model2 loss : 0.018441
[02:41:06.783] iteration 27396 : model1 loss : 0.025632 model2 loss : 0.025344
[02:41:07.456] iteration 27397 : model1 loss : 0.014989 model2 loss : 0.015052
[02:41:08.110] iteration 27398 : model1 loss : 0.018663 model2 loss : 0.018210
[02:41:08.777] iteration 27399 : model1 loss : 0.014938 model2 loss : 0.014536
[02:41:09.442] iteration 27400 : model1 loss : 0.017082 model2 loss : 0.018536
[02:41:27.154] iteration 27400 : model1_mean_dice : 0.876771 model1_mean_hd95 : 6.799081
[02:41:44.960] iteration 27400 : model2_mean_dice : 0.879315 model2_mean_hd95 : 4.252834
[02:41:45.651] iteration 27401 : model1 loss : 0.022431 model2 loss : 0.023025
[02:41:46.301] iteration 27402 : model1 loss : 0.032606 model2 loss : 0.034583
[02:41:46.940] iteration 27403 : model1 loss : 0.015754 model2 loss : 0.016140
[02:41:47.599] iteration 27404 : model1 loss : 0.018440 model2 loss : 0.021580
[02:41:48.269] iteration 27405 : model1 loss : 0.021012 model2 loss : 0.020402
[02:41:48.918] iteration 27406 : model1 loss : 0.020784 model2 loss : 0.019519
[02:41:49.573] iteration 27407 : model1 loss : 0.020419 model2 loss : 0.021576
[02:41:50.227] iteration 27408 : model1 loss : 0.021104 model2 loss : 0.020954
[02:41:50.879] iteration 27409 : model1 loss : 0.016357 model2 loss : 0.015760
[02:41:51.541] iteration 27410 : model1 loss : 0.017350 model2 loss : 0.018135
[02:41:52.206] iteration 27411 : model1 loss : 0.015532 model2 loss : 0.016878
[02:41:52.858] iteration 27412 : model1 loss : 0.036442 model2 loss : 0.031064
[02:41:53.506] iteration 27413 : model1 loss : 0.019290 model2 loss : 0.019638
[02:41:54.149] iteration 27414 : model1 loss : 0.019112 model2 loss : 0.020836
[02:41:54.807] iteration 27415 : model1 loss : 0.015581 model2 loss : 0.016267
[02:41:55.465] iteration 27416 : model1 loss : 0.027258 model2 loss : 0.022606
[02:41:56.125] iteration 27417 : model1 loss : 0.025640 model2 loss : 0.023098
[02:41:56.770] iteration 27418 : model1 loss : 0.036922 model2 loss : 0.042094
[02:41:57.439] iteration 27419 : model1 loss : 0.017900 model2 loss : 0.016967
[02:41:58.102] iteration 27420 : model1 loss : 0.025446 model2 loss : 0.024936
[02:41:58.751] iteration 27421 : model1 loss : 0.012244 model2 loss : 0.012925
[02:41:59.408] iteration 27422 : model1 loss : 0.019296 model2 loss : 0.019890
[02:42:00.061] iteration 27423 : model1 loss : 0.024348 model2 loss : 0.021146
[02:42:00.717] iteration 27424 : model1 loss : 0.018102 model2 loss : 0.017154
[02:42:01.382] iteration 27425 : model1 loss : 0.016569 model2 loss : 0.017254
[02:42:02.029] iteration 27426 : model1 loss : 0.017472 model2 loss : 0.018210
[02:42:02.695] iteration 27427 : model1 loss : 0.020544 model2 loss : 0.017673
[02:42:03.365] iteration 27428 : model1 loss : 0.017355 model2 loss : 0.017180
[02:42:04.033] iteration 27429 : model1 loss : 0.022270 model2 loss : 0.024910
[02:42:04.706] iteration 27430 : model1 loss : 0.022459 model2 loss : 0.021241
[02:42:05.360] iteration 27431 : model1 loss : 0.139997 model2 loss : 0.139925
[02:42:06.015] iteration 27432 : model1 loss : 0.023980 model2 loss : 0.023418
[02:42:06.670] iteration 27433 : model1 loss : 0.017576 model2 loss : 0.018332
[02:42:07.326] iteration 27434 : model1 loss : 0.028492 model2 loss : 0.031575
[02:42:07.985] iteration 27435 : model1 loss : 0.015651 model2 loss : 0.015792
[02:42:08.639] iteration 27436 : model1 loss : 0.019212 model2 loss : 0.019539
[02:42:09.307] iteration 27437 : model1 loss : 0.017256 model2 loss : 0.017161
[02:42:09.963] iteration 27438 : model1 loss : 0.017775 model2 loss : 0.017857
[02:42:10.623] iteration 27439 : model1 loss : 0.018837 model2 loss : 0.015327
[02:42:11.284] iteration 27440 : model1 loss : 0.020218 model2 loss : 0.020213
[02:42:11.933] iteration 27441 : model1 loss : 0.020275 model2 loss : 0.022644
[02:42:12.600] iteration 27442 : model1 loss : 0.019943 model2 loss : 0.020377
[02:42:13.257] iteration 27443 : model1 loss : 0.022994 model2 loss : 0.023280
[02:42:13.914] iteration 27444 : model1 loss : 0.015618 model2 loss : 0.015890
[02:42:14.566] iteration 27445 : model1 loss : 0.023547 model2 loss : 0.023172
[02:42:15.226] iteration 27446 : model1 loss : 0.018674 model2 loss : 0.020170
[02:42:15.894] iteration 27447 : model1 loss : 0.027061 model2 loss : 0.028099
[02:42:16.543] iteration 27448 : model1 loss : 0.018768 model2 loss : 0.017450
[02:42:17.193] iteration 27449 : model1 loss : 0.023081 model2 loss : 0.018860
[02:42:17.853] iteration 27450 : model1 loss : 0.022015 model2 loss : 0.021869
[02:42:18.568] iteration 27451 : model1 loss : 0.021696 model2 loss : 0.020968
[02:42:19.219] iteration 27452 : model1 loss : 0.019300 model2 loss : 0.020758
[02:42:19.873] iteration 27453 : model1 loss : 0.028601 model2 loss : 0.028157
[02:42:20.538] iteration 27454 : model1 loss : 0.016937 model2 loss : 0.016594
[02:42:21.202] iteration 27455 : model1 loss : 0.026246 model2 loss : 0.026691
[02:42:21.857] iteration 27456 : model1 loss : 0.017162 model2 loss : 0.018664
[02:42:22.525] iteration 27457 : model1 loss : 0.018362 model2 loss : 0.017725
[02:42:23.178] iteration 27458 : model1 loss : 0.015518 model2 loss : 0.016465
[02:42:23.838] iteration 27459 : model1 loss : 0.016927 model2 loss : 0.019437
[02:42:24.512] iteration 27460 : model1 loss : 0.018585 model2 loss : 0.020544
[02:42:25.173] iteration 27461 : model1 loss : 0.019824 model2 loss : 0.021632
[02:42:25.828] iteration 27462 : model1 loss : 0.018478 model2 loss : 0.017146
[02:42:26.492] iteration 27463 : model1 loss : 0.019541 model2 loss : 0.017699
[02:42:27.137] iteration 27464 : model1 loss : 0.020455 model2 loss : 0.020757
[02:42:27.805] iteration 27465 : model1 loss : 0.020202 model2 loss : 0.020500
[02:42:28.471] iteration 27466 : model1 loss : 0.025839 model2 loss : 0.028105
[02:42:29.144] iteration 27467 : model1 loss : 0.023136 model2 loss : 0.022484
[02:42:29.802] iteration 27468 : model1 loss : 0.021505 model2 loss : 0.021286
[02:42:30.458] iteration 27469 : model1 loss : 0.018845 model2 loss : 0.018653
[02:42:31.114] iteration 27470 : model1 loss : 0.021686 model2 loss : 0.022681
[02:42:31.769] iteration 27471 : model1 loss : 0.021856 model2 loss : 0.023434
[02:42:32.434] iteration 27472 : model1 loss : 0.024109 model2 loss : 0.026209
[02:42:33.090] iteration 27473 : model1 loss : 0.022305 model2 loss : 0.025127
[02:42:33.761] iteration 27474 : model1 loss : 0.019087 model2 loss : 0.019630
[02:42:34.419] iteration 27475 : model1 loss : 0.014460 model2 loss : 0.015212
[02:42:35.088] iteration 27476 : model1 loss : 0.065800 model2 loss : 0.053549
[02:42:35.752] iteration 27477 : model1 loss : 0.020496 model2 loss : 0.020339
[02:42:36.412] iteration 27478 : model1 loss : 0.031930 model2 loss : 0.031374
[02:42:37.066] iteration 27479 : model1 loss : 0.017736 model2 loss : 0.017649
[02:42:37.724] iteration 27480 : model1 loss : 0.014649 model2 loss : 0.015472
[02:42:38.371] iteration 27481 : model1 loss : 0.018248 model2 loss : 0.018148
[02:42:39.025] iteration 27482 : model1 loss : 0.017199 model2 loss : 0.020314
[02:42:39.694] iteration 27483 : model1 loss : 0.024140 model2 loss : 0.019917
[02:42:40.355] iteration 27484 : model1 loss : 0.018859 model2 loss : 0.018664
[02:42:41.014] iteration 27485 : model1 loss : 0.015960 model2 loss : 0.016527
[02:42:41.677] iteration 27486 : model1 loss : 0.019465 model2 loss : 0.017663
[02:42:42.327] iteration 27487 : model1 loss : 0.022056 model2 loss : 0.020242
[02:42:42.993] iteration 27488 : model1 loss : 0.018673 model2 loss : 0.017749
[02:42:43.645] iteration 27489 : model1 loss : 0.018011 model2 loss : 0.018536
[02:42:44.305] iteration 27490 : model1 loss : 0.023824 model2 loss : 0.023428
[02:42:44.977] iteration 27491 : model1 loss : 0.018863 model2 loss : 0.018879
[02:42:45.647] iteration 27492 : model1 loss : 0.015302 model2 loss : 0.015625
[02:42:46.298] iteration 27493 : model1 loss : 0.022251 model2 loss : 0.020787
[02:42:46.943] iteration 27494 : model1 loss : 0.019143 model2 loss : 0.019732
[02:42:47.591] iteration 27495 : model1 loss : 0.017539 model2 loss : 0.017916
[02:42:48.243] iteration 27496 : model1 loss : 0.021528 model2 loss : 0.022787
[02:42:48.917] iteration 27497 : model1 loss : 0.018191 model2 loss : 0.020074
[02:42:49.576] iteration 27498 : model1 loss : 0.019007 model2 loss : 0.019861
[02:42:50.242] iteration 27499 : model1 loss : 0.018127 model2 loss : 0.018764
[02:42:50.902] iteration 27500 : model1 loss : 0.024935 model2 loss : 0.026137
[02:42:51.595] iteration 27501 : model1 loss : 0.020065 model2 loss : 0.020465
[02:42:52.252] iteration 27502 : model1 loss : 0.025221 model2 loss : 0.027883
[02:42:52.920] iteration 27503 : model1 loss : 0.019408 model2 loss : 0.018814
[02:42:53.582] iteration 27504 : model1 loss : 0.026014 model2 loss : 0.024742
[02:42:54.239] iteration 27505 : model1 loss : 0.022386 model2 loss : 0.022377
[02:42:54.882] iteration 27506 : model1 loss : 0.020172 model2 loss : 0.020540
[02:42:55.558] iteration 27507 : model1 loss : 0.140874 model2 loss : 0.141482
[02:42:56.205] iteration 27508 : model1 loss : 0.034171 model2 loss : 0.029989
[02:42:56.861] iteration 27509 : model1 loss : 0.078472 model2 loss : 0.067637
[02:42:57.531] iteration 27510 : model1 loss : 0.019798 model2 loss : 0.019168
[02:42:58.177] iteration 27511 : model1 loss : 0.024873 model2 loss : 0.024047
[02:42:58.833] iteration 27512 : model1 loss : 0.016665 model2 loss : 0.016060
[02:42:59.504] iteration 27513 : model1 loss : 0.020431 model2 loss : 0.020439
[02:43:00.167] iteration 27514 : model1 loss : 0.017225 model2 loss : 0.017012
[02:43:00.825] iteration 27515 : model1 loss : 0.022692 model2 loss : 0.022716
[02:43:01.478] iteration 27516 : model1 loss : 0.017730 model2 loss : 0.015888
[02:43:02.134] iteration 27517 : model1 loss : 0.018222 model2 loss : 0.018308
[02:43:02.783] iteration 27518 : model1 loss : 0.013355 model2 loss : 0.013426
[02:43:03.445] iteration 27519 : model1 loss : 0.018159 model2 loss : 0.014401
[02:43:04.141] iteration 27520 : model1 loss : 0.019666 model2 loss : 0.019256
[02:43:04.799] iteration 27521 : model1 loss : 0.017564 model2 loss : 0.019567
[02:43:05.454] iteration 27522 : model1 loss : 0.026272 model2 loss : 0.026793
[02:43:06.110] iteration 27523 : model1 loss : 0.016661 model2 loss : 0.017212
[02:43:06.760] iteration 27524 : model1 loss : 0.020555 model2 loss : 0.021369
[02:43:07.426] iteration 27525 : model1 loss : 0.017450 model2 loss : 0.018191
[02:43:08.076] iteration 27526 : model1 loss : 0.020433 model2 loss : 0.020946
[02:43:08.736] iteration 27527 : model1 loss : 0.042460 model2 loss : 0.040872
[02:43:09.401] iteration 27528 : model1 loss : 0.017741 model2 loss : 0.019023
[02:43:10.055] iteration 27529 : model1 loss : 0.018439 model2 loss : 0.017687
[02:43:10.714] iteration 27530 : model1 loss : 0.018096 model2 loss : 0.018400
[02:43:11.394] iteration 27531 : model1 loss : 0.019001 model2 loss : 0.019974
[02:43:12.062] iteration 27532 : model1 loss : 0.020231 model2 loss : 0.019750
[02:43:12.725] iteration 27533 : model1 loss : 0.024367 model2 loss : 0.024280
[02:43:13.382] iteration 27534 : model1 loss : 0.019631 model2 loss : 0.020212
[02:43:14.048] iteration 27535 : model1 loss : 0.018909 model2 loss : 0.019057
[02:43:14.697] iteration 27536 : model1 loss : 0.018783 model2 loss : 0.017041
[02:43:15.359] iteration 27537 : model1 loss : 0.030477 model2 loss : 0.029197
[02:43:16.027] iteration 27538 : model1 loss : 0.020113 model2 loss : 0.018013
[02:43:16.685] iteration 27539 : model1 loss : 0.017824 model2 loss : 0.018035
[02:43:17.350] iteration 27540 : model1 loss : 0.017709 model2 loss : 0.017711
[02:43:18.003] iteration 27541 : model1 loss : 0.020733 model2 loss : 0.022030
[02:43:18.672] iteration 27542 : model1 loss : 0.018314 model2 loss : 0.018073
[02:43:19.329] iteration 27543 : model1 loss : 0.020285 model2 loss : 0.020480
[02:43:19.986] iteration 27544 : model1 loss : 0.018629 model2 loss : 0.016485
[02:43:20.645] iteration 27545 : model1 loss : 0.025417 model2 loss : 0.022102
[02:43:21.301] iteration 27546 : model1 loss : 0.020318 model2 loss : 0.020508
[02:43:21.969] iteration 27547 : model1 loss : 0.022153 model2 loss : 0.022797
[02:43:22.624] iteration 27548 : model1 loss : 0.022751 model2 loss : 0.022078
[02:43:23.280] iteration 27549 : model1 loss : 0.017048 model2 loss : 0.016689
[02:43:23.940] iteration 27550 : model1 loss : 0.143111 model2 loss : 0.143602
[02:43:24.642] iteration 27551 : model1 loss : 0.051465 model2 loss : 0.058292
[02:43:25.309] iteration 27552 : model1 loss : 0.017957 model2 loss : 0.017834
[02:43:25.969] iteration 27553 : model1 loss : 0.017821 model2 loss : 0.018105
[02:43:26.635] iteration 27554 : model1 loss : 0.024136 model2 loss : 0.025818
[02:43:27.297] iteration 27555 : model1 loss : 0.021875 model2 loss : 0.019259
[02:43:27.946] iteration 27556 : model1 loss : 0.019188 model2 loss : 0.021288
[02:43:28.631] iteration 27557 : model1 loss : 0.019399 model2 loss : 0.020836
[02:43:29.304] iteration 27558 : model1 loss : 0.018032 model2 loss : 0.017714
[02:43:29.979] iteration 27559 : model1 loss : 0.021225 model2 loss : 0.019688
[02:43:30.635] iteration 27560 : model1 loss : 0.021164 model2 loss : 0.021327
[02:43:31.285] iteration 27561 : model1 loss : 0.024001 model2 loss : 0.024130
[02:43:31.940] iteration 27562 : model1 loss : 0.020620 model2 loss : 0.023215
[02:43:32.601] iteration 27563 : model1 loss : 0.014807 model2 loss : 0.015506
[02:43:33.256] iteration 27564 : model1 loss : 0.020703 model2 loss : 0.023500
[02:43:33.912] iteration 27565 : model1 loss : 0.017935 model2 loss : 0.017695
[02:43:34.569] iteration 27566 : model1 loss : 0.020352 model2 loss : 0.019477
[02:43:35.225] iteration 27567 : model1 loss : 0.017180 model2 loss : 0.017518
[02:43:35.884] iteration 27568 : model1 loss : 0.017765 model2 loss : 0.018251
[02:43:36.540] iteration 27569 : model1 loss : 0.015622 model2 loss : 0.014827
[02:43:37.197] iteration 27570 : model1 loss : 0.016255 model2 loss : 0.016980
[02:43:37.844] iteration 27571 : model1 loss : 0.015431 model2 loss : 0.016524
[02:43:38.515] iteration 27572 : model1 loss : 0.016443 model2 loss : 0.017138
[02:43:39.188] iteration 27573 : model1 loss : 0.016552 model2 loss : 0.016271
[02:43:39.854] iteration 27574 : model1 loss : 0.019363 model2 loss : 0.018642
[02:43:40.516] iteration 27575 : model1 loss : 0.019687 model2 loss : 0.020116
[02:43:41.167] iteration 27576 : model1 loss : 0.024139 model2 loss : 0.025731
[02:43:41.818] iteration 27577 : model1 loss : 0.023541 model2 loss : 0.024659
[02:43:42.473] iteration 27578 : model1 loss : 0.023698 model2 loss : 0.023731
[02:43:43.132] iteration 27579 : model1 loss : 0.023036 model2 loss : 0.023683
[02:43:43.804] iteration 27580 : model1 loss : 0.020684 model2 loss : 0.021767
[02:43:44.488] iteration 27581 : model1 loss : 0.021223 model2 loss : 0.019132
[02:43:45.151] iteration 27582 : model1 loss : 0.020768 model2 loss : 0.020830
[02:43:45.813] iteration 27583 : model1 loss : 0.021710 model2 loss : 0.023714
[02:43:46.472] iteration 27584 : model1 loss : 0.017401 model2 loss : 0.015832
[02:43:47.130] iteration 27585 : model1 loss : 0.017600 model2 loss : 0.018156
[02:43:47.796] iteration 27586 : model1 loss : 0.018526 model2 loss : 0.017823
[02:43:48.455] iteration 27587 : model1 loss : 0.019115 model2 loss : 0.019208
[02:43:49.107] iteration 27588 : model1 loss : 0.019604 model2 loss : 0.024805
[02:43:49.766] iteration 27589 : model1 loss : 0.018853 model2 loss : 0.019806
[02:43:50.429] iteration 27590 : model1 loss : 0.022622 model2 loss : 0.020272
[02:43:51.101] iteration 27591 : model1 loss : 0.017597 model2 loss : 0.017768
[02:43:51.755] iteration 27592 : model1 loss : 0.016655 model2 loss : 0.016892
[02:43:52.409] iteration 27593 : model1 loss : 0.015750 model2 loss : 0.015188
[02:43:53.067] iteration 27594 : model1 loss : 0.019771 model2 loss : 0.019004
[02:43:53.727] iteration 27595 : model1 loss : 0.019879 model2 loss : 0.019664
[02:43:54.387] iteration 27596 : model1 loss : 0.019951 model2 loss : 0.018875
[02:43:55.078] iteration 27597 : model1 loss : 0.020217 model2 loss : 0.019239
[02:43:55.753] iteration 27598 : model1 loss : 0.016703 model2 loss : 0.017196
[02:43:56.422] iteration 27599 : model1 loss : 0.020171 model2 loss : 0.022019
[02:43:57.084] iteration 27600 : model1 loss : 0.025657 model2 loss : 0.026566
[02:44:14.800] iteration 27600 : model1_mean_dice : 0.879115 model1_mean_hd95 : 6.753753
[02:44:32.342] iteration 27600 : model2_mean_dice : 0.881355 model2_mean_hd95 : 4.686064
[02:44:33.017] iteration 27601 : model1 loss : 0.017676 model2 loss : 0.018002
[02:44:33.672] iteration 27602 : model1 loss : 0.015292 model2 loss : 0.014775
[02:44:34.321] iteration 27603 : model1 loss : 0.020486 model2 loss : 0.020191
[02:44:34.975] iteration 27604 : model1 loss : 0.025882 model2 loss : 0.025259
[02:44:35.620] iteration 27605 : model1 loss : 0.020042 model2 loss : 0.021791
[02:44:36.286] iteration 27606 : model1 loss : 0.019666 model2 loss : 0.018457
[02:44:36.952] iteration 27607 : model1 loss : 0.018676 model2 loss : 0.016027
[02:44:37.598] iteration 27608 : model1 loss : 0.023807 model2 loss : 0.024506
[02:44:38.259] iteration 27609 : model1 loss : 0.022576 model2 loss : 0.022226
[02:44:38.917] iteration 27610 : model1 loss : 0.016613 model2 loss : 0.017060
[02:44:39.584] iteration 27611 : model1 loss : 0.020190 model2 loss : 0.019492
[02:44:40.232] iteration 27612 : model1 loss : 0.018065 model2 loss : 0.019360
[02:44:40.885] iteration 27613 : model1 loss : 0.022504 model2 loss : 0.021301
[02:44:41.545] iteration 27614 : model1 loss : 0.022660 model2 loss : 0.020186
[02:44:42.198] iteration 27615 : model1 loss : 0.022827 model2 loss : 0.023991
[02:44:42.852] iteration 27616 : model1 loss : 0.022842 model2 loss : 0.017424
[02:44:43.514] iteration 27617 : model1 loss : 0.023946 model2 loss : 0.021902
[02:44:44.169] iteration 27618 : model1 loss : 0.022443 model2 loss : 0.021522
[02:44:44.834] iteration 27619 : model1 loss : 0.024385 model2 loss : 0.024197
[02:44:45.494] iteration 27620 : model1 loss : 0.023966 model2 loss : 0.025097
[02:44:46.159] iteration 27621 : model1 loss : 0.020931 model2 loss : 0.022750
[02:44:46.812] iteration 27622 : model1 loss : 0.016077 model2 loss : 0.016694
[02:44:47.463] iteration 27623 : model1 loss : 0.017950 model2 loss : 0.017294
[02:44:48.123] iteration 27624 : model1 loss : 0.032076 model2 loss : 0.028198
[02:44:48.772] iteration 27625 : model1 loss : 0.017683 model2 loss : 0.016905
[02:44:49.446] iteration 27626 : model1 loss : 0.020368 model2 loss : 0.020171
[02:44:50.119] iteration 27627 : model1 loss : 0.017366 model2 loss : 0.017865
[02:44:50.771] iteration 27628 : model1 loss : 0.017198 model2 loss : 0.017017
[02:44:51.443] iteration 27629 : model1 loss : 0.015575 model2 loss : 0.015365
[02:44:52.092] iteration 27630 : model1 loss : 0.019340 model2 loss : 0.019618
[02:44:52.754] iteration 27631 : model1 loss : 0.023994 model2 loss : 0.020884
[02:44:53.412] iteration 27632 : model1 loss : 0.019072 model2 loss : 0.019558
[02:44:54.064] iteration 27633 : model1 loss : 0.020177 model2 loss : 0.017719
[02:44:54.708] iteration 27634 : model1 loss : 0.015236 model2 loss : 0.016550
[02:44:55.361] iteration 27635 : model1 loss : 0.019779 model2 loss : 0.021740
[02:44:56.028] iteration 27636 : model1 loss : 0.020616 model2 loss : 0.019644
[02:44:56.688] iteration 27637 : model1 loss : 0.015602 model2 loss : 0.015175
[02:44:57.340] iteration 27638 : model1 loss : 0.022954 model2 loss : 0.023262
[02:44:58.008] iteration 27639 : model1 loss : 0.015876 model2 loss : 0.015105
[02:44:58.677] iteration 27640 : model1 loss : 0.025563 model2 loss : 0.026235
[02:44:59.342] iteration 27641 : model1 loss : 0.020170 model2 loss : 0.019948
[02:44:59.988] iteration 27642 : model1 loss : 0.014811 model2 loss : 0.013637
[02:45:00.645] iteration 27643 : model1 loss : 0.020698 model2 loss : 0.022096
[02:45:01.305] iteration 27644 : model1 loss : 0.020264 model2 loss : 0.019826
[02:45:01.959] iteration 27645 : model1 loss : 0.019391 model2 loss : 0.022676
[02:45:02.632] iteration 27646 : model1 loss : 0.015138 model2 loss : 0.016105
[02:45:03.278] iteration 27647 : model1 loss : 0.016705 model2 loss : 0.016813
[02:45:03.932] iteration 27648 : model1 loss : 0.021940 model2 loss : 0.022239
[02:45:04.599] iteration 27649 : model1 loss : 0.021362 model2 loss : 0.020400
[02:45:05.288] iteration 27650 : model1 loss : 0.028233 model2 loss : 0.029453
[02:45:06.446] iteration 27651 : model1 loss : 0.027896 model2 loss : 0.024386
[02:45:07.187] iteration 27652 : model1 loss : 0.018015 model2 loss : 0.018816
[02:45:07.935] iteration 27653 : model1 loss : 0.019544 model2 loss : 0.019214
[02:45:08.656] iteration 27654 : model1 loss : 0.019788 model2 loss : 0.020824
[02:45:09.399] iteration 27655 : model1 loss : 0.025089 model2 loss : 0.028474
[02:45:10.084] iteration 27656 : model1 loss : 0.022149 model2 loss : 0.022957
[02:45:10.753] iteration 27657 : model1 loss : 0.027172 model2 loss : 0.027479
[02:45:11.420] iteration 27658 : model1 loss : 0.025708 model2 loss : 0.024201
[02:45:12.076] iteration 27659 : model1 loss : 0.035041 model2 loss : 0.032107
[02:45:12.756] iteration 27660 : model1 loss : 0.022358 model2 loss : 0.023741
[02:45:13.421] iteration 27661 : model1 loss : 0.021509 model2 loss : 0.020253
[02:45:14.083] iteration 27662 : model1 loss : 0.019312 model2 loss : 0.018352
[02:45:14.745] iteration 27663 : model1 loss : 0.027798 model2 loss : 0.026613
[02:45:15.414] iteration 27664 : model1 loss : 0.018585 model2 loss : 0.018010
[02:45:16.099] iteration 27665 : model1 loss : 0.029215 model2 loss : 0.022446
[02:45:16.777] iteration 27666 : model1 loss : 0.017687 model2 loss : 0.019253
[02:45:17.442] iteration 27667 : model1 loss : 0.019250 model2 loss : 0.019674
[02:45:18.113] iteration 27668 : model1 loss : 0.027682 model2 loss : 0.031082
[02:45:18.774] iteration 27669 : model1 loss : 0.016139 model2 loss : 0.016942
[02:45:19.461] iteration 27670 : model1 loss : 0.033245 model2 loss : 0.031605
[02:45:20.185] iteration 27671 : model1 loss : 0.016449 model2 loss : 0.016526
[02:45:20.945] iteration 27672 : model1 loss : 0.019629 model2 loss : 0.018801
[02:45:21.890] iteration 27673 : model1 loss : 0.017269 model2 loss : 0.017818
[02:45:22.618] iteration 27674 : model1 loss : 0.026131 model2 loss : 0.025490
[02:45:23.295] iteration 27675 : model1 loss : 0.018193 model2 loss : 0.020973
[02:45:23.991] iteration 27676 : model1 loss : 0.024111 model2 loss : 0.025031
[02:45:24.687] iteration 27677 : model1 loss : 0.021569 model2 loss : 0.021587
[02:45:25.361] iteration 27678 : model1 loss : 0.017053 model2 loss : 0.017865
[02:45:26.034] iteration 27679 : model1 loss : 0.016020 model2 loss : 0.016543
[02:45:26.723] iteration 27680 : model1 loss : 0.016407 model2 loss : 0.016322
[02:45:27.433] iteration 27681 : model1 loss : 0.021915 model2 loss : 0.019602
[02:45:28.167] iteration 27682 : model1 loss : 0.015761 model2 loss : 0.015758
[02:45:28.835] iteration 27683 : model1 loss : 0.017257 model2 loss : 0.017708
[02:45:29.511] iteration 27684 : model1 loss : 0.022444 model2 loss : 0.023443
[02:45:30.198] iteration 27685 : model1 loss : 0.019799 model2 loss : 0.018633
[02:45:30.875] iteration 27686 : model1 loss : 0.018859 model2 loss : 0.016723
[02:45:31.543] iteration 27687 : model1 loss : 0.025155 model2 loss : 0.024007
[02:45:32.211] iteration 27688 : model1 loss : 0.021915 model2 loss : 0.023205
[02:45:32.885] iteration 27689 : model1 loss : 0.018496 model2 loss : 0.019152
[02:45:33.550] iteration 27690 : model1 loss : 0.018333 model2 loss : 0.019377
[02:45:34.214] iteration 27691 : model1 loss : 0.024785 model2 loss : 0.027526
[02:45:34.876] iteration 27692 : model1 loss : 0.016199 model2 loss : 0.016913
[02:45:35.530] iteration 27693 : model1 loss : 0.036120 model2 loss : 0.025842
[02:45:36.194] iteration 27694 : model1 loss : 0.021256 model2 loss : 0.022620
[02:45:36.866] iteration 27695 : model1 loss : 0.020829 model2 loss : 0.021079
[02:45:37.534] iteration 27696 : model1 loss : 0.018095 model2 loss : 0.018868
[02:45:38.210] iteration 27697 : model1 loss : 0.019437 model2 loss : 0.018814
[02:45:38.865] iteration 27698 : model1 loss : 0.025468 model2 loss : 0.025375
[02:45:39.525] iteration 27699 : model1 loss : 0.012656 model2 loss : 0.013482
[02:45:40.186] iteration 27700 : model1 loss : 0.019958 model2 loss : 0.022296
[02:45:40.898] iteration 27701 : model1 loss : 0.016062 model2 loss : 0.015382
[02:45:41.557] iteration 27702 : model1 loss : 0.014979 model2 loss : 0.014864
[02:45:42.234] iteration 27703 : model1 loss : 0.017469 model2 loss : 0.018868
[02:45:42.920] iteration 27704 : model1 loss : 0.030146 model2 loss : 0.028844
[02:45:43.609] iteration 27705 : model1 loss : 0.040667 model2 loss : 0.053221
[02:45:44.310] iteration 27706 : model1 loss : 0.018416 model2 loss : 0.019843
[02:45:44.974] iteration 27707 : model1 loss : 0.021026 model2 loss : 0.021185
[02:45:45.646] iteration 27708 : model1 loss : 0.019135 model2 loss : 0.017898
[02:45:46.330] iteration 27709 : model1 loss : 0.020085 model2 loss : 0.019786
[02:45:47.001] iteration 27710 : model1 loss : 0.023091 model2 loss : 0.022440
[02:45:47.707] iteration 27711 : model1 loss : 0.016189 model2 loss : 0.015160
[02:45:48.398] iteration 27712 : model1 loss : 0.021184 model2 loss : 0.019176
[02:45:49.100] iteration 27713 : model1 loss : 0.044881 model2 loss : 0.049647
[02:45:49.781] iteration 27714 : model1 loss : 0.026795 model2 loss : 0.027673
[02:45:50.465] iteration 27715 : model1 loss : 0.142672 model2 loss : 0.143109
[02:45:51.155] iteration 27716 : model1 loss : 0.018644 model2 loss : 0.020268
[02:45:51.854] iteration 27717 : model1 loss : 0.016005 model2 loss : 0.014566
[02:45:52.559] iteration 27718 : model1 loss : 0.019287 model2 loss : 0.020636
[02:45:53.257] iteration 27719 : model1 loss : 0.022142 model2 loss : 0.022826
[02:45:53.944] iteration 27720 : model1 loss : 0.015286 model2 loss : 0.014164
[02:45:54.648] iteration 27721 : model1 loss : 0.017319 model2 loss : 0.016591
[02:45:55.353] iteration 27722 : model1 loss : 0.019742 model2 loss : 0.020391
[02:45:56.041] iteration 27723 : model1 loss : 0.022282 model2 loss : 0.022603
[02:45:56.742] iteration 27724 : model1 loss : 0.020662 model2 loss : 0.019656
[02:45:57.431] iteration 27725 : model1 loss : 0.020255 model2 loss : 0.019641
[02:45:58.127] iteration 27726 : model1 loss : 0.017942 model2 loss : 0.018495
[02:45:58.817] iteration 27727 : model1 loss : 0.094381 model2 loss : 0.084222
[02:45:59.520] iteration 27728 : model1 loss : 0.020208 model2 loss : 0.021433
[02:46:00.229] iteration 27729 : model1 loss : 0.028385 model2 loss : 0.027678
[02:46:00.922] iteration 27730 : model1 loss : 0.020168 model2 loss : 0.021348
[02:46:01.619] iteration 27731 : model1 loss : 0.018157 model2 loss : 0.017153
[02:46:02.304] iteration 27732 : model1 loss : 0.026937 model2 loss : 0.026721
[02:46:02.993] iteration 27733 : model1 loss : 0.022756 model2 loss : 0.022099
[02:46:03.663] iteration 27734 : model1 loss : 0.019305 model2 loss : 0.019424
[02:46:04.324] iteration 27735 : model1 loss : 0.021956 model2 loss : 0.020610
[02:46:04.979] iteration 27736 : model1 loss : 0.024489 model2 loss : 0.024685
[02:46:05.678] iteration 27737 : model1 loss : 0.017770 model2 loss : 0.018077
[02:46:06.355] iteration 27738 : model1 loss : 0.043750 model2 loss : 0.042069
[02:46:07.028] iteration 27739 : model1 loss : 0.021934 model2 loss : 0.021441
[02:46:07.689] iteration 27740 : model1 loss : 0.137092 model2 loss : 0.135967
[02:46:08.358] iteration 27741 : model1 loss : 0.014422 model2 loss : 0.014510
[02:46:09.029] iteration 27742 : model1 loss : 0.027539 model2 loss : 0.024248
[02:46:09.685] iteration 27743 : model1 loss : 0.020969 model2 loss : 0.021598
[02:46:10.382] iteration 27744 : model1 loss : 0.037321 model2 loss : 0.037427
[02:46:11.053] iteration 27745 : model1 loss : 0.017751 model2 loss : 0.018477
[02:46:11.714] iteration 27746 : model1 loss : 0.026004 model2 loss : 0.023946
[02:46:12.388] iteration 27747 : model1 loss : 0.021327 model2 loss : 0.018313
[02:46:13.048] iteration 27748 : model1 loss : 0.019945 model2 loss : 0.018679
[02:46:13.725] iteration 27749 : model1 loss : 0.021692 model2 loss : 0.022900
[02:46:14.396] iteration 27750 : model1 loss : 0.015734 model2 loss : 0.016223
[02:46:15.090] iteration 27751 : model1 loss : 0.015817 model2 loss : 0.015517
[02:46:15.766] iteration 27752 : model1 loss : 0.028655 model2 loss : 0.029760
[02:46:16.429] iteration 27753 : model1 loss : 0.026790 model2 loss : 0.022337
[02:46:17.089] iteration 27754 : model1 loss : 0.019029 model2 loss : 0.018095
[02:46:17.756] iteration 27755 : model1 loss : 0.025290 model2 loss : 0.025214
[02:46:18.424] iteration 27756 : model1 loss : 0.018125 model2 loss : 0.015496
[02:46:19.088] iteration 27757 : model1 loss : 0.015545 model2 loss : 0.016926
[02:46:19.759] iteration 27758 : model1 loss : 0.016906 model2 loss : 0.017159
[02:46:20.427] iteration 27759 : model1 loss : 0.018541 model2 loss : 0.018960
[02:46:21.096] iteration 27760 : model1 loss : 0.018307 model2 loss : 0.016506
[02:46:21.759] iteration 27761 : model1 loss : 0.022176 model2 loss : 0.024551
[02:46:22.418] iteration 27762 : model1 loss : 0.015423 model2 loss : 0.015482
[02:46:23.086] iteration 27763 : model1 loss : 0.022288 model2 loss : 0.023990
[02:46:23.748] iteration 27764 : model1 loss : 0.019204 model2 loss : 0.019500
[02:46:24.407] iteration 27765 : model1 loss : 0.013849 model2 loss : 0.013495
[02:46:25.081] iteration 27766 : model1 loss : 0.143280 model2 loss : 0.141816
[02:46:25.755] iteration 27767 : model1 loss : 0.022295 model2 loss : 0.020784
[02:46:26.418] iteration 27768 : model1 loss : 0.013931 model2 loss : 0.014849
[02:46:27.074] iteration 27769 : model1 loss : 0.020526 model2 loss : 0.021759
[02:46:27.743] iteration 27770 : model1 loss : 0.019292 model2 loss : 0.017334
[02:46:28.408] iteration 27771 : model1 loss : 0.017441 model2 loss : 0.017554
[02:46:29.076] iteration 27772 : model1 loss : 0.020490 model2 loss : 0.019181
[02:46:29.746] iteration 27773 : model1 loss : 0.016592 model2 loss : 0.017333
[02:46:30.413] iteration 27774 : model1 loss : 0.014072 model2 loss : 0.014821
[02:46:31.081] iteration 27775 : model1 loss : 0.022714 model2 loss : 0.023197
[02:46:31.742] iteration 27776 : model1 loss : 0.016640 model2 loss : 0.018137
[02:46:32.413] iteration 27777 : model1 loss : 0.017660 model2 loss : 0.019427
[02:46:33.083] iteration 27778 : model1 loss : 0.024235 model2 loss : 0.024141
[02:46:33.742] iteration 27779 : model1 loss : 0.020295 model2 loss : 0.020246
[02:46:34.409] iteration 27780 : model1 loss : 0.022385 model2 loss : 0.024430
[02:46:35.064] iteration 27781 : model1 loss : 0.016208 model2 loss : 0.016321
[02:46:35.760] iteration 27782 : model1 loss : 0.022624 model2 loss : 0.022972
[02:46:36.419] iteration 27783 : model1 loss : 0.026286 model2 loss : 0.022453
[02:46:37.076] iteration 27784 : model1 loss : 0.021464 model2 loss : 0.024554
[02:46:37.745] iteration 27785 : model1 loss : 0.021478 model2 loss : 0.022858
[02:46:38.414] iteration 27786 : model1 loss : 0.019272 model2 loss : 0.016958
[02:46:39.092] iteration 27787 : model1 loss : 0.019853 model2 loss : 0.020152
[02:46:39.754] iteration 27788 : model1 loss : 0.021816 model2 loss : 0.021645
[02:46:40.419] iteration 27789 : model1 loss : 0.019744 model2 loss : 0.020997
[02:46:41.088] iteration 27790 : model1 loss : 0.019066 model2 loss : 0.017146
[02:46:41.755] iteration 27791 : model1 loss : 0.015292 model2 loss : 0.016534
[02:46:42.454] iteration 27792 : model1 loss : 0.017611 model2 loss : 0.017774
[02:46:43.123] iteration 27793 : model1 loss : 0.023141 model2 loss : 0.021490
[02:46:43.789] iteration 27794 : model1 loss : 0.020087 model2 loss : 0.018322
[02:46:44.488] iteration 27795 : model1 loss : 0.022724 model2 loss : 0.017172
[02:46:45.149] iteration 27796 : model1 loss : 0.032762 model2 loss : 0.030122
[02:46:45.816] iteration 27797 : model1 loss : 0.025617 model2 loss : 0.025428
[02:46:46.469] iteration 27798 : model1 loss : 0.020444 model2 loss : 0.020726
[02:46:47.148] iteration 27799 : model1 loss : 0.021386 model2 loss : 0.022783
[02:46:47.813] iteration 27800 : model1 loss : 0.018721 model2 loss : 0.016834
[02:47:05.991] iteration 27800 : model1_mean_dice : 0.879864 model1_mean_hd95 : 6.769106
[02:47:23.984] iteration 27800 : model2_mean_dice : 0.881845 model2_mean_hd95 : 4.551279
[02:47:24.671] iteration 27801 : model1 loss : 0.021057 model2 loss : 0.019719
[02:47:25.344] iteration 27802 : model1 loss : 0.017341 model2 loss : 0.018848
[02:47:25.997] iteration 27803 : model1 loss : 0.023693 model2 loss : 0.029896
[02:47:26.660] iteration 27804 : model1 loss : 0.022087 model2 loss : 0.020205
[02:47:27.333] iteration 27805 : model1 loss : 0.019999 model2 loss : 0.019272
[02:47:28.009] iteration 27806 : model1 loss : 0.028201 model2 loss : 0.022488
[02:47:28.681] iteration 27807 : model1 loss : 0.019398 model2 loss : 0.019162
[02:47:29.344] iteration 27808 : model1 loss : 0.023612 model2 loss : 0.022407
[02:47:29.994] iteration 27809 : model1 loss : 0.018333 model2 loss : 0.019711
[02:47:30.649] iteration 27810 : model1 loss : 0.029055 model2 loss : 0.031351
[02:47:31.317] iteration 27811 : model1 loss : 0.020147 model2 loss : 0.020173
[02:47:31.976] iteration 27812 : model1 loss : 0.016640 model2 loss : 0.015976
[02:47:32.646] iteration 27813 : model1 loss : 0.015559 model2 loss : 0.016248
[02:47:33.320] iteration 27814 : model1 loss : 0.018344 model2 loss : 0.021817
[02:47:33.985] iteration 27815 : model1 loss : 0.019794 model2 loss : 0.020227
[02:47:34.640] iteration 27816 : model1 loss : 0.020940 model2 loss : 0.019316
[02:47:35.298] iteration 27817 : model1 loss : 0.018013 model2 loss : 0.019668
[02:47:35.950] iteration 27818 : model1 loss : 0.018127 model2 loss : 0.019660
[02:47:36.614] iteration 27819 : model1 loss : 0.021084 model2 loss : 0.019701
[02:47:37.274] iteration 27820 : model1 loss : 0.016371 model2 loss : 0.017091
[02:47:37.944] iteration 27821 : model1 loss : 0.017376 model2 loss : 0.016919
[02:47:38.607] iteration 27822 : model1 loss : 0.018480 model2 loss : 0.017089
[02:47:39.268] iteration 27823 : model1 loss : 0.019923 model2 loss : 0.018638
[02:47:39.923] iteration 27824 : model1 loss : 0.016129 model2 loss : 0.015808
[02:47:40.581] iteration 27825 : model1 loss : 0.019310 model2 loss : 0.020190
[02:47:41.244] iteration 27826 : model1 loss : 0.020331 model2 loss : 0.022039
[02:47:41.899] iteration 27827 : model1 loss : 0.012663 model2 loss : 0.013304
[02:47:42.560] iteration 27828 : model1 loss : 0.017685 model2 loss : 0.017623
[02:47:43.226] iteration 27829 : model1 loss : 0.020964 model2 loss : 0.020251
[02:47:43.881] iteration 27830 : model1 loss : 0.020450 model2 loss : 0.020276
[02:47:44.554] iteration 27831 : model1 loss : 0.016901 model2 loss : 0.016620
[02:47:45.211] iteration 27832 : model1 loss : 0.019194 model2 loss : 0.021431
[02:47:45.870] iteration 27833 : model1 loss : 0.030112 model2 loss : 0.034230
[02:47:46.538] iteration 27834 : model1 loss : 0.019347 model2 loss : 0.018640
[02:47:47.202] iteration 27835 : model1 loss : 0.019180 model2 loss : 0.018478
[02:47:47.865] iteration 27836 : model1 loss : 0.019162 model2 loss : 0.023459
[02:47:48.551] iteration 27837 : model1 loss : 0.020251 model2 loss : 0.019970
[02:47:49.221] iteration 27838 : model1 loss : 0.017162 model2 loss : 0.016853
[02:47:49.881] iteration 27839 : model1 loss : 0.016597 model2 loss : 0.017578
[02:47:50.540] iteration 27840 : model1 loss : 0.017980 model2 loss : 0.019678
[02:47:51.207] iteration 27841 : model1 loss : 0.020141 model2 loss : 0.020921
[02:47:51.879] iteration 27842 : model1 loss : 0.023810 model2 loss : 0.024107
[02:47:52.536] iteration 27843 : model1 loss : 0.021347 model2 loss : 0.022148
[02:47:53.198] iteration 27844 : model1 loss : 0.018984 model2 loss : 0.019170
[02:47:53.861] iteration 27845 : model1 loss : 0.017621 model2 loss : 0.016076
[02:47:54.527] iteration 27846 : model1 loss : 0.020176 model2 loss : 0.021471
[02:47:55.189] iteration 27847 : model1 loss : 0.021144 model2 loss : 0.020365
[02:47:55.852] iteration 27848 : model1 loss : 0.019994 model2 loss : 0.020427
[02:47:56.508] iteration 27849 : model1 loss : 0.031126 model2 loss : 0.025631
[02:47:57.164] iteration 27850 : model1 loss : 0.015414 model2 loss : 0.016823
[02:47:57.883] iteration 27851 : model1 loss : 0.016745 model2 loss : 0.014939
[02:47:58.555] iteration 27852 : model1 loss : 0.020783 model2 loss : 0.023200
[02:47:59.224] iteration 27853 : model1 loss : 0.017568 model2 loss : 0.016822
[02:47:59.886] iteration 27854 : model1 loss : 0.018879 model2 loss : 0.018932
[02:48:00.555] iteration 27855 : model1 loss : 0.020435 model2 loss : 0.020019
[02:48:01.221] iteration 27856 : model1 loss : 0.019163 model2 loss : 0.017560
[02:48:01.882] iteration 27857 : model1 loss : 0.016282 model2 loss : 0.017758
[02:48:02.557] iteration 27858 : model1 loss : 0.021328 model2 loss : 0.019159
[02:48:03.233] iteration 27859 : model1 loss : 0.019422 model2 loss : 0.019156
[02:48:03.904] iteration 27860 : model1 loss : 0.022235 model2 loss : 0.022516
[02:48:04.574] iteration 27861 : model1 loss : 0.029955 model2 loss : 0.030109
[02:48:05.237] iteration 27862 : model1 loss : 0.017641 model2 loss : 0.016169
[02:48:05.889] iteration 27863 : model1 loss : 0.021094 model2 loss : 0.022532
[02:48:06.600] iteration 27864 : model1 loss : 0.020923 model2 loss : 0.020149
[02:48:07.273] iteration 27865 : model1 loss : 0.020520 model2 loss : 0.020222
[02:48:07.939] iteration 27866 : model1 loss : 0.024519 model2 loss : 0.024570
[02:48:08.616] iteration 27867 : model1 loss : 0.021343 model2 loss : 0.020623
[02:48:09.282] iteration 27868 : model1 loss : 0.017575 model2 loss : 0.018125
[02:48:09.946] iteration 27869 : model1 loss : 0.021750 model2 loss : 0.019668
[02:48:10.605] iteration 27870 : model1 loss : 0.017598 model2 loss : 0.016324
[02:48:11.271] iteration 27871 : model1 loss : 0.021678 model2 loss : 0.019884
[02:48:11.946] iteration 27872 : model1 loss : 0.017924 model2 loss : 0.018562
[02:48:12.610] iteration 27873 : model1 loss : 0.022729 model2 loss : 0.022205
[02:48:13.275] iteration 27874 : model1 loss : 0.019435 model2 loss : 0.018157
[02:48:13.948] iteration 27875 : model1 loss : 0.022708 model2 loss : 0.022087
[02:48:14.608] iteration 27876 : model1 loss : 0.016615 model2 loss : 0.015659
[02:48:15.282] iteration 27877 : model1 loss : 0.023064 model2 loss : 0.024867
[02:48:15.943] iteration 27878 : model1 loss : 0.017141 model2 loss : 0.017286
[02:48:16.615] iteration 27879 : model1 loss : 0.015136 model2 loss : 0.016345
[02:48:17.289] iteration 27880 : model1 loss : 0.022835 model2 loss : 0.024018
[02:48:17.961] iteration 27881 : model1 loss : 0.016603 model2 loss : 0.019090
[02:48:18.636] iteration 27882 : model1 loss : 0.019114 model2 loss : 0.019225
[02:48:19.306] iteration 27883 : model1 loss : 0.017143 model2 loss : 0.019053
[02:48:19.971] iteration 27884 : model1 loss : 0.019908 model2 loss : 0.020781
[02:48:20.652] iteration 27885 : model1 loss : 0.014876 model2 loss : 0.015544
[02:48:21.325] iteration 27886 : model1 loss : 0.016199 model2 loss : 0.016920
[02:48:21.994] iteration 27887 : model1 loss : 0.023000 model2 loss : 0.022582
[02:48:22.663] iteration 27888 : model1 loss : 0.020121 model2 loss : 0.018492
[02:48:23.338] iteration 27889 : model1 loss : 0.026118 model2 loss : 0.025906
[02:48:24.001] iteration 27890 : model1 loss : 0.016893 model2 loss : 0.017303
[02:48:24.655] iteration 27891 : model1 loss : 0.022187 model2 loss : 0.021479
[02:48:25.320] iteration 27892 : model1 loss : 0.030362 model2 loss : 0.029666
[02:48:25.988] iteration 27893 : model1 loss : 0.024703 model2 loss : 0.024844
[02:48:26.644] iteration 27894 : model1 loss : 0.016430 model2 loss : 0.016898
[02:48:27.308] iteration 27895 : model1 loss : 0.023517 model2 loss : 0.019878
[02:48:27.982] iteration 27896 : model1 loss : 0.025035 model2 loss : 0.023749
[02:48:28.666] iteration 27897 : model1 loss : 0.017959 model2 loss : 0.018641
[02:48:29.341] iteration 27898 : model1 loss : 0.018256 model2 loss : 0.017975
[02:48:30.014] iteration 27899 : model1 loss : 0.021898 model2 loss : 0.020526
[02:48:30.678] iteration 27900 : model1 loss : 0.021311 model2 loss : 0.022882
[02:48:31.397] iteration 27901 : model1 loss : 0.018689 model2 loss : 0.019393
[02:48:32.057] iteration 27902 : model1 loss : 0.017984 model2 loss : 0.016652
[02:48:32.720] iteration 27903 : model1 loss : 0.020894 model2 loss : 0.020512
[02:48:33.379] iteration 27904 : model1 loss : 0.020658 model2 loss : 0.019071
[02:48:34.042] iteration 27905 : model1 loss : 0.016303 model2 loss : 0.016096
[02:48:34.705] iteration 27906 : model1 loss : 0.017206 model2 loss : 0.018171
[02:48:35.365] iteration 27907 : model1 loss : 0.028391 model2 loss : 0.026929
[02:48:36.027] iteration 27908 : model1 loss : 0.023169 model2 loss : 0.023651
[02:48:36.687] iteration 27909 : model1 loss : 0.017932 model2 loss : 0.020361
[02:48:37.376] iteration 27910 : model1 loss : 0.017369 model2 loss : 0.018040
[02:48:38.039] iteration 27911 : model1 loss : 0.033643 model2 loss : 0.036747
[02:48:38.704] iteration 27912 : model1 loss : 0.142537 model2 loss : 0.142138
[02:48:39.383] iteration 27913 : model1 loss : 0.017819 model2 loss : 0.016843
[02:48:40.045] iteration 27914 : model1 loss : 0.018809 model2 loss : 0.018531
[02:48:40.720] iteration 27915 : model1 loss : 0.020852 model2 loss : 0.019669
[02:48:41.383] iteration 27916 : model1 loss : 0.015881 model2 loss : 0.016129
[02:48:42.051] iteration 27917 : model1 loss : 0.018941 model2 loss : 0.019132
[02:48:42.727] iteration 27918 : model1 loss : 0.157208 model2 loss : 0.159537
[02:48:43.393] iteration 27919 : model1 loss : 0.019738 model2 loss : 0.019883
[02:48:44.064] iteration 27920 : model1 loss : 0.022646 model2 loss : 0.022641
[02:48:44.729] iteration 27921 : model1 loss : 0.018766 model2 loss : 0.019789
[02:48:45.406] iteration 27922 : model1 loss : 0.019317 model2 loss : 0.017848
[02:48:46.073] iteration 27923 : model1 loss : 0.026308 model2 loss : 0.025422
[02:48:46.742] iteration 27924 : model1 loss : 0.018849 model2 loss : 0.019983
[02:48:47.414] iteration 27925 : model1 loss : 0.016191 model2 loss : 0.015428
[02:48:48.071] iteration 27926 : model1 loss : 0.021662 model2 loss : 0.020414
[02:48:48.742] iteration 27927 : model1 loss : 0.023136 model2 loss : 0.023206
[02:48:49.424] iteration 27928 : model1 loss : 0.017422 model2 loss : 0.017779
[02:48:50.097] iteration 27929 : model1 loss : 0.017339 model2 loss : 0.016668
[02:48:50.771] iteration 27930 : model1 loss : 0.025528 model2 loss : 0.026169
[02:48:51.441] iteration 27931 : model1 loss : 0.017635 model2 loss : 0.019239
[02:48:52.099] iteration 27932 : model1 loss : 0.016883 model2 loss : 0.016976
[02:48:52.770] iteration 27933 : model1 loss : 0.018681 model2 loss : 0.018399
[02:48:53.437] iteration 27934 : model1 loss : 0.036936 model2 loss : 0.037453
[02:48:54.101] iteration 27935 : model1 loss : 0.019577 model2 loss : 0.018496
[02:48:54.768] iteration 27936 : model1 loss : 0.032917 model2 loss : 0.033057
[02:48:55.433] iteration 27937 : model1 loss : 0.017314 model2 loss : 0.019639
[02:48:56.104] iteration 27938 : model1 loss : 0.014111 model2 loss : 0.015556
[02:48:56.761] iteration 27939 : model1 loss : 0.017059 model2 loss : 0.016258
[02:48:57.424] iteration 27940 : model1 loss : 0.023140 model2 loss : 0.021659
[02:48:58.096] iteration 27941 : model1 loss : 0.030981 model2 loss : 0.033142
[02:48:58.773] iteration 27942 : model1 loss : 0.019408 model2 loss : 0.018678
[02:48:59.431] iteration 27943 : model1 loss : 0.014006 model2 loss : 0.016134
[02:49:00.102] iteration 27944 : model1 loss : 0.019454 model2 loss : 0.019951
[02:49:00.758] iteration 27945 : model1 loss : 0.016822 model2 loss : 0.017954
[02:49:01.429] iteration 27946 : model1 loss : 0.017247 model2 loss : 0.018778
[02:49:02.090] iteration 27947 : model1 loss : 0.021410 model2 loss : 0.021591
[02:49:02.758] iteration 27948 : model1 loss : 0.024713 model2 loss : 0.023686
[02:49:03.426] iteration 27949 : model1 loss : 0.018207 model2 loss : 0.017859
[02:49:04.079] iteration 27950 : model1 loss : 0.029567 model2 loss : 0.028084
[02:49:04.787] iteration 27951 : model1 loss : 0.020364 model2 loss : 0.019461
[02:49:05.448] iteration 27952 : model1 loss : 0.017264 model2 loss : 0.018260
[02:49:06.108] iteration 27953 : model1 loss : 0.030132 model2 loss : 0.029553
[02:49:06.773] iteration 27954 : model1 loss : 0.015470 model2 loss : 0.015136
[02:49:07.435] iteration 27955 : model1 loss : 0.020636 model2 loss : 0.018116
[02:49:08.101] iteration 27956 : model1 loss : 0.024321 model2 loss : 0.029632
[02:49:08.758] iteration 27957 : model1 loss : 0.015423 model2 loss : 0.015836
[02:49:09.428] iteration 27958 : model1 loss : 0.018650 model2 loss : 0.017462
[02:49:10.087] iteration 27959 : model1 loss : 0.022177 model2 loss : 0.020985
[02:49:10.742] iteration 27960 : model1 loss : 0.019367 model2 loss : 0.021472
[02:49:11.406] iteration 27961 : model1 loss : 0.025368 model2 loss : 0.024395
[02:49:12.069] iteration 27962 : model1 loss : 0.031074 model2 loss : 0.027255
[02:49:12.739] iteration 27963 : model1 loss : 0.016157 model2 loss : 0.014984
[02:49:13.407] iteration 27964 : model1 loss : 0.018150 model2 loss : 0.018377
[02:49:14.065] iteration 27965 : model1 loss : 0.022026 model2 loss : 0.018912
[02:49:14.738] iteration 27966 : model1 loss : 0.015933 model2 loss : 0.017194
[02:49:15.412] iteration 27967 : model1 loss : 0.016406 model2 loss : 0.015045
[02:49:16.081] iteration 27968 : model1 loss : 0.020574 model2 loss : 0.020314
[02:49:16.744] iteration 27969 : model1 loss : 0.019277 model2 loss : 0.017009
[02:49:17.410] iteration 27970 : model1 loss : 0.019516 model2 loss : 0.016984
[02:49:18.070] iteration 27971 : model1 loss : 0.019422 model2 loss : 0.020501
[02:49:18.739] iteration 27972 : model1 loss : 0.018390 model2 loss : 0.019951
[02:49:19.400] iteration 27973 : model1 loss : 0.015228 model2 loss : 0.016068
[02:49:20.072] iteration 27974 : model1 loss : 0.016400 model2 loss : 0.017172
[02:49:20.748] iteration 27975 : model1 loss : 0.015837 model2 loss : 0.016113
[02:49:21.419] iteration 27976 : model1 loss : 0.016681 model2 loss : 0.015846
[02:49:22.094] iteration 27977 : model1 loss : 0.022013 model2 loss : 0.021646
[02:49:22.765] iteration 27978 : model1 loss : 0.024686 model2 loss : 0.021288
[02:49:23.431] iteration 27979 : model1 loss : 0.028484 model2 loss : 0.026781
[02:49:24.093] iteration 27980 : model1 loss : 0.020363 model2 loss : 0.022544
[02:49:24.750] iteration 27981 : model1 loss : 0.024094 model2 loss : 0.024356
[02:49:25.409] iteration 27982 : model1 loss : 0.025913 model2 loss : 0.025471
[02:49:26.078] iteration 27983 : model1 loss : 0.022003 model2 loss : 0.021811
[02:49:26.742] iteration 27984 : model1 loss : 0.015212 model2 loss : 0.014470
[02:49:27.412] iteration 27985 : model1 loss : 0.026515 model2 loss : 0.023181
[02:49:28.065] iteration 27986 : model1 loss : 0.024113 model2 loss : 0.024522
[02:49:28.741] iteration 27987 : model1 loss : 0.019252 model2 loss : 0.018223
[02:49:29.401] iteration 27988 : model1 loss : 0.020837 model2 loss : 0.020190
[02:49:30.073] iteration 27989 : model1 loss : 0.017258 model2 loss : 0.018989
[02:49:30.762] iteration 27990 : model1 loss : 0.020815 model2 loss : 0.019348
[02:49:31.431] iteration 27991 : model1 loss : 0.021088 model2 loss : 0.021531
[02:49:32.104] iteration 27992 : model1 loss : 0.016322 model2 loss : 0.018391
[02:49:32.775] iteration 27993 : model1 loss : 0.024694 model2 loss : 0.023405
[02:49:33.452] iteration 27994 : model1 loss : 0.022590 model2 loss : 0.022088
[02:49:34.108] iteration 27995 : model1 loss : 0.025598 model2 loss : 0.022935
[02:49:34.772] iteration 27996 : model1 loss : 0.017474 model2 loss : 0.017678
[02:49:35.443] iteration 27997 : model1 loss : 0.016164 model2 loss : 0.016118
[02:49:36.101] iteration 27998 : model1 loss : 0.020664 model2 loss : 0.023955
[02:49:36.759] iteration 27999 : model1 loss : 0.018274 model2 loss : 0.017920
[02:49:37.433] iteration 28000 : model1 loss : 0.017720 model2 loss : 0.019691
[02:49:55.595] iteration 28000 : model1_mean_dice : 0.879453 model1_mean_hd95 : 6.253204
[02:50:13.607] iteration 28000 : model2_mean_dice : 0.881230 model2_mean_hd95 : 4.061112
[02:50:14.291] iteration 28001 : model1 loss : 0.018356 model2 loss : 0.017588
[02:50:14.955] iteration 28002 : model1 loss : 0.017669 model2 loss : 0.017617
[02:50:15.614] iteration 28003 : model1 loss : 0.022990 model2 loss : 0.022918
[02:50:16.267] iteration 28004 : model1 loss : 0.017705 model2 loss : 0.019004
[02:50:16.934] iteration 28005 : model1 loss : 0.018246 model2 loss : 0.018726
[02:50:17.586] iteration 28006 : model1 loss : 0.023214 model2 loss : 0.022308
[02:50:18.255] iteration 28007 : model1 loss : 0.026304 model2 loss : 0.022380
[02:50:18.916] iteration 28008 : model1 loss : 0.020074 model2 loss : 0.018366
[02:50:19.578] iteration 28009 : model1 loss : 0.018770 model2 loss : 0.020481
[02:50:20.237] iteration 28010 : model1 loss : 0.018335 model2 loss : 0.018976
[02:50:20.895] iteration 28011 : model1 loss : 0.024785 model2 loss : 0.025689
[02:50:21.581] iteration 28012 : model1 loss : 0.019613 model2 loss : 0.022577
[02:50:22.246] iteration 28013 : model1 loss : 0.020677 model2 loss : 0.020309
[02:50:22.906] iteration 28014 : model1 loss : 0.019653 model2 loss : 0.018653
[02:50:23.570] iteration 28015 : model1 loss : 0.022682 model2 loss : 0.025387
[02:50:24.235] iteration 28016 : model1 loss : 0.018829 model2 loss : 0.019740
[02:50:24.891] iteration 28017 : model1 loss : 0.016432 model2 loss : 0.017878
[02:50:25.543] iteration 28018 : model1 loss : 0.021508 model2 loss : 0.021096
[02:50:26.204] iteration 28019 : model1 loss : 0.015724 model2 loss : 0.018508
[02:50:26.872] iteration 28020 : model1 loss : 0.017058 model2 loss : 0.016544
[02:50:27.525] iteration 28021 : model1 loss : 0.014551 model2 loss : 0.015863
[02:50:28.185] iteration 28022 : model1 loss : 0.018512 model2 loss : 0.018973
[02:50:28.854] iteration 28023 : model1 loss : 0.027514 model2 loss : 0.029155
[02:50:29.511] iteration 28024 : model1 loss : 0.018648 model2 loss : 0.018976
[02:50:30.174] iteration 28025 : model1 loss : 0.018950 model2 loss : 0.018198
[02:50:30.845] iteration 28026 : model1 loss : 0.024182 model2 loss : 0.024027
[02:50:31.511] iteration 28027 : model1 loss : 0.014450 model2 loss : 0.013916
[02:50:32.176] iteration 28028 : model1 loss : 0.018081 model2 loss : 0.017784
[02:50:32.833] iteration 28029 : model1 loss : 0.019552 model2 loss : 0.019094
[02:50:33.495] iteration 28030 : model1 loss : 0.017396 model2 loss : 0.016633
[02:50:34.150] iteration 28031 : model1 loss : 0.028662 model2 loss : 0.026141
[02:50:34.822] iteration 28032 : model1 loss : 0.017095 model2 loss : 0.017067
[02:50:35.507] iteration 28033 : model1 loss : 0.020176 model2 loss : 0.020819
[02:50:36.175] iteration 28034 : model1 loss : 0.018660 model2 loss : 0.018127
[02:50:36.840] iteration 28035 : model1 loss : 0.049353 model2 loss : 0.045857
[02:50:37.521] iteration 28036 : model1 loss : 0.022297 model2 loss : 0.018470
[02:50:38.188] iteration 28037 : model1 loss : 0.016924 model2 loss : 0.017534
[02:50:38.849] iteration 28038 : model1 loss : 0.022381 model2 loss : 0.024525
[02:50:39.512] iteration 28039 : model1 loss : 0.017735 model2 loss : 0.017518
[02:50:40.174] iteration 28040 : model1 loss : 0.021870 model2 loss : 0.021371
[02:50:40.833] iteration 28041 : model1 loss : 0.024559 model2 loss : 0.023805
[02:50:41.513] iteration 28042 : model1 loss : 0.024462 model2 loss : 0.034168
[02:50:42.172] iteration 28043 : model1 loss : 0.021094 model2 loss : 0.022630
[02:50:42.825] iteration 28044 : model1 loss : 0.019241 model2 loss : 0.018729
[02:50:43.489] iteration 28045 : model1 loss : 0.018568 model2 loss : 0.018187
[02:50:44.147] iteration 28046 : model1 loss : 0.020930 model2 loss : 0.021760
[02:50:44.812] iteration 28047 : model1 loss : 0.018071 model2 loss : 0.017782
[02:50:45.472] iteration 28048 : model1 loss : 0.023494 model2 loss : 0.022050
[02:50:46.128] iteration 28049 : model1 loss : 0.024523 model2 loss : 0.023752
[02:50:46.786] iteration 28050 : model1 loss : 0.023054 model2 loss : 0.028115
[02:50:47.488] iteration 28051 : model1 loss : 0.012617 model2 loss : 0.011984
[02:50:48.144] iteration 28052 : model1 loss : 0.024427 model2 loss : 0.025094
[02:50:48.816] iteration 28053 : model1 loss : 0.021639 model2 loss : 0.022188
[02:50:49.487] iteration 28054 : model1 loss : 0.018162 model2 loss : 0.017621
[02:50:50.145] iteration 28055 : model1 loss : 0.019379 model2 loss : 0.019870
[02:50:50.810] iteration 28056 : model1 loss : 0.022425 model2 loss : 0.019893
[02:50:51.471] iteration 28057 : model1 loss : 0.016700 model2 loss : 0.015891
[02:50:52.134] iteration 28058 : model1 loss : 0.022205 model2 loss : 0.022321
[02:50:52.801] iteration 28059 : model1 loss : 0.015497 model2 loss : 0.016773
[02:50:53.459] iteration 28060 : model1 loss : 0.018959 model2 loss : 0.018361
[02:50:54.134] iteration 28061 : model1 loss : 0.018809 model2 loss : 0.019500
[02:50:54.800] iteration 28062 : model1 loss : 0.139934 model2 loss : 0.139604
[02:50:55.474] iteration 28063 : model1 loss : 0.026567 model2 loss : 0.025324
[02:50:56.147] iteration 28064 : model1 loss : 0.026045 model2 loss : 0.024372
[02:50:56.802] iteration 28065 : model1 loss : 0.017292 model2 loss : 0.017899
[02:50:57.475] iteration 28066 : model1 loss : 0.015915 model2 loss : 0.016421
[02:50:58.139] iteration 28067 : model1 loss : 0.023933 model2 loss : 0.025412
[02:50:58.822] iteration 28068 : model1 loss : 0.018010 model2 loss : 0.018202
[02:50:59.506] iteration 28069 : model1 loss : 0.023024 model2 loss : 0.019945
[02:51:00.168] iteration 28070 : model1 loss : 0.014960 model2 loss : 0.016449
[02:51:00.845] iteration 28071 : model1 loss : 0.022092 model2 loss : 0.020389
[02:51:01.521] iteration 28072 : model1 loss : 0.020132 model2 loss : 0.019836
[02:51:02.181] iteration 28073 : model1 loss : 0.019512 model2 loss : 0.018998
[02:51:02.854] iteration 28074 : model1 loss : 0.019211 model2 loss : 0.021864
[02:51:03.524] iteration 28075 : model1 loss : 0.028075 model2 loss : 0.027184
[02:51:04.199] iteration 28076 : model1 loss : 0.036957 model2 loss : 0.037874
[02:51:04.862] iteration 28077 : model1 loss : 0.019194 model2 loss : 0.020680
[02:51:05.522] iteration 28078 : model1 loss : 0.017813 model2 loss : 0.017747
[02:51:06.189] iteration 28079 : model1 loss : 0.018319 model2 loss : 0.020302
[02:51:06.853] iteration 28080 : model1 loss : 0.023005 model2 loss : 0.025546
[02:51:07.536] iteration 28081 : model1 loss : 0.018555 model2 loss : 0.018764
[02:51:08.226] iteration 28082 : model1 loss : 0.021585 model2 loss : 0.019916
[02:51:08.905] iteration 28083 : model1 loss : 0.017686 model2 loss : 0.016927
[02:51:09.578] iteration 28084 : model1 loss : 0.139305 model2 loss : 0.138450
[02:51:10.253] iteration 28085 : model1 loss : 0.018804 model2 loss : 0.017069
[02:51:10.914] iteration 28086 : model1 loss : 0.022132 model2 loss : 0.023147
[02:51:11.594] iteration 28087 : model1 loss : 0.024023 model2 loss : 0.024207
[02:51:12.264] iteration 28088 : model1 loss : 0.017746 model2 loss : 0.018869
[02:51:12.945] iteration 28089 : model1 loss : 0.018170 model2 loss : 0.018308
[02:51:13.609] iteration 28090 : model1 loss : 0.022113 model2 loss : 0.020232
[02:51:14.277] iteration 28091 : model1 loss : 0.016305 model2 loss : 0.015196
[02:51:14.946] iteration 28092 : model1 loss : 0.139598 model2 loss : 0.141287
[02:51:15.615] iteration 28093 : model1 loss : 0.025664 model2 loss : 0.032094
[02:51:16.287] iteration 28094 : model1 loss : 0.015976 model2 loss : 0.016029
[02:51:16.962] iteration 28095 : model1 loss : 0.018218 model2 loss : 0.017915
[02:51:17.623] iteration 28096 : model1 loss : 0.024674 model2 loss : 0.024846
[02:51:18.291] iteration 28097 : model1 loss : 0.018708 model2 loss : 0.019151
[02:51:18.954] iteration 28098 : model1 loss : 0.016842 model2 loss : 0.018139
[02:51:19.630] iteration 28099 : model1 loss : 0.018054 model2 loss : 0.016875
[02:51:20.298] iteration 28100 : model1 loss : 0.019865 model2 loss : 0.020703
[02:51:21.007] iteration 28101 : model1 loss : 0.020801 model2 loss : 0.022279
[02:51:21.676] iteration 28102 : model1 loss : 0.025689 model2 loss : 0.025979
[02:51:22.355] iteration 28103 : model1 loss : 0.014674 model2 loss : 0.013792
[02:51:23.182] iteration 28104 : model1 loss : 0.016009 model2 loss : 0.015437
[02:51:23.913] iteration 28105 : model1 loss : 0.023191 model2 loss : 0.021359
[02:51:24.636] iteration 28106 : model1 loss : 0.014691 model2 loss : 0.014068
[02:51:25.344] iteration 28107 : model1 loss : 0.019747 model2 loss : 0.020210
[02:51:26.007] iteration 28108 : model1 loss : 0.012863 model2 loss : 0.012932
[02:51:26.676] iteration 28109 : model1 loss : 0.017141 model2 loss : 0.017420
[02:51:27.338] iteration 28110 : model1 loss : 0.019837 model2 loss : 0.018883
[02:51:27.993] iteration 28111 : model1 loss : 0.016277 model2 loss : 0.017383
[02:51:28.663] iteration 28112 : model1 loss : 0.018831 model2 loss : 0.019280
[02:51:29.336] iteration 28113 : model1 loss : 0.020199 model2 loss : 0.021247
[02:51:30.008] iteration 28114 : model1 loss : 0.017857 model2 loss : 0.018849
[02:51:30.676] iteration 28115 : model1 loss : 0.024546 model2 loss : 0.021811
[02:51:31.351] iteration 28116 : model1 loss : 0.018499 model2 loss : 0.017221
[02:51:32.020] iteration 28117 : model1 loss : 0.023530 model2 loss : 0.022838
[02:51:32.676] iteration 28118 : model1 loss : 0.025032 model2 loss : 0.027881
[02:51:33.351] iteration 28119 : model1 loss : 0.023848 model2 loss : 0.021671
[02:51:34.022] iteration 28120 : model1 loss : 0.018469 model2 loss : 0.017792
[02:51:34.692] iteration 28121 : model1 loss : 0.015294 model2 loss : 0.014033
[02:51:35.363] iteration 28122 : model1 loss : 0.027792 model2 loss : 0.028671
[02:51:36.021] iteration 28123 : model1 loss : 0.018491 model2 loss : 0.018992
[02:51:36.683] iteration 28124 : model1 loss : 0.016567 model2 loss : 0.017001
[02:51:37.358] iteration 28125 : model1 loss : 0.024731 model2 loss : 0.024612
[02:51:38.015] iteration 28126 : model1 loss : 0.018165 model2 loss : 0.018406
[02:51:38.697] iteration 28127 : model1 loss : 0.024553 model2 loss : 0.026850
[02:51:39.402] iteration 28128 : model1 loss : 0.016288 model2 loss : 0.017231
[02:51:40.094] iteration 28129 : model1 loss : 0.019738 model2 loss : 0.018701
[02:51:40.759] iteration 28130 : model1 loss : 0.012180 model2 loss : 0.012707
[02:51:41.431] iteration 28131 : model1 loss : 0.018541 model2 loss : 0.017559
[02:51:42.097] iteration 28132 : model1 loss : 0.029413 model2 loss : 0.032014
[02:51:42.773] iteration 28133 : model1 loss : 0.015354 model2 loss : 0.016927
[02:51:43.442] iteration 28134 : model1 loss : 0.019307 model2 loss : 0.020636
[02:51:44.100] iteration 28135 : model1 loss : 0.031803 model2 loss : 0.023948
[02:51:44.753] iteration 28136 : model1 loss : 0.031651 model2 loss : 0.033519
[02:51:45.427] iteration 28137 : model1 loss : 0.018588 model2 loss : 0.019098
[02:51:46.102] iteration 28138 : model1 loss : 0.018355 model2 loss : 0.016657
[02:51:46.761] iteration 28139 : model1 loss : 0.018301 model2 loss : 0.025424
[02:51:47.431] iteration 28140 : model1 loss : 0.013670 model2 loss : 0.014195
[02:51:48.110] iteration 28141 : model1 loss : 0.028132 model2 loss : 0.028311
[02:51:48.788] iteration 28142 : model1 loss : 0.022074 model2 loss : 0.022507
[02:51:49.451] iteration 28143 : model1 loss : 0.046009 model2 loss : 0.042801
[02:51:50.130] iteration 28144 : model1 loss : 0.029798 model2 loss : 0.036556
[02:51:50.805] iteration 28145 : model1 loss : 0.018927 model2 loss : 0.018799
[02:51:51.469] iteration 28146 : model1 loss : 0.016785 model2 loss : 0.017852
[02:51:52.126] iteration 28147 : model1 loss : 0.015996 model2 loss : 0.016177
[02:51:52.799] iteration 28148 : model1 loss : 0.023548 model2 loss : 0.022608
[02:51:53.459] iteration 28149 : model1 loss : 0.021335 model2 loss : 0.019429
[02:51:54.129] iteration 28150 : model1 loss : 0.016002 model2 loss : 0.016132
[02:51:54.835] iteration 28151 : model1 loss : 0.014798 model2 loss : 0.014258
[02:51:55.496] iteration 28152 : model1 loss : 0.020061 model2 loss : 0.020163
[02:51:56.164] iteration 28153 : model1 loss : 0.017238 model2 loss : 0.015981
[02:51:56.829] iteration 28154 : model1 loss : 0.018702 model2 loss : 0.017344
[02:51:57.508] iteration 28155 : model1 loss : 0.020148 model2 loss : 0.016948
[02:51:58.175] iteration 28156 : model1 loss : 0.021016 model2 loss : 0.020063
[02:51:58.854] iteration 28157 : model1 loss : 0.018072 model2 loss : 0.017193
[02:51:59.511] iteration 28158 : model1 loss : 0.021462 model2 loss : 0.022168
[02:52:00.177] iteration 28159 : model1 loss : 0.016907 model2 loss : 0.017212
[02:52:00.844] iteration 28160 : model1 loss : 0.145636 model2 loss : 0.143441
[02:52:01.503] iteration 28161 : model1 loss : 0.020336 model2 loss : 0.022050
[02:52:02.171] iteration 28162 : model1 loss : 0.017900 model2 loss : 0.017828
[02:52:02.833] iteration 28163 : model1 loss : 0.018940 model2 loss : 0.018563
[02:52:03.498] iteration 28164 : model1 loss : 0.025580 model2 loss : 0.026709
[02:52:04.166] iteration 28165 : model1 loss : 0.019767 model2 loss : 0.017987
[02:52:04.833] iteration 28166 : model1 loss : 0.029585 model2 loss : 0.025883
[02:52:05.503] iteration 28167 : model1 loss : 0.014605 model2 loss : 0.014950
[02:52:06.175] iteration 28168 : model1 loss : 0.018603 model2 loss : 0.018021
[02:52:06.834] iteration 28169 : model1 loss : 0.016484 model2 loss : 0.017629
[02:52:07.505] iteration 28170 : model1 loss : 0.020976 model2 loss : 0.020790
[02:52:08.181] iteration 28171 : model1 loss : 0.023021 model2 loss : 0.020977
[02:52:08.853] iteration 28172 : model1 loss : 0.024043 model2 loss : 0.019862
[02:52:09.521] iteration 28173 : model1 loss : 0.014225 model2 loss : 0.015477
[02:52:10.189] iteration 28174 : model1 loss : 0.020984 model2 loss : 0.019756
[02:52:10.852] iteration 28175 : model1 loss : 0.019363 model2 loss : 0.020424
[02:52:11.524] iteration 28176 : model1 loss : 0.015254 model2 loss : 0.015981
[02:52:12.187] iteration 28177 : model1 loss : 0.019313 model2 loss : 0.019908
[02:52:12.857] iteration 28178 : model1 loss : 0.024080 model2 loss : 0.024211
[02:52:13.529] iteration 28179 : model1 loss : 0.017399 model2 loss : 0.018676
[02:52:14.194] iteration 28180 : model1 loss : 0.017667 model2 loss : 0.018475
[02:52:14.849] iteration 28181 : model1 loss : 0.019422 model2 loss : 0.017258
[02:52:15.517] iteration 28182 : model1 loss : 0.015774 model2 loss : 0.016689
[02:52:16.178] iteration 28183 : model1 loss : 0.017830 model2 loss : 0.017364
[02:52:16.842] iteration 28184 : model1 loss : 0.019209 model2 loss : 0.019347
[02:52:17.521] iteration 28185 : model1 loss : 0.021668 model2 loss : 0.019806
[02:52:18.190] iteration 28186 : model1 loss : 0.020553 model2 loss : 0.021821
[02:52:18.857] iteration 28187 : model1 loss : 0.019858 model2 loss : 0.018800
[02:52:19.525] iteration 28188 : model1 loss : 0.018890 model2 loss : 0.018509
[02:52:20.192] iteration 28189 : model1 loss : 0.024419 model2 loss : 0.025872
[02:52:20.865] iteration 28190 : model1 loss : 0.020125 model2 loss : 0.018652
[02:52:21.540] iteration 28191 : model1 loss : 0.024027 model2 loss : 0.021825
[02:52:22.209] iteration 28192 : model1 loss : 0.017856 model2 loss : 0.017863
[02:52:22.882] iteration 28193 : model1 loss : 0.038166 model2 loss : 0.036738
[02:52:23.547] iteration 28194 : model1 loss : 0.018429 model2 loss : 0.019987
[02:52:24.224] iteration 28195 : model1 loss : 0.020352 model2 loss : 0.019144
[02:52:24.904] iteration 28196 : model1 loss : 0.015045 model2 loss : 0.013932
[02:52:25.573] iteration 28197 : model1 loss : 0.021900 model2 loss : 0.021620
[02:52:26.240] iteration 28198 : model1 loss : 0.019001 model2 loss : 0.020710
[02:52:26.906] iteration 28199 : model1 loss : 0.020897 model2 loss : 0.018497
[02:52:27.571] iteration 28200 : model1 loss : 0.022340 model2 loss : 0.021840
[02:52:45.895] iteration 28200 : model1_mean_dice : 0.877992 model1_mean_hd95 : 6.886072
[02:53:04.200] iteration 28200 : model2_mean_dice : 0.880332 model2_mean_hd95 : 4.764612
[02:53:04.899] iteration 28201 : model1 loss : 0.020715 model2 loss : 0.019935
[02:53:05.560] iteration 28202 : model1 loss : 0.035900 model2 loss : 0.039347
[02:53:06.218] iteration 28203 : model1 loss : 0.016658 model2 loss : 0.016623
[02:53:06.882] iteration 28204 : model1 loss : 0.015650 model2 loss : 0.016794
[02:53:07.542] iteration 28205 : model1 loss : 0.040955 model2 loss : 0.034192
[02:53:08.201] iteration 28206 : model1 loss : 0.016886 model2 loss : 0.014310
[02:53:08.897] iteration 28207 : model1 loss : 0.020469 model2 loss : 0.018741
[02:53:09.568] iteration 28208 : model1 loss : 0.018101 model2 loss : 0.018186
[02:53:10.228] iteration 28209 : model1 loss : 0.016755 model2 loss : 0.017640
[02:53:10.890] iteration 28210 : model1 loss : 0.024886 model2 loss : 0.027204
[02:53:11.554] iteration 28211 : model1 loss : 0.025386 model2 loss : 0.026491
[02:53:12.208] iteration 28212 : model1 loss : 0.016182 model2 loss : 0.018517
[02:53:12.873] iteration 28213 : model1 loss : 0.021765 model2 loss : 0.020887
[02:53:13.535] iteration 28214 : model1 loss : 0.020416 model2 loss : 0.020579
[02:53:14.193] iteration 28215 : model1 loss : 0.036696 model2 loss : 0.032890
[02:53:14.859] iteration 28216 : model1 loss : 0.020019 model2 loss : 0.018688
[02:53:15.532] iteration 28217 : model1 loss : 0.018674 model2 loss : 0.019314
[02:53:16.193] iteration 28218 : model1 loss : 0.021538 model2 loss : 0.020650
[02:53:16.850] iteration 28219 : model1 loss : 0.018928 model2 loss : 0.017833
[02:53:17.515] iteration 28220 : model1 loss : 0.046543 model2 loss : 0.040923
[02:53:18.176] iteration 28221 : model1 loss : 0.015140 model2 loss : 0.016112
[02:53:18.854] iteration 28222 : model1 loss : 0.014347 model2 loss : 0.016130
[02:53:19.510] iteration 28223 : model1 loss : 0.024356 model2 loss : 0.021746
[02:53:20.174] iteration 28224 : model1 loss : 0.019450 model2 loss : 0.018902
[02:53:20.856] iteration 28225 : model1 loss : 0.018976 model2 loss : 0.018416
[02:53:21.559] iteration 28226 : model1 loss : 0.024904 model2 loss : 0.022800
[02:53:22.216] iteration 28227 : model1 loss : 0.031227 model2 loss : 0.041630
[02:53:22.897] iteration 28228 : model1 loss : 0.016275 model2 loss : 0.014692
[02:53:23.560] iteration 28229 : model1 loss : 0.017922 model2 loss : 0.016689
[02:53:24.214] iteration 28230 : model1 loss : 0.018679 model2 loss : 0.018340
[02:53:24.867] iteration 28231 : model1 loss : 0.017626 model2 loss : 0.018946
[02:53:25.536] iteration 28232 : model1 loss : 0.022073 model2 loss : 0.021302
[02:53:26.208] iteration 28233 : model1 loss : 0.019822 model2 loss : 0.020129
[02:53:26.869] iteration 28234 : model1 loss : 0.017117 model2 loss : 0.017280
[02:53:27.536] iteration 28235 : model1 loss : 0.017044 model2 loss : 0.016451
[02:53:28.208] iteration 28236 : model1 loss : 0.019630 model2 loss : 0.019729
[02:53:28.874] iteration 28237 : model1 loss : 0.024433 model2 loss : 0.021243
[02:53:29.549] iteration 28238 : model1 loss : 0.016837 model2 loss : 0.018253
[02:53:30.205] iteration 28239 : model1 loss : 0.020241 model2 loss : 0.019283
[02:53:30.879] iteration 28240 : model1 loss : 0.018059 model2 loss : 0.018018
[02:53:31.552] iteration 28241 : model1 loss : 0.021377 model2 loss : 0.020742
[02:53:32.227] iteration 28242 : model1 loss : 0.017966 model2 loss : 0.018317
[02:53:32.906] iteration 28243 : model1 loss : 0.018741 model2 loss : 0.020510
[02:53:33.571] iteration 28244 : model1 loss : 0.019886 model2 loss : 0.019983
[02:53:34.231] iteration 28245 : model1 loss : 0.016576 model2 loss : 0.017414
[02:53:34.891] iteration 28246 : model1 loss : 0.014436 model2 loss : 0.015196
[02:53:35.554] iteration 28247 : model1 loss : 0.021339 model2 loss : 0.020641
[02:53:36.222] iteration 28248 : model1 loss : 0.021401 model2 loss : 0.019991
[02:53:36.883] iteration 28249 : model1 loss : 0.016423 model2 loss : 0.017649
[02:53:37.551] iteration 28250 : model1 loss : 0.023743 model2 loss : 0.023948
[02:53:38.259] iteration 28251 : model1 loss : 0.015132 model2 loss : 0.015110
[02:53:38.932] iteration 28252 : model1 loss : 0.022952 model2 loss : 0.021137
[02:53:39.598] iteration 28253 : model1 loss : 0.020620 model2 loss : 0.022146
[02:53:40.259] iteration 28254 : model1 loss : 0.040936 model2 loss : 0.029932
[02:53:40.914] iteration 28255 : model1 loss : 0.016642 model2 loss : 0.017453
[02:53:41.587] iteration 28256 : model1 loss : 0.013814 model2 loss : 0.013715
[02:53:42.269] iteration 28257 : model1 loss : 0.016536 model2 loss : 0.017027
[02:53:42.932] iteration 28258 : model1 loss : 0.020327 model2 loss : 0.020883
[02:53:43.599] iteration 28259 : model1 loss : 0.015958 model2 loss : 0.015618
[02:53:44.264] iteration 28260 : model1 loss : 0.019263 model2 loss : 0.018782
[02:53:44.932] iteration 28261 : model1 loss : 0.021948 model2 loss : 0.022678
[02:53:45.601] iteration 28262 : model1 loss : 0.019552 model2 loss : 0.017903
[02:53:46.272] iteration 28263 : model1 loss : 0.018805 model2 loss : 0.020343
[02:53:46.938] iteration 28264 : model1 loss : 0.020963 model2 loss : 0.022585
[02:53:47.602] iteration 28265 : model1 loss : 0.021793 model2 loss : 0.021275
[02:53:48.269] iteration 28266 : model1 loss : 0.020963 model2 loss : 0.027257
[02:53:48.942] iteration 28267 : model1 loss : 0.017707 model2 loss : 0.016356
[02:53:49.618] iteration 28268 : model1 loss : 0.026478 model2 loss : 0.025536
[02:53:50.285] iteration 28269 : model1 loss : 0.019218 model2 loss : 0.018477
[02:53:50.955] iteration 28270 : model1 loss : 0.017477 model2 loss : 0.018419
[02:53:51.632] iteration 28271 : model1 loss : 0.021811 model2 loss : 0.021378
[02:53:52.299] iteration 28272 : model1 loss : 0.016158 model2 loss : 0.016264
[02:53:52.961] iteration 28273 : model1 loss : 0.014204 model2 loss : 0.013863
[02:53:53.638] iteration 28274 : model1 loss : 0.023798 model2 loss : 0.020423
[02:53:54.307] iteration 28275 : model1 loss : 0.019726 model2 loss : 0.021305
[02:53:54.998] iteration 28276 : model1 loss : 0.018984 model2 loss : 0.016823
[02:53:55.664] iteration 28277 : model1 loss : 0.032157 model2 loss : 0.036301
[02:53:56.319] iteration 28278 : model1 loss : 0.019623 model2 loss : 0.017304
[02:53:56.998] iteration 28279 : model1 loss : 0.024213 model2 loss : 0.024183
[02:53:57.658] iteration 28280 : model1 loss : 0.021284 model2 loss : 0.019932
[02:53:58.334] iteration 28281 : model1 loss : 0.021619 model2 loss : 0.019629
[02:53:59.013] iteration 28282 : model1 loss : 0.020467 model2 loss : 0.021039
[02:53:59.675] iteration 28283 : model1 loss : 0.021851 model2 loss : 0.022587
[02:54:00.349] iteration 28284 : model1 loss : 0.019631 model2 loss : 0.020829
[02:54:01.008] iteration 28285 : model1 loss : 0.015918 model2 loss : 0.015234
[02:54:01.675] iteration 28286 : model1 loss : 0.023836 model2 loss : 0.024699
[02:54:02.350] iteration 28287 : model1 loss : 0.034579 model2 loss : 0.039639
[02:54:03.019] iteration 28288 : model1 loss : 0.022098 model2 loss : 0.021154
[02:54:03.693] iteration 28289 : model1 loss : 0.018766 model2 loss : 0.017877
[02:54:04.352] iteration 28290 : model1 loss : 0.025251 model2 loss : 0.024353
[02:54:05.023] iteration 28291 : model1 loss : 0.020937 model2 loss : 0.019881
[02:54:05.687] iteration 28292 : model1 loss : 0.020155 model2 loss : 0.021523
[02:54:06.365] iteration 28293 : model1 loss : 0.022040 model2 loss : 0.020782
[02:54:07.032] iteration 28294 : model1 loss : 0.024001 model2 loss : 0.021750
[02:54:07.692] iteration 28295 : model1 loss : 0.026145 model2 loss : 0.024984
[02:54:08.363] iteration 28296 : model1 loss : 0.017169 model2 loss : 0.015915
[02:54:09.029] iteration 28297 : model1 loss : 0.022901 model2 loss : 0.022164
[02:54:09.713] iteration 28298 : model1 loss : 0.021612 model2 loss : 0.022668
[02:54:10.385] iteration 28299 : model1 loss : 0.017468 model2 loss : 0.016612
[02:54:11.050] iteration 28300 : model1 loss : 0.017541 model2 loss : 0.018500
[02:54:11.756] iteration 28301 : model1 loss : 0.019670 model2 loss : 0.020009
[02:54:12.429] iteration 28302 : model1 loss : 0.016567 model2 loss : 0.015670
[02:54:13.093] iteration 28303 : model1 loss : 0.028747 model2 loss : 0.031042
[02:54:13.756] iteration 28304 : model1 loss : 0.032444 model2 loss : 0.038955
[02:54:14.432] iteration 28305 : model1 loss : 0.025078 model2 loss : 0.023273
[02:54:15.096] iteration 28306 : model1 loss : 0.018467 model2 loss : 0.018621
[02:54:15.767] iteration 28307 : model1 loss : 0.031293 model2 loss : 0.032505
[02:54:16.435] iteration 28308 : model1 loss : 0.014473 model2 loss : 0.015371
[02:54:17.091] iteration 28309 : model1 loss : 0.016008 model2 loss : 0.017447
[02:54:17.755] iteration 28310 : model1 loss : 0.018009 model2 loss : 0.018128
[02:54:18.428] iteration 28311 : model1 loss : 0.017749 model2 loss : 0.018246
[02:54:19.115] iteration 28312 : model1 loss : 0.017567 model2 loss : 0.018318
[02:54:19.775] iteration 28313 : model1 loss : 0.030393 model2 loss : 0.032144
[02:54:20.486] iteration 28314 : model1 loss : 0.019430 model2 loss : 0.019488
[02:54:21.176] iteration 28315 : model1 loss : 0.016786 model2 loss : 0.017117
[02:54:21.844] iteration 28316 : model1 loss : 0.022759 model2 loss : 0.025417
[02:54:22.562] iteration 28317 : model1 loss : 0.023025 model2 loss : 0.023506
[02:54:23.258] iteration 28318 : model1 loss : 0.013990 model2 loss : 0.013634
[02:54:23.970] iteration 28319 : model1 loss : 0.017590 model2 loss : 0.018404
[02:54:24.636] iteration 28320 : model1 loss : 0.018646 model2 loss : 0.020814
[02:54:25.314] iteration 28321 : model1 loss : 0.022063 model2 loss : 0.022714
[02:54:25.973] iteration 28322 : model1 loss : 0.021036 model2 loss : 0.019962
[02:54:26.637] iteration 28323 : model1 loss : 0.031835 model2 loss : 0.029368
[02:54:27.303] iteration 28324 : model1 loss : 0.026618 model2 loss : 0.028104
[02:54:27.975] iteration 28325 : model1 loss : 0.016665 model2 loss : 0.018219
[02:54:28.650] iteration 28326 : model1 loss : 0.017942 model2 loss : 0.017604
[02:54:29.328] iteration 28327 : model1 loss : 0.019905 model2 loss : 0.026212
[02:54:29.990] iteration 28328 : model1 loss : 0.031189 model2 loss : 0.029990
[02:54:30.659] iteration 28329 : model1 loss : 0.029927 model2 loss : 0.036094
[02:54:31.333] iteration 28330 : model1 loss : 0.025211 model2 loss : 0.023516
[02:54:31.988] iteration 28331 : model1 loss : 0.136754 model2 loss : 0.136555
[02:54:32.655] iteration 28332 : model1 loss : 0.021553 model2 loss : 0.020478
[02:54:33.318] iteration 28333 : model1 loss : 0.027338 model2 loss : 0.030893
[02:54:33.989] iteration 28334 : model1 loss : 0.013829 model2 loss : 0.014738
[02:54:34.659] iteration 28335 : model1 loss : 0.017612 model2 loss : 0.017212
[02:54:35.322] iteration 28336 : model1 loss : 0.019591 model2 loss : 0.019982
[02:54:36.013] iteration 28337 : model1 loss : 0.021641 model2 loss : 0.022735
[02:54:36.708] iteration 28338 : model1 loss : 0.019640 model2 loss : 0.021849
[02:54:37.372] iteration 28339 : model1 loss : 0.019453 model2 loss : 0.018728
[02:54:38.045] iteration 28340 : model1 loss : 0.023965 model2 loss : 0.021944
[02:54:38.709] iteration 28341 : model1 loss : 0.020076 model2 loss : 0.019907
[02:54:39.391] iteration 28342 : model1 loss : 0.019335 model2 loss : 0.018281
[02:54:40.065] iteration 28343 : model1 loss : 0.019097 model2 loss : 0.019883
[02:54:40.735] iteration 28344 : model1 loss : 0.021180 model2 loss : 0.021955
[02:54:41.405] iteration 28345 : model1 loss : 0.025472 model2 loss : 0.027106
[02:54:42.069] iteration 28346 : model1 loss : 0.020423 model2 loss : 0.022047
[02:54:42.740] iteration 28347 : model1 loss : 0.014841 model2 loss : 0.016110
[02:54:43.401] iteration 28348 : model1 loss : 0.022047 model2 loss : 0.019142
[02:54:44.055] iteration 28349 : model1 loss : 0.024263 model2 loss : 0.023375
[02:54:44.729] iteration 28350 : model1 loss : 0.022034 model2 loss : 0.021394
[02:54:45.438] iteration 28351 : model1 loss : 0.020520 model2 loss : 0.023284
[02:54:46.103] iteration 28352 : model1 loss : 0.016349 model2 loss : 0.016445
[02:54:46.771] iteration 28353 : model1 loss : 0.016253 model2 loss : 0.017114
[02:54:47.436] iteration 28354 : model1 loss : 0.016377 model2 loss : 0.017223
[02:54:48.097] iteration 28355 : model1 loss : 0.026503 model2 loss : 0.026175
[02:54:48.773] iteration 28356 : model1 loss : 0.024182 model2 loss : 0.025111
[02:54:49.442] iteration 28357 : model1 loss : 0.021555 model2 loss : 0.020749
[02:54:50.100] iteration 28358 : model1 loss : 0.024089 model2 loss : 0.022565
[02:54:50.754] iteration 28359 : model1 loss : 0.018303 model2 loss : 0.017472
[02:54:51.444] iteration 28360 : model1 loss : 0.019324 model2 loss : 0.018795
[02:54:52.124] iteration 28361 : model1 loss : 0.037201 model2 loss : 0.038647
[02:54:52.812] iteration 28362 : model1 loss : 0.021330 model2 loss : 0.021475
[02:54:53.491] iteration 28363 : model1 loss : 0.016163 model2 loss : 0.017492
[02:54:54.176] iteration 28364 : model1 loss : 0.025464 model2 loss : 0.024567
[02:54:54.845] iteration 28365 : model1 loss : 0.015429 model2 loss : 0.015562
[02:54:55.507] iteration 28366 : model1 loss : 0.019794 model2 loss : 0.021536
[02:54:56.168] iteration 28367 : model1 loss : 0.016040 model2 loss : 0.014826
[02:54:56.846] iteration 28368 : model1 loss : 0.018397 model2 loss : 0.018638
[02:54:57.515] iteration 28369 : model1 loss : 0.019000 model2 loss : 0.019918
[02:54:58.181] iteration 28370 : model1 loss : 0.018636 model2 loss : 0.019641
[02:54:58.848] iteration 28371 : model1 loss : 0.021360 model2 loss : 0.021175
[02:54:59.511] iteration 28372 : model1 loss : 0.014808 model2 loss : 0.015773
[02:55:00.191] iteration 28373 : model1 loss : 0.021176 model2 loss : 0.021198
[02:55:00.852] iteration 28374 : model1 loss : 0.016225 model2 loss : 0.017860
[02:55:01.521] iteration 28375 : model1 loss : 0.019101 model2 loss : 0.019251
[02:55:02.185] iteration 28376 : model1 loss : 0.053945 model2 loss : 0.073439
[02:55:02.861] iteration 28377 : model1 loss : 0.020801 model2 loss : 0.020828
[02:55:03.530] iteration 28378 : model1 loss : 0.021509 model2 loss : 0.020598
[02:55:04.191] iteration 28379 : model1 loss : 0.021177 model2 loss : 0.020501
[02:55:04.849] iteration 28380 : model1 loss : 0.024961 model2 loss : 0.021048
[02:55:05.512] iteration 28381 : model1 loss : 0.018331 model2 loss : 0.018297
[02:55:06.178] iteration 28382 : model1 loss : 0.014297 model2 loss : 0.013810
[02:55:06.850] iteration 28383 : model1 loss : 0.016365 model2 loss : 0.017730
[02:55:07.521] iteration 28384 : model1 loss : 0.016942 model2 loss : 0.016789
[02:55:08.183] iteration 28385 : model1 loss : 0.016547 model2 loss : 0.015592
[02:55:08.852] iteration 28386 : model1 loss : 0.017319 model2 loss : 0.016831
[02:55:09.525] iteration 28387 : model1 loss : 0.023385 model2 loss : 0.021332
[02:55:10.216] iteration 28388 : model1 loss : 0.028972 model2 loss : 0.026583
[02:55:10.882] iteration 28389 : model1 loss : 0.022971 model2 loss : 0.021081
[02:55:11.543] iteration 28390 : model1 loss : 0.014023 model2 loss : 0.014277
[02:55:12.229] iteration 28391 : model1 loss : 0.021554 model2 loss : 0.020877
[02:55:12.896] iteration 28392 : model1 loss : 0.026716 model2 loss : 0.024083
[02:55:13.554] iteration 28393 : model1 loss : 0.017838 model2 loss : 0.019437
[02:55:14.220] iteration 28394 : model1 loss : 0.018400 model2 loss : 0.020549
[02:55:14.884] iteration 28395 : model1 loss : 0.022881 model2 loss : 0.019712
[02:55:15.556] iteration 28396 : model1 loss : 0.018545 model2 loss : 0.018798
[02:55:16.214] iteration 28397 : model1 loss : 0.023361 model2 loss : 0.026791
[02:55:16.870] iteration 28398 : model1 loss : 0.023710 model2 loss : 0.022481
[02:55:17.536] iteration 28399 : model1 loss : 0.018599 model2 loss : 0.018314
[02:55:18.205] iteration 28400 : model1 loss : 0.020692 model2 loss : 0.025027
[02:55:36.432] iteration 28400 : model1_mean_dice : 0.876316 model1_mean_hd95 : 7.027782
[02:55:54.407] iteration 28400 : model2_mean_dice : 0.877142 model2_mean_hd95 : 4.840632
[02:55:55.105] iteration 28401 : model1 loss : 0.020353 model2 loss : 0.020877
[02:55:55.762] iteration 28402 : model1 loss : 0.018699 model2 loss : 0.018881
[02:55:56.429] iteration 28403 : model1 loss : 0.016361 model2 loss : 0.016000
[02:55:57.078] iteration 28404 : model1 loss : 0.019789 model2 loss : 0.019318
[02:55:57.725] iteration 28405 : model1 loss : 0.015410 model2 loss : 0.016177
[02:55:58.380] iteration 28406 : model1 loss : 0.017096 model2 loss : 0.019784
[02:55:59.047] iteration 28407 : model1 loss : 0.017401 model2 loss : 0.018270
[02:55:59.702] iteration 28408 : model1 loss : 0.024769 model2 loss : 0.021954
[02:56:00.397] iteration 28409 : model1 loss : 0.025505 model2 loss : 0.024151
[02:56:01.085] iteration 28410 : model1 loss : 0.021997 model2 loss : 0.021762
[02:56:01.741] iteration 28411 : model1 loss : 0.019263 model2 loss : 0.023784
[02:56:02.419] iteration 28412 : model1 loss : 0.017753 model2 loss : 0.018662
[02:56:03.077] iteration 28413 : model1 loss : 0.019640 model2 loss : 0.019147
[02:56:03.737] iteration 28414 : model1 loss : 0.026447 model2 loss : 0.025623
[02:56:04.398] iteration 28415 : model1 loss : 0.033028 model2 loss : 0.035186
[02:56:05.066] iteration 28416 : model1 loss : 0.021845 model2 loss : 0.022489
[02:56:05.729] iteration 28417 : model1 loss : 0.018141 model2 loss : 0.017541
[02:56:06.388] iteration 28418 : model1 loss : 0.146685 model2 loss : 0.147183
[02:56:07.053] iteration 28419 : model1 loss : 0.026111 model2 loss : 0.025148
[02:56:07.716] iteration 28420 : model1 loss : 0.024039 model2 loss : 0.022684
[02:56:08.393] iteration 28421 : model1 loss : 0.022036 model2 loss : 0.022550
[02:56:09.063] iteration 28422 : model1 loss : 0.020837 model2 loss : 0.022333
[02:56:09.713] iteration 28423 : model1 loss : 0.025564 model2 loss : 0.024460
[02:56:10.418] iteration 28424 : model1 loss : 0.017418 model2 loss : 0.015626
[02:56:11.094] iteration 28425 : model1 loss : 0.027282 model2 loss : 0.027185
[02:56:11.749] iteration 28426 : model1 loss : 0.022476 model2 loss : 0.021060
[02:56:12.414] iteration 28427 : model1 loss : 0.020897 model2 loss : 0.019613
[02:56:13.071] iteration 28428 : model1 loss : 0.024542 model2 loss : 0.024092
[02:56:13.724] iteration 28429 : model1 loss : 0.019021 model2 loss : 0.018082
[02:56:14.395] iteration 28430 : model1 loss : 0.019464 model2 loss : 0.018894
[02:56:15.061] iteration 28431 : model1 loss : 0.018187 model2 loss : 0.018538
[02:56:15.734] iteration 28432 : model1 loss : 0.019564 model2 loss : 0.017751
[02:56:16.397] iteration 28433 : model1 loss : 0.018411 model2 loss : 0.016478
[02:56:17.069] iteration 28434 : model1 loss : 0.015629 model2 loss : 0.017548
[02:56:17.738] iteration 28435 : model1 loss : 0.025632 model2 loss : 0.025115
[02:56:18.404] iteration 28436 : model1 loss : 0.020117 model2 loss : 0.022198
[02:56:19.075] iteration 28437 : model1 loss : 0.023079 model2 loss : 0.024345
[02:56:19.735] iteration 28438 : model1 loss : 0.022137 model2 loss : 0.020644
[02:56:20.399] iteration 28439 : model1 loss : 0.016839 model2 loss : 0.016997
[02:56:21.054] iteration 28440 : model1 loss : 0.018496 model2 loss : 0.018835
[02:56:21.712] iteration 28441 : model1 loss : 0.018275 model2 loss : 0.019248
[02:56:22.379] iteration 28442 : model1 loss : 0.013269 model2 loss : 0.014544
[02:56:23.040] iteration 28443 : model1 loss : 0.016018 model2 loss : 0.017067
[02:56:23.708] iteration 28444 : model1 loss : 0.019417 model2 loss : 0.017942
[02:56:24.375] iteration 28445 : model1 loss : 0.019222 model2 loss : 0.018392
[02:56:25.049] iteration 28446 : model1 loss : 0.014752 model2 loss : 0.014602
[02:56:25.708] iteration 28447 : model1 loss : 0.024795 model2 loss : 0.021909
[02:56:26.386] iteration 28448 : model1 loss : 0.020472 model2 loss : 0.019527
[02:56:27.051] iteration 28449 : model1 loss : 0.024374 model2 loss : 0.019820
[02:56:27.713] iteration 28450 : model1 loss : 0.026858 model2 loss : 0.028335
[02:56:28.421] iteration 28451 : model1 loss : 0.019459 model2 loss : 0.017723
[02:56:29.097] iteration 28452 : model1 loss : 0.019691 model2 loss : 0.020680
[02:56:29.763] iteration 28453 : model1 loss : 0.014518 model2 loss : 0.015076
[02:56:30.447] iteration 28454 : model1 loss : 0.018888 model2 loss : 0.018772
[02:56:31.108] iteration 28455 : model1 loss : 0.020651 model2 loss : 0.017314
[02:56:31.779] iteration 28456 : model1 loss : 0.018789 model2 loss : 0.017396
[02:56:32.446] iteration 28457 : model1 loss : 0.019505 model2 loss : 0.018417
[02:56:33.117] iteration 28458 : model1 loss : 0.018308 model2 loss : 0.018332
[02:56:33.785] iteration 28459 : model1 loss : 0.018483 model2 loss : 0.017789
[02:56:34.450] iteration 28460 : model1 loss : 0.021715 model2 loss : 0.022007
[02:56:35.113] iteration 28461 : model1 loss : 0.023733 model2 loss : 0.022938
[02:56:35.772] iteration 28462 : model1 loss : 0.016406 model2 loss : 0.016797
[02:56:36.449] iteration 28463 : model1 loss : 0.019726 model2 loss : 0.021590
[02:56:37.131] iteration 28464 : model1 loss : 0.020031 model2 loss : 0.019672
[02:56:37.791] iteration 28465 : model1 loss : 0.023879 model2 loss : 0.025681
[02:56:38.459] iteration 28466 : model1 loss : 0.018840 model2 loss : 0.016861
[02:56:39.131] iteration 28467 : model1 loss : 0.018144 model2 loss : 0.019669
[02:56:39.793] iteration 28468 : model1 loss : 0.017396 model2 loss : 0.017391
[02:56:40.463] iteration 28469 : model1 loss : 0.018621 model2 loss : 0.019911
[02:56:41.133] iteration 28470 : model1 loss : 0.019474 model2 loss : 0.018659
[02:56:41.801] iteration 28471 : model1 loss : 0.024999 model2 loss : 0.023926
[02:56:42.480] iteration 28472 : model1 loss : 0.014866 model2 loss : 0.015435
[02:56:43.170] iteration 28473 : model1 loss : 0.026656 model2 loss : 0.020743
[02:56:43.838] iteration 28474 : model1 loss : 0.035282 model2 loss : 0.033147
[02:56:44.551] iteration 28475 : model1 loss : 0.018955 model2 loss : 0.024553
[02:56:45.238] iteration 28476 : model1 loss : 0.023886 model2 loss : 0.023287
[02:56:45.898] iteration 28477 : model1 loss : 0.019226 model2 loss : 0.019249
[02:56:46.565] iteration 28478 : model1 loss : 0.031323 model2 loss : 0.030595
[02:56:47.246] iteration 28479 : model1 loss : 0.020069 model2 loss : 0.020857
[02:56:47.912] iteration 28480 : model1 loss : 0.019752 model2 loss : 0.019611
[02:56:48.583] iteration 28481 : model1 loss : 0.018216 model2 loss : 0.018596
[02:56:49.241] iteration 28482 : model1 loss : 0.019689 model2 loss : 0.018391
[02:56:49.901] iteration 28483 : model1 loss : 0.016335 model2 loss : 0.016753
[02:56:50.555] iteration 28484 : model1 loss : 0.014610 model2 loss : 0.015585
[02:56:51.220] iteration 28485 : model1 loss : 0.138941 model2 loss : 0.140245
[02:56:51.891] iteration 28486 : model1 loss : 0.016437 model2 loss : 0.016386
[02:56:52.562] iteration 28487 : model1 loss : 0.019314 model2 loss : 0.019250
[02:56:53.228] iteration 28488 : model1 loss : 0.019017 model2 loss : 0.019363
[02:56:53.897] iteration 28489 : model1 loss : 0.021338 model2 loss : 0.021313
[02:56:54.570] iteration 28490 : model1 loss : 0.016562 model2 loss : 0.015056
[02:56:55.245] iteration 28491 : model1 loss : 0.094907 model2 loss : 0.096944
[02:56:55.901] iteration 28492 : model1 loss : 0.019733 model2 loss : 0.022509
[02:56:56.561] iteration 28493 : model1 loss : 0.020669 model2 loss : 0.021882
[02:56:57.226] iteration 28494 : model1 loss : 0.021643 model2 loss : 0.021975
[02:56:57.882] iteration 28495 : model1 loss : 0.014912 model2 loss : 0.014848
[02:56:58.556] iteration 28496 : model1 loss : 0.015092 model2 loss : 0.015957
[02:56:59.223] iteration 28497 : model1 loss : 0.017187 model2 loss : 0.018932
[02:56:59.884] iteration 28498 : model1 loss : 0.019893 model2 loss : 0.023032
[02:57:00.541] iteration 28499 : model1 loss : 0.020641 model2 loss : 0.021313
[02:57:01.213] iteration 28500 : model1 loss : 0.020772 model2 loss : 0.019549
[02:57:01.913] iteration 28501 : model1 loss : 0.021106 model2 loss : 0.020265
[02:57:02.578] iteration 28502 : model1 loss : 0.018939 model2 loss : 0.018355
[02:57:03.232] iteration 28503 : model1 loss : 0.017980 model2 loss : 0.018804
[02:57:03.894] iteration 28504 : model1 loss : 0.021404 model2 loss : 0.021291
[02:57:04.567] iteration 28505 : model1 loss : 0.021762 model2 loss : 0.022132
[02:57:05.243] iteration 28506 : model1 loss : 0.021629 model2 loss : 0.020285
[02:57:05.900] iteration 28507 : model1 loss : 0.019122 model2 loss : 0.018479
[02:57:06.556] iteration 28508 : model1 loss : 0.017761 model2 loss : 0.017913
[02:57:07.215] iteration 28509 : model1 loss : 0.015606 model2 loss : 0.016250
[02:57:07.878] iteration 28510 : model1 loss : 0.019832 model2 loss : 0.020786
[02:57:08.549] iteration 28511 : model1 loss : 0.020140 model2 loss : 0.022383
[02:57:09.221] iteration 28512 : model1 loss : 0.018544 model2 loss : 0.019490
[02:57:09.881] iteration 28513 : model1 loss : 0.019351 model2 loss : 0.017682
[02:57:10.552] iteration 28514 : model1 loss : 0.021813 model2 loss : 0.021933
[02:57:11.225] iteration 28515 : model1 loss : 0.018007 model2 loss : 0.017311
[02:57:11.889] iteration 28516 : model1 loss : 0.017703 model2 loss : 0.017894
[02:57:12.553] iteration 28517 : model1 loss : 0.018915 model2 loss : 0.019036
[02:57:13.214] iteration 28518 : model1 loss : 0.018670 model2 loss : 0.018918
[02:57:13.870] iteration 28519 : model1 loss : 0.015497 model2 loss : 0.015911
[02:57:14.532] iteration 28520 : model1 loss : 0.020123 model2 loss : 0.020042
[02:57:15.197] iteration 28521 : model1 loss : 0.023488 model2 loss : 0.022481
[02:57:15.862] iteration 28522 : model1 loss : 0.019075 model2 loss : 0.018864
[02:57:16.531] iteration 28523 : model1 loss : 0.021880 model2 loss : 0.020679
[02:57:17.192] iteration 28524 : model1 loss : 0.019144 model2 loss : 0.020536
[02:57:17.849] iteration 28525 : model1 loss : 0.020115 model2 loss : 0.020004
[02:57:18.509] iteration 28526 : model1 loss : 0.018506 model2 loss : 0.017523
[02:57:19.167] iteration 28527 : model1 loss : 0.019829 model2 loss : 0.020079
[02:57:19.845] iteration 28528 : model1 loss : 0.020563 model2 loss : 0.019567
[02:57:20.515] iteration 28529 : model1 loss : 0.016312 model2 loss : 0.015652
[02:57:21.178] iteration 28530 : model1 loss : 0.019264 model2 loss : 0.020860
[02:57:21.852] iteration 28531 : model1 loss : 0.017029 model2 loss : 0.017058
[02:57:22.527] iteration 28532 : model1 loss : 0.017208 model2 loss : 0.017284
[02:57:23.193] iteration 28533 : model1 loss : 0.018830 model2 loss : 0.017397
[02:57:23.863] iteration 28534 : model1 loss : 0.014657 model2 loss : 0.014458
[02:57:24.532] iteration 28535 : model1 loss : 0.018094 model2 loss : 0.019141
[02:57:25.206] iteration 28536 : model1 loss : 0.024253 model2 loss : 0.024561
[02:57:25.858] iteration 28537 : model1 loss : 0.022072 model2 loss : 0.029725
[02:57:26.524] iteration 28538 : model1 loss : 0.020404 model2 loss : 0.018846
[02:57:27.190] iteration 28539 : model1 loss : 0.016337 model2 loss : 0.017887
[02:57:27.871] iteration 28540 : model1 loss : 0.024260 model2 loss : 0.023379
[02:57:28.537] iteration 28541 : model1 loss : 0.024488 model2 loss : 0.021657
[02:57:29.209] iteration 28542 : model1 loss : 0.017682 model2 loss : 0.018867
[02:57:29.873] iteration 28543 : model1 loss : 0.018238 model2 loss : 0.019372
[02:57:30.542] iteration 28544 : model1 loss : 0.044024 model2 loss : 0.037866
[02:57:31.211] iteration 28545 : model1 loss : 0.019990 model2 loss : 0.021086
[02:57:31.882] iteration 28546 : model1 loss : 0.016666 model2 loss : 0.016448
[02:57:32.567] iteration 28547 : model1 loss : 0.040910 model2 loss : 0.041387
[02:57:33.248] iteration 28548 : model1 loss : 0.025196 model2 loss : 0.025506
[02:57:33.905] iteration 28549 : model1 loss : 0.021183 model2 loss : 0.022704
[02:57:34.561] iteration 28550 : model1 loss : 0.026776 model2 loss : 0.026074
[02:57:35.264] iteration 28551 : model1 loss : 0.018149 model2 loss : 0.017584
[02:57:35.940] iteration 28552 : model1 loss : 0.021737 model2 loss : 0.020995
[02:57:36.601] iteration 28553 : model1 loss : 0.022751 model2 loss : 0.022493
[02:57:37.276] iteration 28554 : model1 loss : 0.024834 model2 loss : 0.023470
[02:57:37.941] iteration 28555 : model1 loss : 0.021242 model2 loss : 0.021628
[02:57:38.612] iteration 28556 : model1 loss : 0.030133 model2 loss : 0.028123
[02:57:39.273] iteration 28557 : model1 loss : 0.023246 model2 loss : 0.023060
[02:57:39.934] iteration 28558 : model1 loss : 0.015536 model2 loss : 0.014567
[02:57:40.612] iteration 28559 : model1 loss : 0.017319 model2 loss : 0.016491
[02:57:41.286] iteration 28560 : model1 loss : 0.019979 model2 loss : 0.021640
[02:57:41.949] iteration 28561 : model1 loss : 0.027239 model2 loss : 0.028133
[02:57:42.631] iteration 28562 : model1 loss : 0.019574 model2 loss : 0.019940
[02:57:43.299] iteration 28563 : model1 loss : 0.015569 model2 loss : 0.016416
[02:57:43.959] iteration 28564 : model1 loss : 0.021114 model2 loss : 0.021010
[02:57:44.624] iteration 28565 : model1 loss : 0.021428 model2 loss : 0.024662
[02:57:45.279] iteration 28566 : model1 loss : 0.020205 model2 loss : 0.021709
[02:57:45.956] iteration 28567 : model1 loss : 0.015395 model2 loss : 0.016518
[02:57:46.620] iteration 28568 : model1 loss : 0.021301 model2 loss : 0.022332
[02:57:47.293] iteration 28569 : model1 loss : 0.023218 model2 loss : 0.023393
[02:57:47.960] iteration 28570 : model1 loss : 0.021356 model2 loss : 0.018859
[02:57:48.641] iteration 28571 : model1 loss : 0.016534 model2 loss : 0.016877
[02:57:49.324] iteration 28572 : model1 loss : 0.019227 model2 loss : 0.020223
[02:57:49.989] iteration 28573 : model1 loss : 0.021862 model2 loss : 0.020234
[02:57:50.651] iteration 28574 : model1 loss : 0.021390 model2 loss : 0.023259
[02:57:51.334] iteration 28575 : model1 loss : 0.042197 model2 loss : 0.030570
[02:57:51.999] iteration 28576 : model1 loss : 0.025199 model2 loss : 0.023405
[02:57:52.669] iteration 28577 : model1 loss : 0.019776 model2 loss : 0.019250
[02:57:53.348] iteration 28578 : model1 loss : 0.018556 model2 loss : 0.019050
[02:57:54.007] iteration 28579 : model1 loss : 0.015914 model2 loss : 0.016441
[02:57:54.663] iteration 28580 : model1 loss : 0.017712 model2 loss : 0.016414
[02:57:55.319] iteration 28581 : model1 loss : 0.022018 model2 loss : 0.021025
[02:57:55.995] iteration 28582 : model1 loss : 0.018678 model2 loss : 0.017423
[02:57:56.656] iteration 28583 : model1 loss : 0.018362 model2 loss : 0.018682
[02:57:57.318] iteration 28584 : model1 loss : 0.016022 model2 loss : 0.016127
[02:57:57.982] iteration 28585 : model1 loss : 0.017738 model2 loss : 0.017013
[02:57:58.650] iteration 28586 : model1 loss : 0.017510 model2 loss : 0.016866
[02:57:59.323] iteration 28587 : model1 loss : 0.019696 model2 loss : 0.019353
[02:57:59.978] iteration 28588 : model1 loss : 0.022137 model2 loss : 0.022559
[02:58:00.643] iteration 28589 : model1 loss : 0.016278 model2 loss : 0.019559
[02:58:01.315] iteration 28590 : model1 loss : 0.015517 model2 loss : 0.016950
[02:58:01.980] iteration 28591 : model1 loss : 0.025318 model2 loss : 0.023864
[02:58:02.649] iteration 28592 : model1 loss : 0.021091 model2 loss : 0.023871
[02:58:03.321] iteration 28593 : model1 loss : 0.014562 model2 loss : 0.015943
[02:58:03.985] iteration 28594 : model1 loss : 0.021982 model2 loss : 0.023111
[02:58:04.649] iteration 28595 : model1 loss : 0.020097 model2 loss : 0.020036
[02:58:05.317] iteration 28596 : model1 loss : 0.015759 model2 loss : 0.015746
[02:58:05.983] iteration 28597 : model1 loss : 0.015996 model2 loss : 0.016846
[02:58:06.648] iteration 28598 : model1 loss : 0.015136 model2 loss : 0.016332
[02:58:07.332] iteration 28599 : model1 loss : 0.025426 model2 loss : 0.025637
[02:58:07.987] iteration 28600 : model1 loss : 0.015399 model2 loss : 0.015749
[02:58:26.145] iteration 28600 : model1_mean_dice : 0.878138 model1_mean_hd95 : 7.002520
[02:58:43.944] iteration 28600 : model2_mean_dice : 0.880868 model2_mean_hd95 : 4.647670
[02:58:44.625] iteration 28601 : model1 loss : 0.023431 model2 loss : 0.022386
[02:58:45.282] iteration 28602 : model1 loss : 0.021305 model2 loss : 0.021246
[02:58:45.953] iteration 28603 : model1 loss : 0.022773 model2 loss : 0.022039
[02:58:46.603] iteration 28604 : model1 loss : 0.017323 model2 loss : 0.018212
[02:58:47.269] iteration 28605 : model1 loss : 0.019565 model2 loss : 0.019615
[02:58:47.924] iteration 28606 : model1 loss : 0.017620 model2 loss : 0.019387
[02:58:48.582] iteration 28607 : model1 loss : 0.020064 model2 loss : 0.019944
[02:58:49.251] iteration 28608 : model1 loss : 0.022719 model2 loss : 0.024080
[02:58:49.915] iteration 28609 : model1 loss : 0.024658 model2 loss : 0.028069
[02:58:50.574] iteration 28610 : model1 loss : 0.016206 model2 loss : 0.015956
[02:58:51.246] iteration 28611 : model1 loss : 0.024511 model2 loss : 0.023742
[02:58:51.909] iteration 28612 : model1 loss : 0.020610 model2 loss : 0.019698
[02:58:52.584] iteration 28613 : model1 loss : 0.018470 model2 loss : 0.018727
[02:58:53.245] iteration 28614 : model1 loss : 0.019398 model2 loss : 0.018436
[02:58:53.907] iteration 28615 : model1 loss : 0.023174 model2 loss : 0.023218
[02:58:54.597] iteration 28616 : model1 loss : 0.024320 model2 loss : 0.021665
[02:58:55.257] iteration 28617 : model1 loss : 0.019323 model2 loss : 0.019330
[02:58:55.916] iteration 28618 : model1 loss : 0.021827 model2 loss : 0.023039
[02:58:56.585] iteration 28619 : model1 loss : 0.016279 model2 loss : 0.018224
[02:58:57.273] iteration 28620 : model1 loss : 0.016262 model2 loss : 0.015199
[02:58:57.960] iteration 28621 : model1 loss : 0.020861 model2 loss : 0.021812
[02:58:58.632] iteration 28622 : model1 loss : 0.021322 model2 loss : 0.020583
[02:58:59.303] iteration 28623 : model1 loss : 0.015821 model2 loss : 0.015302
[02:58:59.948] iteration 28624 : model1 loss : 0.015984 model2 loss : 0.015943
[02:59:00.601] iteration 28625 : model1 loss : 0.030219 model2 loss : 0.031987
[02:59:01.273] iteration 28626 : model1 loss : 0.028258 model2 loss : 0.025523
[02:59:01.940] iteration 28627 : model1 loss : 0.022079 model2 loss : 0.021759
[02:59:02.603] iteration 28628 : model1 loss : 0.022759 model2 loss : 0.021093
[02:59:03.259] iteration 28629 : model1 loss : 0.017517 model2 loss : 0.016109
[02:59:03.924] iteration 28630 : model1 loss : 0.018075 model2 loss : 0.017343
[02:59:04.582] iteration 28631 : model1 loss : 0.020774 model2 loss : 0.021470
[02:59:05.246] iteration 28632 : model1 loss : 0.020998 model2 loss : 0.024479
[02:59:05.906] iteration 28633 : model1 loss : 0.039149 model2 loss : 0.035835
[02:59:06.554] iteration 28634 : model1 loss : 0.025069 model2 loss : 0.025069
[02:59:07.207] iteration 28635 : model1 loss : 0.018590 model2 loss : 0.018470
[02:59:07.874] iteration 28636 : model1 loss : 0.031378 model2 loss : 0.034294
[02:59:08.534] iteration 28637 : model1 loss : 0.015853 model2 loss : 0.015583
[02:59:09.205] iteration 28638 : model1 loss : 0.016996 model2 loss : 0.017837
[02:59:09.865] iteration 28639 : model1 loss : 0.020843 model2 loss : 0.020179
[02:59:10.529] iteration 28640 : model1 loss : 0.022514 model2 loss : 0.023566
[02:59:11.192] iteration 28641 : model1 loss : 0.023340 model2 loss : 0.024126
[02:59:11.887] iteration 28642 : model1 loss : 0.017187 model2 loss : 0.017713
[02:59:12.554] iteration 28643 : model1 loss : 0.018629 model2 loss : 0.018138
[02:59:13.229] iteration 28644 : model1 loss : 0.020941 model2 loss : 0.019324
[02:59:13.890] iteration 28645 : model1 loss : 0.015461 model2 loss : 0.017410
[02:59:14.561] iteration 28646 : model1 loss : 0.019500 model2 loss : 0.019492
[02:59:15.226] iteration 28647 : model1 loss : 0.027512 model2 loss : 0.027680
[02:59:15.891] iteration 28648 : model1 loss : 0.024299 model2 loss : 0.020584
[02:59:16.545] iteration 28649 : model1 loss : 0.021581 model2 loss : 0.022196
[02:59:17.211] iteration 28650 : model1 loss : 0.023270 model2 loss : 0.019845
[02:59:17.921] iteration 28651 : model1 loss : 0.018753 model2 loss : 0.020580
[02:59:18.588] iteration 28652 : model1 loss : 0.020704 model2 loss : 0.019516
[02:59:19.269] iteration 28653 : model1 loss : 0.018821 model2 loss : 0.019178
[02:59:19.939] iteration 28654 : model1 loss : 0.017288 model2 loss : 0.020572
[02:59:20.606] iteration 28655 : model1 loss : 0.020445 model2 loss : 0.020538
[02:59:21.287] iteration 28656 : model1 loss : 0.021558 model2 loss : 0.024275
[02:59:21.951] iteration 28657 : model1 loss : 0.025141 model2 loss : 0.024580
[02:59:22.630] iteration 28658 : model1 loss : 0.019072 model2 loss : 0.022400
[02:59:23.288] iteration 28659 : model1 loss : 0.019358 model2 loss : 0.016977
[02:59:23.959] iteration 28660 : model1 loss : 0.018106 model2 loss : 0.019159
[02:59:24.625] iteration 28661 : model1 loss : 0.024142 model2 loss : 0.022299
[02:59:25.294] iteration 28662 : model1 loss : 0.023047 model2 loss : 0.023892
[02:59:25.950] iteration 28663 : model1 loss : 0.023246 model2 loss : 0.027441
[02:59:26.608] iteration 28664 : model1 loss : 0.017788 model2 loss : 0.017664
[02:59:27.273] iteration 28665 : model1 loss : 0.016141 model2 loss : 0.015105
[02:59:27.940] iteration 28666 : model1 loss : 0.021262 model2 loss : 0.021046
[02:59:28.614] iteration 28667 : model1 loss : 0.026986 model2 loss : 0.030050
[02:59:29.286] iteration 28668 : model1 loss : 0.015729 model2 loss : 0.015527
[02:59:29.937] iteration 28669 : model1 loss : 0.018849 model2 loss : 0.020192
[02:59:30.605] iteration 28670 : model1 loss : 0.019764 model2 loss : 0.017936
[02:59:31.281] iteration 28671 : model1 loss : 0.019949 model2 loss : 0.020245
[02:59:31.962] iteration 28672 : model1 loss : 0.023070 model2 loss : 0.024514
[02:59:32.635] iteration 28673 : model1 loss : 0.016281 model2 loss : 0.016957
[02:59:33.324] iteration 28674 : model1 loss : 0.016566 model2 loss : 0.017126
[02:59:34.010] iteration 28675 : model1 loss : 0.020052 model2 loss : 0.019296
[02:59:34.680] iteration 28676 : model1 loss : 0.018269 model2 loss : 0.018580
[02:59:35.353] iteration 28677 : model1 loss : 0.017735 model2 loss : 0.017600
[02:59:36.035] iteration 28678 : model1 loss : 0.021684 model2 loss : 0.022154
[02:59:36.708] iteration 28679 : model1 loss : 0.011082 model2 loss : 0.010922
[02:59:37.368] iteration 28680 : model1 loss : 0.021197 model2 loss : 0.020283
[02:59:38.028] iteration 28681 : model1 loss : 0.025626 model2 loss : 0.024591
[02:59:38.694] iteration 28682 : model1 loss : 0.023712 model2 loss : 0.025365
[02:59:39.363] iteration 28683 : model1 loss : 0.042766 model2 loss : 0.047183
[02:59:40.031] iteration 28684 : model1 loss : 0.017817 model2 loss : 0.017317
[02:59:40.693] iteration 28685 : model1 loss : 0.019443 model2 loss : 0.020587
[02:59:41.365] iteration 28686 : model1 loss : 0.019716 model2 loss : 0.018425
[02:59:42.039] iteration 28687 : model1 loss : 0.023080 model2 loss : 0.023889
[02:59:42.725] iteration 28688 : model1 loss : 0.018272 model2 loss : 0.018317
[02:59:43.417] iteration 28689 : model1 loss : 0.023032 model2 loss : 0.021391
[02:59:44.104] iteration 28690 : model1 loss : 0.015516 model2 loss : 0.016064
[02:59:44.789] iteration 28691 : model1 loss : 0.015103 model2 loss : 0.015227
[02:59:45.482] iteration 28692 : model1 loss : 0.017214 model2 loss : 0.017449
[02:59:46.165] iteration 28693 : model1 loss : 0.018757 model2 loss : 0.018990
[02:59:46.856] iteration 28694 : model1 loss : 0.017610 model2 loss : 0.017638
[02:59:47.541] iteration 28695 : model1 loss : 0.015797 model2 loss : 0.014760
[02:59:48.232] iteration 28696 : model1 loss : 0.018160 model2 loss : 0.020693
[02:59:48.920] iteration 28697 : model1 loss : 0.021957 model2 loss : 0.021746
[02:59:49.604] iteration 28698 : model1 loss : 0.013388 model2 loss : 0.014641
[02:59:50.287] iteration 28699 : model1 loss : 0.018403 model2 loss : 0.017986
[02:59:50.953] iteration 28700 : model1 loss : 0.016256 model2 loss : 0.015723
[02:59:51.687] iteration 28701 : model1 loss : 0.033289 model2 loss : 0.032035
[02:59:52.349] iteration 28702 : model1 loss : 0.017135 model2 loss : 0.017014
[02:59:53.008] iteration 28703 : model1 loss : 0.014632 model2 loss : 0.013842
[02:59:53.679] iteration 28704 : model1 loss : 0.021287 model2 loss : 0.018596
[02:59:54.348] iteration 28705 : model1 loss : 0.021671 model2 loss : 0.020234
[02:59:55.000] iteration 28706 : model1 loss : 0.021843 model2 loss : 0.022623
[02:59:55.664] iteration 28707 : model1 loss : 0.020324 model2 loss : 0.020177
[02:59:56.337] iteration 28708 : model1 loss : 0.024805 model2 loss : 0.025410
[02:59:57.003] iteration 28709 : model1 loss : 0.022388 model2 loss : 0.022490
[02:59:57.667] iteration 28710 : model1 loss : 0.021103 model2 loss : 0.020738
[02:59:58.331] iteration 28711 : model1 loss : 0.028234 model2 loss : 0.029219
[02:59:58.992] iteration 28712 : model1 loss : 0.018343 model2 loss : 0.017718
[02:59:59.651] iteration 28713 : model1 loss : 0.023157 model2 loss : 0.021695
[03:00:00.319] iteration 28714 : model1 loss : 0.022616 model2 loss : 0.022278
[03:00:00.982] iteration 28715 : model1 loss : 0.016836 model2 loss : 0.017702
[03:00:01.646] iteration 28716 : model1 loss : 0.029517 model2 loss : 0.031664
[03:00:02.317] iteration 28717 : model1 loss : 0.023523 model2 loss : 0.022643
[03:00:02.976] iteration 28718 : model1 loss : 0.020821 model2 loss : 0.017456
[03:00:03.647] iteration 28719 : model1 loss : 0.020300 model2 loss : 0.018915
[03:00:04.299] iteration 28720 : model1 loss : 0.021259 model2 loss : 0.018972
[03:00:04.967] iteration 28721 : model1 loss : 0.023931 model2 loss : 0.026902
[03:00:05.639] iteration 28722 : model1 loss : 0.023200 model2 loss : 0.019929
[03:00:06.318] iteration 28723 : model1 loss : 0.019161 model2 loss : 0.018150
[03:00:06.981] iteration 28724 : model1 loss : 0.018781 model2 loss : 0.018356
[03:00:07.649] iteration 28725 : model1 loss : 0.021527 model2 loss : 0.017125
[03:00:08.306] iteration 28726 : model1 loss : 0.017878 model2 loss : 0.018689
[03:00:08.971] iteration 28727 : model1 loss : 0.015345 model2 loss : 0.017403
[03:00:09.645] iteration 28728 : model1 loss : 0.020302 model2 loss : 0.021339
[03:00:10.320] iteration 28729 : model1 loss : 0.021103 model2 loss : 0.022529
[03:00:10.976] iteration 28730 : model1 loss : 0.019501 model2 loss : 0.019697
[03:00:11.645] iteration 28731 : model1 loss : 0.013132 model2 loss : 0.013854
[03:00:12.345] iteration 28732 : model1 loss : 0.017806 model2 loss : 0.018957
[03:00:13.015] iteration 28733 : model1 loss : 0.018828 model2 loss : 0.017941
[03:00:13.668] iteration 28734 : model1 loss : 0.022554 model2 loss : 0.022264
[03:00:14.351] iteration 28735 : model1 loss : 0.017342 model2 loss : 0.017600
[03:00:15.014] iteration 28736 : model1 loss : 0.019681 model2 loss : 0.020428
[03:00:15.681] iteration 28737 : model1 loss : 0.021473 model2 loss : 0.022326
[03:00:16.360] iteration 28738 : model1 loss : 0.017651 model2 loss : 0.016415
[03:00:17.023] iteration 28739 : model1 loss : 0.015976 model2 loss : 0.017536
[03:00:17.689] iteration 28740 : model1 loss : 0.021386 model2 loss : 0.020905
[03:00:18.352] iteration 28741 : model1 loss : 0.016422 model2 loss : 0.017150
[03:00:19.015] iteration 28742 : model1 loss : 0.020232 model2 loss : 0.021638
[03:00:19.680] iteration 28743 : model1 loss : 0.016638 model2 loss : 0.015316
[03:00:20.348] iteration 28744 : model1 loss : 0.023878 model2 loss : 0.022667
[03:00:21.019] iteration 28745 : model1 loss : 0.018390 model2 loss : 0.020973
[03:00:21.687] iteration 28746 : model1 loss : 0.016651 model2 loss : 0.016370
[03:00:22.351] iteration 28747 : model1 loss : 0.030200 model2 loss : 0.020846
[03:00:23.005] iteration 28748 : model1 loss : 0.016825 model2 loss : 0.014548
[03:00:23.670] iteration 28749 : model1 loss : 0.018962 model2 loss : 0.019015
[03:00:24.335] iteration 28750 : model1 loss : 0.022881 model2 loss : 0.020426
[03:00:25.050] iteration 28751 : model1 loss : 0.022084 model2 loss : 0.022442
[03:00:25.715] iteration 28752 : model1 loss : 0.017919 model2 loss : 0.017798
[03:00:26.380] iteration 28753 : model1 loss : 0.016130 model2 loss : 0.017478
[03:00:27.052] iteration 28754 : model1 loss : 0.020359 model2 loss : 0.023914
[03:00:27.715] iteration 28755 : model1 loss : 0.018812 model2 loss : 0.021817
[03:00:28.384] iteration 28756 : model1 loss : 0.018438 model2 loss : 0.017270
[03:00:29.035] iteration 28757 : model1 loss : 0.017878 model2 loss : 0.017795
[03:00:29.695] iteration 28758 : model1 loss : 0.019763 model2 loss : 0.019721
[03:00:30.357] iteration 28759 : model1 loss : 0.018822 model2 loss : 0.019485
[03:00:31.024] iteration 28760 : model1 loss : 0.020195 model2 loss : 0.019367
[03:00:31.683] iteration 28761 : model1 loss : 0.019811 model2 loss : 0.022087
[03:00:32.356] iteration 28762 : model1 loss : 0.017881 model2 loss : 0.016285
[03:00:33.025] iteration 28763 : model1 loss : 0.021481 model2 loss : 0.019738
[03:00:33.682] iteration 28764 : model1 loss : 0.017096 model2 loss : 0.016335
[03:00:34.354] iteration 28765 : model1 loss : 0.013140 model2 loss : 0.013135
[03:00:35.029] iteration 28766 : model1 loss : 0.015462 model2 loss : 0.016644
[03:00:35.695] iteration 28767 : model1 loss : 0.023095 model2 loss : 0.020755
[03:00:36.349] iteration 28768 : model1 loss : 0.021143 model2 loss : 0.021549
[03:00:37.009] iteration 28769 : model1 loss : 0.022479 model2 loss : 0.026928
[03:00:37.680] iteration 28770 : model1 loss : 0.015118 model2 loss : 0.014943
[03:00:38.349] iteration 28771 : model1 loss : 0.015317 model2 loss : 0.017617
[03:00:39.017] iteration 28772 : model1 loss : 0.020059 model2 loss : 0.019663
[03:00:39.681] iteration 28773 : model1 loss : 0.018087 model2 loss : 0.016693
[03:00:40.343] iteration 28774 : model1 loss : 0.026287 model2 loss : 0.026935
[03:00:41.012] iteration 28775 : model1 loss : 0.014496 model2 loss : 0.015540
[03:00:41.680] iteration 28776 : model1 loss : 0.020417 model2 loss : 0.021439
[03:00:42.345] iteration 28777 : model1 loss : 0.019742 model2 loss : 0.019916
[03:00:43.005] iteration 28778 : model1 loss : 0.026790 model2 loss : 0.026341
[03:00:43.667] iteration 28779 : model1 loss : 0.019347 model2 loss : 0.019926
[03:00:44.365] iteration 28780 : model1 loss : 0.017733 model2 loss : 0.017907
[03:00:45.047] iteration 28781 : model1 loss : 0.020069 model2 loss : 0.018502
[03:00:45.724] iteration 28782 : model1 loss : 0.026966 model2 loss : 0.024067
[03:00:46.381] iteration 28783 : model1 loss : 0.017317 model2 loss : 0.017502
[03:00:47.046] iteration 28784 : model1 loss : 0.023399 model2 loss : 0.023133
[03:00:47.707] iteration 28785 : model1 loss : 0.017366 model2 loss : 0.017685
[03:00:48.371] iteration 28786 : model1 loss : 0.016912 model2 loss : 0.019829
[03:00:49.033] iteration 28787 : model1 loss : 0.024746 model2 loss : 0.025438
[03:00:49.713] iteration 28788 : model1 loss : 0.021360 model2 loss : 0.023734
[03:00:50.391] iteration 28789 : model1 loss : 0.016926 model2 loss : 0.018610
[03:00:51.054] iteration 28790 : model1 loss : 0.017666 model2 loss : 0.018015
[03:00:51.713] iteration 28791 : model1 loss : 0.018471 model2 loss : 0.018865
[03:00:52.382] iteration 28792 : model1 loss : 0.018550 model2 loss : 0.019225
[03:00:53.047] iteration 28793 : model1 loss : 0.021731 model2 loss : 0.020792
[03:00:53.712] iteration 28794 : model1 loss : 0.024438 model2 loss : 0.023965
[03:00:54.382] iteration 28795 : model1 loss : 0.022128 model2 loss : 0.022371
[03:00:55.052] iteration 28796 : model1 loss : 0.018461 model2 loss : 0.016997
[03:00:55.706] iteration 28797 : model1 loss : 0.017112 model2 loss : 0.018391
[03:00:56.389] iteration 28798 : model1 loss : 0.021631 model2 loss : 0.021227
[03:00:57.056] iteration 28799 : model1 loss : 0.044905 model2 loss : 0.047543
[03:00:57.726] iteration 28800 : model1 loss : 0.017255 model2 loss : 0.015901
[03:01:16.051] iteration 28800 : model1_mean_dice : 0.876066 model1_mean_hd95 : 7.686642
[03:01:34.051] iteration 28800 : model2_mean_dice : 0.879765 model2_mean_hd95 : 4.869653
[03:01:34.751] iteration 28801 : model1 loss : 0.026208 model2 loss : 0.029250
[03:01:35.439] iteration 28802 : model1 loss : 0.029849 model2 loss : 0.029145
[03:01:36.105] iteration 28803 : model1 loss : 0.023795 model2 loss : 0.021424
[03:01:36.757] iteration 28804 : model1 loss : 0.075981 model2 loss : 0.084880
[03:01:37.434] iteration 28805 : model1 loss : 0.144291 model2 loss : 0.143098
[03:01:38.101] iteration 28806 : model1 loss : 0.025497 model2 loss : 0.022092
[03:01:38.756] iteration 28807 : model1 loss : 0.016257 model2 loss : 0.016645
[03:01:39.408] iteration 28808 : model1 loss : 0.018885 model2 loss : 0.019679
[03:01:40.067] iteration 28809 : model1 loss : 0.034608 model2 loss : 0.026200
[03:01:40.726] iteration 28810 : model1 loss : 0.022359 model2 loss : 0.023072
[03:01:41.396] iteration 28811 : model1 loss : 0.021899 model2 loss : 0.025960
[03:01:42.056] iteration 28812 : model1 loss : 0.020626 model2 loss : 0.021045
[03:01:42.705] iteration 28813 : model1 loss : 0.018427 model2 loss : 0.018371
[03:01:43.368] iteration 28814 : model1 loss : 0.023253 model2 loss : 0.025004
[03:01:44.029] iteration 28815 : model1 loss : 0.038836 model2 loss : 0.036290
[03:01:44.683] iteration 28816 : model1 loss : 0.024654 model2 loss : 0.021495
[03:01:45.348] iteration 28817 : model1 loss : 0.017878 model2 loss : 0.017312
[03:01:46.019] iteration 28818 : model1 loss : 0.018690 model2 loss : 0.017715
[03:01:46.682] iteration 28819 : model1 loss : 0.016157 model2 loss : 0.016021
[03:01:47.351] iteration 28820 : model1 loss : 0.019491 model2 loss : 0.025772
[03:01:47.995] iteration 28821 : model1 loss : 0.015929 model2 loss : 0.013972
[03:01:48.665] iteration 28822 : model1 loss : 0.021795 model2 loss : 0.021732
[03:01:49.320] iteration 28823 : model1 loss : 0.022894 model2 loss : 0.023523
[03:01:50.002] iteration 28824 : model1 loss : 0.018984 model2 loss : 0.021277
[03:01:50.666] iteration 28825 : model1 loss : 0.018976 model2 loss : 0.017647
[03:01:51.328] iteration 28826 : model1 loss : 0.027836 model2 loss : 0.029915
[03:01:51.991] iteration 28827 : model1 loss : 0.016478 model2 loss : 0.016251
[03:01:52.662] iteration 28828 : model1 loss : 0.026839 model2 loss : 0.021806
[03:01:53.319] iteration 28829 : model1 loss : 0.023936 model2 loss : 0.024135
[03:01:53.978] iteration 28830 : model1 loss : 0.018094 model2 loss : 0.018505
[03:01:54.630] iteration 28831 : model1 loss : 0.024194 model2 loss : 0.023065
[03:01:55.302] iteration 28832 : model1 loss : 0.022942 model2 loss : 0.021655
[03:01:55.960] iteration 28833 : model1 loss : 0.015179 model2 loss : 0.017992
[03:01:56.634] iteration 28834 : model1 loss : 0.023275 model2 loss : 0.023395
[03:01:57.304] iteration 28835 : model1 loss : 0.019293 model2 loss : 0.021171
[03:01:57.972] iteration 28836 : model1 loss : 0.017869 model2 loss : 0.017204
[03:01:58.634] iteration 28837 : model1 loss : 0.020819 model2 loss : 0.020730
[03:01:59.290] iteration 28838 : model1 loss : 0.018511 model2 loss : 0.020249
[03:01:59.952] iteration 28839 : model1 loss : 0.018174 model2 loss : 0.017475
[03:02:00.617] iteration 28840 : model1 loss : 0.024779 model2 loss : 0.025066
[03:02:01.284] iteration 28841 : model1 loss : 0.014375 model2 loss : 0.015249
[03:02:01.951] iteration 28842 : model1 loss : 0.018757 model2 loss : 0.017287
[03:02:02.616] iteration 28843 : model1 loss : 0.029699 model2 loss : 0.032549
[03:02:03.276] iteration 28844 : model1 loss : 0.016053 model2 loss : 0.017857
[03:02:03.951] iteration 28845 : model1 loss : 0.017266 model2 loss : 0.017397
[03:02:04.607] iteration 28846 : model1 loss : 0.013338 model2 loss : 0.014876
[03:02:05.271] iteration 28847 : model1 loss : 0.021799 model2 loss : 0.021010
[03:02:05.927] iteration 28848 : model1 loss : 0.015570 model2 loss : 0.015696
[03:02:06.590] iteration 28849 : model1 loss : 0.019804 model2 loss : 0.021817
[03:02:07.269] iteration 28850 : model1 loss : 0.021202 model2 loss : 0.032684
[03:02:07.978] iteration 28851 : model1 loss : 0.018869 model2 loss : 0.020821
[03:02:08.647] iteration 28852 : model1 loss : 0.023108 model2 loss : 0.022866
[03:02:09.319] iteration 28853 : model1 loss : 0.021276 model2 loss : 0.020698
[03:02:09.992] iteration 28854 : model1 loss : 0.017108 model2 loss : 0.019169
[03:02:10.650] iteration 28855 : model1 loss : 0.019873 model2 loss : 0.022254
[03:02:11.315] iteration 28856 : model1 loss : 0.019747 model2 loss : 0.019563
[03:02:11.988] iteration 28857 : model1 loss : 0.015649 model2 loss : 0.014934
[03:02:12.669] iteration 28858 : model1 loss : 0.022090 model2 loss : 0.022416
[03:02:13.336] iteration 28859 : model1 loss : 0.023393 model2 loss : 0.022234
[03:02:14.005] iteration 28860 : model1 loss : 0.014027 model2 loss : 0.014730
[03:02:14.666] iteration 28861 : model1 loss : 0.017270 model2 loss : 0.017352
[03:02:15.324] iteration 28862 : model1 loss : 0.028184 model2 loss : 0.028918
[03:02:16.003] iteration 28863 : model1 loss : 0.021787 model2 loss : 0.019173
[03:02:16.677] iteration 28864 : model1 loss : 0.022593 model2 loss : 0.025783
[03:02:17.353] iteration 28865 : model1 loss : 0.145138 model2 loss : 0.143993
[03:02:18.023] iteration 28866 : model1 loss : 0.016523 model2 loss : 0.016357
[03:02:18.690] iteration 28867 : model1 loss : 0.025823 model2 loss : 0.025062
[03:02:19.355] iteration 28868 : model1 loss : 0.016973 model2 loss : 0.015787
[03:02:20.014] iteration 28869 : model1 loss : 0.018295 model2 loss : 0.017463
[03:02:20.676] iteration 28870 : model1 loss : 0.017027 model2 loss : 0.016053
[03:02:21.348] iteration 28871 : model1 loss : 0.016021 model2 loss : 0.016472
[03:02:22.013] iteration 28872 : model1 loss : 0.017138 model2 loss : 0.017749
[03:02:22.690] iteration 28873 : model1 loss : 0.019187 model2 loss : 0.017277
[03:02:23.348] iteration 28874 : model1 loss : 0.021463 model2 loss : 0.020733
[03:02:24.011] iteration 28875 : model1 loss : 0.024073 model2 loss : 0.026186
[03:02:24.669] iteration 28876 : model1 loss : 0.017421 model2 loss : 0.016382
[03:02:25.337] iteration 28877 : model1 loss : 0.017765 model2 loss : 0.016967
[03:02:26.010] iteration 28878 : model1 loss : 0.020477 model2 loss : 0.020414
[03:02:26.678] iteration 28879 : model1 loss : 0.018263 model2 loss : 0.020463
[03:02:27.347] iteration 28880 : model1 loss : 0.016864 model2 loss : 0.018065
[03:02:28.015] iteration 28881 : model1 loss : 0.021768 model2 loss : 0.021955
[03:02:28.677] iteration 28882 : model1 loss : 0.017766 model2 loss : 0.018713
[03:02:29.351] iteration 28883 : model1 loss : 0.029606 model2 loss : 0.027557
[03:02:30.016] iteration 28884 : model1 loss : 0.028177 model2 loss : 0.024324
[03:02:30.680] iteration 28885 : model1 loss : 0.016362 model2 loss : 0.016386
[03:02:31.348] iteration 28886 : model1 loss : 0.015918 model2 loss : 0.016068
[03:02:32.022] iteration 28887 : model1 loss : 0.021702 model2 loss : 0.021155
[03:02:32.698] iteration 28888 : model1 loss : 0.016623 model2 loss : 0.017778
[03:02:33.349] iteration 28889 : model1 loss : 0.017619 model2 loss : 0.020076
[03:02:34.019] iteration 28890 : model1 loss : 0.017184 model2 loss : 0.017680
[03:02:34.678] iteration 28891 : model1 loss : 0.020378 model2 loss : 0.022038
[03:02:35.344] iteration 28892 : model1 loss : 0.017855 model2 loss : 0.018209
[03:02:36.008] iteration 28893 : model1 loss : 0.026221 model2 loss : 0.027504
[03:02:36.674] iteration 28894 : model1 loss : 0.018495 model2 loss : 0.018203
[03:02:37.337] iteration 28895 : model1 loss : 0.022538 model2 loss : 0.023717
[03:02:37.992] iteration 28896 : model1 loss : 0.016205 model2 loss : 0.014899
[03:02:38.670] iteration 28897 : model1 loss : 0.024955 model2 loss : 0.025797
[03:02:39.348] iteration 28898 : model1 loss : 0.022982 model2 loss : 0.023017
[03:02:40.006] iteration 28899 : model1 loss : 0.018037 model2 loss : 0.019003
[03:02:40.676] iteration 28900 : model1 loss : 0.018761 model2 loss : 0.019497
[03:02:41.379] iteration 28901 : model1 loss : 0.020573 model2 loss : 0.019309
[03:02:42.050] iteration 28902 : model1 loss : 0.021069 model2 loss : 0.018246
[03:02:42.717] iteration 28903 : model1 loss : 0.016939 model2 loss : 0.017477
[03:02:43.380] iteration 28904 : model1 loss : 0.015522 model2 loss : 0.017015
[03:02:44.047] iteration 28905 : model1 loss : 0.018303 model2 loss : 0.019315
[03:02:44.707] iteration 28906 : model1 loss : 0.025954 model2 loss : 0.022827
[03:02:45.383] iteration 28907 : model1 loss : 0.017882 model2 loss : 0.017384
[03:02:46.055] iteration 28908 : model1 loss : 0.020519 model2 loss : 0.023589
[03:02:46.714] iteration 28909 : model1 loss : 0.016524 model2 loss : 0.017763
[03:02:47.378] iteration 28910 : model1 loss : 0.020080 model2 loss : 0.021797
[03:02:48.040] iteration 28911 : model1 loss : 0.016830 model2 loss : 0.017485
[03:02:48.708] iteration 28912 : model1 loss : 0.020198 model2 loss : 0.021811
[03:02:49.373] iteration 28913 : model1 loss : 0.014775 model2 loss : 0.015440
[03:02:50.032] iteration 28914 : model1 loss : 0.026450 model2 loss : 0.027299
[03:02:50.695] iteration 28915 : model1 loss : 0.014991 model2 loss : 0.015768
[03:02:51.394] iteration 28916 : model1 loss : 0.023546 model2 loss : 0.024434
[03:02:52.050] iteration 28917 : model1 loss : 0.022649 model2 loss : 0.023529
[03:02:52.712] iteration 28918 : model1 loss : 0.018865 model2 loss : 0.018436
[03:02:53.386] iteration 28919 : model1 loss : 0.014062 model2 loss : 0.014898
[03:02:54.054] iteration 28920 : model1 loss : 0.025346 model2 loss : 0.023938
[03:02:54.709] iteration 28921 : model1 loss : 0.016273 model2 loss : 0.016905
[03:02:55.377] iteration 28922 : model1 loss : 0.021577 model2 loss : 0.023087
[03:02:56.049] iteration 28923 : model1 loss : 0.017170 model2 loss : 0.016326
[03:02:56.711] iteration 28924 : model1 loss : 0.017286 model2 loss : 0.017941
[03:02:57.372] iteration 28925 : model1 loss : 0.019938 model2 loss : 0.018580
[03:02:58.042] iteration 28926 : model1 loss : 0.021300 model2 loss : 0.020450
[03:02:58.717] iteration 28927 : model1 loss : 0.023497 model2 loss : 0.021995
[03:02:59.378] iteration 28928 : model1 loss : 0.014580 model2 loss : 0.015348
[03:03:00.040] iteration 28929 : model1 loss : 0.018660 model2 loss : 0.018857
[03:03:00.705] iteration 28930 : model1 loss : 0.021075 model2 loss : 0.020566
[03:03:01.370] iteration 28931 : model1 loss : 0.017850 model2 loss : 0.018257
[03:03:02.039] iteration 28932 : model1 loss : 0.016366 model2 loss : 0.014584
[03:03:02.720] iteration 28933 : model1 loss : 0.025623 model2 loss : 0.023108
[03:03:03.389] iteration 28934 : model1 loss : 0.025981 model2 loss : 0.025052
[03:03:04.065] iteration 28935 : model1 loss : 0.022439 model2 loss : 0.022225
[03:03:04.734] iteration 28936 : model1 loss : 0.017352 model2 loss : 0.017317
[03:03:05.398] iteration 28937 : model1 loss : 0.018301 model2 loss : 0.019343
[03:03:06.059] iteration 28938 : model1 loss : 0.016105 model2 loss : 0.015897
[03:03:06.730] iteration 28939 : model1 loss : 0.016715 model2 loss : 0.018582
[03:03:07.399] iteration 28940 : model1 loss : 0.017499 model2 loss : 0.019734
[03:03:08.059] iteration 28941 : model1 loss : 0.021594 model2 loss : 0.021695
[03:03:08.737] iteration 28942 : model1 loss : 0.018112 model2 loss : 0.019233
[03:03:09.402] iteration 28943 : model1 loss : 0.020125 model2 loss : 0.021606
[03:03:10.062] iteration 28944 : model1 loss : 0.018658 model2 loss : 0.017876
[03:03:10.725] iteration 28945 : model1 loss : 0.015510 model2 loss : 0.016243
[03:03:11.384] iteration 28946 : model1 loss : 0.017513 model2 loss : 0.016497
[03:03:12.039] iteration 28947 : model1 loss : 0.020153 model2 loss : 0.020426
[03:03:12.697] iteration 28948 : model1 loss : 0.021694 model2 loss : 0.022892
[03:03:13.396] iteration 28949 : model1 loss : 0.013460 model2 loss : 0.014660
[03:03:14.066] iteration 28950 : model1 loss : 0.015171 model2 loss : 0.014655
[03:03:14.789] iteration 28951 : model1 loss : 0.021632 model2 loss : 0.020525
[03:03:15.457] iteration 28952 : model1 loss : 0.018419 model2 loss : 0.020203
[03:03:16.111] iteration 28953 : model1 loss : 0.023024 model2 loss : 0.021513
[03:03:16.775] iteration 28954 : model1 loss : 0.016941 model2 loss : 0.015965
[03:03:17.430] iteration 28955 : model1 loss : 0.138037 model2 loss : 0.138488
[03:03:18.105] iteration 28956 : model1 loss : 0.024713 model2 loss : 0.022629
[03:03:18.784] iteration 28957 : model1 loss : 0.019157 model2 loss : 0.020117
[03:03:19.441] iteration 28958 : model1 loss : 0.024841 model2 loss : 0.024205
[03:03:20.109] iteration 28959 : model1 loss : 0.025806 model2 loss : 0.030069
[03:03:20.772] iteration 28960 : model1 loss : 0.023928 model2 loss : 0.020685
[03:03:21.455] iteration 28961 : model1 loss : 0.019580 model2 loss : 0.017739
[03:03:22.125] iteration 28962 : model1 loss : 0.027012 model2 loss : 0.023232
[03:03:22.791] iteration 28963 : model1 loss : 0.021835 model2 loss : 0.021793
[03:03:23.456] iteration 28964 : model1 loss : 0.017096 model2 loss : 0.019323
[03:03:24.119] iteration 28965 : model1 loss : 0.020600 model2 loss : 0.019945
[03:03:24.785] iteration 28966 : model1 loss : 0.028484 model2 loss : 0.031991
[03:03:25.449] iteration 28967 : model1 loss : 0.017197 model2 loss : 0.016696
[03:03:26.129] iteration 28968 : model1 loss : 0.025880 model2 loss : 0.022718
[03:03:26.803] iteration 28969 : model1 loss : 0.030494 model2 loss : 0.034883
[03:03:27.465] iteration 28970 : model1 loss : 0.018044 model2 loss : 0.019237
[03:03:28.131] iteration 28971 : model1 loss : 0.026168 model2 loss : 0.025742
[03:03:28.810] iteration 28972 : model1 loss : 0.015513 model2 loss : 0.014649
[03:03:29.476] iteration 28973 : model1 loss : 0.019332 model2 loss : 0.020487
[03:03:30.152] iteration 28974 : model1 loss : 0.048868 model2 loss : 0.060263
[03:03:30.804] iteration 28975 : model1 loss : 0.020894 model2 loss : 0.021117
[03:03:31.478] iteration 28976 : model1 loss : 0.019168 model2 loss : 0.018150
[03:03:32.149] iteration 28977 : model1 loss : 0.021476 model2 loss : 0.021490
[03:03:32.824] iteration 28978 : model1 loss : 0.022344 model2 loss : 0.020192
[03:03:33.505] iteration 28979 : model1 loss : 0.020117 model2 loss : 0.020600
[03:03:34.164] iteration 28980 : model1 loss : 0.014986 model2 loss : 0.013881
[03:03:34.839] iteration 28981 : model1 loss : 0.021378 model2 loss : 0.021309
[03:03:35.518] iteration 28982 : model1 loss : 0.017790 model2 loss : 0.018116
[03:03:36.191] iteration 28983 : model1 loss : 0.022726 model2 loss : 0.024043
[03:03:36.864] iteration 28984 : model1 loss : 0.017969 model2 loss : 0.019417
[03:03:37.530] iteration 28985 : model1 loss : 0.035872 model2 loss : 0.023574
[03:03:38.196] iteration 28986 : model1 loss : 0.019511 model2 loss : 0.017554
[03:03:38.852] iteration 28987 : model1 loss : 0.019017 model2 loss : 0.017937
[03:03:39.514] iteration 28988 : model1 loss : 0.018904 model2 loss : 0.017122
[03:03:40.186] iteration 28989 : model1 loss : 0.029049 model2 loss : 0.029038
[03:03:40.855] iteration 28990 : model1 loss : 0.021220 model2 loss : 0.021301
[03:03:41.517] iteration 28991 : model1 loss : 0.020882 model2 loss : 0.019582
[03:03:42.179] iteration 28992 : model1 loss : 0.019949 model2 loss : 0.021171
[03:03:42.856] iteration 28993 : model1 loss : 0.019668 model2 loss : 0.017541
[03:03:43.529] iteration 28994 : model1 loss : 0.018458 model2 loss : 0.016682
[03:03:44.183] iteration 28995 : model1 loss : 0.019009 model2 loss : 0.019986
[03:03:44.837] iteration 28996 : model1 loss : 0.017514 model2 loss : 0.017929
[03:03:45.504] iteration 28997 : model1 loss : 0.029842 model2 loss : 0.028427
[03:03:46.167] iteration 28998 : model1 loss : 0.016124 model2 loss : 0.017638
[03:03:46.843] iteration 28999 : model1 loss : 0.015951 model2 loss : 0.016198
[03:03:47.521] iteration 29000 : model1 loss : 0.018541 model2 loss : 0.016925
[03:04:05.575] iteration 29000 : model1_mean_dice : 0.875933 model1_mean_hd95 : 7.698945
[03:04:23.452] iteration 29000 : model2_mean_dice : 0.880312 model2_mean_hd95 : 4.914491
[03:04:24.146] iteration 29001 : model1 loss : 0.016069 model2 loss : 0.015408
[03:04:24.810] iteration 29002 : model1 loss : 0.021949 model2 loss : 0.024830
[03:04:25.475] iteration 29003 : model1 loss : 0.027455 model2 loss : 0.025573
[03:04:26.145] iteration 29004 : model1 loss : 0.021553 model2 loss : 0.018526
[03:04:26.803] iteration 29005 : model1 loss : 0.037099 model2 loss : 0.030634
[03:04:27.468] iteration 29006 : model1 loss : 0.019820 model2 loss : 0.017289
[03:04:28.119] iteration 29007 : model1 loss : 0.015354 model2 loss : 0.015944
[03:04:28.781] iteration 29008 : model1 loss : 0.015957 model2 loss : 0.015144
[03:04:29.468] iteration 29009 : model1 loss : 0.030408 model2 loss : 0.031847
[03:04:30.151] iteration 29010 : model1 loss : 0.020643 model2 loss : 0.019559
[03:04:30.812] iteration 29011 : model1 loss : 0.016401 model2 loss : 0.016482
[03:04:31.469] iteration 29012 : model1 loss : 0.025925 model2 loss : 0.026173
[03:04:32.130] iteration 29013 : model1 loss : 0.018580 model2 loss : 0.017408
[03:04:32.782] iteration 29014 : model1 loss : 0.014583 model2 loss : 0.014599
[03:04:33.447] iteration 29015 : model1 loss : 0.017876 model2 loss : 0.018188
[03:04:34.114] iteration 29016 : model1 loss : 0.019377 model2 loss : 0.020621
[03:04:34.774] iteration 29017 : model1 loss : 0.020056 model2 loss : 0.019340
[03:04:35.458] iteration 29018 : model1 loss : 0.017188 model2 loss : 0.016312
[03:04:36.111] iteration 29019 : model1 loss : 0.025256 model2 loss : 0.025739
[03:04:36.814] iteration 29020 : model1 loss : 0.019172 model2 loss : 0.017636
[03:04:37.479] iteration 29021 : model1 loss : 0.020478 model2 loss : 0.020694
[03:04:38.132] iteration 29022 : model1 loss : 0.015360 model2 loss : 0.015860
[03:04:38.816] iteration 29023 : model1 loss : 0.022998 model2 loss : 0.021743
[03:04:39.471] iteration 29024 : model1 loss : 0.021221 model2 loss : 0.019224
[03:04:40.134] iteration 29025 : model1 loss : 0.019111 model2 loss : 0.019874
[03:04:40.798] iteration 29026 : model1 loss : 0.023629 model2 loss : 0.024550
[03:04:41.458] iteration 29027 : model1 loss : 0.022917 model2 loss : 0.021915
[03:04:42.108] iteration 29028 : model1 loss : 0.014666 model2 loss : 0.014162
[03:04:42.768] iteration 29029 : model1 loss : 0.014253 model2 loss : 0.013978
[03:04:43.430] iteration 29030 : model1 loss : 0.017466 model2 loss : 0.016884
[03:04:44.092] iteration 29031 : model1 loss : 0.016397 model2 loss : 0.017495
[03:04:44.750] iteration 29032 : model1 loss : 0.016715 model2 loss : 0.017264
[03:04:45.414] iteration 29033 : model1 loss : 0.021362 model2 loss : 0.021006
[03:04:46.059] iteration 29034 : model1 loss : 0.015385 model2 loss : 0.016318
[03:04:46.739] iteration 29035 : model1 loss : 0.025118 model2 loss : 0.024189
[03:04:47.403] iteration 29036 : model1 loss : 0.022391 model2 loss : 0.022333
[03:04:48.057] iteration 29037 : model1 loss : 0.017246 model2 loss : 0.017793
[03:04:48.717] iteration 29038 : model1 loss : 0.014871 model2 loss : 0.015025
[03:04:49.382] iteration 29039 : model1 loss : 0.020167 model2 loss : 0.019480
[03:04:50.043] iteration 29040 : model1 loss : 0.020902 model2 loss : 0.021043
[03:04:50.701] iteration 29041 : model1 loss : 0.019187 model2 loss : 0.019853
[03:04:51.358] iteration 29042 : model1 loss : 0.023894 model2 loss : 0.021961
[03:04:52.021] iteration 29043 : model1 loss : 0.018404 model2 loss : 0.020830
[03:04:52.684] iteration 29044 : model1 loss : 0.022993 model2 loss : 0.018005
[03:04:53.361] iteration 29045 : model1 loss : 0.022226 model2 loss : 0.022012
[03:04:54.009] iteration 29046 : model1 loss : 0.025533 model2 loss : 0.025533
[03:04:54.678] iteration 29047 : model1 loss : 0.015780 model2 loss : 0.016450
[03:04:55.346] iteration 29048 : model1 loss : 0.025311 model2 loss : 0.028417
[03:04:56.016] iteration 29049 : model1 loss : 0.015629 model2 loss : 0.015573
[03:04:56.700] iteration 29050 : model1 loss : 0.020805 model2 loss : 0.020878
[03:04:57.404] iteration 29051 : model1 loss : 0.018996 model2 loss : 0.018574
[03:04:58.071] iteration 29052 : model1 loss : 0.017104 model2 loss : 0.018297
[03:04:58.748] iteration 29053 : model1 loss : 0.016943 model2 loss : 0.017663
[03:04:59.414] iteration 29054 : model1 loss : 0.015596 model2 loss : 0.015121
[03:05:00.077] iteration 29055 : model1 loss : 0.021056 model2 loss : 0.019833
[03:05:00.749] iteration 29056 : model1 loss : 0.034704 model2 loss : 0.036449
[03:05:01.411] iteration 29057 : model1 loss : 0.026735 model2 loss : 0.026697
[03:05:02.085] iteration 29058 : model1 loss : 0.022047 model2 loss : 0.024112
[03:05:02.757] iteration 29059 : model1 loss : 0.023179 model2 loss : 0.023215
[03:05:03.437] iteration 29060 : model1 loss : 0.054308 model2 loss : 0.056864
[03:05:04.096] iteration 29061 : model1 loss : 0.020232 model2 loss : 0.019063
[03:05:04.753] iteration 29062 : model1 loss : 0.046728 model2 loss : 0.045315
[03:05:05.406] iteration 29063 : model1 loss : 0.024950 model2 loss : 0.029233
[03:05:06.055] iteration 29064 : model1 loss : 0.038617 model2 loss : 0.047828
[03:05:06.722] iteration 29065 : model1 loss : 0.020166 model2 loss : 0.020308
[03:05:07.401] iteration 29066 : model1 loss : 0.023963 model2 loss : 0.023452
[03:05:08.075] iteration 29067 : model1 loss : 0.020485 model2 loss : 0.020349
[03:05:08.744] iteration 29068 : model1 loss : 0.020545 model2 loss : 0.020986
[03:05:09.411] iteration 29069 : model1 loss : 0.021965 model2 loss : 0.022024
[03:05:10.083] iteration 29070 : model1 loss : 0.019266 model2 loss : 0.018089
[03:05:10.751] iteration 29071 : model1 loss : 0.019384 model2 loss : 0.019797
[03:05:11.419] iteration 29072 : model1 loss : 0.020326 model2 loss : 0.021785
[03:05:12.085] iteration 29073 : model1 loss : 0.019791 model2 loss : 0.019536
[03:05:12.767] iteration 29074 : model1 loss : 0.025491 model2 loss : 0.024427
[03:05:13.448] iteration 29075 : model1 loss : 0.017981 model2 loss : 0.019813
[03:05:14.140] iteration 29076 : model1 loss : 0.017896 model2 loss : 0.016450
[03:05:14.812] iteration 29077 : model1 loss : 0.017803 model2 loss : 0.016874
[03:05:15.483] iteration 29078 : model1 loss : 0.019051 model2 loss : 0.020347
[03:05:16.148] iteration 29079 : model1 loss : 0.019534 model2 loss : 0.020928
[03:05:16.817] iteration 29080 : model1 loss : 0.018240 model2 loss : 0.017904
[03:05:17.495] iteration 29081 : model1 loss : 0.027739 model2 loss : 0.022113
[03:05:18.162] iteration 29082 : model1 loss : 0.139646 model2 loss : 0.138876
[03:05:18.836] iteration 29083 : model1 loss : 0.024409 model2 loss : 0.021888
[03:05:19.527] iteration 29084 : model1 loss : 0.020296 model2 loss : 0.020359
[03:05:20.199] iteration 29085 : model1 loss : 0.058351 model2 loss : 0.061311
[03:05:20.890] iteration 29086 : model1 loss : 0.139491 model2 loss : 0.139486
[03:05:21.571] iteration 29087 : model1 loss : 0.018058 model2 loss : 0.018383
[03:05:22.231] iteration 29088 : model1 loss : 0.022009 model2 loss : 0.021216
[03:05:22.897] iteration 29089 : model1 loss : 0.032779 model2 loss : 0.032059
[03:05:23.555] iteration 29090 : model1 loss : 0.022013 model2 loss : 0.020766
[03:05:24.230] iteration 29091 : model1 loss : 0.016501 model2 loss : 0.018460
[03:05:24.894] iteration 29092 : model1 loss : 0.020164 model2 loss : 0.020341
[03:05:25.561] iteration 29093 : model1 loss : 0.019535 model2 loss : 0.020482
[03:05:26.222] iteration 29094 : model1 loss : 0.017519 model2 loss : 0.019019
[03:05:26.881] iteration 29095 : model1 loss : 0.018831 model2 loss : 0.017652
[03:05:27.553] iteration 29096 : model1 loss : 0.016149 model2 loss : 0.015607
[03:05:28.219] iteration 29097 : model1 loss : 0.019228 model2 loss : 0.019874
[03:05:28.882] iteration 29098 : model1 loss : 0.018282 model2 loss : 0.019260
[03:05:29.555] iteration 29099 : model1 loss : 0.015991 model2 loss : 0.015513
[03:05:30.234] iteration 29100 : model1 loss : 0.018192 model2 loss : 0.017789
[03:05:31.109] iteration 29101 : model1 loss : 0.024885 model2 loss : 0.023344
[03:05:31.776] iteration 29102 : model1 loss : 0.017902 model2 loss : 0.017653
[03:05:32.436] iteration 29103 : model1 loss : 0.026883 model2 loss : 0.026492
[03:05:33.103] iteration 29104 : model1 loss : 0.019268 model2 loss : 0.020058
[03:05:33.770] iteration 29105 : model1 loss : 0.019184 model2 loss : 0.017435
[03:05:34.435] iteration 29106 : model1 loss : 0.017194 model2 loss : 0.017334
[03:05:35.091] iteration 29107 : model1 loss : 0.027643 model2 loss : 0.029710
[03:05:35.750] iteration 29108 : model1 loss : 0.016243 model2 loss : 0.017746
[03:05:36.435] iteration 29109 : model1 loss : 0.022418 model2 loss : 0.021168
[03:05:37.123] iteration 29110 : model1 loss : 0.032715 model2 loss : 0.037253
[03:05:37.810] iteration 29111 : model1 loss : 0.038878 model2 loss : 0.036601
[03:05:38.488] iteration 29112 : model1 loss : 0.025496 model2 loss : 0.024695
[03:05:39.148] iteration 29113 : model1 loss : 0.021357 model2 loss : 0.022027
[03:05:39.809] iteration 29114 : model1 loss : 0.023804 model2 loss : 0.022288
[03:05:40.477] iteration 29115 : model1 loss : 0.017148 model2 loss : 0.018458
[03:05:41.138] iteration 29116 : model1 loss : 0.024300 model2 loss : 0.023140
[03:05:41.805] iteration 29117 : model1 loss : 0.018033 model2 loss : 0.017778
[03:05:42.464] iteration 29118 : model1 loss : 0.023799 model2 loss : 0.022989
[03:05:43.150] iteration 29119 : model1 loss : 0.024294 model2 loss : 0.025186
[03:05:43.814] iteration 29120 : model1 loss : 0.016156 model2 loss : 0.016659
[03:05:44.478] iteration 29121 : model1 loss : 0.020684 model2 loss : 0.020374
[03:05:45.152] iteration 29122 : model1 loss : 0.020315 model2 loss : 0.021848
[03:05:45.811] iteration 29123 : model1 loss : 0.020957 model2 loss : 0.020397
[03:05:46.482] iteration 29124 : model1 loss : 0.017465 model2 loss : 0.016188
[03:05:47.139] iteration 29125 : model1 loss : 0.022788 model2 loss : 0.024382
[03:05:47.794] iteration 29126 : model1 loss : 0.028697 model2 loss : 0.028164
[03:05:48.458] iteration 29127 : model1 loss : 0.024133 model2 loss : 0.021119
[03:05:49.108] iteration 29128 : model1 loss : 0.021283 model2 loss : 0.022139
[03:05:49.759] iteration 29129 : model1 loss : 0.015671 model2 loss : 0.015964
[03:05:50.426] iteration 29130 : model1 loss : 0.016678 model2 loss : 0.014861
[03:05:51.075] iteration 29131 : model1 loss : 0.023113 model2 loss : 0.024209
[03:05:51.734] iteration 29132 : model1 loss : 0.025153 model2 loss : 0.023397
[03:05:52.402] iteration 29133 : model1 loss : 0.013951 model2 loss : 0.015068
[03:05:53.062] iteration 29134 : model1 loss : 0.022493 model2 loss : 0.024226
[03:05:53.724] iteration 29135 : model1 loss : 0.023502 model2 loss : 0.021599
[03:05:54.382] iteration 29136 : model1 loss : 0.021284 model2 loss : 0.018259
[03:05:55.044] iteration 29137 : model1 loss : 0.015318 model2 loss : 0.015729
[03:05:55.690] iteration 29138 : model1 loss : 0.035684 model2 loss : 0.042142
[03:05:56.351] iteration 29139 : model1 loss : 0.027139 model2 loss : 0.026111
[03:05:56.997] iteration 29140 : model1 loss : 0.020767 model2 loss : 0.019721
[03:05:57.668] iteration 29141 : model1 loss : 0.017379 model2 loss : 0.018171
[03:05:58.333] iteration 29142 : model1 loss : 0.017254 model2 loss : 0.018264
[03:05:58.987] iteration 29143 : model1 loss : 0.018555 model2 loss : 0.018861
[03:05:59.645] iteration 29144 : model1 loss : 0.031329 model2 loss : 0.035586
[03:06:00.312] iteration 29145 : model1 loss : 0.020179 model2 loss : 0.019852
[03:06:00.980] iteration 29146 : model1 loss : 0.020916 model2 loss : 0.020959
[03:06:01.639] iteration 29147 : model1 loss : 0.024055 model2 loss : 0.022014
[03:06:02.299] iteration 29148 : model1 loss : 0.018626 model2 loss : 0.017954
[03:06:02.958] iteration 29149 : model1 loss : 0.022856 model2 loss : 0.019823
[03:06:03.619] iteration 29150 : model1 loss : 0.022447 model2 loss : 0.022875
[03:06:04.332] iteration 29151 : model1 loss : 0.019727 model2 loss : 0.024094
[03:06:05.004] iteration 29152 : model1 loss : 0.017857 model2 loss : 0.016041
[03:06:05.653] iteration 29153 : model1 loss : 0.023113 model2 loss : 0.022816
[03:06:06.308] iteration 29154 : model1 loss : 0.020064 model2 loss : 0.018508
[03:06:06.959] iteration 29155 : model1 loss : 0.019659 model2 loss : 0.017995
[03:06:07.615] iteration 29156 : model1 loss : 0.021726 model2 loss : 0.020409
[03:06:08.277] iteration 29157 : model1 loss : 0.016975 model2 loss : 0.016251
[03:06:08.927] iteration 29158 : model1 loss : 0.025513 model2 loss : 0.026262
[03:06:09.584] iteration 29159 : model1 loss : 0.020239 model2 loss : 0.018235
[03:06:10.239] iteration 29160 : model1 loss : 0.016588 model2 loss : 0.016153
[03:06:10.906] iteration 29161 : model1 loss : 0.019162 model2 loss : 0.022003
[03:06:11.568] iteration 29162 : model1 loss : 0.019077 model2 loss : 0.017983
[03:06:12.225] iteration 29163 : model1 loss : 0.018415 model2 loss : 0.018253
[03:06:12.887] iteration 29164 : model1 loss : 0.022346 model2 loss : 0.024188
[03:06:13.549] iteration 29165 : model1 loss : 0.048484 model2 loss : 0.053926
[03:06:14.224] iteration 29166 : model1 loss : 0.016095 model2 loss : 0.016435
[03:06:14.924] iteration 29167 : model1 loss : 0.020540 model2 loss : 0.017967
[03:06:15.572] iteration 29168 : model1 loss : 0.016080 model2 loss : 0.016512
[03:06:16.243] iteration 29169 : model1 loss : 0.019950 model2 loss : 0.018085
[03:06:16.904] iteration 29170 : model1 loss : 0.024876 model2 loss : 0.024530
[03:06:17.559] iteration 29171 : model1 loss : 0.019940 model2 loss : 0.020955
[03:06:18.211] iteration 29172 : model1 loss : 0.016220 model2 loss : 0.015993
[03:06:18.864] iteration 29173 : model1 loss : 0.018418 model2 loss : 0.019124
[03:06:19.533] iteration 29174 : model1 loss : 0.016674 model2 loss : 0.017297
[03:06:20.185] iteration 29175 : model1 loss : 0.019365 model2 loss : 0.020906
[03:06:20.856] iteration 29176 : model1 loss : 0.020890 model2 loss : 0.022899
[03:06:21.547] iteration 29177 : model1 loss : 0.022499 model2 loss : 0.022456
[03:06:22.205] iteration 29178 : model1 loss : 0.146676 model2 loss : 0.145955
[03:06:22.870] iteration 29179 : model1 loss : 0.020976 model2 loss : 0.019366
[03:06:23.805] iteration 29180 : model1 loss : 0.018207 model2 loss : 0.018348
[03:06:24.527] iteration 29181 : model1 loss : 0.026463 model2 loss : 0.025270
[03:06:25.190] iteration 29182 : model1 loss : 0.020019 model2 loss : 0.018690
[03:06:25.848] iteration 29183 : model1 loss : 0.017586 model2 loss : 0.017524
[03:06:26.505] iteration 29184 : model1 loss : 0.021077 model2 loss : 0.021091
[03:06:27.179] iteration 29185 : model1 loss : 0.017548 model2 loss : 0.019996
[03:06:27.830] iteration 29186 : model1 loss : 0.018388 model2 loss : 0.017124
[03:06:28.501] iteration 29187 : model1 loss : 0.014228 model2 loss : 0.015075
[03:06:29.163] iteration 29188 : model1 loss : 0.013894 model2 loss : 0.016028
[03:06:29.816] iteration 29189 : model1 loss : 0.016711 model2 loss : 0.018516
[03:06:30.483] iteration 29190 : model1 loss : 0.014134 model2 loss : 0.016991
[03:06:31.143] iteration 29191 : model1 loss : 0.019371 model2 loss : 0.020607
[03:06:31.798] iteration 29192 : model1 loss : 0.016085 model2 loss : 0.016399
[03:06:32.463] iteration 29193 : model1 loss : 0.020799 model2 loss : 0.020820
[03:06:33.123] iteration 29194 : model1 loss : 0.019017 model2 loss : 0.019866
[03:06:33.786] iteration 29195 : model1 loss : 0.020071 model2 loss : 0.017847
[03:06:34.459] iteration 29196 : model1 loss : 0.016795 model2 loss : 0.017072
[03:06:35.117] iteration 29197 : model1 loss : 0.018423 model2 loss : 0.019545
[03:06:35.768] iteration 29198 : model1 loss : 0.022744 model2 loss : 0.023841
[03:06:36.427] iteration 29199 : model1 loss : 0.019817 model2 loss : 0.020474
[03:06:37.093] iteration 29200 : model1 loss : 0.017453 model2 loss : 0.017196
[03:06:55.140] iteration 29200 : model1_mean_dice : 0.878151 model1_mean_hd95 : 6.952681
[03:07:13.149] iteration 29200 : model2_mean_dice : 0.879720 model2_mean_hd95 : 4.794424
[03:07:13.814] iteration 29201 : model1 loss : 0.029835 model2 loss : 0.039358
[03:07:14.467] iteration 29202 : model1 loss : 0.020363 model2 loss : 0.022460
[03:07:15.145] iteration 29203 : model1 loss : 0.019051 model2 loss : 0.019600
[03:07:15.804] iteration 29204 : model1 loss : 0.019933 model2 loss : 0.020134
[03:07:16.455] iteration 29205 : model1 loss : 0.017917 model2 loss : 0.017027
[03:07:17.105] iteration 29206 : model1 loss : 0.030428 model2 loss : 0.030671
[03:07:17.775] iteration 29207 : model1 loss : 0.026150 model2 loss : 0.025186
[03:07:18.451] iteration 29208 : model1 loss : 0.025930 model2 loss : 0.024916
[03:07:19.100] iteration 29209 : model1 loss : 0.020027 model2 loss : 0.020326
[03:07:19.755] iteration 29210 : model1 loss : 0.018527 model2 loss : 0.019745
[03:07:20.420] iteration 29211 : model1 loss : 0.023310 model2 loss : 0.023052
[03:07:21.064] iteration 29212 : model1 loss : 0.019065 model2 loss : 0.018046
[03:07:21.729] iteration 29213 : model1 loss : 0.021184 model2 loss : 0.020712
[03:07:22.379] iteration 29214 : model1 loss : 0.016860 model2 loss : 0.017195
[03:07:23.049] iteration 29215 : model1 loss : 0.017155 model2 loss : 0.018282
[03:07:23.699] iteration 29216 : model1 loss : 0.044032 model2 loss : 0.037569
[03:07:24.355] iteration 29217 : model1 loss : 0.017170 model2 loss : 0.016727
[03:07:25.016] iteration 29218 : model1 loss : 0.019739 model2 loss : 0.018560
[03:07:25.678] iteration 29219 : model1 loss : 0.016451 model2 loss : 0.015859
[03:07:26.333] iteration 29220 : model1 loss : 0.022066 model2 loss : 0.019978
[03:07:26.982] iteration 29221 : model1 loss : 0.020606 model2 loss : 0.022332
[03:07:27.645] iteration 29222 : model1 loss : 0.016984 model2 loss : 0.016971
[03:07:28.305] iteration 29223 : model1 loss : 0.022385 model2 loss : 0.022638
[03:07:28.971] iteration 29224 : model1 loss : 0.020590 model2 loss : 0.020435
[03:07:29.633] iteration 29225 : model1 loss : 0.021778 model2 loss : 0.020625
[03:07:30.282] iteration 29226 : model1 loss : 0.034452 model2 loss : 0.030143
[03:07:30.940] iteration 29227 : model1 loss : 0.024329 model2 loss : 0.022469
[03:07:31.597] iteration 29228 : model1 loss : 0.018716 model2 loss : 0.018413
[03:07:32.249] iteration 29229 : model1 loss : 0.019809 model2 loss : 0.020737
[03:07:32.908] iteration 29230 : model1 loss : 0.018978 model2 loss : 0.017580
[03:07:33.567] iteration 29231 : model1 loss : 0.017998 model2 loss : 0.015185
[03:07:34.230] iteration 29232 : model1 loss : 0.035525 model2 loss : 0.032489
[03:07:34.892] iteration 29233 : model1 loss : 0.018057 model2 loss : 0.017248
[03:07:35.564] iteration 29234 : model1 loss : 0.031295 model2 loss : 0.044638
[03:07:36.217] iteration 29235 : model1 loss : 0.018284 model2 loss : 0.017720
[03:07:36.863] iteration 29236 : model1 loss : 0.017855 model2 loss : 0.017004
[03:07:37.535] iteration 29237 : model1 loss : 0.017884 model2 loss : 0.019180
[03:07:38.199] iteration 29238 : model1 loss : 0.037329 model2 loss : 0.032972
[03:07:38.866] iteration 29239 : model1 loss : 0.023143 model2 loss : 0.022144
[03:07:39.517] iteration 29240 : model1 loss : 0.019762 model2 loss : 0.019077
[03:07:40.178] iteration 29241 : model1 loss : 0.017809 model2 loss : 0.018000
[03:07:40.833] iteration 29242 : model1 loss : 0.018182 model2 loss : 0.020068
[03:07:41.495] iteration 29243 : model1 loss : 0.026514 model2 loss : 0.025887
[03:07:42.153] iteration 29244 : model1 loss : 0.017578 model2 loss : 0.017420
[03:07:42.823] iteration 29245 : model1 loss : 0.015994 model2 loss : 0.016944
[03:07:43.483] iteration 29246 : model1 loss : 0.023198 model2 loss : 0.021655
[03:07:44.139] iteration 29247 : model1 loss : 0.021030 model2 loss : 0.019091
[03:07:44.792] iteration 29248 : model1 loss : 0.013533 model2 loss : 0.013912
[03:07:45.462] iteration 29249 : model1 loss : 0.018845 model2 loss : 0.018275
[03:07:46.113] iteration 29250 : model1 loss : 0.018930 model2 loss : 0.018179
[03:07:46.804] iteration 29251 : model1 loss : 0.021481 model2 loss : 0.022553
[03:07:47.452] iteration 29252 : model1 loss : 0.018300 model2 loss : 0.020236
[03:07:48.122] iteration 29253 : model1 loss : 0.018944 model2 loss : 0.023282
[03:07:48.781] iteration 29254 : model1 loss : 0.015067 model2 loss : 0.015342
[03:07:49.427] iteration 29255 : model1 loss : 0.015381 model2 loss : 0.015023
[03:07:50.088] iteration 29256 : model1 loss : 0.028548 model2 loss : 0.026420
[03:07:50.753] iteration 29257 : model1 loss : 0.016580 model2 loss : 0.015994
[03:07:51.411] iteration 29258 : model1 loss : 0.021486 model2 loss : 0.023876
[03:07:52.073] iteration 29259 : model1 loss : 0.020605 model2 loss : 0.021169
[03:07:52.735] iteration 29260 : model1 loss : 0.042244 model2 loss : 0.033718
[03:07:53.396] iteration 29261 : model1 loss : 0.018676 model2 loss : 0.020119
[03:07:54.051] iteration 29262 : model1 loss : 0.016876 model2 loss : 0.017312
[03:07:54.706] iteration 29263 : model1 loss : 0.016926 model2 loss : 0.017367
[03:07:55.366] iteration 29264 : model1 loss : 0.028819 model2 loss : 0.027098
[03:07:56.026] iteration 29265 : model1 loss : 0.023581 model2 loss : 0.022049
[03:07:56.688] iteration 29266 : model1 loss : 0.017449 model2 loss : 0.018202
[03:07:57.352] iteration 29267 : model1 loss : 0.025878 model2 loss : 0.022383
[03:07:58.015] iteration 29268 : model1 loss : 0.024561 model2 loss : 0.023669
[03:07:58.682] iteration 29269 : model1 loss : 0.020232 model2 loss : 0.018571
[03:07:59.350] iteration 29270 : model1 loss : 0.016238 model2 loss : 0.017345
[03:08:00.016] iteration 29271 : model1 loss : 0.017537 model2 loss : 0.016547
[03:08:00.678] iteration 29272 : model1 loss : 0.022381 model2 loss : 0.024249
[03:08:01.345] iteration 29273 : model1 loss : 0.024229 model2 loss : 0.023240
[03:08:02.018] iteration 29274 : model1 loss : 0.020674 model2 loss : 0.018352
[03:08:02.680] iteration 29275 : model1 loss : 0.014205 model2 loss : 0.013928
[03:08:03.342] iteration 29276 : model1 loss : 0.016113 model2 loss : 0.017917
[03:08:03.997] iteration 29277 : model1 loss : 0.017700 model2 loss : 0.018144
[03:08:04.653] iteration 29278 : model1 loss : 0.041001 model2 loss : 0.035628
[03:08:05.335] iteration 29279 : model1 loss : 0.017372 model2 loss : 0.016791
[03:08:06.015] iteration 29280 : model1 loss : 0.019147 model2 loss : 0.019302
[03:08:06.675] iteration 29281 : model1 loss : 0.016197 model2 loss : 0.018483
[03:08:07.330] iteration 29282 : model1 loss : 0.023330 model2 loss : 0.022162
[03:08:07.982] iteration 29283 : model1 loss : 0.018520 model2 loss : 0.019630
[03:08:08.645] iteration 29284 : model1 loss : 0.018612 model2 loss : 0.020842
[03:08:09.303] iteration 29285 : model1 loss : 0.022786 model2 loss : 0.021773
[03:08:09.954] iteration 29286 : model1 loss : 0.017759 model2 loss : 0.018095
[03:08:10.605] iteration 29287 : model1 loss : 0.029835 model2 loss : 0.027820
[03:08:11.276] iteration 29288 : model1 loss : 0.019997 model2 loss : 0.018284
[03:08:11.933] iteration 29289 : model1 loss : 0.025862 model2 loss : 0.023446
[03:08:12.629] iteration 29290 : model1 loss : 0.026206 model2 loss : 0.026254
[03:08:13.283] iteration 29291 : model1 loss : 0.022864 model2 loss : 0.022759
[03:08:13.937] iteration 29292 : model1 loss : 0.015838 model2 loss : 0.018934
[03:08:14.593] iteration 29293 : model1 loss : 0.020304 model2 loss : 0.019878
[03:08:15.255] iteration 29294 : model1 loss : 0.014054 model2 loss : 0.014148
[03:08:15.935] iteration 29295 : model1 loss : 0.017178 model2 loss : 0.018097
[03:08:16.596] iteration 29296 : model1 loss : 0.016797 model2 loss : 0.017926
[03:08:17.252] iteration 29297 : model1 loss : 0.016986 model2 loss : 0.018434
[03:08:17.901] iteration 29298 : model1 loss : 0.017221 model2 loss : 0.020006
[03:08:18.581] iteration 29299 : model1 loss : 0.017506 model2 loss : 0.017787
[03:08:19.251] iteration 29300 : model1 loss : 0.015653 model2 loss : 0.016273
[03:08:19.944] iteration 29301 : model1 loss : 0.020942 model2 loss : 0.029121
[03:08:20.592] iteration 29302 : model1 loss : 0.016827 model2 loss : 0.015879
[03:08:21.245] iteration 29303 : model1 loss : 0.027972 model2 loss : 0.035092
[03:08:21.911] iteration 29304 : model1 loss : 0.016905 model2 loss : 0.017654
[03:08:22.577] iteration 29305 : model1 loss : 0.015698 model2 loss : 0.016665
[03:08:23.244] iteration 29306 : model1 loss : 0.024397 model2 loss : 0.021908
[03:08:23.899] iteration 29307 : model1 loss : 0.027390 model2 loss : 0.025811
[03:08:24.559] iteration 29308 : model1 loss : 0.016703 model2 loss : 0.015732
[03:08:25.215] iteration 29309 : model1 loss : 0.019942 model2 loss : 0.019207
[03:08:25.876] iteration 29310 : model1 loss : 0.025192 model2 loss : 0.025744
[03:08:26.520] iteration 29311 : model1 loss : 0.019603 model2 loss : 0.021765
[03:08:27.177] iteration 29312 : model1 loss : 0.016931 model2 loss : 0.017148
[03:08:27.836] iteration 29313 : model1 loss : 0.019594 model2 loss : 0.019347
[03:08:28.507] iteration 29314 : model1 loss : 0.022517 model2 loss : 0.021042
[03:08:29.163] iteration 29315 : model1 loss : 0.019730 model2 loss : 0.019048
[03:08:29.818] iteration 29316 : model1 loss : 0.030987 model2 loss : 0.032491
[03:08:30.483] iteration 29317 : model1 loss : 0.022248 model2 loss : 0.021705
[03:08:31.137] iteration 29318 : model1 loss : 0.018929 model2 loss : 0.018511
[03:08:31.792] iteration 29319 : model1 loss : 0.029583 model2 loss : 0.026445
[03:08:32.455] iteration 29320 : model1 loss : 0.013369 model2 loss : 0.013963
[03:08:33.111] iteration 29321 : model1 loss : 0.031458 model2 loss : 0.031279
[03:08:33.774] iteration 29322 : model1 loss : 0.019554 model2 loss : 0.018815
[03:08:34.434] iteration 29323 : model1 loss : 0.022714 model2 loss : 0.020682
[03:08:35.090] iteration 29324 : model1 loss : 0.019798 model2 loss : 0.020444
[03:08:35.745] iteration 29325 : model1 loss : 0.019192 model2 loss : 0.019530
[03:08:36.398] iteration 29326 : model1 loss : 0.016393 model2 loss : 0.017099
[03:08:37.040] iteration 29327 : model1 loss : 0.018735 model2 loss : 0.020031
[03:08:37.699] iteration 29328 : model1 loss : 0.022390 model2 loss : 0.022909
[03:08:38.352] iteration 29329 : model1 loss : 0.017997 model2 loss : 0.019799
[03:08:39.007] iteration 29330 : model1 loss : 0.022036 model2 loss : 0.024170
[03:08:39.659] iteration 29331 : model1 loss : 0.019313 model2 loss : 0.019268
[03:08:40.317] iteration 29332 : model1 loss : 0.015228 model2 loss : 0.016187
[03:08:40.988] iteration 29333 : model1 loss : 0.023868 model2 loss : 0.023823
[03:08:41.647] iteration 29334 : model1 loss : 0.016470 model2 loss : 0.016373
[03:08:42.321] iteration 29335 : model1 loss : 0.020197 model2 loss : 0.020930
[03:08:42.972] iteration 29336 : model1 loss : 0.022129 model2 loss : 0.018905
[03:08:43.627] iteration 29337 : model1 loss : 0.022791 model2 loss : 0.018450
[03:08:44.291] iteration 29338 : model1 loss : 0.021946 model2 loss : 0.020541
[03:08:44.951] iteration 29339 : model1 loss : 0.023181 model2 loss : 0.020411
[03:08:45.614] iteration 29340 : model1 loss : 0.014749 model2 loss : 0.015299
[03:08:46.264] iteration 29341 : model1 loss : 0.024788 model2 loss : 0.024786
[03:08:46.915] iteration 29342 : model1 loss : 0.021785 model2 loss : 0.022233
[03:08:47.582] iteration 29343 : model1 loss : 0.017867 model2 loss : 0.017280
[03:08:48.234] iteration 29344 : model1 loss : 0.021047 model2 loss : 0.021366
[03:08:48.883] iteration 29345 : model1 loss : 0.018724 model2 loss : 0.020934
[03:08:49.537] iteration 29346 : model1 loss : 0.019019 model2 loss : 0.017957
[03:08:50.193] iteration 29347 : model1 loss : 0.022166 model2 loss : 0.022572
[03:08:50.864] iteration 29348 : model1 loss : 0.017511 model2 loss : 0.020543
[03:08:51.521] iteration 29349 : model1 loss : 0.017081 model2 loss : 0.017766
[03:08:52.171] iteration 29350 : model1 loss : 0.024191 model2 loss : 0.023929
[03:08:52.854] iteration 29351 : model1 loss : 0.020104 model2 loss : 0.020243
[03:08:53.507] iteration 29352 : model1 loss : 0.015666 model2 loss : 0.015718
[03:08:54.176] iteration 29353 : model1 loss : 0.018648 model2 loss : 0.017168
[03:08:54.829] iteration 29354 : model1 loss : 0.018807 model2 loss : 0.017514
[03:08:55.498] iteration 29355 : model1 loss : 0.017809 model2 loss : 0.017664
[03:08:56.149] iteration 29356 : model1 loss : 0.021129 model2 loss : 0.021442
[03:08:56.802] iteration 29357 : model1 loss : 0.021975 model2 loss : 0.019635
[03:08:57.456] iteration 29358 : model1 loss : 0.024228 model2 loss : 0.023378
[03:08:58.130] iteration 29359 : model1 loss : 0.021537 model2 loss : 0.021400
[03:08:58.802] iteration 29360 : model1 loss : 0.021113 model2 loss : 0.019871
[03:08:59.463] iteration 29361 : model1 loss : 0.018054 model2 loss : 0.019375
[03:09:00.112] iteration 29362 : model1 loss : 0.015594 model2 loss : 0.016263
[03:09:00.769] iteration 29363 : model1 loss : 0.021323 model2 loss : 0.020755
[03:09:01.435] iteration 29364 : model1 loss : 0.034863 model2 loss : 0.036549
[03:09:02.105] iteration 29365 : model1 loss : 0.014763 model2 loss : 0.015204
[03:09:02.779] iteration 29366 : model1 loss : 0.016632 model2 loss : 0.017501
[03:09:03.446] iteration 29367 : model1 loss : 0.019284 model2 loss : 0.021502
[03:09:04.104] iteration 29368 : model1 loss : 0.014057 model2 loss : 0.014471
[03:09:04.760] iteration 29369 : model1 loss : 0.020869 model2 loss : 0.019355
[03:09:05.434] iteration 29370 : model1 loss : 0.015776 model2 loss : 0.016163
[03:09:06.092] iteration 29371 : model1 loss : 0.014863 model2 loss : 0.017084
[03:09:06.745] iteration 29372 : model1 loss : 0.021496 model2 loss : 0.020309
[03:09:07.401] iteration 29373 : model1 loss : 0.022482 model2 loss : 0.021481
[03:09:08.064] iteration 29374 : model1 loss : 0.017048 model2 loss : 0.016616
[03:09:08.744] iteration 29375 : model1 loss : 0.019331 model2 loss : 0.019084
[03:09:09.406] iteration 29376 : model1 loss : 0.020790 model2 loss : 0.021023
[03:09:10.059] iteration 29377 : model1 loss : 0.020551 model2 loss : 0.017025
[03:09:10.716] iteration 29378 : model1 loss : 0.017079 model2 loss : 0.020364
[03:09:11.374] iteration 29379 : model1 loss : 0.016535 model2 loss : 0.018311
[03:09:12.030] iteration 29380 : model1 loss : 0.022220 model2 loss : 0.021003
[03:09:12.694] iteration 29381 : model1 loss : 0.024600 model2 loss : 0.022961
[03:09:13.358] iteration 29382 : model1 loss : 0.020930 model2 loss : 0.021015
[03:09:14.017] iteration 29383 : model1 loss : 0.014799 model2 loss : 0.013969
[03:09:14.673] iteration 29384 : model1 loss : 0.024073 model2 loss : 0.025954
[03:09:15.346] iteration 29385 : model1 loss : 0.018683 model2 loss : 0.019054
[03:09:16.022] iteration 29386 : model1 loss : 0.014706 model2 loss : 0.015580
[03:09:16.680] iteration 29387 : model1 loss : 0.020041 model2 loss : 0.020618
[03:09:17.351] iteration 29388 : model1 loss : 0.020755 model2 loss : 0.019767
[03:09:17.994] iteration 29389 : model1 loss : 0.019006 model2 loss : 0.018717
[03:09:18.667] iteration 29390 : model1 loss : 0.018200 model2 loss : 0.019080
[03:09:19.334] iteration 29391 : model1 loss : 0.018251 model2 loss : 0.017763
[03:09:19.991] iteration 29392 : model1 loss : 0.023547 model2 loss : 0.023067
[03:09:20.666] iteration 29393 : model1 loss : 0.021641 model2 loss : 0.019901
[03:09:21.316] iteration 29394 : model1 loss : 0.022398 model2 loss : 0.022928
[03:09:21.983] iteration 29395 : model1 loss : 0.029515 model2 loss : 0.032228
[03:09:22.646] iteration 29396 : model1 loss : 0.026554 model2 loss : 0.025706
[03:09:23.311] iteration 29397 : model1 loss : 0.027325 model2 loss : 0.026967
[03:09:23.972] iteration 29398 : model1 loss : 0.039103 model2 loss : 0.039398
[03:09:24.651] iteration 29399 : model1 loss : 0.023227 model2 loss : 0.023428
[03:09:25.326] iteration 29400 : model1 loss : 0.018814 model2 loss : 0.017222
[03:09:43.867] iteration 29400 : model1_mean_dice : 0.876737 model1_mean_hd95 : 7.136947
[03:10:01.476] iteration 29400 : model2_mean_dice : 0.879986 model2_mean_hd95 : 4.908972
[03:10:02.187] iteration 29401 : model1 loss : 0.022472 model2 loss : 0.021557
[03:10:02.833] iteration 29402 : model1 loss : 0.020546 model2 loss : 0.022114
[03:10:03.482] iteration 29403 : model1 loss : 0.017274 model2 loss : 0.016186
[03:10:04.144] iteration 29404 : model1 loss : 0.027718 model2 loss : 0.025172
[03:10:04.794] iteration 29405 : model1 loss : 0.019994 model2 loss : 0.020309
[03:10:05.447] iteration 29406 : model1 loss : 0.021322 model2 loss : 0.022942
[03:10:06.096] iteration 29407 : model1 loss : 0.013961 model2 loss : 0.014997
[03:10:06.739] iteration 29408 : model1 loss : 0.016490 model2 loss : 0.017825
[03:10:07.393] iteration 29409 : model1 loss : 0.021499 model2 loss : 0.020056
[03:10:08.040] iteration 29410 : model1 loss : 0.019115 model2 loss : 0.019104
[03:10:08.696] iteration 29411 : model1 loss : 0.025816 model2 loss : 0.023892
[03:10:09.348] iteration 29412 : model1 loss : 0.020352 model2 loss : 0.019978
[03:10:10.013] iteration 29413 : model1 loss : 0.018115 model2 loss : 0.017385
[03:10:10.677] iteration 29414 : model1 loss : 0.020767 model2 loss : 0.020529
[03:10:11.340] iteration 29415 : model1 loss : 0.021791 model2 loss : 0.021674
[03:10:11.994] iteration 29416 : model1 loss : 0.018659 model2 loss : 0.019121
[03:10:12.650] iteration 29417 : model1 loss : 0.020778 model2 loss : 0.025159
[03:10:13.302] iteration 29418 : model1 loss : 0.018174 model2 loss : 0.016159
[03:10:13.970] iteration 29419 : model1 loss : 0.019534 model2 loss : 0.020393
[03:10:14.618] iteration 29420 : model1 loss : 0.016710 model2 loss : 0.015607
[03:10:15.308] iteration 29421 : model1 loss : 0.013478 model2 loss : 0.015132
[03:10:15.954] iteration 29422 : model1 loss : 0.018541 model2 loss : 0.017386
[03:10:16.646] iteration 29423 : model1 loss : 0.017680 model2 loss : 0.019208
[03:10:17.307] iteration 29424 : model1 loss : 0.015433 model2 loss : 0.016579
[03:10:17.957] iteration 29425 : model1 loss : 0.016469 model2 loss : 0.016839
[03:10:18.630] iteration 29426 : model1 loss : 0.014732 model2 loss : 0.013788
[03:10:19.282] iteration 29427 : model1 loss : 0.016756 model2 loss : 0.018386
[03:10:19.950] iteration 29428 : model1 loss : 0.017945 model2 loss : 0.017843
[03:10:20.613] iteration 29429 : model1 loss : 0.014392 model2 loss : 0.014665
[03:10:21.257] iteration 29430 : model1 loss : 0.019142 model2 loss : 0.018569
[03:10:21.907] iteration 29431 : model1 loss : 0.018313 model2 loss : 0.018026
[03:10:22.573] iteration 29432 : model1 loss : 0.045217 model2 loss : 0.043052
[03:10:23.227] iteration 29433 : model1 loss : 0.019518 model2 loss : 0.019920
[03:10:23.889] iteration 29434 : model1 loss : 0.017996 model2 loss : 0.018656
[03:10:24.552] iteration 29435 : model1 loss : 0.017496 model2 loss : 0.016634
[03:10:25.224] iteration 29436 : model1 loss : 0.023997 model2 loss : 0.025682
[03:10:25.881] iteration 29437 : model1 loss : 0.019339 model2 loss : 0.019880
[03:10:26.537] iteration 29438 : model1 loss : 0.019447 model2 loss : 0.019174
[03:10:27.203] iteration 29439 : model1 loss : 0.019655 model2 loss : 0.019011
[03:10:27.867] iteration 29440 : model1 loss : 0.138826 model2 loss : 0.136249
[03:10:28.538] iteration 29441 : model1 loss : 0.020687 model2 loss : 0.021758
[03:10:29.195] iteration 29442 : model1 loss : 0.015021 model2 loss : 0.016446
[03:10:29.852] iteration 29443 : model1 loss : 0.029511 model2 loss : 0.027126
[03:10:30.516] iteration 29444 : model1 loss : 0.021519 model2 loss : 0.021549
[03:10:31.178] iteration 29445 : model1 loss : 0.018339 model2 loss : 0.017639
[03:10:31.833] iteration 29446 : model1 loss : 0.023461 model2 loss : 0.020303
[03:10:32.490] iteration 29447 : model1 loss : 0.016624 model2 loss : 0.017402
[03:10:33.145] iteration 29448 : model1 loss : 0.021632 model2 loss : 0.021012
[03:10:33.808] iteration 29449 : model1 loss : 0.018686 model2 loss : 0.017365
[03:10:34.470] iteration 29450 : model1 loss : 0.017358 model2 loss : 0.016131
[03:10:35.180] iteration 29451 : model1 loss : 0.019847 model2 loss : 0.020720
[03:10:35.843] iteration 29452 : model1 loss : 0.021583 model2 loss : 0.019992
[03:10:36.498] iteration 29453 : model1 loss : 0.019484 model2 loss : 0.017274
[03:10:37.174] iteration 29454 : model1 loss : 0.025378 model2 loss : 0.029827
[03:10:37.833] iteration 29455 : model1 loss : 0.018980 model2 loss : 0.018346
[03:10:38.491] iteration 29456 : model1 loss : 0.018047 model2 loss : 0.017407
[03:10:39.139] iteration 29457 : model1 loss : 0.020619 model2 loss : 0.019456
[03:10:39.808] iteration 29458 : model1 loss : 0.020088 model2 loss : 0.018971
[03:10:40.471] iteration 29459 : model1 loss : 0.018244 model2 loss : 0.019805
[03:10:41.123] iteration 29460 : model1 loss : 0.014839 model2 loss : 0.014831
[03:10:41.781] iteration 29461 : model1 loss : 0.016673 model2 loss : 0.016340
[03:10:42.452] iteration 29462 : model1 loss : 0.019704 model2 loss : 0.018709
[03:10:43.102] iteration 29463 : model1 loss : 0.013756 model2 loss : 0.012690
[03:10:43.747] iteration 29464 : model1 loss : 0.014989 model2 loss : 0.015830
[03:10:44.401] iteration 29465 : model1 loss : 0.023618 model2 loss : 0.021168
[03:10:45.057] iteration 29466 : model1 loss : 0.022642 model2 loss : 0.022904
[03:10:45.711] iteration 29467 : model1 loss : 0.018841 model2 loss : 0.019752
[03:10:46.360] iteration 29468 : model1 loss : 0.016966 model2 loss : 0.017989
[03:10:47.034] iteration 29469 : model1 loss : 0.026103 model2 loss : 0.024476
[03:10:47.690] iteration 29470 : model1 loss : 0.015954 model2 loss : 0.016168
[03:10:48.347] iteration 29471 : model1 loss : 0.038330 model2 loss : 0.039901
[03:10:49.005] iteration 29472 : model1 loss : 0.015691 model2 loss : 0.017011
[03:10:49.676] iteration 29473 : model1 loss : 0.018856 model2 loss : 0.020180
[03:10:50.350] iteration 29474 : model1 loss : 0.024500 model2 loss : 0.023680
[03:10:51.016] iteration 29475 : model1 loss : 0.015768 model2 loss : 0.015366
[03:10:51.681] iteration 29476 : model1 loss : 0.020148 model2 loss : 0.020406
[03:10:52.346] iteration 29477 : model1 loss : 0.024643 model2 loss : 0.021286
[03:10:52.993] iteration 29478 : model1 loss : 0.022527 model2 loss : 0.022501
[03:10:53.662] iteration 29479 : model1 loss : 0.022649 model2 loss : 0.022382
[03:10:54.321] iteration 29480 : model1 loss : 0.029132 model2 loss : 0.028227
[03:10:54.974] iteration 29481 : model1 loss : 0.019981 model2 loss : 0.018259
[03:10:55.640] iteration 29482 : model1 loss : 0.017762 model2 loss : 0.021252
[03:10:56.307] iteration 29483 : model1 loss : 0.024877 model2 loss : 0.023816
[03:10:56.973] iteration 29484 : model1 loss : 0.015057 model2 loss : 0.014650
[03:10:57.627] iteration 29485 : model1 loss : 0.030390 model2 loss : 0.022635
[03:10:58.293] iteration 29486 : model1 loss : 0.023482 model2 loss : 0.024043
[03:10:58.946] iteration 29487 : model1 loss : 0.017675 model2 loss : 0.017023
[03:10:59.602] iteration 29488 : model1 loss : 0.021058 model2 loss : 0.022299
[03:11:00.262] iteration 29489 : model1 loss : 0.018304 model2 loss : 0.018501
[03:11:00.917] iteration 29490 : model1 loss : 0.026445 model2 loss : 0.026612
[03:11:01.567] iteration 29491 : model1 loss : 0.016331 model2 loss : 0.017238
[03:11:02.227] iteration 29492 : model1 loss : 0.022990 model2 loss : 0.024022
[03:11:02.889] iteration 29493 : model1 loss : 0.018813 model2 loss : 0.019487
[03:11:03.545] iteration 29494 : model1 loss : 0.016555 model2 loss : 0.015925
[03:11:04.197] iteration 29495 : model1 loss : 0.019006 model2 loss : 0.019324
[03:11:04.850] iteration 29496 : model1 loss : 0.016149 model2 loss : 0.016192
[03:11:05.510] iteration 29497 : model1 loss : 0.019518 model2 loss : 0.019003
[03:11:06.168] iteration 29498 : model1 loss : 0.020141 model2 loss : 0.021900
[03:11:06.816] iteration 29499 : model1 loss : 0.020027 model2 loss : 0.019161
[03:11:07.478] iteration 29500 : model1 loss : 0.016759 model2 loss : 0.015210
[03:11:08.185] iteration 29501 : model1 loss : 0.018411 model2 loss : 0.019380
[03:11:08.847] iteration 29502 : model1 loss : 0.018581 model2 loss : 0.017552
[03:11:09.507] iteration 29503 : model1 loss : 0.025654 model2 loss : 0.028441
[03:11:10.162] iteration 29504 : model1 loss : 0.016813 model2 loss : 0.016175
[03:11:10.831] iteration 29505 : model1 loss : 0.020616 model2 loss : 0.019303
[03:11:11.496] iteration 29506 : model1 loss : 0.019698 model2 loss : 0.023110
[03:11:12.164] iteration 29507 : model1 loss : 0.021354 model2 loss : 0.020519
[03:11:12.821] iteration 29508 : model1 loss : 0.018470 model2 loss : 0.019493
[03:11:13.478] iteration 29509 : model1 loss : 0.018587 model2 loss : 0.016951
[03:11:14.145] iteration 29510 : model1 loss : 0.020521 model2 loss : 0.018562
[03:11:14.806] iteration 29511 : model1 loss : 0.015910 model2 loss : 0.016147
[03:11:15.458] iteration 29512 : model1 loss : 0.029309 model2 loss : 0.024845
[03:11:16.121] iteration 29513 : model1 loss : 0.021346 model2 loss : 0.020559
[03:11:16.794] iteration 29514 : model1 loss : 0.023277 model2 loss : 0.024032
[03:11:17.468] iteration 29515 : model1 loss : 0.017711 model2 loss : 0.018354
[03:11:18.129] iteration 29516 : model1 loss : 0.024475 model2 loss : 0.029658
[03:11:18.787] iteration 29517 : model1 loss : 0.017335 model2 loss : 0.017499
[03:11:19.443] iteration 29518 : model1 loss : 0.017820 model2 loss : 0.016970
[03:11:20.091] iteration 29519 : model1 loss : 0.015485 model2 loss : 0.016677
[03:11:20.756] iteration 29520 : model1 loss : 0.024396 model2 loss : 0.018041
[03:11:21.419] iteration 29521 : model1 loss : 0.092793 model2 loss : 0.070288
[03:11:22.076] iteration 29522 : model1 loss : 0.013321 model2 loss : 0.013365
[03:11:22.736] iteration 29523 : model1 loss : 0.018949 model2 loss : 0.018687
[03:11:23.412] iteration 29524 : model1 loss : 0.017531 model2 loss : 0.018075
[03:11:24.071] iteration 29525 : model1 loss : 0.034819 model2 loss : 0.041813
[03:11:24.732] iteration 29526 : model1 loss : 0.016661 model2 loss : 0.017611
[03:11:25.382] iteration 29527 : model1 loss : 0.018822 model2 loss : 0.019735
[03:11:26.034] iteration 29528 : model1 loss : 0.016580 model2 loss : 0.018555
[03:11:26.705] iteration 29529 : model1 loss : 0.016096 model2 loss : 0.015749
[03:11:27.354] iteration 29530 : model1 loss : 0.016706 model2 loss : 0.018540
[03:11:28.020] iteration 29531 : model1 loss : 0.016744 model2 loss : 0.017630
[03:11:28.674] iteration 29532 : model1 loss : 0.019335 model2 loss : 0.018975
[03:11:29.336] iteration 29533 : model1 loss : 0.019953 model2 loss : 0.021315
[03:11:29.997] iteration 29534 : model1 loss : 0.023498 model2 loss : 0.021903
[03:11:30.662] iteration 29535 : model1 loss : 0.021014 model2 loss : 0.020523
[03:11:31.321] iteration 29536 : model1 loss : 0.019223 model2 loss : 0.017478
[03:11:31.968] iteration 29537 : model1 loss : 0.018076 model2 loss : 0.020017
[03:11:32.642] iteration 29538 : model1 loss : 0.017428 model2 loss : 0.016878
[03:11:33.322] iteration 29539 : model1 loss : 0.019340 model2 loss : 0.018717
[03:11:33.975] iteration 29540 : model1 loss : 0.022651 model2 loss : 0.020117
[03:11:34.635] iteration 29541 : model1 loss : 0.016180 model2 loss : 0.016905
[03:11:35.310] iteration 29542 : model1 loss : 0.024660 model2 loss : 0.026482
[03:11:35.967] iteration 29543 : model1 loss : 0.018734 model2 loss : 0.018111
[03:11:36.614] iteration 29544 : model1 loss : 0.021569 model2 loss : 0.021798
[03:11:37.278] iteration 29545 : model1 loss : 0.015704 model2 loss : 0.017653
[03:11:37.947] iteration 29546 : model1 loss : 0.030861 model2 loss : 0.032152
[03:11:38.612] iteration 29547 : model1 loss : 0.139119 model2 loss : 0.138357
[03:11:39.275] iteration 29548 : model1 loss : 0.013023 model2 loss : 0.014674
[03:11:39.927] iteration 29549 : model1 loss : 0.019160 model2 loss : 0.020231
[03:11:40.591] iteration 29550 : model1 loss : 0.020302 model2 loss : 0.019090
[03:11:41.305] iteration 29551 : model1 loss : 0.018269 model2 loss : 0.017359
[03:11:41.960] iteration 29552 : model1 loss : 0.019035 model2 loss : 0.018554
[03:11:42.622] iteration 29553 : model1 loss : 0.018050 model2 loss : 0.017556
[03:11:43.283] iteration 29554 : model1 loss : 0.024868 model2 loss : 0.023750
[03:11:43.947] iteration 29555 : model1 loss : 0.023748 model2 loss : 0.022043
[03:11:44.597] iteration 29556 : model1 loss : 0.023746 model2 loss : 0.023108
[03:11:45.246] iteration 29557 : model1 loss : 0.021445 model2 loss : 0.019932
[03:11:45.894] iteration 29558 : model1 loss : 0.020246 model2 loss : 0.020738
[03:11:46.553] iteration 29559 : model1 loss : 0.017904 model2 loss : 0.017462
[03:11:47.208] iteration 29560 : model1 loss : 0.021463 model2 loss : 0.020394
[03:11:47.866] iteration 29561 : model1 loss : 0.024630 model2 loss : 0.022350
[03:11:48.544] iteration 29562 : model1 loss : 0.014123 model2 loss : 0.015200
[03:11:49.205] iteration 29563 : model1 loss : 0.026037 model2 loss : 0.026235
[03:11:49.868] iteration 29564 : model1 loss : 0.022068 model2 loss : 0.021927
[03:11:50.526] iteration 29565 : model1 loss : 0.019092 model2 loss : 0.019700
[03:11:51.208] iteration 29566 : model1 loss : 0.019022 model2 loss : 0.021158
[03:11:51.865] iteration 29567 : model1 loss : 0.016706 model2 loss : 0.018817
[03:11:52.535] iteration 29568 : model1 loss : 0.022067 model2 loss : 0.022923
[03:11:53.206] iteration 29569 : model1 loss : 0.020012 model2 loss : 0.020898
[03:11:53.870] iteration 29570 : model1 loss : 0.022856 model2 loss : 0.020807
[03:11:54.524] iteration 29571 : model1 loss : 0.024561 model2 loss : 0.026240
[03:11:55.173] iteration 29572 : model1 loss : 0.016086 model2 loss : 0.016669
[03:11:55.833] iteration 29573 : model1 loss : 0.018564 model2 loss : 0.019502
[03:11:56.488] iteration 29574 : model1 loss : 0.021080 model2 loss : 0.018886
[03:11:57.145] iteration 29575 : model1 loss : 0.022731 model2 loss : 0.023223
[03:11:57.807] iteration 29576 : model1 loss : 0.029290 model2 loss : 0.030235
[03:11:58.473] iteration 29577 : model1 loss : 0.020924 model2 loss : 0.019429
[03:11:59.127] iteration 29578 : model1 loss : 0.021031 model2 loss : 0.020841
[03:11:59.781] iteration 29579 : model1 loss : 0.022606 model2 loss : 0.022715
[03:12:00.434] iteration 29580 : model1 loss : 0.018694 model2 loss : 0.018626
[03:12:01.099] iteration 29581 : model1 loss : 0.021100 model2 loss : 0.020294
[03:12:01.769] iteration 29582 : model1 loss : 0.018134 model2 loss : 0.017873
[03:12:02.434] iteration 29583 : model1 loss : 0.021560 model2 loss : 0.021469
[03:12:03.087] iteration 29584 : model1 loss : 0.019296 model2 loss : 0.018618
[03:12:03.740] iteration 29585 : model1 loss : 0.020509 model2 loss : 0.021861
[03:12:04.411] iteration 29586 : model1 loss : 0.013140 model2 loss : 0.013506
[03:12:05.074] iteration 29587 : model1 loss : 0.020009 model2 loss : 0.019850
[03:12:05.733] iteration 29588 : model1 loss : 0.021075 model2 loss : 0.020760
[03:12:06.397] iteration 29589 : model1 loss : 0.018512 model2 loss : 0.019705
[03:12:07.051] iteration 29590 : model1 loss : 0.020112 model2 loss : 0.017151
[03:12:07.708] iteration 29591 : model1 loss : 0.017110 model2 loss : 0.016429
[03:12:08.356] iteration 29592 : model1 loss : 0.023058 model2 loss : 0.027111
[03:12:09.042] iteration 29593 : model1 loss : 0.018322 model2 loss : 0.016983
[03:12:09.712] iteration 29594 : model1 loss : 0.017732 model2 loss : 0.018506
[03:12:10.377] iteration 29595 : model1 loss : 0.018924 model2 loss : 0.019060
[03:12:11.033] iteration 29596 : model1 loss : 0.033892 model2 loss : 0.039861
[03:12:11.689] iteration 29597 : model1 loss : 0.030792 model2 loss : 0.027379
[03:12:12.353] iteration 29598 : model1 loss : 0.013607 model2 loss : 0.012813
[03:12:13.027] iteration 29599 : model1 loss : 0.015008 model2 loss : 0.015054
[03:12:13.693] iteration 29600 : model1 loss : 0.021270 model2 loss : 0.021136
[03:12:31.689] iteration 29600 : model1_mean_dice : 0.876756 model1_mean_hd95 : 7.044768
[03:12:49.344] iteration 29600 : model2_mean_dice : 0.878775 model2_mean_hd95 : 4.845543
[03:12:50.019] iteration 29601 : model1 loss : 0.014991 model2 loss : 0.015235
[03:12:50.676] iteration 29602 : model1 loss : 0.017429 model2 loss : 0.017735
[03:12:51.341] iteration 29603 : model1 loss : 0.018622 model2 loss : 0.017401
[03:12:51.991] iteration 29604 : model1 loss : 0.016469 model2 loss : 0.015765
[03:12:52.642] iteration 29605 : model1 loss : 0.019647 model2 loss : 0.019139
[03:12:53.305] iteration 29606 : model1 loss : 0.018644 model2 loss : 0.018401
[03:12:53.975] iteration 29607 : model1 loss : 0.028126 model2 loss : 0.024928
[03:12:54.625] iteration 29608 : model1 loss : 0.016817 model2 loss : 0.017873
[03:12:55.271] iteration 29609 : model1 loss : 0.023304 model2 loss : 0.020798
[03:12:55.944] iteration 29610 : model1 loss : 0.023169 model2 loss : 0.023163
[03:12:56.600] iteration 29611 : model1 loss : 0.019339 model2 loss : 0.020578
[03:12:57.253] iteration 29612 : model1 loss : 0.022947 model2 loss : 0.021757
[03:12:57.912] iteration 29613 : model1 loss : 0.035094 model2 loss : 0.033580
[03:12:58.574] iteration 29614 : model1 loss : 0.022767 model2 loss : 0.022117
[03:12:59.236] iteration 29615 : model1 loss : 0.018348 model2 loss : 0.017716
[03:12:59.894] iteration 29616 : model1 loss : 0.018355 model2 loss : 0.017786
[03:13:00.553] iteration 29617 : model1 loss : 0.022440 model2 loss : 0.021177
[03:13:01.211] iteration 29618 : model1 loss : 0.017207 model2 loss : 0.018308
[03:13:01.874] iteration 29619 : model1 loss : 0.013658 model2 loss : 0.015038
[03:13:02.549] iteration 29620 : model1 loss : 0.026520 model2 loss : 0.027775
[03:13:03.209] iteration 29621 : model1 loss : 0.018830 model2 loss : 0.018803
[03:13:03.862] iteration 29622 : model1 loss : 0.026393 model2 loss : 0.025539
[03:13:04.513] iteration 29623 : model1 loss : 0.021132 model2 loss : 0.023752
[03:13:05.167] iteration 29624 : model1 loss : 0.024816 model2 loss : 0.023471
[03:13:05.819] iteration 29625 : model1 loss : 0.019372 model2 loss : 0.021429
[03:13:06.472] iteration 29626 : model1 loss : 0.013771 model2 loss : 0.015252
[03:13:07.136] iteration 29627 : model1 loss : 0.014581 model2 loss : 0.014439
[03:13:07.790] iteration 29628 : model1 loss : 0.022914 model2 loss : 0.019732
[03:13:08.452] iteration 29629 : model1 loss : 0.015155 model2 loss : 0.015340
[03:13:09.109] iteration 29630 : model1 loss : 0.019265 model2 loss : 0.020047
[03:13:09.756] iteration 29631 : model1 loss : 0.019815 model2 loss : 0.021639
[03:13:10.418] iteration 29632 : model1 loss : 0.022507 model2 loss : 0.020075
[03:13:11.081] iteration 29633 : model1 loss : 0.021003 model2 loss : 0.021063
[03:13:11.737] iteration 29634 : model1 loss : 0.016166 model2 loss : 0.018885
[03:13:12.381] iteration 29635 : model1 loss : 0.025252 model2 loss : 0.023615
[03:13:13.038] iteration 29636 : model1 loss : 0.015284 model2 loss : 0.015513
[03:13:13.690] iteration 29637 : model1 loss : 0.024856 model2 loss : 0.024774
[03:13:14.347] iteration 29638 : model1 loss : 0.017681 model2 loss : 0.016177
[03:13:15.013] iteration 29639 : model1 loss : 0.024208 model2 loss : 0.021445
[03:13:15.665] iteration 29640 : model1 loss : 0.022021 model2 loss : 0.024498
[03:13:16.337] iteration 29641 : model1 loss : 0.024561 model2 loss : 0.025660
[03:13:17.004] iteration 29642 : model1 loss : 0.017025 model2 loss : 0.015053
[03:13:17.664] iteration 29643 : model1 loss : 0.018115 model2 loss : 0.018329
[03:13:18.337] iteration 29644 : model1 loss : 0.021418 model2 loss : 0.022366
[03:13:18.996] iteration 29645 : model1 loss : 0.019439 model2 loss : 0.019287
[03:13:19.641] iteration 29646 : model1 loss : 0.021713 model2 loss : 0.021263
[03:13:20.303] iteration 29647 : model1 loss : 0.031316 model2 loss : 0.029626
[03:13:20.967] iteration 29648 : model1 loss : 0.023938 model2 loss : 0.023587
[03:13:21.651] iteration 29649 : model1 loss : 0.019167 model2 loss : 0.018515
[03:13:22.306] iteration 29650 : model1 loss : 0.026572 model2 loss : 0.026487
[03:13:23.021] iteration 29651 : model1 loss : 0.033036 model2 loss : 0.033342
[03:13:23.682] iteration 29652 : model1 loss : 0.022374 model2 loss : 0.021673
[03:13:24.344] iteration 29653 : model1 loss : 0.025914 model2 loss : 0.026353
[03:13:24.990] iteration 29654 : model1 loss : 0.019579 model2 loss : 0.019318
[03:13:25.652] iteration 29655 : model1 loss : 0.017964 model2 loss : 0.019392
[03:13:26.320] iteration 29656 : model1 loss : 0.015780 model2 loss : 0.017615
[03:13:26.972] iteration 29657 : model1 loss : 0.020995 model2 loss : 0.021519
[03:13:27.630] iteration 29658 : model1 loss : 0.040057 model2 loss : 0.045226
[03:13:28.287] iteration 29659 : model1 loss : 0.019246 model2 loss : 0.017510
[03:13:28.944] iteration 29660 : model1 loss : 0.015435 model2 loss : 0.014824
[03:13:29.604] iteration 29661 : model1 loss : 0.022162 model2 loss : 0.024226
[03:13:30.264] iteration 29662 : model1 loss : 0.016349 model2 loss : 0.016355
[03:13:30.916] iteration 29663 : model1 loss : 0.022366 model2 loss : 0.023343
[03:13:31.579] iteration 29664 : model1 loss : 0.022650 model2 loss : 0.021923
[03:13:32.235] iteration 29665 : model1 loss : 0.017601 model2 loss : 0.016835
[03:13:32.902] iteration 29666 : model1 loss : 0.013991 model2 loss : 0.015371
[03:13:33.560] iteration 29667 : model1 loss : 0.024229 model2 loss : 0.024435
[03:13:34.221] iteration 29668 : model1 loss : 0.021331 model2 loss : 0.021797
[03:13:34.880] iteration 29669 : model1 loss : 0.014441 model2 loss : 0.015826
[03:13:35.535] iteration 29670 : model1 loss : 0.016825 model2 loss : 0.017312
[03:13:36.194] iteration 29671 : model1 loss : 0.019215 model2 loss : 0.017116
[03:13:36.852] iteration 29672 : model1 loss : 0.022418 model2 loss : 0.021349
[03:13:37.507] iteration 29673 : model1 loss : 0.016869 model2 loss : 0.017065
[03:13:38.171] iteration 29674 : model1 loss : 0.021491 model2 loss : 0.017636
[03:13:38.824] iteration 29675 : model1 loss : 0.023395 model2 loss : 0.024147
[03:13:39.479] iteration 29676 : model1 loss : 0.021762 model2 loss : 0.021558
[03:13:40.142] iteration 29677 : model1 loss : 0.018013 model2 loss : 0.018697
[03:13:40.794] iteration 29678 : model1 loss : 0.023585 model2 loss : 0.022357
[03:13:41.456] iteration 29679 : model1 loss : 0.022988 model2 loss : 0.024676
[03:13:42.110] iteration 29680 : model1 loss : 0.016485 model2 loss : 0.015570
[03:13:42.772] iteration 29681 : model1 loss : 0.014918 model2 loss : 0.016031
[03:13:43.430] iteration 29682 : model1 loss : 0.024140 model2 loss : 0.022969
[03:13:44.085] iteration 29683 : model1 loss : 0.019184 model2 loss : 0.018751
[03:13:44.736] iteration 29684 : model1 loss : 0.018551 model2 loss : 0.019035
[03:13:45.385] iteration 29685 : model1 loss : 0.021839 model2 loss : 0.020869
[03:13:46.047] iteration 29686 : model1 loss : 0.018042 model2 loss : 0.017830
[03:13:46.700] iteration 29687 : model1 loss : 0.019785 model2 loss : 0.017228
[03:13:47.353] iteration 29688 : model1 loss : 0.017310 model2 loss : 0.017331
[03:13:48.018] iteration 29689 : model1 loss : 0.032167 model2 loss : 0.021970
[03:13:48.678] iteration 29690 : model1 loss : 0.021151 model2 loss : 0.021284
[03:13:49.335] iteration 29691 : model1 loss : 0.022765 model2 loss : 0.024526
[03:13:49.988] iteration 29692 : model1 loss : 0.018196 model2 loss : 0.019621
[03:13:50.642] iteration 29693 : model1 loss : 0.016508 model2 loss : 0.016392
[03:13:51.328] iteration 29694 : model1 loss : 0.021963 model2 loss : 0.021631
[03:13:51.981] iteration 29695 : model1 loss : 0.020091 model2 loss : 0.020920
[03:13:52.641] iteration 29696 : model1 loss : 0.018604 model2 loss : 0.017139
[03:13:53.291] iteration 29697 : model1 loss : 0.030091 model2 loss : 0.028941
[03:13:53.950] iteration 29698 : model1 loss : 0.030874 model2 loss : 0.027730
[03:13:54.618] iteration 29699 : model1 loss : 0.018158 model2 loss : 0.018646
[03:13:55.269] iteration 29700 : model1 loss : 0.015275 model2 loss : 0.015066
[03:13:55.997] iteration 29701 : model1 loss : 0.019767 model2 loss : 0.020154
[03:13:56.658] iteration 29702 : model1 loss : 0.018660 model2 loss : 0.020356
[03:13:57.303] iteration 29703 : model1 loss : 0.016008 model2 loss : 0.014510
[03:13:57.966] iteration 29704 : model1 loss : 0.017083 model2 loss : 0.018155
[03:13:58.649] iteration 29705 : model1 loss : 0.016386 model2 loss : 0.015142
[03:13:59.327] iteration 29706 : model1 loss : 0.020697 model2 loss : 0.022083
[03:14:00.003] iteration 29707 : model1 loss : 0.023829 model2 loss : 0.024737
[03:14:00.661] iteration 29708 : model1 loss : 0.024908 model2 loss : 0.026948
[03:14:01.323] iteration 29709 : model1 loss : 0.020170 model2 loss : 0.021520
[03:14:01.982] iteration 29710 : model1 loss : 0.020921 model2 loss : 0.022726
[03:14:02.647] iteration 29711 : model1 loss : 0.017967 model2 loss : 0.018245
[03:14:03.304] iteration 29712 : model1 loss : 0.018638 model2 loss : 0.019876
[03:14:03.964] iteration 29713 : model1 loss : 0.023364 model2 loss : 0.021340
[03:14:04.644] iteration 29714 : model1 loss : 0.023514 model2 loss : 0.024084
[03:14:05.307] iteration 29715 : model1 loss : 0.016220 model2 loss : 0.016572
[03:14:05.956] iteration 29716 : model1 loss : 0.019931 model2 loss : 0.019899
[03:14:06.615] iteration 29717 : model1 loss : 0.016648 model2 loss : 0.016389
[03:14:07.268] iteration 29718 : model1 loss : 0.031033 model2 loss : 0.029776
[03:14:07.926] iteration 29719 : model1 loss : 0.018329 model2 loss : 0.018298
[03:14:08.602] iteration 29720 : model1 loss : 0.020871 model2 loss : 0.020532
[03:14:09.261] iteration 29721 : model1 loss : 0.021245 model2 loss : 0.022786
[03:14:09.921] iteration 29722 : model1 loss : 0.020107 model2 loss : 0.022513
[03:14:10.576] iteration 29723 : model1 loss : 0.017050 model2 loss : 0.017793
[03:14:11.241] iteration 29724 : model1 loss : 0.022069 model2 loss : 0.022427
[03:14:11.891] iteration 29725 : model1 loss : 0.036623 model2 loss : 0.033594
[03:14:12.572] iteration 29726 : model1 loss : 0.030096 model2 loss : 0.029380
[03:14:13.240] iteration 29727 : model1 loss : 0.016213 model2 loss : 0.015589
[03:14:13.898] iteration 29728 : model1 loss : 0.025333 model2 loss : 0.024132
[03:14:14.553] iteration 29729 : model1 loss : 0.019684 model2 loss : 0.019932
[03:14:15.212] iteration 29730 : model1 loss : 0.021106 model2 loss : 0.020795
[03:14:15.872] iteration 29731 : model1 loss : 0.022398 model2 loss : 0.022658
[03:14:16.524] iteration 29732 : model1 loss : 0.018915 model2 loss : 0.019423
[03:14:17.179] iteration 29733 : model1 loss : 0.020607 model2 loss : 0.020007
[03:14:17.847] iteration 29734 : model1 loss : 0.017560 model2 loss : 0.018826
[03:14:18.522] iteration 29735 : model1 loss : 0.023657 model2 loss : 0.020365
[03:14:19.175] iteration 29736 : model1 loss : 0.027100 model2 loss : 0.030631
[03:14:19.834] iteration 29737 : model1 loss : 0.015942 model2 loss : 0.017716
[03:14:20.488] iteration 29738 : model1 loss : 0.022258 model2 loss : 0.022633
[03:14:21.158] iteration 29739 : model1 loss : 0.019152 model2 loss : 0.020220
[03:14:21.837] iteration 29740 : model1 loss : 0.015962 model2 loss : 0.015475
[03:14:22.499] iteration 29741 : model1 loss : 0.020805 model2 loss : 0.017219
[03:14:23.144] iteration 29742 : model1 loss : 0.017089 model2 loss : 0.017621
[03:14:23.807] iteration 29743 : model1 loss : 0.025136 model2 loss : 0.023876
[03:14:24.482] iteration 29744 : model1 loss : 0.026164 model2 loss : 0.025522
[03:14:25.131] iteration 29745 : model1 loss : 0.017392 model2 loss : 0.017036
[03:14:25.791] iteration 29746 : model1 loss : 0.019329 model2 loss : 0.017841
[03:14:26.448] iteration 29747 : model1 loss : 0.020819 model2 loss : 0.019762
[03:14:27.100] iteration 29748 : model1 loss : 0.017898 model2 loss : 0.018765
[03:14:27.754] iteration 29749 : model1 loss : 0.021357 model2 loss : 0.021400
[03:14:28.428] iteration 29750 : model1 loss : 0.014666 model2 loss : 0.014217
[03:14:29.132] iteration 29751 : model1 loss : 0.018028 model2 loss : 0.018353
[03:14:29.787] iteration 29752 : model1 loss : 0.017881 model2 loss : 0.017080
[03:14:30.451] iteration 29753 : model1 loss : 0.020330 model2 loss : 0.019770
[03:14:31.110] iteration 29754 : model1 loss : 0.014736 model2 loss : 0.015914
[03:14:31.779] iteration 29755 : model1 loss : 0.031765 model2 loss : 0.029355
[03:14:32.449] iteration 29756 : model1 loss : 0.018586 model2 loss : 0.017105
[03:14:33.108] iteration 29757 : model1 loss : 0.023422 model2 loss : 0.020321
[03:14:33.767] iteration 29758 : model1 loss : 0.033171 model2 loss : 0.031388
[03:14:34.415] iteration 29759 : model1 loss : 0.017373 model2 loss : 0.018715
[03:14:35.097] iteration 29760 : model1 loss : 0.016770 model2 loss : 0.016706
[03:14:35.750] iteration 29761 : model1 loss : 0.017920 model2 loss : 0.019963
[03:14:36.404] iteration 29762 : model1 loss : 0.016979 model2 loss : 0.017671
[03:14:37.065] iteration 29763 : model1 loss : 0.023878 model2 loss : 0.025751
[03:14:37.740] iteration 29764 : model1 loss : 0.024909 model2 loss : 0.025612
[03:14:38.404] iteration 29765 : model1 loss : 0.014921 model2 loss : 0.015798
[03:14:39.071] iteration 29766 : model1 loss : 0.019439 model2 loss : 0.018453
[03:14:39.736] iteration 29767 : model1 loss : 0.023854 model2 loss : 0.027374
[03:14:40.392] iteration 29768 : model1 loss : 0.022420 model2 loss : 0.019856
[03:14:41.054] iteration 29769 : model1 loss : 0.016969 model2 loss : 0.016939
[03:14:41.711] iteration 29770 : model1 loss : 0.014390 model2 loss : 0.014770
[03:14:42.370] iteration 29771 : model1 loss : 0.014275 model2 loss : 0.014310
[03:14:43.025] iteration 29772 : model1 loss : 0.021566 model2 loss : 0.019750
[03:14:43.684] iteration 29773 : model1 loss : 0.023583 model2 loss : 0.021534
[03:14:44.363] iteration 29774 : model1 loss : 0.018200 model2 loss : 0.018487
[03:14:45.013] iteration 29775 : model1 loss : 0.018582 model2 loss : 0.017742
[03:14:45.676] iteration 29776 : model1 loss : 0.017744 model2 loss : 0.017585
[03:14:46.327] iteration 29777 : model1 loss : 0.023131 model2 loss : 0.023856
[03:14:46.979] iteration 29778 : model1 loss : 0.023060 model2 loss : 0.021788
[03:14:47.643] iteration 29779 : model1 loss : 0.022952 model2 loss : 0.023564
[03:14:48.301] iteration 29780 : model1 loss : 0.037614 model2 loss : 0.039889
[03:14:48.960] iteration 29781 : model1 loss : 0.018080 model2 loss : 0.020739
[03:14:49.624] iteration 29782 : model1 loss : 0.017364 model2 loss : 0.016707
[03:14:50.285] iteration 29783 : model1 loss : 0.024999 model2 loss : 0.032290
[03:14:50.942] iteration 29784 : model1 loss : 0.015148 model2 loss : 0.016585
[03:14:51.607] iteration 29785 : model1 loss : 0.060988 model2 loss : 0.053977
[03:14:52.266] iteration 29786 : model1 loss : 0.018253 model2 loss : 0.017961
[03:14:52.936] iteration 29787 : model1 loss : 0.021480 model2 loss : 0.021400
[03:14:53.585] iteration 29788 : model1 loss : 0.028572 model2 loss : 0.033671
[03:14:54.241] iteration 29789 : model1 loss : 0.015166 model2 loss : 0.014990
[03:14:54.899] iteration 29790 : model1 loss : 0.015540 model2 loss : 0.014339
[03:14:55.555] iteration 29791 : model1 loss : 0.018186 model2 loss : 0.020720
[03:14:56.209] iteration 29792 : model1 loss : 0.019839 model2 loss : 0.017192
[03:14:56.873] iteration 29793 : model1 loss : 0.019703 model2 loss : 0.019411
[03:14:57.544] iteration 29794 : model1 loss : 0.043851 model2 loss : 0.056382
[03:14:58.207] iteration 29795 : model1 loss : 0.021407 model2 loss : 0.019938
[03:14:58.864] iteration 29796 : model1 loss : 0.019547 model2 loss : 0.024336
[03:14:59.522] iteration 29797 : model1 loss : 0.025484 model2 loss : 0.017255
[03:15:00.191] iteration 29798 : model1 loss : 0.017909 model2 loss : 0.017541
[03:15:00.846] iteration 29799 : model1 loss : 0.018775 model2 loss : 0.016926
[03:15:01.513] iteration 29800 : model1 loss : 0.141748 model2 loss : 0.144552
[03:15:19.267] iteration 29800 : model1_mean_dice : 0.876961 model1_mean_hd95 : 7.425565
[03:15:37.003] iteration 29800 : model2_mean_dice : 0.880928 model2_mean_hd95 : 4.800330
[03:15:37.679] iteration 29801 : model1 loss : 0.017868 model2 loss : 0.016747
[03:15:38.335] iteration 29802 : model1 loss : 0.021384 model2 loss : 0.020178
[03:15:38.988] iteration 29803 : model1 loss : 0.020965 model2 loss : 0.019454
[03:15:39.651] iteration 29804 : model1 loss : 0.018754 model2 loss : 0.017992
[03:15:40.298] iteration 29805 : model1 loss : 0.018286 model2 loss : 0.018744
[03:15:40.957] iteration 29806 : model1 loss : 0.014562 model2 loss : 0.014199
[03:15:41.605] iteration 29807 : model1 loss : 0.023848 model2 loss : 0.023225
[03:15:42.263] iteration 29808 : model1 loss : 0.018451 model2 loss : 0.020845
[03:15:42.927] iteration 29809 : model1 loss : 0.015235 model2 loss : 0.015304
[03:15:43.585] iteration 29810 : model1 loss : 0.033187 model2 loss : 0.034928
[03:15:44.242] iteration 29811 : model1 loss : 0.025805 model2 loss : 0.025808
[03:15:44.890] iteration 29812 : model1 loss : 0.018833 model2 loss : 0.018649
[03:15:45.550] iteration 29813 : model1 loss : 0.018443 model2 loss : 0.019414
[03:15:46.207] iteration 29814 : model1 loss : 0.137965 model2 loss : 0.138637
[03:15:46.862] iteration 29815 : model1 loss : 0.018296 model2 loss : 0.019699
[03:15:47.523] iteration 29816 : model1 loss : 0.015920 model2 loss : 0.015316
[03:15:48.174] iteration 29817 : model1 loss : 0.014933 model2 loss : 0.015515
[03:15:48.820] iteration 29818 : model1 loss : 0.017433 model2 loss : 0.016543
[03:15:49.477] iteration 29819 : model1 loss : 0.018558 model2 loss : 0.019943
[03:15:50.127] iteration 29820 : model1 loss : 0.015947 model2 loss : 0.018496
[03:15:50.800] iteration 29821 : model1 loss : 0.023455 model2 loss : 0.022676
[03:15:51.465] iteration 29822 : model1 loss : 0.019087 model2 loss : 0.018701
[03:15:52.118] iteration 29823 : model1 loss : 0.018519 model2 loss : 0.018164
[03:15:52.772] iteration 29824 : model1 loss : 0.018034 model2 loss : 0.018442
[03:15:53.433] iteration 29825 : model1 loss : 0.022528 model2 loss : 0.018756
[03:15:54.084] iteration 29826 : model1 loss : 0.022879 model2 loss : 0.021420
[03:15:54.741] iteration 29827 : model1 loss : 0.020470 model2 loss : 0.020229
[03:15:55.405] iteration 29828 : model1 loss : 0.037900 model2 loss : 0.036955
[03:15:56.069] iteration 29829 : model1 loss : 0.026747 model2 loss : 0.026581
[03:15:56.722] iteration 29830 : model1 loss : 0.018248 model2 loss : 0.016877
[03:15:57.397] iteration 29831 : model1 loss : 0.021664 model2 loss : 0.022606
[03:15:58.056] iteration 29832 : model1 loss : 0.022748 model2 loss : 0.021023
[03:15:58.714] iteration 29833 : model1 loss : 0.021981 model2 loss : 0.025181
[03:15:59.366] iteration 29834 : model1 loss : 0.043846 model2 loss : 0.034323
[03:16:00.008] iteration 29835 : model1 loss : 0.021274 model2 loss : 0.021638
[03:16:00.675] iteration 29836 : model1 loss : 0.020156 model2 loss : 0.018295
[03:16:01.339] iteration 29837 : model1 loss : 0.023307 model2 loss : 0.022168
[03:16:01.995] iteration 29838 : model1 loss : 0.019717 model2 loss : 0.019065
[03:16:02.664] iteration 29839 : model1 loss : 0.015861 model2 loss : 0.015813
[03:16:03.324] iteration 29840 : model1 loss : 0.016280 model2 loss : 0.017107
[03:16:03.999] iteration 29841 : model1 loss : 0.016275 model2 loss : 0.016521
[03:16:04.658] iteration 29842 : model1 loss : 0.016841 model2 loss : 0.015308
[03:16:05.335] iteration 29843 : model1 loss : 0.029904 model2 loss : 0.030996
[03:16:05.982] iteration 29844 : model1 loss : 0.018913 model2 loss : 0.021081
[03:16:06.629] iteration 29845 : model1 loss : 0.015214 model2 loss : 0.014825
[03:16:07.272] iteration 29846 : model1 loss : 0.020302 model2 loss : 0.019981
[03:16:07.936] iteration 29847 : model1 loss : 0.017252 model2 loss : 0.018939
[03:16:08.609] iteration 29848 : model1 loss : 0.018961 model2 loss : 0.018409
[03:16:09.269] iteration 29849 : model1 loss : 0.019618 model2 loss : 0.019227
[03:16:09.935] iteration 29850 : model1 loss : 0.023405 model2 loss : 0.023449
[03:16:10.633] iteration 29851 : model1 loss : 0.027911 model2 loss : 0.030026
[03:16:11.300] iteration 29852 : model1 loss : 0.021378 model2 loss : 0.021069
[03:16:11.958] iteration 29853 : model1 loss : 0.021052 model2 loss : 0.019934
[03:16:12.617] iteration 29854 : model1 loss : 0.020890 model2 loss : 0.019404
[03:16:13.267] iteration 29855 : model1 loss : 0.041014 model2 loss : 0.045387
[03:16:13.929] iteration 29856 : model1 loss : 0.018028 model2 loss : 0.016982
[03:16:14.587] iteration 29857 : model1 loss : 0.020844 model2 loss : 0.020598
[03:16:15.239] iteration 29858 : model1 loss : 0.022017 model2 loss : 0.019339
[03:16:15.899] iteration 29859 : model1 loss : 0.017096 model2 loss : 0.016100
[03:16:16.561] iteration 29860 : model1 loss : 0.017750 model2 loss : 0.016932
[03:16:17.214] iteration 29861 : model1 loss : 0.021891 model2 loss : 0.022686
[03:16:17.879] iteration 29862 : model1 loss : 0.022749 model2 loss : 0.026054
[03:16:18.550] iteration 29863 : model1 loss : 0.016666 model2 loss : 0.016583
[03:16:19.260] iteration 29864 : model1 loss : 0.022211 model2 loss : 0.019934
[03:16:19.922] iteration 29865 : model1 loss : 0.035083 model2 loss : 0.034084
[03:16:20.574] iteration 29866 : model1 loss : 0.020948 model2 loss : 0.020002
[03:16:21.229] iteration 29867 : model1 loss : 0.018484 model2 loss : 0.019071
[03:16:21.883] iteration 29868 : model1 loss : 0.018867 model2 loss : 0.019357
[03:16:22.555] iteration 29869 : model1 loss : 0.019690 model2 loss : 0.018876
[03:16:23.211] iteration 29870 : model1 loss : 0.017548 model2 loss : 0.018264
[03:16:23.868] iteration 29871 : model1 loss : 0.018740 model2 loss : 0.017956
[03:16:24.539] iteration 29872 : model1 loss : 0.015085 model2 loss : 0.015211
[03:16:25.206] iteration 29873 : model1 loss : 0.018811 model2 loss : 0.019718
[03:16:25.866] iteration 29874 : model1 loss : 0.020689 model2 loss : 0.020140
[03:16:26.520] iteration 29875 : model1 loss : 0.014280 model2 loss : 0.014514
[03:16:27.191] iteration 29876 : model1 loss : 0.024137 model2 loss : 0.023373
[03:16:27.860] iteration 29877 : model1 loss : 0.032445 model2 loss : 0.036803
[03:16:28.527] iteration 29878 : model1 loss : 0.020014 model2 loss : 0.019727
[03:16:29.189] iteration 29879 : model1 loss : 0.022533 model2 loss : 0.021774
[03:16:29.849] iteration 29880 : model1 loss : 0.020895 model2 loss : 0.020180
[03:16:30.506] iteration 29881 : model1 loss : 0.019979 model2 loss : 0.018939
[03:16:31.157] iteration 29882 : model1 loss : 0.017647 model2 loss : 0.019501
[03:16:31.824] iteration 29883 : model1 loss : 0.020958 model2 loss : 0.021711
[03:16:32.489] iteration 29884 : model1 loss : 0.015560 model2 loss : 0.014853
[03:16:33.143] iteration 29885 : model1 loss : 0.019804 model2 loss : 0.019192
[03:16:33.804] iteration 29886 : model1 loss : 0.018421 model2 loss : 0.018723
[03:16:34.465] iteration 29887 : model1 loss : 0.013390 model2 loss : 0.012527
[03:16:35.118] iteration 29888 : model1 loss : 0.014664 model2 loss : 0.013726
[03:16:35.770] iteration 29889 : model1 loss : 0.018202 model2 loss : 0.017591
[03:16:36.431] iteration 29890 : model1 loss : 0.024035 model2 loss : 0.024290
[03:16:37.094] iteration 29891 : model1 loss : 0.022755 model2 loss : 0.024057
[03:16:37.753] iteration 29892 : model1 loss : 0.024020 model2 loss : 0.025346
[03:16:38.411] iteration 29893 : model1 loss : 0.016142 model2 loss : 0.016834
[03:16:39.068] iteration 29894 : model1 loss : 0.021223 model2 loss : 0.021906
[03:16:39.725] iteration 29895 : model1 loss : 0.021164 model2 loss : 0.019562
[03:16:40.401] iteration 29896 : model1 loss : 0.018178 model2 loss : 0.020296
[03:16:41.059] iteration 29897 : model1 loss : 0.017584 model2 loss : 0.018840
[03:16:41.702] iteration 29898 : model1 loss : 0.016350 model2 loss : 0.016359
[03:16:42.357] iteration 29899 : model1 loss : 0.141071 model2 loss : 0.140240
[03:16:43.025] iteration 29900 : model1 loss : 0.017172 model2 loss : 0.019008
[03:16:43.744] iteration 29901 : model1 loss : 0.024008 model2 loss : 0.021722
[03:16:44.415] iteration 29902 : model1 loss : 0.014978 model2 loss : 0.015757
[03:16:45.068] iteration 29903 : model1 loss : 0.012009 model2 loss : 0.012581
[03:16:45.736] iteration 29904 : model1 loss : 0.025892 model2 loss : 0.025983
[03:16:46.396] iteration 29905 : model1 loss : 0.019198 model2 loss : 0.019643
[03:16:47.069] iteration 29906 : model1 loss : 0.027570 model2 loss : 0.027091
[03:16:47.734] iteration 29907 : model1 loss : 0.136258 model2 loss : 0.137998
[03:16:48.405] iteration 29908 : model1 loss : 0.019197 model2 loss : 0.020323
[03:16:49.062] iteration 29909 : model1 loss : 0.019741 model2 loss : 0.020106
[03:16:49.721] iteration 29910 : model1 loss : 0.026146 model2 loss : 0.023229
[03:16:50.376] iteration 29911 : model1 loss : 0.020999 model2 loss : 0.020718
[03:16:51.033] iteration 29912 : model1 loss : 0.018025 model2 loss : 0.018732
[03:16:51.701] iteration 29913 : model1 loss : 0.018835 model2 loss : 0.019193
[03:16:52.352] iteration 29914 : model1 loss : 0.024435 model2 loss : 0.023991
[03:16:53.009] iteration 29915 : model1 loss : 0.022744 model2 loss : 0.024215
[03:16:53.675] iteration 29916 : model1 loss : 0.033763 model2 loss : 0.040970
[03:16:54.340] iteration 29917 : model1 loss : 0.019667 model2 loss : 0.019040
[03:16:55.001] iteration 29918 : model1 loss : 0.021523 model2 loss : 0.021079
[03:16:55.663] iteration 29919 : model1 loss : 0.021791 model2 loss : 0.023026
[03:16:56.334] iteration 29920 : model1 loss : 0.016522 model2 loss : 0.016741
[03:16:57.002] iteration 29921 : model1 loss : 0.014896 model2 loss : 0.016239
[03:16:57.661] iteration 29922 : model1 loss : 0.097280 model2 loss : 0.067035
[03:16:58.320] iteration 29923 : model1 loss : 0.017210 model2 loss : 0.015983
[03:16:58.995] iteration 29924 : model1 loss : 0.020113 model2 loss : 0.020177
[03:16:59.658] iteration 29925 : model1 loss : 0.015846 model2 loss : 0.017308
[03:17:00.313] iteration 29926 : model1 loss : 0.021550 model2 loss : 0.020043
[03:17:00.974] iteration 29927 : model1 loss : 0.022344 model2 loss : 0.019572
[03:17:01.621] iteration 29928 : model1 loss : 0.014366 model2 loss : 0.015533
[03:17:02.283] iteration 29929 : model1 loss : 0.019145 model2 loss : 0.021650
[03:17:02.952] iteration 29930 : model1 loss : 0.018548 model2 loss : 0.019968
[03:17:03.610] iteration 29931 : model1 loss : 0.018050 model2 loss : 0.018629
[03:17:04.277] iteration 29932 : model1 loss : 0.023282 model2 loss : 0.021793
[03:17:04.932] iteration 29933 : model1 loss : 0.017538 model2 loss : 0.019757
[03:17:05.599] iteration 29934 : model1 loss : 0.019040 model2 loss : 0.019034
[03:17:06.254] iteration 29935 : model1 loss : 0.020915 model2 loss : 0.020263
[03:17:06.916] iteration 29936 : model1 loss : 0.017050 model2 loss : 0.017565
[03:17:07.583] iteration 29937 : model1 loss : 0.016231 model2 loss : 0.016104
[03:17:08.251] iteration 29938 : model1 loss : 0.019334 model2 loss : 0.019525
[03:17:08.911] iteration 29939 : model1 loss : 0.019369 model2 loss : 0.018986
[03:17:09.573] iteration 29940 : model1 loss : 0.018410 model2 loss : 0.018677
[03:17:10.225] iteration 29941 : model1 loss : 0.019673 model2 loss : 0.020394
[03:17:10.881] iteration 29942 : model1 loss : 0.018673 model2 loss : 0.018412
[03:17:11.539] iteration 29943 : model1 loss : 0.022931 model2 loss : 0.018768
[03:17:12.191] iteration 29944 : model1 loss : 0.015185 model2 loss : 0.015435
[03:17:12.854] iteration 29945 : model1 loss : 0.018026 model2 loss : 0.017996
[03:17:13.519] iteration 29946 : model1 loss : 0.023005 model2 loss : 0.023231
[03:17:14.192] iteration 29947 : model1 loss : 0.140311 model2 loss : 0.141900
[03:17:14.843] iteration 29948 : model1 loss : 0.015798 model2 loss : 0.015923
[03:17:15.513] iteration 29949 : model1 loss : 0.021556 model2 loss : 0.020473
[03:17:16.174] iteration 29950 : model1 loss : 0.027436 model2 loss : 0.028274
[03:17:16.872] iteration 29951 : model1 loss : 0.018993 model2 loss : 0.018989
[03:17:17.535] iteration 29952 : model1 loss : 0.021888 model2 loss : 0.022013
[03:17:18.189] iteration 29953 : model1 loss : 0.017424 model2 loss : 0.018399
[03:17:18.845] iteration 29954 : model1 loss : 0.017901 model2 loss : 0.019982
[03:17:19.556] iteration 29955 : model1 loss : 0.021265 model2 loss : 0.020667
[03:17:20.217] iteration 29956 : model1 loss : 0.017795 model2 loss : 0.016567
[03:17:20.883] iteration 29957 : model1 loss : 0.030366 model2 loss : 0.031451
[03:17:21.538] iteration 29958 : model1 loss : 0.020601 model2 loss : 0.022649
[03:17:22.196] iteration 29959 : model1 loss : 0.016933 model2 loss : 0.016542
[03:17:22.860] iteration 29960 : model1 loss : 0.022273 model2 loss : 0.022124
[03:17:23.531] iteration 29961 : model1 loss : 0.018518 model2 loss : 0.019071
[03:17:24.198] iteration 29962 : model1 loss : 0.020753 model2 loss : 0.023353
[03:17:24.853] iteration 29963 : model1 loss : 0.023283 model2 loss : 0.024004
[03:17:25.521] iteration 29964 : model1 loss : 0.017787 model2 loss : 0.016636
[03:17:26.193] iteration 29965 : model1 loss : 0.016268 model2 loss : 0.018101
[03:17:26.860] iteration 29966 : model1 loss : 0.016916 model2 loss : 0.017415
[03:17:27.525] iteration 29967 : model1 loss : 0.026769 model2 loss : 0.027148
[03:17:28.181] iteration 29968 : model1 loss : 0.025685 model2 loss : 0.025618
[03:17:28.860] iteration 29969 : model1 loss : 0.022511 model2 loss : 0.021289
[03:17:29.524] iteration 29970 : model1 loss : 0.017647 model2 loss : 0.018284
[03:17:30.186] iteration 29971 : model1 loss : 0.020307 model2 loss : 0.020865
[03:17:30.844] iteration 29972 : model1 loss : 0.018539 model2 loss : 0.017447
[03:17:31.506] iteration 29973 : model1 loss : 0.019204 model2 loss : 0.019739
[03:17:32.162] iteration 29974 : model1 loss : 0.023506 model2 loss : 0.024371
[03:17:32.822] iteration 29975 : model1 loss : 0.019911 model2 loss : 0.018612
[03:17:33.492] iteration 29976 : model1 loss : 0.018693 model2 loss : 0.019451
[03:17:34.159] iteration 29977 : model1 loss : 0.022619 model2 loss : 0.023839
[03:17:34.838] iteration 29978 : model1 loss : 0.138589 model2 loss : 0.138523
[03:17:35.494] iteration 29979 : model1 loss : 0.022345 model2 loss : 0.018959
[03:17:36.162] iteration 29980 : model1 loss : 0.016068 model2 loss : 0.015218
[03:17:36.823] iteration 29981 : model1 loss : 0.022323 model2 loss : 0.024375
[03:17:37.471] iteration 29982 : model1 loss : 0.029271 model2 loss : 0.024215
[03:17:38.124] iteration 29983 : model1 loss : 0.018021 model2 loss : 0.017921
[03:17:38.779] iteration 29984 : model1 loss : 0.018091 model2 loss : 0.021122
[03:17:39.438] iteration 29985 : model1 loss : 0.016553 model2 loss : 0.017981
[03:17:40.088] iteration 29986 : model1 loss : 0.018013 model2 loss : 0.017455
[03:17:40.752] iteration 29987 : model1 loss : 0.021031 model2 loss : 0.021325
[03:17:41.416] iteration 29988 : model1 loss : 0.024821 model2 loss : 0.025031
[03:17:42.076] iteration 29989 : model1 loss : 0.016842 model2 loss : 0.017473
[03:17:42.741] iteration 29990 : model1 loss : 0.018183 model2 loss : 0.018717
[03:17:43.402] iteration 29991 : model1 loss : 0.018641 model2 loss : 0.019374
[03:17:44.067] iteration 29992 : model1 loss : 0.018459 model2 loss : 0.019529
[03:17:44.725] iteration 29993 : model1 loss : 0.018192 model2 loss : 0.017549
[03:17:45.379] iteration 29994 : model1 loss : 0.018949 model2 loss : 0.019069
[03:17:46.040] iteration 29995 : model1 loss : 0.018467 model2 loss : 0.016676
[03:17:46.684] iteration 29996 : model1 loss : 0.015827 model2 loss : 0.015602
[03:17:47.342] iteration 29997 : model1 loss : 0.018029 model2 loss : 0.018011
[03:17:47.989] iteration 29998 : model1 loss : 0.017946 model2 loss : 0.017138
[03:17:48.644] iteration 29999 : model1 loss : 0.018965 model2 loss : 0.018948
[03:17:49.296] iteration 30000 : model1 loss : 0.017451 model2 loss : 0.017084
[03:18:06.850] iteration 30000 : model1_mean_dice : 0.876735 model1_mean_hd95 : 7.402036
[03:18:24.543] iteration 30000 : model2_mean_dice : 0.880113 model2_mean_hd95 : 4.821936
[03:18:24.605] save model1 to ../model/ACDC/my_net3210_14/unet_cct\model1_iter_30000.pth
[03:18:24.667] save model2 to ../model/ACDC/my_net3210_14/unet_cct\model2_iter_30000.pth
